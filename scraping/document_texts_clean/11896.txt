detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/11896engaging privacy and information technology in a digital age450 pages | 6 x 9 | hardbackisbn 9780309103923 | doi 10.17226/11896james waldo, herbert s. lin, and lynette i. millett, editors; committee onprivacy in the information age; computer science and telecommunications board;division on engineering and physical sciences; national research councilengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.james waldo, herbert s. lin, and lynette i. millett, editorscommittee on privacy in the information agecomputer science and telecommunications boarddivision on engineering and physical sciencesengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.support for this project was provided by the w.k. kellogg foundation, sponsor award no. p0081389; the alfred p. sloan foundation, sponsor award no. 2001321; the at&t foundation; and the carnegie corporation of new york, sponsor award no. b 7415. any opinions, ndings, conclusions, or recommendations expressed in this publication are those of the author(s) and do not necessarily re˚ect the views of the organizations or agencies that provided support for the project.library of congress cataloginginpublication dataengaging privacy and information technology in a digital age / james waldo, herbert s. lin, and lynette i. millett, editors. p. cm. includes bibliographical references and index. isbn 9780309103923 (hardcover) š isbn 9780309667326 (pdf) 1. data protection. 2. privacy, right ofšunited states. i. waldo, james. ii. lin, herbert. iii. millett, lynette i. qa76.9.a25e5425 2007005.8dc22 2007014433copies of this report are available from the national academies press, 500 fifth street, n.w., lockbox 285, washington, dc 20055; (800) 6246242 or (202) 3343313 (in the washington metropolitan area); internet, http://www.nap.edu.copyright 2007 by the national academy of sciences. all rights reserved.printed in the united states of americaengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. wm. a. wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. wm. a. wulf are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.committee on privacy in the information agewilliam h. webster, milbank, tweed, hadley & mccloy, chairjames waldo, sun microsystems, vice chairjulie e. cohen, georgetown universityrobert w. crandall, brookings institution (resigned april 2006)oscar gandy, jr., university of pennsylvaniajames horning, network associates laboratoriesgary king, harvard universitylin e. knapp, independent consultant, ponte vedra beach, floridabrent lowensohn, independent consultant, encino, californiagary t. marx, massachusetts institute of technology (emeritus)helen nissenbaum, new york universityrobert m. o™neil, university of virginiajaney place, digital thinkingronald l. rivest, massachusetts institute of technologyteresa schwartz, george washington universitylloyd n. cutler, wilmer, cutler, pickering, hale & dorr llp, served as cochair until his passing in may 2005.staffherbert s. lin, senior scientistlynette i. millett, senior staff ofcerkristen batch, associate program ofcerjennifer m. bishop, program associatedavid padgham, associate program ofcerjanice m. sabuda, senior program assistantvengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.computer science and telecommunications boardjoseph f. traub, columbia university, chaireric benhamou, 3com corporationwilliam dally, stanford universitymark e. dean, ibm systems groupdavid dewitt, university of wisconsinmadisondeborah l. estrin, university of california, los angelesjoan feigenbaum, yale universitykevin kahn, intel corporationjames kajiya, microsoft corporationmichael katz, university of california, berkeleyrandy katz, university of california, berkeleysara kiesler, carnegie mellon universityteresa h. meng, stanford universitytom m. mitchell, carnegie mellon universityfred b. schneider, cornell universitywilliam stead, vanderbilt universityandrew viterbi, viterbi group, llcjeannette m. wing, carnegie mellon universityjon eisenberg, directorkristen batch, associate program ofcerrenee hawkins, financial associatemargaret marsh huynh, senior program assistantherbert s. lin, senior scientistlynette i. millett, senior program ofcerdavid padgham, associate program ofcerjanice m. sabuda, senior program assistantted schmitt, program ofcerbrandye williams, ofce assistantjoan winston, program ofcerfor more information on cstb, see its web site at http://www.cstb.org, write to cstb, national research council, 500 fifth street, n.w., washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.viengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.viiprefaceprivacy is a growing concern in the united states and around the world. the spread of the internet and the seemingly unbounded options for collecting, saving, sharing, and comparing information trigger consumer worries; online practices of businesses and government agencies present new ways to compromise privacy; and ecommerce and technologies that permit individuals to nd personal information about each other only begin to hint at the possibilities.the literature on privacy is extensive, and yet much of the work that has been done on privacy, and notably privacy in a context of pervasive information technology, has come from groups with a single point of view (e.g., civil liberties advocates, trade associations) and/or a mission that is associated with a point of view (e.g., regulatory agencies) or a slice of the problem (e.g., privacy in a single context such as health care).many of the groups that have looked at privacy have tended to be singular in their expertise. advocacy groups are typically staffed by lawyers, and scholarship activities within universities are conducted largely from the perspective of individual departments such as sociology, political science, or law. business/management experts address demand for personal information (typically for marketing or ecommerce). although a few economists have also examined privacy questions (mostly from the standpoint of marketable rights in privacy), the economicsoriented privacy literature is signicantly less extensive than the literature on intellectual property or equitable access. in an area such as privacy, approaches from any single discipline are unlikely to ﬁsolveﬂ the problem, making it engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.viii engaging privacy and information technology in a digital ageimportant to assess privacy in a manner that accounts for the implications of technology, law, economics, business, social science, and ethics.against this backdrop, the national research council believed that the time was ripe for a deep, comprehensive, and multidisciplinary examination of privacy in the information age: how are the threats to privacy evolving, how can privacy be protected, and how can society balance the interests of individuals, businesses, and government in ways that promote privacy reasonably and effectively?a variety of conversations in late 2000 with privacy advocates in nonprot organizations, and with private foundation ofcials about what their organizations have not been supporting, and ongoing conversations with computer scientists and other analysts who focus on information technology trends indicated a dearth of analytical work on the subject of online privacy that incorporated expertise about key technologies together with other kinds of expertise. without adequate technical expertise, information technology tends to be treated as a black box that has impacts on society; with such expertise, there can be a more realistic exploration of interactions among technical and nontechnical factors and of design and implementation alternatives, some of which can avoid or diminish adverse impacts.for these reasons, the national research council established the committee on privacy in the information age. the committee™s analytical charge had several elements (see chapter 1). the committee was to survey and analyze the causes for concernšrisks to personal information associated with new technologies (primarily information technologies, but from time to time biotechnologies as appropriate) and their interaction with nontechnologybased risks, the incidence of actual problems relative to the potential for problems, and trends in technology and practice that will in˚uence impacts on privacy. further, the charge called for these analyses to take into account changes in technology; business, government, and other organizational demand for and supply of personal information; and the increasing capabilities for individuals to collect and use, as well as disseminate, personal information. although certain areas (e.g., health and national security) were singled out for special attention, the goal was to paint a big picture that at least sketched the contours of the full set of interactions and tradeoffs.the charge is clearly a very broad one. thus, the committee chose to focus its primary efforts on fundamental concepts of privacy, the laws surrounding privacy, the tradeoffs in a number of societally important areas, and the impact of technology on conceptions of privacy.to what end does the committee offer such a consideration of privacy in the 21st century? this report does not present a denitive solution to any of the privacy challenges confronting society today. it does not proengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.preface ixvide a thorough and settled denition of privacy. and it does not evaluate specic policies or technologies as ﬁgoodﬂ or ﬁbad.ﬂrather, its primary purpose is to provide ways to think about privacy, its relationship to other values, and related tradeoffs. it emphasizes the need to understand context when evaluating the privacy impact of a given situation or technology. it provides an indepth look at ongoing information technology trends as related to privacy concerns. by doing so, the committee hopes that the report will contribute to a better understanding of the many issues that play a part in privacy and contribute to the analysis of issues involving privacy.in creating policies that address the demands of a rapidly changing society, we must be attuned to the interdependencies of complex systems. in particular, this must involve trying to avoid the unwitting creation of undesirable unintended consequences. we may decide to tolerate erosion on one side of a continuumšprivacy versus security, for example. under appropriate conditions the searching of travelers™ bags and the use of behavioral proles for additional examination are understandable. but with this comes a shift in the continuum of given types of privacy.perhaps most importantly, the report seeks to raise awareness of the web of connectedness among the actions we take, the policies we pass, the expectations we change. in creating policies that address the demands of a rapidly changing society, we must be attuned to the interdependencies of complex systemsšand whatever policy choices a society favors, the choices should be made consciously, with an understanding of their possible consequences.we may decide to tolerate erosion on one side of an issuešprivacy versus security, for example. we may decide it makes sense to allow security personnel to open our bags, to carry a ﬁtrusted travelerﬂ card, to ﬁproleﬂ people for additional examination. but with such actions come a change in the nature and the scope of privacy that people can expect. new policies may create a more desirable balance, but they should not create unanticipated surprises.to pursue its work, the national research council constituted a committee of 16 people with a broad range of expertise, including senior individuals with backgrounds in information technology, business, government, and other institutional uses of personal information; consumer protection; liability; economics; and privacy law and policy. from 2002 to 2003, the committee held ve meetings, most of which were intended to enable the committee to explore a wide range of different points of view. for example, briengs and/or other inputs were obtained from government ofcials at all levels, authorities on international law and practice relating to policy, social scientists and philosophers concerned with personal data collection, experts on privacyenhancing technologies, business engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.x engaging privacy and information technology in a digital agerepresentatives concerned with the gathering and uses of personal data, consumer advocates, and researchers who use personal data. several papers were commissioned and received.as the committee undertook its analysis, it was struck by the extraordinary complexity associated with the subject of privacy. most committee members understood that the notion of privacy is fraught with multiple meanings, interpretations, and value judgments. but nearly every thread of analysis leads to other questions and issues that also cry out for additional analysisšone might even regard the subject as fractal, where each level of analysis requires another equally complex level of analysis to explore the issues that the previous level raises. realistically, the analysis must be cut off at some point, if nothing else because of resource constraints. but the committee hopes that this report sufces to paint a representative and reasonably comprehensive picture of informational privacy, even if some interesting threads had to be arbitrarily limited.this study has been unusually challenging, both because of the nature of the subject matter and because the events that occurred during the time the report was being researched and written often seemed to be overtaking the work itself. the temptation to change the work of the committee in reaction to some news story or revelation of a pressing privacy concern was constant and powerful; our hope is that the work presented here will last longer than the concerns generated by any of those particular events.the very importance of the subject matter increases the difculty of approaching the issues in a calm and dispassionate manner. many members of the committee came to the process with welldeveloped convictions, and it was interesting to see these convictions soften, alter, and become more nuanced as the complexities of the subject became apparent. it is our hope that readers of this report will nd that the subject of privacy in our informationrich age is more subtle and complex than they had thought, and that solutions to the problems, while not impossible, are far from obvious.the committee was highly diverse. this diversity re˚ects the complexity of the subject, which required representation not just from the information sciences but also from policy makers, the law, business, and the social sciences and humanities. such diversity also means that the members of the committee came to the problem with different presuppositions, vocabularies, and ways of thinking about the problems surrounding privacy in our increasingly interconnected world. it is a testament to these members that they took the time and effort to learn from each other and from the many people who took the time to brief the committee. it is easy in such situations for the committee to decompose into smaller tribes of likethinking members who do not listen to those outside their tribe; what engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.preface xiin fact happened was that each group learned from the others. the collegial atmosphere that resulted strengthened the overall report by ensuring that many different viewpoints were represented and included.much of this collegial atmosphere was the result of the work of the staff of the national research council who guided this report. lynette millett started the study and has been invaluable through the entire process. herb lin injected the energy needed to move from rst to nal draft, asking all of the questions that needed to be asked and helping us to craft recommendations and ndings that are the real reason for the report. the committee could not have reached this point without them.special thanks are due to others on the cstb staff as well. marjory blumenthal, cstb™s former director, was pivotal in framing the project and making it happen. janice sabuda provided stalwart administrative and logistical support throughout the project. david padgham and kristen batch provided valuable research support and assistance.outside the nrc, many people contributed to this study and report. the committee took inputs from many individuals in plenary sessions, including both scheduled briefers and individuals who attended and participated in discussions. the committee also conducted several site visits and informational interviews and commissioned several papers. the committee is indebted to all of those who shared their ideas, time, and facilities. the committee thanks the following individuals for their inputs and assistance at various stages during the project: anita allencastellitto, kevin ashton, bruce berkowitz, jerry bogart, bill braithwaite, anne brown, david brown, bruce budowle, lee bygrave, michael caloyannides, cheryl charles, david chaum, ted cooper, amy d. corning, lorrie cranor, jim dempsey, george duncan, jeff dunn, ed felten, michael fitzmaurice, michael froomkin, moya gray, rick gubbels, van harp, dawn herkenham, julie kaneshiro, orin kerr, scott larson, edward laumann, ronald lee, david lyon, kate martin, patrice mcdermott, robert mcnamara, judith miller, carolyn mitchell, jim neal, pablo palazzi, kim patterson, merle pederson, priscilla regan, joel reidenberg, jeff rosen, mark rothstein, vincent serpico, donna shalala, martha shepard, eleanor singer, david sobel, joe steffan, barry steinhardt, carla stof˚e, gary strong, richard varn, kathleen wallace, mary gay whitmer and the nascio privacy team, and matthew wynia.finally, we must acknowledge the contribution of lloyd cutler, who served as cochair of the committee from the time of its inception to the time of his death in may 2005. lloyd was an active and energetic member of the committee, who insisted that we think about the principles involved and not just the particular cases being discussed. the intellectual rigor, curiosity, and decency shown and demanded by lloyd set the tone engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xii engaging privacy and information technology in a digital ageand the standard for the committee as a whole. we were fortunate to have him as part of our group, and we miss him very much.william webster, chairjim waldo, vice chaircommittee on privacy in the information ageengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xiiiacknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national research council™s report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:hal abelson, massachusetts institute of technology,ellen clayton, vanderbilt university medical center,peter cullen, microsoft corporation,george duncan, carnegie mellon university,beryl howell, stroz friedberg, llc,alan karr, national institute of statistical sciences,michael katz, university of california, berkeley,diane lambert, google, inc.,susan landau, sun microsystems laboratories,tom mitchell, carnegie mellon university,britton murray, freddie mac,charles palmer, ibm, thomas j. watson research center,emily sheketoff, american library association,engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xiv engaging privacy and information technology in a digital agerobert sparks, independent consultant, el dorado hills, california,peter swire, ohio state university, andalan westin, independent consultant, teaneck, new jersey.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by stephen fienberg, carnegie mellon university. appointed by the national research council, he was responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xvcontentsexecutive summary 1part i thinking about privacy1 thinking about privacy 191.1 introduction, 191.2 what is privacy?, 211.3 an illustrative case, 251.4 the dynamics of privacy, 271.4.1 the information age, 271.4.2 information transformed and the role of technology, 291.4.3 societal shifts and changes in institutional practice, 331.4.4 discontinuities in circumstance and current events, 361.4.4.1 national security and law enforcement, 371.4.4.2 disease and pandemic outbreak, 371.5 important concepts and ideas related to privacy, 381.5.1 personal information, sensitive information, and  personally identiable information, 391.5.2 false positives, false negatives, and data quality, 431.5.3 privacy and anonymity, 451.5.4 fair information practices, 481.5.5 reasonable expectations of privacy, 501.6 lessons from history, 521.7 scope and map of this report, 53engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xvi engaging privacy and information technology in a digital agepart ii the backdrop for privacy2 intellectual approaches and conceptual underpinnings 572.1 philosophical theories of privacy, 582.1.1 a philosophical perspective, 582.1.2 privacy as control versus privacy as restricted access, 592.1.3 coherence in the concept of privacy, 622.1.4 normative theories of privacy, 662.2 economic perspectives on privacy, 692.2.1 the rationale for an economic perspective on privacy, 692.2.2 privacy as fraud, 712.2.3 privacy and the assignment of property rights to  individuals, 732.2.4 the economic impact of privacy regulation, 742.2.5 privacy and behavioral economics, 752.3 sociological approaches, 792.4 an integrating perspective, 843 technological drivers 883.1 the impact of technology on privacy, 883.2 hardware advances, 903.3 software advances, 953.4 increased connectivity and ubiquity, 973.5 technologies combined into a datagathering system, 1013.6 data search companies, 1023.7 biological and other sensing technologies, 1063.8 privacyenhancing technologies, 1073.8.1 privacyenhancing technologies for use by individuals, 1073.8.2 privacyenhancing technologies for use by information collectors, 1093.8.2.1 query control, 1093.8.2.2 statistical disclosure limitation techniques, 1113.8.2.3 cryptographic techniques, 1123.8.2.4 user notication, 1133.8.2.5 information flow analysis, 1143.8.2.6 privacysensitive system design, 1143.8.2.7 information security tools, 1153.9 unsolved problems as privacy enhancers, 1163.10 observations, 118engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.contents xvii4 the legal landscape in the united states 1224.1 constitutional foundations, 1224.1.1 the fourth amendment, 1224.1.2 the first amendment, 1254.1.3 the ninth amendment, 1274.2 common law and privacy torts, 1294.3 freedom of information/open government, 1314.3.1 federal laws relevant to individual privacy, 1334.3.2 federal laws relevant to condentiality, 1424.3.3 regulation, 1434.4 executive orders and presidential directives, 1464.5 state perspectives, 1474.6 international perspectives on privacy policy, 1514.7 the impact of nonu.s. law on privacy, 1515 the politics of privacy policy in the  united states 1555.1 the formulation of public policy, 1555.2 public opinion and the role of privacy advocates, 1625.3 the role of reports, 1665.4 judicial decisions, 1705.5 the formulation of corporate policy, 171part iii privacy in context6 privacy and organizations 1776.1 institutional use of information, 1786.2 education and academic research institutions, 1836.2.1 student information collected for administrative  purposes, 1836.2.2 personal information collected for research purposes, 1876.3 financial institutions, 1886.4 retail businesses, 1916.5 data aggregation organizations, 1966.6 nonprots and charities, 2006.7 mass media and content distribution industries, 2016.8 statistical and research agencies, 2036.9 conclusion, 2057 health and medical privacy 2097.1 information and the practice of health care, 2097.2 privacy in medicine, 211engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.xviii engaging privacy and information technology in a digital age7.3 addressing issues in access to and use of health data, 2167.3.1 industry selfregulation, 2167.3.2 legislationšhipaa and privacy, 2197.3.3 patient perspectives on privacy, 2237.3.3.1 notications of privacy policy, 2237.3.3.2 privacy implications of greater patient involvement in  health care, 2247.3.3.3 improper interpretation and unintended consequences of hipaa privacy regulations, 2257.3.3.4 spillover privacy implications of receiving health care services, 2267.3.4 institutional advocacy, 2277.4 open issues, 2278 libraries and privacy 2318.1 the mission of libraries, 2338.2 libraries and privacy, 2358.3 libraries and technology, 2388.4 libraries and privacy since 9/11, 2428.5 emerging technologies, privacy, and libraries, 2448.6 conclusion, 2489 privacy, law enforcement, and national security 2519.1 information technology, privacy, and law  enforcement, 2529.1.1 background, 2529.1.2 technology and physical observation, 2549.1.3 communications and data storage, 2599.1.4 technology and identication, 2669.1.5 aggregation and data mining, 2719.1.6 privacy concerns and law enforcement, 2759.2 information technology, privacy, and national security, 2779.2.1 background, 2779.2.2 national security and technology development, 2809.2.3 legal limitations on national security data gathering, 2809.2.4 recent trends, 2849.2.5 tensions between privacy and national security, 2929.3 law enforcement, national security, and individual  privacy, 293engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.contents xixpart iv findings and recommendations10 findings and recommendations 30510.1 coming to terms, 30510.2 the value of privacy, 30810.3 pressures on privacy, 31210.4 making tradeoffs, 31810.5 approaches to privacy in the information age, 32310.5.1 principles, 32310.5.2 individual actions, 32510.5.3 organizationbased actions, 32810.5.4 public policy actions, 33210.5.4.1 managing the privacy patchwork, 33310.5.4.2 reviewing existing privacy law and regulations, 33410.5.4.3 respecting the spirit of the law, 33510.5.4.4 the relevance of fair information practices today, 33610.5.4.5 public advocates for privacy, 33910.5.4.6 establishing the means for recourse, 345appendixesa a short history of surveillance and privacy in the  united states 349b international perspectives on privacy 366c biographies 400index 411engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.1executive summaryprivacy has many connotationsšcontrol over information, access to one™s person and property, and the right to be left alone have all been included under this rubric. in political discourse, the term ﬁprivacyﬂ has been used to refer to physical privacy in the home or ofce, the ability to make personal reproductive decisions without interference from government, freedom from surveillance, or the ability to keep electronic communications and personal information condential. for many, privacy is regarded as a fundamental value and right, tied to ideals of autonomy, personal worth, and independence. privacy is often seen as a necessary condition for keeping personal and public lives separate, for individuals being treated fairly by governments and in the marketplace, and for guaranteeing spaces where individuals can think and discuss their views without interference or censure.philosophical approaches to the study of privacy have centered on the elucidation of the basic concept and the normative questions around whether privacy is a right, a good in itself, or an instrumental good. economic approaches to the question have centered around the value, in economic terms, of privacy, both in its role in the information needed for efcient markets and in the value of information as a piece of property. sociological approaches to the study of privacy have emphasized the ways in which the collection and use of personal information have re˚ected and reinforced the relationships of power and in˚uence between individuals, groups, and institutions within society.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.2 engaging privacy and information technology in a digital agekey to any discussion of privacy is a clear specication of what is at stake (what is being kept private) and the parties against which privacy is being invoked (who should not be privy to the information being kept private). for example, one notion of privacy involves condentiality or secrecy of some specic information, such as preventing disclosure of an individual™s library records to the government or to one™s employer or parents. a second notion of privacy involves anonymity, as re˚ected in, for example, the unattributed publication of an article or an unattributable chat room discussion that is critical of the government or of an employer, or an unidentied nancial contribution to an organization or a political campaign.these two simple examples illustrate a number of essential points regarding privacy. first, the party against which privacy is being invoked may have some reason for wanting access to the information being denied. a government conducting a terrorist investigation may want to know what a potential suspect is reading; an employer may be concerned that an article contains trade secrets or companyproprietary information and want to identify the source of that information. privacy rights are invoked to prevent the disclosure of such information. second, some kind of balancing of competing interests may be necessary. third, balancing is a task that is essentially politicalšand thus the political and societal power of various interest groups is critical to understanding how tradeoffs and compromises on privacy develop.drivers of change in notions of privacythis report focuses on three major drivers of the vast changes affecting notions, perceptions, and expectations of privacy: technological change, societal shifts, and discontinuities in circumstance.ł technological change refers to major differences in the technological environment of today as compared to that existing many decades ago (and which has a major in˚uence on today™s social and legal regime governing privacy). the hardware underlying information technology has become vastly more powerful; advances in processor speed, memory sizes, disk storage capacity, and networking bandwidth allow data to be collected, stored, and analyzed in ways that were barely imaginable a decade ago. other technology drivers are just emerging, including sensor networks that capture data and connect that data to the real world. increasingly ubiquitous networking means that more and more information is online. data stores are increasingly available in electronic form for analysis. new algorithms have been developed that allow extraction of information from a sea of collected data. the net result is that new kinds of data are being engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 3collected and stored in vast quantities and over long periods of time, and obscurity or difculty of access are increasingly less practical as ways of protecting privacy. finally, because information technologies are continually dropping in cost, technologies for collecting and analyzing personal information from multiple, disparate sources are increasingly available to individuals, corporations, and governments.ł societal shifts refer to evolutionary changes in the institutions of societyšthe organizations and the activities and practices that make use of the technological systems described abovešand to the transformation of social institutions, practices, and behavior through their routine use. to an unprecedented degree, making personal information available to institutions and organizations has become essential for individual participation in everyday life. these information demands have increasingly appeared in licensing; administration and conferring of government or private sector benets to particular classes of people (e.g., veterans, the unemployed, those with low income, homeowners); providing of services; employment; and retailing.ł discontinuities in circumstance refer to events and emergent concerns that utterly transform the national debate about privacy in a very short time (and thus do not allow for gradual adjustment to a new set of circumstances). the most salient example in recent years concerns the events of september 11, 2001, which transformed the national environment and catapulted counterterrorism and national security to the very top of the public policy agenda. but the sars outbreak in 2003 hinted at the potential for global pandemic on a very short time scale with some other disease, and measures to prevent pandemic outbreaks are receiving greater attention today. in the past, the watergate scandals of 19721973, the church committee hearings of 1976 (also known as the hearings of the united states senate select committee to study governmental operations with respect to intelligence activities), and the attack on pearl harbor in 1941 could also be seen as watershed events with dramatic changes in the environment for privacy.these multiple drivers suggest how our attitudes toward privacy are context dependent. it is difcult to hold a precise view of what privacy is, absent consideration of what kind of information is sought, who seeks it, and how it is to be collected, protected, and used. there are, for example, some things one might not mind the government knowing that one would object to an employer knowing (and vice versa). and there are other things that one would not object to either of them knowing, but would not want passed on to aunts and uncles, just as there are things that one would like to keep within the family. determining what should (1) be left to the realm of ethics and common courtesy, (2) be incentivized engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.4 engaging privacy and information technology in a digital ageor discouraged, or (3) be formalized in regulation or law is yet another balancing question that comes up when contemplating privacy.taken together, these drivers point to an environment for privacy that is quite different from what existed in the era that led to the formation of many of today™s expectations and assumptions about the nature of privacy and the role that privacy plays in individual lives and in society. as the environment changes, it is easy to see how understandings and a status quo developed prior to those changes can be upended. thus, there is no immutable standard for what degree of privacy can be expectedšsuggesting that battles once fought and settled in one era may need to be refought and settled anew in another.understanding privacy tradeoffsprivacy is a complex issue because multiple interests are at stake. indeed, if the information had no value to anyone (either at the moment of collection or in the future), the protection of privacy would be a nonissue; the information would not be gathered in the rst place.but this is not the case. in many ways, both large and small, benets do accrue from the collection of some kinds of information. these benets lead to pressures against privacy measures that might impede the collection of such information. in some cases, these pressures are the result of specic uses for the information collectedšthat is, privacy concerns sometimes emanate from specic uses of information rather than the fact of collection itself. from a privacy protection standpoint, this in turn highlights a major problem for individualsšknowing those ultimate uses can be difcult or impossible.some of the most complex tradeoffsšand the ones most controversial or difcult to managešinvolve a tradeoff of the interests of many individuals against the interests of a collective society. an individual™s interest in keeping his or her medical records privatešan interest shared by many individualsšmay pose a tradeoff when community needs for epidemiological information are concerned or when emergency care for the individual is necessary without explicit consent. video surveillance may deter crime but also poses a privacy risk if male camera operators use the cameras to focus on private parts of women™s bodies. while law enforcement authorities believe that it is helpful to know the identities of individuals interested in reading about terrorism or bomb making, librarians and many state legislatures are concerned about ensuring a free, unfettered, and unmonitored ˚ow of information to all library patrons that could be jeopardized if individuals™ reading habits are potentially the subject of government investigation or even monitoring. surveillance by engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 5government authorities can inhibit legal and legitimate social and political gatherings.however, the fact that tradeoffs are sometimes necessary should not be taken to mean that tradeoffs are always necessary. in some cases, careful design and planning will minimize the tradeoffs that are needed to attend to societal needs without compromising personal information. an example might be a design decision for a system to discard data immediately after it has been used for the purpose at handšin many instances, privacy concerns are strongly mitigated by the nonretention of data.this perspective makes clear that the social context in which privacy is experienced has shifted in recent years. identifying balances that people are comfortable with in legal affairs, security provisions, behavioral norms, and relationships will require an ongoing dialogue involving numerous stakeholders and constituencies. expectations of privacy formed in the preindustrial age were not sufcient after the industrial revolution, and it should not be surprising that notions of privacy developed during the industrial age should show signs of stress in the new information age. it is at just such times of changing capabilities and expectations that we need to examine the core of our notions of privacy to ensure that what is most important survives the transitions.tools for protecting privacythere are many pressures to diminish privacy, regardless of how the term is dened, but there are also a number of tools available to help protect privacy. these tools fall into three generic categories:ł personal unilateral actions (selfhelp). when information collectors rely on individuals themselves to provide personal information, these individuals can take action to withhold that information. they can refuse to provide it at all, or they can provide false, misleading, or incomplete information. a common example is an afnity card, which entitles the holder to a discount on store products. afnity cards are typically provided to an individual upon receipt of a completed application, which usually involves a questionnaire about income, demographics, and spending habits. there is often no verication of the information provided or sanction applied for inaccurate information, and so many individuals simply provide inaccurate information. withholding information also works to protect privacy, although it may also deny one certain benets, such as a license or a job. neither of these approaches is well advised, of course, when there are excessively negative and severe consequences to withholding or providing false information.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.6 engaging privacy and information technology in a digital ageł technology. technical measures can protect privacy as well, although a relevant question is who decides to implement any given technical measure. from an individual standpoint, encryption and anonymizers are today the primary privacyprotecting technologies. that is, encryption of personal information can be used to ensure that such information can only be accessed with the express permission of the subject of that information, and that communications cannot be seen by others than those taking part in the communication. anonymizers (e.g., antispyware tools, anonymous browsers) allow an individual to explore cyberspace (e.g., using email, viewing web sites) with a high degree of anonymity. in addition, antispam and antiphishing technologies help individuals to be left alone and reduce the leakage of personal information. technical safeguards to protect privacy are also available to the collectors of personal information, who may wish to protect such information to make individuals more willing or more comfortable about sharing information with them. for example, technologies are being developed that can screen out individuating characteristics in largescale public datagathering systems such as video cameras, and some statistical methods and datamining algorithms have been developed that facilitate the anonymization of information without changing the important statistical properties of the information taken in the aggregate.ł policy. policy measures, by which are meant actions that information collectors can or must take, are arguably the most important privacy protection tool. that is, privacy is much more an issue of who is permitted to see an individual™s personal information than of technologically restricting access to that information. people may be concerned about personal health and medical information being improperly disclosed, but this problem may arise at least as much as a result of policy decisions to make such information broadly accessible to relevant parties as from the activities of hackers breaking into medical databases. policy measures fall into ve generic categories: šlimits on the information collected and stored (data minimization). for example, often the most ﬁobviousﬂ efforts to enhance public safety or security are highly privacyinvasive (e.g., collect all possible data about individuals and mine it extensively). however, it may be possible, with some thoughtfulness early on, to collect a much more limited set of information that will still satisfy a given purpose. collected information, once used, can also be deleted to prevent further use. of course, such limits will be strongly resisted by information collectors who do not know in advance of collection the specic purposes for which they need information, and who see information as an opportunity to develop a resource that might be useful for an extended time. note also that limits need not be formulated in allornothing engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 7terms. limits may be imposed in the form of differential levels of access for different individuals, varying time windows for access (both when data are made available and for how long), or access for certain purposes but not for others. šlimits on outsider access. by denition, an outsider is a party external to the organization that collects the information in question. outsiders can be denied access through both technical and procedural means. technical means include measures such as encryption and access control mechanisms that prevent unauthorized access; procedural means include regulationbased restrictions on who receives information. šprevention of internal abuse. even organizations with the best of intentions may have insiders (e.g., employees) who do not use the information collected in accordance with organizationally approved purposes. for example, a law enforcement agent may use a national criminal database to investigate an individual for personal reasons, in violation of departmental policy. in such instances, frequent audits to uncover improper access and penalties for improper access are essential elements of preventing such use. šnotication. it is generally believed that violations of privacy are in some sense worse when they occur without the knowledge of the individual in question; thus, notication when unauthorized access occurs can be regarded as a privacy protection measure. šcorrection. the opportunity to review information collected and to ensure that it is at least correct protects the individual against decisions being made on the basis of incorrect information.a basic analytical framework for understanding privacythe notion of privacy is a basic starting point for this framework, and as suggested in the introduction, three essential questions arise:ł what is the information that is being kept private (and with whom is that information associated)?ł from whom is the information being withheld?ł what purposes would be served by withholding or not withholding the information, and whose interests do those purposes serve?a worked example of privacy tradeoffsto illustrate how basic privacy tradeoffs arise, this report considers privacy and the u.s. library community. the issue of privacy in librarengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.8 engaging privacy and information technology in a digital ageies is considered not because it is more important than privacy in other domains (e.g., in health care or law enforcement), but because it provides an opportunity to introduce in a concrete manner some of the basic tradeoffs.the library community has a long historical commitment to protecting the privacy of its patrons, formalized more than ve decades ago and integrated into a core set of shared beliefs. this community was also an early adopter of information technology as a way of furthering its mission of offering full access to all information to libraries™ patrons. since many libraries are publicly funded in one way or another, this community is also directly subject to shifts in the political landscape. this combination makes this community one of the most active, articulate, and thoughtful of the various factions taking part in the debates about privacy.the framework of questions posed above provides a starting point for the discussion of library privacy.ł what is the information that is being kept private (and with whom is that information associated)? the information that is being kept private is the borrowing history of reading materials of library patrons who are identiable by name or the names of all individuals who have had access to specic reading materials. (such information is protected under the laws of many states.) ﬁborrowing historyﬂ can include computer access to information as well.ł from whom is the information being withheld? according to the librarians™ code of ethics, borrowing records should be kept private from all parties except as necessary to provide scal accountability for materials borrowed (you fail to return a book, you pay for it).ł what purposes would be served by withholding or not withholding the information, and whose interests do those purposes serve? the rationale underlying the withholding of borrowing information is the belief that citizens are served best when they can obtain information and access to society™s scientic, cultural, and historical legacy without interference or observation from other parties, and disclosure of that information might subject patrons to pressure and outside in˚uence. moreover, because there is no general social consensus about information that is or is not desirable for people to have (the primary exceptions being materials judged to constitute child pornography), librarians believe that leaving the choice of subjects to the individual™s own choosing maximizes the benet to society as a whole. as for disclosure of information on borrowing, the interests served depend on who has access and for what reasons access is being sought. for example, parents may wish to know if a teenage daughter is reading about sex, or law enforcement authorities engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 9may wish to know if a person of interest is reading about guns or radical politics.from this example, several themes emerge.first, the direct interests of the individual differ from those of the parties seeking the information.second, a long history of privacy concerns in the library community provides the basic context against which today™s current concerns about privacy are judged and assessed.third, technological advances in the library domainšcoupled with change in the social and political milieu in which libraries operatešreopen oncesettled arguments and compromises that have historically been made between privacy and other values. law enforcement authorities have sought information about reading habits of patrons in the past, but debates over library privacy have been reopened as records of internet access in libraries become important to criminal or intelligence investigations.in order to compare how these issues play out in other domains, the next section illustrates three other important scenarios.elaboration of the issuesalthough other parties have many reasons for using personal information of individuals, four stand out as being of particular signicance. one reason is economicšby using personal information about individuals, various protmaking enterprises can enhance their revenue streams, sometimes quite substantially. a second is medicalšdetailed information about patients enables higherquality and less expensive health care than would otherwise be possible. a third is public safety and national securityšcollection of information about criminals, criminal activities, and terrorists enables law enforcement and national security authorities to protect the public more effectively. a fourth is researchšstatistical trends derived from collections of personal information are often of importance to public policy makers. privacy tradeoffs related to each of these reasons are explored below.economic driversa good example of how economic drivers affect privacy can be found in the area of the denition, protection, and enforcement of intellectual property rights in the networked digital environment. deep privacy issues arise in this domain because digital rights management technoloengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.10 engaging privacy and information technology in a digital agegies (drmts)šoriginally intended to help limit illegal distribution of copyrighted digital materialsšalso enable verynegrained control over what legitimate users may do with materials in their possession (e.g., how many times a document can be read, or whether it can be forwarded). of particular concern from a privacy perspective, drmts could also be used to monitor what intellectual property and information an individual uses and how. information can be collected about how many times you read a document, how long you spend listening to a piece of music, how often you visit a particular place on the internet, or what kinds of changes you make to information and whenšamong many other things. such negrained information collection and monitoring of what many perceive to be critical components of their intellectual and emotional selves (the books we read, the music we listen to, the movies that we watch) might have a dramatic impact on people™s perceptions of their individual privacy.in the case of drmts, the economic benet today arises not from the collection of this information about user behavior per se, but from the primary applications of drmts to charge fees for various services for access to protected materials (printing, storage, multiple simultaneous access, and so on). that is, publishers have found that drmts are enablers for a different and more protable business model, although in the future certain parties might also nd signicant economic interest in what could be gleaned from such information such as from targeted marketing based on user interests). privacy concerns arise because of the potential for these drmts to collect detailed information on user behavior regarding the digital content they consume and thus all of the consequences that could result if drmts were in fact used in this way.medical drivershealth and medical privacy has traditionally been considered a core privacy right. the experience of policy makers in implementing the privacy regulations of the health insurance portability and accountability act (hipaa) serves as a case study in some of the subtleties of privacy, showing the difculty of determining the line between what should be private and what can be disclosed (and with whom and for what purposes such sharing can take place); the difculties of placing the appropriate procedures and technologies in place to ensure the required levels of privacy; and the various costs of such privacy regulations. the health and medical communities are also on the leading edge of several possible future privacy issues, having to do with the appropriate use of information that can be gathered from sources such as dna analysis. these issues call into question even the notion of whose privacy is involved, since the information contained in a person™s dna concerns not only that person engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 11but also the set of people who share that person™s genetic lineage. the same may be true to a lesser extent for health habits and infectious diseases, the presence of which often correlates with family membership.privacy issues arise in the health and medical domain primarily as the result of a concern about the consequences should personal health and medical information be disclosed or disclosable. one source of concern is socialšthere is stigma associated with certain medical conditions, and disclosure of those conditions potentially subjects individuals with them to discrimination and to being socially ostracized. a second is economicšdisclosure of information about an individual™s health to insurance companies can be used to deny him or her health insurance (or increase the price of such insurance), and disclosure of such information to an employer may affect his or her employment prospects with that employer. and underlying these social and economic concerns is the fact that candor between a patient and his or her health care provider is essential for good care.an interesting middle ground is the disclosure of personal health information for research purposes (e.g., to determine effective courses of medical treatment). for such purposes, individual names need not be associated with the information being collected, although unique identiers may be needed to track individuals longitudinally. in this context, some people may regard collection of information as benign from a privacy standpoint, while others may regard it as intrusive.more generally, this example illustrates that concerns about privacyšin many domainsšoften relate to the stated reasons for which the information is gathered, the intention of the gatherers, and the subsequent uses to which the information is put. something can be seen either as an invasion of privacy or as an attempt to give better service, depending on the motives, results, explanations offered, safeguards provided, and trust relationships that hold between the individuals and the companies that are gathering and using the information.law enforcement and national security driverslaw enforcement and national security authorities need information about criminals, criminal activities, and terrorists if these authorities are to carry out their missions. and if collection of information could be precisely limited to these targets there would be little controversy.but criminals and terrorists do not wear brightly colored shirts announcing that they are actual or potential criminals and terrorists. as a rule, criminals and terrorists wish to blend in with the lawabiding population so that they do not come under suspicion and thus have a freer hand to plan and operate. thus, any information collection directed engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.12 engaging privacy and information technology in a digital ageat criminals and terrorists potentially gathers information about lawabiding citizens, and striking the appropriate balance between acknowledging the law enforcement/national security need for collecting information and protecting the privacy of lawabiding citizens has been an especially copious source of public policy controversy since september 11, 2001. of course, this is not a new tension; indeed, it has existed far longer than this country. what makes this subject of particular importance for this study is the con˚uence of the technology that makes it possible for privacy to be eroded far more extensively than ever before with the historical context that makes the claims for security more persuasive.there are many reasons that lawabiding individuals might be concerned about the collection of their personal information, but three are worthy of particular mention. first, these individuals may be concerned that such information might be abused. by giving government ofcials the ability to collect personal information, citizens must take on faith that such abilities will be exercised only for proper reasons, such as the investigation of a crime, and not for improper ones, such as the settling of personal vendettas. second, government knowledge about certain activities often has a chilling effect on such activities, even if such activities are entirely legalšan example might be planning a public protest about government action. third, many individuals do not want government authorities to collect personal information simply on the theory that such collection raises their prole and makes it more likely that they might be erroneously singled out in some manner to their detriment even if they have done nothing illegal.findings and recommendationsargumentation for the ndings and recommendations is provided in chapter 10 of the report. recommendations are presented in boldface below.the committee found that the meaning of privacy is highly contextual, and it can vary depending on the specic circumstances at hand, such as the situation and relationships at issue, the intentions of the parties involved, and the historical context, technology, and political environment. despite this contextual meaning, privacy is an important value to be maintained and protected, because the loss of privacy often results in signicant tangible and intangible harm to individuals and to groups. privacy is most important to people when they believe the entity receiving their personal information is not trustworthy and that they may be harmed by sharing that information.at the same time, privacy is not an absolute good in itself. tradeoffs against other desirable societal values or goods are sometimes inevitable. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 13privacyinvasive solutions to public policy problems may be warranted under some circumstances. however, when they are implemented as measures of rst rather than last resort, they generate resistance that might otherwise be avoided if other alternatives were tried rst.businesses, researchers, and government agencies nd value in the exploitation of personal information, and they have further developed many mechanismsšboth voluntary and intrusivešfor obtaining personal information. moreover, because these entities often develop new ways of using personal information in pursuit of their organizational goals and missions, there emerge many pressures for the repurposing of data that have already been collected. changing social trends and sentinel events such as the 9/11 attacks put additional strong pressures on privacy.the changing information technology environment has also helped to compromise privacy, although some developments in information technology and other technologies do have considerable potential to enhance it. in addition, technologybased privacy enhancement rests on rmer ground to the extent that technologists attend to privacy considerations throughout the life cycle of personal information that is collected rather than just at the beginning of the collection process.the committee is concerned about the nature of public debates about privacy and its relationship to other societal interests. for example, the committee found that there is often a lack of clarity about the privacy interests involved and too often a tendency to downplay and to be dismissive of the privacy issues at stake. when privacy is at issue, the committee found that bland assurances that privacy will not be harmed offered by policy makers can do more to raise skepticism than honest presentation and assessment of tradeoffs.to facilitate a more thoughtful public debate, the committee articulated a number of principles. the rst was that the debate should avoid demonization. most threats to privacy do not come from fundamentally bad people with bad intentions. demonization tends to make compromise and thoughtful deliberation difcult. second, the debate should account for context and nuance; taking nuance and context into account will often be necessary if common ground is to be found. third, the debate should respect the complexity inherent in the problem. privacy is a complicated issue, and it is a moving target, as the numerous social and technical factors with which it is intertwined change over time. thus, initiatives that have policy implications and solutions to identied privacy problems are more likely to be successful if they can begin with modest and simple steps that provide feedback to guide and shape further actions. fourth, decision makers must be aware of longterm costs and risks. in particular, it is costly to retrot privacy features into a system (such as the addition of query audit trails to deter inappropriate use by employees), and such engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.14 engaging privacy and information technology in a digital agexes are often necessary when inadvertent violations of privacy occur that might have been prevented if those features had been available in the rst place. (there are also the costs associated with unfavorable publicity and possible economic liability.) thus, it often makes sense to ensure that adequate technologybased enforcement of privacy policies is a part of a system™s initial design.in order to enhance privacy, individual, organizational, and public policy actors have roles to play.individuals can take a number of steps to enhance the privacy of their personal information and to become better informed about the extent to which their privacy has been compromised, although the effectiveness of these measures is bound to be limited. the committee thus recommends that if policy choices require that individuals shoulder the burden of protecting their own privacy, law and regulation should support the individual in doing so.firms and other organizations can design and implement selfregulatory regimes for protecting the privacy of the personal information they collect. selfregulation is limited as a method for ensuring privacy, although it nevertheless offers protections that would not otherwise be available to the public. the committee offers a number of concrete recommendations to enhance the effectiveness of privacy policies. specically, organizations with selfregulatory privacy policies should take both technical and administrative measures to ensure their enforcement, routinely test whether their stated privacy policies are being fully implemented, produce privacy impact assessments when they are appropriate, strengthen their privacy policy by establishing a mechanism for recourse if an individual or a group believes that they have been treated in a manner inconsistent with an organization™s stated policy, and establish an institutional advocate for privacy.the committee found that governmental bodies have important roles to play in protecting the privacy of individuals and or groups and in ensuring that decisions concerning privacy are made in an informed fashion. however, the u.s. legal and regulatory framework surrounding privacy is a patchwork that lacks consistent principles or unifying themes. accordingly, the committee concluded that a less decentralized and more integrated approach to privacy policy in the united states could bring a greater degree of coherence to the subject of privacy. two recommendations follow from this conclusion. first, the committee recommends that the u.s. government should undertake a broad systematic review of national privacy laws and regulations. second, the committee recommends that government policy makers should respect the spirit of privacyrelated law.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.executive summary 15the principles of fair information practice for the protection of personal information were rst enunciated in a 1973 report of the u.s. department of health, education, and welfare. in reviewing the privacy landscape, the committee found that these principles are as relevant and important today as they were in 1973. thus, the committee recommends that principles of fair information practice should be extended as far as reasonably feasible to apply to private sector organizations that collect and use personal information. given the growing importance of repurposing collected personal information, the committee also recommends that to support greater transparency into the decisionmaking process regarding repurposing, guidelines should be established for informing individuals that repurposing of their personal information might occur, and also what the nature of such repurposing would be, and what factors would be taken into account in making any such decision. in addition, the committee recommends that the principle of choice and consent should be implemented so that individual choices and consent are genuinely informed and so that its implementation accounts fairly for demonstrated human tendencies to accept without change choices made by default.furthermore, although a number of laws do protect the privacy of personal information in government hands, the use of private sector data aggregators is a gray area, and the committee recommends that the u.s. congress should pay special attention to and provide special oversight regarding the government use of private sector organizations to obtain personal information about individuals.as for the government use of personal information, the committee found that because the benets of privacy often are less tangible and immediate than the perceived benets of other interests such as public security and economic efciency, privacy is at an inherent disadvantage when decision makers weigh privacy against these other interests. the committee concluded that, to reduce this inherent disadvantage, governments at federal, state, and local levels should establish mechanisms for the institutional advocacy of privacy within government. accordingly, the committee recommends that governments at various levels should establish formal mechanisms for the institutional advocacy of privacy within government, and furthermore that a national privacy commissioner or standing privacy commission should be established to provide ongoing and periodic assessments of privacy developments.finally, the committee found that the availability of individual recourse for recognized violations of privacy is an essential element of public policy regarding privacy. accordingly, it recommends that governments at all levels should take action to establish the availability of appropriate individual recourse for recognized violations of privacy.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.17part ithinking about privacychapter 1 (ﬁthinking about privacyﬂ) introduces many of the concepts needed for an informed discussion about privacy. the chapter underscores that privacy is an elusive concept, even though many people have strong intuitions about what it is. indeed, privacy is seen to be a concept that acquires specic meaning only in the context of specic circumstances and settings. notions of privacy are in˚uenced by many factors, including technological change, societal and organizational change, and changes in immediate circumstances. relevant technical issues include concepts of false positives and false negatives, the nature of personal information, the distinction between privacy and anonymity, fair information practices, and reasonable expectations of privacy.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.191thinking about privacyjust as recent centuries saw transitions from the agricultural to the industrial to the information age and associated societal and technological changes, the early 21st century will continue to pose dynamic challenges in many aspects of society. most importantly from the standpoint of this report, advances in information technology are proceeding apace. in this rapidly changing technological context, individuals, institutions, and governments will be forced to reexamine core values, beliefs, laws, and social structures if their understandings of autonomy, privacy, justice, community, and democracy are to continue to have meaning. a central concept throughout u.s. history has been the notion of privacy and the creation of appropriate borders between the individual and the state. in the latter 19th century, as industrial urban society saw the rise of large bureaucratic organizations, notions of privacy were extended to the borders between private organizations and the individual. this report focuses on privacy and its intersections with information technology and associated social and technology trends.1.1 introductionone of the most discussed and worriedabout aspects of today™s information age is the subject of privacy. based on a number of other efforts directed toward analyzing trends and impacts of information technology (including the evolution of the internet, a variety of information security issues, and publicprivate tensions regarding uses of information and engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.20 engaging privacy and information technology in a digital ageinformation technology), the national research council saw a need for a comprehensive assessment of privacy challenges and opportunities and thus established the committee on privacy in the information age.the committee™s charge had four basic elements:ł to survey and analyze potential areas of concernšprivacy risks to personal information associated with new technologies and their interaction with nontechnologybased risks, the incidence of actual problems relative to the potential, trends in technology and practice that will in˚uence impacts on privacy, and so on;ł to evaluate the technical and sociological context for those areas as well as new collection devices and methodologiesšwhy personal information is at risk given its storage, communication, combination with other information, and various uses; trends in the voluntary and involuntary (and knowing and unknowing) sharing of that information;ł to assess what is and is not new about threats to the privacy of personal information today, taking into account the history of the use of information technology over several decades and developments in government and private sector practices; andł to examine the tradeoffs (e.g., between more personalized marketing and more monitoring of personal buying patterns) involved in the collection and use of personal information, including the incidence of benets and costs,1 and to examine alternative approaches to collection and use of personal information.further, in an attempt to paint a big picture that would at least sketch the contours of the full set of interactions and tradeoffs, the charge called for these analyses to take into account changes in technology; business, government, and other organizational demand for and supply of personal information; and the increasing capabilities for individuals to collect and use, as well as disseminate, personal information. within this big picture, and motivated by changes in the national security environment since the september 11, 2001, attacks on the world trade center and the pentagon, the committee addressed issues related to law enforcement and national security somewhat more comprehensively than it did other areas in which privacy matters arise.to what end does the committee offer this consideration of privacy in the 21st century? most broadly, to raise awareness of the spider web of connectedness among the actions we take, the policies we pass, the 1 throughout this report, the term ﬁbenets and costsﬂ should be construed broadly, and in particular should not be limited simply to economic benets and costs.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 21expectations we change, the ﬁ˚ip sideﬂ of impacts policies have on privacy. there should not be unintended consequences to privacy created by policies we write or change to address the continuing shifts in our society. we may decide to tolerate erosion on one side of a continuumšprivacy and security sometimes pose a con˚ict, for example. we may decide it makes sense to allow security personnel to open our bags, to carry a ﬁtrusted travelerﬂ card, to accept ﬁprolingﬂ of people for additional examination. but we should not be surprised by the erosion of our own and other people™s privacy by this shift in the continuum. policies may create a new and desirable equilibrium, but they should not create unforeseen consequences.the goals here are not to evaluate ﬁgoodﬂ and ﬁbad,ﬂ whether in changes in the continuums privacy moves on, policies, technologies, and laws. rather, the committee hopes that this report will contribute to a recalibration of the many issues that play a part in privacy and will contribute to the analysis of issues involving privacy. the degree of privacy traded for security or public health, for example, should be a result of thoughtful decisions following public discussion in which all parties can participate. only then will the policies that emerge from the pressures at work during the early years of the 21st century be understood in their impacts on privacy.to be clear, the committee does not claim that this report presents comprehensive solutions to the many privacy challenges confronting society today. nor does it provide a thorough and settled denition of privacy. debate will continue on this complicated and valueladen topic for the foreseeable future. this report does provide ways to think about privacy, its relationship to other values, and related tradeoffs. it emphasizes the need to understand context when evaluating the privacy impact of a given situation, piece of legislation, or technology. and it provides an indepth look at ongoing information technology trends as related to privacy concerns.1.2 what is privacy?the committee began by trying to understand what privacy is, and it quickly found that privacy is an illdened but apparently wellunderstood concept. it is illdened in the sense that people use the term to mean many different things. any review of the literature on privacy will reveal that privacy is a complicated concept that is difcult to dene at a theoretical level under any single, logically consistent ﬁumbrellaﬂ theory, even if there are tenuous threads connecting the diverse meanings. specifying the concept in a way that meets with universal consensus is a difcult if not impossible task, as the committee found in doing its work.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.22 engaging privacy and information technology in a digital ageat the same time, the term ﬁprivacyﬂ is apparently well understood in the sense that most people using the term believe that others share their particular denition. nonetheless, privacy resists a clear, concise denition because it is experienced in a variety of social contexts. for example, a question may be an offensive privacy violation in one context and a welcome intimacy in another.the committee believes that in everyday usage, the term ﬁprivacyﬂ generally includes reference to the types of information available about an individual, whether they are primary or derived from analysis. these types of information include behavioral, nancial, medical, biometric, consumer, and biographical. privacy interests also attach to the gathering, control, protection, and use of information about individuals. informational dimensions of privacy thus constitute a denitional center of gravity for the term that is used in this report, even while recognizing that the term may in any given instance entail other dimensions as wellšother dimensions that are recognized explicitly in the discussion.2the multidimensional nature of privacy is explicated further in chapter 2, and a theme that becomes apparent is the situational and contextual nature of privacyšthat is, it depends on a number of specic factors that often do not cleanly and clearly overlap, rather than being identied by a sweeping universal calculus or denition.moreover, privacy in any given situation may be in tension with other values or desires of the individual, subgroups, and society at large. privacy, like most other values in modern democratic societies, is not an absolute but rather must be interpreted and weighed alongside other socially important values and goals. how this balancing (which need not mean equivalent weighing) is to be achieved is often the center of the controversy around privacy, because different people and groups balance in different ways these values that are in tension.a further complication is that participants in the balancing debate often confuse the needs of privacy with other values that might be tied to privacy but that are, in fact, distinct from it. for example, concerns over whether an individual™s hiv status should be private may in fact re˚ect, in part, a concern about his or her ability to obtain health insurance.in short, as with most interesting and contentious social topics, where privacy is concerned there are both costs and benets, and these vary by the group, context, and time period in question, as well as by the means used to measure them. sometimes, tradeoffs are inevitable (box 1.1 pro2 the term ﬁprivateﬂ can have both descriptive and normative meanings. to describe information as ﬁprivate informationﬂ might mean ﬁinformation that is not accessible to others,ﬂ or it could mean ﬁinformation that should not be accessible to others.ﬂ generally the context will specify the meaning, but these two different meanings are noteworthy.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 23box 1.1 some illustrative tradeoffs in privacy ł government or privately controlled cameras monitoring the movement of ordinary citizens in public places for the stated purpose of increasing public safety. ł government collection of data on peoples™ political activities for the stated purpose of increasing public safety or homeland security. ł collection by a retailer of personal information about purchases for the stated purpose of future marketing of products to specic individuals. ł collection by a bank of personal nancial information about an individual for the stated purpose of evaluating his or her creditworthiness for a loan. ł aggregation by insurers of medical data obtained through third parties for the stated purpose of deciding on rates or availability of health insurance for an individual. ł provision of information to law enforcement agencies about library patrons (including who they are and what they read or saw in the library) for the stated purpose of increasing public safety or homeland security, and a prohibition of discussing or acknowledging that this has been done. ł availability of public government records (including criminal records, family court proceedings, real estate transactions, and so on, and formerly only available in paper format) on the world wide web for the stated purpose of increasing the openness of government. ł geographic tracking of cellphone locations at all times for the stated purpose of enabling emergency location. note also that privacy concerns are often grounded in information that may be used for purposes other than a stated purpose. indeed, in each of the examples given above, another possiblešand less benignšpurpose might easily be envisioned and thus might change entirely one™s framing of a privacy issue.vides some illustrative examples). advocates for various positions who argue vigorously for a given policy thus run the risk of casting their arguments in unduly broad terms. though rhetorical excesses are often a staple of advocacy, in truth the factors driving the information age rarely create simple problems with simple solutions.perhaps the best known of the general tradeoffs in the privacy debate is that which contrasts privacy with considerations of law enforcement and national security. at this writing, there is considerable debate over the bush administration™s use of warrantless wiretapping in its counterterrorism efforts against alqaeda. furthermore, the usa patriot act, passed in the immediate wake of the september 11, 2001, attacks on the world trade center and the pentagon and extended and amended in early 2006, changed a number of privacyrelated laws in order to facilitate certain law engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.24 engaging privacy and information technology in a digital ageenforcement and national security goals. (chapter 9 contains an extensive discussion of these issues.)but the law enforcement/national security versus privacy debate is hardly the only example of such tradeoffs that are being made. box 1.1 provides some illustrations. privacy concerns interact with the delivery of health care and the information needed to contribute to public health as well as the information needed to discover and understand risk factors that any individual may have. privacy concerns interact with the ability to do long and shortterm sociological studies. techniques that are believed to increase productivity and protability may come at a cost to the privacy interests of many consumers and workers. privacy concerns also are re˚ected in the debates about new forms of intellectual property. privacy concerns also interact with sociological and policy research. in order to conduct these kinds of research, substantial amounts of personal information are often necessary. however, in general, these data never have to be associated with specic individuals. this situation contrasts sharply with the societal needs described above: law enforcement authorities are interested in apprehending a specic individual guilty of criminal wrongdoing, national security authorities are interested in identifying a particular terrorist, or a business wants to identify a specic customer who will buy a product. for these reasons, protected data collections such as those found in social science data archives and census publicuse les serve the interests of groups and communities with less controversy; when controversy does exist, it usually relates to whether the data contained in these les and archives are sufciently anonymized, or to specic nonstatistical uses of these data.tradeoffs are also not limited to the value of information to an organization versus the value of privacy to an individualšthey also arise in the same situation of an individual alone. for example, an individual might regard his or her personal information as a commodity that can be traded freely in exchange for some other good or service of valuešand thus he or she might well be willing to provide personal information on shopping habits at a chain drugstore or supermarket in exchange for a 2 percent discount on all purchases. furthermore, even if the tradeoffs do appear to pit value to an organization against value to an individual, some would argue that there is benet to the individual as well (albeit not specic benet to him or her) if the organization can be construed as ﬁall or most of society.ﬂ this point is discussed in greater detail in section 6.4.not only are these tradeoffs complex, difcult, and sometimes seemingly intractable, but they are also often not made explicit in the discussions that take place around the policies that, when they are enacted, quietly embody the value tradeoffs. clarications on these points would not necessarily relieve the underlying tensions, but they would likely help engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 25illuminate the contours of the debate. a major purpose of this report is to contribute to that illumination.1.3 an illustrative casein early 2005, a rm known as choicepoint announced that ﬁa crime committed against choicepoint . . . may have resulted in [consumer] name[s], address[es], and social security number[s] being viewed by businesses that are not allowed access to such information.ﬂ3 specically, choicepoint reported that ﬁseveral individuals, posing as legitimate business customers, recently committed fraud by claiming to have a lawful purpose for accessing information about individuals, when in fact, they did not.ﬂ choicepoint explained its business as verifying for its business customers information supplied by individuals as part of a business transaction, often as part of an application for insurance, a job, or a home loan.choicepoint notied approximately 143,000 individuals that their personal information might have been compromised. in early 2006, the u.s. federal trade commission (ftc) announced that choicepoint would pay $15 million in nes and other penalties for lax security standards in verifying the credentials of its business customers. furthermore, the ftc noted that ﬁthis breach occurred because choicepoint failed to implement reasonable and appropriate procedures for approving new customers and for monitoring existing ones.ﬂ4 it also said that more than 800 cases of identity theft arose from this breach in security.for purposes of this study, the truth or falsity of the ftc™s allegations about choicepoint™s security practices per se is not relevant. but what is relevant is that the personal information of more than 143,000 individuals was released to parties that did not have a lawful purpose in receiving that information, and that a number of cases of identity theft arose from this release.several questions immediately come to mind:1. how is choicepoint able to aggregate such voluminous information? the data that choicepoint collects on individuals includes criminal histories, social security numbers, and employment histories.3 ﬁchoicepoint™s letter to consumers whose information was compromised,ﬂ cso magazine, available at http://www.csoonline.com/read/050105/choicepointletter.html.4 federal trade commission, ﬁchoicepoint settles data security breach charges; to pay $10 million in civil penalties, $5 million for consumer redress,ﬂ available at http://www.ftc.gov/opa/2006/01/choicepoint.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.26 engaging privacy and information technology in a digital age2. why do choicepoint and other similar rms collect such voluminous data on individuals?3. what was the harm suffered by the individuals whose identities were not stolen? eight hundred individual cases of identity theft were attributed to the breach, a number corresponding to about ½ of 1 percent of the 143,000 individuals involved.4. to what extent were individuals notied by choicepoint surprised by the existence of such aggregations of personal data?question 1 points to the availability of great quantities of personal information on a large scale to organizations that have no direct involvement in the creation of the data. choicepoint is not the primary collector of such information; it is an aggregator of it. it also points to the fact that information collected for one purpose (e.g., a job application with a certain employer) can be ﬁrepurposedﬂ and used for an entirely different purpose (e.g., verication of job history in connection with a background investigation).question 2 points to a demand on the part of private businesses and government agencies for personal information about its employees and customers. indeed, such information is so important to these businesses and government agencies that they are willing to pay to check and verify the accuracy of information provided by employees and customers. (note also that by insisting that employees and customers provide personal information, these businesses and agencies often add to the personal information that is available to data aggregators.)question 3 focuses attention on the value of privacy and the nature of the harm that can accrue to individuals when their privacy is breached even if they have not been the victims of identity theft. in this case, the answer is that these individuals suffer the same harm that damocles experienced when he was partying and feasting under the sword. no physical harm came to damocles, yet the cost to his sense of wellbeing was high indeed. a person whose privacy has been breached is likely to be concerned about the negative consequences that might ˚ow from the breach, and those kinds of psychological concerns constitute a type of actual though intangible harm entirely apart from the other kinds of tangible harm that the law typically recognizes. a second kind of intangible harm experienced by damocles might have been his reluctance to engage in dancing and making loud noises that might have caused the thread holding the sword to breakša socalled chilling effect on his activities and behaviors. in shortšharm need not be tangible to be real or actual.55 nor is ﬁharmﬂ a concept that is relevant only to individuals. as section 2.3 addresses in greater detail, certain kinds of harm may relate to groups or to society as a whole. group or engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 27question 4 alerts us to issues involving the commodication of personal information and its being treated as a kind of marketable property to be used as those who come to possess it choose. question 4 also calls attention to several collateral issues surrounding privacy. in this case, the issue is the role of notication in privacy, and whether notication that personal information is being collected about an individual in any sense ameliorates any breach of privacy that might be associated with that collection. given legal requirements to notify individuals after privacy violations have been documented, are such violations thus less likely?questions and issues such as these recur frequently in this report, although in no sense do these examples exhaust the kinds of questions and issues that arise. privacy provides a useful lter through which to think about individual and societal benets and costs.1.4 the dynamics of privacyprivacy is part of a social context that is subject to a range of factors. while a relationship between privacy and society has always existed, the factors (or pressures) affecting privacy in the information age are varied and deeply interconnected. these factors, individually and collectively, are changing and expanding in scale with unprecedented speed in terms of our ability to understand and contend with their implications to our world, in general, and our privacy, in particular. some of these factors include the volume, magnitude, complexity, and persistence of information; the expanding number of ways to collect information; the number of people affected by information; and the geographic spread and reach of information technology.1.4.1 the information agewhat is meant by the term ﬁinformation age,ﬂ and what are the factors so profoundly affecting the dynamics of privacy? with respect to the information age, a great deal has been written about the fact that almost no part of our lives is untouched by computing and information technology. these technologies underlie new ways of collecting and handling information that in turn have ramications throughout society, as they mediate much private and public communication, interaction, and transactions. they are central components of contemporary infrastructures involving (but certainly not restricted to) commerce, banking and nance, utilities, communications, national defense, education, and entertainment.societal harms may be related to individually suffered harm, but are conceptually separate notions.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.28 engaging privacy and information technology in a digital agebox 1.2 largescale factors affecting privacytechnological changeł ubiquitył connectivitył data collectionł storageł computational powerł commoditization of hardwareł software usabilitył encryptionł privacyrelevant biotechnologył extensions of human sensesł portability of data and communications devicesł persistence of informationł affordability of data and communicationsł advances in sensor technologysocietal trendsł globalizationł mobilitył virtualitył urbanizationł constant accessibilitył litigiousnessł demographics/agingł new ways of living and communicatingł increases in social networkingł increased societal interdependenceł increase in electronic communication literacył increase in expectations for information availabilitył linked monetary systemsł linked production systemsdiscontinuities in circumstanceł catastrophic attacks in 2001 on the world trade center/pentagonł watergate scandal in 19721973ł church committee hearings of 1976 (also known as the hearings of the united states senate select committee to study governmental operations with respect to intelligence activities)ł attack on pearl harbor in 1941ł invention in 1995 of the world wide web1ł national and international health threats (sars and avian ˚u)1the world wide web is a product of technology trends, but it was also the primary driving force underlying the explosion of easytouse internet applications that ultimately made enormous amounts of informationšpersonal and otherwisešpublicly accessible.this brief characterization of the information age highlights the three major factors, indeed drivers, of the vast changes affecting current notions, perceptions, and expectations of privacy: technological change, societal shifts, and discontinuities in circumstances (box 1.2).technological change (column 1 in box 1.2) refers to major differences in the technological environment of today as compared to that existing many decades ago (differences that have a major in˚uence on today™s social and legal regime governing privacy). column 2 in box 1.2 identies a number of trends that set a largescale social and cultural context for discussions of privacy. societal shifts refer to evolutionary trends in engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 29society writ large. discontinuities in circumstances (column 3 in box 1.2) are events and emergent concerns that transformed the national debate about privacy in a very short time (and thus did not allow for gradual adjustment to a new set of circumstances).society is thus experiencing the effects of changes in these factors. for example:ł changes in technology have enhanced access to information and images previously available to the public but then much more difcult to access. new technologies that extend the senses have made new kinds of data available as a result of covert ﬁsoft surveillance.ﬂ the fact that such surveillance permits the collection of personal information without the consent or knowledge of the subject offers temptations for misuse.ł changes in business models, which are increasingly based on the notion of greater customization of services and products, a process that in turn requires large amounts of personal information so that the appropriate customization can be employed.ł changes in expectations of security following the terrorist attacks of 2001 have reduced people™s expectations of the privacy rights of foreign nationals and u.s. citizens in this country, as did the attack on pearl harbor in 1941. similarly, the postwatergate revelations of government abuse of records containing personal information increased people™s expectations of the privacy rights to which they were entitled.subsequent chapters characterize these rapid changes in some detail. for the purposes of this introduction to thinking about privacy, it is sufcient to note that each of these changes is having signicant impacts on society. however, in combination, these changes are key drivers of the information society and underlie fundamental changes in how we, as individuals and as a society, grapple with privacy, business activities, social interaction, and information. these systemic and profound changes in turn have a most direct in˚uence on the dynamics of privacyšand indeed privacy™s salience as a topic of importance to this committee and to citizens generally.1.4.2 information transformed and the role of technologytechnological advancements, coupled with changes in other areas, combine to make the privacy challenge particularly vexing. technological change is, of course, not new. the printing press has been described as a precursor to the world wide web; email and cell phone text messaging have revolutionized interpersonal and group correspondence. affordability and advances in sensor technologies have broadened the volume engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.30 engaging privacy and information technology in a digital ageand scope of information that can be practically acquired. the privacy debate in the united states itself has part of its roots in the technological changes involving the press and technology for photographyšwarren and brandeis, in their landmark 1890 harvard law review paper,6 were responding to, as they put it, ﬁrecent inventions and business methods.ﬂthe business method at issue was the popular press, and the most striking of the recent inventionsšthe technologyšwas the unposed photograph. suddenly, it was easy to take spontaneous and often uninvited photos of peoplešwhich warren and brandeis denounced as ﬁinvad[ing] the sacred precincts of private and domestic lifeﬂšand to show the results to a large, literate, curious, and gossipy audience.7what makes information special is that it is reproducible. in digital form, information can be copied an innite number of times without losing delity. digitized information is also easy to distribute at low cost. today, in the information age, the sheer quantity of information; the ability to collect unobtrusively, aggregate, and analyze it; the ability to store it cheaply; the ubiquity of interconnectedness; and the magnitude and speed of all aspects of the way we think about, use, characterize, manipulate, and represent information are fundamentally and continuously changing. consider concepts of:ł information search. within half a generation we have moved from dusty card catalogues and le drawers full of rolls of microche to warehouses of servers connected to the worldwide internet that allow, among many other things, much of the internet to be searched for keywords at the click of a button.ł information production. in just the world of publishing alone, we have moved from mimeographs and hand distribution for the truly dedicated amateur to parents creating, modifying, and publishing entire photo and video albums of their children in ways that are accessible almost instantly around the globe. blogging enables many of us to publish nearly anything we want on the internet.ł information manipulation. the ways in which information can be manipulated have expandedšboth in terms of capability and also in terms of who has access to the tools that allow such manipulation. photoediting software and soundediting technologies are now bundled with many common personal computers. what might have taken hours to 6 samuel d. warren and louis d. brandeis, ﬁthe right to privacy,ﬂ harvard law review iv (december 15, no. 5):195, 1890, available at http://www.lawrence.edu/fac/boardmaw/privacybrandwarr2.html. 7 george radwanski, address to the privacy lecture series, toronto, ontario, march 26, 2001, available at http://www.privcom.gc.ca/speech/0205a0103262e.asp.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 31correct or modify in the days of the professional darkroom or recording studio can now be trivially accomplished by anyone with a pc.ł information storage. in many cases, records containing information are no longer thrown away. it has become less expensive to keep the data on larger, cheaper storage devices than to cull the information accurately so as to remove data. as a result data that has outlived its original use is retained and becomes subject to future unanticipated uses.ł information acquisition. it is easier today than ever before to acquire many kinds of information about individuals. sensors such as video surveillance cameras and radiofrequency id tags are rapidly dropping in cost and are increasingly ubiquitous in the environment. cell phones are capable of localizing to an accuracy of 100 meters the realtime whereabouts of the individuals carrying them. electronic fare cards for public transportation often identify entry and exit points, along with the time of day.ł information analysis. sophisticated algorithms are increasingly capable of nding patterns buried in large quantities of data. basic statistics of data can be generated on board sensor platforms, or even the sensors themselves, before even being transmitted to a central point of analysis. and the ingenuity of users knows few bounds, as such users nd new ways of using information already collected for new purposes.trends in information technology have made it easier and cheaper by orders of magnitude to gather, retain, and analyze information. other trends have also enabled access to new kinds of information that historically would have been next to impossible to gather about another individual. for example, certain kinds of data acquisition devices are already widely deployed (e.g., video cameras). the cost of such devices is dropping, which will enable even more ubiquitous deployment. and it will be increasingly easy to collect information from them as they are deployed not as standalone devices but in networks. such devices have many socially benecial applications, ranging from health care monitoring to monitoring of weather and geophysical variables to trafc control. but even if the data from these systems are not intended to monitor human interaction and behavior, they can often be repurposed to do exactly that. moreover, information about human behavior can be inferred from seemingly innocuous data (such as heat sources in buildings or the way a person walks).still another effect of new information technologies is the erosion of privacy protection once provided through obscurity or the passage of time; e.g., youthful indiscretions can now become impossible to outlive as an adult. for much of the past, the effects of data collection were not a major issue, perhaps because the relevant data were inaccessible for engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.32 engaging privacy and information technology in a digital agepractical purposes or individual pieces of data were stored in different locations so that patterns contained within the potentially aggregated data were difcult to nd. often either the sheer volume of input would overwhelm the method of analysis or the patterns would be lost in a sea of data. it is not quite the case that data were inaccessible, but they were contained in the form of, for example, public records stored in ling cabinets in county clerks™ basements, and were in practice expensive and difcult to access.today and increasingly in the future, electronic storage of information is less expensive and potentially more persistent than paper storage.8 also, information systems have moved from isolated systems to clustered systems of users and machines to what now is becoming a mesh of interconnected information and analysis systems, which can share information and work collectively, leading to a much greater ease of data aggregation. once data is aggregated, new and more powerful techniques and technologies for analyzing information (generically known as data mining) will make it much easier to extract and identify personally identiable patterns that were previously protected by the vast amounts of data ﬁnoiseﬂ around them. furthermore, as the interrelationships between systems become more closely identied, the issues of ownership, control, prerogative, and privacy also become more difcult to discern or manage.similarly worrisome to many is the emergence of biometric identication, the use of information technologies to measure and record biological or physiological characteristics of the human body for identication purposes. such characteristics can include dna sequences, gait, retinal patterns, ngerprints, and so on. the primary signicance of biometrics in a privacy context is that certain markers are selected for largescale use because they are believed to be more or less invariant over an individual™s lifetime. (whether this is in fact the case in any given instance can be a subject of great debate.)the comments above should not be taken to mean that the advance of technology has only negative effects on privacy. as the discussion in chapter 3 indicates, some advances in technology can promote or enhance privacy. for example, technology enables the maintenance of audit trails 8 whether paper or electronic storage is in fact more persistent in the long run (measured in decades) is not known with certainty. whereas paper is a very simple and enduring medium, today™s highcapacity cdroms and dvds may be largely unusable in 10 years. the problem of electronic media obsolescence as it affects access to stored information can be addressed by periodically rewriting the information onto new media, but such rewriting presents logistical challenges that can be daunting for individuals and organizations alike. (on the difculties faced by organizations, see national research council, lc21: a digital strategy for the library of congress, national academy press, washington, d.c., 2000.)engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 33that can keep track of who accesses what data. the possibility of accessing sensitive data improperly on an anonymous basis often presents a strong temptation for doing so, and the keeping of audit logs can often deter such activity. however, such privacyprotecting technologies must be deployed in order to enhance privacy, and because they generally have no operational or business value other than protecting privacy, it is often the case that such protective technologies are not deployed.1.4.3 societal shifts and changes in institutional practicefocusing solely on technological advancements provides an incomplete view of how values, understandings, and expectations shift over time. important consideration must be given to societal institutionsšthe organizations and the activities and practices that make use of the technological systems described abovešand to the transformation of social institutions through their routine use.modern society is characterized, in part, by a multitude of demands for personal information not just from families and one™s immediate community but also from governments and institutions. whether these demands are the result of new technologies searching for problems to solve at lower cost, or whatever they serve to stimulate the growth of new technologies, is open to questionšas with most such questions, the most likely answer is ﬁsome of both.ﬂ9 but what is clear today is that making personal information available to institutions and organizations is absolutely essential for individual participation in everyday life.consider, for example, the information demands involved in:ł licensing practices, of which the driver™s license is the most ubiquitous example. to obtain a driver™s license, an individual must provide personal information (e.g., name, address, and so on) as well as proof of driving ability. but over time, a driver™s license comes to contain a driver™s history of moving violations and accidents as well. furthermore, a driver™s license is a de facto id standard for many purposes, ranging from admission to facilities and air travel to check cashing. though auto9 as one example, a string of technological innovations that shaped, and were shaped by, the development of the modern bureaucracy between 1890 and 1939 is described in james beniger, the control revolution: technological and economic origins of the information society, harvard university press, cambridge, mass., 1986. the duality of causation is re˚ected quite well in the example of the use of herman hollerith™s punch card system to increase the efciency of the 1890 census. while hollerith™s machines cannot be blamed, there is little doubt that they were an integral part of the transformation of the national government™s data gathering, processing, and distribution activities.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.34 engaging privacy and information technology in a digital agemated systems are not in place today to collect driver™s license numbers in all of these applications, they could bešand the volume of personal information about spending habits, locations, travel, and so on that might be assembled through such systems is rather large. for other licensing applications, such as licenses needed for various professions, other kinds of information may be needed, such as various histories of education, records of previous practice, and customer complaints and/or disciplinary actions taken. to receive an amateur radio operator™s license, a personšregardless of agešmust allow his or her name and address to be posted on the internet.ł many benets in society are conferred by law only to particular classes of people (e.g., veterans, the unemployed, those with low income, homeowners). establishing eligibility and verifying claims require individual information. in response to concerns about fraud, administering government agencies are asking for more information and have increasingly turned to computer matching involving diverse databases. in contrast, such agencies rarely do computer matching to identify potential clients who are not utilizing benets to which they are entitled.ł many private sector institutions make distinctions between categories of people. for example, the granting and the terms of credit to individuals both depend heavily on many of the details of their nancial history (e.g., records of payment, length of time at particular addresses, employment record, income). admissions to many institutions of higher education depend on a detailed history and record of an individual™s curricular and extracurricular activities.ł many institutions require personal information as a condition of providing service at all. in some cases, the need for personal information is intrinsic to the service itselfšhealth care services for an individual are perforce informationintensive, and given societal pressures to deliver more effective health care at lower cost, are likely to become more so in the future. in other cases, the need for personal information is externally motivatedšfor example, as a matter of regulation for the purpose of inhibiting money laundering, banks are legally required to collect and le information from customers that is not intrinsically connected to the provision of nancial services.ł employers are demanding more information about employees as they seek to validate employment credentials, to better match a person to a job, and to avoid liability suits. wouldbe employees submit extensive application forms documenting previous work histories and education; once hired, they are often subject to drug tests and location checks to help ensure that they are continuing to observe the conditions of their employment. on the job, intensive work monitoring has increased, particularly as individuals work with computers and or work in areas subject to video engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 35surveillance. this may go beyond monitoring of work products per se, to the monitoring of behavior unrelated to work and sometimes behavior offduty.ł retailers of goods and services galore are seeking to provide more personalized products and targeted attention to their customers. from customization of goods and services to individual needs targeted at marketing specic products to selected audiences likely to buy them, detailed personal information about the preferences and habits and buying histories of customers is an enabler for personalization.ł members of the public demand information as well. through the legislative process, previously private information such as physician malpractice histories, sexual offender status, and political contributions are now publicšand more importantly, easily availablešfor all to see.ł individuals demand more information from each other in many contexts. for example, it is common that individualsšespecially young peoplešusing social networking sites post large amounts of personal information. no one forces these people to do so, and yet the social context of the sites™ use provides a strong impetus for doing so.the examples above illustrate current information demands. they also suggest how our attitudes toward privacy are context dependent. it is difcult to hold a broad view, absent consideration of what kind of information is sought, who seeks it, and how it is to be collected, protected, and used. there are, for example, some things one might not mind the government knowing that one would object to an employer knowing (and vice versa). and there are other things that one would not object to either of them knowing, but would not want passed on to aunts and uncles, just as there are things that one would like to keep within the family. determining what should be left to the realm of ethics and common courtesy, what should be incentivized or discouraged, and what should be formalized into a code of law is yet another balancing question that comes up when contemplating privacy.a further complicating factor is the changing nature of expectations about the revelation and concealment of personal information. social and cultural trends over the last century (perhaps accelerated during the 1960s) have softened traditional beliefs that opposed the easy revelation of certain kinds of personal information. although many individuals do seek a certain measure of privacy in their lives (e.g., they purchase homes with privacyprotecting features such as enclosed porches or obscuring bushes), there has been a lessening or outright ending of reticence in mass culture as seen in the popularity of reality television shows and talk show confessionals. in addition, an emphasis in some parts of society on sharing and building trust and community through openness in comengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.36 engaging privacy and information technology in a digital agemunication and discussion may con˚ict with privacy notions regarding what is (or should be) kept as ﬁpersonal informationﬂ and what should be revealed.finally, in some cases personal information is used to determine a category into which a given individual might fall, and what is of interest to another party is the category rather than the person.10 the availability of personal information enables the assignment of an individual to one or more categories, such as those who share a characteristic such as age, race, or genetic marker. for example, the popularity of geodemographic targeting for the marketing of goods and services at the neighborhood level re˚ects a determination that there is quite a bit of predictive utility in the differences between 100 types of communities denable at the zip + 4 level of precision.11 political parties use personal information to determine how to target their voter turnout efforts towards those most likely to vote for their candidates.12undertaken in the context of selling different products based on a zip code™s socioeconomic status indicators, such a practice may be benign. nevertheless, it is important to consider the implications of less benign applications, such as political campaigns run on a similar basis, in which different messages are targeted to different geographical areas, or redliningšthe practice of denying service (or increasing the cost of service) to people in selected geographic areasšwhich may serve as a proxy for race, ethnicity, or income. such issues re˚ect the potential for an informationbased ability for discrimination of many different kindsšagainst individuals and against groupsšin the name of increasing efciency. (note that this notion of discrimination is not necessarily conned to discrimination against categories of people protected by law.)1.4.4 discontinuities in circumstance and current eventscurrent events can be important factors in shaping attitudes toward privacy.10 geoffrey c. bowker and susan l. star, sorting things out: classication and its consequences, mit press, cambridge, mass., 1999.11 see the discussion of geodemographic clustering and commercial services offered by claritas corporation in mark monmonier, spying with maps, university of chicago press, 2002.12 see, for example, chris cillizza and jim vandehei, ﬁin ohio, a battle of databases,ﬂ washington post, september 26, 2006, p. a1.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 371.4.4.1 national security and law enforcementthe events of september 11, 2001, have led to a renewed emphasis on homeland security and how best to achieve it in the united states. the primary focus of homeland security is now prevention of deliberate catastrophically harmful incidents rather than prosecution of those responsible for such acts. prevention and disruption of a terrorist act are much more difcult than is prosecution of those responsible after the act, primarily because investigative activities can be focused much more precisely, working backward from the event.this new focus has resulted in a number of privacyrelevant changes in the policy environment. one of the most important changes has been to elide the traditional separation of law enforcement and national security intelligence gathering. but this change poses numerous challenges, the most important of which is the nal disposition of ﬁlaw enforcementﬂ information versus ﬁnational securityﬂ information. law enforcement ofcials operate in a prosecutorial role, which means that ﬁlaw enforcementﬂ information must be usable in open court, along with information about its origins and provenance. ﬁnational security intelligenceﬂ information is often tied to the sources and methods used to gather it, most of which must remain secret if they are to be productive sources in the future. this means, for example, that it is not generally feasible to allow individuals about whom information has been collected to challenge the accuracy of such information, or even to notify these individuals about the fact of such collection.a second change has been a greater willingness to focus informationgathering efforts on the continental united states. although they were foreign citizens, the september 11 hijackers operated from u.s. soil and used u.s. airliners ˚ying from u.s airports to strike u.s. targets. thus, attention has been focused on identifying other possible terrorist cells operating in the united states by detecting their operational ﬁsignaturesﬂ through domestically focused information gathering and analysis. while the concerns of law enforcement and national security ofcials regarding the possibility of u.s.based terrorist operations cannot be discounted, the mere fact of including information about u.s. persons within the scope of counterterrorist operations inevitably raises privacy concerns as well.these issues are addressed at greater length in chapter 9.1.4.4.2 disease and pandemic outbreakin recent years, concerns about pandemic disease outbreaks have also advanced to the top of the public policy agenda. by denition, pandemics result from the emergence of a new disease (or a variant of an old one) engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.38 engaging privacy and information technology in a digital agethat is both infectious in humans and highly contagious. pandemics have occurred throughout human history, but the cost and time required to travel great distances have diminished now to the point where longdistance travel is within the reach of a large part of the world™s population. along with increased cultural exchange and commerce, this rapid and accessible travel, especially by airplane, has increased the chances for rapid spread of communicable diseases across local and national borders. a person may become infected with a disease and ˚y to a foreign country before even realizing that he or she is sickšan especially relevant point when the symptoms of the disease in question take a long time to appear.as this report is written, world scientists are monitoring two diseases in particular, sars and the avian (bird) ˚u. in both cases, the public health response calls for rapid detection of a medical anomaly and, if possible, identication of the location and direction of spread of the disease so that, for example, quarantine and inoculation zones can be established to stem the spread of disease.the options available from a public health standpoint to prevent pandemic outbreaks originating from outside national borders are limited. the volume of air trafc is so large that it cannot be shut down or even seriously attenuated without enormous economic consequences. thus, the only other option is to monitor closely for the outbreak of disease in other nations and to seek to prevent those who are disease carriers from crossing one™s own national borders.although individuals seeking to enter the united states have fewer and more limited privacy protections than they would if they were already present incountry, monitoring and obtaining information on the health of individuals have implications for privacy. monitoring for the outbreak of disease can entail the acquisition of a great deal of personal information so that public health ofcials can track a disease as it spreads. but even more (potentially) invasive is the idea of obtaining information from travelers (who may be either foreign nationals or one™s own citizens returning from abroad) in order to differentiate them into disease carriers and nondisease carriers. thus, in the pursuit of public health, nations have sometimes required individuals seeking to enter to undergo tests for hiv, ll out detailed medical questionnaires, take medical examinations at the border, and undergo (sometimes covert) thermal scans that detect the presence of fever.1.5 important concepts and ideas related to privacydebates over privacy often make use of specialized concepts whose intuitive meaning is not necessarily clear on the face of it. moreover, these engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 39debates are often conducted without much cognizance of the topic™s long history in the public policy sphere. this section addresses key concepts, and section 1.6 addresses important historical lessons.1.5.1 personal information, sensitive information, and personally identiable informationpersonal information can be regarded as the set of all data that is associated with a specic individual, e.g., date of birth, gender, address, name of rst pet, favorite chocolate, high school of graduation, geographical location at 3:14 p.m. on march 30, 2005, and on and on and on. the specic value of any given element in that set (e.g., a date of birth january 2, 1957) can almost always be associated with more than one individual (many people were born on january 2, 1957).personal information thus has meaning only through the ways in which it associates or differentiates an individual from others. the value of any given data element (call that data element d1) divides the set of all human beings in the universe into two subsetsša set s1 comprising those with whom the value of d1 can validly be associated, and the complement of that set. multiple data (d2, d3, d4–) result in sets s2, s3, s4. combining the values of personal data elements d1, d2, d3, d4 means taking the intersection of s1, s2, s3, s4 (call the intersection s1, and the number of people in s1 the bin size. in general, s1 has more than one person in it (i.e., the bin size is more than one). in the case when the bin size is one, s1 has exactly one person in it, and the data values associated with s1 can be said to uniquely specify a specic individual.several points are worth noting here:ł privacy is perforce a relative concept. in a specic context, i may feel that my ﬁprivacyﬂ is adequately protected if i can be identied within a bin size of 1,000; you may feel that your privacy is adequately protected only if you can be identied within a bin size of 10,000.ł certain combinations of data elements can be particularlyšand surprisinglyšeffective in reducing bin size. for example, 87 percent of the u.s. population can be uniquely specied by knowledge of his or her 5digit zip code of residence, gender, and date of birth.13 none of these individual pieces of information are individually identifying, but most of 13 latanya sweeney, uniqueness of simple demographics in the u.s. population, lidapwp4, laboratory for international data privacy, carnegie mellon university, pittsburgh, pa., 2000.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.40 engaging privacy and information technology in a digital agethe general public would be surprised by their collective power in identifying individuals.14ł a person™s identity (whether dened by the individual in question or others labeling him or her) is dened by some subset of personal information. by convention and for legal purposes, that subset generally includes the name of the person in question. but people often operate with multiple identities (or may have identities imposed upon them)šone™s identity as a parent, as an employee, as a social security recipient, as a member of america online with several screen names, and so on. reconciling multiple identities is, in essence, the process of taking the union of all of these subsets, although efforts to link multiple identities through a common identier are often controversial. (also, knowing a person™s name will not necessarily permit access to that person if his or her location (whether in real space or in cyberspace) is unknown.)ł in general, it is the values of data elements and combinations thereof that specify unique individuals, not the data elements themselves. in some cases, ﬁunique identiersﬂšif genuinely uniquešcould be said to specify unique individuals. for example, ruling out the case of identical twins, an individual™s complete genomic sequence (the specic sequence of all 3 billion dna base pairs) could specify a unique individual. barring errors and fraud, the social security number was originally intended to be a unique identier. but in general, no one data element species a unique individual.ł unique identiers require special protection from a privacy perspective. because it is a data element (and not a specic value) that can be used to uniquely specify an individual, a unique identier for a person can greatly facilitate the linkage of other information about that person and hence the collection of large amounts of information under that one identier. when such unique identiers fall into criminal hands, and especially when it is impossible to revoke an identier and obtain a new one, impersonation, identity theft, and even location tracking become much easier to accomplish.ł the value of any given data element may or may not be permanently associated with a given individual. an individual™s date of birth does not change, but an individual™s weight does. matters of historical 14 date of birth is an especially powerful tool for reducing bin size. knowing the day of the year splits the population into 366 groups. knowing the year of birth splits the population into an additional 90 to 100 years, depending on one™s estimate of the age of the oldest individuals. thus, date of birth alone splits a population into some 32,940 to 36,600 bins. a 5digit zip code splits the population into 100,000 bins. these attributes taken together constitute approximately 3.5  109 bins, a number that is about 10 times the population of the united states. thus, sweeney™s empirical result is not entirely surprising.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 41fact, if recorded correctly and accurately, do not change and thus are permanent, although their meaning is subject to interpretation and those interpretations may changeše.g., what to make of an individual who undergoes a sex change operation. names and addresses do change with some frequency, although one may be able to make some general sociodemographic inferences with knowledge of such changes over time. an individual™s dna sequence does not change throughout his or her lifetime, but the longevity and stability of many other biometric indicators have not been denitively established.individuals vary considerably in their privacy demands or expectations for different kinds of data and for the same individual data element in different situations. that is, in one situation, an individual may regard a particular data element as highly private (one that might require a large bin size) and in a different situation regard the same data element as not at all private (i.e., he would be perfectly ne with a bin size of one). relevant situational factors may include:ł the specic value of the data element and whether or not it stigmatizes or disadvantages. for example, an hivpositive individual may require a bin size of one million to feel that his hiv status is private; an hivnegative individual may feel entirely comfortable with a bin size of one (i.e., being identied with certainty as being hivnegative).ł the stated purpose for which any given data element is requested. the closer the t between the goals of the supplier and the requester of information and between the information requested and the goal, the more likely it is to be provided. in most doctorpatient contexts, the patient is only too glad to offer information. if a newspaper™s web site asks a visitor her income, she may refuse to provide it, whereas she would willingly supply that same information in lling out an online application for a mortgage. note also that if there is an incentive or reward for supplying personal information, many consumers sell that information more cheaply than their statements about the value of their personal information would lead one to expect.ł the accessibility of the given data element. data that are public and hard to access (e.g., paper records, such as property taxes or divorce proceedings, that are kept in the physical facilities of many jurisdictions) are very different from data that are public and very easy to access (e.g., the same public information posted online). the ease or difculty of nding a particular type of data element may also contribute to accessibility.ł the transience of the given data element. for example, when information is stored in paper form, it may be discarded eventually because it is expensive to store. there may be different privacy implications if the data engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.42 engaging privacy and information technology in a digital ageelement is available only for an instant (e.g., a conversation being heard in real time), for one hour, one year, one decade, or one century.15the above discussion also illuminates the distinction between three categories of informationšpersonal information, sensitive information, and personally identiable information.16ł personal information is the set of all information that is associated with a specic person x. personal information is thus dened in a technical or objective sense.ł sensitive information is the set of personal information that some party believes should be kept private. if the party is the person associated with that information (call that person x), the set is dened by personal preferences of x, and x™s denition of private (which may be highly context dependent and linked to particular cultural standards regarding the revelation or withholding of information). note that context may re˚ect a temporal aspect as well. in some circumstances, one might regard a certain item of personal information as less sensitive if it referred to his or her information ﬁstateﬂ in the past rather than in the present. (for example, i may regard my physical location now as being a more sensitive item of information than my physical location 3 weeks ago.) the converse may be true as well. the party dening ﬁsensitive informationﬂ may also be a party other than person x. this other party may take into account the interests and preferences of person x, but may also be taking other factors into consideration. for example, person x may prefer that her criminal record be kept private, but most criminal records are regarded legally as public information. who denes what information should count as ﬁsensitiveﬂ is often a controversial matter.ł personally identiable information (pii) refers to any information that identies or can be used to identify, contact, or locate the person to whom such information pertains. this includes information that is used in a way that is personally identiable, including linking it with identi15 privacy is not necessarily a monotonically decreasing function of the holding period. personal information held for 100 years after the death of the person involved is arguably nonsensitive as far as that person is concerned, although it may be highly sensitive to grandchildren if it contains genetic or severely stigmatizing information. the converse may be true as well.16 these and some additional distinctions are discussed in gary t. marx, ﬁvarieties of personal information as in˚uences on attitudes towards surveillance,ﬂ in r. ericson and k. haggerty, eds., the new politics of surveillance and visibility, university of toronto press, 2006; and ﬁidentity and anonymity: some conceptual distinctions and issues for research,ﬂ in j. caplan and j.t. torpey, documenting individual identity: the development of the state since the french revolution, princeton university press, princeton, n.j., 2000.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 43able information from other sources, or from which other personally identiable information can easily be derived, including, but not limited to, name, address, phone number, fax number, email address, nancial proles, social security number, and credit card information.17 although pii is also said to not include information collected anonymously, the discussion above suggests both that the ability to make an identication may depend on the specic values of the pii in question and on the ability to aggregate data in ways that reduce signicantly or even eliminate the anonymity originally promised or implied. thus, information that previously was not pii may at a later date become pii as new techniques are developed or as other nonpii information becomes available.1.5.2 false positives, false negatives, and data qualityin many societies, alleged criminals are tried by jury. in any given trial, the jury nds a defendant either innocent or guilty (apart from jury deadlocks). if a defendant found guilty did not in fact commit the crime for which he or she is being tried, the result is a ﬁfalse positive.ﬂ if a defendant found innocent did in fact commit the crime for which he or she is being tried, the result is a ﬁfalse negative.ﬂfalse positives and false negatives arise in any kind of classication exercise.18 for example, a creditcardissuing bank examines personal information of potential clients and classies them as good credit risks (likely to pay their bills) and bad credit risks (unlikely to pay their bills). some individuals identied as good credit risks will, in fact, not pay their billsšthese are the false positives. some individuals identied as bad credit risks would, in fact, pay their billsšthese are the false negatives. these errors can arise either from the problems in the data or from the classication mechanism. for example, if the credit card company has information on two john smith™s mixed together, it is easy to see how a classication of john smith might be erroneous. however, even if the data are entirely accurate, mistaken classications are still possible, even though they would be less likely than in the case of con˚ated data.or, an intelligence analyst examines nancial transactions and phone records of a set of individuals, searching for possible indications of terrorist planning. he classies them as ﬁunlikely to be involved in terrorist activityﬂ and ﬁlikely to be involved in terrorist activity,ﬂ and sends only 17 this denition is a commonly used one, although the precise wording may vary depending on the user in question.18 an extensive treatment of false positives and false negatives (and the tradeoffs thereby implied) can be found in national research council, the polygraph and lie detection, the national academies press, washington, d.c., 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.44 engaging privacy and information technology in a digital agethose in the latter category up the chain of command for further investigation. a false positive is someone in the latter category who, upon further investigation, has no terrorist connection at all. a false negative is someone in the former category who should have received further investigation but did not.two important points arise in this discussion.ł for a given database and given analytical approach, false positives and false negatives are in some sense complementary. more precisely, for a given database, one can drive the rate of false positives to zero, or the rate of false negatives to zero, but not simultaneously. for example, it is easy to identify all individuals who are bad credit risksšjust deny everyone credit. this approach catches all of the bad credit risksšbut also results in a huge number of false negatives. decreases in the false positive rate are inevitably accompanied by increases in the false negative rate, and vice versa, though not necessarily in the same proportion. however, if the quality of the data is improved, or if the classication technique is improved, it is possible to reduce both the false positive rate and the false negative rate.ł identifying false negatives in any given instance may be problematic. in the case of credit card issuers, the bank will probably not issue cards to the bad credit risks. thus, it may never learn that these individuals are in fact creditworthyšand these individuals may forevermore be saddled with another declination of credit on their records without being given the chance to prove their creditworthiness. in the case of the terrorist investigation, it is essentially impossible to know if a person is a false negative until he or she commits the terrorist act.false positives and false negatives are important in a discussion of privacy because they are the language in which the tradeoffs described in section 1.2 are often cast. banks obtain personal information on individuals for the purpose of evaluating their creditworthiness. all of these individuals surrender some nancial privacy, but some do not receive the benet of obtaining credit, and some of those not receiving credit are deserving of credit. a law enforcement ofcial may obtain personal information on individuals searching evidence of criminal activity. all of these individuals surrender some privacy, and those who have not been involved in criminal activity have had their privacy violated despite the lack of such involvement.data quality is the property of data that allows them to be used effectively, economically, and rapidly to inform and evaluate decisions.19 19 alan f. karr, ashish p. sanil, and david l. banks, ﬁdata quality: a statistical perspecengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 45typically, data should be correct, current, complete, and relevant. data quality is intimately related to false positives and false negatives, in that it is intuitively obvious that using data of poor quality is likely to result in larger numbers of false positives and false negatives than would be the case if the data were of high quality.data quality is a multidimensional concept. measurement error and survey uncertainty contribute (negatively) to data quality, as do issues related to measurement bias. but in the context of using largescale data sets assembled by multiple independent parties using different denitions and processes, many other issues come to the fore as well.it is helpful to distinguish between issues related to data quality in a single database and data quality associated with a collection of databases. data quality issues for a single database include (but are not limited to) missing data elds; inconsistent data elds in a given record, such as recording a pregnancy for a 9yearold boy; data incorrectly entered into the database, such as that which might result from a typographical error; measurement error; sampling error and uncertainty; timeliness (or lack thereof); coverage or comprehensiveness (or lack thereof); improperly duplicated records; data conversion errors, as might occur when a database of vendor x is converted to a comparable database using technology from vendor y; use of inconsistent denitions over time; and denitions that become irrelevant over time.data quality issues for multiple databases include all of those issues for a single database, and also syntactic inconsistencies (one database records phone numbers in the form 2025551212 and another in the form 2025551212); semantic inconsistencies (weight measured in pounds vs. weight measured in kilograms); different provenance for different databases; inconsistent data elds for records contained in different databases on a given data subject; and lack of universal identiers to specify data subjects.1.5.3 privacy and anonymityprivacy is an umbrella concept within which anonymity is located. a vandal may break a window, but his or her identity may not be directly tive,ﬂ statistical methodology 3:137173, 2006; thomas c. redman, ﬁdata: an unfolding quality disaster,ﬂ dm review magazine, august 2004, available at http://www.dmreview.com/articlesub.cfm?articleid=1007211; wayne w. eckerson, ﬁdata warehousing special report: data quality and the bottom line,ﬂ may 1, 2002, available at http://www.adtmag.com/article.aspx?id=6321&amp;page=; y. wand and r. wang, ﬁanchoring data quality dimensions in ontological foundations,ﬂ communications of the acm 39(11):8695, november 1996; and r. wang, h. kon, and s. madnick, ﬁdata quality requirements analysis and modelling,ﬂ ninth international conference of data engineering, vienna, austria, 1993.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.46 engaging privacy and information technology in a digital ageknown. someone may send an unsigned or pseudonymous email, or make a charitable contribution. anonymity may involve a protected right, as in the delivery of political messages. or it may simply be an empirical condition generated by stealth or circumstance. unsigned grafti illustrates the former and ﬁfacelessﬂ individuals in a crowd the latter.the distinction between privacy and anonymity is clearly seen in an information technology context. privacy corresponds to being able to send an encrypted email to another recipient. anonymity corresponds to being able to send the contents of the email in plain, easily readable form but without any information that enables a reader of the message to identify the person who wrote it. privacy is important when the contents of a message are at issue, whereas anonymity is important when the identity of the author of a message is at issue. depending on the context, privacy expectations (and actualities apart from the rules) may extend to content or the identity of the sender or to both.the relationship between privacy and anonymity can be made more formal. if personal information about an individual is denoted by the set p, the individual has privacy to the extent that he or she can keep the value of any element in the set private. consider then another set q, a subset of p, which consists of all elements that could be usedšindividually or in combinationšto identify the individual. the anonymity of the individual thus depends on keeping q private.for example, one might dene a number of different sets: the set of all people with black hair, the set of all people who work for the national academies, the set of all people who type above a certain rate, and so on. knowledge that an individual is in any one of these sets does not identify that individual uniquelyšhe or she is thus ﬁanonymousﬂ in the usual meaning of the term. but knowledge that an individual is in all of these setsšthat is, considering the intersection of all of these setsšmight well result in the ability to identify the individual uniquely (and hence in the loss of anonymity).20note also that anonymity is often tied to the identication of an individual rather than the specication of that individual. a person may be specied by his or her complete genomic sequence, but in the absence of databases that tie that sequence to a specic identity the person is still anonymous. a ngerprint may be found on a gun used in a murder, but the ngerprint does not directly identify the shooter unless the ngerprint 20 more precisely, q is the set of all subsets of p that could be used to identify the individual. imagine that elements p2, p4, p17 of p could be used together to identify the individual, as could elements p2, p3, p14 taken together, and elements p3, p7, p14. then anonymity would require that these three sets be kept private, that is {p2, p4, p17}, {p2, p3, p14}, and {p3, p7, p14}. in practice, this might well imply keeping private the union of all these sets {p2, p3, p4, p7, p14, p17}. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 47is on le in some law enforcement databank. in short, the specication of a unique individual is not necessarily the same thing as identifying that individual.21an additional consideration is that ﬁidenticationﬂ usually means unique identicationšusing any of these sets would result in a bin size of one. in other words, in the usual discussion of anonymity, an anonymous person is someone whose identity cannot be denitively ascertained. however, for some purposes, a bin size of three would be insufcient to protect his or her identityšif a stool pigeon for an organized crime syndicate were kept ﬁanonymousﬂ within a bin size of three, it is easy to imagine that the syndicate would be perfectly willing and able to execute three murders rather than one. here again is a situational factor that contributes to the relative nature of such concepts.the anonymity dimension of privacy is central to the problem of protecting data collected for statistical purposes. for example, many agencies of the federal government collect information about the state of the nationšfrom the national economy to household use of medicarešin order to evaluate existing programs and to develop new ones. that information is often derived from data collected by statistical agencies or others under a pledge of condentiality. a most critical data source is microdata, which includes personal information about individuals, households, and businesses, and a central concern of the federal statistical agencies is that the responses provided by information providers will be less candid if their condentiality cannot be guaranteed.22 (this issue is addressed at greater length in section 6.8.)this issue also arises explicitly, although in a somewhat different form, in contemplating the signicance of an organization™s privacyšthat is, information about an organization with whom a number of individuals may be associated. information about an organization can reveal information about individuals, although it may not be uniquely associated with an individual. for example, if a survey of employers shows that a company pays a large amount in employee health care benets to medi21 it is worth noting that despite the common ﬁintuitively obviousﬂ usage of the term ﬁidentity,ﬂ identity is fundamentally a social construct and thus has meaning only in context. i may know a person who sends me email only by his or her email address, but the identity ﬁjohnl7534@yahoo.comﬂ may be entirely sufcient for our relationshipšand it may not matter if his rst name is really john, whether his last name begins with l, or even whether this person is male or female. in this sense, specication might be regarded as a decontextualized identication.22 see, for example, national research council, expanding access to research data: reconciling risks and opportunities, the national academies press, washington, d.c., 2005; national research council, private lives and public policies: condentiality and accessibility of government statistics, national academy press, washington, d.c., 1993.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.48 engaging privacy and information technology in a digital agecal care providers that specialize in treating aids, then it can be inferred that some employees of that company have aids. this fact may have signicance for all of the employeesšthose with aids may face a greater likelihood of having their status revealed, and those without aids may face higher health care premiums in the future if their past employment history becomes known.1.5.4 fair information practicesfair information practices are standards of practice required to ensure that entities that collect and use personal information provide adequate privacy protection for that information. these practices include notice to and awareness of individuals with personal information that such information is being collected, providing individuals with choices about how their personal information may be used, enabling individuals to review the data collected about them in a timely and inexpensive way and to contest that data™s accuracy and completeness, taking steps to ensure that the personal information of individuals is accurate and secure, and providing individuals with mechanisms for redress if these principles are violated.fair information practices were rst articulated in a comprehensive manner in the u.s. department of health, education, and welfare™s 1973 report records, computers and the rights of citizens.23 this report was the rst to introduce the code of fair information practices (box 1.3), which has proven in˚uential in subsequent years in shaping the information practices of numerous private and governmental institutions and is still well accepted as the gold standard for privacy protection.24from their origin in 1973, fair information practices ﬁbecame the dominant u.s. approach to information privacy protection for the next three decades.ﬂ25 the ve principles not only became the common thread running through various bits of sectoral regulation developed in the united states, but they also were reproduced, with signicant extension, in the guidelines developed by the organisation for economic cooperation and 23 u.s. department of health, education, and welfare, records, computers and the rights of citizens, report of the secretary™s advisory committee on automated personal data systems, mit press, cambridge, mass., 1973.24 fair information principles are a staple of the privacy literature. see, for example, the extended discussion of these principles in d. solove, m. rotenberg, and p. schwartz, information privacy law, aspen publishers, 2006; alan westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):431453, 2003; helen nissenbaum, ﬁprivacy as contextual integrity,ﬂ washington law review 79:101139, 2004; and an extended discussion and critique in roger clarke, ﬁbeyond the oecd guidelines: privacy protection for the 21st century,ﬂ available at http://www.anu.edu.au/people/roger.clarke/dv/pp21c.html.25 westin, ﬁsocial and political dimensions of privacy,ﬂ 2003, p. 436.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 49box 1.3 codes of fair information practice fair information practices are standards of practice required to ensure that entities that collect and use personal information provide adequate privacy protection for that information. as enunciated by the u.s. federal trade commission (other formulations of fair information practices exist),1 the ve principles of fair information practice include: ł notice and awareness. secret record systems should not exist. individuals whose personal information is collected should be given notice of a collector™s information practices before any personal information is collected and should be told that personal information is being collected about them. without notice, an individual cannot make an informed decision as to whether and to what extent to disclose personal information. notice should be given about the identity of the party collecting the data, how the data will be used and the potential recipients of the data, the nature of the data collected and the means by which it is collected, whether the individual may decline to provide the requested data and the consequences of a refusal to provide the requested information, and the steps taken by the collector to ensure the condentiality, integrity, and quality of the data. ł choice and consent. individuals should be able to choose how personal information collected from them may be used, and in particular how it can be used in ways that go beyond those necessary to complete a transaction at hand. such secondary uses can be internal to the collector™s organization, or can result in the transfer of the information to third parties. note that genuinely informed consent is a sine qua non for observation of this principle. individuals who provide personal information under duress or threat of penalty have not provided informed consentšand individuals who provide personal information as a requirement for receiving necessary or desirable services from monopoly providers of services have not, either. ł access and participation. individuals should be able to review in a timely and inexpensive way the data collected about them, and to similarly contest that data™s accuracy and completeness. thus, means should be available to correct errors, or at the very least, to append notes of explanation or challenges that would accompany subsequent distributions of this information. ł integrity and security. the personal information of individuals must be accurate and secure. to assure data integrity, collectors must take reasonable steps, such as using only reputable sources of data and crossreferencing data against multiple sources, providing consumer access to data, and destroying untimely data or converting it to anonymous form. to provide security, collectors must take both procedural and technical measures to protect against loss and the unauthorized access, destruction, use, or disclosure of the data. ł enforcement and redress. enforcement mechanisms must exist to ensure that the fair information principles are observed in practice, and individuals must have redress mechanisms available to them if these principles are violated.1see http://www.ftc.gov/reports/privacy3/fairinfo.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.50 engaging privacy and information technology in a digital agedevelopment (oecd). these principles are extended in the context of oecd guidelines that govern ﬁthe protection of privacy and transborder ˚ows of personal dataﬂ and include eight principles that have come to be understood as ﬁminimum standards . . . for the protection of privacy and individual liberties.ﬂ26 they also include a statement about the degree to which data controllers should be accountable for their actions. this generally means that there are costs associated with the failure of a data manager to enable the realization of these principles.1.5.5 reasonable expectations of privacya common phrase in discussions of privacy is ﬁreasonable expectation of privacy.ﬂ the phrase has a long history in case law, rst introduced in katz v. united states, 389 u.s. 347 (1967), that re˚ects the fact that expectations are shaped by tradition, common social practices, technology, law, regulations, the formal and informal policies of organizations that are able to establish their own rules for the spaces that they control, and the physical and social context of any given situation. expectations of privacy vary depending on many factors, but place and social relationships are among the most important.historically, the home has been the locale in which the expectation of privacy has been the most extensive and comprehensive. yet there are different zones of privacy even within the home, and within the sets of interpersonal relationships that are common to one™s home. while customs vary across cultures and individual families, there is a welldistributed sense of the nature of these spatial boundaries within the home. kitchens and living rooms are common or relatively public spaces within the home, and they are places into which outsiders may be invited on special occasions. bedrooms and bathrooms tend to be marked off from the more public or accessible spaces within the home because of the more intimate and personal activities that are likely to take place within them.in u.s. workplaces, individuals have only very limited expectations of privacy. the loss of privacy begins for many with the application, and reaches quite personal levels for those jobs that require drug tests and personality assessments. on the other hand, privacy does not evaporate entirely on the job. closets may be provided for the storage of personal effects, and depending on the relative permanence of assigned spaces, desk drawers may be treated as personal space. the presence or absence 26 marc rotenberg, the privacy law sourcebook 2001, electronic privacy information center, 2001, pp. 270272.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 51of doors within workspaces affects the ability of workers to control direct observation by others.technology also affects reasonable expectations of privacy. technology can be used to enhance human senses and cognitive capabilities, and these enhancements can affect the ability to collect information at a distance. the result is that space is not the marker it once was for indicating boundaries between private and public interactions. in the case of information technology, the ﬁobjectsﬂ about which one is private (digital objects such as electronic les or streams of bits as communications) are quite distinct from objects that were originally the focus of privacy concerns (physical, tangible objects made of atoms). thus, kerr argues, for example, that the wellestablished history of fourth amendment law governing permissible searches (and also reasonable expectations of privacy) must be rethought in light of the manifest differences between physical and digital objects.27critical events such as the terrorist attacks of 2001 have dramatically increased the level of personal and records surveillance that travelers encounter. heightened concern about threats of violence means that searches of personal effects are becoming more common at sporting events, popular tourist sites, and even schools.formal and informal policies that dene the boundaries between the public and the private also help to shape our expectations of privacy that develop over time. privacy policies are not only established by legislatures, administrative agencies, and the courts. individual rms, trade unions, professional associations, and a host of other institutional actors have also developed policies to govern the collection and use of personal information. individuals also have policies, or norms, that govern the ways in which they will interact with organizations and with other individuals. indeed, individuals™ reciprocal behavior with respect to asking for, and offering, information is conditioned by custom and manners that are no less signicant for not being less formal than the written policies.crosscultural differences with respect to expectations of privacy can be noted. for example, compared to western cultures, a number of eastern cultures place a far lower value on certain kinds of privacy in the home, and an asian child often grows up with very different expectations of privacy than might an american child.finally, the concept of ﬁreasonable expectations of privacyﬂ has a normative meaning as well as a descriptive meaning. for example, in 27 orin kerr, ﬁsearches and seizures in a digital world,ﬂ harvard law review 119:531, 2005. kerr™s normative reformulation of fourth amendment law calls for maintaining ﬁthe specic goals of specic doctrinal rules in light of changing facts,ﬂ although he clearly recognizes that other normative reformulations are possible.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.52 engaging privacy and information technology in a digital agea world where electronic surveillance technologies make surveillance easy to conduct on a wide scale, one could argue that no one today has a ﬁreasonable expectationﬂ that his or her phone calls will not be tapped. but both statutory law (e.g., title iii in the u.s. code) and case law (e.g., katz v. united states, 389 u.s. 347 (1967)) stipulate that under most circumstances, an individual does have a reasonable expectation that his or her phone calls will not be tapped.1.6 lessons from historyin the history of the united states, a number of societal shifts have taken place that relate to contemporary visions of privacy (appendix a). for example, a move from primarily rural to a more urban (or suburban) society resulted in changes to the scale of one™s community and increased one™s proximity to strangers. in addition, the impact of information technologies is often to compress time and distance in the social sphere, and one result has been an increasingly diminished utility of time and space as markers of the boundaries between private and public space. associated changes in how trust is developed and sustained have all shaped our understanding and appreciation of the value of privacy and the limits on it in a more impersonal society.furthermore, there is an increased appetite on the part of many sectors of society for information collection and analysis and verication. the kinds of interactions individuals have with institutions and with each other have changed as a result. increased societal needs, increased interdependence, new kinds of risks, ever greater complexity, and an increase in the number of rules one needs to be aware of to move safely and smoothly through society have radically altered the kinds of interactions individuals have with institutions and with each other. both private organizations and government agencies are increasingly concerned with the ability to document compliance and discover violations. this is a major motivation for collection of information about individuals and about organizations.as the discussion in appendix a (on the history of surveillance and privacy in the united states) suggests, a number of lessons can be gleaned from history. the rst is that surveillance has been intensifying as society has grown more complex.28the second lesson is that each technological advance in the spheres 28 living in small towns or tightly knit communities is often associated with lesser degrees of privacy (where ﬁeveryone knows everyone else™s businessﬂ). but lesser privacy in these communities is not generally the result of explicit acts of surveillance or information gatheringšrather, it is a byproduct of routine daytoday living.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.thinking about privacy 53of sensing, communication, and information processing invites greater surveillance, and often those invitations are accepted. the invention of the telegraph led almost immediately to the invention of wiretapping. the invention of automated ngerprint matching led to the fbi™s integrated automated ngerprint identication system. the development of the computer resulted in unprecedented recordkeeping power, and the emergence of networking technology has further increased that power. this is not to suggest that technologies make things happen on their own, but they do facilitate the activities and ambitions of those who might use them and who can afford the costs of those new technologies.the third lesson is that times of crisis or war are often marked by contractions in the scope of civil liberties. often, when u.s. government leaders have come to believe that the security or the core interests of the nation were being threatened from without, the government has increased its surveillance of groups within its borders. in case after case whether british loyalists, or japaneseamericans, or arabamericans, the unequal weight of government surveillance on these groups has been justied on the basis of alleged links between the groups in question and threats to the national interest. moreover, as the putative threat from these groups has faded with history, actions taken against these groups have generally been regarded with a degree of retrospective shame.the fourth lesson is that although u.s. conceptions of privacy can be traced historically, the meaning of the concept has been highly varied and vague, and there has never been an agreedupon meaning. one result is that the legal and regulatory framework surrounding privacy has been a patchwork without a unifying theme or driving principles. this state of affairs in the united states contrasts sharply with those of certain other nations (notably the member states of the european union) that often take a more comprehensive approach to privacyrelated issues. this point is discussed further in chapter 4.1.7 scope and map of this reportthis report examines privacy from several perspectives and offers analysis and ways of thinking through privacy questions at the same time that it provides a snapshot of the current state of affairs.part i is this chapter (chapter 1).part ii includes chapters 2 through 5, which are primarily expository. chapters 2 and 3 seek to lay the groundwork for what privacy is and how it affects and is affected by societal and technological complexities. chapters 4 and 5 address the legal landscape of privacy in the united states and the political forces shaping that landscape throughout recent history.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.54 engaging privacy and information technology in a digital agepart iii (chapters 6 through 9) considers privacy in context, examining privacy issues in different sectors of society. chapter 6 looks at institutional practice in privacy broadly in several different sectors. chapter 7 provides a more indepth look at health and medical privacy. chapter 8 explores privacy and the u.s. library community and also mentions the issue of intellectual property and privacy (where technology, policy, and privacy intersect strongly). chapter 9 looks at law enforcement and national security.part ii can be skipped without loss of continuity if the reader wishes to consider the various case studies rst in part iii. however, parts i and ii supply important background information that provides a context for part iii.part iv consists of a single and nal chapter (chapter 10) and provides the bulk of the report™s look to the future. it examines mechanisms and options for privacy protection and presents the report™s ndings and recommendations.appendix a presents a short history of surveillance and privacy in the united states. appendix b provides a look at international considerations.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.55part ii the backdrop for privacychapter 2 (ﬁintellectual approaches and conceptual underpinningsﬂ) provides a primer on privacy as an intellectual concept from the perspective of three disciplinesšphilosophy, economics, and sociology. philosophical approaches to the study of privacy have centered on the elucidation of the basic concept and the normative questions around whether privacy is a right, a good in itself, or an instrumental good. economic approaches to the question have centered around the value, in economic terms, of privacy, both in its role in the information needed for efcient markets and in the value of information as a piece of property. sociological approaches to the study of privacy have emphasized the ways in which the collection and use of personal information have re˚ected and reinforced the relations of power and in˚uence between individuals, groups, and institutions within society. that there is such a multiplicity of legitimate intellectual approaches to the study of privacy suggests that no one discipline captures, or can capture, the richness and texture of its various nuances, and what appear at rst to be very slight or subtle differences turn out to have deep implications in practice.chapter 3 (ﬁtechnological driversﬂ) examines the vast changes enabled by information technology by exploring the ramications of increased connectivity and ubiquity, data gathering, evergrowing computational power and storage capacity, and moresophisticated sensors; what architecture choices mean for social values such as privacy; and what kind of control (or lack of control) technology enables for individuals. such change has dramatically altered the ontheground realities within which engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.56 engaging privacy and information technology in a digital agethe concept of privacy is necessarily embedded. the net result is that new kinds of data are being collected and stored in vast quantities and over long periods of time, and obscurity or difculty of access are increasingly less practical as ways of protecting privacy. finally, because information technologies are continually dropping in cost, technologies for collecting and analyzing personal information from multiple, disparate sources are increasingly available to individuals, corporations, and governments.chapter 4 (ﬁthe legal landscape in the united statesﬂ) provides a detailed overview of the legal landscape in the united states. the foundation of privacy law in the united states is, of course, the u.s. constitution, and the first, fourth, and ninth amendments of the constitution have important implications for privacy, and specically constrain the applicability of federal and state law regarding certain privacyrelated issues. in addition, there are a large number of federal laws (and regulations and executive orders) that address privacy in one form or another, so many in fact that what emerges is an ad hoc patchwork of law that lacks strong coherence or unifying themes. state laws regarding privacy and common law and private causes of action (privacy torts) add to this patchwork but do not rationalize it. finally, in a global economy, the need to conduct commerce across international borders suggests that the united states cannot ignore foreign law regarding privacyšand foreign law regarding privacy is often much more comprehensive than domestic law.chapter 5 (ﬁthe politics of privacy policy in the united statesﬂ) addresses the question of how privacy policy is made. privacy advocates use public opinion as a lever to generate concern and action. in addition, a number of reports over the past several decades have served to catalyze public action. judicial decisionsšimportant in interpreting existing lawšare also the most important, and perhaps the only, forum in which competing goals and values are explicitly weighed and balanced against each other. finally, corporate policy regarding privacyševen if it is established by default or inattentionšhas potentially enormous impact on the privacy actually enjoyed by individuals, because such policies often delve into areas of privacy that are minimally addressed by existing law.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.572intellectual approaches and conceptual underpinningsthe concept of privacy has a long intellectual history. many have written attempting to characterize privacy philosophically, sociologically, psychologically, and legally. this chapter provides a brief sampling of some major intellectual perspectives on privacy, along with some analysis of how these different perspectives relate to one another. these perspectives illustrate some common themes while demonstrating the difculty inherent in characterizing privacy, no matter what intellectual frameworks or tools are used.note also that this chapteršas well as this reportšfocuses on privacy as it relates to information. the informational dimensions of privacy are clearly central, but at the same time some have argued that the concept of privacy must be broader than that; for example, the u.s. supreme court has held that a right to choose an abortion or to receive information about contraceptives is founded on privacy protections implied in the constitution. the discussion below is not intended to address these noninformational dimensions of privacy and mentions them only in passing as they may help to illuminate some of the issues surrounding the notion of privacy and the ethical and moral dimensions of the general privacy debate.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.58 engaging privacy and information technology in a digital age2.1 philosophical theories of privacy2.1.1 a philosophical perspectivephilosophical works on privacy generally focus on two central tasks.1 the rst is to attempt to answer the question, what is privacy?, by giving a precise denition or analysis of the concepts involved. the second is to explain why we value privacy and why privacy should be respected by others, whether those others are individuals, organizations, or governments.it is useful to distinguish these two tasks by calling the rst a descriptive account of privacy and the second a prescriptive or normative account of privacy. these tasks are conceptually distinct, and maintaining the distinction between them allows a rich set of questions to be asked.for example, a descriptive analysis does not need to justify the ethical questions surrounding privacy as part of the analysis of the concept. once a descriptive analysis of privacy has been accomplished, the normative aspects of the concept can then be discussed based on that description, and the discussion may wellšand properlyšinclude ethical questions.further, normative accounts of privacy may depend on subtle differences in the descriptive analysis that are either stated or presumed, and that can be masked if the two tasks are intertwined. so, for example, a descriptive account of privacy may show that there are cases where privacy con˚icts with other values. such a con˚ict may lead to the decision that not all violations of privacy are to be avoided. but if descriptive and prescriptive accounts of privacy were merged, such an analysis might be precluded from the outset since our prescriptive account might hold that all reductions of privacy count as moral violations.any descriptive account of privacy will have to correspond to the perceptions and intuitions of most people about clear cases of the concept. so, for example, an analysis of the concept that held that privacy is a binary property that an individual either has or has totally lost would not be acceptable, as it violates the commonly held intuition about degrees of privacy and the loss of some privacy. a descriptive account that adequately deals with clear cases can then be used to elucidate less clear cases, and can then be used as a base for prescriptive discussions about privacy. so, for example, starting from a descriptive analysis of privacy that acknowledges that there are levels or degrees to privacy, it is then possible to address the prescriptive question of where a particular loss or 1 note that the discussion in section 2.1.1 draws not only on the writings of professional philosophers, but also on other work that undertakes explicit conceptual analysis devoted to exploring what privacy is, what a right to privacy consists in, and why we ought to protect it.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 59gain of privacy is good or bad, problematic or not, and for whom and for what time period and under what conditions.much of the philosophical work on privacy has been stimulated by contentious activities in realms such as law, policy, institutional practices, and specic or novel applications of technology. in such a context, the prescriptive aspects of privacy are the most commonly discussed. what descriptive work has been done is often in the context of clarifying the basic concepts as part of a discussion of a particular normative view.2.1.2 privacy as control versus privacy as restricted accessthe most common descriptive accounts of privacy re˚ect two basic views: (1) privacy as restrictions on the access of other people to an individual™s personal information and (2) privacy as an individual™s control over personal information2 such as information on health status. while related, these two views can also be seen as distinct.political science professor emeritus alan westin™s take on privacy was (and remains) an in˚uential example from the group that denes privacy in terms of control. indeed, westin can be credited with developing one of the very rst formulations of socalled informational privacy in the late 1960s, and his denition of privacy has proven quite useful to scholars as society has moved more fully into the information age: ﬁprivacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others.ﬂ3in privacy and freedom, westin took an interdisciplinary approach to analyzing the nature and functions of privacy, its roles in society, and new technologies for surveillance, as well as the push for new privacy standards and protections. as part of the overall theory put forth in the book, westin denes four distinct functions of (or reasons for wanting) privacyšpersonal autonomy, emotional release, selfevaluation, and limited/protected communicationšas well as four distinct states of privacyšsolitude, freedom from observation; intimacy, closeness among a small group of people; anonymity, freedom from being identied in public settings; and reserve, the freedom to withdraw from communication. as he describes it, these states are subject to constant change, depending on one™s personal needs and choices about what to reveal and what not to reveal at a given time. indeed, for westin, the importance of this control over information disclosure, ﬁboth to [an] individual™s selfdevelopment 2 a second use of ﬁcontrolﬂ refers to an external agency with the power to compel a person to disclose personal information. ﬁcontrolﬂ in this section is not used in this sense.3 see alan westin, privacy and freedom, atheneum, new york, 1967, p. 7.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.60 engaging privacy and information technology in a digital ageand to the exercise of responsible citizenship, makes the claim to privacy a fundamental part of civil liberty in democratic society.ﬂ4 westin™s model of informational privacy and his ideas regarding privacy more generally have informed most subsequent scholarly discussions of privacy and have often acted as a crucial jumpingoff point for the work of other researchers.5in more recent years, much of westin™s work has been somewhat less philosophical in nature, involving surveys to assess the attitudes of u.s. consumers and internet users toward privacy, often in association with harris interactive (previously louis harris and associates)šwork that has earned him both praise and criticism. in contrast to traditional universitybased research, this work has often been done in cooperation with commercial interests.in his survey research, westin has suggested that americans hold differing views regarding the value of certain aspects of privacy. for example, based on his analysis of surveys over a number of years, he groups consumers into one of three categories:ł privacy fundamentalistsšthose who reject trading information for special offers, who prefer only optin approaches, and who would prefer to see more legislative approaches to privacy protection;ł privacy unconcernedšconsumers who are comfortable with trading their information for almost any consumer value; andł privacy pragmatistsšpeople who take time to weigh the benets and risks associated with providing their personal information.westin goes on to suggest that the ﬁprivacy pragmatistsﬂ are the largest group, at over 60 percent of u.s. consumers, and are thus a group deserving of focused attention from businesses and policy makers. his survey work has also shown that of the four states of privacy he identied in his earlier research, intimacy is the most important state to americans, followed by solitude, reserve, and anonymity (in that order).westin™s empirical research also led him to identify three phases in the state of u.s. consumer attitudes toward privacy: 1961 to 1979, 1980 to 1989, and 1990 to 2002.6 he notes that privacy has gone from ﬁa modest matter for a minority of consumers in the 1980s to an issue of high 4 alan f. westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):431453, 2003.5 for an additional perspective on the impact of westin™s privacy work, see stephen margulis, ﬁon the status and contributions of westin™s and altman™s theories of privacy,ﬂ journal of social issues 59(2):411429, 2003.6 these three phases, as well as the baseline period leading up to them (1945 to 1960), are described in detail in westin, ﬁsocial and political dimensions of privacy,ﬂ 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 61intensity expressed by more than [75 percent] of american consumers in 2001,ﬂ7 citing driving factors like increasing distrust of institutions and fears surrounding the potential abuse of technology.analyses of privacy in terms of individuals™ control over their personal information are far more common than those that are based on access, and hence are rarely backed by systematic argument. arguments based on the ﬁprivacy as controlﬂ perspective tend to concentrate on the extent of what must be controlled for privacy to be maintained. at one extreme is the position that says that all that needs to be controlled is information about the individual per se (e.g., health status). more general analysis includes other aspects of an individual™s life, such as control over the receipt of information (such as information concerning birth control, argued in griswold v. connecticut, 381 u.s. 479 (1965)) or the control over one™s body (the crux of roe v. wade, 410 u.s. 11 (1973)).theorists supporting the accessbased denition of privacy have offered explicit explanations for their analysis, based on the ability of that analysis to explain situations that cannot be explained by a controlbased theory. one such class of situations is exemplied by a person choosing to reveal intimate details of his life on national television. on the basis of the ﬁprivacy as controlﬂ theory, he could not reasonably claim that he had less privacy as the result of doing so because he chose to reveal those details. however, on the basis of the ﬁprivacy as restricted accessﬂ theory, he would have less privacy, because the information given on the show had become accessible to the entire audience.american university philosopher jeffrey reiman has presented a case in which the control theory would say that privacy had been violated but our intuitions say that no such violation has occurred. he points out that societies often regulate certain public activities, by requiring, for example, that bathrooms are used or that clothing is worn in public. such requirements diminish the control of individuals over the information that they can allow to others, but the laws are also seen as privacy enhancing. thus control over information cannot be the exclusive dening characteristic of privacy. however, laws and related expectations regarding disclosure and nondisclosure of personal information do limit the access to information by others, which is just the sort of thing that the accessbased models of privacy would predict.although the issue of whether privacy is best seen as a question of access or a question of control is the primary disagreement in much of the philosophical literature, it is hardly the only point of dispute. another 7 alan westin, 2001, testimony before the house committee on energy and commerce™s subcommittee on commerce, trade, and consumer protection, may 28, available at http://energycommerce.house.gov/107/hearings/05082001hearing209/westin309.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.62 engaging privacy and information technology in a digital agebasic question has to do with what aspects of a person™s life are relevant to the question of privacy. ruth gavison, professor of human rights at the hebrew university in jerusalem, denes privacy along three axes: the rst has to do with access to information about the person (secrecy), the second has to do with knowledge of the person™s identity (anonymity), and the third has to do with access to the physical proximity of the person (solitude).8 university of pennsylvania professor of law anita allen™s early work distinguished among informational privacy (limited access to information, condentiality, secrecy, anonymity, and data protection), physical privacy (limited access to persons, possessions, and personal property), and decisional privacy (limited intrusion into decision making about sex, families, religion, and health care).92.1.3 coherence in the concept of privacythe wide variation in the accounts of privacy has led some commentators to question the whole endeavor of giving a descriptive account of privacy. for example, yale professor of law robert post writes, ﬁprivacy is a value so complex, so entangled in competing and contradictory dimensions, so engorged with various and distinct meanings, that i sometimes despair whether it can be usefully addressed at all.ﬂ10 some of the commentators who question the descriptive accounts of privacy have argued for a general skepticism toward the coherence of the concept of privacy, while others have claimed that the concept is best understood not as a single concept but rather as a combination of other, more basic rights.a radical example of this second approach is the analysis of mit philosopher judith jarvis thompson, who argues that privacy is neither distinctive nor useful.11 in fact, says thompson, privacy is not a coherent concept in itself, but rather a catchall that reduces, in various cases, to more primitive concepts that are more easily understood, such as property, contracts, and bodily rights. treating privacy as a concept distinct from these others simply confuses the issues surrounding the more basic concepts.a less radical approach admits that privacy is a distinct concept but argues that it is impossible to clearly analyze because of the excess baggage that the concept has accumulated over time. indeed, this baggage is seen to make the overall concept of privacy incoherent. this approach 8 ruth gavison, ﬁprivacy and the limits of law,ﬂ yale law journal 89:421471, 1980.9 anita allen, ﬁconstitutional law and privacy,ﬂ in dennis patterson, ed., a companion to philosophy of law and legal theory, oxford university press, blackwell, england, 1996.10 robert c. post, ﬁthree concepts of privacy,ﬂ georgetown law journal 89(6):2087, 2001.11 judith jarvis thomson, ﬁthe right to privacy,ﬂ philosophy & public affairs 4:295314, 1975.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 63suggests reducing and simplifying the distinct claims, interests, and values that common usage covers in the term ﬁprivacyﬂ to a few basic concepts (or a single, much reduced, concept). some aspects of the general concept of privacy are reducible to more fundamental concepts, and some aspects do not belong within the rubric of privacy and should be dropped altogether. in this approach, what remains should be a coherent and useful concept of privacy, even if it does not re˚ect current use of the term.an even weaker form of reductionism is willing to accept a multidimensional concept of privacy, made up of several nonreducible parts that relate to each other in some fundamental way. for example, judith decew argues that privacy covers information, physical and mental access to oneself, and decisionmaking autonomy.12 these concepts are distinct, and therefore the concept of privacy is in some way made up of others that are more basic. however, decew argues that there is a coherence to these concepts that makes the notion of privacy important in its own way; the whole is greater than the sum of the parts.new york university professor of culture and communication helen nissenbaum™s approach to privacy is based on the idea that social norms governing information ˚ow depend on context.13 a judgment that a given action or practice violates privacy is a function of the context in which the activity takes place, what type of information is in question, and the social roles of the people involved. social contexts, such as health care, education, commerce, religion, and so on, are governed by complex social norms, including informational norms that specify the principles of transmission governing the ˚ow of information.these norms prescribe how certain types of information about specic individuals acting in specic roles ought to ˚ow from party to party. in a health care context, for example, one such norm might specify that patients are obliged to share healthrelated information with physicians who are treating them; another norm for that context species that physicians may not release that information to anyone else. in a context of friendship, friends share information not out of any obligation but through choice, and the ˚ow of information is generally reciprocal. the term ﬁcontextual integrityﬂ is applied to those circumstances in which informational norms are respected.according to nissenbaum™s theory of contextual integrity, these informational norms establish an expectation against which certain actions and practices are evaluated. in particular, they provide a guide to evaluating 12 judith decew, in pursuit of privacy: law, ethics, and the rise of technology, cornell university press, ithaca, n.y., 1997.13 see, for example, helen nissenbaum, ﬁprivacy as contextual integrity,ﬂ washington law review 79(1):119158, 2004.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.64 engaging privacy and information technology in a digital agenew sociotechnical practices, which are judged to respect or violate contextual integrity on the bases of several key factors:ł the governing context;ł whether the new practice changes the types of information at issue;ł whether the new practice causes a shift in who is involved as senders, receivers, and subjects of this information; andł whether new patterns of information ˚ow t with the relevant principles of transmission.when new technologies or sociotechnical practices are disturbing from a privacy standpoint, the reason is that they are seen as violating standing informational norms. under certain circumstances, norms may be revisited and revised: critical events, such as the september 11 attacks, may demand a revision of informational norms governing public spaces; the outbreak of an epidemic may demand that norms of information ˚ow in the medical health care context be revisited; emergence of online dating might also result in a shift of the norms governing information ˚ow. nevertheless, a systematic and comprehensive strategy for evaluating whether change should be resisted or embraced starts with the important rst step of revealing how, if at all, standing norms have been breached or are threatened.the theory of contextual integrity augments dominant approaches to privacy by introducing a middle layer of social analysis missing from theories analyzing privacy as a fundamental human right or value and also from theories placing privacy interests among a whole set of moral and nonmoral interests to be weighed and traded in the course of political decision making. by bringing social norms to the foreground through contexts, roles, and transmission principles, this social approach adds a dimension of thought that can help address some of the critical challenges posed by new practices, and can help illuminate many of the intractable puzzles and standoffs regularly faced in traditional approaches to privacy, for example, cultural and historical differences.gary t. marx, mit professor emeritus, offers a related approach emphasizing the importance of dening terms and identifying contextual variation.14 examining context can guide empirical inquiries and help identify assumptions often buried within normative arguments. among 14 gary t. marx, windows into the soul: surveillance and society in an age of high technology, university of chicago press, forthcoming, and various articles by gary marx on privacy, equality, soft surveillance, borders, the public and the private, ethics, varieties of personal information and anonymity, available at http://garymarx.net.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 65the most relevant factors in his situational or contextual approach are the following:ł keeping distinct (yet noting relationships among) the family of concepts encompassing personal informationše.g., privacy and publicity, public and private, personal and impersonal information, surveillance, secrecy, condentiality, anonymity, pseudoanonymity, and identiability and being clear about which concepts (whether as factors to be explained or to be approached as social issues) are being discussed;ł the nature of the means or techniques used (contrast the unaided and aided sensesše.g., directly overhearing a conversation with intercepting electronic communication on the internet);ł the goals (contrast collecting information to prevent a health epidemic with the spying of the voyeur);ł the location (contrast personal information obtained from the home with that gathered on a public street);ł the type of informationprotective border that is crossed (contrast crossing the borders of the physical person as in a body cavity search, with crossing via aggregation the de facto borders resulting from the disaggregation of information in scattered databases);ł the direction of a personal border crossing (compare taking information from a person as with drug testing or a photo with imposing information on a person as with spam or subliminal sounds);ł the type of personal information involved (contrast a general characteristic such as gender or age with information that may be stigmatizing, intimate, and/or offer a unique and locatable identity);ł the form of the data itself (contrast a third party™s written account of an event with the same event revealed by a hidden video camera);ł the roles and relationships among those involved (contrast parents gathering personal information on children or an ill family member with an employer or merchant gathering information on employees or customers); andł the conditions of information collection, involving, e.g., informed consent, adequate security, reciprocity, sharing in the benets, and so on.this approach yields a number of hypotheses about the patterning of normative expectations with respect to privacy behavior and helps give structure to the intuitive understandings of privacy mentioned below in this chapter.the multidimensional nature of personal information and the related contextual and situational variation prevent reaching any simple conclusions about how crossing personal informational borders will, or should, be judged. thus, the intellectual approach is one of contingency rather than absolutism.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.66 engaging privacy and information technology in a digital agealthough the conceptual questions surrounding the notion of privacy are important, it is not necessary to resolve these matters here. it is sufcient to observe that in all of these various perspectives, personal informationšinformation about usšplays a central role, and questions of access to and use of such information are important. the challenges posed for privacy in the information agešby technological advancement, societal shifts, and critical or signal eventsšfall squarely within the scope of most dominant accounts of privacy and do not require resolution of some of the more difcult conceptual questions concerning the full scope or borders of the concept.2.1.4 normative theories of privacythe philosophical works that attempt to characterize the concept of privacy see that activity as necessary for addressing the important normative questions surrounding privacy. these normative questions concern the value of privacy and include such issues as why privacy is important, both to the individual and to society; why we should individually and as a society protect privacy; and how and to what extent and in what ways with what costs and benets privacy should be protected.this last issue arises because of the need to consider privacy in relation to other values that may be in con˚ict with it. for example, maximizing privacy will constrain the information available to others, and in so doing may decrease efciency, or security, or other things that society or various subgroups value. deciding how much privacy to allow or require sometimes entails a tradeoff with respect to other values, and understanding the nature of those tradeoffs is necessary before one can think in a systematic fashion about decisions involving tradeoffs.one position on the value of privacy is that it is a fundamental human right, like the right to liberty or life. in this view, privacy is an intrinsic good in itself, and a life shorn of privacy is less meaningful than one that has some measure of privacy. the fundamentalist position holds that privacy is tied to a cluster of rights, such as autonomy and dignity. these are tied together in such a way that the combination allows a human life to be more essentially human than if they are missing. carried to its logical extreme, if privacy is an intrinsic (and absolute) good, then there are no cases in which any lack of privacy can be justied.a more common view holds privacy to be of instrumental rather than intrinsic value; that is, the value of privacy derives from the value of other, more fundamental values that privacy allows. in the instrumentalist view, the value of privacy comes because it sustains, promotes, and protects other things that we value. in this view, privacy can be traded off or limited because doing so will promote other values that we hold dear.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 67one example of the instrumentalist view holds that the value of privacy derives from the need for privacy to allow autonomy in the individual. unlike the fundamentalist, who claims that privacy is a basic right on the same level as autonomy, the instrumentalist will claim that autonomy (the ability to control our actions and make free choices) is a fundamental value that is aided by privacy. without privacy, in this view, the individual could be manipulated or coerced in such a way as to lose autonomy. people with no sense of privacy are less able to dene and pursue the goals and ends that are meaningful to them. the actions of such an individual are more likely to be dictated by what others think than by his or her own decisions. but privacy, in this view, is not a fundamental right; if the autonomy of the individual could be guaranteed without a guarantee of privacy, there would be no need (in this view) to ensure privacy.another instrumentalist view holds that the value of privacy is derived from the fact that privacy contributes to fairness. it is because of privacy that we can ensure a level playing eld in the information that is known by each of the two parties in an interaction. without privacy, it would be easy for the more powerful (rich, devious) of the parties to hold extra information about the other party, disadvantaging that party in the interactions. without privacy, the party with the greatest resources can get an unfair information advantage over other parties, ensuring the maintenance of the power or resource disparity.privacy has also been identied as an instrument needed for other, less tangible, goods. arguments have been presented that tie privacy with such things as the ability to dene relationships with others and the ability to sustain intimacy. respect for privacy, in such views, is needed to demonstrate to individuals that they have control of their minds and their bodies. without privacy there could be no such demonstration of respect, and without such respect the intimacy needed for personal relationships would be impossible.all of this chapter™s previous discussions of the value of privacy concentrate on that value to the individual. there have been other approaches that try to see privacy through the lens of the society or group of which the individual is a part. some discussions, for example those by communitarians, call attention to possible negative consequences of privacy.for example, amitai etzioni contrasts certain privacy interests of individuals against what he identies as the common good, or the wellbeing of the society as a whole.15 in most cases in which the interests of an individual are assessed against the interests of the collective, etzioni 15 amitai etzioni, the limits of privacy, basic books, new york, 1999.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.68 engaging privacy and information technology in a digital ageinsists that the collective interests must prevail. protecting the privacy of individuals makes it harder for the society to enforce laws and ensure good public health, and it makes the overall economy less efcient. in this view, privacy has a negative value to the overall community in many settings, even if it has some value to individuals within that society. because people tend to see only their own point of view, privacy has historically been seen to be valuable. etzioni™s view holds that if the price society sometimes pays for individual privacy were clearer, privacy would be given less importance by society.similar arguments are set forth by anita allencastellito, who suggests that individuals are ﬁaccountableﬂ to a number of ﬁothersﬂ including employers, family members, and in some instances, members of a racial or ethnic group.16 accountability means that we may reasonably be expected to ﬁanswer forﬂ our behavior to others with whom we have a meaningful relationship. in her view, we are not entitled to say ﬁit is none of your businessﬂ when some people inquire into our reasons for acting in some way that might place others, or the relationship or the person we care about, at risk.there are also communitarians who hold that privacy is actually of value to society as a whole. while it is true that the lack of information about the individual required by privacy may have drawbacks in the areas of public health, law enforcement, and the economy, it is argued that privacy is needed to ensure the best results to society in all of these areas. without privacy, for example, public health authorities would obtain less accurate reporting of disease and be less sure that those who have communicable diseases would seek treatment. while privacy may impede law enforcement, it is also required to insulate citizens from governmental tyranny and to ensure the general health of liberal democracy. citizens with faith in government and law enforcement are more likely to be cooperative when they perceive that power is limited by decent rules. while aspects of the economy might be more efcient if there were no privacy, such a state of affairs would favor those able to obtain the most information, tending to ensure that unfair distributions of wealth and privilege would be perpetuated.as is often the case with ethical and philosophical discussions, the value of these debates over privacy is not so much that we can nd an answer to our questions, but rather that the issues becomes clearer and more precisely identied.for example, the descriptive debate concerning the nature of privacy shows the difculty of saying just what privacy is in a single simplistic 16 anita l. allencastellito, why privacy isn™t everything: feminist re˚ections on personal accountability, rowman and littleeld, oxford, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 69denition. while we can be reasonably sure that privacy is a matter of individuals™ control over information about themselves, it is less clear whether the emphasis should be on control over the gathering of that information, the access to that information after it has been gathered, the use of the information that has been gathered, or on all equally.in addition, the debate about the normative status of privacy shows that it is sometimes unclear why we should value privacy, and what sort of value privacy has. it does seem clear that privacy must be balanced with other values that we have (at least some of the time), but the mechanisms for establishing such a balance are far from clear. indeed, as the debates about the value of privacy for the individual or the group show, different circumstances can lead to very different decisions about the value of privacy. the debate has brought forward examples where claims to privacy are used to protect behavior that we nd of great value, and examples where claims to privacy are used to protect behavior we abhor. the advantages and disadvantages will also have differential impact on the group or individual in question.2.2 economic perspectives on privacy172.2.1 the rationale for an economic perspective on privacynormative discussions of privacy emphasize the notion of privacy as something of value, which has led some to attempt to look at privacy through the lens of economic theory. rather than philosophizing about what societal values are being balanced, an economic perspective on privacy regards privacy as something that people value in varying degrees under varying circumstances (box 2.1). to the extent that the value of privacy can be imagined in meaningful quantitative terms, an economic approach provides a framework for specifying some of the various costs and tradeoffs privacy is presumed to involve.thus, one starting point is the idea brought forth in section 1.2 that privacy inherently involves tradeoffs, and understanding the nature and scope of tradeoffs is squarely in the domain of economics. a second starting point is a growing awareness that personal information about individuals, their interests, their buying tendencies, and so on has commercial value. indeed, as culnan and bies suggest, consumers™ personal 17 this section is based largely on kailung hui and i.p.l. png, 2006, ﬁthe economics of privacy,ﬂ in terry hendershott, ed., handbook of information systems and economics, elsevier, forthcoming; and alessandro acquisti, the economics of privacy, available at http://www.heinz.cmu.edu/~acquisti/papers/acquistiprivacyeconomics.ppt.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.70 engaging privacy and information technology in a digital agebox 2.1 personal information as an economic good consider the passing of personal information in some kind of transaction between the subject of the information and the recipient. ł the amount of personal information can be increased by recombinations and analysis of existing data. ł the individual generally does not know how, how often, or for how long the information provided will be used. ł other parties who may gain access to the information are not known to the individual. ł the value of personal information to the individual is highly uncertain, and is often determined by events or circumstances extant after the transaction. ł individuals often place different values on the protection and on the sale of the same piece of information. ł the information, as information, is generally nonrivalrous (use of the information by one party generally does not prevent its use by another party). personal information is also often nonexcludable (other parties often cannot be prevented from using the information).source: adapted from alessandro acquisti, the economics of privacy, available at http://www.heinz.cmu.edu/~acquisti/papers/acquistiprivacyeconomics.ppt.information is at the center of the tension between many corporate and consumer interests.18finally, from a policy standpoint, economics is relevant because much of the public policy debate about privacy involves a consideration of the positive or negative market effects (whether real or potential) of government privacy regulation. for example, one longrunning debate concerns using ﬁoptinﬂ or ﬁoptoutﬂ approaches for permitting the sharing of consumer information among organizations. (optin regimes do not collect information unless the individual explicitly takes steps to allow it; optout regimes collect information unless the individual explicitly takes steps to disallow it.) optin is largely seen as an undue burden by the business world, whereas many privacy advocates see consumer optin (which, in a sense, places consumers in the position of owner of their own information) as the best approach for protecting consumers™ privacy.18 mary j. culnan and robert j. bies, ﬁconsumer privacy: balancing economic and justice considerations,ﬂ journal of social issues 59(2):323342, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 71in considering the economics of privacy, alessandro acquisti notes that privacy issues actually originate from two different markets: a market for personal information and a market for privacy. the market for personal information focuses on economically valuable uses for personal information and how such information can be bought, sold, and used in ways that generate value. consider, for example, companies that may need to make decisions about extending credit to individuals. these companies may engage the services of credit bureaus that provide personal nancial information regarding these individuals that is relevant to determining their creditworthiness. or a company may use personal information about the tastes and buying preferences of its customers so that it can tailor its products more precisely to customer needs or market its products with greater efciency. in general, personal information can be regarded as an economic good.the market for privacy can be conceptualized as the market for goods and services that help consumers enhance or protect the privacy of their personal information. for example, they may buy products based on privacyenhancing technologies, or adopt privacyenhancing strategies, or patronize companies that promise to keep their customers™ personal information protected and private.the sections below describe four economic perspectives on privacy: a ﬁprivacy as fraudﬂ perspective, a perspective based on assigning to individuals the property rights to their personal information, a perspective based on regulation, and a perspective based on behavioral economics.2.2.2 privacy as fraudfirst appearing in the late 1970s, one school of thought about the economics of privacy asserts that government facilitates the free ˚ow of personal information for commercial uses in the interests of promoting and maximizing market efciency.19 in this view, both consumers and sellers benet: consumers benet when sellers have access to useful information about them, and sellers benet from being able to get the best return on their advertising or marketing approaches and ultimately make more sales. for example, having information about a given consumer™s interest in golf might help a travel agency tailor vacation offerings or packages that would interest or benet that consumer, as well as allow the agency 19 among the pioneering economic and legal studies with a focus on privacy are richard posner, ﬁan economic theory of privacy,ﬂ regulation (may/june):1926, 1978; richard a. posner, ﬁthe economics of privacy,ﬂ american economic review 71(2):405409, 1981; and george j. stigler, ﬁan introduction to privacy in economics and politics,ﬂ journal of legal studies 9:623644, 1980.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.72 engaging privacy and information technology in a digital ageto save money by not wasting resources in reaching out to people with no interest in such things.however, as hui and png have noted, this approach ﬁmay not work efcientlyﬂ as it is predicated on, among other things, sellers having perfect information about consumers.20 such is rarely the case, as relevant consumer information is often inaccurate, too costly, or simply too difcult to obtain. moreover, access to information about buyers (especially transaction information) can also allow sellers to engage in socalled price discrimination, whereby consumers willing to pay a higher price for a given good or service will be charged a higher price. for example, odlyzko describes how one computer manufacturer offered the same system for sale to small businesses, health care companies, and state and local governments at respectively lower prices.21in addition, this approach can also lead to certain external effects that consumers often view as undesirable. indeed, many consumers perceive unsolicited marketing appeals of a type enabled by the sharing of information (e.g., an unsolicited phone call about a tailored golng vacation package when one has no interest whatsoever in a golng vacation) as intrusions into their privacy and hence as becoming costs that they must bear.22 generally, research suggests that this approach tends to favor sellers over consumers and often results in undesirable externalities for consumers.in the context of this approach, privacy involves the ﬁwithholding or concealment of informationﬂ23šthe ability of buyers to keep personal information away from sellers. advocates of this approach assert that because efcient markets depend on the free ˚ow of information, privacy thus renders markets less efcient.24 for instance, a buyer would choose to hide discrediting or negative information out of selfinterest rather than allowing that information to be used in the decisionmaking process of the seller, particularly if it would raise the cost of the good or service for 20 kailung hui and i.p.l. png, ﬁthe economics of privacy,ﬂ in terry hendershott, ed., handbook of information systems and economics, elsevier, forthcoming.21 andrew odlyzko, ﬁprivacy, economics, and price discrimination on the internet,ﬂ 2003, available at http://www.dtc.umn.edu/~odlyzko/doc/privacy.economics.pdf.22 as a general matter, it is not evident whether privacy leads to more or fewer intrusions such as telemarketing calls. increased information allows rms to better target their marketing efforts. on the one hand, marketing efforts become more effective, so that rms engage in more of them. on the other hand, because rms target, a consumer is less likely to get a worthless call.23 posner, ﬁan economic theory of privacy,ﬂ 1978, p. 19.24 stigler, ﬁan introduction to privacy in economics and politics,ﬂ 1980.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 73the buyer.25 in this view, privacy would create inefciencies and impose restraints on businesses, and ultimately, would lower the general welfare. furthermore, in this view, market forces would create the necessary balance between the opposing interests of buyers and sellers for the most efcient allocation of personal information for maximum benet.2.2.3 privacy and the assignment of property rights to individualsafter the initial economic analyses in the late 1970s and 1980s, privacy reappeared in the economic literature in the mid1990s,26 as the ﬁdotcomﬂ it sector expanded and markets for personal information grew. in these analyses, assignment of property rights to information was proposed as one way to control or improve the use of personal information:27 consumers would ﬁownﬂ their personal information and would be free to share it in whatever manner they chose. for example, some might choose to restrict commercial access to their personal information entirely, whereas others might choose to sell some or all of their personal information or make it available in exchange for some other benet.from the ﬁprivacy as fraudﬂ perspective, the assignment of property rights to information would distort the free market for information, shifting society away from an economically efcient equilibrium and reducing overall societal welfare. for example, granting workers property rights to their personal information might allow them to conceal information from employers. individual workers might benet in the short term, but employersšbeing denied valuable informationšwould make less efcient employment decisions and in the long run might be able to offer fewer jobs, resulting in fewer opportunities for these workers overall.assigning property rights to personal information would result largely in an optin market for information sharing, whereby sellers would have access to the information only of those consumers who chose to make it available. this approach would arguably free consumers from some of the negative effects permitted by a more free market approach (e.g., 25 it is this point that makes the ﬁprivacy as fraudﬂ school of thought signicantly different from a free market school. in a completely free market, individuals would be free to spend money to conceal information. rather, the ﬁprivacy as fraudﬂ school stipulates that the government acts to prevent such concealment.26 economic literature in the mid1990s emphasizing privacy aspects includes roger clarke, ﬁcomputer matching by government agencies: the failure of cost/benet analysis as a control mechanism,ﬂ information infrastructure & policy 4(1):2965, 1995; eli noam, ﬁprivacy and selfregulation: markets for electronic privacy,ﬂ and hal varian, ﬁeconomic aspects of personal privacy,ﬂ both in privacy and selfregulation in the information age, u.s. department of commerce, 1997; and kenneth laudon, ﬁmarkets and privacy,ﬂ communications of the acm 39:9, 1996.27 varian, ﬁeconomic aspects of personal privacy,ﬂ 1997.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.74 engaging privacy and information technology in a digital agecosts/intrusions from unsolicited marketing appeals), but it might also mean that consumers would not benet as much from tailored goods and services from sellers or that sellers would be forced to pass along higher costs associated with less efcient marketing.hermalin and katz have found that privacy can be efcient in certain circumstances but that privacy property rightsšpersonal control over one™s personal informationšare often worthless.28 suppose, for example, that a job candidate has the right to withhold health information from a potential employer. such silence would likely be inferred by the employer to mean that the candidate™s health is poor. the same holds true for a job candidate who declines to answer a question about whether he was in prison: the employer would likely assume that the candidate has served a prison term. if an employer assumes the worst about a potential employee who chooses to exercise his or her privacy rights, then the right to remain silent can be completely valueless, and anyone other than those with the most to hide will ﬁvoluntarilyﬂ reveal their personal information. to protect privacy in such settings, it may be necessary that public policy make it mandatory for everyone to remain silent about their personal information.2.2.4 the economic impact of privacy regulationwhereas the assignment of property rights can have value in resolving privacy issues in contexts where the collectors and users of personal information and the information owners can enter into contractual arrangements, there are many situations in which such contractual arrangements are difcult to manage. such situations are generally handled through regulatory and tort law, and economic analyses of such laws make it possible to understand some of their economic impact.hui and png argue that privacy regulation is most appropriate when many information providers (consumers) are highly sensitive to the gathering of their personal information. (in this context, regulation refers to restrictions, and possibly prohibitions, on the sale or use of personal information for commercial purposes.) when this is so, regulation works efciently and overall welfare is maximized because consumers can avoid the cost of understanding the privacy policy of each individual information gatherer. by contrast, regulation is highly inefcient when most consumers do not care very much about protecting their personal information; under these circumstances, information collectors will avoid the cost of protecting the personal information they gather.28 ben hermalin and michael katz, ﬁprivacy, property rights & efciency: the economics of privacy as secrecy,ﬂ quantitative marketing and economics 4(3, september):209239, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 75one argument in favor of regulation is that it may be a more effective form of commitment than contractual arrangements.29 hui and png argue that under some circumstances, sellers benet from privacy guarantees provided to consumers. a privacy guarantee assures the consumer that his information will not be further shared with a third party, thus making a privacysensitive consumer more likely to make a purchase from a seller. in this setting, the efciency of regulation emerges from eliminating uncertainty on the consumer™s part about whether his personal information will be shared with other parties. an example is the privacy of patient health information. because candor is required for effective provision of health care services, privacy guarantees for patient health information promote healthier individualsšand healthier individuals enhance overall community health.yet there are contexts in which privacy guarantees detract from overall welfare. hui and png suggest that although the ﬁdo not callﬂ list has helped to reduce the volume of telephone solicitors, it may not be possible to control spam email in the same way. one reason is that the majority of spam email likely comes from illicit spammers in any event, and these individuals are unlikely to obey a law that requires senders of spam to consult with a ﬁdo not spamﬂ list. even worse, spammers might nd ways of obtaining the email addresses on the ﬁdo not spamﬂ list, thus rendering the law counterproductive.hui and png conclude that the key issue is how to balance the interests of sellers and consumers, and note that a sweeping ﬁokay to useﬂ or ﬁdo not useﬂ solution will not work across all contexts. when it is feasible to determine the benets and costs of information use, one approach is industryspecic regulation.2.2.5 privacy and behavioral economicsin 2004, some of the rst work on a behavioral economic perspective on privacy appeared. behavioral economics seeks to integrate insights from psychology with neoclassical economic theory and to understand the economic implications of behavior that does not conform to the calculating, unemotional, utilitymaximizing characteristics of homo economicus.in a privacy context, it has been observed that despite consumer concern about privacy, survey results point to broad discrepancies between 29 although private contracts can represent a stronger commitment than does public policy (which can be unilaterally changed), a regulatory approach to privacy protection has the dual advantages of greater enforceability and broad applicability and relevance across the entire population. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.76 engaging privacy and information technology in a digital ageattitudes of individuals and their actual behavior toward privacy protection.30 given the lack of consumer demand, markets for privacyprotecting goods and services (e.g., anonymizers) will continue to remain small, and other selfregulating markets relying on consumer behavior for input may not sufciently protect consumer privacy.31moreover, research in social psychology and behavioral economics indicates that the ﬁdefault conditionﬂ of many choices is very ﬁstickyﬂšthat is, most people nd it easier to accept a default choice made on their behalf regarding a putative decision than to change that choice, even if the default choice is less advantageous to them than changing that choice.32recent work by acquisti is illustrative, offering an explanation for the wellknown discrepancy between individuals™ attitudes and their behavior when it comes to online privacy.33 acquisti argues that contrary to traditional economic analyses that assume that individuals are fully rational, forwardlooking, bayesian updaters who take into account how current behavior will in˚uence their future wellbeing and preferences, individuals instead demonstrate various forms of psychological inconsistencies (selfcontrol problems, hyperbolic discounting, presentbiases). furthermore, the ability to make fully informed decisions regarding one™s privacy is extremely difcult after personal information has been transmitted to a third party and can continue to change hands, without the individual™s knowledge, for any length of time.to provide further insight on individual decision making, acquisti relies on the concept of immediate gratication,34 an individual™s preference for wellbeing earlier rather than later and the tendency to engage in desirable activities over undesirable activities, even if the choice may result in negative future consequences. furthermore, an individual™s preferences are also inconsistent over time (i.e., preferences for the future activities will change as the date to undertake the activity approaches) 30 see, for example, studies cited in section 8 in hui and png, ﬁthe economics of privacy,ﬂ forthcoming.31 alessandro acquisti, ﬁprivacy, economics, and immediate gratication: why protecting privacy is easy, but selling it is not,ﬂ in proceedings of the 2004 blackhat conference, las vegas, nev., july 2004.32 see, for example, william samuelson and richard zeckhauser, ﬁstatus quo bias in decision making,ﬂ journal of risk & uncertainty 1:759, 1988; b.c. madrian and d.f. shea, ﬁthe power of suggestion: inertia in 401(k) participation and savings behavior,ﬂ quarterly journal of economics 116(4):11491187, 2001.33 alessandro acquisti, ﬁprivacy in electronic commerce and economics of immediate gratication,ﬂ pp. 2129 in proceedings of the acm electronic commerce conference (ec 04), acm press, new york, 2004.34 immediate gratication is related to other types of psychological distortion described in economic and psychological literature that include time inconsistency, hyperbolic discounting, and selfcontrol bias. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 77and are disproportionate (i.e., perception of risks will vary for nearterm and longerterm consequences). in relating this to an individual™s online behavior, he suggests that individuals want to protect their privacy in principle but put off to some time in the future the effort required, rather than taking immediate action.combining these two sets of factors reveals broader consequences for individual privacy protection. acquisti suggests that individuals tend to dismiss possible future consequences of revealing personal information for an immediate reward, but also lack complete information to grasp the magnitude of the riskšbecause each instance of revealing personal information can be linked together, resulting in ﬁa whole that is more than the sum of its parts.ﬂ acquisti concludes that more attention will have to be paid to behavioral responses to privacy protections, rather than focusing on protecting privacy solely through informational awareness and industry selfregulation.acquisti™s conclusions have deep privacy implications. for example, one principle of fair information practice (see box 1.3) is that of choice and consent. but the principle itself is silent on whether the appropriate choice should be optin or optout. under the canons of traditional economic analysis and the rational actor model, these regimes are essentially equivalent (under the assumption that there are no transaction costs associated with either choice). but there are impassioned arguments about whether optin or optout consent better re˚ects the willingness of data subjects to provide information without limitations on its secondary usešand these arguments are rooted in a realization that in the real world, the default choice makes a huge difference in the regime that will end up governing most people. those who advocate optout regimes know that most people will not take the trouble to opt out, and thus they can be presumed to ﬁwantﬂ to allow information to be collected. those who advocate optin regimes know that most people will not take the trouble to opt in, and that their privacy (in this case, their immunity to having information collected) will thus be protected.behavioral economics calls into question how to determine the value that consumers place on their personal information. hui and png suggest that one important factor is that the information owners are unlikely to fully take into account the benet of their information to the parties wanting their information.35 this has both a societal consequence (in that overall welfare is reduced as these parties are unable to exploit that information) and personal consequences (in that they may thus exclude 35 kailung hui and i.p.l. png, ﬁthe economics of privacy,ﬂ in terry hendershott, ed., handbook of information systems and economics, elsevier, forthcoming.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.78 engaging privacy and information technology in a digital agethemselves from being offered certain goods or services that they might desire). in addition, information owners are likely to attach too high a price to their personal information, which might excessively raise the barrier to potential buyers of the information, and there is often a signicant discrepancy between what consumers report being willing to pay to protect their personal information and what they are willing to accept to allow the use of their personal information. hui and png go on to suggest that consumers often attach a high price to their personal information when discussing privacy and personal information, but often readily part with their personal information ﬁin exchange for even small rewards or incentives.ﬂ36finally, the ndings of behavioral economics have implications for the various critiques of how fair information principles have been implemented in the united states.37 at the heart of these critiques is the oftexpressed concern that the federal trade commission (ftc), the government agency with responsibility for the protection of certain privacy rights, at least for consumers in the united states, has compressed these fair information practices into a limited construct referred to as ﬁnotice and choice.ﬂ most often, the provision of notice is satised by largely unintelligible industrial sector ﬁboilerplateﬂ language that is not subject to review by the ftc, and the default choice is framed in terms of consumers™ opting out of some subcomponent as standard business practice, unless specic legislation establishes informed afrmative consent as the default.38 behavioral economics thus implies that a default optout choice will not result in a regime that would be afrmatively chosen under a default optin choice.36 see section 6 in hui and png, ﬁthe economics of privacy,ﬂ forthcoming.37 see for example, marc rotenberg, ﬁfair information practices and the architecture of privacy (what larry doesn™t get),ﬂ stanford technology law review, volume 1, 2001 (online journal available at http://stlr.stanford.edu/stlr/articles/01stlr1/index.htm); robert gellman, ﬁdoes privacy law work?,ﬂ in p. agre and m. rotenberg, eds., technology and privacy: the new landscape, mit press, cambridge, mass., 1997; and r. clarke, ﬁbeyond the oecd guidelines,ﬂ xamax consultancy pty ltd., 2000.38 the special and highly contested case of telecommunications policy, in which customer proprietary network information (cpni) could be released only with explicit consumer permission, is one such example. the federal communications commission (fcc) issued an order interpreting the ﬁapprovalﬂ requirements in february 1998 (available at http://www.fcc.gov/bureaus/commoncarrier/orders/1998/fcc98027.txt). under the fcc™s rule, telephone companies must give customers explicit notice of their right to control the use of their cpni and obtain express written, oral, or electronic approval for its use. the rule was unsuccessfully challenged by a potential competitor, u.s. west, 182 f.3d 1223 (10th cir. 1999).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 792.3 sociological approachessociological approaches to the study of privacy have emphasized the ways in which the collection and use of personal information may re˚ect and reinforce the relationships of power and in˚uence between individuals, groups, and institutions within society. this emphasis on power relationships is an important factor characterizing the behavior of institutional actors in modern societies.39 there are also important distinctions to be drawn with the work of those scholars who focus on structural or institutional relationships and those who focus on the cognitive, affective, behavioral, and social process responses of individuals.surveillance from this perspective is generally understood to refer to the systematic observation of individuals undertaken in an effort to facilitate their management and control. some scholars concerned with surveillance emphasize the ways in which surveillance technology has changed over time, while others focus on the ways in which old and new surveillance techniques are used in the exercise of control over individuals in their roles as employees, consumers, and citizens. still others emphasize the ways in which the use of surveillance techniques becomes a commonplace activity within more and more varied organizational and institutional contexts. still others focus on interpersonal uses among families, friends, and strangers and the role of the mass media.40an important but distinct body of work within this scholarly tradition is one that focuses on a variety of surveillance techniques used by 39 within sociology there are different perspectives on surveillance. more technologically oriented observers might prefer to talk about the ﬁcaptureﬂ of transactiongenerated information (see, for example, philip e. agre, ﬁsurveillance and capture: two models of privacy,ﬂ the information society 10(2):101127, 1995). on the other hand, david lyon (in surveillance society: monitoring everyday life, open university press, 2001) argues that ﬁrather late in the day sociology started to recognize surveillance as a central dimension of modernity, an institution in its own right, not reducible to capitalism, the nationstate, or even bureaucracy.ﬂ gary t. marx (ﬁseeing hazily, but not darkly, through the lens: some recent empirical studies of surveillance technologies,ﬂ law and social inquiry 30(2):339399, 2005) notes limitations on an exclusive focus on power and control as the dening elements. there are also goals involving protection, documentation, planning, strategy, and pleasure (e.g., as entertainment and to satisfy curiosity).40 one surprisingly relatively unstudied and unregulated type here that arouses strong social concern is the voyeur secretly gathering data. see, for example, c. calvert, voyeur nation: media, privacy and peering in modern culture, westview, boulder, colo., 2000; and a ﬁtrue ctionﬂ case in which the protagonist tom voire engages in, or is the victim of, more than 100 kinds of questionable personal information practices, as described in gary t. marx, ﬁforget big brother and big corporation: what about the personal uses of surveillance technology as seen in cases such as tom i. voire?ﬂ rutgers journal of law & urban policy 3(4):219286, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.80 engaging privacy and information technology in a digital agethe police and security forces.41 however, debates continue among scholars of surveillance who contest evidence and claims about the extent to which there is a meaningful possibility of limiting, resisting, or reversing the trend toward more complete social control and domination through surveillance.another important distinction within sociology is a focus on the macro level of grand theory examining the structural or institutional relationships versus a focus on the cognitive, affective, and behavioral responses of individuals who are subject to surveillance. this latter approach makes it easier to test theories empirically. among those taking a macrolevel approach, david lyon also brings a long historical view to his assessment of the role of surveillance in society. he integrates a number of insights from an evolving cultural studies tradition to study that which is referred to as the postmodern condition. he provides examples to illustrate the ways in which ﬁdataveillance,ﬂ or the analysis of transactiongenerated data, reduces the need for access to a physical or material body in order to gather information and intelligence about the past, present, or future behavior of data subjects.42priscilla m. regan has proposed framing privacy as a collective concern rather than as an individualistic one.43 she gives three reasons for arguing that privacy has value not only to individuals but also to society in general. first, she believes that all individuals value some degree of privacy and have some common perceptions about privacy. second, she notes that privacy is a value that supports democratic political systems. third, she asserts that technology and market forces make it hard for any one person to have privacy without all persons having a similar minimum level of privacy. she also conceptualizes personal information as a resource that is available to multiple parties, is difcult to prevent others from using, and is subject to degradation as a result of overuse. thus, she argues, personal information as a resource is subject to some of the same kinds of excessiveuse pressures as are resources such as clean air and edible ocean sh. privacy can be framed as preventing the overuse of personal information, and thus she argues that public policies to support privacy would have much in common with policies that address the issue of commonpool resources such as air and sh.scholars working from within a marxist or neomarxist tradition 41 richard ericson and kevin haggerty, policing the risk society, university of toronto press, 1997; and gary t. marx, undercover: police surveillance in america, university of california press, 1988.42 lyon, surveillance society, 2001. 43 p.m. regan, ﬁprivacy as a common good in the digital world,ﬂ information, communication and society 5(3, september 1):382405, 2002. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 81engage the development of surveillance techniques as a response of capitalists to continuing crises of over and underproduction. as the logic of capital is extended to more and more activities, surveillance facilitates coordination and control.44 anthony giddens, who extends the analyses of surveillance, combines the grand theories begun by michel foucault and max weber with empirical data in an effort to cross these distinctions.45 scholars in˚uenced by giddens have focused on surveillance as an aspect of rationalization within government46 and corporate bureaucracies.47in terms of understanding how individuals perceive surveillance processes, irwin altman™s work re˚ects a psychological emphasis and contributes not only concepts and measures of desired and realized levels of privacy, but also behavioral insights that are useful in cataloging the resources available to individuals that allow them to exercise more or less control over the boundaries between themselves and others.48finally, and in addition to his identication and assessment of important trends, critical events, and important distinctions between segments of the population (section 2.1.2), westin™s analyses have provided insights into the ways in which privacy policies emerge in response to public concerns. but critics have suggested that for a number of reasons, including the in˚uence of corporate sponsors and a concern with assessing the public™s response to the issue of the day, westin™s empiricism has stretched its theoretical foundations beyond its useful limits.49the work within sociology on surveillance (and, by extension, its relationship to privacy) considers the effect of surveillance on individuals and society. these effects can occur even in the absence of actual surveillance if the individuals believe that they are being observedšthese are intangible effects in the sense that they affect individuals™ states of mind, but are no less real. this feeds into the worries about the impact of tech44 frank webster and kevin robins, information technology: a luddite analysis, ablex, 1986.45 see, for example, anthony giddens, the nation state and violence: volume two of a contemporary critique of historical materialism, polity press, cambridge, mass., 1985. this work integrates an understanding of bureaucracy from max weber (see reinhard bendix, max weber, an intellectual portrait, doubleday, 1960) and panoptic surveillance from michel foucault (discipline and punish: the birth of the prison, vintage books, 1979).46 christopher dandeker, surveillance power and modernity, polity press, cambridge, mass., 1990.47 oscar h. gandy, jr., the panoptic sort: a political economy of personal information, westview, 1993.48 stephen t. margulis, ﬁon the status and contribution of westin™s and altman™s theories of privacy,ﬂ journal of social issues 59(2):411429, 2003.49 oscar h. gandy, jr., ﬁthe role of theory in the policy process: a response to professor westin,ﬂ pp. 99106 in charles firestone and jorge reina schement, eds., towards an information bill of rights and responsibilities, the aspen institute, 1995.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.82 engaging privacy and information technology in a digital agenology advances, since many of those advances enable the observation of an individual without the knowledge of the person being observed. even if these beliefs are groundless, they can change the behavior of the individual. sociological studies attempt to understand these effects.sociological perspectives on privacy also examine the consequences that ˚ow from the lack of privacy. for example, although one could dene privacy as ﬁthat which can be lost under excessive surveillance,ﬂ sociological analyses would highlight the point that under excessive surveillance far more is lost than just privacy. human dignity, equal opportunity, social justice, and equality for groups with historical disadvantagesšamong other valuesšcan suffer as a result of excessive and inappropriate surveillance. on the other hand and somewhat ironically, surveillance may also be a factor in documenting wrongs. (for example, a tape from a video surveillance may inadvertently capture an incident of police misconduct.) to approach the topic using only the language of privacy is to miss some of the pressing social, ethical, and political issues raised by contemporary surveillance. alternatively, one might formulate issues of human dignity, equal opportunity, social justice, and racial parity as being some of the areas in which societal or group harms may result from a loss of (individual) privacy.it is helpful to consider some of the distinctions between personal identity and externally constructed identication.50 for example, david phillips accepts the critical distinction between identity and identication,51 noting the differences in agency that usually locate within bureaucratic organizations the power to impose identication on someone. furthermore, phillips claries the distinctions between nominal, indexical, and descriptive forms of identication:ł nominal identication refers to the names people have been given. such names often do not provide unique identication in that more than one person can have the same name. additional data can reduce the number of persons to whom these data apply. biometric data are assumed to reduce the range of associations rather dramatically.ł indexical identication associates information about place and time in order to enable a particular person to be ﬁidentiedﬂ in some way.ł descriptive identication refers to the ways in which identication can be based on an association of attributes, behaviors, and locations with other markers.50 oscar h. gandy, jr., ﬁexploring identity and identication in cyberspace,ﬂ notre dame journal of law, ethics and public policy 14(2):10851111, 2000.51 david j. phillips, ﬁprivacy policy and pets: the in˚uence of policy regimes on the development and social implications of privacy enhancing technologies,ﬂ new media & society 6(6):691706, 2004.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 83descriptive identication plays an important role in the identication of groups, and such identication can enable and justify discriminatory actions that reduce the space for autonomous action that people might otherwise enjoy. such issues are often discussed under the heading of group privacy.group privacy is not a new concept,52 although most of the attention that has been paid to the concept in the past has been focused on the freedom of association. privacy scholars have begun to argue that group privacy should also be understood as a right of selfdetermination that is increasingly limited by the use of transactiongenerated information to dene group membership on the basis of behavioral rather than biological attributes. developments in genetic research may or may not establish linkages between biology and behavior, but the emerging concern with behavioral identication is different.the reason is that behavioral identication or characterization of groups can be done covertly. persons who are members of groups dened on the basis of biological markers (age, race, gender) have some opportunity to mobilize and petition for rights on the basis of a common identity. persons who are members of groups that have been identied and dened on the basis of statistical analyses are less likely to be aware of the identities of others in their group, even if they manage to discover the nature of their own classication. these ascriptive groups often have names that are used only by the organizations that produce them.53because the existence of such groups is rarely made public, and little effort is made to inform group members of their status, they are less likely to organize politically to press for their rights. to the extent that members of social groups that have traditionally been victims of discrimination are also members of statistically derived groups of ﬁdisfavored others,ﬂ it seems likely that their social position will re˚ect the impact of cumulative disadvantage.54an important cluster of concerns is inherent in an informationbased ability to discriminate against persons as individuals or as members of groups in the name of increasing efciency and economic competitiveness 52 edward j. bloustein, individual and group privacy, transaction publications, 1978. also relevant is s. alpert, ﬁprotecting medical privacy: challenges in the age of genetic information,ﬂ journal of social issues 59(2):301322, 2003.53 the names for communities produced by users of geodemographic targeting techniques may be interpreted by the general public, but those names are rarely made public because people so identied are often angered when they learn of their identication. examples might be a group characterized as ﬁshotgun and pickupsﬂ or ﬁvolvodriving gucci lovers.ﬂ54 the concept of cumulative disadvantage is examined in considerable detail in r.m. blank, m. dabady, and c.f. citro, eds., measuring racial discrimination, the national academies press, washington, d.c., 2004.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.84 engaging privacy and information technology in a digital ageor meeting other socially desirable goals.55 the ability to discriminate has the potential to reinforce differences in power and privilege within social systems. discrimination is an exercise in social sorting, and such sorting relies heavily on personal information. sorting occurs for all kinds of reasonsšsome benign and some insidiousšbut social sorting can mean that individuals in some categories will face more limitations on their opportunities to choose than will individuals in other categories. on the other hand, the protection of privacy means that some personal information will not be available for such sorting.as a matter of national policy, it is illegal to make certain decisions (e.g., on employment, housing) on the basis of categorical distinctions regarding race, gender, religion, and certain aspects of lifestyle. at the same time, many believe that attention to these very factors is appropriate as a tool to overcome historic and persistent disadvantage. but the con˚icts are clear, and the sociological and cultural challenge is thus to determine what kinds of information about persons are and are not appropriate to use and under what conditions. new contested means of classication and identication are likely to continually appear and to be challenged as values con˚ict. there is no simple answer to such questions, but discussion of and openness with respect to the factors used in social sorting for public policy purposes are of the utmost importance.2.4 an integrating perspectivethe discussion above of philosophical, economic, and sociological perspectives on privacy indicates that understanding privacy in the information age requires consideration of a variety of approaches, methods, and ideas. taken as a whole, the privacy literature is a cacophony, suggesting that trying to dene privacy in the abstract is not likely to be a fruitful exercise. indeed, a number of varied and sometimes incommensurate perspectives on privacy were re˚ected in the committee. but the committee also found common ground on several points among its members, witnesses, and in the literature.the rst point is that privacy touches a very broad set of social concerns related to the control of, access to, and uses of informationšthis report emphasizes privacy as access to and control over information about individuals. an interesting question is whether privacy is a concept relevant to information about groups of people, although of course for many 55 see, for example, frederick schauer, proles, probabilities, and stereotypes, harvard university press, cambridge, mass., 2003, and bernard e. harcourt, ﬁrethinking racial proling: a critique of the economics, civil liberties, and constitutional literature, and of criminal proling more generally,ﬂ university of chicago law review 71(fall):12751381, 2004. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 85purposes a group can be treated as an individual (e.g., corporations are given the legal right to make contracts and to sue and be sued as legal persons).second, to the extent that privacy is a ﬁgood thing to have,ﬂ it sometimes con˚icts with other good things to have. thus, needs for privacy must sometimes be balanced with other considerationsšcomplaints of some privacy advocates or privacy foes about excessive or inappropriate balancing notwithstanding. how this balance is to be achieved is often the center of the controversy around privacy. complicating the effort to nd the appropriate balance is the tendency to confuse the needs of privacy with other values that might be tied to privacy but are, in fact, distinct from it and the differential impact of policies on various social groups and over time. for example, the privacy of personal health information is often related to concerns about discriminatory access to heath care; this point is discussed further in box 7.1 in chapter 7.third, privacy in context is much more understandable than privacy in the abstract. as the literature illustrates, agreement on a broad analytical denition of privacy in the abstract is difcult if not impossible. but discussions of the privacy implications of specic events and practices are easier to understand and discuss. one approach to grounding a discussion of privacy in context is the use of anchoring vignettes (box 2.2). the anchoring vignette technique can be useful for understanding the impact of any given technology on privacy by posing a set of grounded, scenariospecic questions that can be answered with and without the presence of that technology. it can also be helpful for understanding public perceptions of privacy in various contexts. in this report, the technique is used in multiple ways to illustrate and to help unpack intuitions about privacy in different contexts.knowing a context for privacy discussions does not result in an overarching theoretical denition of privacy. nor does it represent an agreement about the level of privacy that is appropriate in any given situation. however, knowing the relevant dimensions of privacy and what ﬁmoreﬂ or ﬁlessﬂ privacy might mean in the specic context of each dimension does clarify the discussion, and the anchoring vignette technique is one useful approach to obtain such knowledge.the contextsensitive nature of privacy makes it clear that questions about privacy necessarily imply specifying privacy ﬁfrom whom,ﬂ ﬁabout what,ﬂ ﬁfor what reasons,ﬂ and ﬁunder what conditions.ﬂ for example, a set of possible privacy violators might include one™s employer; family; friends, acquaintances, and neighbors; researchers; businesses; and government. associated with each of these potential violators is an ﬁabout whatﬂša (different) set of information types that might arise with any given possible privacy violator. for example, in the context of an employer engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.86 engaging privacy and information technology in a digital agebox 2.2 the anchoring vignette approach to grounding discussions of privacy developed by committee member gary king and others, an anchoring vignette is a brief description of a specic situation involving personal information.1 organized into related sets in which a range of privacy considerations are manifest, the vignettes help to collect, articulate, and organize intuitions about privacy in a more precise and empirical fashion; clarify assumptions about privacy; empirically document views on privacy; and serve as a good tool for illustrating, expressing, and communicating existing concepts of privacy. vignettes have been extensively used for conducting actual surveys and in helping develop actual survey instruments, but in the context of this report they help to dene the concepts so that all participants in a privacy discussion have the same frame of reference. although they are not intended to suggest a particular policy to adopt, anchoring vignettes help to provide a lingua franca for privacy and so they may be of use to citizens in attaining a better understanding of public policy regarding privacy. the vignettes form a continuum along which various policy scenarios can be placed and in that sense can help to frame questions that might be asked about any given policy. to illustrate, consider the issue of privacy with respect to criminal charges. a set of useful vignettes might be as follows: 1. [jonathan] was arrested on charges of assault and battery last year. he lives in a county that stores records of criminal charges at the police headquarters, where there is no public access. 2. [monali] was arrested on charges of assault and battery last year. she lives in a county that maintains all records of criminal charges for public inspection at the county courthouse. 3. [david] was arrested on charges of assault and battery last year. he lives in a county that maintains all records of criminal charges at the county courthouse for public inspection and in an electronic database, to which any police ofcer or county ofcial has access. 4. [andrea] was arrested on charges of assault and battery last year. she lives in a county that posts all criminal charges on the internet. the web page includes pictures and detailed proles of all arrested. our intuitions about privacy in each of these situations re˚ect our answers to questions such as, how much privacy does the individual have in this situation?, does david have more privacy than andrea?, and so on. we can also ask how much privacy the individual should be granted in the situation. one way to think about these vignettes is to imagine being asked a survey question about each vignette or even about yourself: how much privacy [does ﬁnameﬂ/do you] have? (a) unlimited, (b) a lot, (c) moderate, (d) some, (e) none? the imagined survey context helps to make the examples concrete and claries how they are to be read. although such vignettes are often used for survey research, dening privacy from the bottom up does not involve administering a survey or necessarily asking these questions of others. for each set of anchoring vignettes (denoting privacy in one specic context), different people will have different views about what thresholds delineate levels of privacy below which violations should be considered undesirable, unethical, illegal, or immoral. agreement on normative issues like these will always be difcult to achieve. the anchoring vignettebased approach to privacy thus does not resolve all normative issues, but it helps to clearly dene the playing eld. note also that vignettes can be modied to illustrate different scenarios. for example, the above scenario can be modied by substituting ﬁconvictedﬂ for ﬁarrested on chargesﬂ and ﬁconvictionsﬂ for ﬁcharges.ﬂ it is likely that such changes might cause at least some people to reevaluate their answers.as a possible privacy violator, one might be concerned about surveillance of work or about drug testing. by contrast, in the context of friends, acquaintances, and neighbors as possible privacy violators, one might be concerned about personal secrets, nudity, sex, medical information, and invasiveness.56the kinds of social roles and relationships involved are as central as 56 in thinking through who might be a possible privacy violator, it also helps to consider parties with whom one might be willing to share information. although in some sense, one is the complement of the other, in practice the complement is more likely to be fuzzy, with zones of more gray and less gray rather than sharp boundaries between black and white.1gary king, christopher j.l. murray, joshua a. salomon, and ajay tandon, ﬁenhancing the validity and crosscultural comparability of survey research,ﬂ american political science review 98(1):191207, 2004, available at http://gking.harvard.edu/les/abs/vignabs.shtml. see also gary king and jonathan wand, ﬁcomparing incomparable survey responses: new tools for anchoring vignettes,ﬂ political analysis, forthcoming, 2007, available at http://gking.harvard.edu/les/abs/cabs.shtml. extensive examples and other information can be found at the anchoring vignettes web site, at http://gking.harvard.edu/vign/. the committee thanks dan ho and matthew knowles, who assisted in the development of material on anchoring vignettes presented to the committee during its open datagathering sessions.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.intellectual approaches and conceptual underpinnings 87box 2.2 the anchoring vignette approach to grounding discussions of privacy developed by committee member gary king and others, an anchoring vignette is a brief description of a specic situation involving personal information.1 organized into related sets in which a range of privacy considerations are manifest, the vignettes help to collect, articulate, and organize intuitions about privacy in a more precise and empirical fashion; clarify assumptions about privacy; empirically document views on privacy; and serve as a good tool for illustrating, expressing, and communicating existing concepts of privacy. vignettes have been extensively used for conducting actual surveys and in helping develop actual survey instruments, but in the context of this report they help to dene the concepts so that all participants in a privacy discussion have the same frame of reference. although they are not intended to suggest a particular policy to adopt, anchoring vignettes help to provide a lingua franca for privacy and so they may be of use to citizens in attaining a better understanding of public policy regarding privacy. the vignettes form a continuum along which various policy scenarios can be placed and in that sense can help to frame questions that might be asked about any given policy. to illustrate, consider the issue of privacy with respect to criminal charges. a set of useful vignettes might be as follows: 1. [jonathan] was arrested on charges of assault and battery last year. he lives in a county that stores records of criminal charges at the police headquarters, where there is no public access. 2. [monali] was arrested on charges of assault and battery last year. she lives in a county that maintains all records of criminal charges for public inspection at the county courthouse. 3. [david] was arrested on charges of assault and battery last year. he lives in a county that maintains all records of criminal charges at the county courthouse for public inspection and in an electronic database, to which any police ofcer or county ofcial has access. 4. [andrea] was arrested on charges of assault and battery last year. she lives in a county that posts all criminal charges on the internet. the web page includes pictures and detailed proles of all arrested. our intuitions about privacy in each of these situations re˚ect our answers to questions such as, how much privacy does the individual have in this situation?, does david have more privacy than andrea?, and so on. we can also ask how much privacy the individual should be granted in the situation. one way to think about these vignettes is to imagine being asked a survey question about each vignette or even about yourself: how much privacy [does ﬁnameﬂ/do you] have? (a) unlimited, (b) a lot, (c) moderate, (d) some, (e) none? the imagined survey context helps to make the examples concrete and claries how they are to be read. although such vignettes are often used for survey research, dening privacy from the bottom up does not involve administering a survey or necessarily asking these questions of others. for each set of anchoring vignettes (denoting privacy in one specic context), different people will have different views about what thresholds delineate levels of privacy below which violations should be considered undesirable, unethical, illegal, or immoral. agreement on normative issues like these will always be difcult to achieve. the anchoring vignettebased approach to privacy thus does not resolve all normative issues, but it helps to clearly dene the playing eld. note also that vignettes can be modied to illustrate different scenarios. for example, the above scenario can be modied by substituting ﬁconvictedﬂ for ﬁarrested on chargesﬂ and ﬁconvictionsﬂ for ﬁcharges.ﬂ it is likely that such changes might cause at least some people to reevaluate their answers.the goals, location, type of technology, and data involved, and the conditions under which personal information is collected and used. indeed, what constitutes privacy, what information should be private, and what individuals or institutions are posing potential threats to that privacy are all questions subject to considerable debate. a related set of questions involves the circumstances under which privacy can be seen to go too far. under some conditions the failure to discover or reveal personal information can be harmful socially (e.g., in the case of potential for exposure to deadly contagious diseases or a person with a history of violent and abusive behavior).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.883technological driversprivacy is an information concept, and fundamental properties of information dene what privacy canšand cannotšbe. for example, information has the property that it is inherently reproducible: if i share some information with you, we both have all of that information. this stands in sharp contrast to apples: if i share an apple with you, we each get half an apple, not a whole apple. if information were not reproducible in this manner, many privacy concerns would simply disappear.3.1 the impact of technology on privacyadvances in technology have often led to concerns about the impact of those advances on privacy. as noted in chapter 1, the classic characterization of privacy as the right to be left alone was penned by louis brandeis in his article discussing the effects on privacy of the thennew technology of photography. the development of new information technologies, whether they have to do with photography, telephony, or computers, has almost always raised questions about how privacy can be maintained in the face of the new technology. today™s advances in computing technology can be seen as no more than a recurrence of this trend, or can be seen as different in that new technology, being fundamentally concerned with the gathering and manipulation of information, increases the potential for threats to privacy.several trends in the technology have led to concerns about privacy. one such trend has to do with hardware that increases the amount of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 89information that can be gathered and stored and the speed with which that information can be analyzed, thus changing the economics of what it is possible to do with information technology. a second trend concerns the increasing connectedness of this hardware over networks, which magnies the increases in the capabilities of the individual pieces of hardware that the network connects. a third trend has to do with advances in software that allow sophisticated mechanisms for the extraction of information from the data that are stored, either locally or on the network. a fourth trend, enabled by the other three, is the establishment of organizations and companies that offer as a resource information that they have gathered themselves or that has been aggregated from other sources but organized and analyzed by the company.improvements in the technologies have been dramatic, but the systems that have been built by combining those technologies have often yielded overall improvements that sometimes appear to be greater than the sum of the constituent parts. these improvements have in some cases changed what it is possible to do with the technologies or what it is economically feasible to do; in other cases they have made what was once difcult into something that is so easy that anyone can perform the action at any time.the end result is that there are now capabilities for gathering, aggregating, analyzing, and sharing information about and related to individuals (and groups of individuals) that were undreamed of 10 years ago. for example, global positioning system (gps) locators attached to trucks can provide nearrealtime information on their whereabouts and even their speed, giving truck shipping companies the opportunity to monitor the behavior of their drivers. cell phones equipped to provide e911 service can be used to map to a high degree of accuracy the location of the individuals carrying them, and a number of wireless service providers are marketing cell phones so equipped to parents who wish to keep track of where their children are.these trends are manifest in the increasing number of ways people use information technology, both for the conduct of everyday life and in special situations. the personal computer, for example, has evolved from a replacement for a typewriter to an entry point to a network of global scope. as a network device, the personal computer has become a major agent for personal interaction (via email, instant messaging, and the like), for nancial transactions (bill paying, stock trading, and so on), for gathering information (e.g., internet searches), and for entertainment (e.g., music and games). along with these intended uses, however, the personal computer can also become a datagathering device sensing all of these activities. the use of the pc on the network can potentially generate data that can be analyzed to nd out more about users of pcs than they engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.90 engaging privacy and information technology in a digital ageanticipated or intended, including their buying habits, their reading and listening preferences, who they communicate with, and their interests and hobbies.concerns about privacy will grow as the use of computers and networks expands into new areas. if we can™t keep data private with the current use of technology, how will we maintain our current understanding of privacy when the common computing and networking infrastructure includes our voting, medical, nancial, travel, and entertainment records, our daily activities, and the bulk of our communications? as more aspects of our lives are recorded in systems for health care, nance, or electronic commerce, how are we to ensure that the information gathered is not used inappropriately to detect or deduce what we consider to be private information? how do we ensure the privacy of our thoughts and the freedom of our speech as the electronic world becomes a part of our government, central to our economy, and the mechanism by which we cast our ballots? as we become subject to surveillance in public and commercial spaces, how do we ensure that others do not track our every move? as citizens of a democracy and participants in our communities, how can we guarantee that the privacy of putatively secret ballots is assured when electronic voting systems are used?the remainder of this chapter explores some relevant technology trends, describing current and projected technological capacity and relating it to privacy concerns. it also discusses computer, network, and system architectures and their potential impacts on privacy.3.2 hardware advancesperhaps the most commonly known technology trend is the exponential growth in computing poweršloosely speaking the central processor unit in a computer will double in speed (or halve in price) every 18 months. what this trend has meant is that over the last 10 years, we have gone through about seven generations, which in turn means that the power of the central processing unit has increased by a factor of more than 100. the impact of this change on what is possible or reasonable to compute is hard to overestimate. tasks that took an hour 10 years ago now take less than a minute. tasks that now take an hour would have taken days to complete a decade ago. the end result of this increase in computing speed is that many tasks that were once too complex to be automated can now be easily tackled by commonly available machines.while the increase in computing power that is implied by this exponential growth is well known and often cited, less appreciated are the economic implications of that trend, which entail a decrease in the cost of computation by a factor of more than 100 over the past 10 years. one engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 91outcome of this is that the desktop computer used in the home today is far more powerful than the most expensive supercomputer of 10 years ago. at the same time, the cell phones commonly used today are at least as powerful as the personal computers of a decade ago. this change in the economics of computing means that there are many more computers in simple numbers than there were a decade ago, which in turn means that the amount of total computation available at a reasonable price is no longer a limiting factor in any but the most complex of computing problems.nor is it merely central processing units (cpus) that have shown dramatic improvements in performance and dramatic reductions in cost over the past 10 years. dynamic random access memory (dram), which provides the working space for computers, has also followed a course similar to that for cpu chips.1 over the past decade memory size has in some cases increased by a factor of 100 or more, which allows not only for faster computation but also for the ability to work on vastly larger data sets than was possible before.less well known in the popular mind, but in some ways more dramatic than the trend in faster processors and larger memory chips, has been the expansion of capabilities for storing electronic information. the price of longterm storage has been decreasing rapidly over the last decade, and the ability to access large amounts of such storage has been increasing. storage capacity has been increasing at a rate that has outpaced the rate of increase in computing power, with some studies showing that it has doubled on average every 12 months.2 the result of this trend is that data can be stored for long periods of time in an economical fashion. in fact, the economics of data storage has become inverted. traditionally, data was discarded as soon as possible to minimize the cost of storing that data, or at least moved from primary storage (disks) to secondary storage (tape) where it was more difcult to access. with the advances in the capacities of primary storage devices, it is now often more expensive to decide how to cull data or transfer it to secondary storage (and to spend the resources to do the culling or transferring) than it is to simply store it all on primary storage, adding new capacity when it is needed.the change in the economics of data storage has altered more than just the need to occasionally cull data. it has also changed the kind of 1 on the other hand, the speed with which the contents of ram chips can be accessed has not increased commensurately with speed increases in cpu chips, and so ram access has become relatively ﬁslower.ﬂ this fact has not yet had many privacy implications, but may in the future.2 e. grochowski and r.d. halern, ﬁtechnological impact of magnetic hard disk drives on storage systems,ﬂ ibm systems journal 42(2):338346, july 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.92 engaging privacy and information technology in a digital agedata that organizations are willing to store. when persistent storage was a scarce resource, considerable effort was expended in ensuring that the data that were gathered were compressed, ltered, or otherwise reduced before being committed to persistent storage. often the purpose for which the data had been gathered was used to enhance this compression and ltering, resulting in the storing not of the raw data that had been gathered but instead of the computed results based on that data. since the computed results were taskspecic, it was difcult or impossible to reuse the stored information for other purposes, part of the compression and ltering caused a loss of the general information such that it could not be recovered.with the increase in the capacity of longterm storage, reduction of data as they are gathered is no longer needed. and although compression is still used in many kinds of data storage, that compression is often reversible, allowing the recreation of the original data set. the ability to recreate the original data set is of great value, as it allows more sophisticated analysis of the data in the future. but it also allows the data to be analyzed for purposes other than those for which it was originally gathered, and allows the data to be aggregated with data gathered in other ways for additional analysis.additionally, forms of data that were previously considered too large to be stored for long periods of time can now easily be placed on nextgeneration storage devices. for example, highquality video streams, which can take up megabytes of storage for each second of video, were once far too large to be stored for long periods; the most that was done was to store samples of the video streams on tape. now it is possible to store large segments of realtime video footage on various forms of longterm storage, keeping recent video footage online on hard disks, and then archiving older footage on dvd storage.discarding or erasing stored information does not eliminate the possibility of compromising the privacy of the individuals whose information had been stored. a recent study has shown that a large number of disk drives available for sale on the secondary market contain easily obtainable information that was placed on the drive by the former owner. included in the information found by the study was banking account information, information about prescription drug use, and college application information.3 even when the previous owners of the disk drive had gone to some effort to erase the contents of the drive, it was in most cases fairly easy to repair the drive in such a way that the data that the drive had held 3 simson l. garnkel and abhi shelat, ﬁremembrance of data past: a study of disk sanitization practices,ﬂ ieee security and privacy 1(1):8388, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 93were easily available. in fact, one of the conclusions of the study is that it is quite hard to really remove information from a modern disk drive; even when considerable effort has been put into removing the information, sophisticated ﬁdigital forensicﬂ techniques can be used to recreate the data. from the privacy point of view, this means that once data have been gathered and committed to persistent storage, it is very difcult to ever be sure that the data have been removed or forgottenša point very relevant to the archiving of materials in a digital age.with more data, including more kinds of data, being kept in its raw form, the concern arises that every electronic transaction a person ever enters into can be kept in readily available storage, and that audio and video footage of all of the public activities for that person could also be available. this information, originally gathered for purposes of commerce, public safety, health care, or for some other reason, could then be available for uses other than those originally intended. the fear is that the temptation to use all of this information, either by a governmental agency or by private corporations or even individuals, is so great that it will be nearly impossible to guarantee the privacy of anyone from some sort of prying eye, if not now then in the future.the nal hardware trend relevant to issues of personal privacy involves datagathering devices. the evolution of these devices has moved them from the generating of analog data to the generation of data in digital form; from devices that were on specialized networks to those that are connected to larger networks; and from expensive, specialized devices that were deployed only in rare circumstances to cheap, ubiquitous devices either too small or too common to be generally noticed. biometric devices, which sense physiological characteristics of individuals, also count as datagathering devices. these sensors, from simple temperature and humidity sensors in buildings to the positioning systems in automobiles to video cameras used in public places to aid in security, continue to proliferate, showing the way to a world in which all of our physical environment is being watched and sensed by sets of eyes and other sensors. box 3.1 provides a sampling of these sensing devices.the ubiquitous connection of these sensors to the network is really a result of the transitive nature of connectivity. it is not in most cases the sensors themselves that are connected to the larger world. the standard sensor deployment has a group of sensors connected by a local (often specialized) network to a single computer. however, that computer is in turn connected to the larger network, either an intranet or the internet itself. because of this latter connection, the data generated by the sensors can be moved around the network like any other data once the computer to which the sensors are directly connected has received it.the nal trend of note in sensing devices is their nearly ubiquitous engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.94 engaging privacy and information technology in a digital ageproliferation. video cameras are now a common feature of many public places; trafc sensors have become common; and temperature and humidity sensors (which can be used as sensors to detect humans) are in many modern ofce buildings. cell phone networks gather position information for 911 calling, which could be used to track the locations of their users. many automobiles contain gps sensors, as part of either a navigation system or a driver aid system. as these devices become smaller and more pervasive, they become less noticeable, leading to the gathering of data in contexts where such gathering is neither expected nor noticed.the proliferation of explicit sensors in our public environments has been a cause for alarm. there is also the growing realization that every computer used by a person is also a datagathering device. whenever a computer is used to access information or perform a transaction, informabox 3.1 a sampling of advanced datagathering technologies ł pervasive sensors and new types of sensors (e.g., ﬁsmart dustﬂ) ł infrared/thermal detectors ł gps/location information ł cellphonegenerated information ł radiofrequency identication tags ł chips embedded in people ł medical monitoring (e.g., implanted heart sensors) ł spycams and other remote cameras ł surveillance cameras in most public places ł automated homes with temperature, humidity, and power sensors ł trafc ˚ow sensors ł camera/cellphone combinations ł toys for children that incorporate surveillance technology (such as a stuffed animal that contains a nannycam) ł biometricsbased recognition systems (e.g., based on face recognition, ngerprints, voice prints, gate analysis, iris recognition, vein patterns, hand geometry) ł devices for remote reading of monitors and keyboards ł brain wave sensors ł smell sensors however, it should also be noted that datagathering technologies need not be advanced or electronic to be signicant or important. mail or telephone surveys, marketing studies, and health care information forms, sometimes coupled with optical scanning to convert manually created data into machinereadable form, also generate enormous amounts of personal and often sensitive information.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 95tion about the use or transaction can be (and often is) gathered and stored. this means that data can be gathered about far more people in far more circumstances than was possible 10 years ago. it also means that such information can be gathered about activities that intuitively appear to occur within the connes of the home, a place that has traditionally been a center of privacyprotected activities. as more and more interactions are mediated by computers, more and more data can be gathered about more and more activities.the trend toward ubiquitous sensing devices has only begun, and it shows every sign of accelerating at an exponential rate similar to that seen in other parts of computing. new kinds of sensors, such as radiofrequency identication (rfid) tags or medical sensors allowing constant monitoring of human health, are being mandated by entities such as walmart and the department of defense. singlesensor surveillance may be replaced in the future with multiplesensor surveillance. the economic and health benets of some ubiquitous sensor deployments are signicant. but the impact that those and other deployments will have in practice on individual privacy is hard to determine.3.3 software advancesin addition to the dramatic and wellknown advances in the hardware of computing have come signicant advances in the software that runs on that hardware, especially in the area of data mining and information fusion/data integration techniques and algorithms. owing partly to the new capabilities enabled by advances in the computing platform and partly to better understanding of the algorithms and techniques needed for analysis, the ability of software to analyze the information gathered and stored on computing machinery has made great strides in the past decade. in addition new techniques in parallel and distributed computing have made it possible to couple large numbers of computers together to jointly solve problems that are beyond the scope of any single machine.although data mining is generally construed to encompass data searching, analysis, aggregation, and, for lack of a better term, archaeology, ﬁdata miningﬂ in the strict sense of the term is the extraction of information implicit in data, usually in the form of previously unknown relationships among data elements. when the data sets involved are voluminous, automated processing is essential, and today computerassisted data mining often uses machine learning, statistics, and visualization techniques to discover and present knowledge in a form that is easily comprehensible.information fusion is the process of merging/combining multiple sources of information in such a way that the resulting information is engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.96 engaging privacy and information technology in a digital agemore accurate or reliable or robust as a basis for decision making than any single source of information would be. information fusion often involves the use of statistical methods, such as bayesian techniques and random effects modeling. some information fusion approaches are implemented as articial neural networks.both data mining and information fusion have important everyday applications. for example, by using data mining to analyze the patterns of an individual™s previous credit card transactions, a bank can determine whether a credit card transaction today is likely to be fraudulent. by combining results from different medical tests using information fusion techniques, physicians can infer the presence or absence of underlying disease with higher condence than if the result of only one test were available.these techniques are also relevant to the work of government agencies. for example, the protection of public health is greatly facilitated by early warning of outbreaks of disease. such warning may be available through data mining of the highly distributed records of rstline health care providers and pharmacies selling overthecounter drugs. unusually high buying patterns of such drugs (e.g., cold remedies) in a given locale might signal the previously undetected presence and even the approximate geographic location of an emerging epidemic threat (e.g., a ˚u outbreak). responding to a public health crisis might be better facilitated with automated access to and screening analyses of patient information at clinics, hospitals, and pharmacies. research on these systems is today in its infancy, and it remains to be seen whether such systems can provide reliable warning on the time scales needed by public health ofcials to respond effectively.datamining and information fusion technologies are also relevant to counterterrorism, crisis management, and law enforcement. counterterrorism involves, among other things, the identication of terrorist operations before execution through analysis of signatures and database traces made during an operation™s planning stages. intelligence agencies also need to pull together large amounts of information to identify the perpetrators of a terrorist attack. responding to a natural disaster or terrorist attack requires the quick aggregation of large amounts of information in order to mobilize and organize rstresponders and assess damage. law enforcement must often identify perpetrators of crimes on the basis of highly fragmentary informationše.g., a suspect™s rst name, a partial license number, and vehicle color.in general, the ability to analyze large data sets can be used to discern statistical trends or to allow broadbased research in the social, economic, and biological sciences, which is a great boon to all of these elds. but the ability can also be used to facilitate target marketing, enable broadbased engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 97email advertising campaigns, or (perhaps most troubling from a privacy perspective) discern the habits of targeted individuals.the threats to privacy are more than just the enhanced ability to track an individual through a set of interactions and activities, although that by itself can be a cause for alarm. it is now possible to group people into smaller and smaller groups based on their preferences, habits, and activities. there is nothing that categorically rules out the possibility that in some cases, the size of the group can be made as small as one, thus identifying an individual based on some set of characteristics having to do with the activities of that individual.furthermore, data used for this purpose may have been gathered for other, completely different reasons. for example, cell phone companies must track the locations of cell phones on their network in order to determine the tower responsible for servicing any individual cell phone. but these data can be used to trace the location of cellphone owners over time.4 temperature and humidity sensors used to monitor the environment of a building can generate data that indicate the presence of people in particular rooms. the information accumulated in a single database for one reason can easily be used for other purposes, and the information accumulated in a variety of database can be aggregated to allow the discovery of information about an individual that would be impossible to nd out given only the information in any single one of those databases.the end result of the improvements in both the speed of computational hardware and the efciency of the software that is run on that hardware is that tasks that were unthinkable only a short time ago are now possible on lowcost, commodity hardware running commercially available software. some of these new tasks involve the extraction of information about the individual from data gathered from a variety of sources. a concern from the privacy point of view is thatšgiven the extent of the ability to aggregate, correlate, and extract new information from seemingly innocuous informationšit is now difcult to know what activities will in fact compromise the privacy of an individual.3.4 increased connectivity and ubiquitythe trends toward increasingly capable hardware and software and increased capacities of individual computers to store and analyze information are additive; the ability to store more information pairs with the increased ability to analyze that information. when combined with these 4 matt richtel, ﬁtracking of mobile phones prompts court fights on privacy,ﬂ new york times, december 10, 2005, p. a1.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.98 engaging privacy and information technology in a digital agetwo, a third technology trend, the trend toward increased connectivity in the digital world, has a multiplicative effect.the growth of network connectivityšobvious over the past decade in the world wide web™s expansion from a mechanism by which physicists could share information to a global phenomenon, used by millions to do everything from researching term papers to ordering booksšcan be traced back to the early days of local area networks and the origin of the internet: growth in the number of nodes on the internet has been exponential over a period that began roughly in 1980 and continues to this day.5 once standalone devices connected with each other through the use of ˚oppy disks or dedicated telephone lines, computers are now networked devices that are (nearly) constantly connected to each other.a computer that is connected to a network is not limited by its own processor, software, and storage capacity, and instead can potentially make use of the computational power of the other machines connected to that network and the data stored on those other computers. the additional power is characterized by metcalfe™s law, which states that the power of a network of computers increases in proportion to the number of pairwise connections that the network enables.6a result of connectivity is the ability to access information stored or gathered at a particular place without having physical access to that place. it is no longer necessary to be able to actually touch a machine to use that machine to gather information or to gain access to any information stored on the machine. controlling access to a physical resource is a familiar concept for which we have welldeveloped intuitions, institutions, and mechanisms that allow us to judge the propriety of access and to control that access. these intuitions, institutions, and mechanisms are much less well developed in the case of networked access.the increased connectivity of computing devices has also resulted in a radical decrease in the transaction costs for accessing information. this has had a signicant impact on the question of what should be considered a public record, and how those public records should be made available. much of the information gathered by governments at various levels is considered public record. traditionally, the costs (both in monetary terms and in terms of costs of time and human aggravation) to access such 5 raymond kurzweil, the singularity is near, viking press, 2005, pp. 7881.6 see b. metcalfe, ﬁmetcalfe™s law: a network becomes more valuable as it reaches more users,ﬂ infoworld, oct. 2, 1995. see also the may 6, 1996, column at http://www.infoworld.com/cgibin/displaynew.pl?/metcalfe/bm050696.html. the validity of metcalfe™s law is based on the assumption that every connection in a network is equally valuable. however, in practice it is known that in many networks, certain nodes are much more valuable than others, a point suggesting that the value may increase less rapidly in proportion to the number of possible pairwise connections.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 99public records have been high. to look at the real estate transactions for a local area, for example, required physically going to the local authority that stored those records, lling out the forms needed for access, and then viewing the records at the courthouse, tax ofce, or other government ofce. when these records are made available through the world wide web, the transaction costs of accessing those records are effectively zero, making it far easier for the casual observer to view such records.connectivity is also relevant to privacy on a scale smaller than that of the entire internet. corporate and government intranets allow the connection and sharing of information between the computers of a particular organization. the purpose of such intranets is often for the sharing of information between various computers (as opposed to the sharing of information between the users of computers). such sharing is a rst step toward the aggregation of various data repositories, combining information collected for a variety of reasons to enable that larger (and richer) data set to be analyzed in an attempt to extract new forms of information.along with the increasing connectivity provided by networking, the networks themselves are becoming more capable as a mechanism for sharing data. bandwidth, the measure of how much data can be transferred over the network in a given time, has been increasing dramatically. new network technologies allowing some ltering and analyzing of data as it ˚ows through the network are being introduced. projects such as seti@home7 and technologies like grid computing8 are trying to nd ways of utilizing the connectivity of computers to allow even greater computational levels.from the privacy point of view, interconnectivity seems to promise a world in which any information can be accessed from anywhere at any time, along with the computational capabilities to analyze the data in any way imaginable. this interconnectivity seems to mean that it is no longer necessary to actually have data on an individual on a local computer; the data can be found somewhere on another computer that is connected to the local computer, and with the seemingly unlimited computing ability of the network of interconnected machines, nding and making use of that information is no longer a problem.ubiquitous connectivity has also given impetus to the development of digital rights management technologies (drmts), which are a response to the fact that when reduced to digital form, text, images, sounds, and other forms of content can be copied freely and perfectly. drmts harness the power of the computer and the network to enforce predened limits on 7 available at http://setiathome.ssl.berkeley.edu/.8 available at http://www.gridforum.org/.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.100 engaging privacy and information technology in a digital agethe possible distribution and use of a protected work. these predened limits can be very negrained. they can include:ł limits on the number of times that protected information is viewed or on the extent to which protected information can be altered;ł selective permissions that allow protected information to be read but not copied, printed, or passed along electronically except to selected parties;ł selective access to certain portions of protected information and denial of access to others;ł tracking of the parties that receive protected information and what they did with it (e.g., what they read, when they read it, how many times they read it, how long they spent reading it, to whom they forwarded it); andł enforcement of time windows during which certain access privileges are available.drmts are a particularly interesting technological development with a potential impact on privacy. originally developed with the intent of enhancing privacy, their primary application to date has been to protect intellectual property rights. but some applications of drmts can also detract from privacy. for example, drmts offer the potential for institutional content owners to collect highly detailed information on user behavior regarding the texts they read and the music they listen to, a point discussed further in section 6.7. and in some instances, they have the potential to create security vulnerabilities in the systems on which they run, exploitation of which might lead to security breaches and the consequent compromise of personal information stored on those systems.9on the other hand, drmts canšin principlešbe used by private individuals to exert greater control over the content that they create. an individual could set permissions on his or her digital document so that only certain other individuals could read it, or could make a copy of it, and so on. although, this capability is not widely available today for individuals to use, some document management systems are beginning to incorporate some such features.9 an example is the recent sony drm episode, during which sony™s bmg music entertainment surreptitiously distributed software on audio compact disks that was automatically installed on any computer that played the cd. this software was intended to block the copying of the cd, but it had the unintentional side effect of opening security vulnerabilities that could be exploited by other malicious software such as worms or viruses.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 1013.5 technologies combined into a datagathering systemeach of the technology trends discussed above can be seen individually as having the potential to threaten the privacy of the individual. combined into an overall system, however, such technologies seem to pose a far greater threat to privacy. the existence of ubiquitous sensors, generating digital data and networked to computers, raises the prospect of data generated for much of what individuals do in the physical world. increased use of networked computers, which are themselves a form of activity sensor, allows the possibility of a similar tracking of activities in the electronic world. and increased and inexpensive data storage capabilities support retention of data by default.once stored, data are potentially available for analysis by any computer connected via a network to that storage. networked computers can share any information that they have, and can aggregate information held by them separately. thus it is possible not only to see all of the information gathered about an individual, but also to aggregate the information gathered in various places on the network into a larger view of the activities of that individual. such correlations create yet more data on an individual that can be stored in the overall system, shared with others on the network, and correlated with the sensor data that are being received.finally, the seemingly unlimited computing power promised by networked computers would appear to allow any kind of analysis of the data concerning the individual to be done thoroughly and quickly. patterns of behavior, correlations between actions taken in the electronic and the physical world, and correlations between data gathered about one individual and that gathered about another are capable, in principle, of being found, reported, and used to create further data about the individual being examined. even if such analysis is impractical today, the data will continue to be stored, and advances in hardware and software technology may appear that allow the analysis to be done in the future.at the very least, these technology trendsšin computation, sensors, storage technology, and networkingšchange the rules that have governed surveillance. it is the integration of both hard and soft technologies of surveillance and analysis into networks and systems that underlies the evolution of what might be called traditional surveillance to the ﬁnewﬂ surveillance.10 compared to traditional surveillance, the new surveillance is less visible and more continuous in time and space, provides fewer 10 the term originates with gary marx, ﬁwhat™s new about the ‚new™ surveillance?,ﬂ surveillance & society 1(1):929, 2005; and gary marx, ﬁsoft surveillance: the growth of mandatory volunteerism in collecting personal information,ﬂ in t. monahan, surveillance and security: technological politics and power in everyday life, routledge, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.102 engaging privacy and information technology in a digital ageopportunities for targets to object to or prevent the surveillance, is greater in analytical power, produces data that are more enduring, is disseminated faster and more widely, and is less expensive. (table 3.1 presents some examples.) essentially all of these changes represent additional surveillance capabilities for lower cost, and exploitation of these changes would bode ill for the protection of privacy.3.6 data search companiesall of the advances in information technology for data aggregation and analysis have led to the emergence of companies that take the raw technology discussed above and combine it into systems that allow them to offer directly to their customers a capability for access to vast amounts of information. search engine services, such as those provided by google, yahoo!, and msn, harness the capabilities of thousands of computers, joined together in a network, that when combined give huge amounts of storage and vast computational facilities. such companies have linked these machines with a software infrastructure that allows the nding and indexing of material on the world wide web.the end result is a service that is used by millions every day. rather than requiring that a person know the location of information on the world wide web (via, for example, a uniform resource locator (url), such as www.cstb.org), a search engines enables the user to nd that information by describing it, typically by typing a few keywords that might be associated with that information. using sophisticated algorithms that are the intellectual property of the company, links to locations where that information can be found are returned. this functionality, undreamed of a decade ago, has revolutionized the way that the world wide web is used. further, these searches can often be conducted for free, as many search companies make money by selling advertising that is displayed along with the search results to the users of the service.while it is hard to imagine using the web without search services, their availability has brought up privacy concerns. using a search engine to assemble information about an individual has become common practice (so common that the term ﬁto googleﬂ has entered the language). when the web newspaper, cnet.com, published personal information about the president of google that had been obtained by using the google service, google charged cnet with publishing private information and announced that it would not publicly speak to cnet for a year in retribution.11 this 11 carolyn said, ﬁgoogle says cnet went too far in googling,ﬂ san francisco gate, august 9, 2005, available at http://sfgate.com/cgibin/article.cgi?le=/c/a/2005/08/09/google.tmp&type=business.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 103table 3.1 the evolution of surveillance over timedimensiontraditional surveillancethe new surveillancerelation to sensesunaided sensesextends sensesvisibility of the actual data collection, who does it, where, and on whose behalfvisible reduced visibility, or invisibleconsentlower proportion involuntaryhigher proportion involuntarycostexpensive per unit of datainexpensive per unit of datalocation of data collectors and analyzeron sceneremoteethosharder (more coercive)softer (less coercive)integrationdata collection as separate activitydata collection folded into routine activitydata collectorhuman, animalmachine (wholly or partly automated)where data residewith the collector, stays localwith third parties, often migratestiming of data collectionsingle point or intermittentcontinuous (omnipresent)time period of collectionpresentpast, present, futureavailability of data frequent time lagsrealtime availabilityavailability of data collection technologydisproportionately available to elitesmore democratized, some forms widely availableobject of data collectionindividualindividual, categories of interestcomprehensivenesssingle measuremultiple measurescontextcontextualacontextualdepthless intensivemore intensivebreadthless extensivemore extensiveratio of knowledge of observed to observerhigher (what the surveillant knows the subject probably knows as well)lower (surveillant knows things that the subject doesn™t)identifiability of object of surveillanceemphasis on known individualsemphasis also on anonymous individuals, individual massesrealismdirect representationdirect and simulationformsingle medium (likely narrative or numerical)multiple media (including video and/or audio)who collects data?specialistsspecialists, role dispersal, selfmonitoringanalysis of data more difficult to organize, store, retrieve, analyzeeasier to store, retrieve, analyzeease of merging data discrete noncombinableeasy to combinecommunication of data more difficult to send, receiveeasier to send, receivesource: g.t. marx, ﬁwhat™s new about the new surveillance?,ﬂ surveillance & society 1(1):929, 2002, available at www.surveillanceandsociety.org/articles1/whatsnew.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.104 engaging privacy and information technology in a digital ageis an interesting case, because the information that was obtained was accessible through the web to anyone, but would have been difcult to nd without the services offered by google. whereas in this case privacy could perhaps have been maintained because of the difculty of simply nding the available information, the google service made it easy to nd the information, and made it available for free.a second privacy concern arises regarding the information that search engine companies collect and store about specic searches performed by users. to service a user™s search request, the specic search terms need not be kept for longer than it takes to return the results of that search. but search engine companies keep that information anyway for a variety of purposes, including marketing and enhancement of search services provided to users.the potential for privacyinvasive uses of such information was brought into full public view in a request in early 2006 by the department of justice (doj) for search data from four search engines, including search terms queried and web site addresses, or urls, stored in each search engine™s index but excluding any user identifying information that could link a search string back to an individual. the intended doj use of the data was not to investigate a particular crime but to study the prevalence of pornographic material on the web and to evaluate the effectiveness of software lters to block those materials in a case testing the constitutionality of the child online protection act (copa).12the four search engines were those associated with america online, microsoft, yahoo!, and google. the rst three of these companies each agreed to provide at least some of the requested search data. google resisted the original subpoena demanding this information; subsequently, the information sought was narrowed signicantly in volume and character, and google was ultimately ordered by a u.s. district court to provide a much more restricted set of data.13 although the data requested did not include personally identiable information of users, this case has raised a number of privacy concerns about possible disclosures in the future of the increasing volumes of usergenerated search information.google objected to the original request for a variety of reasons. google asserted a general interest in protecting its users™ privacy and 12 attorney for alberto r. gonzales, mcelvain declaration in gonzales v. google, inc. (subpoena request), available at http://i.i.com.com/cnwk.1d/pdf/ne/2006/googledoj/notice.of.stark.declaration.pdf.13 antone gonsalves, ﬁjudge hands google mixed ruling on search privacy,ﬂ internet week, march 17, 2006, available at http://internetweek.cmp.com/showarticle.jhtml?articleid=183700724. the ndings based on the search data were to serve as part of the government™s case in defending the constitutionality of the child online protection act, a law aimed at protecting minors from adult material online.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 105anonymity.14 additionally, google believed the original request was overly broad, as it included all search queries entered into the search engine during a 2month period and all urls in google™s index. in negotiations with the doj, the data request was reduced to a sampling of 50,000 urls and 5,000 search terms by the doj.15in considering only the doj™s modied request, the court decided to further limit the type of data that was released to include only urls and not search terms. several of the privacy implications considered in this ruling included the recognition that personally identifying information, although not requested, might be available in the text of searches performed (e.g., such as searching to see if personal information is on the internet, such as social security numbers or credit card information, or to check what information is associated with one™s own name, socalled vanity searches). the court also acknowledged the possibility of the information being shared with other government authorities if text strings raised national security issues (e.g., ﬁbomb placement white houseﬂ).16although this case was seen as a partial victory for google and for the privacy of its users, the court as well as others acknowledged that the case could have broader implications. though outside its ruling, the court could foresee the possibility of future requests to google, particularly if the narrow collection of data used in the doj™s study was challenged in the copa case.17 however, others have suggested that this case underscores the larger problem of how to protect internet user privacy, particularly as more usergenerated information is being collected and stored for unspecied periods of time, which makes it increasing vulnerable to subpoenaed requests.18many of the concerns about compromising user privacy were illustrated graphically when in august 2006, aol published on the web a list of 20 million web search inquiries made by 658,000 users over a 3month 14 declan mccullagh, ﬁgoogle to feds: back off,ﬂ cnet news.com, february 17, 2006, available at http://news.com.com/google+to+feds+back+off/2100103036041113.html ?tag=nl.15 order granting in part and denying in part motion to compel compliance with subpoena duces tecum, united states district court for the northern district of california, san jose division, court ruling no. cv 068006misc jw, p. 4, available at http://www.google.com/press/images/ruling20060317.pdf.16 united states district court for the northern district of california, san jose division, court ruling, pp. 1819.17 united states district court for the northern district of california, san jose division, court ruling, p. 15.18 thomas claburn, ﬁgoogle™s privacy win could be pyrrhic victory,ﬂ informationweek, march 22, 2006, available at http://www.informationweek.com/showarticle.jhtml;jsessionid =lmwtormpfh2b4qsndbcskh0cjumekjvn?articleid=183701628.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.106 engaging privacy and information technology in a digital ageperiod.19 aol sought to anonymize users by substituting a code number for their login names, but the list of inquiries sorted by code number shows the topics in which a person was interested over many different searches. a few days later, aol took down the 439megabyte le after many complaints were received that the le violated user privacy. aol acknowledged that the publication of the data was a violation of its own internal policies and issued a strongly worded apology. some users were subsequently identied by name.20a related kind of itenabled companyšthe data aggregation companyšis discussed further in chapter 6.3.7 biological and other sensing technologiesthe technology trends outlined thus far in this chapter are all well established, and technologies that follow these trends are deployed in actual systems. there is an additional trend, only now in its beginning stages, that promises to extend the sensing capabilities beyond those that are possible with the kinds of sensors available today. these are biological sensing technologies, including such things as biometric identication schemes and dna analysis.biometric technologies use particular biological markers to identify individuals. fingerprinting for identication is well known and well established, but interest in other forms of biometric identication is high. technologies using identifying features as varied as retinal patterns, walking gait, and facial characteristics are all under development and show various levels of promise. many of these biometric technologies differ from the more standard and currently used biometric identication schemes in two ways: rst, these technologies promise to allow the nearrealtime identication of an individual from a distance and in a way that is noninvasive and, perhaps, incapable of being detected by the subject being identied; second, some of these mechanisms facilitate automated identication that can be done solely by the computer without the aid of a human being. such identication could be done more cheaply and far more rapidly than humanmediated forms of identication.joined into a computing system like those discussed above, such identication mechanisms offer a potential for tracing all of the activities of an individual. whereas video camera surveillance now requires human watchers, automated faceidentication systems could allow the logging 19 saul hansell, ﬁaol removes search data on group of web users,ﬂ new york times, august 8, 2006.20 michael barbaro and tom zeller, jr., ﬁa face is exposed for aol searcher no. 4417749,ﬂ new york times, august 9, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 107of a person™s location, which could then be crossreferenced with other information gathered about that individual, all without the knowledge of the person being tracked. such capabilities raise the prospect of a society in which everyone can be automatically tracked at all times.in addition to these forms of biometric identication is the technology associated with the mapping and identication of human dna. the mapping of the human genome is one of the great scientic achievements of the past decade, and work is ongoing in understanding the phenotypic implications of variations at specic sites within the gnome. a full understanding of these relationships would allow use of a dna sample to obtain information not only about the individual from whom the dna was taken, but also about individuals genetically related to that individual. just what information will be revealed by our dna is currently unknown, but there is speculation that it might indicate everything from genetic predisposition to certain kinds of disease to behavioral patterns that can be expected in an individual. much of this information is now considered to be private, but if it becomes easily accessible from our own dna or from the dna of our relatives, issues will arise as to how that information should be treated or even who the subject of the information really is.3.8 privacyenhancing technologiesalthough much of the discussion above concerns advances in technology that potentially threaten privacy, technology is not inherently destructive of privacy. technology developments can help with limiting access to or control of information about people. these fall into two categories: those that can be used by the individual whose privacy is being enhanced, and those that can be used by an information collector who wishes to protect the privacy of the individuals about whom information is being collected.213.8.1 privacyenhancing technologies for use by individualsone cluster of technologies allows individuals to make basic data unavailable through the use of cryptography. data about a person is made private by encrypting that data in such a way that the data cannot be decrypted without the consent and active participation of the person who provides the decryption key; this is known as the condentiality 21 a useful reference, and one on which much in this section is based, is lorrie faith cranor, the role of privacy enhancing technologies, at&t labs research, available at http://www.cdt.org/privacy/ccp/roleoftechnology1.shtml.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.108 engaging privacy and information technology in a digital ageapplication of cryptography. despite considerable work on decryption technologies, the cost to decrypt an encrypted data set without access to the decryption keys can currently be made almost arbitrarily high in comparison to the cost of encrypting the data set.however, such technologies are not universally accepted as an appropriate approach to the problem of protecting privacy. in particular, they allow the hiding of data from everyone, including those who some feel should be able to see the data, such as law enforcement agencies or intelligencegathering branches of the government. in addition, they make it impossible for the data to be accessed in cases when the owner of the data is unable to participate. it would be impossible, for example, for emergency medical personnel to gain access to protected medical information if the subject of the records (and holder of the decryption key) were unconscious.other privacyenhancing technologies that are usable by individuals facilitate anonymization in certain contexts. for example, some anonymization technologies allow email or web surng that is anonymous to internet eavesdroppers for all practical purposes. these technologies can also exploit national boundaries to increase the difculty of breaking the anonymity they offeršidentifying information stored on a server located in country a may be difcult or impossible for authorities in country b to obtain because of differing legal standards or the lack of a political agreement between the two nations. this same technology, however, can also hide the identity of those who use the networks to threaten or libel other members of the network community. although it can facilitate privacy, anonymity can also help to defeat accountability. since law enforcement is based on the notion of individual accountability, law enforcement pressures to restrict the use of anonymizing technologies are not unexpected. antispyware technologies stem the ˚ow of personal information related to one™s computer and internet usage practices to other parties, thereby enhancing privacy.another category of privacyenhancing technologies includes those that assist users in avoiding spam email, that prevent spyware programs from being installed, or that alert individuals that they might be the subject of ﬁphishingﬂ attacks.22 antispam technologies promote the privacy of those who believe that being left alone is an element of privacy. phishalerting technologies enhance privacy by warning the individual that he 22 ﬂphishingﬂ is the act of fooling someone into providing condential information or into doing something under false pretenses. a common phishing attack is for an attacker to send an email to someone falsely claiming to be a legitimate enterprise in an attempt to trick the user into providing private information (e.g., a login name and password for his bank account) that can be used by the attacker to impersonate the victim.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 109or she may be about to divulge important personal information to a party that should not be getting it.none of the technologies above are focused on privacy per se, which relates to the protection of personal information. for example, encryption provides condentiality of stored information or information sent over a networkšany information, not just personal information. anonymizing technologies protect only a subset of personal informationšpersonal information that can be used to identify an individual.3.8.2 privacyenhancing technologies for use by information collectorsprivacyenhancing tools that can be used by information collectors include anonymization techniques that can help to protect privacy in certain applications of data mining.3.8.2.1 query controlteresa lunt has undertaken some work in the development of a privacy appliance23 that is based on a heuristic approach to query control and can be viewed as a rewall that is placed in between databases containing personal information and those querying those databases. programmed by a party other than the querying party, the appliance is intended to prevent:ł direct disclosures (e.g., by withholding from query results data such as names, social security numbers, credit card numbers, addresses, and phone numbers);ł inferences of identity based on the combined results of multiple queries. this requires the maintenance of a log of earlier queries and a determination of whether any given query can yield an inference of identity; if so, the appliance is intended to prevent that query result from being returned.ł access to sensitive statistics. if a statistic will reveal information about an individual or if sensitive information can be inferred from a statistical summary, the appliance should block access to that statistic (if, for example, a statistical query is computed over too few records).in those instances where identifying information must be obtained (e.g., in order to identify the wouldbe perpetrator of a terrorist event), 23 privacy appliance, xerox parc, information available at http://www.parc.com/research /projects/privacyappliance/.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.110 engaging privacy and information technology in a digital ageindividuals with proper authorization such as a court order could be granted privileges to override the blocking by the appliance.the query control approach draws from the broader literature on approaches to privacy protection and disclosure limitation. nonetheless, it also poses some unresolved issues for which further research is needed.ł a lesson from the literature on the statistics of disclosure limitation is that privacy protection in the form of ﬁsafe releasesﬂ from separate databases does not guarantee privacy protection for information in a merged database.24 it is not known how strongly this lesson applies to the query control approach, especially given the fact that the literature addresses aggregate data, whereas questions of privacy often involve identication of individuals.ł the query control approach assumes that it is possible to analyze a log of previous queries to determine if any given query can yield an inference of identity. while this result is clearly possible when the previous queries are simple and relatively few, the feasibility of such analysis with a large number of complex queries is at present not known.ł still to be determined are the scope and the nature of analyses that can be undertaken with a privacy appliance in place. because the kanonymity concept on which the appliance is based relies on reporting sums or averages rather than individual data elds, there is some degradation of data. whether and in what contexts that degradation matters operationally is not known.ł some attacks on kanonymity are known to succeed under certain circumstances by taking advantage of background knowledge or database homogenity.25 background knowledge is externally provided knowledge about the variables in question (e.g., the statistical likelihood of their occurrence). database homogeneity refers to the situation in which there is insufcient diversity in the values of sensitive attributes. techniques have been proposed that reduce such difculties,26 but their compatibility with the query control approach of the privacy appliance remains to be seen.24 stephen e. fienberg, ﬁprivacy and condentiality in an ecommerce world: data mining, data warehousing, matching and disclosure limitation,ﬂ statistical science 21(2):143154, 2006.25 ashwin machanavajjhala, johannes gehrke, daniel kifer, and muthuramakrishnan venkitasubramaniam, ﬁldiversity: privacy beyond kanonymity,ﬂ proceedings of the 22nd ieee international conference on data engineering (icde 2006), atlanta, georgia, april 2006, available at http://www.cs.cornell.edu/johannes/papers/2006/2006icdepublishing.pdf.26 machanavajjhala et al., ﬁ1diversity,ﬂ 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 1113.8.2.2 statistical disclosure limitation techniques27other techniques can be used to reduce the likelihood that a specic individual can be identied in a datamining application that seeks to uncover certain statistical patterns. such techniques are useful to statistical agencies such as the census bureau, the bureau of labor statistics, and the centers for disease control and prevention (to name only a few), which collect vast amounts of personally identiable data and use it to produce useful data sets, summaries, and other products for the public or for research usesšmost often in the form of statistical tables (i.e., tabular data). some agencies (e.g., census) also make available socalled microdata lesšthat is, les that can show (while omitting specic identifying information) the full range of responses made on individual questionnaires. such les can show, for example, how one household or one household member answered questions on occupation, place of work, and so on.given the sensitive nature of much of this information and the types of analysis and comparison facilitated by modern technology, statistical agencies also can and do employ a wide range of techniques to prevent the disclosure of personally identiable information related to specic individuals and to ensure that the data that are made available cannot be used to identify specic individuals or, in some cases, specic groups or organizations. following are descriptions of many of those techniques.ł limiting details. both with tabular data and microdata, formal identiers and many geographic details are often simply omitted for all respondents.ł adding noise. data can be perturbed by adding random noise (adding a random but small amount or multiplying by a random factor close to 1, most often before tabulation) to help disguise potentially identifying values. for example, imagine perturbing each individual™s or household™s income values by a small percentage.ł targeted suppression. this method suppresses or omits extreme values or values that might be unique enough to constitute a disclosure.ł topcoding and bottomcoding. these techniques are often used to limit disclosure of specic data at the high end or low end of a given range by grouping together values falling above or below a certain level. for instance, an income data table could be congured to list every income below $20,000 as simply ﬁbelow $20,000.ﬂł recoding. similar to topcoding and bottomcoding, recoding 27 additional discussion of some of these techniques can be found in national research council, private lives and public policies, national academy press, washington, d.c., 1993.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.112 engaging privacy and information technology in a digital ageinvolves assigning individual values to groups or ranges rather than showing exact gures. for example, an income of $54,500 could simply be represented as being within the range of ﬁ$50,000 $60,000.ﬂ such recoding could be adequate for a number of uses where detailed data are not required.ł rounding. this technique involves rounding values (e.g., incomes) up or down based on a set of earlier decisions. for example, one might decide to round all incomes down to the nearest $5,000 increment. another model involves making random decisions on whether to round a given value up or down (as opposed to conforming data according to a predetermined rounding convention).ł swapping and/or shuf˚ing. swapping entails choosing a certain set of elds among a set of records in which values match, and then swapping all other values among the records. records can also be compared and ranked according to a given value to allow swapping based on values that, while not identical, are close to each other (socalled rankswapping). data shuf˚ing is a hybrid approach, blending perturbation and swapping techniques.ł sampling. this method involves including data from only a sample of a given population.ł blank and impute. in this process, values for particular elds in a selection of records are deleted and the elds are then lled either with values that have been statistically modeled or with values that are the same as those for other respondents.ł blurring. this method involves replacing a given value with an average. these average values can be determined in a number of different waysšfor example, one might select the records to be averaged based on the values given in another eld, or one might select them at random, or vary the number of values to be averaged.3.8.2.3 cryptographic techniquesthe portia project28 is a crossinstitutional research effort attempting to apply the results of cryptographic protocols to some of the problems of privacy. such protocols theoretically allow the ability to do queries over multiple databases without revealing any information other than the answer to the particular query, thus ensuring that multidatabase queries can be accomplished without the threat of privacythreatening aggregation of the data in those databases. although there are theoretical protocols that can be proved to give these results, implementing those protocols in a fashion that is efcient enough for common use is an open research 28 see more information about the portia project at http://crypto.stanford.edu/portia/.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 113problem. these investigations are in their early stages, so it is too soon to determine if the resulting techniques will be appropriate for wide use.a similar project is attempting to develop a socalled hippocratic database, which the researchers dene as one whose owners ﬁhave responsibility for the data that they manage to prevent disclosure of private information.ﬂ29 the thrust behind this work is to develop database technology to minimize the likelihood that data stored in the database are used for purposes other than those for which the data were gathered. while this project has produced some results in the published literature, it has not resulted in any widely deployed commercial products.3.8.2.4 user noticationanother set of technologies focus on notication. for example, the platform for privacy preferences (p3p) facilitates the development of machinereadable privacy policies.30 visitors to a p3penabled web site can set their browsers to retrieve the web site™s privacy policy and compare it to a number of visitorspecied privacy preferences. if the web site™s policy is weaker than the visitor prefers, the visitor is notied of that fact. p3p thus seeks to automate what would otherwise be an onerous manual process for the visitor to read and comprehend the site™s written privacy policy. an example of a p3p browser addon is privacy bird.31 results of the comparison between a site™s policy and the user™s preferences are displayed graphically, showing a bird of different color (green and singing for a site whose policy does not violate the requirements set by the user, angry and red when the policy con˚icts with the desires of the user) in the toolbar of the browser.systems such as privacy bird cannot guarantee the privacy of the individual who uses themšsuch guarantees can only be provided by enforcement of the stated policy. they do attempt to address the privacy issue directly, allowing the user to determine what information he or she is willing to allow to be revealed, along with what policies the recipient of the information intends to follow with regard to the use of that information or the transfer of that information to third parties. also, the process of developing a p3pcompatible privacy policy is structured and systematic. thus, a web site operator may discover gaps in its existing privacy policy as it translates that policy into machinereadable form.29 rakesh agrawal, jerry kiernan, ramakrishnan srikant, and yirong xu, ﬁhippocratic databases,ﬂ 28th international conference on very large databases (vldb), hong kong, 2002.30 see http://www.w3.org/p3p/.31 see http://www.privacybird.com/.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.114 engaging privacy and information technology in a digital age3.8.2.5 information flow analysisprivacy can also be protected by tools for automated privacy audits. some companies, especially large ones, may nd it difcult to know the extent to which their practices actually comply with their stated policies. the purpose of a privacy audit is to help a company determine the extent to which it is in compliance with its own policy. however, since the information ˚ows within a large company are multiple and varied, automated tools are very helpful in identifying and monitoring such ˚ows. when potential policy violations are identied, these tools bring the information ˚ows in question to the attention of company ofcials for further attention.such tools often focus on information ˚ows to and from externally visible web sites, monitoring form submissions and cookie usage, and looking for web pages that accidentally reveal personal information. tools can also tag data as privacy sensitive, and when such tagged data are subsequently accessed, other software could check to ensure that the access is consistent with the company™s privacy policy.because of the many information ˚ows in and out of a company, a comprehensive audit of a company™s privacy policy is generally quite difcult. but although it is virtually impossible to deploy automated tools everywhere within a company™s information infrastructure, automated auditing tools can help a great deal in improving a company™s compliance with its own stated policy.3.8.2.6 privacysensitive system designperhaps the best approach for protecting privacy is to design systems that do not require the collection or the retention of personal information in the rst place.32 for example, systems designed to detect weapons hidden underneath clothing have been challenged on privacy grounds because they display the image recorded by the relevant sensors, and what appears on the operator™s display screen is an image of an unclothed body. however, the system can be designed to display instead an indicator signaling the possible presence of a weapon and its approximate location on the body. this approach protects the privacy of the subject to a much greater degree than the display of an image, although it requires a much more technically sophisticated approach (since the image detected must be analyzed to determine exactly what it indicates).32 from the standpoint of privacy advocacy, it is difcult to verify the nonretention of data since this would entail a full audit of a system as implemented. data, once collected, often persist by default, and this may be an important reason that a privacy advocate might oppose even a system allegedly designed to discard data.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 115when a web site operator needs to know only if a visitor™s age is above a certain threshold (e.g., 13), rather than the visitor™s age per se, collecting only an indicator of a threshold protects the visitor™s privacy. more generally, systems can be designed to enable an individual to prove that he or she possesses certain attributes (e.g., is authorized to enter a building, holds a diploma, is old enough to gamble or drink) without revealing anything more about the individual. even online purchases could, in principle, be made anonymously using electronic cash.however, the primary impediments to the adoption of such measures appear to be based in economics and policy rather than in technology. that is, even though measures such as those described above appear to be technically feasible, they are not in widespread use. the reason seems to be that most businesses benet from the collection of detailed personal information about their customers and thus have little motivation to deploy privacyprotecting systems. law enforcement agencies also have concerns about electronic cash systems that might facilitate anonymous money laundering.3.8.2.7 information security toolsfinally, the various tools supporting information securityšencryption, access controls, and so onšhave important privacyprotecting functions. organizations charged with protecting sensitive personal information (e.g., individual medical records, nancial records) can use encryption and access controls to reduce the likelihood that such information will be inappropriately compromised by third parties. a cdrom with personal information that is lost in transit is a potential treasure trove for identity thieves, but if the information is encrypted on the cd, the cd is useless to anyone without the decryption key. medical records stored electronically and protected with good access controls that allow access only to authorized parties are arguably more private than paper records to which anyone has access. electronic medical records might also be protected by audit trails that record all accesses and prevent forwarding to unauthorized parties or even their printing in hard copy.with appropriate authentication technologies deployed, records of queries made by specic individuals can also be kept for future analysis.33 retention of such records can deter individuals from making privacyinvasive queries in the course of their workšin the event that personal information is compromised, a record might exist of queries that might 33 the committee is not insensitive to the irony that keeping query logs is arguably privacyinvasive with respect to the individual making the queries.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.116 engaging privacy and information technology in a digital agehave produced that personal information and the parties that may have made those queries.3.9 unsolved problems as privacy enhancersalthough much of the discussion above involves trends in technology that can lead to privacy concerns, many technical challenges must be addressed successfully to enable truly ubiquitous surveillance. if so, one can argue that many worries about technology and privacy are therefore misplaced.for example, the problem of data aggregation is far more than simply the problem of nding the data to be combined and using the network to bring those data to a shared location. one fundamental issue is that of interpreting data collected by different means so that their meaning is consistent. digital data, by denition, comprises elds that are either on (represent 1) or off (represent 0). but how these 1s and 0s are grouped and interpreted to represent more complex forms of data (such as images, transaction records, sound, or temperature readings) varies from computer to computer and from program to program.even so simple a convention as the number of bits (values of 1 or 0) used to represent a value such as an alphanumeric character, an integer, or a ˚oating point number varies from program to program, and the order in which the bits are to be interpreted can vary from machine to machine. the fact that data are stored on two machines that can talk to each other over the network does not mean that there is a program that can understand the data stored on the two machines, as the interpretation of that data is generally not something that is stored with the data itself.this problem is compounded when an attempt is made to combine the contents of different databases. a database is organized around groupings of information into records and indexes of those records. the combinations and indexes, known as schema, dene the information in the database. different databases with different schema denitions cannot be combined in a straightforward way; the queries issued to one of those databases might not be understood in the other database (or, worse still, might be understood in a different way). since the schema used in the database denes, in an important way, the meaning of the information stored in the database, two databases with different schema store information that is difcult to combine in any meaningful way.note that this issue is not resolved simply by searching in multiple databases of similar formats. for example, although search engines facilitate the searching of large volumes of text that can be spread among multiple databases, this is not to say that these data can be treated as belonging to a single database, for if that were the case both the format and the engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 117semantics of the words would be identical. the semantic web and similar research efforts seek to reduce the magnitude of the semantic problem, disambiguating syntactically identical words. but these efforts have little to do with aggregations of data in dissimilar formats, such as video clips and text or information in nancial and medical databases.this problem of interpretation is not new; it has plagued businesses trying to integrate their own data for nearly as long as there have been computers. huge amounts of money are spent each year on attempts to merge separate databases within the same corporation, or in attempts by one company to integrate the information used by another company that it has acquired. even when the data formats are known by the programmers attempting to do the integration, these problems are somewhere between difcult and impossible. the notion that data gathered by sensors about an individual by different sources can be easily aggregated by computers that are connected by a network presupposes, contrary to fact, that this problem of data integration and interpretation has been solved.similarly, the claim that increases in the capacity of storage devices will allow data to be stored forever and used to violate the privacy of the individual ignores another trend in computing, which is that the formats used to interpret the raw data contained in storage devices are program specic and tend to change rapidly. data are now commonly lost not because they have been removed from some storage device, but because there is no program that can be run that understands the format of the data or no hardware that can even read the data.34 in principle, maintaining documentation adequate to allow later interpretation of data stored in old formats is a straightforward taskšbut in practice, this rarely happens, and so data are often lost in this manner. and as new media standards emerge, it becomes more difcult to nd and/or purchase systems that can read the media on which the old data are recorded.a related issue in data degradation relates to the hardware. many popular and readily available storage devices (cds, dvds, tapes, hard drives) have limited dependable lifetimes. the standards to which these devices were originally built also evolve to enable yet more data to be packed onto them, and so in several generations, any given storage device may well be an orphan, with spare parts and repair expertise difcult to nd.data can thus be lost ifševen though the data have not been destroyedšthey become unreadable and thus unusable.finally, even with the advances in the computational power available 34 national research council, building an electronic records archive at the national archives and records administration: recommendations for a longterm strategy, robert sproull and jon eisenberg, eds., the national academies press, washington, d.c., 2005. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.118 engaging privacy and information technology in a digital ageon networks of modern computers, there are some tasks that will remain computationally infeasible without far greater breakthroughs in computing hardware than have been seen even in the past 10 years. some tasks, such as those that require the comparison of all possible combinations of sets of events, have a computational cost that rises combinatorially (i.e., faster than exponentially) with the number of entities being compared. such computations attempted over large numbers of people are far too computationally expensive to be done by any current or anticipated computing technology. thus, such tasks will remain computationally infeasible not just now but for a long time to come.35similar arguments also apply to certain sensing technologies. for example, privacy advocates worry about the wide deployment of facial recognition technology. today, this technology is reasonably accurate under controlled conditions where the subject is isolated, the face is exposed in a known position, and there are no other faces being scanned. attempts to apply this technology ﬁin the wild,ﬂ however, have largely failed. the problem of recognizing an individual from a video scan in uncontrolled lighting, where the face is turned or tilted, and where the face is part of a crowd, or when the subject is using countermeasures to defeat the recognition technology, is far beyond the capabilities of current technology. facial recognition research is quite active today, but it remains an open question how far and how fast the eld will be able to progress.3.10 observationscurrent trends in information technology have greatly expanded the ability of its users to gather, store, share, and analyze data. indeed, metrics for the increasing capabilities provided by information technology hardwarešstorage, bandwidth, and processing speed, among othersšcould be regarded as surrogates for the impact of technological change on privacy. the same is true, though in a less quantitative sense, for softwarešbetter algorithms, better database management systems 35 to deal with such problems, statisticians and computer scientists have developed pruning methods that systematically exclude large parts of the problem space that must be examined. some methods are heuristic, based on domainspecic knowledge and characteristics of the data, such as knowing that men do not get cervical cancer or become pregnant. others are built on theory and notions of model simplication. still others are based on sampling approaches that are feasible when the subjects of interest are in some sense average rather than extreme. if a problem is such that it is necessary to identify with high probability only some subjects, rather than requiring an exhaustive search that identies all subjects with certainty, these methods have considerable utility. but some problemsšand in particular searches for terrorists who are seeking to conceal their prole within a given populationšare less amenable to such treatment. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 119and more powerful query languages, and so on. these data can be gathered both from those who use the technology itself and from the physical world. given the trends in the technology, it appears that there are many ways in which the privacy of the individual could be compromised, both by governments, private corporations, and individual users of the technology.many of these concerns echo those that arose in the 1970s, when the rst databases began to be widely used. at that time, concerns over the misuse of the information stored in those databases and the accuracy of the information itself led to the creation of the fair information practice guidelines in 1973 (section 1.5.4 and box 1.3).current privacy worries are not as well dened as those that originally led to the fair information practice guidelines. whereas those guidelines were a reaction to fears that the contents of databases might be inaccurate, the current worries are more concerned with the misuse of data gathered for otherwise valid reasons, or the ability to extract additional information from the aggregation of databases by using the power of networked computation. furthermore, in some instances, technologies developed without a conscious desire for affecting privacy mayšupon closer examinationšhave deep ramications for privacy. as one example, digital rights management technologies have the potential to collect highly detailed information on user behavior regarding the texts they read and the music they listen to. in some instances, they have a further potential to create security vulnerabilities in the systems on which they run, exploitation of which might lead to security breaches and the consequent compromise of personal information stored on those systems. the informationcollection aspect of digital rights management technologies is discussed further in section 6.7.at the same time, some technologies can promote and defend privacy. cryptographic mechanisms that can ensure the condentiality of protected data, anonymization techniques to ensure that interactions can take place without participants in the interaction revealing their identity, and database techniques that allow extraction of some information without showing so much data that the privacy of those whose data has been collected will be compromised, are all active areas of research and development. however, each of these technologies imposes costs, both social and economic, for those who use them, a fact that tends to inhibit their use. if a technology has no purpose other than to protect privacy, it is likely to be deployed only when there is pressure to protect privacyšunlike other privacyinvasive technologies, which generally invade privacy as a sideeffect of some other business or operational purpose.an important issue is the impact of data quality on any system that involves surveillance and matching. as noted in chapter 1, data quality engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.120 engaging privacy and information technology in a digital agehas a signicant impact on the occurrence of false positives and false negatives. by denition, false positives subject individuals to scrutiny that is inappropriate and unnecessary given their particular circumstancesšand data quality issues that result in larger numbers of false positives lead to greater invasions of privacy. by denition, false negatives do not identify individuals who should receive further scrutinyšand data quality issues that result in larger numbers of false negatives compromise mission accomplishment.technology also raises interesting philosophical questions regarding privacy. for example, chapter 2 raised the distinction between the acquisition of personal information and the use of that information. the distinction is important because privacy is contextually denedšuse x of certain personal information might be regarded as benign, while use y of that same information might be regarded as a violation of privacy. but even if one assumes that the privacy violations might occur at the moment of acquisition, technology changes the meaning of ﬁthe moment.ﬂ is ﬁthe momentﬂ the point at which the sensors register the raw information? the point after which the computers have processed the bit streams from the sensors into a meaningful image or pattern? the point at which the computer identies an image or pattern as being worthy of further human attention? the point at which an actual human being sees the image or pattern? the point at which the human being indicates that some further action must be taken? there are no universal answers to such questionsšcontextual factors and value judgments shape the answers.a real danger is that fears about what technology might be able to do, either currently or in the near future, will spur policy decisions that will limit the technology in articial ways. decisions made by those who do not understand the limitations of current technology may prevent the advancement of the technology in the direction feared but also limit uses of the technology that would be desirable and that do not, in fact, create a problem for those who treasure personal privacy. consider, for example, that datamining technologies are seen by many to be tools of those who would invade the privacy of ordinary citizens.36 poorly formulated limitations on the use of data mining may reduce its impact on privacy, but may also inadvertently limit its use in other applications that pose no privacy issue whatever.finally, it is worth noting the normative question of whether technology or policy ought to have priority as a foundation for protecting privacy. one perspective on privacy protection is that policy should come rstšpolicy, and associated law and regulation, are the basis for the per36 a forthcoming study by the national research council will address this point in more detail.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.technological drivers 121formance requirements of the technologyšand that technology should be developed and deployed that conforms to the demands of policy. on the other hand, policy that is highly protective of privacy on one day can be changed to one that is less protective the next day. thus, a second view of privacy would argue that technology should constitute the basis for privacy protection, because such a foundation is harder to change or circumvent than one based on procedural foundations.37 further, violations of technologically enforced privacy protections are generally much more difcult to accomplish than violations of policyenforced protections. whether such difculties are seen as desirable stability (i.e., an advantage) or unnecessary rigidity (i.e., a disadvantage) depends on one™s position and perspective.in practice, of course, privacy protections are founded on a mix of technology and policy, as well as selfprotective actions and cultural factors such as ethics, manners, professional codes, and a sense of propriety. in large bureaucracies, signicant policy changes cannot be implemented rapidly and successfully, even putting aside questions related to the technological infrastructure. indeed, many have observed that implementing appropriate human and organizational procedures that are aligned with highlevel policy goals is often harder than implementing and deploying technology.37 lessig argues this point in code, though his argument is much broader than one relating simply to privacy. see lawrence lessig, code and other laws of cyberspace, basic books, new york, 2000.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.1224the legal landscape in the united statesmany discussions of privacy ultimately end up turning toward the law. how have legislatures and the courts dened and interpreted privacy? what are individuals™ and organizations™ rights and obligations under the law? is there a constitutional right to privacy? these are the sorts of questions that have inspired hundreds of books and journal articles about the legal underpinnings of privacy. this chapter presents an overview of the legal landscape as background for discussion elsewhere in the report.4.1 constitutional foundationsthis section addresses constitutional safeguards for a citizen™s privacy against government invasion and intrusion. although the word ﬁprivacyﬂ does not appear expressly in the u.s. constitution, the supreme court has made clear that this fundamental right is implicit from the panoply of other rights guaranteed in the first, fourth, and ninth amendments.4.1.1 the fourth amendmentthe source of constitutional protection for privacy (now embodied most clearly in the constitution™s fourth amendment) lies deep in english history. precisely four centuries ago, british courts declared in semayne™s case that ﬁthe house of every one is to him as his castle and fortress.ﬂ1 1 semayne™s case, 5 co. rep. 91a, 91b, 77 eng. rep. 194, 195 (k.b. 1603).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 123from that bold beginning developed a more specic expectation that government may search a person™s house, or personal papers, only with a valid reason (later, ﬁprobable causeﬂ), legal authority (eventually in the form of a search warrant), and only after giving adequate notice before seeking entry or access.prominent among the principles that the u.s. constitution™s framers felt imperative to embody in the bill of rights was that of privacy. the fourth amendment has for the past 212 years been the bulwark of such privacy protection. most states have comparable provisions in their own constitutions, and in 1963 the u.s. supreme court declared that state and local governments are as fully bound to respect privacy as is the national government, since the due process clause of the fourteenth amendment incorporates or absorbs the basic safeguards of the fourth and makes those safeguards fully applicable to ofcial action at all levels.interpreting and applying the spare words of the fourth amendment have posed a major and continuing challenge for the courts. indeed, hardly a term of the u.s. supreme court passes without at least one case on the docket that juxtaposes government™s need for information, usually pursuant to law enforcement investigation, and a citizen™s or organization™s wish to withhold that information, or to prevent government from gathering the information by invading premises or conducting surveillance in other forms.the supreme court™s recognition of a citizen™s right to be secure against unauthorized government intrusion dates at least to a batch of cases in the 1880s, beginning with kilbourn v. thompson, 103 u.s. 168, 190 (1880), noting that congress does not ﬁpossess the general power of making inquiry into the private affairs of the citizen.ﬂ later rulings extended the same principle to inquiries by federal administrative agencies. in 1886, in boyd v. united states, 116 u.s. 616, 530 (1886), the court struck down a regulatory measure that it found unduly intrusive into ﬁthe sanctity of a man™s home and the privacies of life.ﬂthe later evolution of fourth amendment privacy guarantees highlights several notable 20thcentury decisions. while the court ruled in olmstead v. united states, 277 u.s. 438 (1928), that the use of a wiretap did not violate the fourth amendment because there had been no physical invasion of a citizen™s home, person, or papers, later judgments importantly qualied the potential scope of that decision. notably, the court held in katz v. united states, 389 u.s. 347 (1967), that privacy rights did extend to a telephone booth, noting that ﬁwherever a man may be, he is entitled to know that he will remain free from unreasonable searches and seizures.ﬂthe supreme court has dealt extensively in the last half century with conditions and circumstances under which searches of automobiles, engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.124 engaging privacy and information technology in a digital agepedestrians, hotel rooms, and ofces may or may not be deemed reasonable. these rulings have usually re˚ected close divisions within the court, often by the narrowest of margins. while the prevailing principles remain constant, variations in circumstances, in the potential effect of a particular search, and in the claimed needs of law enforcement inevitably affect the outcome.a more recent decision affecting privacy of the home may aptly illustrate the process. in 2001, the supreme court considered for the rst time whether the use of a thermal imaging device aimed at a private home from a public street to detect relative amounts of heat within the homešto determine whether marijuana was probably being grown withinšconstituted a ﬁsearchﬂ for fourth amendment purposes. distinguishing permissible ﬁnaked eye surveillance of a homeﬂ the court held on a 54 vote that thermalimaging surveillance was constitutionally different and did involve an unlawful search. the explanation recalls the clarity and simplicity of basic fourth amendment precepts: ﬁwhere, as here, the government uses a devise that is not in general public use, to explore details of the home that would not previously have been knowable without physical intrusion, the surveillance is a ‚search™ and is presumptively unreasonable without a warrant.ﬂ2within the ambit of protecting privacy against government action, the supreme court declined in paul v. davis, 424 u.s. 693 (1976), to extend privacy interests to the ﬁstigmaﬂ created by ofcial publication of a person™s name and photo on a list of ﬁactive shopliftersﬂ after a larceny charge led against him had been dismissed. while renewing the broad scope of the ﬁzone of privacy,ﬂ the court distinguished other situations in which it had recognized such interests, noting that the claim posed here was not legally analogous, but simply sought to avoid unwelcome publicity. the high court™s 2003 decisions, rejecting similar claims against the display on state internet web sites of the identities of past sex offenders who had served time and been released, are much in the same vein.finally, the court has long held that the probable cause standard of the fourth amendment does not apply to individuals seeking to enter the country (as opposed to those individuals already in the united states). for example, the supreme court has held that ﬁsearches of persons or packages at the national border rest on different considerations and different rules of constitutional law from domestic regulations,ﬂ3 and has thus recognized the right of congress to grant the executive ﬁplenary authority to conduct routine searches and seizures at the border, without probable 2 kyllo v. united states, 533 u.s. 27 (2001).3 united states v. 12 200ft. reels of film, 413 u.s. 123 (1973).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 125cause or a warrant, in order to regulate the collection of duties and to prevent the introduction of contraband into this country.ﬂ44.1.2 the first amendmentthe first amendment™s recognition of free speech and press safeguards citizens™ privacy in several distinct ways: government may not compel citizens to reveal certain highly sensitive information (e.g., membership in controversial political groups) or require them to disclaim membership in such organizations as a condition of receiving public benets such as food stamps. nor may government require a postal patron to declare publicly a desire to continue to receive mail from communist countries.the supreme court has also found in the first amendment rights to speak, write, or publish anonymously or pseudonymously (especially in making political statements). beginning with its 1960 decision in talley v. california, 362 u.s. 60 (1960), the court has consistently found in freedom of expression a right to resist compelled disclosure of one™s identity, especially in the context of volatile political communications. some years later, in mcintyre v. ohio elections comm™n, 514 u.s. 334 (1995), the justices reafrmed their commitment to protection of anonymity, insisting that governments that had legitimate reasons to regulate political communications could use less intrusive means.in a similar vein, the court also struck down on first amendment grounds a law that required citizens who wished to receive ﬁcommunist political propagandaﬂ to explicitly notify the post ofce. the court™s reasoning was that such notication was a limitation on the unfettered exercise of the addressee™s first amendment rights. that decision, in lamont v. postmaster general, 381 u.s. 301 (1965), retains much value to privacy law, and is indeed the touchstone of current debate about the ﬁoptinﬂ provision of the federal law that requires public libraries to lter internet access, but permits patrons wishing unltered access to request it.however, the legal status of potentially intrusive government surveillance is less clear under the first amendment; three decades ago, the supreme court rejected citizens™ efforts to enjoin the government™s vietnam era surveillance and inltration of controversial antiwar political groups. the high court has never revisited this issue, although a few lower courts have been more protectivešnotably the california supreme court, a few years after the high court ruling, in barring police departments from sending undercover agents into university classrooms, posing as students, to compile dossiers on suspected radicals.4 u.s. v. montoya de hernandez, 473 u.s. 531, 537, 105 s. ct. 3304, 3308 (1985). engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.126 engaging privacy and information technology in a digital agethe first amendment has also served as the basis for protecting privacy in the home. starting with breard v. alexandria, 341 u.s. 622 (1951), the supreme court has shown substantial deference to local ordinances that protect privacy by forbidding doortodoor solicitation without the homeowner™s permissionšsave when such laws unduly burden free expression, as the justices found in their most recent encounter with such privacyprotecting measures, watchtower bible & tract soc™y v. stratton, 536 u.s. 150 (2002). in watchtower, the court held that a requirement to register with the mayor™s ofce and to obtain a local permit prior to engaging in doortodoor advocacy violated the first amendment as it applied to religious proselytizing, anonymous political speech, and the distribution of handbills.turning to legal protection for privacy that concerns intrusion by individuals rather than by government, the case law is more easily summarized. publication of the truthšno matter how unwelcome or invasive of privacyšis almost invariably protected under u.s. law, though less clearly under the laws of most other nations.the supreme court has stopped just short of declaring ˚atly that speaking truth is categorically protected. what the justices have consistently said on this subject is that a publisher may not be held criminally or civilly liable if the challenged information meets three conditions, spelled out in cases like cox broadcasting corp. v. cohn, 420 u.s. 469 (1975), and the florida star v. b.j.f., 491 u.s. 524 (1989). the statements must be accurate, else they would be subject to a legal claim for defamation. they must hold public interestšwhich means little more than that someone wishes to read or hear them. finally, the information or images must not have been unlawfully obtained. this last criterion created substantial confusion over the issue of whose unlawful conduct would taint the information. that issue has now been largely resolved by the supreme court™s 2001 ruling in bartnicki v. vopper, 532 u.s. 514 (2001), that even if a tape recording that was eventually broadcast on the defendant™s radio station resulted from a clearly illegal wiretap, the station would not be liable if the evidence showed no complicity on its part in the unlawful taping. the case did involve, beyond a nding for the station™s innocence, subject matter of great public interest and value to the community, and a privacy interest on the part of the illegally taped parties, whichšgiven the illegality of the activities they were plotting on the phonešthe court characterized as ﬁattenuated.ﬂthe supreme court™s reluctance ever to declare unambiguously that truth trumps privacy may give pause to some publishers, and might imply that the ghost of warren and brandeis survives. indeed, there are several situations in which truthful publications might generate liability. clearly if the information was unlawfully obtained by the publisher or engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 127by someone for whose conduct the publisher bears responsibilityšby hacking into an electronic database or breaching a legal privilege such as that between physician and patient, the legal immunity no longer applies. if truthful information is presented in a damaging ﬁfalse light,ﬂ the law of some states affords redress, which the supreme court seems to have condoned. conceivably an intrusive publication could be deemed to lack public interest, and forfeit protection on that basis.the ultimate question remains: if information has clear public interest, is accurate, and was not unlawfully obtained, can there ever be liability? the short answer seems to be no, and perhaps the longer answer as well. yet one can imagine two cases in which such a negative answer would at least compel re˚ection. one would be the widespread disseminationšthrough a popular web site, for example, of a photograph taken on a public street by a concealed camera of a female pedestrian™s intimate apparel and private features. since the site was publicša place where there is no expectation of privacy (unlike a bathroom, dressing room, etc.)šthe general policy is that anyone walking there is fair game for potentially embarrassing images. (as close as canada, the law differs on just this point; a canadian may be photographed with impunity at a rally or athletic event, but not without consent when sitting on a doorstep, even in clear public view.) there have been persistent suggestions that u.s. law should recognize some exception to the publisher™s immunity in such a situation.the other poignant case involves a person whose hivpositive status is unknown to friends, family, employer, and neighbors but is disclosed to the world by someone who obtained this highly sensitive information ﬁnot unlawfullyﬂ (an estranged exspouse, for example). here again, the revelation may not be actionable for a violation of a federal right of privacy, although it may be actionable under state constitutional privacy jurisprudence, for a variety of torts (e.g., tortuous interference with business relations), state or federal statutes, or for violation of contractual rights (e.g., divorce settlement agreements often have gag provisions). yet there is something about such a case that gives even the most ardent freepress advocate some pause. for the moment, the short answeršﬁthe truth shall set you freeﬂšremains the long answer as well.4.1.3 the ninth amendmentfinally among constitutional safeguards for privacy (though not for informational privacy), a ﬁpenumbralﬂ protection derived in part from the ninth amendment has recently joined more traditional sources. among the most prominent cases in this regard is griswold v. connecticut, 381 u.s. 479 (1965). in this case, the supreme court held unconstitutional a conengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.128 engaging privacy and information technology in a digital agenecticut law banning the use even by married couples of contraceptives, stating that the ban violated basic privacy precepts since it invaded ﬁa zone of privacy created by several fundamental constitutional guarantees.ﬂ in that case, justice william o. douglas concluded his opinion for the court with a reminder that is useful here: ﬁwe deal with a right of privacy older than the bill of rightsšolder than our political parties, older than our school system.ﬂ such statements remind us that the framers of the constitution and of the bill of rights were not creating protection for privacy against government, but codifying ancient precepts in new language, and with new force behind those words.on the other hand, a sharply split court failed in bowers v. hardwick, 478 u.s. 186 (1986), to nd in the right of privacy a constitutional basis for protection against state laws criminalizing homosexual sodomy. the status of that case had become increasingly problematic. before his death, one justice who had voted in the majority declared he had been wrong in so doing. at least ve states declined to follow hardwick, granting protection to private homosexual activity under their own constitutionsšas states are free to do, since the national bill of rights sets only a ˚oor and not a ceiling. thus when the issue returned to the supreme court during the 20022003 term, the likelihood of an overruling seemed substantial. only the margin was in doubt, as well as the precise rationale a differently disposed majority would adopt.on june 26, 2003, the nal day of its term, the justices by a decisive 63 vote overruled bowers v. hardwick, in lawrence v. texas, 539 u.s. 558 (2003). justice anthony m. kennedy, writing for the majority, posed in this way the central question of the case: ﬁwhether [the defendants] were free as adults to engage in the private conduct in the exercise of their liberty under the due process clause . . . .ﬂ after reviewing the high court™s own posthardwick privacy rulings, and taking an unprecedented account of foreign judgments, the majority concluded that the constitution did and should protect such activity among consenting adults. though primary emphasis rested on due process and equal protection, the court did stress a strong privacy interest as well: ﬁthe [defendants] are entitled to respect for their private lives. the state cannot demean their existence or control their destiny by making their private sexual conduct a crime.ﬂ the majority quoted a passage from one of the earlier abortionrights cases, recognizing ﬁthat there is a realm of personal liberty which the government may not enter,ﬂ and concluded that ﬁthe texas statute furthers no legitimate state interest which can justify its intrusion into the personal and private life of the individual.ﬂnot every recent ruling has favored privacy claims, however. a few years ago, the court declined in washington v. glucksberg, 521 u.s. 702 (1997), to nd in the due process clause a privacy interest sufcient to engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 129invalidate state laws that ban assisted suicideša ruling that was actually consistent with the high court™s earlier refusal in cruzan v. missouri health dep™t, 497 u.s. 261 (1990), to order the removal (pursuant to parental pleas) of life support from a vegetative accident victim.4.2 common law and privacy tortsthe modern quest for recognition of such a right of privacy is often traced to a seminal harvard law review article, published in 1890 by a young louis d. brandeis and his senior partner samuel warren.5 the article re˚ected growing concern about unwelcome and intrusive media publicity about the private lives of the rich and famous (notably the newspaper publication of sensitive guest lists for social events hosted by the warrens). the thesis of the piece was that courts should be more receptive to claims of privacy, and should develop ﬁa right to an inviolate personality.ﬂtoday, common law regarding privacy is formulated in terms of a set of four privacy torts for which legal recourse may be appropriatešalthough when the threat is created by a publisher, broadcaster, or other entity protected by the first amendment, courts will not always grant relief to the person whose privacy has been compromised. first articulated by william prosser,6 these torts include:ł intrusionšobjectionable intrusion into the private affairs or seclusion of an individual. the intrusion may be physical or electronic and is oriented toward improper information gathering. for example, watching someone urinating in a bathroom stallšwhether through a peephole or using a video camerašis likely such an intrusion. intrusion would generally not be applicable when someone is seen or photographed in public, although certain exceptions can be easily imagined (e.g., an outofvisualband camera that could generate realistic images of human bodies underneath clothing or ﬁupskirtﬂ cameras embedded in the sidewalk.ł public disclosure of private factsšpublication of personal information 5 samuel warren and louis d. brandeis, ﬁthe right to privacy,ﬂ harvard law review 4(5):193, 1890.6 william l. prosser, ﬁprivacy,ﬂ california law review 48:383, 1960. the discussion in this section draws on joey senat, ﬁ4 common law privacy torts,ﬂ 2000, an online study reference, available at http://www.cas.okstate.edu/jb/faculty/senat/jb3163/privacytorts.html; ﬁthe privacy torts: how u.s. state law quietly leads the way in privacy protection,ﬂ a special report issued by privacilla.org, july 2002, available at http://www.privacilla.org/releases/tortsreport.html; and national research council, who goes there? authentication through the lens of privacy, stephen t. kent and lynette i. millett, eds., the national academies press, washington, d.c., 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.130 engaging privacy and information technology in a digital agethat a reasonable person would object to having made public. the information must be both true and reasonably construable as private (e.g., a person™s height would be less private than an account of his sexual past). in addition, the disclosure must be publicšdisclosure to a small number of people or those with a legitimate need to know does not count as public. disclosure in the form of a movie that reveals someone by name is public; discussion among a group of acquaintances is not. finally, the disclosure must not be newsworthyšthus making publication about the private lives of celebrities fair game. in an information age context, publication of a noncelebrity™s personal information on a publicly accessible web page is largely uncharted territory.ł misappropriation of name or likenessšunauthorized use of an individual™s picture or name for commercial advantage. the misappropriation tort applies if and when a person™s name, likeness, or identity is used without his or her permission for trade or advertising purposes. the misappropriation tort relates to information privacy, but only insofar as it deals with a particular kind of use of a certain kind of personal information.ł false lightšpublication of objectionable, false information about an individual. the intent of this tort is to protect people against being cast in a false light in the public eye. for example, this tort would apply when someone™s photograph is publicly exhibited in a way or a context that creates negative inferences about him. the false light tort has been found applicable when people have been wrongly associated with juvenile delinquents or drug dealing, for example. of the four privacy torts, the false light tort is least applicable to informational privacy, since it deals with false information.the 1964 restatement of the law of torts (a clarication and compilation of the law by the american law institute) adopted the prosser framework.7 together, these torts provide a basis for privacy suits against the disclosure, without consent, of embarrassing false information about a person, or of intimate details or images from a person™s private life, or unauthorized use for prot or commercial gain of an individual™s image, likeness, voice, or reputation.as a matter of practice, these privacy torts have not been used much to protect the informationage privacy of individuals. however, the principles behind these torts are useful reminders of some of the interests that privacy is designed to protect againstšintrusion into personal affairs and disclosure of sensitive personal information, among others.as a historical matter, the warrenbrandeis article may not fully 7 american law institute, restatement of the law of torts, philadelphia, 1964.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 131deserve the credit it usually draws. fully a decade earlier, judge thomas cooley had written in his treatise on the law of torts that ﬁthe right to one™s person may be said to be a right of complete immunity: to be let alone.ﬂ8 although cooley seems to have been more focused on physical than psychological intrusion, the phrase that he used rst gave momentum to the quest for broader protection. warren and brandeis, in fact, fashioned an analogy between the legal basis for physical privacy (well established in british case law) and the emerging and more subtle value of protection for feelings, personal dignity and the like, for which they would invoke the new doctrine championed in their article.the impact of the warrenbrandeis thesis, well over a century later, is still not easily assessed. on the one hand, nearly every state has adopted statutory protection for privacy claims that extend well beyond the physical sanctity of the home and ofce; at last count, north dakota and wyoming were the only holdouts. on the other hand, the degree to which the warrenbrandeis view really has gained legal acceptance remains far less uniform.the most recent restatement of the law of torts, issued in 1977, recognized a cause of action for unconsented ﬁpublic disclosure of private factsﬂ but qualied that recognition by noting, for example, that ﬁwhile [a person] is walking on the public highway, there can be no liability for observing him or even taking his photograph.ﬂ9nonetheless, another comment to the 1977 restatement posits that publishing ﬁwithout consent, a picture of [the subject nursing her child]ﬂ would be actionable even if taken in a public place. in short, there is uncertainty and substantial ambivalence on the precise contours of this legal claim. scholars, too, have remained ambivalent. in the mid1960s, harry kalven asked rhetorically (in the title of an article on just this subject), ﬁwere warren and brandeis wrong?,ﬂ concluding that we are probably better off today because their plea for broad protection of privacy never has been fully embraced by the courts.4.3 freedom of information/open governmentfreedom of information has been and remains in this country a creature of statute and not of constitutional right. save for a few situations (notably the criminal trial) where courts have recognized a first amendment claim of access, obtaining government information or covering sen8 thomas cooley, a treatise on the law of torts or the wrongs which arise independent of contract, callaghan, chicago, 1879.9 american law institute, restatement of the law of torts, 2nd edition, philadelphia, 1977, pp. 379380.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.132 engaging privacy and information technology in a digital agesitive proceedings remains subject to the will of that government which controls the data or the site. since 1965, at the federal level, the freedom of information act (foia) has been the vital basis for access claims, many of which have been litigated with varying results.among the nine statutory exemptions to a citizen™s right of access under foia, those most likely to precipitate privacy tensions are exemptions 6 and 7c. the rst of these relates to information such as personnel and medical les, the disclosure of which would ﬁconstitute a clearly unwarranted invasion of personal privacy.ﬂ exemption 7c excludes records or information compiled for law enforcement purposes, ﬁbut only to the extent that the production of such [materials] . . . could reasonably be expected to constitute an unwarranted invasion of personal privacy.ﬂin the major decision construing and applying exemption 7c, united states department of justice v. reporters committee for freedom of the press, 489 u.s. 749 (1989), the supreme court noted the need, under the statute, to balance the interests of openness and accountability against the statutory recognition of individual privacy. the justices unanimously rejected claims of access to a suspect™s rap sheet, noting the vital distinction (in foia) between the statute™s ﬁpurpose to ensure that the government™s activities be opened to the sharp eye of public scrutinyﬂ and the contrasting claim that ﬁinformation about private citizens that happens to be in the warehouse of the government be so disclosed.ﬂbut in a case that eventually led to extensive revelations of truly chilling law enforcement activity in the 1960s, a federal appeals court ruled in rosenfeld v. department of justice, 57 f.3d 803 (9th cir. 1995), that exemption 7 would not justify withholding fbi documents pertaining to investigations of faculty and students at berkeley during the vietnam war era, the court noting that the fbi had no legitimate law enforcement interest in its probe of the free speech movement and thus could not invoke a valid privacy interest to resist disclosure.tensions between privacy and access arise occasionally in a very different context. the supreme court has twice in recent years resolved those debates in favor of the privacy interest. california law, in the interests of privacy, limited to certain groups ready access to records including the addresses of persons arrested on driving charges. commercial enterprises were excluded from the access pathway and challenged the restriction through the state courts to the u.s. supreme court. the justices, in los angeles police department v. united reporting publishing co., 528 u.s. 32 (1999), rejected, at the least, the challenge brought forward by the proprietary data seekers, leaving open the possibility of a future attack on the statute as it had been applied.finally, in the aftermath of the september 11, 2001, attacks, regulations binding on federal agencies have been promulgated to reduce the engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 133amount of information available through the freedom of information act. specically, in october 2001, attorney general john ashcroft promulgated a memorandum throughout the executive branch that established a ﬁsound legal basisﬂ standard for governing the department of justice™s decisions on whether to defend agency actions under foia when they are challenged in court. that is, the department of justice would defend all decisions to withhold information under foia ﬁunless they lack a sound legal basis or present an unwarranted risk of adverse impact on the ability of other agencies to protect other important records.ﬂ this new standard changed the previously operative ﬁforeseeable harmﬂ standard that was employed under previous guidance, which would defend a decision to withhold information only in those cases where the agency reasonably foresees that disclosure would be harmful to an interest protected by that exemption.4.3.1 federal laws relevant to individual privacyover the past three decades, many federal laws have been enacted to protect individual privacy.10 often they have responded to growing public awareness of privacy invasions made possible by technology developments.in commerce, one of the most important pieces of legislation with privacy impact is the ftc act (15 u.s.c. 4158, as amended), enacted by the u.s. congress in 1914. the ftc act established the federal trade commission and charges it with, among other things, protecting the public from unfair and deceptive trade practices.in recent years, the ftc has brought a number of cases to enforce the promises in statements of privacy policy, including promises about the security of consumers™ personal information, and to challenge practices that cause substantial consumer injury. these cases include actions against companies with faulty information security practices that allow sensitive customer data to be exposed to unauthorized parties (a typical settlement might require the offending company to implement a comprehensive information security program and to obtain audits by independent thirdparty security professionals every other year for 20 years) and companies that use collected data in a manner inconsistent with their stated policies (a typical settlement agreement might require the offending company to 10 many of the thumbnail descriptions of the laws in this section draw heavily on a description of laws related to information law and privacy prepared by the john marshall law school, ﬁinformation law and policy: existing u.s. informationrelated law,ﬂ 2000, available at http://www.citpl.org/infolaw/spring2000/law.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.134 engaging privacy and information technology in a digital ageforego monetary gains from its improper use and to agree to not engage in such improper use in the future).in addition, in late 2005 and early 2006, the ftc has also used its authority to hold companies liable for insufcient security measures in place to protect customer information, and at least two cases have been brought against companies on this basis, both of which resulted in consent agreements to obtain security audits and be subject to ftc oversight of their security practices.11 a complete listing of cases undertaken by the ftc can be found on the ftc web site.12in the nancial area, congress has enacted several bills that relate to privacy. some are intended to enhance individual privacy, and some detract from it.ł the fair credit reporting act (fcra), 15 u.s.c. 1681 (1970), broadly regulates the consumer reporting agencies in the interest of protecting the condentiality and privacy rights of the consumer. the fcra requires credit investigations and reporting agencies to make their records available to the subjects of the records, provides procedures for correcting information, and permits disclosure only to authorized customers.ł the bank secrecy act, 31 u.s.c. 53115355 (1970), was designed to aid the federal government in detecting illegal activity through tracking certain monetary transactions, and it requires nancial institutions to le reports of certain kinds of cash transactions and to keep records on other kinds of transactions for which no recordkeeping or ling requirements previously existed.ł the right to financial privacy act (rfpa), 12 u.s.c. 3401 et seq. (1978), provides some condentiality for the nancial records of depositors by governing the transfer of nancial records. in general, the act prohibits banks from disclosing client payment information to the government without a court order or other formal request. in some instances, the consumer has the right to challenge the request.ł the consumer credit reporting reform act, 15 u.s.c. 16811681t (1997), helps to close some of the loopholes found in the fcra. the act 11 the ftc identied six practices that contribute to a judgment that security practices were insufcient: storing sensitive information in multiple les when the company no longer had a business need to keep the information; failure to encrypt consumer information when it was transmitted or stored on computers in company stores; failure to use readily available security measures to limit access to its computer networks through wireless access points on the networks; storing the information in les that could be easily accessed using a commonly known or default user id and password; failure to limit sufciently the ability of computers on one instore network to connect to computers on other instore and corporate networks; and failure to employ sufcient measures to detect unauthorized access. 12 see http://www.ftc.gov/privacy/privacyinitiatives/promisesenf.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 135narrows the broad ﬁlegitimate needﬂ purpose for which credit reports can be disseminated. consumer credit reports cannot be furnished for employment purposes except if the employer certies that the employee has consented in writing.ł the grammleachbliley act (1999) requires nancial institutions to notify consumers of their privacy policies and gives them the opportunity to prevent disclosure of nonpublic personal information about them to nonafliated third parties. it also makes the practice of ﬁpretextingﬂ unlawful (i.e., seeking nancial information under the pretext of being the customer). see section 6.3 for more on the grammleachbliley act.in the area of electronic communications (including telephone, pager, and computerbased communications), congress has passed several acts.ł the omnibus crime control and safe street act (1968) in title iii sets forth specic requirements for conducting telephone wiretaps. the legislation today is typically known as the title iii wiretap act. under title iii legislation, law enforcement authorities must usually obtain a warrant based on a court™s nding that ﬁthere is probable cause [to believe] that an individual is committing, has committed, or is about to commit a particular offense . . . [and that] normal investigative procedures have been tried and have failed or reasonably appear to be unlikely to succeed if tried or to be too dangerous.ﬂ only certain federal crimes may be investigated under title iii authority (e.g., murder, kidnapping, child molestation, racketeering, narcotics offenses), and title iii also has a variety of provisions that minimize the intrusiveness of the wiretap on telephonic communications that are unrelated to the offense being investigated, provide for civil and criminal penalties for law enforcement ofcials or private citizens who violate its provisions, and allow the suppression of evidence obtained in violation of the central features of title iii requirements, even if such evidence meets the relevant fourth amendment tests.ł the foreign intelligence surveillance act (1978), enacted as a reaction to an asserted executive branch authority to conduct wiretaps without restriction in intelligence matters, establishes mechanisms through which courtapproved legal authority for obtaining a wiretap can be granted. passed at the time with strong support from the american civil liberties union, this extent of this law™s reach is now being challenged, as discussed in chapter 9.ł the cable communications policy act, 47 u.s.c. 551 (1984), requires cable services to inform their customers of the nature of personally identiable information and the use of that information, and also places restrictions on the cable services™ collection and disclosure engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.136 engaging privacy and information technology in a digital ageof information. signicantly, it requires that cable operators utilize fair information procedures and that they not disclose identiable information, including viewer choices or retail transactions, without written or electronic consent. subscribers are given the right to limit disclosure of name and address for mail solicitation purposes and have a right of accuracy and correction. however, restrictions in this act on disclosure of information related to the cable provision of communications services such as voiceoverip phone service were substantially relaxed by the usa patriot act in response to law enforcement requests for information.ł the electronic communications privacy act (ecpa), 18 u.s.c. 25102520, 27012709 (1986), amends the title iii wiretap act. ecpa extends the coverage of title iii to new forms of voice, data, and video communications including cellular phones, electronic mail, computer transmissions, and voice and display pagers.ł the telephone consumer protection act (1991) protects the consumer™s right to be left alone by authorizing the fcc to require telemarketers to create and maintain lists of consumers who do not wish to be called (do not call lists). the law also protects consumers from some forms of marketing by banning the use of unsolicited prerecorded telephone calls, and unsolicited advertisements by fax.ł the communications assistance for law enforcement act (calea; 1994) requires telecommunications carriers to expeditiously isolate and enable the government to surreptitiously intercept all wire and electronic communications in the carrier™s control to or from the equipment, facilities, or services of a subscriber, in real time or at any later time acceptable to the government. calea covers telephone communications carried over traditional circuitswitched networks, but it provides an exemption for ﬁinformation service providersﬂ unless they are providing services that are ﬁa replacement for a substantial portion of the local telephone exchange serviceﬂ as determined by the fcc. in may 2006, the fcc determined that voiceoverip providers were indeed subject to the requirements of calea.13ł the telemarketing and consumer fraud and abuse prevention act, 15 u.s.c. 61016108 (1994), places constraints on telemarketing calls, especially those made by autodialers, and also forbids telemarketing conducted in a pattern that is abusive of consumers™ privacy.ł the telecommunications act, 47 u.s.c. 222 (1996), was a major overhaul of telecommunications law. certain provisions impose restrictions on the use of automated phone dialing systems, articial or prerecorded voice messages, and fax machines to send unsolicited advertise13 see http://www.askcalea.net/docs/200605032ndmemorandum.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 137ments. where calling information (which might be regarded as sensitive personal information) is obtained by one telecommunications carrier from another, the telecommunications act stipulates that the sole purpose must be the provision of communications service or ancillary purposes necessary to or used in the provision of such services, including the publishing of directories.in the area of information contained in government records, congress has passed several acts.ł the freedom of information act (1996) establishes a presumption that records in the possession of agencies and departments of the executive branch of the u.s. government are accessible to the people. federal agencies are required to disclose records upon receiving a written request for them, except for those records that are protected from disclosure by any of the nine exemptions or three exclusions of foia. this right of access is enforceable in court. in 1996, congress passed the electronic freedom of information act (efoia) amendments, which provided for public access to information in an electronic format and for the establishment of electronic foia reading rooms through agency foia sites on the internet.ł the privacy act of 1974, 5 u.s.c. 552a, provides safeguards against an invasion of privacy through the misuse of records by federal agencies. in general, the act allows a citizen to learn how records are collected, maintained, used, and disseminated by the federal government. the act also permits an individual to gain access to most personal information maintained by federal agencies and to seek amendment of any inaccurate, incomplete, untimely, or irrelevant information. note that the privacy act is concerned primarily with systems of records rather than data accrued from networks.ł the driver™s privacy protection act of 1994, 18 u.s.c. 2721, was passed subsequent to the stalking and murder of actress rebecca schaeffer by a fan who allegedly retrieved her name and address from a motor vehicle department. the act, which became effective in 1997, prohibits state departments of motor vehicles and their employees from releasing ﬁpersonal informationﬂ from a driver™s record unless the request ts within 1 of 14 exemptions. as originally passed, it also required state motor vehicle departments to provide a citizen an optout means of prohibiting the disclosure of certain personal information to other individuals, although businesses could still receive such information for certain specied purposes. the act was subsequently amended to require optin consent for disclosure of personal information to other individuals, and also for the disclosure of ﬁhighly restricted personal informationﬂ (an engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.138 engaging privacy and information technology in a digital ageindividual™s photograph or image, social security number, or medical or disability information) for almost all purposes.ł megan™s law, 42 u.s.c. 14071 (1999), obligates states to require prison ofcials or courts to inform convicted sex offenders of their obligation to register with state law enforcement authorities and to reregister if they move to another state. the state agencies in turn are to inform local law enforcement authorities, typically the local police department, of convicted sex offenders who reside in their jurisdiction. the state law enforcement agencies are also required to inform the fbi about the whereabouts of convicted sex offenders. (in many cases, states have gone farther in requiring the publishing of the addresses of sex offenders so that the communities in which they reside will be alerted to their presence.)also, a number of federal laws require the attorney general to promulgate regulations for access to criminal history and incarceration records of individuals. these regulations, 28 c.f.r. 20, are intended to ensure the accuracy, completeness, currency, integrity, and security of such information and to protect individual privacy.in 1996 congress passed a major piece of health care legislation called the health insurance portability and accountability act (hipaa). among its privacy provisions, it mandates regulations to protect the condentiality of individually identiable health information and is further discussed in chapter 7.in 2001, congress passed the uniting and strengthening america by providing appropriate tools required to intercept and obstruct terrorism (usa patriot) act, and in 2006, a number of amendments to the act. in general, the usa patriot act and subsequent amendments lower some of the barriers to conducting surveillance in the united states for national security or foreign intelligence purposes, provide the u.s. intelligence community with greater access to information uncovered during criminal investigations, and encourage cooperation between law enforcement and foreign intelligence investigators. the usa patriot act also lessens certain restrictions on criminal investigations, such as delayed notication of physical searches executed pursuant to a search warrant under some circumstances and courtenabled access to otherwiseprotected educational records in terrorism cases. finally, the usa patriot act creates judicial oversight for email monitoring and grand jury disclosures.1414 this discussion is based on charles doyle, the usa patriot act: a legal analysis, order code rl31377, congressional research service, washington, d.c., april 15, 2002, available at http://www.fas.org/irp/crs/rl31377.pdf; and brian t. yeh and charles doyle, usa patriot improvement and reauthorization act of 2005: a legal analysis, order code rl33332, congressional research service, washington, d.c., march 24, 2006, available at http://www.fas.org/sgp/crs/intel/rl33332.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 139a host of miscellaneous privacy protection acts have also been passed in the last 30 years.ł the family educational rights and privacy act (ferpa), 20 u.s.c. 1232g (1974), regulates institutions that receive public funds. the act requires educational institutions to grant students, or parents of students, access to student records, establishes procedures to challenge and correct information, and limits disclosure to third parties. section 6.2 discusses the impact of this legislation. section 5.1 addresses ferpa™s origins.ł the computer fraud and abuse act, 18 u.s.c. 1030, was originally passed in 1986 and subsequently amended in 1994, 1996, and 2001 to criminalize certain computer ﬁhackingﬂ activities, such as intentionally accessing a computer without authorization to obtain information contained in a nancial record of a nancial institution, information from any department or agency of the united states, or information from any protected computer if the conduct involves an interstate or foreign communication and knowingly causing damage through the use of a computer. authorities under this act have been used to protect the privacy and condentiality of computerresident information.ł the video privacy protection act, 18 u.s.c. 2710, was passed in 1988 in response to actions taken by reporters covering the hearings for judge robert bork™s nomination to the supreme court. reporters were able to gain access to records of the bork family™s video rentals. congress deemed this an invasion of privacy and reacted by enacting the video privacy protection act.ł the children™s online privacy protection act, 15 u.s.c. 65016506 (1998), requires the ftc to prescribe regulations to protect the privacy of personal information collected from and about children on the internet and to provide greater parental control over the collection and use of that information.ł the identity theft and assumption deterrence act, 18 u.s.c. 1028 (1998), addresses the problem of identity theft (box 4.1). it stipulates that the person whose identity was stolen is a true victim (whereas previously only the credit grantors who suffered monetary losses were considered victims); enables the secret service, the fbi, and other law enforcement agencies the authority to investigate this crime; allows the identity theft victim to seek restitution if there is a conviction; and establishes the ftc as a central agency to act as a clearinghouse for complaints, referrals, and resources for assistance for victims of identity theft.ł the canspam act (controlling the assault of nonsolicited pornography and marketing act), 15 u.s.c. 77017713 (2003), applies to unsolicited commercial email. in such emails, the act bans false or misleading header information (e.g., false ﬁfromﬂ information) and deceptive subject lines, requires that recipients be given a method for opting out of receivengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.140 engaging privacy and information technology in a digital agebox 4.1 identity theft identity theft or fraud is a major and growing concern in the information age. in 1998, it was made a federal crime under the identity theft and assumption deterrence act. the crime consists of stealing key pieces of another™s personal information such as social security, credit card, or bank account numbers, and using that information to obtain credit or purchase goods or services. in the typical case, the thief uses the personal information to open a new credit card account, cellular phone service, or new checking account (with new blank checks). or the thief uses a stolen account number to gain access to the account, and then changes the address on the account and runs up a huge bill before the account owner discovers what has happened. the injury to consumers is considerable, even though much of the ultimate nancial loss falls on nancial institutions. the injury to consumer victims takes many forms, including the signicant amount of time and frustration involved in tracking down the extent of the theft, and reporting it to all the various institutions that must be notied, such as credit card issuers, banks, lenders, credit reporting agencies, and so on. injury can also take the form of lost credit, insurance, and even jobs and driver™s licenses, before victims are able to correct their nancial records. identity theft also has implications for national security. for example, dennis m. lormel, chief of the fbi™s terrorist financial review group, testied on july 9, 2002, before the senate judiciary committee subcommittee on technology, terrorism and government information:1 the threat [of identity theft] is made graver by the fact that terrorists have long utilized identity theft as well as social security number fraud to enable them to obtain such things as cover employment and access to secure locations. these and similar means can be utilized by terrorists to obtain driver™s licenses, and bank and credit card accounts through which terrorism nancing is facilitated. terrorists and terrorist groups require funding to perpetrate their terrorist agendas. the methods used to nance terrorism range from the highly sophisticated to the most basic. there is virtually no nancing method that has not at some level been exploited by these groups. identity theft is a key catalyst fueling many of these methods.  for example, an alqaeda terrorist cell in spain used stolen credit cards in ctitious sales scams and for numerous other purchases for the cell. they kept purchases below amounts where identication would be presented. they also used stolen telephone and credit cards for communications back to pakistan, afghanistan, lebanon, etc. extensive use of false passports and travel documents were used to open bank accounts where money for the mujahadin movement was sent to and from countries such as pakistan, afghanistan, etc. identity thieves obtain information in a variety of ways. often oldfashioned techniques are used, e.g., retrieving numbers from paperwork in trash bins (ﬁdumpster divingﬂ) and observing numbers entered by consumers at atms, pay telephones, or on forms at bank counters (ﬁshoulder surngﬂ). these techniques seem more common than more sophisticated methods, such as hacking into databases on the internet. but modern information technology facilitates identity theft on a large scale. for example, 8 of the 36 incidents of largescale compromise of personal information reported by the identity theft resource center2 involved the theft of computers containing personal information. in other cases, the compromise of personal information arises from unauthorized breakins into databases containing such information or the loss or theft of tapes and other storage media with such information in unencrypted form.3 the internet is also increasingly important in facilitating the use of illicitly acquired information, since online transactions require no personal interaction. the speed of the internet also allows thieves to engage in large numbers of transactions in a very short period of time, thus increasing the losses that result from identity theft. for example, in november 2005 six men who administered and operated the ﬁshadowcrew.comﬂ web sitešone of the largest online centers for trafcking in stolen credit and bank card numbers and identity informationšpleaded guilty to charges of conspiracy to commit credit and bank card fraud, as well as identication document fraud. some have argued that identity theft is more accurately described as a nancial crime than as a privacy problem. they argue that solutions should focus on stopping the behavior of wrongdoers, and express concern about solutions that might have the effect of limiting the availability of information. but stopping wrongdoers is a real challenge. the thieves are difcult to identify and locate; often consumers do not know how their information was stolen and remain unaware of the theft for some time (on average from 6 months to a year). notication of consumers does help, but in some instances, the notication is accompanied by an offer of a year of free credit monitoring, and to obtain this service consumers have to provide personal information as an authenticating mechanism to prove who they are. this approach thus opens yet another mechanism for identity theftša forged letter or email from identity thieves notifying consumers of a purported compromise of personal information. finally, such crimes may not be a high priority for federal or local prosecutors. while the federal trade commission (which receives the complaints and refers cases to law enforcement agencies) reports that prosecutions have increased, criminal law enforcement can never be expected to address more than a small percentage of the cases. private sector solutions offer an alternative to law and regulation for reducing the impact of identication theft. financial institutions, which bear the considerable nancial loss from identity theft, have considerable incentive and capacity to nd effective tools for detecting fraud and preventing the misuse of stolen information. consumer education is also part of the solution. and increasingly, word is getting out through government and private sector initiatives on how consumers can prevent their information from being stolen. it is too soon to tell whether all these efforts will put a real dent in identity theft. the federal trade commission™s call center reports continuing increases in the number of complaints. while these numbers no doubt re˚ect greater consumer awareness of the problem and the toll free number, they also suggest a growing problem and the considerable challenge ahead.1 testimony available at http://www.fbi.gov/congress/congress02/idtheft.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 141box 4.1 identity theft identity theft or fraud is a major and growing concern in the information age. in 1998, it was made a federal crime under the identity theft and assumption deterrence act. the crime consists of stealing key pieces of another™s personal information such as social security, credit card, or bank account numbers, and using that information to obtain credit or purchase goods or services. in the typical case, the thief uses the personal information to open a new credit card account, cellular phone service, or new checking account (with new blank checks). or the thief uses a stolen account number to gain access to the account, and then changes the address on the account and runs up a huge bill before the account owner discovers what has happened. the injury to consumers is considerable, even though much of the ultimate nancial loss falls on nancial institutions. the injury to consumer victims takes many forms, including the signicant amount of time and frustration involved in tracking down the extent of the theft, and reporting it to all the various institutions that must be notied, such as credit card issuers, banks, lenders, credit reporting agencies, and so on. injury can also take the form of lost credit, insurance, and even jobs and driver™s licenses, before victims are able to correct their nancial records. identity theft also has implications for national security. for example, dennis m. lormel, chief of the fbi™s terrorist financial review group, testied on july 9, 2002, before the senate judiciary committee subcommittee on technology, terrorism and government information:1 the threat [of identity theft] is made graver by the fact that terrorists have long utilized identity theft as well as social security number fraud to enable them to obtain such things as cover employment and access to secure locations. these and similar means can be utilized by terrorists to obtain driver™s licenses, and bank and credit card accounts through which terrorism nancing is facilitated. terrorists and terrorist groups require funding to perpetrate their terrorist agendas. the methods used to nance terrorism range from the highly sophisticated to the most basic. there is virtually no nancing method that has not at some level been exploited by these groups. identity theft is a key catalyst fueling many of these methods.  for example, an alqaeda terrorist cell in spain used stolen credit cards in ctitious sales scams and for numerous other purchases for the cell. they kept purchases below amounts where identication would be presented. they also used stolen telephone and credit cards for communications back to pakistan, afghanistan, lebanon, etc. extensive use of false passports and travel documents were used to open bank accounts where money for the mujahadin movement was sent to and from countries such as pakistan, afghanistan, etc. identity thieves obtain information in a variety of ways. often oldfashioned techniques are used, e.g., retrieving numbers from paperwork in trash bins (ﬁdumpster divingﬂ) and observing numbers entered by consumers at atms, pay telephones, or on forms at bank counters (ﬁshoulder surngﬂ). these techniques seem more common than more sophisticated methods, such as hacking into databases on the internet. but modern information technology facilitates identity theft on a large scale. for example, 8 of the 36 incidents of largescale compromise of personal information reported by the identity theft resource center2 involved the theft of computers containing personal information. in other cases, the compromise of personal information arises from unauthorized breakins into databases containing such information or the loss or theft of tapes and other storage media with such information in unencrypted form.3 the internet is also increasingly important in facilitating the use of illicitly acquired information, since online transactions require no personal interaction. the speed of the internet also allows thieves to engage in large numbers of transactions in a very short period of time, thus increasing the losses that result from identity theft. for example, in november 2005 six men who administered and operated the ﬁshadowcrew.comﬂ web sitešone of the largest online centers for trafcking in stolen credit and bank card numbers and identity informationšpleaded guilty to charges of conspiracy to commit credit and bank card fraud, as well as identication document fraud. some have argued that identity theft is more accurately described as a nancial crime than as a privacy problem. they argue that solutions should focus on stopping the behavior of wrongdoers, and express concern about solutions that might have the effect of limiting the availability of information. but stopping wrongdoers is a real challenge. the thieves are difcult to identify and locate; often consumers do not know how their information was stolen and remain unaware of the theft for some time (on average from 6 months to a year). notication of consumers does help, but in some instances, the notication is accompanied by an offer of a year of free credit monitoring, and to obtain this service consumers have to provide personal information as an authenticating mechanism to prove who they are. this approach thus opens yet another mechanism for identity theftša forged letter or email from identity thieves notifying consumers of a purported compromise of personal information. finally, such crimes may not be a high priority for federal or local prosecutors. while the federal trade commission (which receives the complaints and refers cases to law enforcement agencies) reports that prosecutions have increased, criminal law enforcement can never be expected to address more than a small percentage of the cases. private sector solutions offer an alternative to law and regulation for reducing the impact of identication theft. financial institutions, which bear the considerable nancial loss from identity theft, have considerable incentive and capacity to nd effective tools for detecting fraud and preventing the misuse of stolen information. consumer education is also part of the solution. and increasingly, word is getting out through government and private sector initiatives on how consumers can prevent their information from being stolen. it is too soon to tell whether all these efforts will put a real dent in identity theft. the federal trade commission™s call center reports continuing increases in the number of complaints. while these numbers no doubt re˚ect greater consumer awareness of the problem and the toll free number, they also suggest a growing problem and the considerable challenge ahead.2 see http://www.idtheftcenter.org/breaches.pdf.3 see, for example, http://www.consumersunion.org/campaigns//learnmore/002232indiv.html. in a quite recentšand largescalešincident, social security numbers and other personal information for as much as 80 percent of the u.s. activeduty military force were among the unencrypted data stolen from the home of a department of veterans affairs analyst in may 2006. see ann scott tyson and christopher lee, ﬁdata theft affected most in military: national security concerns raised,ﬂ washington post, june 7, 2006, p. a01.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.142 engaging privacy and information technology in a digital ageing further communications, and requires that the email is identied as an advertisement and includes the sender™s valid physical postal address. the act also gives the ftc the authority to enforce it, and the department of justice the authority to enforce its criminal sanctions.ł the real id act (2005) requires federal agencies to accept drivers™ licenses or personal identication cards as identication after may 11, 2008, only if these documents meet certain federal standards. these documents must include, at a minimum, a person™s full legal name, date of birth, gender, driver™s license or personal id card number, digital photograph, address of legal residence, and signature; physical security features designed to prevent tampering, counterfeiting, or duplication for fraudulent purposes; and a common machinereadable format for dened data elements. in addition, states must require the presentation and verication of a photo identity document (except that a nonphoto identity document is acceptable if it includes both the person™s full legal name and date of birth), documentation showing the person™s date of birth, proof of the person™s social security number (ssn) or verication that the person is not eligible for an ssn, and documentation showing the person™s name and address of principal residence. states are also required to provide to all other states electronic access to information contained in the motor vehicle database of the state.4.3.2 federal laws relevant to condentialitya number of federal laws protect the condentiality of personal information collected by the statistical agencies of the united states. for example, the census bureau collects detailed personal information on most americans every decade. such information includes but is not limited to income, housing situation and living arrangements, employment, and ethnicity. these data, collected via survey, are protected by the provisions of title 13, section 9, which prohibits dissemination of such data in a manner that allows identication of the respondent. this prohibition applies to individuals who have not been sworn as agents of the census. in addition, the census bureau is explicitly prohibited from using survey information in any way apart from statistical purposes. survey information may also not be used as legal evidence.a second relevant law is the condential information protection and statistical efciency act (cipsea), passed as title v of the egovernment act of 2002. cipsea strengthens and extends condentiality protection for all statistical data collections of the u.s. government. if data are furnished by individuals or organizations to an agency under a pledge of condentiality for exclusively statistical purposes, cipsea provides that the data will be used only for statistical purposes and will not be disclosed in identiable form to anyone not authorized by the title. data covered engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 143under cipsea are also not subject to release under a freedom of information act request.a third example (and there are still others) is the condentiality of information collected for public health purposes, specied by section 308(d) of the public health service act (42 u.s.c. 242m). this section requires that the information collected can be used only for the stated purposes unless consent for another purpose is obtained.note also that laws protecting the condentiality of personal information can be, and have been, altered to allow uses other than the one for which such information was originally collected. for example, the usa patriot act amended the national education statistics act of 1994 to allow the u.s. attorney general or assistant attorney general to submit a written application to a court of competent jurisdiction for an ex parte order to collect reports, records, and information from the national center for education statistics (nces), all of which may have been collected under the condentiality guarantee, if they are related to investigations and prosecutions of terrorism.4.3.3 regulationregulations related to privacy are extensive and too voluminous to recap fully in this report. at the federal level, most privacy statutes are implemented through rule making. the u.s. congress passes legislation that lays out the general issues and principles in question, but leaves to a regulating agency the responsibility of working out the details of how that legislation will be implemented. the agency proposes the regulations, invites public comment on the proposal, and issues the nal regulation, which can be challenged in court. once promulgated, regulation has the force of law. enforcement actions may be taken for violations of regulations, often resulting in a consent decree, in which a company agrees to take actions to ensure that the offending behavior will not be repeated. typically, consent decrees are enforceable in federal courts.although many agencies have regulatory authority, the federal trade commission has played a key role in enforcing regulations related to informationage privacy and has some authority to promulgate regulations as well. for example, the ftc states,privacy is a central element of the ftc™s consumer protection mission. in recent years, advances in computer technology have made it possible for detailed information about people to be compiled and shared more easily and cheaply than ever. . . . at the same time, as personal information becomes more accessible, each of usšcompanies, associations, government agencies, and consumersšmust take precautions to protect against the misuse of our information.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.144 engaging privacy and information technology in a digital ageunder a number of statutory provisions (including the grammleachbliley act, the fair credit reporting act, the fair and accurate credit transactions act, and the children™s online privacy protection act), the ftcšoften jointly with other regulatory agenciesšhas issued a variety of regulations that relate to privacy.ł under the grammleachbliley act (also known as the financial modernization act of 1999 and codied at 15 u.s.c. 68016809 and 68216827), the ftc has issued regulations (16 c.f.r. part 313) to ensure that nancial institutions protect the privacy of consumers™ personal nancial information.15 the main privacy protection provision is the financial privacy rule, which governs the collection and disclosure of customers™ personal nancial information by nancial institutions.16 in brief, the financial privacy rule requires covered institutions to give consumers privacy notices that explain the institutions™ informationsharing practices, gives consumers the right to limit certain types of sharing of their nancial information on an optout basis, and puts some limits on how anyone receiving nonpublic personal information from a nancial institution can use or redisclose the information.in addition, the ftc has also promulgated the safeguards rule, which requires nancial institutions to have a security plan to protect the condentiality and integrity of personal consumer information. such a plan has administrative, technical, and physical information safeguards, and is intended to protect against any unauthorized access that might harm the consumer. finally, other provisions of the grammleachbliley act also affect how a company conducts business, such as a prohibition on nancial institutions disclosing customers™ account numbers to nonafliated companies for marketing purposes.ł under section 114 of the fair and accurate credit transactions act of 2003, the ftc (in cooperation with the federal agencies regulating nancial services, such as the securities and exchange commission and the commodity futures trading commission, and the national credit union administration) promulgated regulations specifying procedures under which nancial institutions would protect account holders from 15 ﬁfinancial institutionsﬂ include banks, securities rms, insurance companies, and other companies providing certain types of nancial products and services to consumers, including lending, brokering, or servicing any type of consumer loan, transferring or safeguarding money, preparing individual tax returns, providing nancial advice or credit counseling, providing residential real estate settlement services, collecting consumer debts, and an array of other activities.16 see federal trade commission, ﬁin brief: the financial privacy requirements of the grammleachbliley act,ﬂ available at http://www.ftc.gov/bcp/conline/pubs/buspubs/glbshort.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 145identity theft. section 151 directed these agencies to jointly develop a summary of the rights of identity theft victims that would be made available to all such victims. regulations issued under section 211 established a single source through which a consumer could obtain a free credit report. section 216 directed these agencies and the securities and exchange commission to promulgate regulations for the disposal of consumer report information and records, whether they are stored in electronic or paper form. examples of consumer reports include credit reports, credit scores, reports businesses or individuals receive with information relating to employment background, check writing history, insurance claims, residential or tenant history, and medical history.ł under the children™s online privacy protection act (15 u.s.c. 65016506), the ftc is responsible for promulgating regulations (16 c.f.r. part 312) implementing the protections of the act. these protections require that operators of commercial web sites and online services directed to collect or knowingly collecting personal information from children under 13 must (1) notify parents of their information practices; (2) obtain veriable parental consent before collecting a child™s personal information; (3) give parents a choice as to whether their child™s information will be disclosed to third parties; (4) provide parents access to their child™s information; (5) let parents prevent further use of collected information; (6) not require a child to provide more information than is reasonably necessary to participate in an activity; and (7) maintain the condentiality, security, and integrity of the information.the rulemaking authority of the ftc described above illustrates a common relationship between statutory authority and regulation. the u.s. congress passes legislation that lays out the general issues and principles in question, but leaves it to a regulating agency to work out the details of how that legislation should be implemented. but this relationship is not the only possible one, and in some instances, congress has delegated extremely broad regulatory authority to an agency, thus making it the primary source of guidance on a major privacyrelated topic.a good example of this phenomenon is apparent in the privacyprotecting regulations of the health insurance portability and accountability act of 1996. legislators understood very well that the privacy of personal health information was a central issue for health insurance portability, but they were unable to reach agreement on the nature and scope of the appropriate privacy protections. thus, section 264 of hipaa directed the secretary of the department of health and human services (dhhs) to promulgate regulations on appropriate privacy standards (covering at least the rights that an individual who is a subject of individually identiable health information should have, the procedures that should be engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.146 engaging privacy and information technology in a digital ageestablished for the exercise of such rights, and the uses and disclosures of such information that should be authorized or required) if the u.s. congress did not pass appropriate privacy legislation within 3 years of hipaa™s enactment. this is indeed what happened, and the nal privacy rule was published in the federal register (65 fr 82462) on december 28, 2000. on august 14, 2002, the final modications to the privacy rule were published in the federal register.17in short, congress anticipated its possible inability to reach agreement on the contentious issue of health care privacy, and delegated to the dhhs secretary the regulatory authority to act in its stead.4.4 executive orders and presidential directivesas the chief executive, the president of the united states has considerable latitude to direct the activities of various executive branch agencies. some directives or executive orders have a bearing on privacy, as illustrated below.one example is executive order 13145, issued on february 8, 2000. this executive order prohibited the federal government and its agencies from using genetic testing in any employment decision, and specically forbids federal employers from requesting or requiring that employees undergo genetic tests of any kind. in addition, it forbids federal employers from using genetic information to classify employees in such a way that deprives them of advancement opportunities, such as promotion for overseas posts.a second example is executive order 13181, issued on december 20, 2000. this executive order declared as the policy of the government of the united states that law enforcement may not use protected health information concerning an individual that is discovered during the course of health oversight activities for unrelated civil, administrative, or criminal investigations of a nonhealth oversight matter, except when the balance of relevant factors weighs clearly in favor of its use.a third example is a presidential order issued in 2002 that authorized the u.s. national security agency to eavesdrop on americans and others inside the united states to search for evidence of terrorist activity under certain circumstances without the courtapproved warrants ordi17 for more information, see u.s. department of health and human services, ﬁmedical privacyšnational standards to protect the privacy of personal health information: background and general information,ﬂ available at http://www.hhs.gov/ocr/hipaa/bkgrnd.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 147narily required for domestic wiretapping.18 this presidential order is still classied.orders and directives such as these clearly have a potential for affecting the privacy interests of americans. but it is important to note that they are limited in at least three important ways.ł though they are authoritative statements of presidential direction, their implementation must be consistent with existing statutory law.ł executive orders have the force of law, but only with respect to executive branch agencies.ł executive orders have no direct impact or force on private sector entities, although because they change the behavior of government, they can have considerable indirect impact.upon signing a law, presidents often issue a signing statement that is published in the federal register and that documents the presidential interpretation of how the law should be construed. signing statements do not have the force of law, but if a president directs an agency to behave in a manner that is allegedly contravened by the law, or by some other law, only court action can force the agency to cease and desist.4.5 state perspectivesas one might expect within a federal system such as the u.s. system, legal protection of privacy varies vastly from state to statešre˚ecting what are often little more than anecdotal experiences that have triggered legislative safeguards. table 4.1 indicates the variation in state laws regarding privacy for the rst 16 states, listed alphabetically.such diversity is not inherently problematic; one recalls justice louis brandeis™s commendation for the role that unusually progressive states might play as ﬁlaboratoriesﬂ for reform and innovation. the problem in regard to privacy protection, however, is the inevitably broad reach across much (if not all) of the nation of especially restrictive measures, and the potentially heavy burdens of compliance for those business entities that serve clients and customers in many states.efforts to protect the privacy of sensitive (and even notsosensitive) nancial data illustrate the problem extremely well. in the mid to late 1990s, north dakota and minnesota each enacted uniquely protective measures, ostensibly to shield its own citizens from unwelcome sharing or disclosure of nancial information. it soon became apparent to insur18 james risen and eric lichtblau, ﬁbush lets u.s. spy on callers without courts,ﬂ new york times, december 16, 2005. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.148table 4.1 privacy laws by statestateacategoryusalakazarcacoctdedcflgahiiliniaksarrest recordsoxoxoxxxxxxxxxxoobank recordsxxxooxoxooxooxoxocable tvxooooxoxoxoooxooocomputer crimexxxxxxxxxoxxxxxxxcreditxooxoxoxxoxxoooxxcriminal justicexxxxxxxxxoxxxxxxxgovernment data banksxxxxoxxxxxxoxxxxxemploymentxoxooxoxxxxoxxoxoinsurancexooxoxoxoxxxoxooxmailing listsxooxoxoxxoxoxoxxxmedicalxxxxxxxxxxxxxxxxxmiscellaneousxooooxoxooxoxxxoopolygraph resultsxxxxxxoxxxoxxxoxoprivacy statutesxoxxoxooxoxxxxoooprivilegesoxxoooxxxooxooxooschool recordsxooxoxxxxoxooxoxosocial security numbersoooooooooooooooootax recordsxoxxooxoxooxxoooxtelephone solicitationxoxxxxxxooxxxxxxxtestingoooooooxooxoxooxowiretapsxxxxxxxxxxxxxxxxx aan x in indicates that the state has a privacy law relevant to the category indicated, although it does not indicate how effective or strong the law is. only the rst 16 states (in alphabetical order) are listed.source: data from http://www.epic.org/privacy/consumer/states.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 149ance and nancial service providers that the need for compliance with this exceptionally protective law went well beyond the state of its origin and initial reach. since north dakotans and minnesotans might well move to other states, while policy holders or customers from elsewhere would move to north dakota and minnesota, the costs of bringing the entire national business enterprise into compliance with the strictest standard eventually seemed less onerous than the incalculable costs of conning compliance to residents of the target state. what ensued was a novel kind of reverse gresham™s law, in which the most rigorous standard eventually shaped the norm, effectively forcing divergent standards to yield by default.congress could, of course, achieve uniformity in several ways. in a very few areasšpatent, copyright, and admiralty being the most familiaršthe constitution itself makes federal law exclusive and thus completely forestalls any possibility of variant regulation at other levels. but the exclusively federal eld is the rarity, and in most regulatory realms power is shared between national and state government until and unless congress or the federal courts declare otherwise.the most obvious means of setting a single national standard would be for congress itself to regulate the activity in question, and in so doing either declare that inconsistent state and local standards were being preempted, or establish that the federal norm was the exclusive mode of regulation, thus precluding even consistent action by state and local government. a less obvious but theoretically possible approach would be for congress to enter a regulatory area only to the extent necessary to limit or ensure uniformity in the standards that states and localities may set, but without creating its own federal regulatory systemšin other words, leaving the actual regulation to other levels of government, but at the same time ensuring a degree of uniformity by setting parameters and boundaries for the exercise of that authority by states and localities.there is one precedent for such action. in 1999, congress amended the driver™s privacy protection act (dppa) to forbid state departments of motor vehicles and law enforcement ofcials to sell or otherwise release personal information obtained in connection with any motor vehicle or license record without afrmative optin consent. the constitutionality of this law was challenged by a group of states that apparently wished to retain the revenue streams associated with the sale of such data.in 2000, the u.s. supreme court unanimously sustained the constitutionality of this act in reno v. condon, 528 u.s. 141 (2000). the dppa was found to be not only an appropriate exercise of congress™s power over interstate commerce, but also one that invaded no state powers protected by the ninth and tenth amendments.the condon decision was unusual and stands as one among a very engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.150 engaging privacy and information technology in a digital agefew decisions in the rehnquist court that sustains an act of congress imposing obligations on the states or limiting state power. by contrast, during the late 1980s and much of the 1990s the supreme court was generally unsympathetic to congressional initiatives in areas of state and local interest and authority. whereas previous courts would likely have had little trouble nding federal power under the commerce (or other) clause, the rehnquist court rejected on constitutional grounds a number of acts that seemed to be perfectly reasonable and appropriate exercises of federal power. two such decisions were one striking down federal laws that sought to ensure public school safety by requiring installation of metal detectors, and another that granted relief to women who had been victims of sexual assaults and wished to seek redress in federal courts. in these and a host of other situations in which the warren court and even the burger court would almost routinely have sustained the power of congress to act, the rehnquist court found federal power lacking under its view of article i of the constitution, and deferred to state power under the ninth and tenth amendments. although the justices were sharply divided in these cases, a clear majority consistently sided with the states throughout this decade.thus, the extent to which the condon decision indicates a willingness of the supreme court to uphold congressional preemption of state laws regarding privacy is unknown. and a new chief justicešjohn robertsšhas been recently sworn in, making predictions about future court action in this domain much more uncertain than they already were.finally, it should be noted that state laws can have national impact. the best such example is california™s sb1386 (sometimes known as the california security breach information act), which mandated the disclosure of compromises in the security of certain types of personal information. even though the law ostensibly affected only enterprises operating in california, that many businesses affected by the law have multistate operations has meant that residents of other states have also sometimes been notied when their personal information has been compromised. in addition, the passage of this law has spurred a number of other states to attempt the passage of similar legislation.19 (as this report is being written, congress is considering a law (h.r. 4127, the data accountability and trust act) to set uniform standards across the states for disclosure in the event of such breaches; as written, some proposals for this law would reduce notication and disclosure requirements for some states.)19 for additional discussion, see eric m. friedberg and michael f. mcgowan, lost backup tapes, stolen laptops and other tales of data breach woe, white paper from stroz friedberg, llc, washington, d.c., june 26, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 1514.6 international perspectives on privacy policyinterest in and concern about privacy as a legal and a policy matter are certainly not limited to the united states. a review of perspectives on privacy around the world (appendix b) suggests that the issues usually covered under the rubric of privacy in the united states are also evident in other western nations, although they tend to be couched in a language that avoids explicit reference to ﬁprivacyﬂ or closely related terms. instead, the term ﬁdata protectionﬂ seems to have gained broad popularity, especially in europe and, to a lesser extent, elsewhere, although the term ﬁdata privacyﬂ is becoming more prominent. a number of other nations also use terms such as ﬁpersonal integrityﬂ or ﬁinformation selfdetermination.ﬂu.s. perspectives on privacy rights are shaped by a view that tends to focus primarily on the benets of such rights for individuals as individuals: individuality, autonomy, dignity, emotional release, selfevaluation, and so on. although such concerns also characterize the debate in many other nations, the balance and emphases of these other debates are often different. for example, the german jurisprudential perspective emphasizes that the value of data privacy norms lies in their ability to secure the necessary conditions for active citizen participation in public life, in other words, to secure a ˚ourishing democracy, whereas this perspective is arguably underdeveloped in u.s. jurisprudence.finally, it is important to note that the united states does not protect privacy as extensively or as comprehensively as some other nations, notably the member states of the european union. this is best illustrated by the absence of comprehensive data privacy legislation regulating the u.s. private sector and the absence of an independent agency (data protection authority or privacy commissioner) to specically oversee regulation of data privacy matters. whether this absence re˚ects differences in the popular support for privacy in various nations is much less clear. for example, it can be attributable to differences in perceptions of the degree to which privacy is or will be threatenedšone might easily argue that the comprehensive nature of european data privacy regulation re˚ects traumas induced by relatively recent, rsthand experience of totalitarian oppression. or the u.s. approach might be due to skepticism about the value and appropriateness of government involvement in the social sphere.4.7 the impact of nonu.s. law on privacyin an increasingly globalized economy, it might be expected that the laws of foreign nations might have a privacy impact on u.s. citizens and businessesšand this is indeed the case. two examples will illustrate:engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.152 engaging privacy and information technology in a digital ageł in 1998, the european commission™s directive on data protection went into effect. this directive was intended to prohibit the transfer of personal data to noneuropean union nations that do not meet the european ﬁadequacyﬂ standard for privacy protection. however, differing approaches of the united states and the european union to protecting privacy might have hampered the ability of u.s. companies to engage in many transatlantic transactions.20 while some privacy advocates at the time had hoped that the directive would force the united states to move signicantly in the direction of the european approach to protecting privacy (i.e., in the direction of comprehensive privacy protection), the united states and the european union agreed on a ﬁsafe harborﬂ approach.21 under this approach, any u.s. company may selfcertify that it agrees to adhere to the safe harbor™s requirements, which are based in large measure on the fair information practices described in chapter 1. enforcement of the safe harbor takes place in the united states in accordance with u.s. law and is carried out primarily by the private sector, backed up as needed by government enforcement of the federal and state statutes prohibiting ﬁunfair and deceptiveﬂ trade practices. companies in certiable compliance with safe harbor requirements are deemed to meet the european ﬁadequacyﬂ standard.ł in 2004, yahoo! (more specically, its chinese subsidiary) provided chinese government authorities the computer ip address and other information that was used to link specic email messages to the email account of shi tao, a former chinese journalist. the informationšgenerally regarded as nonpublicšwas used to convict and sentence tao to 10 years in prison in 2004, for emailing groups in the united states about the return of chinese emigrants for the 15th anniversary of the tiananmen square incident.22 more recently, yahoo! has been accused of releasing information generally regarded as nonpublic from an online discussion group that led to the conviction of li zhi, a former civil servant, in december 2003, who is serving 8 years in prison for the charge of ﬁinciting sub20 as discussed in appendix b, the united states protects privacy by relying on a sectoral approach based on a mix of legislation, regulation, and selfregulation. the european union relies on comprehensive legislation that is, in part, based on the use of government data protection agencies, registration of databases containing personal information with those agencies, and in some instances prior approval of the data subject before any processing of that data may begin. 21 for more information, see http://www.export.gov/safeharbor.22 court documents, released by reporters without borders, reveal that the yahoo! subsidiary in hong kong supplied the information to the chinese authorities revealing the user™s identity. for a translated copy of the court verdict, see http://www.rsf.org/article.php3?idarticle=14884.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the legal landscape in the united states 153version.ﬂ23 yahoo! has declined to comment on these cases or to disclose how often it provides user information to chinese authorities. however, yahoo! has acknowledged that it lacks control over some operations since yahoo! china merged with alibaba.com, a chinese company that holds 60 percent of the company.24these examples barely scratch the surface of an extraordinarily complex and illdened international policy environment in which nonu.s. organizations and institutions have an impact on u.s. companies and policy. for many years, the organisation for economic cooperation and development was actively involved in the negotiation of guidelines for the management and protection of personal information that had become a substantial part of the transborder data ˚ows essential to international trade in information goods and services. although debates about trade became tangled up within erce ideological struggles about ﬁcultural imperialismﬂ and the new world information and communication order,25 ideological concerns were replaced to some degree by concerns about market power as the development of a more closely integrated european marketplace was thought to depend on more uniform policies regarding the treatment of personal information.in order to understand the development of privacy policies at the international level, it is important to understand the interests, strategies, and resources of different sorts of participants in the policy process. although traditional sources of power and in˚uence such as national governments and representatives from key missions and administrative agencies with interests and responsibility for national security and foreign trade have to be considered along with the more complex interests of transnational rms, it is also important to consider the role of the epistemic community of policy experts who are engaged in the elaboration of new ways of thinking about the international arena.26policy formation at the international level is also characterized by a considerable amount of negotiation, bargaining, and compromise among 23 hiawatha bray, ﬁyahoo said to aid china in 2003 subversion trial,ﬂ boston globe, february 9, 2006, available at http://www.boston.com/business/technology/articles/2006/02/09/yahoosaidtoaidchinain2003subversiontrial/.24 eric schonfeld, ﬁanalysis: yahoo™s china problem,ﬂ cnnmoney.com, february 8, 2006, available at http://money.cnn.com/2006/02/08/technology/yahoochinab20/.25 thomas l. mcphail, ﬁelectronic colonialism: the future of international broadcasting and communication,ﬂ sage library of social research, revised second edition, vol. 126, sage publications, 1987.26 jonathan d. aronson, ﬁthe evolution of global networks: the precarious balance between governments and markets,ﬂ pp. 241255 in eli noam and alex wolfson, eds., globalism and localism in telecommunications, elsevier science, 1997.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.154 engaging privacy and information technology in a digital agedifferent stakeholders. coalitions among business leaders facing similar limitations on their ability to make use of personal information for marketing purposes pooled their resources to support intensive lobbying efforts against the optin requirements that seemed likely in the european union in 1990.27 these business coalitions also sought and received support from their nations™ trade commissions because of a wellplaced concern about regulatory threats to the market in dataprocessing services. coalitions among regulators were also common.28 privacy and data protection commissioners met to develop strategies for preserving what they saw as important progress in the protection of privacy.one result of the participation of so many actors with such varied interests and resources was the development of highly complex policy instruments. unique and often contradictory policy perspectives continue to challenge policy advocates largely dependent on grants from foundations. global policies regulating the treatment of personal information as it moves across virtual borders raise important questions about national sovereignty and respect for policies re˚ecting cultural values and social history.29 the presumed need to identify the location of the jurisdiction from which an order is placed, or is to be delivered, in order to determine whether a particular transaction can be completed within the laws of that region raises a complex set of issues for supporters of autonomous choice.3027 priscilla m. regan, ﬁamerican business and the european data protection directive: lobbying strategies and tactics,ﬂ pp. 199216 in colin bennett and rebecca grant, eds., visions of privacy: policy choices for the digital age, university of toronto press, 1999.28 colin j. bennett and charles d. raab, the governance of privacy: policy instruments in global perspective, ashgate publishing, 2003.29 national research council, global networks and local values: a comparative look at germany and the united states, national academy press, washington, d.c., 2001.30 priscilla m. regan, ﬁ‚dry counties™ in cyberspace: governance and enforcement without geographic borders,ﬂ pp. 257276 in thomas leinbach and stanley brunn, eds., worlds of ecommerce: economic, geographical and social dimensions, john wiley & sons, 2001.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.1555the politics of privacy policy in the united statesprivacy policies are formulated in response to problems in the management of access to information about persons or their effects, or to images or impressions of people as may be derived from the analysis of data. but many factors affect the formulation of policy.5.1 the formulation of public policyprotection of privacy has been an objective of public policy for at least a century, especially for the legislative branch. when new york state™s highest court declined, in 1902, to create a cause of action for invasions of privacy, the legislature promptly intervened. the result of that intervention was, at that time, the most rigorous and farreaching of state privacy statutes, and remains among the strongest even to this day. new york has hardly been alone in responding to concerns about the status of personal privacy, and nearly all states provide such protection today, either by statute or by court decision. by the 1920s, protecting privacy had become a matter of federal policy as congress focused rst on making wiretapping unlawful.1although legislators have addressed privacy to a considerable extent, it is less clear that the legal safeguards for privacy that they have enacted 1 it is unclear today whether the legislation of the time re˚ected more a concern about the integrity of the burgeoning telecommunications system rather than a fear that wiretapping would imperil the privacy of individual conversations.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.156 engaging privacy and information technology in a digital agere˚ect political pressure from a public distressed in general about unwelcome exposure of their private lives. public concerns about privacy, and pressures for its protection, seem closely related to episodic ﬁhorror storiesﬂ about violations of privacy (at least violations perceived to be egregious). on an ongoing basis, scholars of public policy often view the development of policy as a struggle between interests, and the history of policy regarding privacy illustrates this point clearly. privacy is not pursued or defended by public policy makers in the united states as a fundamental right to be protected. instead it is framed as one of a number of interests that have to be weighed on the scales of social worth. as a result, the scope of privacy concerns has been narrowed to a limited array of individual and personal interests.for example, priscilla regan notes that public policy regulation can serve the interests of the nation or the society for the collective good. she underscores the distinction between privacy policy as a struggle over ideas and privacy policy as a struggle between interests.2 because the idea of privacy is so broad and complex as to defy specication, privacy policy has rarely been pursued on the basis of privacy as a fundamental value. unlike the values of ﬁcompetitionﬂ and ﬁefciencyﬂ that have emerged as compelling rationales for the pursuit of a broad range of policy outcomes, privacy policies have been far more narrowly drawn. some of those opposed to the extension or reinforcement of privacy rights have tended to argue that privacy was the enemy of efciency; respecting privacy imposed costs on actors and agents in ways that could not be justied in economic terms. this was nearly always the case when opponents of privacy restraint sought to justify the use of some new technology of surveillance that was supposed to enhance security and reduce fraud, waste, and abuse in the delivery of goods and services.3 from the perspective of business, opposition to measures to enhance individual privacy was often cast in terms of unnecessarily increasing the regulatory burden of compliance. because the value of economic efciency had emerged as the dominant rationale for policy choice in the decade between 1974 and 1984,4 much of the legislation that was presented as preserving privacy interests actually helped to normalize a set of routine institutional practices that narrowed the scope of privacy™s reach.5one way of framing the interests at stake is according to the distribu2 priscilla m. regan, legislating privacy: technology, social values, and public policy, university of north carolina press, 1995.3 david lyon, surveillance society: monitoring everyday life, open university press, 2001.4 regan identied seven bills passed in this decade that explicitly traded privacy interests against expected gains in efciency. see regan, legislating privacy, 1995, p. 88.5 see oscar h. gandy, jr., the panoptic sort: a political economy of personal information, westview press, 1994, pp. 209211, for a discussion of the video privacy protection act of 1998.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 157tions of costs and benets among the stakeholders involved in any policy issue. for example, james q. wilson distinguishes between ﬁmajoritarian,ﬂ ﬁentrepreneurial,ﬂ ﬁclient,ﬂ and ﬁinterest groupﬂ politics in terms of whether the costs and benets are broadly or narrowly distributed.6 in this framework, majoritarian politics describes outcomes in which both the costs and the benets are widely distributed. entrepreneurial politics describes outcomes in which the costs are concentrated, while the benets are widely distributed. in the case of client politics, the benets are concentrated while the costs are widely distributed. finally, in the case of interest group politics, both the costs and the benets are narrowly concentrated.7 expectations regarding the distribution of costs and benets help to determine the level of interest and involvement of stakeholders in the policy process. the mass media play a critical role in shaping the expectations of the general public about the ways in which the policies will affect their wellbeing. it is only in the case of interest group politics, where the benets and the costs are narrowly distributed, that public concerns about a particular policy outcome are dormant.theorists of policy change such as baumgartner and jones associate changes in u.s. political agendas within shifts in the legislative venues and evaluative orientations of policy entrepreneurs concerned about emergent and maturing technologies.8 understanding cyclical and even irregular patterns of change in public policy requires considerable attention to the role of organized interests that are able to focus their resources on committees and in other venues where their chance of success is higher. organized interests, especially those with a longstanding institutional claim on resources derived from existing government practice, tend to prefer to keep the discussion private, or limited to a manageable group of insiders.multiple jurisdictions also provide many venues for different stakeholders to pursue their interests. government policies affecting privacy are established at the administrative, legislative, and judicial levels in states, nations, and economic regions like the european union, as well as at the international level.9 the fact that these policies can vary quite substantially from jurisdiction to jurisdiction means that informationinten6 james q. wilson, ﬁthe politics of regulation,ﬂ pp. 35794 in james q. wilson, ed., the politics of regulation, basic books, new york, 1980.7 elizabeth e. bailey, ﬁthe evolving politics of telecommunications regulation,ﬂ pp. 379399 in roger noll and monroe price, eds., a communications cornucopia, brookings institution press, washington, d.c., 1998.8 frank baumgartner and bryan jones, agendas and instability in american politics, university of chicago press, 1993.9 colin j. bennett and charles d. raab, the governance of privacy: policy instruments in global perspective, ashgate publishing, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.158 engaging privacy and information technology in a digital agesive businesses and their trade associations have to invest considerable time, effort, and economic resources to ensure that their standards and practices conform to local regulations. they are also likely to be involved in coordinated attempts at modifying those policies, or negotiating special exceptions.10the large number of stakeholders leads to a proliferation of voices speaking on privacy issues in national and state councils. lawmakers not only hear from both sides of almost any privacy proposal but also receive potentially con˚icting counsel from organizations with nearly indistinguishable titles. while such a cacophony complicates the lawmaking process in almost any contentious area of public policy, the range of the dissonance in the privacy area adds a new dimension to the process.consistent with the view of privacy policy as a struggle between competing interests, efforts to protect privacy have not had much resonance with lawmakers seeking to broaden their electoral appeal. as recently as 1995, priscilla regan, drawing on her capitol hill experience as well as her extensive scholarship, concluded that ﬁprivacy issues do not provoke great electoral supportﬂ and so members of congress are ﬁunlikely to champion or adopt these issues because they believe there will be an electoral payoff.ﬂ11 indeed, noting that ﬁprivacy has not been an issue in the electoral arena at either the national or the state level,ﬂ regan nds no obvious ﬁexplanation for why a member of congress chooses to champion privacy issues.ﬂpoliticians, especially members of the house of representatives, who are almost continually in search of support for reelection, are careful to select issues that can attract press coverage. as an issue, privacy does not usually generate support and opposition along party lines, but instead nds bipartisan agreement through compromise and negotiation after extended periods of debate.12 indeed, in her review of the legislative history of major privacy bills passed before 1992, regan suggests that these issues were ﬁon the congressional agenda for years, if not decades, before congress passed legislation.ﬂ13 indeed, the candidate who runs on a privacy protection platform is a rarity, and the evidence is scarce at best that voters care enough to make elections turn on which candidate offers the boldest privacyprotective platform.10 priscilla m. regan, ﬁamerican business and the european data protection directorate: lobbying strategies and tactics,ﬂ pp. 217228 in c.j. bennett and r. grant, eds., visions of privacy: policy choices for the digital age, university of toronto press, 1999. 11 regan, legislating privacy, 1995. 12 bipartisanship, of course, does not mean that support is unanimous throughout the membership of each party. rather, it means that any given measure can appeal to a substantial number of members from both sides of the aisle.13 regan, legislating privacy, 1995. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 159this is not to say that legislators have never taken the lead in ghting for privacy protection. for example, a number of such leaders can be identied, including former senator sam ervin and former representative robert kastenmeier. senator ervin was especially dogged in his pursuit of the kind of statutory restraints on government data gathering that eventually became the privacy act of 1974.14 concerns about the excesses of the mccarthy era and the emergence of a ﬁnational security stateﬂ attracted the interest of representative kastenmeier to problems of surveillance.15 more recently, representatives ed markey (dmass.) and joe barton (rtex.) cooperated in 2001 to provide privacy protections in the grammleachbliley act, discussed further in chapter 6.the lack of abiding electoral concern about privacy can be explained in part by a deepseated popular ambivalence about just howšand how faršprivacy should be protected. david brin aptly observes that ﬁwhenever a con˚ict arises between privacy and accountability, people demand the former for themselves and the latter for everybody else.ﬂ16 such paradoxical views exist ﬁin almost every realm of modern life, from special prosecutors investigating the nances of political gures to worried parents demanding that lists of sex offenders be made public.ﬂ the framing and passage of broadly acceptable privacyenabling legislation have undoubtedly been impeded by the existence of such ambivalent views, and by the imposition of irreconcilable demands by constituents who are often unaware of the con˚ict they create by insisting that privacy be protected as far, but only as far, as necessary to serve subjective needs and interests.when privacy concerns do emerge on the public agenda, the development of privacy policy almost inevitably involves some con˚ict over the ﬁbalancingﬂ of competing interests and values.17 while privacy is not weightless, considerations of efciency, security, and global competitiveness hold considerable sway in the policy debate.moreover, contemporaneously with the rise of the internet as a pervasive technological substrate for much of society, policy makers have demonstrated in recent years an increasing tendency to think about pri14 david f. linowes, privacy in america: is your private life in the public eye?, university of illinois press, 1989, p. 2. regan suggests that ervin actually resisted labeling his concerns about government surveillance as ﬁprivacyﬂ concerns, preferring instead to emphasize the value of ﬁdue process.ﬂ15 regan, legislating privacy, 1995, p. 202.16 david brin, the transparent society: will technology force us to choose between privacy and freedom?, addisonwesley, 1998.17 charles d. raab, ﬁfrom balancing to steering: new directions for data protection,ﬂ pp. 6893 in colin bennett and rebecca grant, eds., visions of privacy: policy choices in the digital age, university of toronto press, 1999.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.160 engaging privacy and information technology in a digital agevacy in terms of technological systems, marketplace incentives, and even selfregulation rather than government regulation. such perspectives are consistent with growing skepticism among many elected representatives about government as a meaningful and positive in˚uence on the lives of citizens.among the most common criticisms of u.s. privacy policy making is its eclectic and piecemeal quality. instead of regulating from the top down after a comprehensive overview of privacy needs and concerns, as do most other western nations, the united states tends to address particular problems as they arise, thus moving from the bottom up.18 the resulting patchwork re˚ects little broad policy making, and much intuitive response to momentary concerns. there is little correlation, in consequence, between the importance or value of protecting certain elements of privacy (as might be determined with the benet of a comprehensive framework to prioritize different privacy concerns) and the degree to which u.s. laws do in fact protect those interests.a classic example of this patchwork is the video privacy protection act of 1998. during conrmation hearings over the eventually thwarted supreme court nomination of appeals court judge robert h. bork, a washington, d.c., weekly (the city paper) published a list of videotape titles the judge had recently borrowed from video rental stores. in the wave of popular indignation that followed the defeat of the nomination, congress easily enacted the video privacy protection act (vppa) of 1988, which bars retailers from selling or disclosing video rental records without a customer™s permission or a court order. as a result of this eclectic and selective response to a special perceived need, video borrower records have for nearly a decade been better protected than a wide range of arguably more sensitive and vital data, such as personal medical information.much the same could be said of the socalled buckley amendment (more formally the family educational rights and privacy act), adopted in the mid1970s in response to similar pressure. in that case, a few lessthanfullysatised recent university graduates found themselves in powerful staff positions on capitol hill and seized an opportunity to bar forever any dissemination of all but minimal information about college students to the news media, or for that matter to any but a tiny group of academic ofcials with an urgent need for access to such data.the result of legislative forays like those that produced the buckley 18 appendix b addresses the point from a comparative perspective. in addition, the national research council report global networks and local values (national academy press, washington, d.c., 2001) elaborates on the difference between u.s. and german perspectives on privacy regulation.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 161amendment and vppa is that certain types of informationšspecically college student records and video rental prolesšenjoy a highly elevated, though not altogether logical, level of protection, whereas much highly sensitive information remains far more vulnerable. regardless of the desirability or undesirability of these specic statutes, few features of the u.s. network of privacy protection could more fairly be faulted than its patchwork or piecemeal quality.as noted in the national research council report global networks and local values, ﬁin practice, the u.s. norm [of privacy protection] is a patchwork of legislation and court decisions arising from episodic scandals and political pressures from both industry and privacy advocates.ﬂ19 as a result, the report continues, ﬁhighly specialized solutions have been crafted for different technologies (e.g., statutory regimes specic to the protection of postal mail, email, and other internet communications) and for different subject areas.ﬂ although the united states might be credited with the development of privacy as an individual right,20 the legislative approach to the specication of this right, especially as it relates to the behavior of private rms, has been sectoral and piecemeal, rather than comprehensive.21 critics suggest that as a result of this sectoral emphasis, the interests of data users will be more clearly understood and appreciated than the interests of individuals or groups of data subjects.22the patchwork is further complicated by the fact that states are allowed to set higher standards for protecting privacy and may be more protective than national policy requiresšat least as long as doing so does not abridge due process or equal protection or violate any other federal constitutional guarantee. to phrase the point quite simply, the u.s. constitution and federal laws generally set a ˚oor but not a ceiling, so that state actions cannot fall below the ˚oor but may surpass the ceiling.a recent and quite apt example of this dynamic comes from the regulation of the ways in which nancial service providers secure the consent of their customers for the use and possible dissemination of certain personal information. federal law, for the most part, adopts an ﬁoptoutﬂ approach, under which banks and other providers must inform their customers of potential datasharing practices and can assume acquiescence from a customer™s silencešthat is, from the customer™s refusal to 19 national research council, global networks and local values, national academy press, washington, d.c., 2001, p. 141.20 irwin r. kramer, ﬁthe birth of privacy law: a century since warren and brandeis,ﬂ catholic university law review 39:703724, 1990.21 david h. flaherty, protecting privacy in surveillance societies, university of north carolina press, 1989.22 charles d. raab and colin j. bennett, ﬁthe distribution of privacy risks: who needs protection?,ﬂ the information society 14:263274, 1998.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.162 engaging privacy and information technology in a digital ageopt out by so informing the provider, as only 2 or 3 percent of customers have in fact done in response to such an invitation. if a single state wishes, however, to empower customers to a higher degree by requiring that they must afrmatively opt in before their consent to data sharing may be inferred, that is an option open to any state.to date, a number of states (alaska, california, vermont, connecticut, florida, illinois, north dakota) have required that banking and nancial services customers be invited to opt in. but even if only one state takes such a position, it effectively requires nancial service providers to treat their customers in that state very differently, and to make certain that they have evidence of opting in before any personal data are shared. such state action may, of course, be challenged on grounds other than due processšfor example, as a burden on interstate commerce or invasion of an area in which uniformity is essential even though congress has not so mandatedšbut such challenges rarely succeed, since the federal courts often (or even mostly) defer to the judgment of state legislatures on the needs of their citizens.5.2 public opinion and the role of privacy advocatespublic opinion is one obvious and important in˚uence on the legislative formulation of many aspects of public policy, and privacy is no exception. a review of public opinion over the last decade performed for the committee suggests the following generalizations:23ł the public expresses considerable concern over privacy; this concern appears to have increased over time. moreover, much of the u.s. public appears to believe that privacy is a fundamental right that they ought to enjoy, and this belief seems to be independent of perceptions of threat.ł people are not concerned about privacy in general; they are concerned about protecting the privacy of sensitive information about themselves. thus, for example, they are quite willing to agree to contact tracing in the case of aids patients, and they are ready to dene aids as a community health rather than a privacy issue. most people are not hivpositive, and they are more concerned about the risks of being infected than about the privacy interests of patients. at the same time, most people are unwilling to have medical information about themselves disclosed without their permission, even when the information does not identify them 23 amy corning and eleanor singer, ﬁsurvey of u.s. privacy attitudes,ﬂ survey research center, university of michigan, 2003, a paper written under contract to the national research council for this project.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 163by name. in that situation, the privacy value of the information outweighs the juxtaposed social value of ﬁresearch.ﬂł public opinion about privacy is not well crystallized; people tend to be highly responsive to the way questions are framed. for example, public support for individual monitoring or surveillance measures can be very high, particularly when questions emphasize the need to combat terrorism. respondents also generally believe that government will use its powers appropriately. yet when respondents are reminded that government powers may be abused, or that even properly used powers may reduce the rights and freedoms people enjoy, they appear to be quite concerned about such possibilities.ł public opinion is responsive to salient events. for example, alan westin and others have explored the ways in which public attention to privacy concerns has tended to rise and fall in response to a number of changes in the policy environment.24 these changes included both longterm trends in the organization of the economy as well as shortterm disruptions marked by critical events, such as those on september 11, 2001. immediately after the september 11 attacks, the u.s. public expressed an increase in support for public policy measures with negative implications for privacy. however, this support has gradually waned in the attackfree years afterward. similarly, public concerns about privacy jumped in the mid1970s in the wake of the watergate scandal and the church committee report, but tended downward in subsequent years.25ł public opinion is also responsive to technological developments. for example, concerns have risen with technology developments that make it easier, faster, and cheaper to store, process, and exchange vast amounts of individuallevel data, and with the advent of new and expanding techniques for acquiring information about individuals such as data mining to link consumer purchases with demographic information and new techniques of surveillance.ł despite manifest concerns about privacy, public opinion about privacy is generally not well informed. because of this, and perhaps for other reasons, individuals do not generally take actions to protect their privacy even though they are highly concerned about personal privacy (e.g., they return warranty cards lled out with personal information even though such information is not needed to validate the warranty). nevertheless, 24 alan westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(1):431453, 2003.25 warrantless fbi electronic surveillance, book iii of the final report of the select committee to study governmental operations with respect to intelligence activities, united states senate, u.s. government printing ofce, washington, d.c., april 23, 1976. (the select committee is popularly known as the church committee, after its chair, frank church, senator from idaho.)engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.164 engaging privacy and information technology in a digital agetheir perspectives on privacy may well in˚uence their opinions in other domains and even possibly their behavior. concerns about privacy and condentiality do affect people™s participation in surveys, and in particular the u.s. decennial census. specically, singer et al. found that concerns about privacy and condentiality have a small but statistically signicant effect on response rates.26ł consumers are often willing to trade away their control over their personal information in return for some benet, which may be small in absolute terms. some analysts believe that such behavior is the result of a rational approach on the part of the public to privacy issues, which allegedly weighs the privacy risks against the potential benets of providing information. others believe that such behavior results from the average consumer being simply unaware of the ways in which transactiongenerated information is gathered and used by businesses on the web and in other places.27although public opinion about privacy is shaped by myriad actors that affect the policymaking process (including in particular organized interest groups and policy entrepreneurs),28 privacy advocacy groups and the mass media are among the most important. westin™s analysis of change in the privacy agenda notes the very important role that publicity or media coverage has played in the policy process, and emergent theory suggests that it is when the policy debate moves into the public sphere that the outcomes of the process are less certain.29public concern and a legislative response are often activated in response to the efforts of activist organizations concerned with technology, media, and civil liberties more generally.30 the press and these activist organizations help to raise public awareness about the extent to which many of the business practices that the public assumed were against the 26 eleanor singer, nancy a. mathiowetz, and mick p. couper, ﬁthe role of privacy and condentiality as factors in response to the 1990 census,ﬂ public opinion quarterly 57(4):465482; and corning and singer, ﬁsurvey of u.s. privacy attitudes,ﬂ 2003.27 oscar h. gandy, ﬁpublic opinion surveys and the formation of privacy policy,ﬂ journal of social issues 59(2):283299, 2003; priscilla m. regan, ﬁfrom privacy rights to privacy protection: congressional formulation of online privacy policy,ﬂ in c.c. campbell and j.f. stack, jr., eds., congress and the politics of emerging rights, blackwell publishing, lanham, md., 2002; and corning and singer, ﬁsurvey of u.s. privacy attitudes,ﬂ 2003.28 bennett and raab, the governance of privacy, 2003, pp. 171183.29 bruce berger, ﬁprivate issues and public policy: locating the corporate agenda in agendasetting theory,ﬂ journal of public relations research 13(2):91126, 2001.30 alan f. westin, ﬁsocial and political dimensions of privacy,ﬂ journal of social issues 59(2):431453, 2003; see also gandy, ﬁpublic opinion surveys and the formation of privacy policy,ﬂ 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 165law are in fact the behavioral norm31 and alert citizens to the fact that their privacy rights (e.g., those granted under the privacy act) may have been infringed. members of public interest groups, or outsiders to the debate, play a key role in ﬁtaking the discussion publicﬂ by amplifying public concerns about institutional practices that they oppose.a number of public interest organizations have established a signicant presence within the policy environment as supporters of what they dene as the public interest in privacy, and a reasonable argument can be made to suggest that very little in the way of regulatory proprivacy policy would exist if it were not for the efforts of privacy advocates.32general organizations like the american civil liberties union (aclu) have long been active in pressing both in court and in lawmaking and regulatory bodies for protection of a range of personal freedoms, privacy among them. the aclu™s concerns continue unabated, indeed intensied, especially in the period after september 11, 2001, and other broad mission organizations have now entered the fray, including some that have found common ground with the aclu on privacy issues regarding government access to personal information despite being in opposite corners in many other areas.the most dramatic change in public advocacy groups is that, within the past decade or less, the eld has now become far more crowded by the entry of a host of in˚uential specialized groups, such as the electronic frontier foundation, the electronic privacy information center, americans for computer privacy, the online privacy alliance, the center for democracy and technology, and the privacy rights clearinghouse. a number of these organizations emerged into prominence during what alan westin identies as the ﬁthird era of privacy development.ﬂthese organizations attempt to in˚uence the policy process through a variety of means, including the mobilization of public opinion. policy advocates attempt to raise public awareness and concern about privacy by supplying sympathetic reporters and columnists with examples of corporate or government malfeasance, or with references to the ﬁhorror storiesﬂ of individuals who have been the direct or indirect victims of privacy invasion.33 these stories help to raise the level of concern that is then re˚ected in the periodic surveys of public opinion that get reported 31 joseph turow, ﬁamericans and online privacy: the system is broken,ﬂ a report from the annenberg public policy center of the university of pennsylvania, philadelphia, 2003.32 bennett and raab, the governance of privacy, 2003, pp. 4243.33 timothy e. cook, making laws and making news: media strategies in the u.s. house of representatives, brookings institution, washington, d.c., 1989.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.166 engaging privacy and information technology in a digital agein the press34 and referred to in testimony in legislative hearings on privacy policy.35privacy advocates play an important role in the framing of privacy issues. this framing is a strategic activity oriented toward nding the best way to mobilize support or opposition. privacy advocates have followed the general trend in policy rhetoric away from a discourse of ﬁrightsﬂ toward a more instrumentalist framework in support of developing protections for valued interests, and the avoidance of measurable harm.36 some argue that this shift from rights to interests re˚ects a larger shift in policy discourse from talk about citizens and moral rights to talk about consumers and the performance of markets.37corporate strategies for addressing public opinion differ somewhat from those of public interest organizations in that rms within informationintensive industries can afford to sponsor opinion surveys that are directly relevant to emerging policy deliberations. for example, privacyrelated surveys sponsored by equifax not only enjoyed a high degree of visibility in the press but also were cited in legislative testimony more often than surveys by any other sources.38finally, surveys by independent sources, such as the pew internet and american life project, reinforce the general conclusion that the public would prefer the presumption of privacy online at the same time that they express a concern about business practices that challenge that presumption.395.3 the role of reportsthe position of privacy on the legislative agenda is often established in response to the release of a special investigative report by a government 34 timothy e. cook, governing with the news: the news media as a political institution, university of chicago press, 1998.35 gandy, ﬁpublic opinion surveys and the formation of privacy policy,ﬂ 2003.36 priscilla m. regan, ﬁfrom privacy rights to privacy protection: congressional formulation of online privacy policy,ﬂ pp. 4563 in colton campbell and john stack, eds., congress and the politics of emerging rights, rowman and littleeld publishers, 2002.37 oscar h. gandy, jr., with the assistance of francesca wellings, ﬁthe great frame robbery: the strategic use of public opinion in the formation of media policy,ﬂ report to the ford foundation, 2003. see also simon g. davies, ﬁreengineering the right to privacy: how privacy has been transformed from a right to a commodity,ﬂ pp. 143165 in philip agre and marc rotenberg, eds., technology and privacy: the new landscape, mit press, cambridge, mass.,1997.38 gandy, ﬁpublic opinion surveys and the formation of privacy policy,ﬂ 2003, p. 292.39 gandy, ﬁpublic opinion surveys and the formation of privacy policy,ﬂ 2003; regan, ﬁfrom privacy rights to privacy protection,ﬂ 2002; and corning and singer, ﬁsurvey of u.s. privacy attitudes,ﬂ 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 167agency, a special task force, a policy center, or an independent commission established with support from foundations or private sector coalitions. a substantial increase in apparent public concern occurred during the 1960s, driven in part by the appearance of such ominous studies as alan westin™s privacy and freedom (1969), jerry rosenberg™s the death of privacy (1969), and arthur miller™s the assault on privacy (1971).reports can lay the groundwork for the passage of legislation. in each of the three policy phases identied by westin, an in˚uential report established the basis for a signicant policy response. in the rst phase, between 1960 and 1980, a report from the national academy of sciences titled databanks in a free society: computers, recordkeeping and privacy (box 5.1) was followed by a report from an advisory committee to the department of health, education, and welfare that proposed the very in˚uential framework on fair information practices (fip) that was later adopted by the organisation for economic cooperation and development.40 the watergate scandal and related concerns about the abuses of civil liberties by elements within the intelligence community led to the establishment of a special senate committee headed by frank church. the report generated by the farranging investigation of this committee41 helped to support the passage of the foreign intelligence surveillance act (1978),42 the right to financial privacy act (1978), and the privacy protection act (1980) as an effort to establish more meaningful boundaries around the government™s intelligence activities.although westin describes the years between 1980 and 1989 as a period of relative calm, a series of reports by the ofce of technology assessment and the general accounting ofce focused on the use of computers and information technology within the federal government that raised important privacy concerns. the computer matching and privacy protection act and the employee polygraph protection act of 1988 were the results of those studies.43in the third phase (19902002) described by westin it was not a single investigation or comprehensive report that sparked a legislative response but instead what westin characterizes as a ﬁstream of national surveysﬂ that focused on a rise in privacy concerns among the public.44 for example, content analyses designed to assess the presence and quality of the privacy notices of rms engaged in ecommerce were the result of a 40 regan, legislating privacy, 1995.41 warrantless fbi electronic surveillance, select committee to study governmental operations with respect to intelligence activities, 1976.42 whiteld dife and susan landau, privacy on the line: the politics of wiretapping and encryption, mit press, cambridge, mass., 1998.43 regan, legislating privacy, 1995.44 westin, ﬁsocial and political dimensions of privacy,ﬂ 2003, p. 444.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.168 engaging privacy and information technology in a digital agebox 5.1 databanks in a free society in the early 1970s, professors alan westin and michael baker directed a study investigating how the increasing use of computers was affecting u.s. recordkeeping processes and what impact the resulting largescale collections of data (or databanks) might have on privacy, civil liberties, and due process. conducted under the aegis of the national academy of sciences™ computer science and engineering board, the study was prompted byšamong other thingsšgrowing concerns about the increasing feasibility and efciency of collecting and sharing large volumes of personal information, things made much simpler by the use of computer technology. the study, which included more than 50 project staff site visits to organizations with recordkeeping operations, culminated in a nal report written by westin and baker, databanks in a free society: computers, recordkeeping and privacy.1 the report had ve major sections: (1) a brief contextsetting discussion of computers and privacy concepts; (2) proles of the recordkeeping practices of 14 organizations from both the public and the private sector, including descriptions of organizational recordkeeping practices before the application of computer technology, as well as information on the ways that computers were affecting or changing their recordkeeping practices at that time; (3) presentation of the principal ndings from the site visits; (4) a discussion of how organizational, legal, and sociopolitical factors affect the deployment of computer technology; and (5) a discussion of public policy issues in light of the report™s ndings and forecasts, including several priority areas for civic action. the report described a ﬁprofound public misunderstandingﬂ about the effects of using computers in largescale recordkeeping systems and suggested that u.s. public policy, legislation, and regulation (at that time) had not kept pace with the rapid spread of computer technology and growing public concern. the report also identied a number of policy areas deserving of higher priority by courts and legislaturesšfor example, citizens™ rights to see and contest the contents of their own records; rules for condentiality and data sharing; limitations on the unnecessary collection of data; technological safeguards for information systems; and the use of social security numbers as universal identiers. the report went on to suggest that the thenpresent 1970s was the right time for lawmakers to address many of the public policy, civil liberties, and due process issues being brought to light by changing recordkeeping technology. the report has in˚uenced much of the privacy work that has followed it and has been cited extensively, no doubt also informing the policy debate leading up to the passage of the privacy act of 1974 (5 u.s.c. section 552a).1alan f. westin and michael a. baker, databanks in a free society: computers, recordkeeping and privacy, quadrangle books, new york, 1972. additional commentary can be found in alan f. westin and michael a. baker, ﬁdatabanks in a free society,ﬂ acm sigcas computers and society 4(1):2529, 1973.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 169renewed activism at the federal trade commission (ftc). the children™s online privacy protection act of 1998 was the major legislative result of this assessment. regan suggests that the bill received overwhelming legislative support because of the unusual strength of a broadbased privacy coalition, sustained attention to the issue in the press, and a wellreceived report from the ftc on the inadequacy of business efforts at selfregulation.45finally, the discontinuity in the privacy policy environment since september 11, 2001, has been evident in the nature and tone of a number of in˚uential reports released in the aftermath. a primary focus of these reports has been the inability of the u.s. government to ﬁconnect the dotsﬂ that might indicate a terrorist operation in planning or preparation, and it is not surprising that they have emphasized the importance of improving the government™s information collection and analytic capabilities. for example, a special task force organized by the markle foundation argued forcefully for the accelerated development of the government™s capacity to gather, process, and interpret information from sources and with means that had previously been barred by law.46 the 911 commission emphasized the key role of information and intelligence in preventing future terrorist actions in the united states and the importance of sharing information among appropriate agencies.47though the ultimate outcomes remain to be seen, reports cast in such terms may well help to tip the scales toward greater collection, consolidation, and sharing of personal information than had been considered reasonable, appropriate, or just in the past. indeed, the core fundamentals of the fair information practices that emphasize the minimization of information gathering and limitation of the use of information to the purposes for which it was originally gathered are largely incompatible with the fundamental principles of intelligence analysis, which include notions of collecting everything just in case something might be useful and using any information that might be available.45 regan, ﬁfrom privacy rights to privacy protection,ﬂ 2002, p. 58.46 freedom in the information age, a report of the markle foundation task force, october 2002; creating a trusted network for homeland security, second report of the markle foundation task force, december 2003; mobilizing information to prevent terrorism: accelerating development of a trusted information sharing environment, third report of the markle foundation task force, july 2006.47 national commission on terrorist attacks upon the united states, the 9/11 commission report, 2004, available at http://www.911commission.gov/report/911report.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.170 engaging privacy and information technology in a digital age5.4 judicial decisionsperiodically we are reminded of the special benet we expect to derive from the separation of legislative, administrative, and judicial powers.48 yet it is clear that the independent decisions and pronouncements of jurists have an enormous in˚uence on the nature of statutory bars and constitutional limits on the actions of public and private actors.it is difcult to characterize the development of privacy policies through the courts as the same sort of process that is seen with regard to federal and state legislatures. still, the courts have been the focus of political action involving privacy advocates as well as organized interests in search of relief from a statutorily enforced constraint. public opinion can be expressed in many different ways, ranging from demonstrations in front of the supreme court to ﬁfriends of the courtﬂ amicus briefs, although the u.s. judiciary has long enjoyed relative independence from the vagaries of public opinion. nevertheless, some believe that public opinion can at the very least pressure members of the judiciary to provide extended rationales for decisions that appear to con˚ict with popular views.49it is also difcult to characterize the interactions between legal scholars who engage in extended debates over the meaning and importance of legislative and judicial activities that help to determine the legal status of privacy as a right and abuses as actionable torts. this difculty extends to the efforts of authoritative bodies, such as the american law institute, that have codied the ﬁright of privacyﬂ in successive restatement(s) of torts.50the action of the courts is also important to consider because of their corrective function in the face of executive branch opposition or indifference to the privacy agenda. such opposition or indifference is rarely manifested in declaratory policy by responsible administration ofcials but can be seen in a lack of compliance with fair information practices. under such circumstances, it is generally only the courts that can induce the agency or agencies involved to comply, and individual citizens and privacy advocates have had to sue government agencies in order to ensure that the rights of privacy established under the privacy act have meaning in practice.5148 jurgen habermas, between facts and norms: contributions to a discourse theory of law and democracy, translated by william rehg, mit press, cambridge, mass., 1998.49 habermas, between facts and norms, 1998, p. 442.50 an initial restatement was published in 1937, but the identication of four separate but ultimately unequal torts was published in 1977, adding weight to the suggestions along these lines offered by william prosser in 1960 (cal. l. rev. 48:383).51 flaherty, protecting privacy in surveillance societies, 1989, p. 315.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 171individual petitioners in search of relief or compensation for the harms visited upon them by others contribute to the development of the body of laws that are recognized as the torts of privacy. individuals in pursuit of their own interests have been joined from time to time by ﬁfriends of the courtﬂ who argue in support of more general principles of law. these advocates may also intervene in the development of case law through their active pursuit of the interests of a broad class of citizens whom they claim to represent. they may act as members of a special interest coalition to challenge the actions of an administrative agency.it is when those decisions reach the supreme court that the political nature of the process becomes more clear. because there are few restraints on the power of the justices to pursue their own ideological perspectives in supporting or opposing the decisions of their colleagues on the court, the appointment of judges to the supreme court is a highly political act. for example, privacy advocate robert ellis smith has argued that the appointment of william rehnquist to the court came just in time for him to demonstrate the extent of his opposition to a privacy agenda that had only been hinted at by his testimony before the senate on presidential powers.52 somewhat ironically, concerns about the private lives of some nominees to the court have gured prominently in their review.53although political debate addresses one or another competing values, it is rare that the political debate explicitly addresses tradeoffs. explicit discussion of tradeoffs does often take place during judicial review, where tensions between competing values, such as those between privacy and the freedom of speech, can be made explicit. it is also here that the almost metaphysical ﬁbalancingﬂ among incommensurable values is thought to take place.545.5 the formulation of corporate policywhile administrative, legislative, and judicial processes are largely open to public scrutiny, the deliberations of business and other private organizations tend to be more hidden behind a wall of proprietary interest.55 as a result, most individuals are relatively uninformed about the 52 rehnquist™s testimony before the senate judiciary subcommittee on constitutional rights is discussed by robert ellis smith, ben franklin™s web site: privacy and curiosity from plymouth rock to the internet, privacy journal, providence, r.i., 2000, pp. 263275.53 the cases of robert bork and clarence thomas are especially relevant because of the privacy concerns that were raised during their consideration.54 cass sunstein, ﬁincommensurability and valuation in law,ﬂ pp. 70107 in c. sunstein, ed., free markets and social justice, oxford university press, 1997.55 h. jeff smith, managing privacy: information technology and corporate america, university of north carolina press, 1994.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.172 engaging privacy and information technology in a digital ageways in which corporate policies affecting privacy are brought into being.private rms, especially those that do business with individual consumers, have always had a privacy policy of one sort or another, even if the policy was implied by routine practice rather than explicitly stated. however, in recent years more rms are establishing formal policies and informing consumers of the nature of those policies than was common in the past. firms within informationintensive (and therefore privacysensitive) businesses such as insurance, health care, nance, telecommunications, and direct marketing to consumers are more likely than other rms to establish a set of formal policies governing the collection and use of personal information.56 the establishment and posting of privacy policies by rms doing business over the internet has become a standard business practice, and the lack of a published policy has become an exception.these policies are often based on guidelines developed by membership associations representing the sectoral interests of rms within a particular industry. trade associations, such as the direct marketing association, often develop and publish a set of standard practices or codes of ethics that members are expected to honor.two privacyrelated organizations are also in˚uential in shaping corporate privacy policies. one organization is privacy & american business, which is an activity of the nonprot center for social & legal research, a nonprot, nonpartisan public policy think tank exploring u.s. and global issues of consumer and employee privacy and data protection. launched by alan westin in 1993 as a ﬁprivacysensitive but businessfriendlyﬂ organization to provide information useful to businesses about privacy,57 it began training and certifying corporate privacy ofcers in 2000. a second organization, the international association of privacy professionals, offers the certied information privacy professional credentialing program and a variety of information resources (newsletters, conferences, discussion forums, and so on).58firms within industrial sectors that have traditionally been the target of government oversight are more likely than rms in other sectors to have established their own privacy policiesšnancial services and health care are two of the most obvious, and privacy efforts in these areas have been driven legislatively with the grammleachbliley act of 1999 for the former and the health insurance portability and accountability act of 1996 for the latter. firms in other business sectors tend not to develop 56 gandy, the panoptic sort, 1993.57 westin, ﬁsocial and political dimensions of privacy,ﬂ 2003, p. 443. more information on privacy and u.s. business can be found at http://www.pandab.org/.58 for more information on the iapp, see http://www.privacyassociation.org.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.the politics of privacy policy in the united states 173privacy policies until the weight of public opinion demands a response, either from them or from the government.59 the threat of government regulation of information practices that have aroused public anger and concern often provides an especially powerful incentive for rms to develop their own versions of ﬁfair information practices.ﬂon the basis of his study of a number of rms within privacyintensive lines of business, smith identied a characteristic ﬁpolicymaking cycleﬂ that moves through a period of rudderless ﬁdriftﬂ that is disrupted by some form of ﬁexternal threatﬂ that activates a number of ﬁreactive responsesﬂ at different levels of the organization.60on occasion, the external threat that an informationintensive rm is forced to respond to is a class action suit, such as the one led against doubleclick for its use of cookies to develop proles of individuals™ navigation of the web.61 on other occasions the threat to current or proposed business practices comes from competitors that claim proprietary rights to customer information. on a number of occasions retailers and direct marketers have challenged the right of telephone companies or credit card rms to make use of transactiongenerated customer information for their own business purposes.62con˚icts within the corporate policy environment re˚ect both strategic interests as well as concerns about ethical standards of good business practice. these con˚icts represent constraints on the ability of corporate actors to develop a comprehensive position on the privacy rights of employees, consumers, and members of the public at large.6359 smith, managing privacy, 1994.60 smith, managing privacy, 1994, pp. 8385.61 doubleclick inc. privacy litigation, case no. 00civ0641, 154 f. supp. 2d 497 (s.d. n.y. 2001).62 smith, managing privacy, 1994, pp. 184204.63 oscar h. gandy, jr., ﬁdividing practices: segmentation and targeting in the emerging public sphere,ﬂ pp. 141159 in w. bennett and r. entman, eds., mediated politics: communication in the future of democracy, cambridge university press, 2001.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.175part iiiprivacy in contextchapters 25 sketch out the intellectual tools with which the committee addresses privacy in specic contexts. as noted in chapter 1, privacy in the abstract is an illdened concept. however, privacy in specic contexts is much easier to dene and talk about.chapter 6 (ﬁprivacy and organizationsﬂ) discusses how organizations of various kinds use personal information and looks at some of the implications for privacy of such use. in particular, chapter 6 focuses on the education sector (both k12 and university), nancial institutions, retail establishments, data brokers and aggregators, nonprot institutions and charities, mass media and publishing companies, and statistical and research agencies. the diversity of these sectors suggests that the interaction of technology and privacy is not an issue that can be limited to only some isolated areas of our society. what this quick look at various sectors of society makes clear is that it is often not the gathering of information itself that is perceived as a violation of privacy, but rather a specic use of that information. in addition, a number of generic questions are suggested by the privacy issues these domains raise, questions that set the stage for a more detailed analysis of three important sectors: health care, libraries, and law enforcement and national security.chapter 7 (ﬁhealth and medical privacyﬂ) notes the importance of personal information for providing effective health care, and it describes four approaches for protecting such information: industry selfregulation, legislation and regulation, consumer/patient awareness and selfhelp, and ofcial advocacy. the chapter also notes that issues related to the engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.176 engaging privacy and information technology in a digital ageprivacy of health information will become more salient and important as electronic medical records become more widely deployed.chapter 8 (ﬁlibraries and privacyﬂ) addresses the long tradition of sensitivity to privacy issues in the library community. in addition, the library community has been an early adopter of information technology as a way of furthering its mission, and thus the impacts of technological change have manifested themselves very clearly in the library context. thus, many of the most basic questions about policy can be seen in libraries and among librarians.chapter 9 (ﬁprivacy, law enforcement, and national securityﬂ) addresses some of the starkest polarities in the privacy debate. since the terrorist attacks on september 11, 2001, some of the loudest arguments have been heard about the appropriate balance between counterterrorism efforts and privacy. although this is not a new tension, new information technologies make it possible for privacy to be eroded far more extensively than ever before. chapter 9 identies a number of reasons that citizens might be concerned about privacy in a law enforcement/national security context. first, these individuals may be concerned that such information might be abused. second, government knowledge about certain activities often has a chilling effect on individuals™ participation in such activities, even if such activities are entirely legal. third, many individuals do not want government authorities to collect personal information simply on the theory that such collection raises their proles and makes it more likely that they might be erroneously singled out in some manner to their detriment even if they have done nothing illegal.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.1776privacy and organizationsprivacy is an issue in many sectors of society. this report addresses privacy concerns in depth in the areas of health care (chapter 7), libraries (chapter 8), and law enforcement and national security (chapter 9). however, tensions between the access to information that technology makes possible and the privacy of the individual are not restricted to those clearly sensitive areas. in recent years, technology has transformed organizations and institutional practice across the board. our lives are intimately tied to organizations and institutions that gather, collate, and use information about us. whether those organizations are forprot corporations, educational institutions, media and content providers, or notforprot organizations, they all gather, store, and use information about their customers, users, and clients.this chapter presents a brief overview of several institutional sectors and their use of information and information technology particularly as that use relates to the privacy of the individuals involved. it points out some of the difcult tradeoffs required in applying the technology and shows how concerns about privacy can arise even when the technology user™s intent is to help the customer or client. the purpose of this chapter is not to examine any of the areas in depth or to solve any of the problems being discussed, but rather to indicate the difculty of sorting them out and addressing them even when it would seem that answers should be easy to nd.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.178 engaging privacy and information technology in a digital age6.1 institutional use of informationinformation is an enabler for modern businesses and other institutions. that technology allows increasing amounts of information to be brought to bear raises the possibility that decision making can be improved.1 for example, an insurance company can use more and better information about customers as a basis for improving the judgments it makes about risks. a retail rm can use more and better information about customers to target advertising to those who are most likely to respond to it. businesses and organizations that know more about their customers are better able to offer enhanced services, or even completely new services.at the same time, the personal information collected about customers can be used for many different purposes, and information that was initially gathered for a benign purpose can be used in different ways for other purposesšsometimes with undesirable or inappropriate results. for example, information gathered to study the correlations between the nancial wellbeing of residents and their place of residence can be used for redlining by lenders, that is, denying nancial services to people based solely on the shared attribute of where they live, rather than a full consideration of their individual situation. information gathered to allow updating people on new therapies can be misused in the marketing of antidepressants. the same techniques that can be used to offer higher levels of service can also be used to target products to particularly susceptible individuals, to generate and send larger quantities of both electronic and physical junk mail, or to inappropriately deny nancial or other kinds of services to individuals based on their place of residence, their ethnicity, or a host of other factors that are only weakly correlated, if at all, with increased risk.a key aspect of the use of information by businesses involves the practice of record linkage, or in other words linking databases on individuals collected for apparently unrelated purposes. for example, a small amount of information collected at the drugstore about your purchase can become quite valuable to businesses if linked to your medical records, which contain much more information.as a point of departure, consider the issue of privacy as it relates 1 of course, technologybased presentations of information can hide inadequacies in that information. beyond the dangers of drowning in the data, the information age offers an abundance of unsubstantiated theories and bogus data, and unquestioning faith in ﬁthe computer that said soﬂ has been the downfall of many a decision maker. data entries and means of analyzing these are not given in nature but re˚ect human decisions at a multitude of levels. interesting though these considerations are, they are unfortunately outside the scope of this report.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 179to businesses linking records on their customers. using the anchoring vignette approach described in section 2.4 (see box 2.2), a possible survey question might be, how much do businesses respect [your/ﬁname™sﬂ] privacy? here are a number of possible vignettes:1. [jerry] signs up for an account at the local video store. the rental record is shared with the afliated video store in a neighboring city.2. [suzanne] signs up for an account at the local video store. the store shares her rental record with the afliated local music store, which begins to send [suzanne] coupons for soundtrack cds of movies that she has rented.3. [roderick] sees a doctor to treat an illness. the doctor calls in the prescription to the pharmacy via a shared database. [roderick] begins to receive advertisements from the pharmacy for drugs that treat his illness.4. [anne™s] bank shares information about its customers™ income and spending habits, including those of [anne], with its investment division. [anne] now regularly receives investment advertisements related to her recent purchases.5. a parent company creates a database with consumer information obtained from its subsidiary companies. the database contains information on people™s spending habits at grocery stores, cable tv usage, telephone calls, and the internet surng of many consumers, including [marie]. the company offers this information for free on its web site, although in a deidentied form.as indicated in the above vignette, information originally collected for one reason can be used for many different reasonsša practice known as repurposing. individuals may be unaware of how their information is used or what the ne print they supposedly have agreed to actually means.2 the information collector may be disingenuous in describing how information will be used. information may be fraudulently obtained (as in cases of identity theft) and used for purposes clearly unanticipated by its original provider. and, in many instances, a new use for information occurs simply because a clever individual or an innovative organization discovers or invents a way that information already collected and on 2 the ﬁne printﬂ of published privacy policies is a wellknown issue. many privacy policies are written in a way that requires collegelevel reading scores to interpret. see, for example, mark hochhauser, ﬁlost in the fine print: readability of financial privacy notices,ﬂ privacy rights clearinghouse, july 2001, available at http://www.privacyrights.org/ar/glbreading.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.180 engaging privacy and information technology in a digital agele can be used in some novel way to solve some problem or to advance some interest.3ﬁrepurposingﬂ of information is not by denition wrong, at least not always. but it often happens that information collected and used in one domain, and expected by the individual to be used in that domain, turns up in another. even if such use is entirely legal, the surprise and sometimes shock individuals feel as a result of learning about this use of information about them can generate not only personal angst, but also political issues in our system of democratic elections, judicial litigation, and public debate.similar issues arise in an internet context. consider the issue of privacy as it relates to businesses and the behavior of their internet customers. using the anchoring vignette approach, a possible survey question might be, how much privacy [do you/does ﬁnameﬂ] have about information that [you/he/she] disclose[s] while surng the internet? here are a number of possible vignettes:1. [sandra] is diagnosed with diabetes and consults the web for related information. she begins to receive email advertisements offering diabetes supplies.2. [jamie] is diagnosed with diabetes and consults the web for related information. he begins to receive catalogs for products related to diabetes.3. [ricardo] is diagnosed with diabetes and consults the web for related information. he begins to receive catalogs for products related to diabetes. some of the catalogs are too big to t into his mailbox, and his neighbors see them.4. [alicia] is diagnosed with diabetes and participates in an online diabetes support group. she reads and posts anonymous email to the support group from her computer at work. her employer monitors all web usage from work computers and learns that she has diabetes.a broader though related issue is how businesses advertise their goods and services to prospective customers. consumers often nd advertising, particularly targeted advertising based on personal information, infuriating, but they also nd some advertisements, catalogues, and so on to be of 3 for example, the use of the swift banking communications network as a tool for tracing international banking system transfers of funds to and from terrorists was an innovative way to use existing information for a new purpose. for more information, see jennifer k. elsea and m. maureen murphy, treasury™s terrorist finance program™s access to information held by the society for worldwide interbank financial telecommunication (swift), congressional research service, report code rs22469, july 7, 2006, available at http://www.fas.org/sgp/crs/natsec/rs22469.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 181considerable information value. businesses normally want more information to reduce the costs of advertising by better targeting, but they do not want a backlash from consumers. a different set of vignettes might pose the following survey question: how much privacy [do you/does ﬁnameﬂ] have from business solicitations?1. [elizabeth] has an unlisted telephone number and address. she never receives any advertisements or telemarketing calls.2. [jasper] occasionally receives ﬁpopupﬂ advertisements while browsing the web.3. [george] occasionally receives email advertisements.4. [mark] occasionally receives catalogues from department stores that he has shopped at.5. [grace] frequently receives phone calls from telemarketers asking her to purchase various household items.6. doortodoor salesmen frequently come to [derek™s] home and attempt to sell household items to him.these vignettes suggest some of the variability in this issue and leave room for consumers, businesses, public policy makers, and others to identify scenarios that they nd appropriate and inappropriate.yet another dimension of organizational conduct involves the relationship between the supervision of employees in the workplace and the nature and extent of surveillance of those employees.4 it is broadly accepted that employers have rights and even obligations to supervise employees. in one sense, any kind of employee supervision might be regarded as surveillance. as a point of departure, consider the possible survey question, how much privacy [do you/does ﬁnameﬂ] have at work from [your/his/her] employer? here are a number of possible vignettes:1. [alex] works without supervision. he sets his own schedule and takes breaks whenever he wants.2. [bob] submits a time sheet summarizing how he has spent his day. he may take breaks as long as they are listed.3. [carol] punches a clock to check in and out of work. her boss checks in on her frequently and uses a monitoring system to record how many keystrokes she types per minute.4. [jane™s] employer keeps lists of every web site visited by each 4 additional discussion of privacy issues related to worker surveillance can be found in mark jeffery, ed., ﬁinformation technology and workers™ privacy,ﬂ comparative labor law and policy journal 23(4):251280, 2002. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.182 engaging privacy and information technology in a digital ageemployee who uses a computer at work. her boss occasionally reviews the lists.5. [gordon™s] employer hires a company to search the web for information about all employees, including their posts to web boards and chat rooms. the employer reviews this information to see if employees are criticizing the company.6. [debbie™s] boss frequently listens in on her phone conversations at work and reads her email, whether workrelated or not.7. [ed™s] boss monitors all forms of communications in the ofce, whether workrelated or not, and uses a video camera system to track work activity. [ed] must bring a letter from his doctor to be paid for his sick leaves, and breaks are timed to the minute.government collection of personal information presents special issues by virtue of government™s unique status without competitors, its coercive capabilities, and the mandatory character of many of its data requests. governments are involved in many activities of daily life, and they collect a great deal of personal information pursuant to such involvement. this provides many opportunities for repurposing. for example, states issue drivers™ licenses, for which they collect personal information. such information is manifestly necessary for the purpose of enforcing state laws about drivingšbut states have also sold driver™s license information, including names and addresses, to obtain additional revenue. such actions have had tragic consequences, as in the 1987 rebecca schaeffer shooting discussed in section 4.3.1. government agencies also collect large amounts of personal information for statistical purposes, such as the census.the scenarios discussed above and below are not necessarily instances of ﬁgoodﬂ technology or information being misappropriated by ﬁbadﬂ people, or of ﬁbadﬂ technology that is being used only for the invasion of privacy. looking at particular cases shows the range of purposes and motives for both the technology and the institutions using that technology. there is often a difference in perception about whether a given application of technology offers more or less privacy and whether the outcome of the use is good or bad. indeed, there are con˚icting desires by both the targets of the information gathering and those who are doing the gathering. understanding these issues gives a picture of a privacy landscape that is painted not in black and white but in multiple shades of gray.to the extent that businesses and other organizations see t to develop and implement privacy policies, these policies to varying degrees are informed by the principles of fair information practice described in section 1.5.4. fair information practices were originally developed in a context of government use of information, but over the past 30 years, they engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 183have proven relevant to private sector use of information as well. this is not to say that businesses and other organizations have fully embraced them in practicešonly that they are an important point of departure for these organizations in formulating relevant privacy policies.6.2 education and academic research institutions6.2.1 student information collected for administrative purposeseducational institutions at all levels maintain enormous quantities of information about their students. indeed, school children often learn that information about them is being kept and accumulated in a ﬁpermanent recordﬂ that potentially follows them throughout life. this record contains not only grades but also standardized testing scores, comments from teachers, and a record of behavioral and developmental changes, challenges, and observations. although all educational institutions at all levels collect a rich store of information about the students who have attended the institution, the amount of information increases with the level of education. elementary and secondary schools have considerable information about the grades, behaviors, and capabilities of their current and former students. colleges and universities usually have richer (although, perhaps, less centrally aggregated) stores of information about their students. indeed, colleges and universities could be regarded as conglomerates of different ﬁbusinessesﬂ that need personal information for different purposes (e.g., student health services, registration, management of facilities such as dormitories, issuing transcripts and parking permits, providing food service, and so on) in addition to the primary purposes of educating students and performing research. in the course of their everyday functioning, they may collect information on students™ movements on campus (as id cards are used to unlock doors electronically), library use (as they check out books), and even some forms of consumption (as their id card is used to debit their account when they purchase a meal at the cafeteria or condoms at the campus book store).much of this information is gathered to chart the progress of the individual student. grades, standardized test scores, and various evaluations are used to track the progress of the individual student and to determine future placements and admissions as well as past accomplishments. most of this information is considered condentialšit is available only to the student and possibly that student™s parents, teachers who can demonstrate a need to see the information, and the administrators and counselors in the school itself. some information, such as scores on diagnostic or capabilities testing, may not even be available to the student or parents of the student.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.184 engaging privacy and information technology in a digital agewhile the original goal of gathering information about students was to aid in the education of the student, much of that information is now being used for secondary purposes. standardized test scores are now often aggregated and used to evaluate the effectiveness of teachers, the curriculum, or the school itself. demographic information about students is gathered and used to show compliance with federal regulations concerning equal opportunity. information about studentsšsometimes individually and sometimes in the aggregatešis used internally and externally by schools for fundraising purposes and for marketing of the school itself.colleges and universities also gather large amounts of information about students as a byproduct of the educational process. such information ranges from the mundane (e.g., student telephone listings and class schedules) to the potentially quite intrusive (e.g., records of email and chat sessions conducted via school computer networks, records of web browsing activities). in a desire to exploit the full educational potential of computer networks, many institutions now provide ﬁwiredﬂ dormitories, classrooms, and even campuses. information collected within such systems may include records of whereabouts on campus generated by networked id cards or laptop ethernet access logs, purchase records generated by multipurpose student id/debit cards, and so on. university libraries contain records of varying degrees of completeness of what students have borrowed or checked out or used online. meal plan records may contain detailed information on the eating habits of individual students. student health services collect detailed medical histories. as more and more educational institutions begin using access control mechanisms for entry to their facilities, even the location of individual students will become more traceable at various levels of granularityšand information about who entered and left a given location in a given time window could facilitate the identication of social networks.much of the academic information about students is subject to the protection of the family educational rights and privacy act (ferpa), sometimes known as the buckley amendment, which drastically limits the range of information that schools and colleges can release about their students. this act bars nonconsensual release of student records, and little beyond a student™s enrolled status and (if it appears in a published source like a campus directory) address and phone number can be revealed, except to persons within the institution who have a demonstrable ﬁneed to know.ﬂ it also ensures that students (and the parents of students who are minors) will have access to those records and a right to correct or amend those records. other information, such as medical records generated in university hospitals, is often subject to other legal protections, such as those mandated by the health insurance portability and accountability act (hipaa) of 1996 (as discussed in chapter 7).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 185the implementation of appropriate data management and security procedures to fulll external and internal privacy requirements would be a challenge in the best of cases, and is doubly so in many educational contexts where the network of computers storing personal information tends to develop out of systems that were originally selfcontained and unavailable over a network. adding appropriate security to such applications is difcult on a casebycase basis. ensuring that all of the applications containing condential information are appropriately protected is far more difcult.this is especially so as these institutions try to use the internet to allow easy access for staff, faculty, and students. simply designing appropriate authentication procedures is a challenge; coupling those with the correct authorization and auditing mechanisms is an additional technical challenge.5 media accounts frequently report on weaknesses in such systems, whether it be the inappropriate use of social security numbers for identication (as was done at princeton university in 20026) or the hacking in to a thirdparty admissions records site for the mba programs of such schools as harvard university, mit, and carnegie mellon university (box 6.1).if nothing else, these cases illustrate the fact that implementing appropriate data management procedures has always been a challenge; doing so securely in a digital networked environment is even more difcult. the desire to provide secure but accessible online services that would simplify the application process for students and allow ready access for those within the educational institutions to the submitted material led to a situation in which the security of the overall system could be compromised. similar worries have arisen over other systems used by educational institutions, whether they have to do with applications, current students, or alumni. in all cases, allowing anyone access to these online repositories raises additional security concerns that those who are not to have access will somehow gain it, violating the privacy of the individuals involved. the issues range from the proper design of authentication procedures to parameters for enabling access from publicly accessible terminals.this case also points to disagreements about the proper balance between technical and nontechnical approaches to guaranteeing security and privacy. those who argue that the applicants should not be penalized since they only exploited a hole in the system advance a position that anything that can be done in such systems is permissible. the schools, 5 see national research council, who goes there? authentication through the lens of privacy, stephen t. kent and lynette i. millett, eds., the national academies press, washington, d.c., 2003.6 ﬁcybercrime? princeton spies on yale,ﬂ cbs news, july 26, 2002, available at http://www.cbsnews.com/stories/2002/07/27/tech/main516598.shtml.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.186 engaging privacy and information technology in a digital agebox 6.1 a case study in the ethics of privacy the discovery, reaction, and counterreaction to the 2005 compromise of information in records for several universities™ businessschool admissions add up to an interesting case study in the area of privacy, technology, and education. a number of business schools subscribed to a service that allowed a single admissions dossier to be shared among the schools, which is a convenience for the students applying to these schools. the service also allowed the schools to manage their own admissions procedure, which is a way for the schools to gain efciency. however, the security of the service was compromised by a person who published a way for those who had used the service to get access to their own records (which could in principle contain information about the disposition of their applications). a number of the applicants did so. however, using an audit procedure, the schools were able to determine which records had been observed in this way, and a number of those schools decided that anyone who had accessed the records would be denied admission to the program on the basis of a lack of ethics. a privacy issue arises because applicants could also, in principle, gain access to the records of other applicants, although none were known to do so in this case. this decision by the schools caused considerable controversy. there were some who agreed with the schools, pointing out that such a lapse was just the sort of bending of the rules that had led to scandals such as those surrounding enron and worldcom. others claimed that the schools had acted far too harshly, arguing that the breach of security was the fault of the service used by the schools, and the use of the mechanism by the applicants was no worse than looking at their records if those records had been left out in public.source: geoff gloeckler and jennifer merritt, ﬁan ethics lesson for mba wannabes,ﬂ business week, march 9, 2005, available at http://www.businessweek.com/bschools/content/mar2005/bs20050397827bs001.htm.on the other hand, took the position that even though looking at the sites was technically feasible, actually looking shows a ˚aw in character that counts against the applicant. they are enforcing the security by other than technical meansšby showing that violation of the integrity of the admissions process will entail a penalty, they hope to deter such actions in the future. this case also raises the question of when individuals should have access to information about themselves and just whose information it is. the schools maintain that the information about the applicants was properly withheld, while others argued that the information (including admissions status), being about a given student, should properly be accessible to that student.as a condition for the use of campus it resources, many institutions require students to sign and abide by acceptable use policies under which engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 187students agree that their internet activities are subject to monitoring under certain circumstances. although students sign these agreements routinely, 6 months later they often have no memory of having signed them, let alone what the agreement actually said.7 as a result, these institutions nd themselves in the forefront of debates about the values and costs of surveillance, and must develop policies about handling the vast amounts of information they cause to be generated.6.2.2 personal information collected for research purposesalong with all of the information gathered and stored concerning potential, current, and future students, educational institutions involved in research gather and store large amounts of data as part of that research. some of this information (especially in the social sciences) may be condential but not refer to any person actually associated with the educational institution (e.g., data on public responses to a questionnaire). other information can have considerable worth in terms of intellectual property.unlike information about the students that attend such institutions, information gathered in the course of research is not clearly covered by the general laws and regulations regarding the privacy of student records. however, there are extensive federal and international statues, policies, and guidelines that govern the use of human subjects in research. these regulations, many of which trace their heritage back to the nuremberg code,8 govern not only what information can be gathered as part of research but when and how that information can be released to ensure the privacy of the individuals who were the subjects of the study.however, there are competing interests in such information, given that the institution holding the information needs to weigh the cost of releasing the information, both in terms of the privacy of the subjects and in terms of possible lost revenues in terms of patent rights and other intellectual property fees, against the value of having open research results based on repeatable experimentation.the tradeoff between the value of privacy to an individual and the 7 janet w. schoeld and ann l. davidson, bringing the internet to school: lessons from an urban district, josseybass, new york, 2002, pp. 319320.8 the nuremberg code was developed in the wake of the nuremberg tribunals after world war ii. brie˚y, the nuremberg code articulates 10 points that dene legitimate and permissible medical research. prior to the nuremberg tribunals, no international law or informal statement differentiated between legal and illegal human experimentation. see trials of war criminals before the nuremberg military tribunals under control council law no. 10, vol. 2, pp. 181182, u.s. government printing ofce, washington, d.c., 1949, available at http://www.hhs.gov/ohrp/references/nurcode.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.188 engaging privacy and information technology in a digital agevalue of the individual™s information to the researcher and ultimately to society is real, substantial, and not resolvable in any nal sense. it will always remain an important tension, no matter how society™s rules govern any particular research project, at any one time, in any one institution, under any one set of policies, and as governed by any given granting institution. the benets here are so contextual and dependent on the type of privacy and the value of the information to the individual and society that there will be a continuing need to make decisions about the tradeoff in each research situation.6.3 financial institutionsfinancial organizations (including insurance companies) gather and maintain enormous amounts of sensitive information about individual adults. financial organizations such as banks, credit card issuers, investment houses, and loan originators (all of which may be part of the same organization) know how much we make, how much we save, what investments we make, and how much (and to whom and for what) we owe money. such organizations seek information about their customers and potential customers, both so that the organizations can offer new services to those customers and so that the organizations can more completely manage the risks involved in a customer™s use of those services (such as the use of credit). insurance companies seek and maintain information on the health, possessions, security provisions, and other habits of their customers, both to keep track of what is insured and to determine the prices they will charge based on the actuarial information that can be derived from such information.the amount, sensitivity, and importance of this information have long been known. the nancial sector was one of the rst to be subject to broadranging privacy legislation with the passage of the fair credit reporting act of 1970, and many of the considerations cited in the landmark study records, computers, and the rights of citizens originated in concerns regarding the gathering and use of nancial information.9 many of these regulations have as their main goal ensuring that the information gathered and used by these institutions is accurate. however, recent worries have also centered on how that information is used and shared between various parts of the nancial institution.the need for accuracy is clear; inaccurate information that makes a person appear to be a higher risk than would otherwise be the case can 9 u.s. department of health, education, and welfare, records, computers, and the rights of citizens, report of the secretary™s advisory committee on automated personal data systems, mit press, cambridge, mass., 1973.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 189slow the delivery of nancial services, increase the cost to the person of those services, or even keep the person from receiving those services at all.10 the fair credit reporting act allows consumers to see the information on which nancial institutions base their decisions concerning lending or the offer of other services, and provides mechanisms by which those credit records can be corrected or amended.in 1978, the u.s. congress passed the right to financial privacy act, which is intended to protect the condentiality of personal nancial records. today, the act covers nancial records held by covered institutions, including banks, credit card issuing institutions, credit unions, and securities rms, among others. the act forbids most federal authorities from obtaining access to these records unless the individual(s) in question has granted access or an appropriate legal authorization has been explicitly sought. in addition, under most circumstances, the individual in question has the right to challenge the government™s request before the access occurs.however, the act also immunizes covered institutions and their employees against civil liability for the voluntary ling of suspicious activity reports (sars) with the financial crimes enforcement network of the department of treasury. the usa patriot act, passed in 2001, also expanded the circumstances under which covered institutions must le an sar and established identication requirements for customers. the right to financial privacy act also does not apply to state or local governments, private organizations, or individualsšand to the extent that covered institutions do not comply with requests for such records originating from these entities, their refusal is based on constraints other than the act (e.g., rules of business practice, auditing requirements, state or local law, and so on).more recent worries about such information center on the use of the information gathered for one purpose and then used for a completely different purpose. for example, information gathered to determine the risk of offering loan or credit services could be used to market other, unrelated services to particularly creditworthy customers, such as additional credit cards or lines of credit. payment records indicating international travel could be used to market travel insurance or loss protection. such repurposing of information has led many consumers to feel that their privacy is being violated, and led to the passage of the privacy protections contained 10 the sarbanesoxley act, also known as the public company accounting reform and investor protection act of 2002, was intended to increase management accountability in private rms, and has had the effect of increasing the need for highquality personal information before it is aggregated or deidentied and transformed into ﬁnancial data.ﬂengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.190 engaging privacy and information technology in a digital agein the grammleachbliley act (also known as the financial services modernization act) of 1999.the primary purpose of the grammleachbliley act was to eliminate distinctions between commercial banking and investment banking. it allowed the creation of nancial service companies that could hold commercial banks, investment banks, and insurance companies as afliated subsidiaries, and it permitted those subsidiaries to sell each other™s products where such sales had not been permitted in the previous regulatory regime established by the 1933 banking act (also known as the glasssteagall act). more important from a privacy standpoint, nancial service companies were allowed to use personal information obtained from one subsidiary to further the sales of another subsidiary™s products. for this reason, the grammleachbliley act required nancial service companies to state their policies having to do with privacy, especially with respect to sharing information among subsidiaries and selling that information to third parties. the act also gave consumers the right to opt out of various forms of information sharing that would result in the use of that information for purposes other than the originally intended purpose.the success of the grammleachbliley act is uncertain, at best. from the consumer standpoint, the privacy statements that are required by the law are detailed and technical. they are hard to understand, and as a result there are a number of public web sites that attempt to explain to consumers what the privacy statements mean,11 and some regulators are pushing to rationalize privacy notices in order to increase their clarity and usefulness to customers. while the law allows consumers to choose not to allow sharing of certain kinds of information, some studies have shown that relatively few consumers who could make such a choice have actually done so. this could be an indication of a lack of interest in blocking such sharing, or it could be an indication of the complexity of the mechanism created by the law for making such a choice. the exercise of formulating these notices, however, has arguably forced nancial institutions to review their privacy policies and datahandling practices in a way that they otherwise would not have done, and thus reduced the likelihood of egregious privacy practices that might have slipped through the cracks.even if opting out were easier, it is not clear that making use of the mechanism would have the intended effect. the worry of the privacy advocates is that by sharing this information across divisions, subsidiaries, and with partners, the companies doing the marketing are adding to the number of useless catalogs, mass mailings, and solicitations received by consumers. however, those within the industry argue that such shar11 see, for example, ﬁfact sheet 24(a): how to read your ‚optout™ notices,ﬂ privacy rights clearinghouse, available at http://www.privacyrights.org/fs/fs24aoptout.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 191ing actually reduces the amount of extraneous marketing received by a consumer by enabling solicitation that can be targeted to only those more likely to respond to it as determined by the interests shown in the shared information. the alternative is to ensure that the solicitations are sent to everyone, rather than a targeted set.finally, the nancial sector presents a number of good examples to illustrate the need for tradeoffs. the discussion above makes clear at least a rough societal consensus that nancial information is sensitive and is deserving of considerable privacy protection. at the same time, criminal elements often interact with nancial institutions, and law enforcement authorities have found nancial information to be of enormous value in apprehending and prosecuting criminals. thus, a number of laws enable law enforcement agencies to obtain personal nancial information under appropriately authorized circumstances. laws related to the reporting of large cash transactions (in excess of $10,000) are also intended to discourage money laundering, even though a privacy interest might well be asserted in such transactions.6.4 retail businessesthe attempts by nancial institutions to provide better service (and to cut their own costs) through the gathering and mining of information about their customers have been mirrored by similar efforts in the retail industry. whether in online ecommerce or the bricksandmortar retail trade, the gathering of information about the buying habits and past histories of customers has led to efciencies in retail businesses, but also to concerns about the privacy of the individuals about whom the information is gathered.although many different schemes have been used to collect information about consumers, the dimension of privacy that these affect is fairly straightforward to understand. as a point of departure, consider the issue of privacy as it relates to merchants collecting information from shoppers. using the anchoring vignette approach, a possible survey question might be, how much privacy [do you/does ﬁnameﬂ] have from merchants while shopping? here are a number of possible vignettes:1. [susan] pays cash at a large, crowded department store and provides no information about herself to the cashier.2. [mary] pays with cash at a convenience store. the clerk insists on recording her zip code on the computergenerated receipt.3. [carmen] pays with her credit card at the convenience store. the clerk insists that she provide picture identication, as well as her telephone number to record on the transaction slip.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.192 engaging privacy and information technology in a digital age4. [horace] goes to a drugstore to buy lm, which was advertised to be on sale. he nds out at the store that in order to receive the discount, he must apply for a courtesy card, which entails an application requiring home address, work, and marital status.5. [julio] applied for a courtesy card at the drugstore, which entailed an application requiring home address, work, and marital status. whenever he shops he receives by mail advertisements and coupons for alternatives to the drugs that he usually purchases.6. [evelyn] applied for a courtesy card at the drugstore, which entailed an application requiring home address, work, and marital status. evelyn used the middle initial ﬁqﬂ on her application, even though that is not her real middle initial. she now receives catalogs in the mail from businesses that she has never patronized, all with mailing labels that include the middle initial ﬁq.ﬂ7. [rosco] applies to join a local gym. the membership application includes questions about his health, income, and criminal background. in addition, he is required to grant permission for the search of public records and undergo a credit check.of course, although one dimension can be dened by example through these vignettes, consumers and different businesses have markedly different preferences about what level of privacy, as indicated by one of these seven vignettes listed from most privacy preserving to least, is acceptable or even should be legal.one such informationenabled marketing effort to come to the attention of consumers is the use of historical information by the online bookstore amazon.com to make suggestions to visitors on items that might interest them. when customers log in to the amazon.com web site, they are greeted with a series of recommendations on items they might like. these recommendations are based on the purchase history of the customer and the purchase history of other customers who resemble the one logging on. many people nd the recommendations helpful, and amazon.com nds that it helps their business. nevertheless, there are some who nd this an indication of how much information has been gathered about them and wonder what else this customer database reveals about them.a similar trend can be seen in bricksandmortar retail businesses such as grocery stores and pharmacies that use customer loyalty cards. these cards are used to identify customers, allowing the purchases made by those customers to be tracked and aggregated. some stores use the information to give out discount coupons differentially depending on the interests and history of different customers, which can be thought of as a variation on the recommendations made by the online retail sites. in addition to the accumulation of information that these cards allow, there engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 193have been some who are troubled by the fact that the use of such cards can be a condition for a discount on certain purchases, meaning that those who do not want this information gathered about them are forced to pay higher prices than those who allow the information to be gathered.12the change, in both the online and the bricksandmortar retail case, is not necessarily in the information that is being gathered. for some time now, individual merchants have had their own credit cards, and all purchases by customers using such cards were thus recorded and the records made available to those merchants. what has changed is the use of that information. with new datamining software, this information has become an important input for decisions about what suggestions to make to particular customers to how to lay out a retail store to what items to put on sale.as the above discussion suggests, retailers, credit card companies, and manufacturers often collect and make subsequent use of purchase information, and because they do not go out of their way to remind consumers that they are doing so, such collection and use are unlikely to be foremost in a consumer™s mind. to the extent that individual consumers are not aware of informationbased marketing, they may nd such marketing helpful and benign or intrusive and inappropriate.in the helpful and benign category are marketing offers that consumers value, such as a discount on the next purchase of an item previously purchased, a coupon for a competitor™s product, a more convenient online shopping experience, or a suggestion for a different purchase that the customer might nd useful and of interest. indeed, some consumers seek out informationbased marketing services and knowingly provide information about themselves to improve the operation of recommendation systems.in the intrusive and inappropriate category are sales techniques that make individuals feel that their privacy has been violated, such as advertisements for undesired sexually oriented material or drugs for socially stigmatizing diseases. more troubling is the use of informationbased marketing to avoid certain demographic groups in offering an advantageous deal or to target certain groups with fraudulent intentions in mind.12 in some cases, a customer without an individual loyalty card is supplied with a ﬁregisterﬂ card upon checking out, thereby enabling the customer to receive the discount. however, the existence of this practice does not negate the potential privacy concerns raised by customer loyalty cards in the rst place. although even a customer with a loyalty card can request that the register card be used, the customer must know about that option to exercise it, and it is not accidental that there is generally no sign at the register indicating that customers may use the register card. in addition, the customer may lose any benets associated with aggregate purchases over a period of time (e.g., a coupon for a 10 percent savings after $500 in purchases).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.194 engaging privacy and information technology in a digital agesome have asserted that one way to solve, or at least substantially mitigate, the intrusive aspects of informationbased marketing is to collect even more personal information so that offers can be targeted more precisely to those who are likely to appreciate getting them, and other customers can then be left alone. but the notion that preserving privacy could depend on providing even more personal information is ironic and counterintuitive at best. indeed, much of the objection to marketing uses of personal and transactional information is based in the fact that many people simply do not believe that marketers are their agents working in their interest. by contrast, sharing personal and sensitive information with someone known to have the information provider™s interests at heart is likely to be undertaken with much greater comfort and ease.the latest extension to worries in a retail privacy context is the introduction of radiofrequency identication (rfid) tags that carry an identier able to differentiate retail goods at the item level (as opposed to just the kind of item, which is the case with barcodes). rfid tags respond to transmissions in the radio frequency range by sending a reply that is their unique identier. their use is not currently widespread, but both the department of defense and walmart have active plans for deploying the technology in the near future.privacy advocates have argued that rfid tags will allow anyone with a reader to determine all of the items carried or worn by an individual, and would allow someone with a reader to take a complete inventory of the contents of a house from outside the house. correlating the items being worn by an individual could enable determining the identity of that individual. moreover, a tag wearer/holder™s movements and personal contacts might become more traceable.13 tags placed in books could allow inferences to be made about the reading habits of the individual.to date, the use of rfid technology in retail applications has, in almost all cases, been conned to the supply chain, in keeping with rfid™s original purpose to ensure a smooth movement from the manufacturer, through the warehouse, and to the nal retail space. it is believed that the automation of the identication of palettes and items through this process will save considerable cost and improve the detection of lost, misplaced, and stolen items. even in the retail store, the main use of rfid technology is intended to be the reduction of the inventory that the store must carryšpilot programs (such as that done in the united kingdom by 13 once an individual is identied and associated with the serial numbers of tagged items possessed, the individual is subject to identication when he or she passes an rfidmonitoring point. if two such people meetšdeliberately or by chancešnearby a monitoring point, a de facto record of their meeting can made.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 195marks and spencer14) show considerable cost savings in the use of this technology.rfids also have marketing signicance. for example, it is relatively straightforward to embed a different product serial number in each product, so that every shirt sold by any store has its own serial number. a consumer who bought an rfidtagged shirt at store a could then be identied every time she wore that shirt in store a. since the array of personal items she would be carrying on each visit would vary, it would be possible over time to develop an inventory of many of the personal items that she owned. furthermore, it is possible that the databases of different stores could be networked together, which means that every store in the network would have such information available. with an inventory of personal items in hand, albeit incomplete, stores could deploy recommender systems to suggest other items that an individual might be likely to purchase, with suggestions transmitted to the consumer as text messages on a cell phone.to date, no retailer has announced any such plans and would receive abundant negative press if it did. this subject has become ﬁradioactiveﬂ because of privacy concerns, and retailers are currently using rfid technology only for inventory, supply chain management, and theft control. an individual retailer might be reluctant to expose itself to such risk, and it is even less likely that retailers would do this en masse, an action that would be required for the network scheme described above. but as privacy advocates point out, it could someday be possible.although few people object to the use of rfid tags in retail stores before an item becomes the property of the consumer, postsale privacy concerns have been raised regarding just such scenarios. as in the case of the amazon.com book recommender systems, targeted marketing can be considered a benet to the willing consumer or an intrusion to the unwilling consumer. one technical approach to address postsale privacy concerns involves deactivating the tags at the point of sale.15 such an operation would make the tags permanently unresponsive to any request; in effect the tag would become inoperable.most of the controversy around the collection of information at the retail level seems to stem, on analysis, from a concern about the amount of information that could be gathered about everyone during even the most mundane of tasks. today, even the seemingly anonymous shopping over 14 see generally, simson garnkel and beth rosenberg, eds., rfid applications, security and privacy, addison wesley, 2006. see especially chapters 46.15 some rfid tags can also be deactivated by microwaving them for several seconds. consumer deactivation of an rfid tag has the advantage of verication, as vendors themselves have little inherent economic incentive to kill the tag.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.196 engaging privacy and information technology in a digital agethe internet results in enough information to allow merchants to make suggestions that seem uncomfortably accurate to some. new technologies seem to allow ever greater collections of information about what we buy, wear, and do, and about our associates as well. the information can be gathered at a distance (and thus without our knowledge) and might even be gathered well after the action that led to the acquisition of the item giving out the information (as would be the case with rfid tags being read in the clothing we were wearing instead of buying). multiple worries arise from the volume and variety of information being gathered, the known uses to which that information is being put, and the unknowns about what other uses there are now or may be in the future.6.5 data aggregation organizationsin addition to allowing the collection, retention, and analysis of information by existing organizations, advances in technology have led to the creation of the data aggregation business. this business might be thought of as the networkedworld™s equivalent to the traditional private detective agency of the past, in that it is built around being able to supply information to those who need it. unlike the detective agencies of the past, however, these newage businesses attempt to aggregate and repackage alreadyavailable information.data aggregation services obtain their information in a number of ways. much of the information is gathered from public sources, such as the records held by various governmental bodies. these records are public by law, and many of these records are now available in digital form, either by request or directly over the internet. other forms of information come from partner businesses, or from businesses that want to use the information supplied by the data aggregation service. such information can include the history of insurance claims made or the jobs held by an individual. in addition, customers of a data aggregation service supply it with some information about an individual of interest, which can then be used to nd still more information about that individual. when the work for the client who has supplied the ﬁseedﬂ information is done, the seed data are added to the aggregator™s store of information.unlike search engine companies, which index information about individual users as a byproduct of the overall indexing of the world wide web, the main business of data aggregation companies is the gathering and indexing of information about individuals, and the amount of information that can be gathered in the ways described above is staggering. and the more information acquired concerning an individual, the more valuable the services data aggregators can provide.data aggregation services are businessesšone must pay for and must engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 197be credentialed by the data aggregation company to use, those services.16 the services offered by data aggregators are used by businesses for preemployment background checks, by law enforcement agencies for investigations, and by nancial and insurance and other companies to check the backgrounds of potential customers and associates. however, the quality of the data available through these services is variable. in a 2005 study, pierce and ackerman found that 67 to 73 percent of data records on individuals obtained from two data aggregation services contained incorrect biographical data, and between 13 and 25 percent contained errors in basic biographical data (name, date of birth, social security number, current address, phone number).17in a sense, data aggregators can be seen as an extension of companies such as equifax, experian, and trans union corporationšcredit bureaus that have made a business of amassing nancial information about individuals and businesses for years. but data aggregators are made possible by the advances in technology over the past decade. only because of the amount of information that is available on the network, the amount that can be easily stored, and the advances in hardware and software that allow analysis of that information can data aggregators offer information services that cover almost everyone in the united states.that these companies can collect enough information that they can ﬁknowﬂ a person well is noteworthy to many and troubling to some. perhaps a greater concern is the fact that many of the activities of these companies are not clearly covered by the laws and regulations that cover nancial institutions, such as the fair credit reporting act. unless they are in fact covered by such laws and regulations, there is no requirement that the companies make known to individuals information gathered about them, nor are individuals guaranteed by law a means for challenging, changing, correcting, or amending that information.indeed, the public was generally uninformed about the existence of data aggregation services until one company (choicepoint) disclosed that it had provided large amounts of personal information on many individuals to fraudulently constituted businesses. choicepoint has always marketed itself to business and the government rather than consumers, thereby escaping much public notice. in february 2005, choicepoint reported, most likely as the result of california law mandating such notice 16 some data aggregation services are free, although the amounts of data made available for free are quite limited. for example, zabasearch (www.zabasearch.com) makes available for free personal information regarding name, address, phone number, and year of birth.17 deborah pierce and linda ackerman, data aggregators: a study of data quality and responsiveness, may 19, 2005, available at http://www.privacyactivism.org/docs/dataaggregatorsstudy.pdf#search=%22data%20brokers%20choicepoint%20acxiom%22.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.198 engaging privacy and information technology in a digital agein the event of improper disclosures of personal information, that it had sold information about individuals to fraudulent front companies.18choicepoint™s response to this breach was to tighten its mechanisms for credentialing a company; from its point of view the problem was one of fraud in obtaining the services it offered. but many observers argued that the incident showed a basic problem with the relatively unregulated and unrestrained companies that collect and store personal information about individuals without their knowledge and without direct benet to them. these observers argued that the appropriate response was greater regulation of the data aggregation industry along the lines of how the nancial and health sectors are now regulated.it is not known at this writing what the ultimate reaction will be to the disclosure of the loss of this information. calls have been made for new legislation and regulation of data aggregators. many people have expressed shock that these kinds of businesses even exist. however, without such services it would be more difcult for businesses to do the required checks on potential employees to validate claims regarding educational background or the absence of prior criminal records, although data aggregation companies have much more personal information on individuals than just what is needed for background checks regarding criminal records and educational history.what and how much information should be collected about citizens by private businesses has generally not been the subject of regulation in the united states, where worries have generally focused on the potential for privacy violations by the government. knowledge of the existence of data aggregation services, and the dangers posed by the compromise of the information held by such services, potentially changes that, and concerns may increase about the possibility of privacy violations by private rms, especially as the data aggregation industry grows. in addition, an increasing tendency for government agencies to contract with data aggregation companies to provide otherwise unavailable data could easily lead to more intense concern as the line between the public and private sector becomes more blurred.19 box 6.2 lists the data that are easily accessible to 18 ﬁconsumer data company warns 145,000 of possible identity theft,ﬂ ap news, february 17, 2005, available at http://sfgate.com/cgibin/article.cgi?f=/n/a/2005/02/17/state/n041832s59.dtl.19 for example, hoofnagle found that law enforcement authorities can quickly obtain a broad array of personal information about individuals from data aggregation companies. indeed, in 2004, choicepoint had designed a web site, www.cpgov.com, as a onestop shopping point for obtaining a compilation of personal information on almost any adult (chris jay hoofnagle, ﬁbig brother™s little helpers: how choicepoint and other commercial data brokers collect, process, and package your data for law enforcement,ﬂ university of north carolina journal of international law & commercial regulation 29:595, 2004). at this writing, this site has been replaced by another site, www.atxp.com, which is the entry point for a engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 199choicepoint customers, and although most of the information is available from public sources, the service provided is that of onestop shopping on a relatively short time scale.new service known as autotrackxp (see box 6.2). the www.cpgov.com web site notes that the choicepoint online public records interface is no longer available and directs users to the new site, www.atxp.com, with instant access to ﬁchoicepoint™s premier webbased investigative information solution, autotrackxp®.ﬂ the site further notes that autotrackxp ﬁprovides the extensive public record content you are accustomed to obtaining through choicepoint online.ﬂbox 6.2 the autotrackxp service of choicepoint a typical information set (autotrackxp) from choicepoint offers the following information on a given individual subject: ł aliases for the subject ł social security numbers associated with the subject ł other names and associated social security numbers linked with the subject ł driver licenses held ł addresses associated with the subject ł risk classication for the subject™s address ł infractions ł phone listings for the subject™s addresses ł sexual predator status ł felony/probation/parole status ł realproperty ownership and deed transfers ł property owners of subject™s addresses ł deed transfers ł vehicles registered at subject™s addresses ł realtime vehicle registrations ł criminal offenses ł watercraft owned ł federal aviation administration (faa) aircraft registrations ł uniform commerical code (ucc) lings ł bankruptcies, liens, and judgments ł professional licenses ł faa pilot licenses ł drug enforcement administration controlledsubstance licenses ł hunting and shing licenses ł business afliations (including ofcer name match) ł fictitious business names (doing business as, or dba) ł names of relatives ł other people who have used the same addresses as the subject ł licensed drivers at the subject™s addresses ł neighbor listings for the subject™s addressesengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.200 engaging privacy and information technology in a digital ageobservers critical of data aggregators are specically concerned about the ways in which private rms in the business of collecting, aggregating, and aggressively marketing services that depend on the secondary use of information about individuals have managed to avoid compliance with fair information principles.20 they suggest that implementing fair information practices in a way that would protect legitimate privacy interests in this growing sphere of activity would require the following:1. some mechanism for providing notice to the general public about the kinds of information gathered for use by organizations that are the clients and customers of these rms;2. a centralized resource that would allow individuals to consent to, or at the very least opt out of, particular kinds of secondary uses of their personal information; and3. reduction of the government™s reliance on private rms as adjuncts that enable agencies to bypass statutory limitations on access to personal information. of particular importance would be the development of rules governing the kinds of contracts that can be let by agencies for datamining efforts.6.6 nonprofits and charitiesnonprot organizations and charities have become increasingly sophisticated in the information that they gather about their contributors, members, and potential contributors and members. many of these organizations use some of the techniques of forprot businesses, such as keeping track of those who visit their web sites or make use of the services they offer. in many respects, the personal information stored by noncommercial entities is much the same as the information stored by forprot enterprises. credit card information, for example, is often stored to allow ease of contribution in the future, or private nancial information is stored over time to enable automatic payments from bank accounts.at times the information acquired by noncommercial entities about their members or contributors is even more sensitive than that kept by forprot businesses. while tracking clothing stores patronized and the purchases made at those stores can generate information about an individual™s taste and style, knowing the charities to which an individual contributes and the nonprot organizations of which one is a member can reveal political or religious views, intellectual interests, and personal 20 daniel j. solove and chris jay hoofnagle, ﬁa model regime of privacy protection (version 2.0),ﬂ gwu law school public law research paper no. 132, gwu legal studies research paper no. 132, april 5, 2005, available at http://ssrn.com/abstract=699701. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 201opinions that are far more telling and private. the supreme court recognized the connection between the privacy of organizational membership and the right to free association in naacp v. alabama (357 u.s. 449 (1958)), holding that public identication could not be forced for members of an organization engaged in the dissemination of ideas as such identication could be a limit on the right of free association. some nonprot organizations also seek to raise money from wealthy individuals, and they often compile information relevant to estimating a potential donor™s net worth. such information also may be regarded as sensitive in many contexts.unlike forprot entities such as nancial institutions, noncommercial collectors of information are not governed by laws concerning either the privacy of those about whom they collect information, or the uses to which they can put the information. they are exempt from the do not call registry on first amendment grounds. further, such organizations are often resource constrained, and thus unable or unwilling to invest in a security infrastructure that will protect from acquisition by third parties the information they have gathered. the combination of the information gathered and the weaker security found in many noncommercial undertakings makes them lucrative targets for those gathering information needed for identity theft, or for observation for political purposes, although to the committee™s knowledge such things have happened only rarely, if at all.6.7 mass media and content distribution industrieswhether they distribute information through the printed page or broadcast media or the internet, mass media and content distribution companies gather information about their customers both to hone the content they offer and to determine the rates that they charge the advertisers that are often their main source of revenue.customer databases maintained by providers of subscription or membershipbased content to ensure delivery to and billing of the customers have evolved to often include information on the age, sex, income levels, and other demographic and personal details of the subscriberšinformation that the content providers keep and use to determine how best to serve their customers, and also to determine the size and the demographics of their audience, which in turn allows them to attract advertisers and set rates. the more information that can be gathered, the better the information that can be used to plan the content provided in the future.newpapers, radio and television news, and internet sites all try to provide content of interest to subscribers, viewers, and readers that often includes information of a personal nature about individuals and that might be considered private. although libel laws provide some protecengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.202 engaging privacy and information technology in a digital agetions against the publication of untrue information, it is difcult to claim invasion of privacy when the information is truthful (as discussed in section 4.2).for many people, privacy from the media is important. of concern to them is the surprise factor, that unbeknownst to individuals, and without their permission, they are suddenly in the public view more than they had realized would be possible. as a point of departure, consider the issue of privacy as it relates to the media collecting personal information about individuals. using the anchoring vignette approach, a possible survey question might be, how much privacy [do you/does ﬁnameﬂ] have from the media? here are a number of possible vignettes:1. [claudio] just got divorced from his spouse. he calls his close friends to tell them and they keep this condential.2. [pamela] just got divorced from her spouse. the local newspaper publishes a list of all civil divorce lings, including [pamela™s], in its back section.3. [mary] just got divorced from her spouse. her college alumni magazine publishes an article about her divorce, speculating what the disagreement was about.4. [christopher] just got divorced from his spouse. without his permission, cnn runs a feature story on divorce in america, which includes interviews with his exspouse and friends about his divorce.the range here is quite clear, and the diverse interested parties involved will often have different preferences about where on this scale the media should be allowed to go. developing consensus positions is especially difcult when views change as they affect individuals. this will be all the more so as marketing continues to become more focused, and as the need for personal information about the audience for a particular form of mass media becomes ever more important and the risk of exposing individual information in a way that is unexpected thus increases.information about the number of people who might be reached through a particular program or publication is no longer sufcient to attract advertisers. instead, the advertisers want to see that the ﬁrightﬂ kind of people for their product will be attracted by the content. advertisers attracted to the web site www.collegehumor.com are very different from those that advertise on network telecasts of a golf tournament. as the amount of information about a viewer becomes more sophisticated and more personalized, advertising can be more targeted. internet sites that sell advertising, for example, can now determine which advertisement to show based on the viewing and browsing habits of the individual visiting the site.another dimension of personal privacy has emerged as the result of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 203the digitization of entertainment content such as music, video, and movies over the past decade. digitization has allowed new mechanisms for distribution of those forms of content, but has also allowed the possibility of perfect copying of a digital work. such perfect copying, in which no information (and thus no quality) is lost, was not economical with analogue versions of these kinds of content. but with a standard computer, it is possible to make an unlimited number of copies of digital content without degrading the original in any physical manner, a capability that has led the owners of the intellectual content of such works to worry that they are losing (or have already lost) control of that property. the result has been an attempt to reassert the property rights of these owners, and such reassertion has privacy implications. in particular, content owners have sought to create new technologies for digital rights management (or drm) that will allow the owners of the intellectual property to control copies of that property even when it has been sold to the consumer and is no longer physically under the direct control of the initial owner. these technologies may have a serious impact on the privacy of the consumers of the content.drm technologies would allow the original content owners (such as the producers of a movie or the distributor of a music cd) to control when and where that content could be used and, more importantly, how that content could be copied. the privacy concern, which is discussed more fully in chapter 8, is that ensuring such control means that the content owner will be able to trace what content a person buys, what devices are used to view or listen to the content, how often the content is accessed, what parts the user nds most interesting, and perhaps even where the content is accessed, all in a manner that is entirely impossible with traditional media.there is also the worry that information gathered in the name of protecting intellectual property will in fact be repurposed to other ends, since that information will be gathered and owned by the companies producing the content. such information, not available in content without digital rights management, could lead to the establishment of even more invasive databases for marketing purposes.6.8 statistical and research agencies21a large number of federal agencies have a role in collecting data from individuals, households, farms, businesses, and governmental bod21 this section is based largely on national research council, expanding access to research data: reconciling risks and opportunities, the national academies press, washington, d.c., 2005; and national research council, private lives and public policies: condentiality and accessibility of government statistics, national academy press, washington, d.c., 1993. another engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.204 engaging privacy and information technology in a digital ageies and disseminating those data for a variety of statistical purposes, including the development and dissemination of large, generalpurpose data sets based on censuses, surveys, and administrative records. they also include the collection and analysis of personal data in experimental research with human subjects. a few federal statistical agencies conduct general or multipurpose programs (e.g., the bureau of the census), but many others conduct specialized programs or activities (e.g., the bureau of labor statistics and the national center for education statistics). some programmatic agencies conduct some statistical activities (e.g., the federal aviation administration and the internal revenue service). the data collected by these agencies help policy makers understand the state of the nationšfrom the national economy to household use of medicarešand support both the evaluation of existing programs and the development of new ones.agencies work with both statistical and administrative data. to carry out their basic functions, government agencies collect enormous amounts of data, most of which are used directly for various administrative purposes and much of which is personally identiable information. those data collected exclusively for statistical and research purposes form a tiny fraction of the total. data collected for administrative purposes (which include matters such as determination of benet eligibility and amounts) are often useful and appropriate for statistical purposes, as when patterns of food stamp applications are used to trace the effects of program changes. in contrast, data collected for research and statistical purposes are inappropriate for administrative uses, and privacy concerns can arise if data subjects worry that their provision of data intended for statistical purposes might be used administratively. (for example, a census survey respondent might be worried that his or her survey answers might be turned over to the internal revenue service and make him or her more vulnerable to a tax audit.)all of the statistical agencies work to protect individual respondents (data subjects) against the use of statistical data for administrative purposes. in some cases, these protections are provided through statutes. governmentwide legislation includes the privacy act of 1974, the freedom of information act of 1966, and the paperwork reduction act of 1980. agencyspecic legislation further species the condentiality and data access policies that those specic agencies must follow (e.g., the bureau of the census and the national center for health statistics). howuseful reference is g.t. duncan, ﬁexploring the tension between privacy and the social benets of governmental databases,ﬂ in peter m. shane, john podesta, and richard c. leone, eds., a little knowledge: privacy, security, and public information after september 11, the century foundation, new york, 2004.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 205ever, the condentiality policies of some agencies are not backed by statutory provisions. instead, these agencies rely on persuasion, commonlaw tradition, and other means to protect identiable statistical records from mandatory disclosure for nonstatistical uses, and such means may not always be successful.in part to ensure that statistical data are not used for administrative purposes, agencies give data subjects pledges of condentiality, both explicit and implicit. but when those pledges are not backed by statutory assurances, the pledges may not necessarily be honored (and statutory assurances can themselves be changed retroactively).these pledges of condentiality also lead to another set of privacy concerns. for analytical purpose, it is sometimes valuable to release to the public microdata data sets, that is, data sets consisting of some of the individual survey responses that were collected for statistical purposes. but the condentiality pledges require that these data sets be released in a form that does not allow individual identication in any form or in any way, and promoting access to microdata increases the risks of breaching the condentiality of the data.one approach to honoring the condentiality pledge in this context is the use of statistical disclosure limitation techniques (discussed in section 3.8.2.2) to transform data in ways that limit the risk of identity disclosure. use of such a procedure is called masking the data, because it is intended to hide personal information associated with data subjects. some statistical disclosure limitation techniques are designed for data accessed as tables, and some are designed for data accessed as records of individual data subjects (microdata). statistical disclosure limitation techniques almost always degrade data to some extent, although the degradation involved may not matter for a given purpose.6.9 conclusionmany types of organizations face privacy issues. some of these, like nancial institutions, have long been recognized as holding large amounts of sensitive information about individuals and have had some scrutiny in their handling and use of that information. other organizations, such as retail businesses merchants, data aggregation services, and noncommercial groups, are not so clearly identied with privacy issues, either in the public eye or through regulation, but are beginning to be seen as gathering many of the same kinds of information and of having many of the same vulnerabilities that can lead to concerns about privacy.this brief examination of a variety of privacy issues centering on institutions and organizations makes it clear that the interaction of information technology and privacy is not an issue in only some isolated areas engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.206 engaging privacy and information technology in a digital agebox 6.3 questions for judgments and policies about privacy 1. goalsšhave the goals been clearly stated, justied, and prioritized? are they consistent with the values of a democratic society? 2. accountable, public, and participatory policy developmentšhas the decision to apply the technique been developed through an open process, and if appropriate, with the participation of those to be surveilled? this involves a transparency principle. 3. law and ethicsšare the means and ends not only legal but also ethical? 4. opening doorsšhas adequate thought been given to precedentcreation and longterm consequences? 5. golden rulešwould the watcher be comfortable in being the subject rather than the agent of surveillance if the situation were reversed? is reciprocity or equivalence possible and appropriate? 6. informed consentšare participants apprised of the system™s presence and the conditions under which it operates? what exceptions to informed consent are deemed legitimate? is consent genuine (i.e., beyond a response to deception or unreasonable seduction) and can participation be refused without dire consequences for the person? 7. truth in usešwhere personal and private information is involved, does a principle of unitary usage apply, whereby information collected for one purpose is not used for another? are the announced goals the real goals? 8. meansends relationshipsšare the means clearly related to the end sought and proportional in costs and benets to the goals? 9. can science save us?šcan a strong empirical and logical case be made that a means will in fact have the broad positive consequences its advocates claim? 10. competent applicationševen if in theory it works, does the system (or operative) using it apply it as intended? 11. human reviewšare automated results with signicant implications for life chances subject to human review before action is taken? 12. minimizationšif risks and harm are associated with a tactic, is it applied to minimize risk and harm with only the degree of intrusiveness and invasiveness that is absolutely necessary? 13. alternativesšare alternative solutions available that would meet the same ends with lesser costs and greater benets (using a variety of measures, not just nancial measures)? 14. inaction as actionšhas consideration been given to the principle that sometimes it is better to do nothing? 15. periodic reviewšare there regular efforts to test the system™s vulnerability, effectiveness, and fairness and to review policies? 16. discovery and rectication of mistakes, errors, and abusesšare there clear means for identifying and xing these (and in the case of abuse, applying sanctions)? 17. right of inspectionšcan individuals see and challenge their own records? 18. reversibilityšif evidence suggests that the costs outweigh the benets, how easily can the surveillance be stopped (e.g., extent of capital expenditures and available alternatives)? 19. unintended consequencesšhas adequate consideration been given to undesirable consequences, including possible harm to watchers, the watched, and third parties? can harm be easily discovered and compensated for? 20. data protection and securityšcan data collectors protect the information they collect? do they follow standard data protection and information rights as expressed in the code of fair information protection practices and the expanded european data protection directive?source: g.t. marx, ﬁseeing hazily (but not darkly) through the lens: some recent empirical studies of surveillance technologies,ﬂ law and social inquiry 30(2):339400, 2005.of society. large amounts of information are being gathered by agencies in many areas of u.s. society, whether it be government, the private commercial sector, or the noncommercial sector. this information is being aggregated, mined, and exchanged in ways about which most of us are unaware. although some situations (such as the use of rfid tags) have attracted public attention, others (such as the aggregation of information in data services such as choicepoint) are not known about until a major breach is announced.another feature of privacy that this chapter illustrates is that often it is not the gathering of information itself that is a violation of privacy, but rather the use of that information. schools, for example, need to gather large amounts of information about their students to be able to design classes for those students, among other purposes. but that same information can be used to provide marketing information, and that secondary use can lead to the perception of a violation of privacy.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy and organizations 207box 6.3 questions for judgments and policies about privacy 1. goalsšhave the goals been clearly stated, justied, and prioritized? are they consistent with the values of a democratic society? 2. accountable, public, and participatory policy developmentšhas the decision to apply the technique been developed through an open process, and if appropriate, with the participation of those to be surveilled? this involves a transparency principle. 3. law and ethicsšare the means and ends not only legal but also ethical? 4. opening doorsšhas adequate thought been given to precedentcreation and longterm consequences? 5. golden rulešwould the watcher be comfortable in being the subject rather than the agent of surveillance if the situation were reversed? is reciprocity or equivalence possible and appropriate? 6. informed consentšare participants apprised of the system™s presence and the conditions under which it operates? what exceptions to informed consent are deemed legitimate? is consent genuine (i.e., beyond a response to deception or unreasonable seduction) and can participation be refused without dire consequences for the person? 7. truth in usešwhere personal and private information is involved, does a principle of unitary usage apply, whereby information collected for one purpose is not used for another? are the announced goals the real goals? 8. meansends relationshipsšare the means clearly related to the end sought and proportional in costs and benets to the goals? 9. can science save us?šcan a strong empirical and logical case be made that a means will in fact have the broad positive consequences its advocates claim? 10. competent applicationševen if in theory it works, does the system (or operative) using it apply it as intended? 11. human reviewšare automated results with signicant implications for life chances subject to human review before action is taken? 12. minimizationšif risks and harm are associated with a tactic, is it applied to minimize risk and harm with only the degree of intrusiveness and invasiveness that is absolutely necessary? 13. alternativesšare alternative solutions available that would meet the same ends with lesser costs and greater benets (using a variety of measures, not just nancial measures)? 14. inaction as actionšhas consideration been given to the principle that sometimes it is better to do nothing? 15. periodic reviewšare there regular efforts to test the system™s vulnerability, effectiveness, and fairness and to review policies? 16. discovery and rectication of mistakes, errors, and abusesšare there clear means for identifying and xing these (and in the case of abuse, applying sanctions)? 17. right of inspectionšcan individuals see and challenge their own records? 18. reversibilityšif evidence suggests that the costs outweigh the benets, how easily can the surveillance be stopped (e.g., extent of capital expenditures and available alternatives)? 19. unintended consequencesšhas adequate consideration been given to undesirable consequences, including possible harm to watchers, the watched, and third parties? can harm be easily discovered and compensated for? 20. data protection and securityšcan data collectors protect the information they collect? do they follow standard data protection and information rights as expressed in the code of fair information protection practices and the expanded european data protection directive?source: g.t. marx, ﬁseeing hazily (but not darkly) through the lens: some recent empirical studies of surveillance technologies,ﬂ law and social inquiry 30(2):339400, 2005.there can even be differences in the perceived threat to privacy for the same action seen from different viewpoints. for example, information on past purchases can be used by marketing organizations to send out more targeted catalogs; this is seen by the marketing organizations as a way of cutting down the number of catalogs that a consumer receives (and thus is a way of giving that customer better, more personalized service). but some customers see this use of information as a mechanism to build a dossier of the customer™s likes and dislikes, and therefore as a violation of the privacy of the customer.abstracting across the domains outlined in sections 6.2 to 6.8, a number of generic questions are suggested by the privacy issues these domains raise (box 6.3). asked about any proposed collection of personal information, these questions can help to indicate the complexity of these issues.there are no simple answers in this complex of issues surrounding privacy. the principles implied in these issues are not necessarily of equal engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.208 engaging privacy and information technology in a digital ageweight and are sometimes even in tension. they touch on other issues involving innovation, property rights, the desire to provide customers better and more personalized services, and improvement of efciency and protability by gathering more information. furthermore, their applicability will vary depending on perceptions of crisis and across contexts (e.g., public health, law enforcement, and national security may involve exemptions that would be inappropriate for the private sector or individuals). a snapshot view of these institutions selectively illustrates some of the problems that will have to be addressed in thinking about privacy in an age of information.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.2097health and medical privacyhealth and medical information (including medical records, prescription histories, patient data, surgical records, and so on) is one of the most obvious of those types of information that have long been considered to be personal and deserving of privacy protection. not only are the intuitions of most people nearly universal regarding the need for privacy in the medical and health arena, but the need to keep private the information about a patient™s health has also been recognized as a requirement since the time of the hippocratic oath. yet trends in the collection, storage, and use of health information collectively have made this area one of the most worried about by those who believe that privacy is being eroded.7.1 information and the practice of health careinformation has traditionally been a central aspect of health care, touching the science, the practice, the equipment, and the business of medicine. health and medical information is also basic to the interpersonal and institutional relationships of individuals (e.g., involving expectations about sharing intimate health information with close friends or undergoing health exams for employment). moreover, advances in the science of medicine have led to more types of information being relevant to patient care.health care information also has particular relevance apart from an individual™s health. taken in the aggregate over many people, longterm largescale population studies allow the discovery of statistical correlaengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.210 engaging privacy and information technology in a digital agetions between environmental factors and disease and are also used to help assess the efcacy of treatments, to determine the overall costs of particular kinds of treatment regimes, and to conduct epidemiological research that can generate insight into the genesis, development, and spread of disease.in addition, advances in the integration of computing with sensing devices have led to new generations of instruments for the medical profession, from enhanced magnetic resonance imaging devices to improved equipment for testing blood chemistry. these devices now generate information about individuals which would, in a very real sense, not have been possible to obtain without the information revolution, and the information they provide is more revealing than what was available in the past. such advances are the latest manifestation of an evolution of medical practice from a nearexclusive focus on the presentday symptoms of a patient to a search for root causes of those symptoms, and an increasing ability to determine predispositions and susceptibility, in advance, for preemptive medical action.the greater availability of more types of patient information has changed how medicine is practiced. the model of 50 years ago, where each person had a single physician who dealt with all of the medical aspects of the patient, has been replaced with group practices and health maintenance organizations in which groups of specialists work together to deal with the needs of a patient. even if an individual has a primary health care provider, that provider may be a nurse practitioner as well as a physician, and may well be the agent of referral to other specialists rather than the single source of medical care. in turn, the need for medical specialists is directly related to the growth in medical knowledgešmuch more is known now about disease and treatment than was understood in the notsodistant past, and no single doctor can be asked to know all of the complexities and details associated with all of this information or to keep up with the ongoing rapid changes in knowledge.the new information environment for medicine has been driven both by new instrumentation and new information technology. new instruments enable new kinds of information to be gathered about patients, and the increasing volume of information can be managed only with the use of information technology. furthermore, the ability to store, retrieve, and transfer information from caregiver to caregiver supports the continuity of care that has to be maintained from one specialist to another, as patient records can be collected, collated, and interpreted by all of the members (perhaps geographically dispersed) of the medical team.these changes in the practice of medicine have correlates in changes in the business of medicine that also have been enabled and encouraged by the use of information technology. the expanding number of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 211people involved in providing medical care to an individual has been more than paralleled by the growing number of those involved in paying for that care. the payment trails from ofce and hospital practice through insurance company and employer all make extensive use of information technologies.7.2 privacy in medicineprivacy has been a part of medical practice since the 4th century b.c. the classical version of the hippocratic oath for physicians states, ﬁwhat i may see or hear in the course of the treatment or even outside of the treatment in regard to the life of men, which on no account one must spread abroad, i will keep to myself, holding such things shameful to be spoken about.ﬂ1it is not surprising that medical practice requires privacy. the patient is the source of much of the information that relates to his or her health, and if the physician (or more generally, the caregiver) is to obtain the information needed to make good medical decisions about the patient, the patient must be persuaded to provide it. put differently, patient candor is an essential element of health care and depends heavily on the patient™s condence that the information provided will indeed be kept private. patient cooperation is also needed for laboratory testing and analysis and for treatment, particularly when treatment is ongoing.from the patient™s perspective, medical information is often the most privacysensitive personal information that they provide. for these reasons, protecting medical privacy has long been recognized as an essential element of any regulatory system in health care.as a point of departure, consider the issue of privacy as it relates to certain medical issues. using the anchoring vignette approach described in section 2.4 (see box 2.2), a possible survey question might be, to what degree does [your/ ﬁname™sﬂ] doctor respect [your/his/her] privacy? here are a number of possible vignettes:1. [renée] is ill and goes to the hospital to consult with the doctor. after she steps into the consultation room, the doctor closes the door and tells her that everything she says is condential.2. [alioune] is ill and goes to the hospital to consult with the doctor. while he is in the consultation room, a nurse opens the door several times 1 the modern version reads as follows: ﬁi will respect the privacy of my patients, for their problems are not disclosed to me that the world may know.ﬂ for both versions, see http://www.medterms.com/script/main/art.asp?articlekey=20909.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.212 engaging privacy and information technology in a digital ageto give messages to the doctor, allowing people in the waiting room to catch parts of his conversation with the doctor.3. [chandikha] is ill and goes to the hospital to consult with the doctor. the doctor forgets to close the door of the consultation room. as a result, individuals in the hallway or waiting room are able to hear their conversation.4. [ben] is ill and goes to the hospital to consult with the doctor. the doctor takes notes of their conversation and orders a number of tests to be done. the doctor misplaces this le, including the notes and orders for tests, among the magazines in the waiting room. individuals in the waiting room are thereby able to see the le.5. [paul] is ill and goes to the hospital to consult with the doctor. the hospital maintains an electronic database of all diagnoses, tests, and treatments. the database is hacked and all the information, including that of [paul™s] visit, is posted online.by design, this set of anchoring vignettes constitutes one specic domain of privacy, capturing some of the essential issues that face patients, doctors, hospitals, and public policy makers. due to changes in information technology, for example, protecting medical privacy is more difcult today than just a few years ago for many reasons:ł more patient information is collected, both in volume and in types of information.ł more people have access to patient information, including medical caregivers, researchers, and administrators in the health care system and, in many cases, employers and government agencies outside it.ł patient information is more easily accessible because it is increasingly stored in digital form (and so it can be transmitted more easily than in paper form).ł patient information is held for very long periods of time, and the longer it remains in existence the greater the opportunities for abuse.ł more patient information is being collected by types and in volumes that are intended to aid medical practitioners in predicting future medical conditions with greater accuracy.ł patient information (such as dna information) is being (or soon will be) collected that has relevance to individuals related to the patient (parents, siblings, current and future offspring), thus raising the potential for signicant violations of medical privacy and complicating both the technical and ethical issues involved in managing such information.such factors make individuals nervous about their medical privacy, since in a very real sense the individual is no longer in control of what engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 213persons, or even what organizations, have access to their medical records. box 7.1 provides additional discussion.these concerns are enhanced by the fact that the collected medical records provide a storehouse of information that can be used in a variety of ways other than those intended when the information was rst collected. these records can also be used for the marketing of particular drugs, or for the denial of medical health insurance coverage. such uses, often seen as invasions of privacy, are more than just hypothetical possibilities; actual cases in which medical information has been used and misused in such ways have been reported in the press, leading to fears about the overall privacy of medical information. in an industry that combines business, treatment, and research, it is often difcult to draw clear lines delineating where information gathered for one of these purposes slips into being used for another.the issue of the repurposing of personal information in areas unexpected by the individual recurs as a theme throughout this report as it affects a variety of domains of privacy, and it is no less important here. as a point of departure, consider the issue of privacy as it relates to the repurposing of personal health information. using the anchoring vignette approach, a possible survey question might be, when obtaining a medical diagnosis from [your/ﬁname™sﬂ] doctor, how much privacy [do you/does he/she] have about that medical condition? here are a number of possible vignettes:1. [alexandra] is diagnosed with diabetes. her doctor makes a note of the diagnosis in his own patient database.2. [margareta] is diagnosed with diabetes. her doctor makes a note of the diagnosis to the insurance company, which uses the information to calculate reimbursements and then discards the diagnosis.3. [gerard] is diagnosed with diabetes. his doctor makes a note of the diagnosis to the insurance company, which uses the information to calculate reimbursements and then adds it to an internal database of all medical histories of its clients.4. [bobbie] is diagnosed with diabetes. his doctor makes a note of the diagnosis in the university hospital database. this information is available to university researchers, and [bobbie] receives several solicitations for participation in a diabetes study being conducted by the university™s public health school.5. [danny] is diagnosed with diabetes. his doctor makes a note of the diagnosis in the hospital database. the hospital then enters into a joint venture with a multinational drug company, and [danny] receives numerous sample diabetes drugs via mail from that company.6. [joanna] is diagnosed with diabetes. her doctor makes a note of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.214 engaging privacy and information technology in a digital agebox 7.1 personal health information, the availability of health insurance, and privacy the privacy of personal health information looms large in many policy debates, and most people believe that such information is entitled to a very high degree of privacy. the essential public policy argument is over whether personal health information should be available to companies that offer health insurance, for use either as a screening device or as a mechanism to set rates for the primary provider of information or even for relatives who are tied to that information. (for purposes of this discussion, the health care payers™ needs for specic information related to payments for medical procedures already performed are not at issue; there is little controversy associated with the need for personal health information to prevent fraudulent billing.) the argument against allowing insurance companies to have access to such information often asserts that nothing is more personal than personal health information, and holds that an individual should not be forced, either explicitly (as a requirement for coverage) or implicitly (by being given possible rate incentives) to reveal this information to outside parties such as health insurance companies. moreover, the argument goes, individualsšbased on their genetic propensity toward a disease or on their personal medical historyšmight be denied health coverage and thus effectively health care, which without insurance would be prohibitively expensive. since these are the people who are most likely to need access to that health care system, denial of coverage is inherently improper and should be contrary to public policy. the health insurers argue that their economic wellbeing depends on their being able to use personal health information to assign each applicant to the appropriate risk pool, thereby enabling them to run their business in a more accurate and efcient manner. in this view, dna information or hiv status or mental health history or family history should be treated no differently than any other kind of personal health information. further, health care insurers fear a world in which those seeking insurance have more information about their future health probabilities than is available to the insurance companies. in that case those unlikely to have health care problems could remove themselves from the shared risk pool, whereas those at a high risk for future disease would enroll. insurance companies denied access to personal health information would be unable to do the actuarial assessments necessary to set their rate structures differentially so as to provide service to a broad population and to prosper as companies. conversely, health care insurers believe it is to their advantage to be able to ﬁcherry pick,ﬂ by providing coverage preferentially or at lower cost to those unlikely to use a great deal of medical care, and the availability of personal health information helps them to identify such individuals. seen in this light, the fundamental underpinnings of the health care privacy/health insurance debate concern whether or not access to medical care is a basic right that should be guaranteed for all. those arguing for the privacy of certain kinds of personal health information (at least with regards to denying access to health insurance companies) tend to believe that health insurance is a requirement for access to medical care, and that such access is a basic need that should not be denied to anyone. the insurers, on the other hand, see health insurance as a product being offered by protmaking companies, which can obtain an adequate return on their investments only if they are able to set rates based on the future risk calculated on the individual being insured. if this risk is too high, then the individual can be denied coverage, or given coverage only at very high prices. from the standpoint of an individual wondering about providing personal health information, the relevant issue is a matter of privacy. that is, given the lack of national consensus on whether or not health care is a basic right, his or her only decisionšas an individualšis whether or not to provide information that might ultimately result in the denial or excessive pricing of health care services. but at the policy level, there is in addition to the debate over privacy another debate about the right to and the mechanisms for access to the health care system in this country. the latter debate is important and is being discussed in many venues. however, these two debates should not be con˚ated. the addition of dna information to the personal health information of an individual creates complexities of a different order. indeed, sensitivities have arisen in recent years due to the possibilityšindeed the high likelihoodšthat medical records will soon contain increasing amounts of information about a person™s dna. the expected benets of dna information are large, because it can be used to predict the probability of future disease in an individual or the success of any given treatment for that individual. but dna information can be extraordinarily revealing about a person™s medical predispositions. perhaps more signicantly, the dna information of an individual reveals genetic truths (and secrets) not just about that individual, but also about his or her relativesša dimension much less present for other kinds of personal health information. this is not to say that dna information is necessarily more sensitive or more deserving of protection than information about an individual™s hiv status, for example. but dna information and to a much lesser extent familial history raise the question of the party or parties that should be identied as the providers or the owners of such information, and therefore whose interests are compromised when an individual chooses to release ﬁhisﬂ or ﬁherﬂ dna information. as an illustration, consider that it is controversial today to base coverage decisions on conditions beyond an individual™s control; such a case would surely involve dna information as an instance. consider also the implications that an individual™s father or child might be denied medical coverage on the basis of the individual™s provision of dna information.the diagnosis in the hospital database. the database is hacked and the information is posted online. a software company extracts the information and sells the database on cd to pharmaceutical companies.a key issue here is the repurposing of information in unexpected areas. the importance of medical information to individuals, businesses, researchers, and doctors explains why this is such a sensitive issue. moreengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 215box 7.1 personal health information, the availability of health insurance, and privacy the privacy of personal health information looms large in many policy debates, and most people believe that such information is entitled to a very high degree of privacy. the essential public policy argument is over whether personal health information should be available to companies that offer health insurance, for use either as a screening device or as a mechanism to set rates for the primary provider of information or even for relatives who are tied to that information. (for purposes of this discussion, the health care payers™ needs for specic information related to payments for medical procedures already performed are not at issue; there is little controversy associated with the need for personal health information to prevent fraudulent billing.) the argument against allowing insurance companies to have access to such information often asserts that nothing is more personal than personal health information, and holds that an individual should not be forced, either explicitly (as a requirement for coverage) or implicitly (by being given possible rate incentives) to reveal this information to outside parties such as health insurance companies. moreover, the argument goes, individualsšbased on their genetic propensity toward a disease or on their personal medical historyšmight be denied health coverage and thus effectively health care, which without insurance would be prohibitively expensive. since these are the people who are most likely to need access to that health care system, denial of coverage is inherently improper and should be contrary to public policy. the health insurers argue that their economic wellbeing depends on their being able to use personal health information to assign each applicant to the appropriate risk pool, thereby enabling them to run their business in a more accurate and efcient manner. in this view, dna information or hiv status or mental health history or family history should be treated no differently than any other kind of personal health information. further, health care insurers fear a world in which those seeking insurance have more information about their future health probabilities than is available to the insurance companies. in that case those unlikely to have health care problems could remove themselves from the shared risk pool, whereas those at a high risk for future disease would enroll. insurance companies denied access to personal health information would be unable to do the actuarial assessments necessary to set their rate structures differentially so as to provide service to a broad population and to prosper as companies. conversely, health care insurers believe it is to their advantage to be able to ﬁcherry pick,ﬂ by providing coverage preferentially or at lower cost to those unlikely to use a great deal of medical care, and the availability of personal health information helps them to identify such individuals. seen in this light, the fundamental underpinnings of the health care privacy/health insurance debate concern whether or not access to medical care is a basic right that should be guaranteed for all. those arguing for the privacy of certain kinds of personal health information (at least with regards to denying access to health insurance companies) tend to believe that health insurance is a requirement for access to medical care, and that such access is a basic need that should not be denied to anyone. the insurers, on the other hand, see health insurance as a product being offered by protmaking companies, which can obtain an adequate return on their investments only if they are able to set rates based on the future risk calculated on the individual being insured. if this risk is too high, then the individual can be denied coverage, or given coverage only at very high prices. from the standpoint of an individual wondering about providing personal health information, the relevant issue is a matter of privacy. that is, given the lack of national consensus on whether or not health care is a basic right, his or her only decisionšas an individualšis whether or not to provide information that might ultimately result in the denial or excessive pricing of health care services. but at the policy level, there is in addition to the debate over privacy another debate about the right to and the mechanisms for access to the health care system in this country. the latter debate is important and is being discussed in many venues. however, these two debates should not be con˚ated. the addition of dna information to the personal health information of an individual creates complexities of a different order. indeed, sensitivities have arisen in recent years due to the possibilityšindeed the high likelihoodšthat medical records will soon contain increasing amounts of information about a person™s dna. the expected benets of dna information are large, because it can be used to predict the probability of future disease in an individual or the success of any given treatment for that individual. but dna information can be extraordinarily revealing about a person™s medical predispositions. perhaps more signicantly, the dna information of an individual reveals genetic truths (and secrets) not just about that individual, but also about his or her relativesša dimension much less present for other kinds of personal health information. this is not to say that dna information is necessarily more sensitive or more deserving of protection than information about an individual™s hiv status, for example. but dna information and to a much lesser extent familial history raise the question of the party or parties that should be identied as the providers or the owners of such information, and therefore whose interests are compromised when an individual chooses to release ﬁhisﬂ or ﬁherﬂ dna information. as an illustration, consider that it is controversial today to base coverage decisions on conditions beyond an individual™s control; such a case would surely involve dna information as an instance. consider also the implications that an individual™s father or child might be denied medical coverage on the basis of the individual™s provision of dna information.over, the trend toward increased collection of medical data, coupled with increased sharing of that information for a multitude of purposes, is accelerating. the vignettes given above, ordered from most to least protective of privacy, help to provide a context that is relevant for informed decision making about what level of privacy is acceptable or required in the medical domain.the recent mapping of the human genome, which would have been engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.216 engaging privacy and information technology in a digital ageimpossible without the increased power of informationprocessing equipment, continues to open new areas for the collection of data about each of us that has the potential to aid in the prevention, diagnoses, and treatment of disease as well as to increase the knowledge of medical science concerning the genetic components of health and longevity. however, the possibilities for the abuse of such information are immense and of great concern to those who want to ensure the privacy of personal health information. although the technology for obtaining this information is being developed rapidly, we have yet to answer the important questions of who should have access to that information and for what purposesšand the longer such questions go unanswered, the greater the longterm risk of irreversible consequences.7.3 addressing issues in access to and use of health datathis section examines four approaches to addressing the challenges posed by questions regarding access to and use of individuals™ health and medical information: industry selfregulation, legislation and regulation, consumer/patient awareness, and ofcial advocacy. of course, these are not necessarily mutually exclusive, but we provide examples from each to demonstrate the variety of strategies being explored in this space.7.3.1 industry selfregulationa direct attempt to deal with issues about the privacy of medical information is the ethical force program of the american medical association (ama),2 which lays out principles for the ethical treatment of patients and information about those patients. in addition, the program seeks to formulate performance measures to enable evaluation of whether or not those principles are being followed.as would be expected from a program staffed by and directed toward professionals in the health care industries,3 the ethical force program re˚ects a keen awareness of the tensions and requirements of 2 ethical force program, protecting identiable health care informationl privacy: a consensus report on eight content areas for performance measure development, american medical association, december 2000, available at http://www.amaassn.org/ama/pub/category/7726.html.3 the ethical force program is intended to apply to every individual or organization that has access to or uses identiable health care information. however, the primary constituency of the ama is physicians, thus leaving open the question of comparable efforts by professional organizations related to nurses, laboratory technicians, hospital administrators, and so on.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 217the business, treatment, and science aspects of medicine. as such, its principles for the privacy of individually identiable information are both complex and nuanced. based on the concepts of informed consent for the collection and use of information, limitations on the information collected, and limitations on the use to which the collected information is put, each of these principles is seen not as an absolute, but rather as a starting point from which exceptions can be identied.the notion of informed consent is justied by an appeal to ﬁwellaccepted principles of autonomy and respect for persons.ﬂ4 informed consent for the collection or use of personally identiable information should be obtained ﬁwhenever feasibleﬂ; however, the ama report on the ethical force program then goes on to note that there are circumstances in which such consent is either not feasible or not needed. cases where the consent is not feasible should be reviewed by some ﬁformal, authoritative, and publicly accountable process.ﬂ furthermore, in cases where the sharing of identiable health information ﬁconfer[s] direct therapeutic or diagnostic benet on the person whose information is at issue,ﬂ no informed consent is needed at all. interestingly, the sharing of information with an insurance company for the payment of medical claims is considered to confer a direct therapeutic effect on the individual, and hence does not require any form of informed consent.a second principle of the ethical force guidelines is that of limiting the information collected to that which is ﬁrequired for current needs, or reasonably projected future needs, which are made explicit at the time consent is obtained.ﬂ this principle is reinforced in the notion of uselimitation; even when limits have been observed in the collection of information, the use of that information should also be limited to those purposes for which the information was originally obtained. (of course, because modern information technology facilitates the longterm storage of information, the future will almost certainly see many possible uses of information that cannot be foreseen today.)a third principle is that patients should have access to their records and be able to amend or append information to such les (although not necessarily to delete information, even if that information is found to be in error).5the ethical force guidelines also recognize that there will be excep4 ethical force program, protecting identiable health care informational privacy, december 2000.5 an important policy question arises regarding the deletion of erroneous information. on the one hand, the presence of information known to be erroneous may cause subsequent confusion or misunderstandingša point that argues for deleting it. on the other hand, information that is found to be in error can be useful for monitoring the process of patient careša point that argues for ˚agging it but not deleting it.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.218 engaging privacy and information technology in a digital agetions to the principles established. one such exception, having to do with the ability to release information when it is for the direct therapeutic benet of the individual, is noted above. in addition, the guidelines recognize that legal requirements from law enforcement or public health agencies sometimes require the release of personally identiable information without the consent of the individual. in addition, information can be released if it is released in a form that allows only statistical study and not the identication of the individuals whose data are released (box 7.2 addresses this topic in more detail). finally, the guidelines allow the release and use of such information that would otherwise be in violation of the guidelines if that use has been approved by an agency (such as an institutional review board) that has followed some welldened, publicly accountable process of review.the nuances in the ethical force principles echo the complexities of the balance between medicine as a business, as a service to individuals, and as a science. the need to share information freely with other medical professionals for the therapeutic good of the patient is a clear re˚ection of the overriding concern of treating the patient, along with the specialization in and collaborative nature of current medical practice. the inclusion of sharing information with insurers to allow payment for the treatment received re˚ects the business aspect of medicine. but the exceptions for access in accordance with the law re˚ects the history of public health in this country, where laws have been passed that recognize the need to violate the privacy of the individual in cases where the health of the general public is put at risk. finally, the ability to override the privacy of the individual if allowed after review by a publicly accountable board ensures the possibility of using information in medical records for the purpose of scientic studies.in most cases, the normative preferences of many individuals would allow some consideration of the balance between the privacy of the individual™s medical information and the advances in scientic knowledge possible for society if that information is available to researchers. but this is not a trivial issue in the medical domain, and the issue can be put quite starkly: if it weren™t for prohibitions on access to information due to privacy concerns, it might be possible to help many people live longer and more healthy lives. determining what portions of individual information are acceptable to protect or distribute then becomes a critical issue.to illustrate, consider the issue of privacy as it relates to researchers obtaining personal health information. using the anchoring vignette approach, a possible survey question might be, during [your/ﬂname™sﬂ] [most recent] hospital treatment, how much privacy did [you/she/he] have from medical researchers? here are a number of possible vignettes:engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 2191. [george] is a cancer patient at the university hospital. the hospital maintains a policy of complete separation of research and treatment, and assures him that his le will never be accessed by anyone but his doctor.2. [elaine] is a cancer patient at the university hospital. as a condition of being a patient, she must let data on her recovery be used anonymously in a study of several thousand cancer patients nationwide. her tests will only be reported as a small part of an average across all patients.3. [tinika] is a cancer patient at the university hospital. as a condition of being a patient, she must release her le to the hospital, to be used as an anonymous case study for the hospital training manual.4. [mark] is a cancer patient at the university hospital. the hospital requires that all patients allow their medical les to be used for research purposes. any medical researcher may obtain [mark™s] le.7.3.2 legislationšhipaa and privacythe most comprehensive legislative attempt to address the issues around the uses of individual health information is the health insurance portability and accountability act (hipaa) of 1996. this act, one of the outcomes of the clinton administration™s attempt to deal with the overall state of health care in the united states, had as its purpose the protection of health insurance coverage for workers and their families when workers changed or lost their job. however, as is often the case in such bills, the attempt to provide portability of coverage grew to encompass a number of other areas, as well.portability required that the insurance companies adopt a common way of representing the medical information about the insured. this common format was also seen as a way of introducing efciencies in the transmission and payment of claims from health care providers to the insurance companies, and so the effort toward portability also included establishing standards for electronic health care transactions, as well as national identiers for providers, health plans, and employers. the hope was that by enabling a common format, the industry could adopt electronic means of transmitting and settling claims, which would in turn allow a reduction in the administrative costs of the health system. this administrative cost has been estimated to be 25 percent of the overall cost of the health system in the united states, and so reductions of such costs could have a signicant impact on the overall cost of health care.although using standardized format for medical information to enable electronic transfer of information was intended to lead to considerable savings and efciencies, legislators also realized that such standardization and transmission opened the possibility of misuse and privacy invasion. because of this, the hipaa legislation addressed the concerns of privacy engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.220 engaging privacy and information technology in a digital agebox 7.2 the anonymization and deidentification of data both the american medical association™s ethical force guidelines1 and the privacy regulations related to the health insurance portability and accountability act (hippa) make a distinction between the use of personally identiable medical information and the use of that same information put into a form that cannot be traced back to the individuals associated with that information. if this is possible, questions of personal privacy having to do with access to that information become moot. however, it turns out that it is very difcult to draw a bright or even a stable line between these two kinds of information. there is a class of information that is obviously identifying of individuals, such as their social security number, the combination of their name and address, or a listing of the names of the immediate family members. (under hipaa, personal identiers include name, address including city and zip code, telephone number, fax number, email address, social security number, date of birth, medical record number, health plan identication number, and dates of treatment.) the excising of such information from a listing of medical data is generally what is thought of by most when they think of deidentication of a medical record. however, statistical techniques can be used to determine the identity of individuals given far less obvious markers. for example, given the location of residence at the level of granularity of a voting district, and the date of birth of a subject (both the day and the year), there is a high probability that a single individual will be identied. this is surprising to many, but is simply an outcome of the statistical distribution of birth dates and the size of voting districts. the ability to perform such statistical identication has a signicant impact on medical research that mines historical data. researchers in this area are generally unable to obtain informed consent from those whose records are being used because of the large sample sizes that are mined in such studies. often many of the subjects are unavailable to provide such consent, either because they are deceased or because the contact information in the record is out of date. without such consent, both the ethics of the profession and current federal privacy regulations mandate that the information be rendered anonymous. there are technologies for anonymization that have been developed for statistical disclosure limitation. as noted in chapter 3, the core concept behind such technology is to randomly scramble the information in complex records in such a way as to make it impractical to correlate an individual record and a particular person while maintaining the statistical relationships between those parts of the record being analyzed. however, such technologies can often mask just the kinds of relationships that medical research is trying to discover. when the information to be correlated is known before the anonymization occurs, such techniques are often valuable. however, often these studies are an attempt to discover correlations that are not known before examining the data. in such cases, deidentication can mask the very correlations that are the goal of the study. part of the problem with the notion of anonymization of records is that the regulations regarding the use of anonymized information treat the notion as a binary relationšeither the record has been anonymized, or it is individually identiable information. however, since much of the information is such that it lends itself to statistical correlation, the notion of anonymization is more accurately represented as a probability that the collection of information can be used to identify an individual out of a target population at an affordable cost. if the probability must be zero, much of the wealth of medical information that is available for longterm statistical study will be far more difcult to obtain or use in such research. a further confusion is that guidelines and regulations often speak of ﬁdeidentiedﬂ information even though a close reading suggests that they mean anonymized (i.e., information for which reidentication is for practical purposes impossible).and security. while the bill itself did not include any provisions governing the privacy and security of personal health information, it did contain language committing congress to pass legislation addressing those concerns. further, if congress was unable to pass such legislation within 3 years of the passage of the hipaa bill itself, the legislation directed the department of health and human services to draw up a regulation covering those areas.the hipaa bill was passed and signed into law in 1996. by 1999 it was clear that congress was not going to be able to draft and pass a bill that addressed the privacy and security concerns that had been outlined in the original bill. at that time, the department of health and human services began drafting regulations designed to improve the privacy of personal health information and the security of such information as it was 1ethical force program, protecting identiable health care informational privacy: a consensus report on eight content areas for performance measure development, american medical association, december 2000, available at http://www.amaassn.org/ama/pub/category/7726.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 221box 7.2 the anonymization and deidentification of data both the american medical association™s ethical force guidelines1 and the privacy regulations related to the health insurance portability and accountability act (hippa) make a distinction between the use of personally identiable medical information and the use of that same information put into a form that cannot be traced back to the individuals associated with that information. if this is possible, questions of personal privacy having to do with access to that information become moot. however, it turns out that it is very difcult to draw a bright or even a stable line between these two kinds of information. there is a class of information that is obviously identifying of individuals, such as their social security number, the combination of their name and address, or a listing of the names of the immediate family members. (under hipaa, personal identiers include name, address including city and zip code, telephone number, fax number, email address, social security number, date of birth, medical record number, health plan identication number, and dates of treatment.) the excising of such information from a listing of medical data is generally what is thought of by most when they think of deidentication of a medical record. however, statistical techniques can be used to determine the identity of individuals given far less obvious markers. for example, given the location of residence at the level of granularity of a voting district, and the date of birth of a subject (both the day and the year), there is a high probability that a single individual will be identied. this is surprising to many, but is simply an outcome of the statistical distribution of birth dates and the size of voting districts. the ability to perform such statistical identication has a signicant impact on medical research that mines historical data. researchers in this area are generally unable to obtain informed consent from those whose records are being used because of the large sample sizes that are mined in such studies. often many of the subjects are unavailable to provide such consent, either because they are deceased or because the contact information in the record is out of date. without such consent, both the ethics of the profession and current federal privacy regulations mandate that the information be rendered anonymous. there are technologies for anonymization that have been developed for statistical disclosure limitation. as noted in chapter 3, the core concept behind such technology is to randomly scramble the information in complex records in such a way as to make it impractical to correlate an individual record and a particular person while maintaining the statistical relationships between those parts of the record being analyzed. however, such technologies can often mask just the kinds of relationships that medical research is trying to discover. when the information to be correlated is known before the anonymization occurs, such techniques are often valuable. however, often these studies are an attempt to discover correlations that are not known before examining the data. in such cases, deidentication can mask the very correlations that are the goal of the study. part of the problem with the notion of anonymization of records is that the regulations regarding the use of anonymized information treat the notion as a binary relationšeither the record has been anonymized, or it is individually identiable information. however, since much of the information is such that it lends itself to statistical correlation, the notion of anonymization is more accurately represented as a probability that the collection of information can be used to identify an individual out of a target population at an affordable cost. if the probability must be zero, much of the wealth of medical information that is available for longterm statistical study will be far more difcult to obtain or use in such research. a further confusion is that guidelines and regulations often speak of ﬁdeidentiedﬂ information even though a close reading suggests that they mean anonymized (i.e., information for which reidentication is for practical purposes impossible).stored and transmitted by those entities covered by the hipaa law. these regulations became nal in 2002, and their phased introduction began in april 2003.like the policy set forward by the ama ethical force program, the privacy regulation that is part of hipaa is based on the principle of informed consent. with certain statutory exceptions (such as use of information for the purposes of treatment, payment, or health care operations, or for law enforcement or research purposes), consent of the individual must be obtained for all uses and disclosures of personally identiable health information. in addition, the hipaa privacy regulations require that all covered entities (a category that includes all government health plans, private sector health plans and managed care organizations, health care providers who submit claims for reimbursement and payment clearengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.222 engaging privacy and information technology in a digital ageinghousesšeffectively, all members of the health care industry other than certain small selfadministered health plans) must train every member of their workforce in privacy protection, must appoint a privacy ofcer, and must provide notice of their privacy policies to all of their members and patients. individuals can request copies of health care information kept about them, and can request corrections and amendments of that information.the privacy regulation acknowledges that the burden of receiving informed consent may be unreasonable for researchers attempting to do largescale studies based on collections of personally identiable medical information. both the use of deidentied information and the use of personally identiable information whose use has been approved by an institutional review board are allowed by the hipaa privacy regulations, although the latter is the case only if the conditions for waiver specied under the socalled common rule are met,6 or under a few other limited circumstances. however, the guidelines for when such use is allowed are not clear to practitioners in the eld. nor are they without cost; protecting patient privacy is an overhead expense that might not be incurred absent hipaa regulations.while the privacy regulation focuses on the rights of the individual, it does not give the individual the right of action against those that are claimed to have violated the regulation. individuals who believe that their privacy rights under the regulation have not been met must rst complain to the health and human services ofce of civil rights, which is the government agency charged with enforcing the regulation.the hipaa privacy regulation was met with considerable trepidation by members of the health care industry. the regulation was complex enough (at 31 pages) that it was difcult to know what was required for compliance; some of the requirements that were understood (such as those having to do with training of staff or mass notication of patients about their privacy rights under hipaa) involved considerable cost.the overall efcacy of informing patients of privacy policies seems minimal, much as has been the case in the nancial industry with the similar requirements of grammleachbliley, and there has been some degree of confusion among care providers about the nature and extent of personal health information that may be provided, and to whom and 6 the common rule directs research institutions to assure the federal government that it will provide and enforce protections for human subjects of research conducted under its auspices. these institutions are responsible for assessing research proposals in terms of their risks to subjects and their potential benets, and they must see that the common rule™s requirements for selecting subjects and obtaining informed consent are met. common rule requirements are set forth in title 45 of the code of federal regulations, part 46, subpart a.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 223under what circumstances.7 whether this confusion merely re˚ects a transitional effect between prehipaa and posthipaa regimes remains to be seen.the requirement for training has been seen by some as a way of changing the culture of the medical provider profession in a way that is positive albeit costly. the impact on researchers, especially those wishing to do largescale and longterm investigations across sets of medical records, is currently unknown; however, the formulation of the privacy regulation has created a mechanism for dialog between researchers and regulators.finally, there remains the question of enforcement of hipaa™s privacy regulations. in june 2006, the washington post reported that in the 3 years since the hipaa regulations went into force, thousands of complaints alleging violations have resulted in two criminal prosecutions, no civil nes, and many agreements to x problems that may have occurred without any penalty.8 these complaints have included allegations that personal medical details were wrongly revealed, information was poorly protected, more details were disclosed than necessary, proper authorization was not obtained, and that patients were frustrated in obtaining their own records. one administration ofcial was quoted as saying that ﬁour rst approach to dealing with any complaint is to work for voluntary compliance.ﬂ critics have asserted, however, that a lack of aggressive enforcement has made providers and insurers complacent about complying.in the long run, an enforcement regime of some sort is likely to be needed to ensure substantial compliance with the regulations. but as with the confusion about the circumstances under which what personal health information may be provided to which parties, the longterm results of the current approach to compliance remain to be seen.7.3.3 patient perspectives on privacy7.3.3.1 notications of privacy policyas noted above, hipaa mandates a number of privacy protections for personal health information. the concept of informed consent is important to these protections, and thus health care providers are required to 7 rob stein, ﬁpatient privacy rules bring wide confusion: new directives often misunderstood,ﬂ washington post, august 18, 2003, available at http://www.washingtonpost.com/ac2/wpdyn/a71242003aug17.8 rob stein, ﬁmedical privacy law nets no fines: lax enforcement puts patients™ files at risk, critics say,ﬂ washington post, june 5, 2006, available at http://www.washingtonpost.com/wpdyn/content/article/2006/06/04/ar2006060400672pf.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.224 engaging privacy and information technology in a digital ageprovide privacyrelevant information to patients about how their personal health information will be used.however, patients have been notied of privacy and informationhandling policies in forms that are largely incomprehensible to the average patient. for example, a readability analysis of hipaa privacy notices indicated that they were written at a level that requires collegelevel reading skills. the analysis concluded that the writing styles use too many words per sentence, too many complicated sentences, and too many complicated and uncommon words.9 going beyond this analysis, the concepts (or implications) of nonperishable data, quasiunidentiable data, semipermeable security systems, and informationsharing principles that allow abrogation of privacy for business (insurance reimbursement) or research reasons, are likely to be beyond the experience or expertise of most people who will have to make decisions based on these concepts. under such circumstances, it is not unreasonable to expect that many people will ignore such notices rather than seek assistance in understanding them.7.3.3.2 privacy implications of greater patient involvement in  health careinformation technology is now beginning to be used as a market differentiator in health care by hmos and private health care partnerships to allow patients to view some or all of their medical information over the internet, email their caregivers with questions, or send in their blood glucose readings by email or fax so that the caregivers can evaluate the quality of the patient™s disease management. this trend benets patients by helping them to better understand their state of health, and by reinforcing their role as an active member of the health care team, which has been shown to correlate with better patient selfcare.one consequence of this active partnership with the patient is that personal health information will increasingly be made available to the patient outside the connes of the health care setting per se (e.g., at home). to the extent that this information is made available online, many concerns about the end user™s ability to manage security on his or her own come to the fore. considering the high vulnerability of many end users to nigerian scam letters and ﬁphishingﬂ attacks, a substantial amount of health information could be compromised directly from end users.a related point is that search engines are capable of storing individual search histories (identied by the ip address originating the search). 9 mark hochhauser, ﬁwhy patients won™t understand their hipaa privacy notices,ﬂ privacy rights clearinghouse, april 10, 2003, available at http://www.privacyrights.org/ar/hipaareadability.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 225given that the internet gives individuals the ability to search the web for information about specic medical conditions and treatments, an extensive search history can be quite revealing about the health conditions of the individual searching for those terms. note that such information would not, in general, be protected by any health care privacy legislation, although it might enjoy some protection under more general statutes.7.3.3.3 improper interpretation and unintended consequences of hipaa privacy regulationsin the early days of hipaa implementation, confusion was common over what was and was not allowed under hipaa. hipaa privacy regulations were designed to prevent the inappropriate transfer of personal health information. however, as health care establishments sought to implement these regulations, they often went overboard and withheld information even when they would have been authorized to provide it. for example, in one instance, and citing hipaa regulations, a hospital refused to release the medical records of a heart donor on privacy grounds to the physicians treating the heart recipient.10 in other instances, patients and their family members have been unable to access their own personal health information because health care providers were erring on the side of caution in providing such information. in some such instances, patients have been exposed to unnecessary medical risk.as health care providers have developed more experience with hipaa regulations, such incidents have become fewer in number. but they still do occur from time to time, and the early days of hipaa implementation provide a cautionary tale of some of the things that can go wrong when privacy legislation or regulation is rst implemented.more recently, hipaa privacy regulations have impeded the efforts of patients to untangle problems associated with their medical records or payments for medical services received.11 in particular, some patients have been the victim of medical identity theft, in which another person assumes a patient™s identity for the purpose of receiving medical services. medical identity theft has both a medical and a nancial impact on the victim, whose health care records come to contain health information that is not associated with the victim and whose nances are compromised by liability for medical services never received. however, victims of medical identity theft report many difculties in obtaining their 10 rob stein, ﬁpatient privacy rules bring wide confusion: new directives often misunderstood,ﬂ washington post, august 18, 2003, p. a01.11 joseph menn, ﬁid theft infects medical records,ﬂ los angeles times, september 25, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.226 engaging privacy and information technology in a digital agerecords so that they can investigate what might have happened. in some cases, the victim™s investigations are stymied because a victim™s medical record now has personal health information on another person (the thief), and some hospitals argue that hipaa prevents them from turning over documents that contain information on other people even under these circumstances.7.3.3.4 spillover privacy implications of receiving health care servicesin april 2005, the target corporation (operators of a large chain of department stores that often include pharmacies) began to require photo identication for the purchase of certain overthecounter cold medicines. identity information is recorded in a database along with the purchase so that target can limit customers to two packages every 2 weeks and can see if they have purchased other cold medicine from target. the stated reason for the policy is that these medicines contain pseudoephedrine, which can be converted to methamphetamine (also known as crystal meth)šan addictive and illegal drug.12 although target states that it obeys all federal and state laws regarding the privacy of such information, this policy was promulgated by target on its own initiative and not at the behest of any state or federal law.for many years, medication has been provided by prescription or over the counter, and the privacy implications of such medications were clear. prescription drugs required the presentation of identication under the rationale that such medications were specically prescribed for the individual in question by a physician who had examined him or her and made a determination about the appropriateness and safety of the drug. overthecounter medications could be purchased by essentially anyone, without presenting identication.whether or not target™s purpose in adopting this policy is appropriate or socially benecial, the policy changes this traditional paradigm by requiring presentation of identication and storage of such information for overthecounter drugs in pursuit of nonmedical goals. as a rule, consumers have many choices about where to purchase overthecounter medications, but target™s policy regarding cold medicines does illustrate how privacy can be eroded in a service as vital as health care.12 c. benjamin ford, ﬁtarget wants photo id for cold medicine,ﬂ the gazette, february 15, 2006, available at http://www.gazette.net/stories/022406/polia%20s19514431962.shtml.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 2277.3.4 institutional advocacythe notion of institutional advocacy most commonly arises when there is no natural constituency for a certain perspective. for example, there are many shortterm incentives for exploiting the environment for economic reasons, but few similar incentives to refrain from exploiting the environment. thus, the environmental protection agency was established in large part to reduce this imbalance.in the domain of health care, there are similarly many incentives to use patient information, and very few to refrain from using it. the issues involved with health care privacy are also complex and highly conditional and situational. under these circumstances, some privacy analysts suggest that an institutional advocate is needed to help balance the scales. indeed, there are today chief privacy ofcers in many corporations that deal with personal information on a large scale. the role of such ofcers is to ensure that adequate attention to privacy is paid in decision making that might have an effect on privacy, and hipaa itself stipulates that organizations covered by the act must designate a ﬁprivacy ofcialﬂ responsible for the ﬁdevelopment and implementationﬂ of the policies and procedures necessary for compliance with the hipaa privacy requirements.similar arguments could be made on a larger scale as well. on this view, issues related to medical privacy are too complex for the average consumer to understand, let alone take informed action about. thus, an institutional advocate for medical privacy in the u.s. government, or in state governments, would help to ensure that adequate attention to privacy is paid in policy making that might have an effect on privacy.7.4 open issuesalthough the questions surrounding privacy have been discussed for years in the context of individual health information, it is not clear that any of the issues in this area are either less controversial or less murky as a result. the traditional approach, in which the privacy of the patient could be controlled by that patient™s doctor and in which the information about that patient was kept in les owned and controlled by the doctor and not easily shared physically, is no longer a viable model. this model has been made impractical by changes in how the information itself is stored and how medical treatment is paid for and delivered. adding in the growing realization that medical information traditionally regarded as private holds promise for changing the way the science of medicine can be conducted, it is clear that there are additional pressures on the traditional notions of medical privacy and that the rules of practice relevant to medical information will continue to evolve.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.228 engaging privacy and information technology in a digital agebecause of the way medicine has evolved, it is helpful though sometimes difcult, to distinguish clearly the following aspects:ł the practice of medicine, which is concerned with the medical care of individuals and communities, both to maximize current and future health and to track and monitor current disease;ł the science of medicine, which is concerned with the advancement of medical knowledge and technique;ł the business of medicine, which determines how and where medical care is provided and how best to ensure that the costs of medical care are held to a reasonable level, as well as what is reasonable in highly competitive protdriven sectors of the business; andł the regulation of medicine, which is society™s way of ensuring that medicine is practiced competently and in safe settings.even within this very particular domain, there are multiple contextsšbusiness, practice, science, and law and regulationšin which privacy considerations as well as other concerns have to be evaluated, and each entails different tradeoffs. for example, it is easy to imagine a patient who is perfectly willing to share very sensitive information for the purpose of improving her medical care but is far less comfortable with providing that information for inclusion in a longitudinal research study. she might also be made uneasy by realizing that the same information might be entered into records that will make their way to an insurance company that will than make decisions about the extent and nature of her coverage (or that of her relatives), or might be made available to a public health laboratory for epidemiological purposes.there are even subcontexts that are relevant. in the general context of medicine as business, one might identify the business of medicine per se and the business of the elds that surround medicine. the pharmaceutical industry is commonly seen as an adjunct to the health care industry, but pharmaceutical companies are often held to business and ethical standards very different from those that apply to such clearly healthrelated businesses as hospitals or medical clinics. insurance companies, which are more and more the payer of the costs of medical treatment, provide yet another subcontext, given that it is the rare person in the united states who is able to obtain consistent medical care without the use of these insurance companies and abiding by their sometimesonerous information requirements.to illustrate, consider the issue of privacy as it relates to the availability of health insurance. using the anchoring vignette approach, a possible survey question might be, how much privacy [do you/does ﬁnameﬂ] have from [your/his/her] health insurance provider? here are a number of possible vignettes:engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.health and medical privacy 2291. [jordan] wants to sign up for health insurance. the application requests basic information such as his name, address, age, and prior medical insurance providers.2. [suzanne] wants to sign up for health insurance. the application asks her for basic personal information as well as an immunization record.3. [mandy] wants to sign up for health insurance. the application asks her for basic personal information, as well as a detailed description of all prior illnesses.4. [andrew] wants to sign up for health insurance. the application requires him to list all doctors who have treated him, to answer specic questions about his behaviors, and to give permission for a nancial background check.5. [david] wants to sign up for health insurance. the application consists of a copy of his full les from prior insurance providers and doctors, a detailed medical history, and an interview as well as a physical examination that includes blood and urine tests.6. [joanna] wants to sign up for health insurance. the application consists of a copy of her full les from prior insurance providers and doctors, a detailed medical history, and an interview as well as a physical examination that includes blood and urine tests. in addition, the health insurance company purchases customer information from local grocery store membership programs so that it can consider her dietary habits.given such a variegated landscape, the lines between proper and improper use of health information are unclear. the use of information for the treatment of an individual is generally accepted, but the scope of the set of people who might need to use the information for that purpose is becoming less and less clear. the right of a society to ensure the public health of all its members has long been seen as taking precedence over the privacy of the individual when it comes to the incidence of infectious disease, as illustrated by the tracing by public health authorities of an infected person™s sexual contacts in the case of sexually transmitted disease. some see the release of health information to insurance companies to allow payment for services to the individual as having direct benet to the patient and therefore not subject to the informed consent required for other kinds of release of that information, but do not see direct benet in the release of such information to pharmaceutical companies.determining the proper balance between access to information and protection of privacy in the business, practice, and science aspects of medicine under the new realities of medical treatment is not something that can or should be done casually or by some small group either inside or outside the industry. the decisions made in this area will have an impact on the lives of everyone, and will affect the cost, efcacy, and range engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.230 engaging privacy and information technology in a digital ageof treatments. greater clarity regarding what the tradeoffs are between individual privacy and the use of this information would allow more informed discussion of alternatives for decision making. there is a certain urgency for making these decisions, as every day the techniques of medical information gathering and sharing improve. although we now have some handle on the notion of what constitutes personal health information, a time will come when current notions surrounding those ideas will not be adequate.perhaps the largest policy driver in the near term is the push for substantially greater use of electronic medical records. the privacy issues associated with such records are well understood in a theoretical sense,13 although how these issues will play out in the ubiquitous national deployments of electronic medical records envisioned in current policy plans is quite uncertain. what can be said with condence is that they will play out, and policy makers cannot assume that the existing policy regime will necessarily be adequate in an era of widespread deployments.13 see, for example, national research council, for the record: protecting electronic health information, national academy press, washington, d.c., 1997.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.2318libraries and privacylibraries have played a central role in american life for over a century. and the issues raised today about privacy are very similar to those associated with library privacy: tensions between values and between reality and perception; the potential for use of technology to help ensure privacy as well as compromise it; issues that affect all age groups; and issues related to national security, law enforcement, and commercial use.libraries have been at the forefront of discussions about the uses of technology to expand access to and use of information. libraries of all types (e.g., local public libraries, metropolitan libraries, university research libraries, corporate libraries) see their core mission as storing and organizing information so that it can be accessed by their patrons. what may be surprising to some is that for more than 50 years libraries and librarians have been at the forefront of discussions concerning privacy. in fact, the american library association™s code of ethics for members (box 8.1) explicitly recognizes a responsibility to protect the rights of library users to privacy and condentiality regarding information that they have sought or received and resources that they have consulted, borrowed, acquired, or transmitted.unlike some who see privacy as a right or a good in and of itself, the library community sees privacy as a necessary condition for the accomplishment of its primary goal, which is to provide the atmosphere and the resources for patrons to educate themselves in whatever way they desire. for libraries, privacy is seen primarily as an instrumental good, but one that has been discussed and thought about to such an extent that engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.232 engaging privacy and information technology in a digital agebox 8.1 the american library association™s code of ethics the american library association™s (ala™s) code of ethics for members was adopted by the ala council on june 28, 1995. as members of the american library association, we recognize the importance of codifying and making known to the profession and to the general public the ethical principles that guide the work of librarians, other professionals providing information services, library trustees and library staffs. ethical dilemmas occur when values are in con˚ict. the american library association code of ethics states the values to which we are committed, and embodies the ethical responsibilities of the profession in this changing information environment. we signicantly in˚uence or control the selection, organization, preservation, and dissemination of information. in a political system grounded in an informed citizenry, we are members of a profession explicitly committed to intellectual freedom and the freedom of access to information. we have a special obligation to ensure the free ˚ow of information and ideas to present and future generations. the principles of this code are expressed in broad statements to guide ethical decision making. these statements provide a framework; they cannot and do not dictate conduct to cover particular situations. i.  we provide the highest level of service to all library users through appropriate and usefully organized resources; equitable service policies; equitable access; and accurate, unbiased, and courteous responses to all requests. ii.  we uphold the principles of intellectual freedom and resist all efforts to censor library resources. iii.  we protect each library user™s right to privacy and condentiality with respect to information sought or received and resources consulted, borrowed, acquired or transmitted. iv.  we recognize and respect intellectual property rights. v.  we treat coworkers and other colleagues with respect, fairness and good faith, and advocate conditions of employment that safeguard the rights and welfare of all employees of our institutions. vi.  we do not advance private interests at the expense of library users, colleagues, or our employing institutions. vii.  we distinguish between our personal convictions and professional duties and do not allow our personal beliefs to interfere with fair representation of the aims of our institutions or the provision of access to their information resources. viii.  we strive for excellence in the profession by maintaining and enhancing our own knowledge and skills, by encouraging the professional development of coworkers, and by fostering the aspirations of potential members of the profession.source: see the american library association web site at http://www.ala.org/alaorg/oif/ethics.html.the members of the american library association have become erce advocates for the privacy of their patrons.libraries come in almost as many different varieties as the people they serve. indeed, the american library association estimates that there are ﬁ117,418 libraries of all kinds in the united states today,ﬂ1 a number that includes public libraries (large and small), school libraries, university libraries, research libraries, law libraries, institutional (or special) libraries, and medical libraries.this chapter presents the library community as a case study in the pursuit and protection of privacy. first, it examines what the library community sees as its primary goal, tracing the evolution of that goal from 1 see american library association, ﬁnumber of libraries: ala fact sheet 1,ﬂ september 2005, available at http://tinyurl.com/if19.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 233box 8.1 the american library association™s code of ethics the american library association™s (ala™s) code of ethics for members was adopted by the ala council on june 28, 1995. as members of the american library association, we recognize the importance of codifying and making known to the profession and to the general public the ethical principles that guide the work of librarians, other professionals providing information services, library trustees and library staffs. ethical dilemmas occur when values are in con˚ict. the american library association code of ethics states the values to which we are committed, and embodies the ethical responsibilities of the profession in this changing information environment. we signicantly in˚uence or control the selection, organization, preservation, and dissemination of information. in a political system grounded in an informed citizenry, we are members of a profession explicitly committed to intellectual freedom and the freedom of access to information. we have a special obligation to ensure the free ˚ow of information and ideas to present and future generations. the principles of this code are expressed in broad statements to guide ethical decision making. these statements provide a framework; they cannot and do not dictate conduct to cover particular situations. i.  we provide the highest level of service to all library users through appropriate and usefully organized resources; equitable service policies; equitable access; and accurate, unbiased, and courteous responses to all requests. ii.  we uphold the principles of intellectual freedom and resist all efforts to censor library resources. iii.  we protect each library user™s right to privacy and condentiality with respect to information sought or received and resources consulted, borrowed, acquired or transmitted. iv.  we recognize and respect intellectual property rights. v.  we treat coworkers and other colleagues with respect, fairness and good faith, and advocate conditions of employment that safeguard the rights and welfare of all employees of our institutions. vi.  we do not advance private interests at the expense of library users, colleagues, or our employing institutions. vii.  we distinguish between our personal convictions and professional duties and do not allow our personal beliefs to interfere with fair representation of the aims of our institutions or the provision of access to their information resources. viii.  we strive for excellence in the profession by maintaining and enhancing our own knowledge and skills, by encouraging the professional development of coworkers, and by fostering the aspirations of potential members of the profession.source: see the american library association web site at http://www.ala.org/alaorg/oif/ethics.html.the rst establishment of public libraries in the united states to the ways in which those libraries fulll that goal today. it then explores why this community has decided throughout its history that the preservation of privacy is required for it to accomplish that goal. next, it looks at the ways in which libraries have responded to technological change, with respect to both their primary goal and efforts to secure the privacy of their patrons. finally, it outlines some of the new technological developments that will affect the practices of librarians and describes actions that the library community is already taking to ensure that it will be able to guarantee the privacy of library patrons in the face of these developments.8.1 the mission of librariespublic libraries were established in the united states at a time when the average level of education was not much beyond elementary school, engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.234 engaging privacy and information technology in a digital ageand at a time when large numbers of immigrants were coming to the country. the public library movement was based on the conviction that democracy in the united states could only be furthered if members of the public were able to educate themselves, and to have access to information that would allow them to make informed decisions. the public library was seen as a way of allowing individuals to nd information that would enable them to form opinions on current issues and in general become more informed citizens.this ideal, combining practical access to information with the notion that, given the chance, people would educate themselves, drove the development of public libraries and shaped the role of the librarian. rather than seeing themselves as caretakers of information, librarians saw themselves as educators and enablers whose stock in trade was helping others to access information. rather than hoarding information and protecting it from those outside the library, the librarian™s job was to spread the information contained in the library to the community in which the library was located. the information to be distributed was not to be determined by the tastes of the librarian, but rather by the interests and desires of library patrons. it was the job of the librarian to help when needed, but it was up to the patron to decide what he or she wanted to read, study, or learn.this historical background can still be seen in the mission statements of public libraries. for example, the louisville, kentucky, public library™s mission statement begins, ﬁthe louisville public library is committed to providing its citizens: the benet and pleasure of learning and discovery through its collections, services, and staffﬂ;2 the greene county, ohio, public library™s mission statement begins, ﬁthe greene county public library system is the community connection to reading, lifelong learning, and personal and professional enrichment for people of all ages.ﬂ3while the mission of public education was rst articulated as part of the movement to establish public libraries, this mission now has been adopted by all kinds of libraries. for example, research libraries that are part of universities might be seen as having a mission more narrowly directed toward the needs of the university community, but the mission statements of such institutions look remarkably like those of the public libraries. in all of these cases, a primary mission of the library is to enable its users to gain access to materials that will allow them to learn.2 city of louisville public library, ﬁmission statement of the louisville public library,ﬂ november 17, 2004, available at http://www.ci.louisville.co.us/library/mission.asp.3 greene county public library, ﬁmission,ﬂ available at http://www.gcpl.lib.oh.us/mission.asp, accessed june 12, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 2358.2 libraries and privacyto meet their primary mission, libraries have had to ensure that the atmosphere they provided did not discourage patrons from investigating any subject that they found of interest. in a statement that is strikingly relevant today, the american library association stated in 1953 that:. . . reading is among our greatest freedoms. the freedom to read and write is almost the only means for making generally available ideas or manners of expression that can initially command only a small audience. the written word is the natural medium for the new idea and the untried voice from which come the original contributions to social growth. it is essential to the extended discussion that serious thought requires, and to the accumulation of knowledge and ideas into organized collections. . . .4in order to provide this right, librarians have afrmed as a part of their contract with their patrons that they will ﬁprotect each individual™s privacy and condentiality in the use of library resources and services.ﬂ5the connection between privacy and the goal of enabling individual learning re˚ected several different considerations. many patrons of the early public libraries were members of the waves of immigrants that came to the united states during the late 19th and early 20th centuries. the public libraries were seen as a way of helping those immigrants assimilate into a new country and culture. many of the newcomers came from countries whose governments took great care to monitor the interests of their citizens, often to the citizens™ detriment. the library community felt that it was necessary to protect the privacy of these patrons so that they would feel free to use the libraries, and so that their selfeducation would not be, or appear to be, subject to government scrutiny. this consideration is still a major concern for librarians in areas with large immigrant populations.6for librarians, similar considerations applied even when library 4 american library association, ﬁthe freedom to read statement,ﬂ adopted june 25, 1953, by the ala council and the aap freedom to read committee, available at http://www.ala.org/ala/oif/statementspols/ftrstatement/freedomreadstatement.htm.5 american library association, ﬁlibraries: an american value,ﬂ adopted february 3, 1999, available at http://www.ala.org/ala/oif/statementspols/americanvalue/librariesamerican.htm.6 for example, the committee took testimony in april 2003 from the director of the queensborough public library in new york city, which serves a population that is predominantly immigrant. he indicated that as the result of such concerns, the library took several steps to protect the privacy of patron information, including the separation of the library™s information retention policies into ﬁpaperﬂ and ﬁelectronic,ﬂ the delinking of electronic book/patron information when the book is returned, and the daily destruction of internet usage signup sheets.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.236 engaging privacy and information technology in a digital agepatrons were native to the united states. the goal of selfeducation was meant to allow patrons to explore controversial and unpopular ideas and ideologies. to engage in this sort of exploration, patrons of the library needed to feel that their choice of reading material would not be subject to the scrutiny of neighbors, friends, or employers, even though concerns about government scrutiny were perhaps less common among the nonimmigrant u.s. population. for citizen and noncitizen alike, the interest in privacy extended even to scrutiny by the librarians themselves; it dictated that librarians should not try to guide their patrons™ selfeducation activities, but instead should merely enable whatever study a patron wished to undertake.this connection between selfeducation and privacy is made explicit in the ofcial interpretation of the american library association™s library bill of rights (box 8.2).7 this interpretation conceptualizes privacy as follows: ﬁin a library (physical or virtual), the right to privacy is the right to open inquiry without having the subject of one™s interest examined or scrutinized by others.ﬂthis conception of a privacy interest in one™s intellectual pursuits is arguably different from an interest in maintaining the condentiality of one™s medical records or in resisting broad law enforcement surveillance tactics for privacy reasons. while one might worry about embarrassment resulting from the disclosure of medical information, or about interference by government or law enforcement in the study of politically or socially unacceptable ideas, the concern for intellectual privacy also rests on a more general fear of the ostracism, ridicule, or loss of social status that could result if the subject matter of inquiry were generally known. the kind of privacy that libraries seek to guarantee also is different from the kind of privacy that might be needed by the patron of an abortion clinic, pawnshop, or drug rehabilitation center. in those other cases, the privacy interest extends to the actual use of the service being provided. in the case of the library, worries about privacy do not center on the fact that a person is a patron of a library, but rather about the content of that patron™s use. indeed, the interpretation states that ﬁwhen users recognize or fear that their privacy or condentiality is compromised, true freedom of inquiry no longer exists.ﬂwell before the advent of modern information technology, the desire to ensure patron privacy led librarians to develop techniques for tracking books checked out of the library that minimized leakage of information 7 american library association, ﬁprivacy: an interpretation of the library bill of rights,ﬂ adopted june 19, 2002, by the ala council, available at http://www.ala.org/template.cfm?section=interpretations&template=/contentmanagement/contentdisplay.cfm&contentid=76546.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 237box 8.2 the american library association™s library users™ bill of rights the american library association™s (ala™s) library users™ bill of rights was adopted by the ala council on june 18, 1948. it was amended on february 2, 1961, and january 23, 1980, and inclusion of ﬁageﬂ was reafrmed on january 23, 1996. the american library association afrms that all libraries are forums for information and ideas, and that the following basic policies should guide their services. i.  books and other library resources should be provided for the interest, information, and enlightenment of all people of the community the library serves. materials should not be excluded because of the origin, background, or views of those contributing to their creation. ii.  libraries should provide materials and information presenting all points of view on current and historical issues. materials should not be proscribed or removed because of partisan or doctrinal disapproval. iii.  libraries should challenge censorship in the fulllment of their responsibility to provide information and enlightenment. iv.  libraries should cooperate with all persons and groups concerned with resisting abridgment of free expression and free access to ideas. v.  a person™s right to use a library should not be denied or abridged because of origin, age, background, or views. vi.  libraries which make exhibit spaces and meeting rooms available to the public they serve should make such facilities available on an equitable basis, regardless of the beliefs or afliations of individuals or groups requesting their use.source: see the american library association web site at http://www.ala.org/work/freedom/lbr.html.about who was reading which books. many libraries were early adopters of systems in which patrons were identied by the numbers on their library cards. only the library could make the correlation between the numbers and the people to whom they were assigned. the records of who had checked out the books (often available on paper cards placed in the books when those books were on the shelves) contained only the numbers. further, more complete records linking numbers to names were destroyed soon after the book had been returned.although there are no federal laws protecting the privacy of library patrons, 48 states and the district of columbia have passed laws and the other two states have prevailing opinions from their attorneys general. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.238 engaging privacy and information technology in a digital agethe language of these laws varies from state to state. the american library association recommends that librarians understand state condentiality laws and that libraries have in place procedures for cooperating expeditiously with law enforcement ofcers when a subpoena or other legal order for records is made within the framework of state law.88.3 libraries and technologymodern information technology has become central to all parts of a modern library. libraries were early adopters of computerized systems and have used these systems to organize their holdings, to keep track of which patrons have checked out which items, and to expand the range of materials that they are able to offer to patrons. in all of these applications, the privacy of patrons has been a major concern. the library community also has taken a proactive approach to evaluating the potential and the privacy implications of new technologies, and has recognized that raising questions about privacy is much more difcult after a technology has been adopted.one of the rst uses of information technology in libraries was for tracking the books checked out by patrons. many systems adopted by libraries needed to be altered so that records associating patrons with the books they had checked out would be purged from the system as soon as possible. even though that information might be useful for tracking the popularity of some titles or the interests of the library™s patrons, enabling secondary use of circulation information was considered improper because this capability might enable use of the information for other purposes in ways that could compromise patron privacy. rather than risk compromising privacy, the library community generally has required that information systems purchased for library use be tailored to capture only the minimum amount of data necessary to track who has checked out a book, and to ensure that the information is purged as soon as possible after the book has been returned. in this way, the computerbased systems adopted by librarians would provide the same privacy guarantees as the noncomputerized systems previously in use.indeed, librarians are constantly looking for ways to use technology to enhance the privacy protections they offer to their patrons. michael gorman has talked about an example of a technology that might help preserve patron privacy and intellectual freedom in libraries. he describes how selfservice book checkout systems might make a ﬁsignal contribu8 american library association, ﬁstate privacy laws regarding library records,ﬂ available at http://www.ala.org/alaorg/oif/stateprivacylaws.html, accessed june 12, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 239tion to the library right to privacy.ﬂ9 patrons might be more willing to borrow sensitive or controversial material if they know that the transactions will be handled entirely by the checkout machine.for similar reasons, libraries have developed computerized catalog systems that do not require identication of the patron using the catalog. this ensures that patrons™ searches of the catalog will remain private. libraries have made this decision even though records of past searches might be used to help patrons nd other holdings of interest. there is also some interest in recommender systems that can suggest to a given user that he or she might be interested in certain references, based on the preferences and access behavior of other members of the user community, though these systems do not make reference to specic user identities.perhaps the most visible and dramatic change that information technology has brought about in libraries relates to the holdings of those libraries. modern libraries are far more than book repositories. over the years, libraries have expanded their holdings to include music, movies, and most recently access to the internet (especially that part of the internet known as the world wide web). all these developments further the goal of providing educational materials to the public. but as libraries have expanded their holdings beyond books to other forms of media and other methods of information access, the pressures on their commitment to protecting the privacy of their patrons have intensied. the provision of access to music and lm can be seen as a simple extension of the traditional role of the library as a place to access books, but the provision of internet access seems different.public access to the internet is now nearly universal in modern libraries, both through computers connected to the internet that are owned by the library and through access to networks owned and maintained by the library to which individuals can connect their own computers. indeed, many libraries now offer unrestricted wireless network access, allowing patrons to connect to the internet not only inside the library itself but also from an area around the library. in many ways, the internet seems to be the ultimate mechanism for fullling the goal of public libraries, as it opens up to all library patrons a vast world of information that they can explore at their leisure. the internet multiplies the holdings of any library by allowing access to information stored anywhere in the world, without expanding the physical space needed for the library.but there are also aspects of the internet that make it different from 9 michael gorman, ﬁprivacy in the digital environmentšissues for libraries,ﬂ 67th ifla council and general conference, august 1625, 2001, available at http://www.i˚a.org/iv/i˚a67/papers/145083e.pdf. this paper is adapted from a chapter in the author™s our enduring values, american library association, chicago, 2000.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.240 engaging privacy and information technology in a digital agethe other means of information access that have traditionally been offered by libraries. the most obvious of these is that unlike the physical holdings of a library, which are chosen by the library staff after being vetted by publishers, the offerings on the internet are not required to be selected by either a librarian or a publisher. anyone can publish on the world wide web with little or no expense. this means that while there are great amounts of information on the web, there is also a great amount of misinformation on the web. along with expanded access to information of great educational value, the web offers access to sites that contain racist, sexist, and homophobic diatribes, as well as sexually explicit material.access to the internet is also different from the traditional access to information offered by libraries, because the internet is a twoway mechanism for communication. this means that not only can patrons of a library use the internet to access information, but they also can use that access to send communications of their own. in providing patrons with internet access, libraries are also providing patrons with a communication mechanism that is generally difcult to trace.the american library association has developed a toolkit to help individual libraries develop policies designed to address both of these aspects of internet use.10 this toolkit acknowledges that there is content on the internet that is both inappropriate and, in some cases, illegal, but also emphasizes the importance of ensuring patron privacy, allowing patrons free use of the tools that enable access to information, and ensuring that the dignity and autonomy of individual patrons is not compromised.in general, the library community rejects the notion that librarians should act as guardians or gatekeepers of their patrons™ access to the internet. in the case of patrons who are children, the american library association™s policy toolkit makes explicit that the primary responsibility for enforcing restrictions on internet access for children rests with the parents of those children, not with the librarians.11the children™s internet protection act of 2002 (p.l. 1060554) sought to change this approach by conditioning eligibility for certain federal funding on a library™s willingness to block all patrons™ access to sexually explicit material deemed harmful to minors. the american library association (ala) challenged this law, and in 2002 a threejudge panel in the federal court for the eastern district of pennsylvania overturned the law, ruling that it violated the first amendment rights of library patrons. however, the federal government appealed this decision, and in 2003 the 10 see http://www.ala.org/ala/oif/iftoolkits/litoolkit/librariesinternet.htm.11 american library association, ﬁlibraries and the internet toolkit: key messages,ﬂ updated december 1, 2003, available at http://www.ala.org/template.cfm?section=litoolkit&template=/contentmanagement/contentdisplay.cfm&contentid=50645.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 241supreme court ruled that the law was valid.12 the ala now suggests that if libraries install ltering software, such software be placed ﬁat the least restrictive level.ﬂ13 better yet, the ala advises that libraries comply with the law by educating their patrons on the appropriate use of the internet rather than restricting such use.the use of the internet and networked information services (such as some specialized databases) also brings thirdparty suppliers into the relationship between the library and its patrons. many of the databases that libraries wish their patrons to be able to access require that users log on or otherwise identify themselves. while this can be done through the library™s computer system, and the library can ensure that it does not keep information about which patron uses what database, the library has little or no control over whether the database provider gathers information on the subjects of interest to the library patrons.although libraries are the primary customers for computer systems used to track the circulation of library materials, they are simply patrons of the database service (and often patrons requesting discounted fees). as such, they often cannot dictate the privacy policies that will be enforced by the database service. in such cases, librarians are put in the delicate position of having to choose between being able to offer the service and being able to ensure adherence to the standards of privacy to which they have become accustomed. some libraries, with better bargaining power, have addressed this issue through detailed policies and agreements with vendors. columbia university, for instance, requires that ﬁ[s]ervices licensed by columbia that gather user or marketing data . . . notify users in each session how and why this data is being collected and . . . provide users the option of not having such data collected about them.ﬂ14patrons™ use of the internet as a communication medium raises other issues that are more complex. in some cases,15 threatening email has been sent from an internet connection provided by a library, and the library subsequently has made the computer from which the threat was sent available to law enforcement ofcers seeking to identify the person who sent the threat. these libraries did not, however, keep records that enabled law enforcement personnel to discover this information, nor did 12 united states v. american library assn., inc. (02361) 539 u.s. 194 (2003), 201 f. supp. 2d 401, reversed.13 american library association, ﬁlibraries and the internet toolkit: libraries, the internet and filtering,ﬂ updated december 1, 2003, available at http://www.ala.org/template.cfm?section=litoolkit&template=/contentmanagement/contentdisplay.cfm&contentid=50667.14 see columbia university™s ﬁinformation sheet for database vendors,ﬂ updated december 6, 2005, available at https://www1.columbia.edu/sec/cu/libraries/staffweb/digital/ner/vendordata.html.15 carla stof˚e, university of arizona, testimony to the committee, january 30, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.242 engaging privacy and information technology in a digital agethe librarians believe that such record keeping would comport with the library™s commitment to ensure privacy.16there are other emerging technologies suggested for use within libraries that have caused additional privacy concerns. the two most commonly cited are radiofrequency identication (rfid) tags and digital rights management systems, discussed further in section 8.5.8.4 libraries and privacy since 9/11in the wake of the terrorist attacks of 2001 and the subsequent increased focus on national and homeland security, libraries have seen their commitment to privacy questioned in the name of the need for safety. as repositories of information, libraries have been seen by some as fertile grounds for the education of terrorists. with their policy of open access to the internet, libraries also have been seen as venues from which terrorists can safely communicate with each other. certainly a factor in the increasing scrutiny of libraries was the revelation that some of the september 11 terrorists, including mohammed atta himself, had used publicly available library computers to access email17 and possibly conduct terrorist business.the traditional privacy policies of libraries have come into con˚ict with some of the provisions of laws passed in response to the 9/11 attacks and the continued worries about terrorism. legislation passed in the post9/11 period, including the usa patriot act, has expanded the authority of law enforcement to conduct surveillance and gather data on individu16 under the provisions of 18 u.s.c. 2709, an ﬁelectronic communication service providerﬂ must comply with ﬁa request for electronic communication transactional records in its custody or possession made by the director of the federal bureau of investigation.ﬂ however, section 5 of the usa patriot act additional reauthorizing amendments act of 2006, p.l. 109178, exempts libraries from this requirement if they provide internet access but are not themselves ﬁprovidingﬂ the users with ﬁthe ability to send or receive wire or electronic communications.ﬂ according to the congressional research service, a reasonable interpretation of this denition suggests that to be considered an electronic communication service provider under this law, a library must independently operate the means by which transmission, routing, and connection of digital communication occur. in contrast, a local county library usually has a service contract with an internet service provider (isp) to furnish the library with the electronic communication service, as many businesses and individuals do; the fact that the library has set up a computer with internet access for the use of its patrons probably does not, by itself, turn the library into a communications service ﬁprovider.ﬂ under this characterization, the actual ﬁproviderﬂ of internet access is the isp, not the library. see brian yeh and charles doyle, ﬁusa patriot improvement and reauthorization act of 2005: a legal analysis,ﬂ rl order code 33332, congressional research service, washington, d.c., march 24, 2006.17 ﬁprivacy and security: a librarian™s dilemma,ﬂ the san francisco chronicle, february 2, 2003, p. d4.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 243als even when there is not probable cause to believe that the individuals targeted for surveillance are engaged in any criminal activity. although law enforcement ofcials have always had the ability to seek grand jury subpoenas (with no court order required) to compel the production of any information from any party, including libraries, that is (merely) relevant to a criminal investigation, section 215 of the usa patriot act expanded the authority of the fisa court to issue an order compelling the production of any tangible object from any source as part of an investigation to protect the united states from international terrorism or clandestine intelligence activities (box 8.3).the american library association has been very active in opposing some sections of the usa patriot act, passing a resolution on january 29, 2003, that states, in part, ﬁthe american library association (ala) opposes any use of governmental power to suppress the free and open exchange of knowledge and information or to intimidate individuals exercising free inquiry. . . . ala considers that sections of the usa patriot box 8.3 section 215 of the usa patriot act ﬁthe foreign intelligence surveillance act previously allowed senior ofcials of the federal bureau of investigation to apply for a court order, in connection with a foreign intelligence investigation, for access to the records of common carriers, public accommodation providers, physical storage facility operators, and vehicle rental agencies (50 u.s.c. 18611863 [2000 ed.]). ﬁsection 215 rewrites those provisions. assistant special agents in charge of the fbi eld ofces may now also apply. the court orders extend to any tangible object held by anyone. items sought need not relate to an identied foreign agent or foreign power as was once the case, but they may be sought only as part of an investigation to protect the united states from international terrorism or clandestine intelligence activities. nor may they be sought in conjunction with the investigation of an american or permanent resident alien predicated solely on the basis of activities protected by the first amendment. there is a good faith defense for anyone who produces items in response to a court order under the section, and production does not constitute a waiver of applicable privilege. under the usa patriot improvement and reauthorization act of 2005, section 215 will expire on december 31, 2009, unless it is explicitly made permanent by an additional act of congress.ﬂsource: charles doyle, ﬁterrorism: section by section analysis of the usa patriot act,ﬂ order code rl 31200, congressional research service, washington, d.c., 2001, available at http://fpc.state.gov/documents/organization/7952.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.244 engaging privacy and information technology in a digital ageact are a present danger to the constitutional rights and privacy rights of library users.ﬂ18an example of the library community™s view of the dangers appears in the writing of a washington state librarian who refused an fbi request for circulation records associated with a biography of osama bin laden and wrote about the usa patriot act™s implications for her profession (box 8.4). the ala also has urged librarians to review the records that they currently keep to ensure that they maintain only those that are absolutely needed, and that all other information about patrons is purged as soon as possible.it should be noted that the phenomenon of law enforcement personnel or agencies looking to libraries for information about particular people and their reading (or websurng) habits is certainly not new.19 indeed, during the 1980s, there was widespread concern within the library community regarding the fbi™s library awareness program (part of a foreign counterintelligence program that sought to discover what was interesting to people from eastern europe when they visited premier university research libraries). in the 1950s, the library community was sometimes approached in attempts to nd evidence of communist sympathy. at those times, as now, the library community held to its commitment to privacy in the face of pressures in the name of security.8.5 emerging technologies, privacy, and librariesas mentioned in the discussion of technology drivers (chapter 3), advances in technology have often led to new concerns about the impact of those advances on privacy. emerging technologies that affect library operations such as digital rights management technologies (drmts) and rfid tags are timely illustrations and are already topics of controversy.consider, for example, drmts, whose overall goal is to ensure that digital content is not copied and distributed without the knowledge and consent of the providers of that content. some proposals for such technologies envision enabling content providers to trace every use of every copy, including not only who the purchaser might be but also who is actually viewing the content. if such technologies become widely used in connection with the digital content held by libraries, the difculty of ensuring the privacy of patrons who view such content will increase. if every viewing is subject to the content provider™s being able to learn the 18 american library association, ﬁusa patriot act and intellectual freedom,ﬂ available at http://www.ala.org/ala/oif/issues/usapatriotact.htm, accessed june 14, 2006.19 much of this story is told, from the perspective of the library community, at http://www.ala.org/ala/oif/issues/fbiyourlibrary.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 245box 8.4 a librarian™s view of the usa patriot act on june 8, 2004, an fbi agent requested from the deming branch of the whatcom county library system in northwest washington state a list of people who had borrowed a biography of osama bin laden. the fbi said that a library patron had sent the fbi the book after discovering some words written in the margin: ﬁif the things i™m doing is considered a crime, then let history be a witness that i am a criminal. hostility toward america is a religious duty and we hope to be rewarded by god.ﬂ the library system attorney told the fbi that it would have to go through legal channels before the board of trustees would consider releasing the names of the borrowers, and also that a google search indicated that the words in the margin were almost identical to a statement by bin laden in a 1998 interview. the fbi served a subpoena on the library a week later demanding a list of everyone who had borrowed the book since november 2001. after deliberation, the board of trustees voted unanimously to go to court to quash the fbi subpoena. fifteen days later, the fbi withdrew its request. however, for the library, the circumstances had been fortuitous. the subpoena had not been issued pursuant to the usa patriot act of 2001, which would have allowed the fbi to demand library records. it also could have prevented the library from revealing that it had received an order to surrender patron information, and thus could have prevented appeal or independent review of the order. as the librarian writing about this situation noted, if the fbi had returned with an order from a secret court under section 215 of the usa patriot act, the fbi might now know which residents in that part of washington state had simply tried to learn more about bin laden. faced with a usa patriot act order, the library would have been forbidden to disclose even the fact that it had received the order, and the librarian would not have been able to write the oped article.source: adapted from joan airoldi, ﬁlibrarian™s brush with fbi shapes her view of the usa patriot act,ﬂ usa today, may 18, 2005, available at http://www.usatoday.com/news /opinion/editorials/20050517librarianeditx.htm.identity of the viewer, libraries will nd it difcult to assure patrons that these records have been kept condential, have been deleted as soon as possible, and have not been used for purposes other than that of ensuring that borrowed materials were returned.2020 the problems posed for privacy protection are not necessarily insurmountable. for example, it might be possible for a library to provide users with a smart card keyed to allow access to drmprotected content. there is no particular need for the smart card to be associated with a specic library patron, and indeed a library could present the patron with a bin of smart cards with different electronic identiers that he or she could pick at random and/or trade in at any time. the bin itself could be made available only on presentation of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.246 engaging privacy and information technology in a digital agebox 8.5 digital millennium copyright act and digital rights management the protection afforded to digital les by digital rights management technologies (drmts) is bolstered by federal law. the digital millennium copyright act (dmca), enacted in 1998, instituted a variety of penalties related to circumvention of technical protection measures applied to copyrighted works. in addition, other recent changes to the copyright laws are designed to assist copyright owners in their attempts to limit the ˚ow of unauthorized, unprotected copies. in particular, the online service provider liability limitation act, enacted in 1998 as title ii of the dmca and codied at section 512 of the copyright act, grants online service providers (osps) immunity from secondary copyright infringement liability in exchange for their cooperation in stemming the ˚ow of unprotected content on the internet. title i of the dmca, codied at sections 12011204 of the copyright act, establishes legal protection for drmts. this protection consists of two main prohibitions. first, the statute prohibits the circumvention of technologies that effectively control access to a copyrighted work. second, it proscribes the manufacture and distribution of technologies or devices that can be used to circumvent either accesscontrol technologies or technologies that protect a right of the copyright owner (e.g., copycontrol technologies and the like).1 both prohibitions are subject to a variety of narrow exceptions for a variety of activities ranging from reverse engineering to nonprot library acquisition decisions. section 512, meanwhile, establishes procedures for osps that provide web hosting or information location services to remove infringing material upon receipt of noticefrom the copyright owner. while osps are not required to comply with these provisions, those that do comply are granted immunity from contributory infringement liability. an osp is ineligible to claim the shelter of the noticeandtakedown provisions, however, if it receives a direct nancial benet from the infringing activity and has the right and opportunity to control the activity, or if it knows or has reason to know of the infringing activity and takes no action to stop it. section 512 also includes a provision authorizing a copyright owner to apply to the clerk of any federal district court for a subpoena requiring an osp to furnish personal identifying information about a subscriber who is an alleged infringer identied in a takedown notice. copyright owners also have attempted to use this provision to discover information about individuals alleged to be using internet access services to trade copies of copyrighted works via peertopeer networks. however, two federal courts of appeal have rejected the argument that the subpoena provision should be read to apply to any subscriber, including subscribers who simply use an internet connection supplied by the osp.2 copyright owners are now using a procedural device known as the ﬁjohn doeﬂ lawsuit to discover information about these subscribers via judicially authorized subpoenas.3 finally, at the behest of the motion picture industry, there is currently a movement underway at the state level to enact laws prohibiting the attachment of unauthorized devices to communications networks. although these laws are described as simply targeting unauthorized and unpaid access to telecommunications and cable services, their breadth leaves them open to much broader interpretation, potentially encompassing any device that can be attached to a personal computer connected to the internet. for this reason, they have been dubbed ﬁmini dmcas.ﬂ2 see riaa v. verizon internet services, inc., 351 f.3d 1229 (d.c. cir. 2003), cert. denied, 125 s. ct. 309 (2004); in re charter communications, inc., subpoena enforcement matter, 393 f.3d 771 (8th cir. 2005).3 see sony music entertainment, inc. v. does 140, 326 f. supp. 2d 556 (s.d.n.y. 2004).1 a device falls within this prohibition if (1) it is primarily designed or produced for circumvention, (2) it has only limited commercially signicant purpose or use other than to circumvent, or (3) it has been knowingly marketed for use in circumvention. see 17 u.s.c. 1201(a)(2), (b).the digital millennium copyright act (dmca) further complicates matters from a privacy perspective. as noted in box 8.5, title i of the dmca prohibits technological attempts to circumvent drmts deployed to protect digital content, and thus eliminates (or at least reduces signicantly) the availability of such circumvention technologies to the publicšand in particular to members of the public who are interested in protectan id (e.g., a library card), but the gap between the act of presenting the card and picking a smart card from the bin would ensure the patron™s privacy. nevertheless, the easiest, most straightforward, and least expensive way to enable access to drmprotected materials is indeed to use the library card infrastructure (presumably electronic) to provide such access, in which case the potential privacy problems described above become far more real.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 247box 8.5 digital millennium copyright act and digital rights management the protection afforded to digital les by digital rights management technologies (drmts) is bolstered by federal law. the digital millennium copyright act (dmca), enacted in 1998, instituted a variety of penalties related to circumvention of technical protection measures applied to copyrighted works. in addition, other recent changes to the copyright laws are designed to assist copyright owners in their attempts to limit the ˚ow of unauthorized, unprotected copies. in particular, the online service provider liability limitation act, enacted in 1998 as title ii of the dmca and codied at section 512 of the copyright act, grants online service providers (osps) immunity from secondary copyright infringement liability in exchange for their cooperation in stemming the ˚ow of unprotected content on the internet. title i of the dmca, codied at sections 12011204 of the copyright act, establishes legal protection for drmts. this protection consists of two main prohibitions. first, the statute prohibits the circumvention of technologies that effectively control access to a copyrighted work. second, it proscribes the manufacture and distribution of technologies or devices that can be used to circumvent either accesscontrol technologies or technologies that protect a right of the copyright owner (e.g., copycontrol technologies and the like).1 both prohibitions are subject to a variety of narrow exceptions for a variety of activities ranging from reverse engineering to nonprot library acquisition decisions. section 512, meanwhile, establishes procedures for osps that provide web hosting or information location services to remove infringing material upon receipt of noticefrom the copyright owner. while osps are not required to comply with these provisions, those that do comply are granted immunity from contributory infringement liability. an osp is ineligible to claim the shelter of the noticeandtakedown provisions, however, if it receives a direct nancial benet from the infringing activity and has the right and opportunity to control the activity, or if it knows or has reason to know of the infringing activity and takes no action to stop it. section 512 also includes a provision authorizing a copyright owner to apply to the clerk of any federal district court for a subpoena requiring an osp to furnish personal identifying information about a subscriber who is an alleged infringer identied in a takedown notice. copyright owners also have attempted to use this provision to discover information about individuals alleged to be using internet access services to trade copies of copyrighted works via peertopeer networks. however, two federal courts of appeal have rejected the argument that the subpoena provision should be read to apply to any subscriber, including subscribers who simply use an internet connection supplied by the osp.2 copyright owners are now using a procedural device known as the ﬁjohn doeﬂ lawsuit to discover information about these subscribers via judicially authorized subpoenas.3 finally, at the behest of the motion picture industry, there is currently a movement underway at the state level to enact laws prohibiting the attachment of unauthorized devices to communications networks. although these laws are described as simply targeting unauthorized and unpaid access to telecommunications and cable services, their breadth leaves them open to much broader interpretation, potentially encompassing any device that can be attached to a personal computer connected to the internet. for this reason, they have been dubbed ﬁmini dmcas.ﬂ2 see riaa v. verizon internet services, inc., 351 f.3d 1229 (d.c. cir. 2003), cert. denied, 125 s. ct. 309 (2004); in re charter communications, inc., subpoena enforcement matter, 393 f.3d 771 (8th cir. 2005).3 see sony music entertainment, inc. v. does 140, 326 f. supp. 2d 556 (s.d.n.y. 2004).ing their anonymous access to such content. it also eliminates or reduces the availability of these technologies to libraries that might otherwise be inclined to take afrmative steps in protecting patron privacy.drmts and the dmca thus pose a potential threat to libraries™ current practice of ensuring that the content viewed by patrons of the library is kept private. the potential privacy problems have much in common with the problems libraries have already encountered in connection with patron access to information in subscription digital databases, discussed brie˚y above. however, the database access privacy is a problem that can be dealt with contractually between the libraries and the database vendors. approaching the problem of privacy in the context of drmts may require that libraries negotiate with content providers regarding engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.248 engaging privacy and information technology in a digital ageterms that do not compromise the privacy of usersšan approach that might signicantly raise the cost of obtaining those terms. on the other hand, in much the same way that some online subscription databases simply require identication of the library as the entity responsible for access, content providers might be satised simply with measuring the number of accesses to protected content, the number of individual users per month, or the peak number of simultaneous users in a month.concerns have also been raised about the use of rfid tags in library books.21 some proposals envision placing rfid tags in all of the physical materials held by libraries. these tags could then be used to control loss and to speed checkoutšanother application of information and information technology to improve the efciency of libraries and perhaps even enhance patron privacy, as the library staff would not have to conduct the checkout procedures. the privacy concern is that anyone with an rfid reader could then surreptitiously discover what any patron of the library was checking out by simply getting close enough to the patron to read the rfid tags of the books in the patron™s possession when he or she left the library. this assumes, however, that the individual doing the surreptitious reading of the tag would also have access to the database that linked the tag identication to the book title or isbn.this worry is more evident in the community of privacy advocates than it is in the library community itself. indeed, the attitude of the library community seems best summed up by david dorman, who wrote,. . . forgive me for being skeptical of all the hullabaloo, but i just can™t get too worked up about a library book broadcasting its bar code for several feet to any and all who care to lug around portable rfid readers and eavesdrop on the reading habits of passersby carrying library books. however, if that thought bothers some folks, i recommend they campaign for encrypting the barcode number in the rfid tag rather than foment (or buy into) vague apprehensions about a very useful and rather benign library inventory control tool.228.6 conclusionleadership for privacy within libraries has come from within that sector itself. libraries have long been advocates of personal privacy, seeing privacy as a necessary condition for libraries™ fulllment of their primary 21 beth givens, ﬁrfid implementation in libraries: some recommendations for ‚best practices™,ﬂ privacy rights clearinghouse, posted january 10, 2004, available at http://www.privacyrights.org/ar/rfidala.htm.22 david dorman, ﬁrfid poses no problem for patron privacy,ﬂ american libraries online, december 2003, available at http://www.ala.org/ala/alonline/techspeaking/2003columns2/december2003.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.libraries and privacy 249function as facilitators of access to information. this function, in turn, serves libraries™ ultimate goal of enabling the ongoing education and cultural advancement of their patrons. such an orientation makes the library community fundamentally different from other communities, such as businesses (as discussed in chapter 6) or the medical establishment (discussed in chapter 7), that have been perceived as compromising privacy from within, and on which privacy requirements have been imposed by law. library professionals have championed laws protecting the privacy of library patrons as mechanisms to shore up their own guarantees of privacy to their patrons.libraries have always had to keep signicant amounts of personal information about their patrons. because of this, and because of the close connection between library use and patrons™ intellectual lives, libraries have long been aware of the privacy problems that are now besetting other industries. the library community has a long and rich tradition of debate and policy formation around privacy and has taken seriously the problem of ensuring privacy. librarians also have experience confronting and evaluating the asserted need to make tradeoffs between privacy and such other values as efciency, law enforcement, and security.electronic information technology has engendered a new cycle of debate about these tradeoffs. whether it is the use of electronic systems to maintain checkout records or the new ways in which information can be accessed via the internet, the library community has had to consider again whether and to what extent the privacy of its patrons should be compromised to enable full utilization of the new technologies. without exception these decisions have come down on the side of privacy to the fullest extent permitted by law. librarians have also become proactive in assessing the privacy implications of emerging technologies, such as digital rights management and rfid tags.not all of these decisions have been left to the library community. given the kind of information that library records might reveal about individuals, the law enforcement and intelligence communities have shown great interest in gaining access to that information. they have hoped that the information could be used to discover patterns of inquiry that might indicate threats to the united states. the library community has strenuously resisted such attempts, and continues to challenge recent laws that it believes compromise the privacy of library patrons. if history is any indication, attempts to use library information for these other means will be short lived and ultimately unsuccessful. the tradeoff between the freedom to read (and the associated freedoms of thought and expression) and the enhancement to security that might be gained from breaching the privacy guarantees provided by libraries has been examined many times engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.250 engaging privacy and information technology in a digital agein the past, and the end result has always been in favor of privacy as a means of ensuring freedom.however, it would be shortsighted to think that the only threat to the privacy of library patrons comes from governmental attempts to access library records in an attempt to discover what citizens are thinking or studying. as the format of the content that libraries offer their patrons becomes more and more digitally based, attempts by the providers of that content to ensure that they retain control of it may become as great a threat as that posed by the government, because of the nancial implications of such control. while statutes like the usa patriot act may dene the current battleground for the library community™s attempt to ensure patron privacy, drmts may well dene the next battleground.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.2519privacy, law enforcement, and national securitythe tension between individual privacy and law enforcement or national security interests has been an enduring force in american life, its origins long predating the advent of new media or current technologies. nowhere else is the tension between ﬁit™s none of your businessﬂ and ﬁwhat have you got to hideﬂ so easily seen.1although these tensions predate the information revolution, new technologies, new societal contexts, and new circumstances have sharply intensied that con˚ict, and even changed its focus. section 9.1 focuses on the uses of information technology in law enforcement and discusses the pressures that such uses place on individual privacy. section 9.2 does the same for national security and intelligence.1 as an illustration of the latter, houston police chief harold hurtt referred to a proposal to place surveillance cameras in apartment complexes, downtown streets, shopping malls, and even private homes to ght crime during a shortage of police ofcers and told reporters at a police brieng, ﬁi know a lot of people are concerned about big brother, but my response to that is, if you are not doing anything wrong, why should you worry about it?ﬂ see pam easton, ﬁhouston eyes cameras at apartment complexes,ﬂ associated press newswire, february 15, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.252 engaging privacy and information technology in a digital age9.1 information technology, privacy, and law enforcement9.1.1 backgroundby its very nature, law enforcement is an informationrich activity. the information activities of law enforcement can be broken into three categories.1. gathering and analyzing information to determine that a law has been violated;2. gathering and analyzing information to determine the identity of the person or persons responsible for a violation of law; and3. gathering and analyzing information to enable a legal showing in court that the person or persons identied in fact were guilty of the violation.all of these gathering and analysis activities have been altered in basic ways by functional advancements in the technologies that have become available for collecting, storing, and manipulating data.in actual practice, these categories can overlap or the activities in each category can occur in several temporal sequences. when a police ofcer observes someone breaking a law, the ofcer is determining that a law has been violated, gathering information about who broke the law (presumably the person he or she is observing), and gaining evidence that may be introduced in court (the testimony of the ofcer).the essential difference between these categories is the locus or subject about which the information is gathered. in the rst category concerning the breaking of a law, the locus of information is the event or activity. in the second sort of activity, the locus is the determination of an individual or set of individuals involved in the activity. in the third category, information associated with categories one and two are combined in an attempt to link the two in a provable way.although activities in the rst category usually precede those in the second, this is not always the case. law enforcement authorities have been known to start with ﬁsuspicious peopleﬂ and then seek to discover what laws they might have broken, might be breaking, or might be planning to break. this is one of the rationales for certain kinds of undercover activity and is frequently regarded as more controversial.these distinctions are important because they help to differentiate cases that generate concern about invasions of privacy from those that involve less controversial uses of the state™s investigatory power. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 253concerns about privacy invasions often involve the possibility that law enforcement ofcials can cast an unduly broad net, or one that is seen as discriminatory, as they gather information about persons in the absence of specic reasons to suspect that these individuals have violated some particular law.a case in which an individual is targeted to see if he or she has violated a law is conceptually (and legally and morally) different from a case in which information is gathered about an individual as part of an investigation into a known or suspected violation of law or in which there are other grounds for suspicion. in the former case, information may be gathered about individuals who in fact were not involved in a violationšwhich is different in kind from the task of assembling information about an individual in the hope of nding a violation of law.the potential for data gathering targeted at a particular individual or set of individuals to aid in the discovery of previously unknown violations of the law, or the risk that data gathered by law enforcement may be used for political or harassment purposes, often underlies efforts to restrict the kinds of information that law enforcement agencies can gather and the ways in which it is gathered. even if the information is never used, the very fact that considerable amounts of data have been collected about individuals who have not been accused or convicted of a crime ensures that substantial amounts of information about noncriminals will end up in the databases of law enforcement agencies. moreover, with such data a permanent part of their les, citizens may be concerned that this information will eventually be misused or mistakenly released, even if they are not suspects in any crime. they may even engage in selfcensorship, and refrain from expressing unpopular opinions. for individuals in this position, issues such as recourse for police misbehavior or carelessness are thus very important.nor are worries about the gathering of information by law enforcement agencies restricted to how that information could be used in legal proceedings. such proceedings are governed by the laws and professional ethics that protect the privacy of the individual, and the inappropriate use (in a criminal context) of information gathered by law enforcement agencies can be balanced by judicial review. however, even the suspicion of wrongdoing or being a ﬁperson of interestﬂ can have an effect on an individual™s ability to ˚y in a commercial airliner, obtain certain kinds of permits, gain some kinds of employment, obtain nancial services, or conduct business. for example, watch lists, such as those used by the transportation security agency, are not subject to the same level of scrutiny as evidence in a court of law yet can still affect the lives of those whose names appear on such lists. these uses of information are often not engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.254 engaging privacy and information technology in a digital agebalanced by judicial or any other kinds of review, leaving the individual at a severe disadvantage when information is inaccurate or incomplete.2none of these concerns about balancing the need for law enforcement agencies to gather information and the need of the citizen for privacy are new. what is new are the modern information technologies that law enforcement agencies can now use to observe situations and identify individuals more quickly, more accurately, and at less expense than ever before. these technologies include surveillance cameras, largescale databases, and analytical techniques that enable the extraction of useful information from large masses of otherwise irrelevant information.the sections that follow describe a number of technologies that allow law enforcement agencies expanded capabilities to observe, to listen, and to gather information about the population. just as the ability to tap phone lines offered law enforcement new tools to gather evidence in the past century, so also these new technologies expand opportunities to discover breaches in the law, identify those responsible, and collect the evidence needed to prosecute. and just like the ability to tap telephones, these new technologies raise concerns about the privacy of those who arešrightly or wronglyšthe targets of the new technologies. use of the technologies discussed requires careful consideration of the resulting tension posed between two legitimate and sometimes competing goals: information gathering for law enforcement purposes and privacy protection.9.1.2 technology and physical observationas a point of departure, consider the issue of privacy as it relates to government authorities conducting surveillance of its citizens. using the anchoring vignette approach described in chapter 2 (see box 2.2), a  possible survey question might be, how much does [your/ﬂname™sﬂ] local town or city government respect [your/ﬂname™sﬂ] privacy in [your/her/his] routine local activities? here are a number of possibilities:1. [anita] lives in a city that prohibits any form of video or photographic monitoring by government agencies.2. [bita] commutes to work every day into a city that automatically photographs each car to see whether it runs a particular stoplight.3. [jake] lives in a city that videotapes all cars on cityowned property.2 see, for example, peter m. shane, ﬁthe bureaucratic due process of government watch lists,ﬂ ohio state public law working paper no. 55, february 2006, available at http://ssrn.com/abstract=896740.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 2554. [beth] lives in a city that videotapes all people inside the hallways of cityowned buildings.5. [mark] lives in a city that uses a device in police cars to detect whether individuals are at home.6. [juanita] lives in a city that uses an imaging device in police cars that can see through walls and clothes.these vignettes, ordered from most to least privacyprotecting, illustrate only a single dimension of privacy (namely imagebased personal information), but they are a starting point for knowing what must be analyzed and understood in this particular situation, and what decisions society will have to make with respect to the issues the vignettes raise.whether it is used to see that a law has been or is being broken, to determine who broke the law, or to nd a suspect for arrest, physical observation has historically been the main mechanism by which law enforcement agencies do their job. physical observation is performed by law enforcement ofcers themselves, and also by citizens called as witnesses in an investigation or a trial. the vignettes above suggest that physical observation has evolved far beyond the inperson human witness in sight of the event in question.when individuals are watched, particularly by the state with its special powers, privacy questions are obviously relevant. the usual expectation is that, unless there is a reason to suspect an individual of some particular infraction of the law, individuals will not be under observation by law enforcement agencies. but because of advances in technology, the means by which law enforcement can conduct physical observation or surveillance have expanded dramatically. new technologies that provide automated surveillance capabilities are relatively inexpensive per unit of data acquired; vastly expand memory and analytical ability, as well as the range and power of the senses (particularly seeing and hearing); and are easily hidden and more difcult to discover than traditional methods. they can be used to observe violations of law as well as a particular individual over extended periods of time unbeknownst to him or her.today, for example, the use of video cameras is pervasive. once only found in highsecurity environments, they are now deployed in most stores and in many parks and schools, along roads, and in public gathering places. a result is that many people, especially in larger cities, are under recorded surveillance for much of the time that they are outside their homes.law enforcement ofcials, and indeed much of the public, believe that video cameras support law enforcement investigations, offering the prospect of a video record of any crime committed in public areas where they are used. such a record is believed to have both investigatory value engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.256 engaging privacy and information technology in a digital age(in identifying perpetrators) and deterrent value (in dissuading wouldbe perpetrators from committing crimes).3 however, these cameras also give those who operate them ever more information, often in the form of a reusable and possibly permanent record regarding where many lawabiding individuals are, who they are with, and what they are doing.another example concerns automobiles equipped with tracking systems, such as general motors™ onstar system, that permit the location tracking to a fairly ne resolution of anyone holding a cell phone. (such systems may be based on the use of gps or on cell phones that provide location information as part of e911 services.) by tracking people™s position over time, it is also possible to track their average speed,4 where they have been, and (by merging the positional information for multiple people) with whom they might have met. if such tracking is recorded, correlations can be made at any time in the future. indeed, given the right monitoring equipment and enough recording space, it is even possible that the locations of every person for much of a lifetime could be made available to law enforcement agencies or even family members or researchers.similar issues regarding data reuse arise with respect to the use of video cameras for the enforcement of trafc regulations. in many cities the trafc lights have been equipped with cameras that allow law enforcement agencies to determine violations of redlight stop zones simply by photographing the offending vehicles as they pass through the red light. such images allow local police agencies to automatically send redlightrunning tickets to the vehicle owners. even such a seemingly straightforward use of surveillance technology, however, brings up a host of privacy 3 it is unquestionable that video records have had forensic value in the investigations of crimes that have already been committed. the deterrent effect is less clear. a study done for the british home ofce on the crime prevention effects of closedcircuit television (cctv) cameras systematically reviewed two dozen other empirical studies on this subject and concluded that, on balance, the evidence suggested a small effect on crime reduction (on the order of a few percent) and only in a limited set of venues (namely, car parks). the deployment of cctv cameras had essentially no effect in public transportation or in citycenter contexts. welsh and farrington also noted that poorly controlled studies systematically indicated larger effects than did wellcontrolled ones. see brandon welsh and david farrington, crime prevention effects of closed circuit television, home ofce research study 252, august 2002, available at http://www.homeofce.gov.uk/rds/pdfs2/hors252.pdf.4 a lowertech version of this capability is inherent in toll systems on highways. for some highways, periodic toll plazas on turnpikes were replaced by a system in which the driver picked up a ticket at the point of entry that was then used to determine the toll at the location where the car exited. given that these tickets included the time of entry into the turnpike, there were concerns that the tickets could also be used upon exit to determine if the car had exceeded the speed limit. stories of such secondary use have the ring of urban myth, but they continue to surface on the internet and are certainly consistent with what the technology enables.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 257issues. for example, consider that these cameras could also be used to trace and record the presumed locations of people based on the observed time and location of their cars. that is, they could take pictures even when no car was running a red light. such a concern is based on the future possibilities for repurposing the information gathered by such cameras rather than on the purpose for which these cameras were originally deployed.note that nothing intrinsic in the use of a video system to catch those running trafc lights enables secondary use of the information. the system could be designed in such a way that only those images showing someone running a red light were kept, and all other images were discarded immediately. such a system could not be used to track the location of any but a small number of vehicles. designing such a system in this way is simple to do when the system is rst being built but is far more difcult once the system has been installed. however, privacy concerns associated with possible secondary uses are usually not raised when a system is designed, if nothing else because those secondary uses are not yet known or anticipated.it could be argued that a video camera at the stoplight is no different in principle from posting a live police ofcer at the same place. a police ofcer can issue a ticket for a car that runs a red light, and if a live police ofcer on trafc detail at the intersection is not a threat to privacy, then neither is the placement of a video camera there. others, however, would argue that a live ofcer could not accurately record all vehicles passing lawfully through the intersection, and could not be used to trace the movements of every vehicle passing through a busy intersectionšlawfully or notšin the way that a video camera can. the imageretention capacity of a video system vastly exceeds that of even the most astute human observer and thus allows the tracking of all vehicles, not just those that are of interest at the time they move through the intersection. the images stored by the video system can, in principle, be not just those of vehicles that have violated the law, but of all vehicles that have passed by the camera.in addition, information gathered by a video camera ostensibly deployed to catch cars running a red light can be used for other purposes, such as tracking the location of particular cars at particular points in time, or nding speeders (this would require combining of information from multiple cameras at multiple locations)špurposes that are not possible with a human ofcer. further, when the images are stored, law enforcement agencies gain the capability to track what individuals have done in the past, and not just what they are currently doing. the worry is that once the information has been gathered and stored, it will be used in a variety of ways other than that for which it was originally intended. such ﬁfeature creepﬂ is possible because what is stored is the raw information, in image form, which can be used in a variety of ways.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.258 engaging privacy and information technology in a digital agefinally, video surveillance is far less expensive than the use of many human ofcers. from an economic point of view, it is impossible in large jurisdictions to station ofcers at every intersection, but placing a video camera at many intersections is much less expensive and within the means of many police departments. an important check on executive power has always been based on the allocation of resources, and if technology can enable a greater amount of police activityšin particular, more surveillancešfor the same cost, the introduction of that technology changes the balance of power. perhaps most importantly, this change in the balance of power is often unnoticed or not discussedšand when it is, a dispute about the amount of police activity must be resolved explicitly on policy grounds rather than implicitly on economic grounds.beyond video technologies such as those discussed above, there is also the prospect that emerging technologies can extend the reach of observation from public spaces into what have traditionally been private spaces. there has been some use of infrared detectors to ﬁlook throughﬂ walls and see into a suspect™s home;5 although the supreme court recently suggested that such law enforcement surveillance tactics might violate the resident™s ﬁreasonable expectation of privacyﬂ (section 1.5.5), the courts have not categorically rejected the use of such sophisticated imaging devices. if environmental sensors become pervasive, it may in the near future become possible to infer the location of people from the information gathered for purposes such as energy conservationšand to infer identities by correlating that information with other recorded information (such as building access records).the conditions under which law enforcement agencies will or should have access to such information raises difcult questions both of law and of policy. concern over the potential use of such sensitive information lies at the heart of many privacybased concerns about the deployment of such technologies. the deepest concern, from the privacy perspective, is the potential for combining constant and nonobvious data gathering and the ability to assemble the data gathered to give the effect of largely constant observation of any space, whether public or private. such a prospect, combined with the temporally permanent nature of the data when they are stored, appears to give law enforcement agencies the ability to constantly monitor almost any place and to have access to a history of that 5 a number of court cases have been brought addressing the question of whether the use of a thermalimaging device aimed at a private home from a public street to detect relative amounts of heat within the home constitutes a ﬁsearchﬂ within the meaning of the fourth amendment. the denitive ruling on this point is the decision of the u.s. supreme court in kyllo v. united states, no. 998508 and decided on june 11, 2001, which held that it is a search and thus must be governed by the apparatus designed to protect the public against unreasonable searches.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 259place. together with the ability to aggregate and mine the data that have been gathered (discussed below), this prospect would appear to give law enforcement enormous amounts of information.the most serious issues arise if and when such technologies enable monitoring of specic individuals. many presentday technologies indicate bodies, but not the identities of the persons who own those bodies. future technologies may enable the identication of individualsšthat is, the highaccuracy association of specic names with the bodies within viewšin which case the privacy concerns are accentuated manyfold. (even today, modern cell phones with location identication capabilities yield information about the whereabouts of individuals, because of the generally unviolated presumption that individuals carry their cell phones with them.)9.1.3 communications and data storageboth communication and data storage technologies have long been of interest and use to the law enforcement community. being able to observe and overhear the discussions of those suspected of breaking the law and to obtain records of criminal activity has been an important means for gaining evidencešbut has also created inevitable threats to principles of privacy.the primary difference between records and communications is that by denition, records are intended to persist over time, whereas communications are more transient. transient phenomena vanish, and they are generally more private than persistent entities that can be reviewed anew, copied, and circulated. for this reason, technologies that threaten the privacy of records are often seen as less problematic than those that threaten the privacy of communications.for keeping records private, the most common technique used has been to hide the records in a location known only to their owner. one can ﬁhideﬂ records by placing the le in a secret location (e.g., in an ﬁinvisibleﬂ directory on one™s disk, on a cdrom stored under the mattress or under a rock in the back yard or in a safe deposit box, or embedded secretly in another document). today, there are few generally applicable technologies that enable law enforcement authorities to nd records in a secret location without the (witting or unwitting) cooperation of their owner. thus, debates over the appropriate balance between the privacy of recordsševen digital recordsšand the needs of law enforcement authorities for those records have been relatively straightforward, and based on the ability of law enforcement authorities to compel or trick the owner into revealing the records™ location. (the use of encryption to hide records, discussed in more detail below, presents a wrinkle in this debate, but the engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.260 engaging privacy and information technology in a digital agesame techniques are available to law enforcement authorities to compel or trick the owner or others into revealing the decryption keys that would allow law enforcement access.)but history paints a much different picture when it comes to communications. for the interception of telephone conversations, email, and internetbased communication, the proper balance between the claimed needs of law enforcement for access to such communications, and the privacy interests of persons who are the participants in the targeted communication, has been elusive and more difcult to dene.when the bill of rights was enacted, communication consisted either of spoken language (which could only be heard directly) or written. written communications are a type of record, and such records can be obtained by law enforcement personnel as the result of a search (under rules covered by the fourth amendment). but what of written communications being sent through the mailsšwere these communications more like utterances made in public, and therefore not subject to the same explicit protections of privacy, or were they more like records private and covered by the protections of the fourth amendment?in the case of mail carried by the u.s. postal service, the decision was that the outside of the mail (such as the address and return address) was public information, and not covered by the need for a search warrant,6 but that any communication inside the envelope was considered private and any viewing of that information by law enforcement required a search warrant obtained under the requirements of probable cause.7as communication technologies advanced, the distinction between what was publicly available and what was private in those technologies became the crux of the debates about the privacy of those communica6 ex parte jackson, 96 u.s. (6 otto) 727,733 (1877).7 the process by which national security investigators have obtained mail cover information has been governed by u.s. postal regulations for nearly 30 years. see 39 c.f.r. 233.3. the authority to use mail covers for law enforcement purposes rst appeared in the 1879 postal regulations. section 212 statutorily authorizes the continued use of mail covers in national security investigations. a ﬁmail coverﬂ is the process by which the u.s. postal service furnishes to the fbi the information appearing on the face of an envelope addressed to a particular address: i.e., addressee, postmark, name and address of sender (if it appears), and class of mail. the actual mail is delivered to the addressee, and only the letter carrier™s notation reaches the fbi. a mail cover does not include the contents of any ﬁsealed mail,ﬂ as dened in existing u.s. postal regulations (see 39 c.f.r. 233.3(c)(3)) and incorporated in section 212. although the supreme court has not directly addressed the constitutionality of mail covers (the court has denied certiorari in cases involving the issue), lower courts have uniformly upheld the use of mail covers as consistent with the requirements of the fourth amendment. see vreeken v. davis, 718 f.2d 343 (10th cir. 1983); united states v. depoli, 628 f.2d 779 (2d cir. 1980); united states v. huie, 593 f.2d 14 (5th cir. 1979); and united states v. choate, 576 f.2d 165 (9th cir.), cert. denied, 439 u.s. 953 (1978).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 261tions and what access law enforcement agencies had to the communication. perhaps the best example concerns communication by telephone. when telephones were rst introduced, the circuits were connected by an operator who often needed to listen in on the call to monitor quality, and most of the telephone lines were shared or ﬁpartyﬂ lines, allowing conversations to be heard by anyone with whom the line was shared (although good manners suggested not listening when the call was not for you).with this history, it was generally held that discussions over a telephone were like discussions in public, so that law enforcement agents could listen in on such conversations, and could use in criminal prosecutions the contents of what they heard, with no oversight and without the consent of those whose words were monitored. indeed, in olmstead v. united states, 277 u.s. 438 (1928), the u.s. supreme court held that ﬁthe reasonable view is that one who installs in his house a telephone instrument with connecting wires intends to project his voice to those quite outside, and that the wires beyond his house, and messages while passing over them, are not within the protection of the fourth amendment. here those who intercepted the projected voices were not in the house of either party to the conversation.ﬂ in so holding, it ruled that ﬁthe wire tapping here disclosed [in the case] did not amount to a search or seizure within the meaning of the fourth amendment,ﬂ and thus that telephone conversations were not protected or privileged in any way over ordinary speech outside the home. there was, in this view, no (rational) expectation of privacy for such conversations (although the term ﬁexpectation of privacyﬂ had not yet come into use).this view of telephone conversations lasted until 1967,8 when the supreme court ruled that there was, in fact, a constitutional expectation of privacy in the use of the telephone. by this time, operators were hardly ever used for the connection of circuits and were not expected to monitor the quality of phone conversations, nor were most phone lines shared. however, the decision that there was an expectation of privacy in such conversations lagged signicantly behind the technological developments that created such an expectation. at this point, the court decided that telephone calls were like physical mail, in which each call had a public ﬁoutsideﬂ and a private ﬁcontents.ﬂ the public envelope contained the information necessary to establish the circuit for the call (including the phone from which the call was being made and the phone to which the call was made) but did not include the contents of the call, which was considered private. gaining legal access to that part of the call required a warrant issued by a judge after a showing of probable cause.the last two decades have seen a novel set of communication technol8 katz v. united states, 389 u.s. 347.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.262 engaging privacy and information technology in a digital ageogies become generally available. the internet, encompassing both electronic mail and the world wide web, has provided new mechanisms for communication. the web allows onetomany communication, enabling nearly everyone to be a publisher for very little cost. electronic mail allows communication between parties in ways that are fast, efcient, and highly resilient to failure. the cell phone network has changed many of the old limitations on telephony, allowing conversations between people who are mobile. new emerging technologies such as voiceoverip, in which telephonelike communication can be carried over the same internet using protocols rst designed for data transmission, merge the functionality of voice networks with the underlying technologies of data networks.new communication technologies are of obvious interest to law enforcement agencies. some law enforcement ofcials see the web sites that a person visits, or the email that a person sends or receives, as information that could be relevant to the prosecution of criminals. on that basis, they have argued that law enforcement agencies should have legal access to such information equivalent to that available for telephone conversations. law enforcement ofcials currently have access to pen registers and trapandtrace registers on telephone calls, which show what calls were made from a particular phone (pen registers) or to the phone (trap and trace). the installation or attachment of pen registers and trapandtrace registers does require a court order, but obtaining such an order need not overcome a high standard of probable cause, requiring only a request by the law enforcement agency. similarly, because agents can discover the source and destination of paper mail simply by observing an envelope, it has been argued by analogy that law enforcement agencies should have access to the destinations of web browsing and email messages. those who are troubled by this analogy note (correctly) that on the internet addressing information cannot easily be separated from the content of the message, a distinction that is central to the availability of routing information for telephone calls and paper mail (box 9.1).in a similar fashion, cell phone networks are quite different from those that connect landlines. cell phone networks allow the users to move while a call is in progress. this new functionality requires that the ﬁcircuitﬂ connecting the cell phone and the rest of the network go through a series of connections, depending on the cell that is handling the phone. as the phone moves from one cell to another, technical handoff protocols allow the voice trafc to be moved from cell to cell without the interruption of service. while the voice service being offered is similar to that provided by landlines, the technology underlying the network is very different.the claim that law enforcement should have access to internet and cell phone communication rests on analogies drawn between these sorts engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 263of communication and more traditional communication mechanisms such as landline phones and physical mail. however, the technology needed to provide the same capabilities is very different, as the characteristics of the networks underlying the communication mechanisms are very different. the separation of information that made it possible to provide the ﬁpublicﬂ information without compromising the ﬁprivateﬂ information is a property of the underlying network. while it is possible to separate seeing the addressing information on a piece of sealed physical mail from seeing its content (although the letter could always be surreptitiously opened), there is no easy equivalent physical separation for electronic mail.debates over law enforcement access to internet and cell phone communications also reveal another point of contention that is rarely acknowledged explicitly: whether the protection of privacy should be a property or a characteristic or a feature afforded by technology or by policy. those taking the position that the protection of privacy should be technologically based argue that technologically based assurances of privacy cannot be easily circumvented by capricious changes in policy or by law enforcement personnel acting outside their authority. a more moderate version of this position is to build technology that enforces policy rigidly, so that, for example, a wiretap that requires legal authorization from a judge cannot physically be performed without a onetimeuse key (physical or logical) that is available only from a judge. thus, grounding privacy protection in technology eliminates or reduces the need to trust law enforcement authorities to respect privacy rights of lawabiding citizens, and advocates of this position often justify their position by references to past government violations of privacy.by contrast, those who argue that policy considerations should be the source of privacy protections note that without special attention, changing technologies can also change the preexisting balance between privacy protection and law enforcement accessša balance that has been obtained through the policymaking process, and thus should be changed only by that process (rather than by technological advancement). further, they argue, procedural protectionsšsuch as excluding evidence obtained through improperly obtained techniques and strict enforcement of internal regulations against improper behavioršsufce to deter abuse of authority. thus, proponents of this position argue that technological developments in communications should be guided or regulated in such a way that they do not compromise the communications access capabilities that prior policy decisions have endorsed and sanctioned. policy decisions and law, rather than everchanging technology, should determine functionality and use.these differences in perspective have played out many times in recent years, notably in debates over the communications access for law engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.264 engaging privacy and information technology in a digital agebox 9.1 telephone networks, data networks, and the law much of the law having to do with access by law enforcement and national security agencies to data networks has been drawn from similar laws dealing with telephone networks. indeed, notions of tapping a communication line and establishing pen registers, and decisions about when a warrant is needed for data communications, often make explicit reference to the decisions and laws governing the phone network. intuitively, such an extension from the phone system to data networks like the internet makes sense. both are communication networks, and much of the trafc that is now carried over the internet (such as email and newsgroups) was originally carried over the phone lines. however, these analogies lead to confusing and contradictory results, since the technology underlying data networks such as the internet and the technology that underlies phone networks are intrinsically different in ways that are relevant to the decisions that have been made. traditional phone networks are circuit based. when a phone call is initiated, information is supplied to the network that allows a bidirectional connection to be made between the caller and the phone being called. in early incarnations of the phone network, this was done by calling an operator, who would literally connect a cable that would complete the connection between the two phones. automated switching and dialing have eliminated the operator, but the idea is the same; when you dial a call, the switching hardware is used to create a connection between the two phones that is unshared, is bidirectional, and carries the signal that is the conversation between one phone and the other. unlike the traditional phone network, the protocols that are the basis of the internet are packet based. rather than establishing a circuit between the sender of information and the receiver and then sending the information over that circuit, any message is broken into chunks, with each chunk being wrapped with information about its destination and each being sent over the network. these packets are sent from one machine to another, with each machine looking at the information having to do with where the packet is to be sent and forwarding that packet. different packets may take very different routes to the same destination. at the nal destination, the packets are reassembled into a single message, which is then delivered to the intended recipient. one of the major differences between a packetbased network and a circuitbased network is that a packetbased network mixes the routing information with the information being sent over the network. in a circuitbased network, the routing information is used only to establish a circuit; once the circuit is established this information is not needed. further, during the establishment of the circuit, no content is sent or revealed. packetbased networks make no such separation between the routing information and the contentšindeed, these two kinds of information are present in all of the packets. these differences may seem minor until we see how the law has been extended from one kind of network to the other. for example, the law concerning interception of communication on a traditional phone network distinguishes between a pen register, which allows the recording of the establishment of a call (essentially, a trace of all of the calls made from a particular phone, showing the numbers to which the calls were made) and tapping the phone, which allows listening in on the conversation. the burden of proof for a pen register is much lower than that for a phone tap. such a distinction makes sense in the case of the traditional phone network, where the information gathered as part of the pen register is concerned with the setting up of the circuit, which happens in a fashion that is distinct from the carrying of information over the circuit. extending the distinction between a pen registry and a full tap is not so easy in the case of a packetbased network. as with phone networks, requests by law enforcement agencies for information about the recipients of messages from a computer require much less cause for granting than requests to intercept the content of such messages. however, since the routing information is mingled with the content, it is not clear how the observation of the routing information can be done in such a way that the content of the messages is not also revealed. circuitbased networks also dedicate a separate circuit to each connection, keeping the contents of each circuit separate. this allows the tapping of a particular telephone conversation to be done without the observation of the contents of other telephone conversations. in packetbased networks, there is no such isolation of contents. packets from all communications are mixed together on the same network, and it is only by the observation of the packets that one can tell which packet is part of which communication. this also means that any attempt to view the contents of one communication on such a packetbased network can require the observation of many other communications over that network. there have been attempts to interpose technology on packetbased networks in an attempt to allow pen registries and isolated tapping of communications in such networks. one such attempt was the carnivore program,1 which interposed a piece of specialized hardware between the network and the observers of network communications. the purpose of the hardware was to pass along to law enforcement ofcials only those packets that they had legal authorization to read, but to do so the hardware had to observe all packets passing by. however, critics noted that the hardware was under the control of the very agencies that were doing the observation, and that the process required trust in the law enforcement agency using the hardware to congure it properly (i.e., to pass along only the legally authorized information) without external oversight.1for more information on carnivore, see independent technical review of the carnivore system final report, iit research institute, december 8, 2000, available at http://www.usdoj.gov/jmd/publications/carnivnal.pdf.enforcement act (calea) and over encryption. calea required that telecommunications providers build into their networks and switching systems the capability to provide the contents of voice communications to law enforcement authorities (subject to all of the existing restrictions on such wiretaps imposed by law) regardless of the technology used. thus, engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 265box 9.1 telephone networks, data networks, and the law much of the law having to do with access by law enforcement and national security agencies to data networks has been drawn from similar laws dealing with telephone networks. indeed, notions of tapping a communication line and establishing pen registers, and decisions about when a warrant is needed for data communications, often make explicit reference to the decisions and laws governing the phone network. intuitively, such an extension from the phone system to data networks like the internet makes sense. both are communication networks, and much of the trafc that is now carried over the internet (such as email and newsgroups) was originally carried over the phone lines. however, these analogies lead to confusing and contradictory results, since the technology underlying data networks such as the internet and the technology that underlies phone networks are intrinsically different in ways that are relevant to the decisions that have been made. traditional phone networks are circuit based. when a phone call is initiated, information is supplied to the network that allows a bidirectional connection to be made between the caller and the phone being called. in early incarnations of the phone network, this was done by calling an operator, who would literally connect a cable that would complete the connection between the two phones. automated switching and dialing have eliminated the operator, but the idea is the same; when you dial a call, the switching hardware is used to create a connection between the two phones that is unshared, is bidirectional, and carries the signal that is the conversation between one phone and the other. unlike the traditional phone network, the protocols that are the basis of the internet are packet based. rather than establishing a circuit between the sender of information and the receiver and then sending the information over that circuit, any message is broken into chunks, with each chunk being wrapped with information about its destination and each being sent over the network. these packets are sent from one machine to another, with each machine looking at the information having to do with where the packet is to be sent and forwarding that packet. different packets may take very different routes to the same destination. at the nal destination, the packets are reassembled into a single message, which is then delivered to the intended recipient. one of the major differences between a packetbased network and a circuitbased network is that a packetbased network mixes the routing information with the information being sent over the network. in a circuitbased network, the routing information is used only to establish a circuit; once the circuit is established this information is not needed. further, during the establishment of the circuit, no content is sent or revealed. packetbased networks make no such separation between the routing information and the contentšindeed, these two kinds of information are present in all of the packets. these differences may seem minor until we see how the law has been extended from one kind of network to the other. for example, the law concerning interception of communication on a traditional phone network distinguishes between a pen register, which allows the recording of the establishment of a call (essentially, a trace of all of the calls made from a particular phone, showing the numbers to which the calls were made) and tapping the phone, which allows listening in on the conversation. the burden of proof for a pen register is much lower than that for a phone tap. such a distinction makes sense in the case of the traditional phone network, where the information gathered as part of the pen register is concerned with the setting up of the circuit, which happens in a fashion that is distinct from the carrying of information over the circuit. extending the distinction between a pen registry and a full tap is not so easy in the case of a packetbased network. as with phone networks, requests by law enforcement agencies for information about the recipients of messages from a computer require much less cause for granting than requests to intercept the content of such messages. however, since the routing information is mingled with the content, it is not clear how the observation of the routing information can be done in such a way that the content of the messages is not also revealed. circuitbased networks also dedicate a separate circuit to each connection, keeping the contents of each circuit separate. this allows the tapping of a particular telephone conversation to be done without the observation of the contents of other telephone conversations. in packetbased networks, there is no such isolation of contents. packets from all communications are mixed together on the same network, and it is only by the observation of the packets that one can tell which packet is part of which communication. this also means that any attempt to view the contents of one communication on such a packetbased network can require the observation of many other communications over that network. there have been attempts to interpose technology on packetbased networks in an attempt to allow pen registries and isolated tapping of communications in such networks. one such attempt was the carnivore program,1 which interposed a piece of specialized hardware between the network and the observers of network communications. the purpose of the hardware was to pass along to law enforcement ofcials only those packets that they had legal authorization to read, but to do so the hardware had to observe all packets passing by. however, critics noted that the hardware was under the control of the very agencies that were doing the observation, and that the process required trust in the law enforcement agency using the hardware to congure it properly (i.e., to pass along only the legally authorized information) without external oversight.1for more information on carnivore, see independent technical review of the carnivore system final report, iit research institute, december 8, 2000, available at http://www.usdoj.gov/jmd/publications/carnivnal.pdf.debates have arisen about the extent and nature of technological measures needed to comply with this regulation with technologies in use such as voiceoverip and cellular technology.in the case of encryption, the past 20 years have seen a revolution in easy access to encryption technology, and easy access to highgrade crypengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.266 engaging privacy and information technology in a digital agetography has the potential to change the balance between individuals and their government (box 9.2). with encryption widely available today, it is now possible for agencies to have physical access to data but not be able to interpret the data without the cooperation of parties with access to the relevant decryption keys.law enforcement authorities have expressed concerns that the use of encryption by criminals would stymie access to communications and records important to prosecution. a problem arises because encryption is also a tool that can be used to prevent many crimesštheft of proprietary data, identity theft, nonauthorized wiretapping, and so on.to address this issue, the u.s. government proposed in the 1990s a concept of encryption known as key escrow, in which strong encryption systems would be allowed subject to the proviso that the decryption keys for such systems be placed in a database that could be accessed by the government under certain conditions.9 while the initial plans for such a database required that access be protected by ensuring court review, privacy objections to the plan were based on the inability of the government to guarantee that such review would always be required and that the requirement for such a review would always be followed. furthermore, implementing key escrow would potentially introduce additional security vulnerabilities that nongovernmental entities could exploit. for these and other reasons unrelated to the protection of personal privacy, key escrow systems for communications have largely been abandoned.109.1.4 technology and identicationobservation of the physical presence of a person, or the ability to intercept the communications of a person, is most useful to law enforcement if the person who is being observed, or whose communications are intercepted, can be identied. identication is essential to enable multiple observations or communications to be correlated. it is the identity of the individual that allows a coherent picture to be pieced together from the set of observations and communications that have been taken. even when sure identication of the individual is impossible, the ability to limit the identity to a member of a small group might be enough to make 9 for more discussion, see national research council, cryptography™s role in securing the information society, kenneth w. dam and herbert s. lin, eds., national academy press, washington, d.c., 1996.10 however, key escrow systems for data storage have been deployed with some success, simply because there are good business reasons for such systems. in these systems, keys for emergency decryption are stored in a database controlled by the owner of the records being stored, and if that owner loses the decryption keys, the backup keys still remain available.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 267box 9.2 encryption for many years, strong encryption algorithms were the property and province of government, since the ability to generate good encryption algorithms and to build the machinery to employ those algorithms was prohibitively expensive for most corporations, let alone individuals. however, the combination of much faster computing machinery and the development of publickey cryptosystems (along with the expanded interest in other cryptographic systems) have brought within the abilities of an individual the capacity to encrypt all of his or her data in a way that makes it extremely difcult (or impossible) and costly for law enforcement agencies to read that data. such cryptographic techniques are no longer limited to computerbased communication systems. as more and more communication systems move to a digital base, it becomes progressively easier to apply the same cryptographic techniques used in computers to those other communication channels. cell phones, which are now reaching the computational capacity found only on desktop computers as recently as 3 to 5 years ago, are now capable of performing reasonablegrade cryptography on voice communications. one method to prevent criminal use of encryption would be to forbid private encryption, making the private possession of encryption devices an offense by itself. this is not feasible for two reasons. first, it would necessarily outlaw the legitimate applications of cryptography, such as those used to secure networks, enable safe electronic commerce, and protect intellectual property. second, it would be largely impossible to enforce, since any generalpurpose computer (including anyone™s desktop machine) can be programmed to provide encryption capabilities. consider, for example, software cryptographic systems such as pretty good privacy (pgp) that are easily obtained in opensource form and can be built and run by users with little technical sophistication, or commercial operating systems such as mac os x and windows that include features that allow all of the user™s data to be encrypted (in the case of the macintosh, using a u.s. governmentapproved encryption algorithm). utilities such as the secure shell (ssh) allow easy encryption of data over the network. historically, the u.s. government™s position on cryptography re˚ected the premises that drove the asserted need for national security access to data. by limiting the economic viability of developing strong cryptographic systems (by, for example, making it difcult for u.s. information technology vendors to export such systems), the spread of strong cryptography internationally was inhibited for many years, and this phenomenon had the collateral effect of inhibiting the domestic use of cryptography as well. law enforcement considerations were much more prominent in the key escrow proposal, which the administration ˚oated in the mid1990s as an intermediate step between weak encryption and the widespread availability of strong encryption.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.268 engaging privacy and information technology in a digital agethe information useful in an investigation. further, the ability to identify an individual is essential to the capturing of that individual once it has been determined that there is reason to prosecute that individual for some violation of law.the most common form of identication is that which occurs when some other person directly observes and identies a suspect or target. however, such identication requires that the person to be identied must rst be known to the person doing the identication. the most common form of identication not dependent on personal knowledge of the suspect or target involves the use of identication documents. such documents are often government issued, although there is currently no single governing standard in the united states for whom and under what circumstances such a document is issued. indeed, the chain of documents used to establish identity often leads through multiple governmental bodies; passports (which are issued by the federal government) are often issued based on identity established via a driver™s license (issued by the state government) and a birth certicate (usually issued by the city or county). this documentation chain is long enough and the connections between the documents tenuous enough that it is often possible to obtain fraudulent identication.11the task of identication in the law enforcement context is complicated by at least two factors. the rst is that the person who is the subject or target may wish to remain anonymous, and will thus have done whatever is possible to preclude or at least hamper accurate identication. this process does not entail identication in the sense of authentication, where all that is at issue is whether or not the subject is who he or she claims to be with respect to some (often nonpersonal) standard of eligibility, but rather full˚edged identication, where the task is to determine, often in the face of falsied evidence or testimony, a person™s true identity.12 the second complicating factor is that law enforcement can seek to identify a subject at various times during an investigation, using different types of evidence. such evidence might be the reports of an eyewitness or might involve more circumstantial evidence (such as the use of a computer or cell phone at a particular time).biometrics is a technology that has long been used to aid in the identication of persons. perhaps the best known biometric identication system involves the use of ngerprints. the use of ngerprints for 11 national research council, idsšnot that easy: questions about nationwide identity systems, stephen t. kent and lynette i. millett, eds., national academy press, washington, d.c., 2002.12 recall that section 1.5.1 of this report comments on the issue of a person™s ﬁtrueﬂ identity.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 269identication is possible because of two factors: the putative uniqueness of a person™s ngerprints and their relatively unchanging nature over time. because of these characteristics, ngerprints can be used to identify a subject as the same person over time (although not identify who that person is, unless there are prior records that associate a particular ngerprint with a particular individual on the basis of still other records or accounts).the ability to identify a person consistently over time is all that is needed to knit together the information that might be gathered about an individual through observation (either direct or indirect) or through the interception of communications. technology is beginning to provide a number of such biometric measures that are of interest to law enforcement agencies. emerging as an identication mechanism on a par with ngerprints is dna proling, which has been used in court cases to establish that a subject is (or is not) the person who left some dna at a crime scene. other biometrics that can aid in uniquely identifying a person, such as palm prints or retinal scanning, are being investigated as mechanisms to ensure the identity of a person, both by law enforcement agencies and to aid in the control of access to secure areas. none of these forms of identication is foolproof, with some (like ngerprints and dna proling) offering a high degree of accuracy, and others (such as palm prints, retinal scanning, or voice prints) having a lower degree of accuracy today. most must be measured either in the laboratory or in carefully controlled conditions.the aforementioned biometric mechanisms share a third characteristic: most currently require that the person being identied be in close proximity to or in actual contact with the device that is doing the reading of the biometric identier, and are therefore seldom if ever used without the knowledge (and, often, without the consent and active participation) of the person being identied. of even greater interest to the law enforcement community and relevance to issues of privacy are a set of biometric identication techniques that can be used from a distance without the knowledge or consent of the person being identied. such remote identication techniques offer the promise of being able not only to identify individuals as part of routine observation, but also to aid in the capture of fugitives by enabling covert identication in a broad set of contexts.perhaps the best known remote identication technique is automated facial recognition, which attempts to identify a person from the characteristics of his or her face. this technology is currently being used in a number of prototype systems. the technology allows automated matching from a database of pictures to images that can be taken from photographs or video streams. especially in the case of video streams, facial recognition technology promises to allow the identication of individuals from a engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.270 engaging privacy and information technology in a digital agedistance and without their knowledge (or consent). however, the results of the use of this technology have been mixed, at best, in all but the most controlled of conditions. in addition, there have been few real tests of the efcacy of facial recognition technology in the kinds of environments that are of most interest to law enforcement agencies that have not been conducted by selfinterested parties (e.g., the vendors of such technology). without independent analysis by uninvolved parties, it is difcult to assess the real promise of such technology.in the same way that facial recognition technology might be combined with the visual observation technologies to enable the tracking of the activities of a person, the biometric of voice recognition can be used as an identication mechanism for vocal forms of communication. voice recognition technologies are reasonably robust in controlled environments (making them excellent choices for some forms of access control) but are less so in noisy environments.other biometric identication mechanisms have also been proposed or are being actively studied. among those listed by the international biometric group13 as having ﬁreduced commercial viability or in exploratory stagesﬂ are odor recognition, through which an individual can be identied by his or her smell, and gait recognition, in which a person can be recognized by the way in which he or she walks.today, the technology is relatively immature for remote biometric identication and/or identication without the consent or participation of the individual being identied, and in no meaningful sense can remote biometric identication technology be said to usefully work. thus, there exists an opportunity for discussion of the privacy aspects of the technology to begin before the systems have been fully formed.14 this fact allows, for example, discussions of such things as the repurposing of the identication information or the longterm storage of information coming from such systems before the systems are actually built. the premature deployment of these technologies has made everyone more aware of the problems that can arise because of false positive identications. by understanding the limitations of these technologies, it is also possible to design 13 international biometric group, ﬁwhat are the leading biometric technologies?,ﬂ available at http://www.biometricgroup.com/reports/public/reports/biometrictypes.html, accessed june 14, 2006.14 nonconsensual and/or remote identication of individuals poses by far the most serious privacy issues, as compared to identication techniques that require consent. however, this is not to say that biometrics of all kinds do not pose other issues. a forthcoming cstb report on biometrics will address these points in greater detail than is possible here, but as one example, consider the possibility that a biometric identier might somehow be compromised. ﬁgummi bearﬂ ngerprint duplicates have been used to fool ngerprint readers, thus raising the question of how a biometric identier might somehow be revoked.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 271the systems using the technologies for those contexts in which they can be most valuable, rather than thinking that they can be extended to any environment.presented in such a way, the debate over the use of biometrics could be an example of how the development of such technology can be more effectively, more rationally, and less contentiously considered in relation to privacy and related values. the technology has great promise but also is open to signicant abuse. by raising the issue before it is too late to shape the direction of the technology, the development of biometric identication might offer a model case study for future technologies that pose issues arising from con˚icting societal needs.biometrics technology by itself is not inevitably privacy invasive. however, when combined with the various forms of surveillance technologies discussed in the previous section, such identication technologies (especially those that allow identication at a distance in a noninvasive fashion) permit the repeated collection of information about individuals and linking of information to that individual. this in turn can be used to populate a database that stores information on where a person has been and when he or she has been there.9.1.5 aggregation and data miningdatabases, generally in paper format, have long been created and maintained on the habits, histories, and identifying characteristics of those who have been arrested, convicted of breaking laws, or are otherwise considered by law enforcement agencies to be a ﬁperson of interest.ﬂ for example, collections of ngerprints of individuals have been assembled and kept at both the local and national level since the early parts of the 20th century, when it was determined that identication by ngerprint could be used in linking individuals to violations and in locating them for arrest and trial.computers were adopted early by law enforcement agencies in order to improve their ability to collect, collate, manipulate, and share information. moving information into computer databases, rather than keeping it in paper les, allowed the information to be searched, located, shared, and crossreferenced in ways that were previously impossible. by vastly increasing the amount of information that could be gathered and stored and by introducing new ways in which that information could be retrieved and correlated, the computer soon became an indispensable tool in law enforcement.what has changed is the amount of digital information generated and stored about everyone. almost every activity in modern life, from grocery shopping to surng the web to making a phone call, generates engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.272 engaging privacy and information technology in a digital agesome record in a database somewhere. the sum total of these records, which might be described as our ﬁdigital shadow,ﬂ provides a view into the activities of a person that can reveal activities, interests, tastes, and routines. for law enforcement agencies, these digital shadows can also provide a rich environment for investigation and evidence gathering.how much of this digital shadow is available to law enforcement agencies, and under what circumstances that information should be available, are currently open questions. some databases compiled by the federal government, such as those of the census bureau, are protected by statutorily enforced condentiality guarantees, and law enforcement agencies do not have legal access to them. general federal databases are open to law enforcement examination but are governed by the privacy act of 1974, which requires that databases containing individually identifying information be identied to the public and that those whose information is stored in those databases be allowed to have access to the information and to correct or amend the information within the database. (this issue is addressed further in section 9.3.)also of interest (and concern) from the privacy perspective are the data gathered and stored by nongovernmental agencies. this information would include most of the digital shadow of any individual, including nancial information, transaction histories, and the myriad other forms of data that are accumulated about each of us in our everyday lives. some of this information (such as personal health information stored in one™s medical record) is mostly private under existing law. but the vast majority of the information gathered and stored by third parties (such as banks or other nancial institutions) has been determined by the courts and legislation not to be private records and is routinely available to law enforcement agencies. when that information is stored electronically, there are fears that the information can be shared and linked even more easily. the end result is that the amount of information that is available to a law enforcement agency about any particular individual is considerable, and the tools that can be used to comb through that information continue to grow in sophistication.the valid concerns created by the vast amount of information available to law enforcement agencies should be tempered by the realization that the process of aggregating such information is not a simple undertaking. when talking about the information that is gathered by law enforcement agencies, people often speak as if there were a single database containing all of the information about a particular person, or even a single database containing all of the information about all persons. in fact, this is far from the case. different law enforcement agencies at different levels of government (local, state, federal) do not share a single megadatabase of information. different agencies even at the same level of government engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 273maintain their own distinct data repositories. even within a particular law enforcement agency, there are many different databases, in many different forms, containing the information gathered on individuals. these databases may not share formats, or even have compatible mechanisms for identifying an individual.as discussed in section 3.9, aggregation of the information in such databases is not a trivial undertaking. generally these databases have been designed with different keys, different elds, and different ways of interpreting the elds.the task of formulating queries that will be understood by multiple databases or in interpreting the results from any such queries requires that the person formulating the query know the details of each of the databases. this task can easily become more complex than current techniques can handle, although in any given instance and with sufcient work, the task is often doable. for example, consider the seemingly simple problem of identifying a person in multiple databases. the name of the person is generally not sufcient for unique identication. some number can be assigned to the individual, but it is unlikely that the number will be the same from one database to the next unless that number has some other signicance (such as being the person™s social security number).nor is it the case that the information gathered by law enforcement, even when in digital form, can always be easily manipulated or aggregated with other information. for example, the video taken from observation cameras may be in digital form, but it is not captured in a form that can easily be manipulated by the computer or correlated with other digital information. to correlate the digital shadow of an individual with the movements of that person as shown by video cameras requires that the video camera images be identied as those of a particular individual. to convert from data that represents information about the light that entered the video lens to information about the location of some person requires the ability to recognize the pictures on the video as particular individuals. as noted above, remote identication technology that will aid in this conversion is currently being developed, but it is far from being in a state that allows even the most sophisticated of government agencies to routinely convert observation information into something that could be used in datamining applications.in fact, very little technology exists that allows the automatic conversion of the kinds of raw data collected by the sophisticated sensors discussed above into a format that permits the data to be mined or otherwise collated. if law enforcement agencies have the raw data (in the form of, say, video images from cameras in public places) that would allow them to trace the movements of a person, the technology today will allow that tracing only by the application of large amounts of human effort (a law engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.274 engaging privacy and information technology in a digital ageenforcement agent watching all of the tape for all of the places that a person might have been). nor is there any feature today that permits these raw data to be converted into information in a fully automated fashion. while there have been attempts to automate such a conversion in the elds of image processing, years of research have failed to move the techniques to a level beyond the most basic, in which images of people (rather than a particular person) can be distinguished from images of other environmental features such as houses or plants. the same also holds for thermal imaging devices, which yield only very crude representations of heat patterns and cannot provide much identication information by themselves. today, it appears that the automated recognition of individuals will be a laborintensive activity for the foreseeable future.even the much simpler task of identifying the drivers of vehicles that have been photographed running a stoplight cannot currently be automated. in this case, all that is required is identifying the license number on the car, a much simpler task than recognizing a person from a photo of his or her face. but even this seemingly simpler process cannot be executed with the level of delity needed for law enforcement purposes, which requires human mediation in the recognition of which car was pictured.the ability of the police to reconstruct movements of a person of interest has been misconstrued by many as an indication that law enforcement agencies can follow the movements of anyone in an ongoing fashion. however, reconstructions (which often use as data positional information from cars, video images from various public and commercial locations, and the like) are timeconsuming, humanintensive activities that can only be done by using the known location of the individual at a given time to reduce the search space of possible locations at a previous time. connecting the dots, in such cases, is possible only because a human being is looking for a known person at each of the locations where the known ﬁdotﬂ might be present, and when nding such a location is using that information to cut down on the next places to search. it is not an activity that can be fully automated, nor is it one that could be easily and routinely performed for broad segments of the population.even if we restrict the supposed data mining to the information in an individual™s digital shadow, there are problems inherent in data aggregation. the same information can be represented in very different ways in different databases. correlating information between those databases is a nontrivial problem, generally requiring signicant design and programming to ensure that the information can be interpreted in a consistent way across the databases.somewhat ironically, the very fact that the law enforcement agencies were early adopters of information technology now works against their ability to use the cutting edge of that technology. as early adopters, those engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 275agencies made signicant investments in technology that is now obsolete. further, those early technologies were developed in a fashion that makes them far more difcult to knit together into integrated systems, instead leaving ﬁsilosﬂ of information in the various systems that cannot be correlated in the ways that re˚ect the worst privacy invasion nightmares. for example, the federal bureau of investigation has struggled for many years to integrate and upgrade its systems,15 with the end result at this writing that the fbi is still using an antiquated system with capabilities far below those envisioned by people concerned about the use of the system to violate personal privacy.law enforcement authorities can also obtain signicant amounts of personal information from data aggregation companies, as described in section 6.5. as noted in that section, there is particular concern over the use by law enforcement agencies of the aggregated information assembled by these companies. the laws and regulations that govern the gathering of information by the law enforcement establishment do not necessarily apply (or do not apply with clarity) to these data aggregators, and there is some concern that by contracting with these companies law enforcement will be able to avoid the restraints that have been placed on it to ensure the privacy of the individual citizen.9.1.6 privacy concerns and law enforcementany modern society requires an effective and rational law enforcement system. gathering, storing, and analyzing extensive information are vital to the law enforcement process, even though some information will also be gathered about persons who are manifestly beyond suspicion.privacy concerns arise most clearly when law enforcement agencies gather information about those who have broken no law and are not suspects, or when such information is used for purposes other than the discovery or prosecution of criminals, or when the very process of gathering the information or the knowledge that such information is being gathered changes the behavior of those who are clearly innocent and above reproach.one of the basic safeguards against potential abuse by law enforcement agencies of information gathering is the longstanding constitutional 15 see, for example, national research council, a review of the fbi™s trilogy information technology modernization, james mcgroddy and herbert s. lin, eds., the national academies press, washington, d.c., 2004; and dan eggen and griff witte, ﬁthe fbi™s upgrade that wasn™t: $170 million bought an unusable computer system,ﬂ washington post, august 18, 2006, available at http://www.washingtonpost.com/wpdyn/content/article/ 2006/08/17/ar2006081701485pf.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.276 engaging privacy and information technology in a digital agebarrier to the use in court of evidence that has been obtained unlawfullyšfor example, through a warrantless search or other means that violate a suspect™s or defendant™s rights. while prosecutors are sometimesšor often, depending on the authorities queried on the matteršable to introduce evidence that came to light as a consequence of illegality in law enforcement, the barrier against ofcial exploitation of a suspect™s privacy is an important protection against excesses and abuses in information gathering. (the primary loophole in the exclusionary rule is that if law enforcement authorities are not themselves guilty of unlawful warrantless searches, it does not matter very much how evidence was brought to the attention of those authorities.)moreover, prosecutors are usually obligated to reveal the content and sources of evidence they wish to use at trial against a defendant, thus adding further to the safeguards and protections. in a manner consistent with the principles of fair information practices (chapter 1), courts generally insist that the accused should have access to relevant information that has been gathered about him or her, and the ability to challenge and correct that information should it be introduced in court.one extreme in the spectrum of views is that the collection of information by various branches of government about those governed is part of the price that must be paid for the continued security of the whole. in this view, the ability of government to collect data should not be limited, as the individual cannot be harmed by the information gathered unless the individual was in fact doing something wrong. such a view holds that these government agencies are well intentioned and therefore will not use the information gathered for illicit or mischievous purposes. the laws that exist ensure that abuses cannot be used against the citizen even if they do occur.this view adopts a narrow construction of what ﬁharmﬂ might be possible. that is, it requires a belief that a lawabiding individual is not ﬁharmedﬂ if personal information (e.g., buying habits, reading history, mental health status) is viewed by people who have no reason to have access to that information but who as a consequence of their jobs do have such access. in this view, a largebreasted woman whose clothed body is viewed closeup through the zoom telephoto lens on a remotely controlled surveillance camera by security guards during daylight hours suffers no harm.16 nor is a farmer harmed who misses a ˚ight because his 16 jeffrey rosen, ﬁbeing watched: a cautionary tale for a new age of surveillance,ﬂ new york times magazine, october 7, 2001. rosen noted that a group of ﬁbored, unsupervised men in front of live video screensﬂ with the ability to ﬁzoom in on whatever happens to catch their eyesﬂ tends to spend ﬁa fair amount of time leering at women.ﬂ he reported on one control room in which there were closeup shots of women with large breasts taped onto the walls.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 277or her name is put onto a donot˚y list because of recent large purchases of ammonium nitrate and fuel oil and a truck rental.there is a different view that arises from the sheer imbalance between the power of the state and that of the individual. this imbalance makes some citizens understandably anxious about the informationgathering abilities of the state. consequently, the disparity in resources that can be brought to bear by the state versus those that are available to most individuals also justies the imposition of certain limits on government™s information gatheringševen if such limits complicate or impede the task of law enforcement agencies.9.2 information technology, privacy, and national securitynowhere is the disparity of power and resources greater than that between the individual citizen and the federal government. at the same time, it is primarily the federal government that needs to gather information not only for law enforcement purposes but also to ensure the national security of the country. such datagathering activity differs in several respects from similar activities performed for law enforcement, notably in the procedures that must be followed, the oversight that constrains the intelligence agencies, and the ability of those about whom data is gathered to view and amend or correct that data.9.2.1 backgroundthe general category of national security comprises many functions of government, including those performed by the armed forces and federal law enforcement agencies. however, the term ﬁnational securityﬂ has recently become associated with the agencies of the federal government that are most directly involved in the gathering and analysis of intelligence information relating to threats against the united states, and those agencies of other governments that play a similar role for other countries. the tension between individual privacy and national security arises, for the most part, with regard to these intelligencegathering and analysis functions for national security.while the informationgathering role of the government in law enforcement serves mainly to aid detection and conviction of a suspect after a law has been violated, the role of government agencies charged with protecting national security often entails gathering information about possible future threats, and identifying possible ways to change or control that future. indeed, the role of an intelligence agency can be characterized as ensuring that its government knows all the secrets of its engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.278 engaging privacy and information technology in a digital ageadversaries or potential adversaries while at the same time ensuring that these adversaries know none of the government secrets. given this role, the technologies developed for intelligence may dene both the boundary for technology that can be privacy invasive, and the boundary for those technologies that help to ensure privacy. furthermore, in order to maintain advantages over foreign adversaries, the nature and the extent of intelligencerelated technological capabilities are often kept secret.because the mission of national security agencies is quite openended, limiting the scope of inquiry by such agencies becomes far more difcult and complex than imposing comparable limits on law enforcement. while law enforcement data gathering may be reviewed by other agencies and conned to active investigations, intelligence agencies are not required to demonstrate in advance the potential relevance of the information they gather. instead, such agencies often try to compile as much information as possible that might be potentially relevant to their tasks, and then analyze all of that data in an attempt to dene and describe potential adversaries. as information technology for counterterrorism put it:17because terrorists are not clearly identied with any entity (such as a nationstate) whose behavior can be easily studied or analyzed, their individual proles of behavior and communication are necessarily the focus of an intelligence investigation. most importantly, it is often not known in advance what specic information must be sought in order to recognize a suspicious pattern, especially as circumstances change. from the perspective of intelligence analysis, the collection rule must be ﬁcollect everything in case something might be useful.ﬂ such a stance generates obvious con˚icts with the strongest proprivacy rule ﬁdon™t collect anything unless you know you need it.ﬂthe notion of intelligence agencies being compelled to respect the privacy of the individual seems almost as quaint as henry stimson™s justication for shutting down the original cryptography section in the state department, stating in 1930 that ﬁgentlemen do not read other gentlemen™s mail.ﬂ since the time of world war ii, it has been the role of the intelligence agencies to read nearly everyone™s mail (or cables, or radio transmissions) to protect national security. the role of the intelligence agency is, in effect, to violate the privacy of those individuals and countries that might jeopardize national security.the second aspect of intelligence gathering for national security that makes this activity different from the gathering of information for law enforcement is the inherent need for secrecy in the very process itself. 17 national research council, information technology for counterterrorism: immediate actions and future possibilities, john l. hennessy, david a. patterson, and herbert s. lin, eds., the national academies press, washington, d.c., 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 279any information gathered by law enforcement agencies and subsequently used as evidence in the prosecution of an individual eventually becomes public and is open to challenge by the person being prosecuted. much of the information gathered by intelligence agencies for national security, however, must be kept secret. secrecy is required not only to keep an adversary from learning what is known about him, but also to ensure that the sources of information cannot be identied and compromised. the need for secrecy in this realm means that those who might be the subjects of interest for information gathering cannot know what information is gathered about them (or even if information is being gathered about them), much less check or challenge the accuracy of that information.the balance between individual privacy and national security is often seen as a balance between the types of information necessary to ensure national security, and the constraints imposed on those that gather the information. there is a common belief that the more the ability to gather information is constrained, the more likely it is that information of potential relevance to national security will be lost or overlooked.18 this tension, like its counterpart in the realm of law enforcement, is as old as the republic. what has changed is the technology of information gathering and analysis that can be used by the intelligence agencies.along with the changes in the technology, there has been a major change in the nature of the national security endeavor itself. the traditional intelligence endeavor, shaped by world war ii and the ensuing cold war, was focused on the preservation of the state from the threats posed by other states. these threats were long term, comparatively overt, and carried out on a stage on which all of the players were known to each other. the decrease in this sort of threat, occasioned largely by the ending of the cold war, has been replaced by a far more amorphous threat coming from nongovernmental bodies using nontraditional tactics. while perhaps best illustrated by the terrorist attacks on the world trade center and the pentagon on september 11, 2001, these groups perform acts of terrorism meant to destabilize governments by undermining the sense of security of the citizens of those governments. while u.s. citizens tend to focus on the threat to the united states and its allies, the threat from terrorists is not conned to any particular country or region. these combatants, who are hard to identify and willing to sacrice their own lives in the course of their attacks, now form a threat whose proactive neutralization is one of the main objects of national security.18 this view is not necessarily true. indeed, there is an opposing view that the more information gathered, the more likely it is that relevant information will be lost in the ˚ood of irrelevant data. in this view, quantity of information is not the only thing that should be sought; the quality and the relevance of the information are of greater importance.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.280 engaging privacy and information technology in a digital age9.2.2 national security and technology developmentwhile law enforcement agencies were among the early adopters of information technology, the agencies involved in intelligence gathering and analysis have often been the generators of technological innovation. since the efforts during world war ii to break the codes of other countries and to ensure that u.s. codes could not be broken, the intelligence community has directly developed, collaborated in the development, or funded the development of much of the current information infrastructure.many of the technologies that are used to gather, sift, and collate data were developed initially by the intelligence agencies either for the purposes of cryptography or to allow them to sift through the vast amounts of information that they gather to nd patterns for interpretation. at the same time, the cryptographic techniques that can be used both to ensure the privacy of stored information and to secure channels of communication trace their roots back to the same intelligence services, in their role as securers of the nation™s secrets. moreover, many of the concepts of computer security, used to ensure that only those with the appropriate rights can access sensitive information, have been leveraged from developments that trace back to the intelligence or defense communities.there is considerable uncertainty outside the intelligence community about the true nature and extent of national capabilities in these areas. many of those concerned about protecting privacy rights assume that the technology being used for intelligence purposes has capabilities far above technology available to the public. rightly or wrongly, it is often assumed that the intelligence community can defeat any privacyenhancing technology that is available to the general public, and has a capability of gathering and collating information that is far beyond any that is commercially available. given the secret nature of the national security endeavor, this assumption is understandably neither conrmed nor denied by either those intelligencegathering groups themselves or the governmental bodies that are supposed to oversee those groups.9.2.3 legal limitations on national security data gatheringanalysis of the limitations on national securitybased data gathering is complicated by the distinction between u.s. citizens and noncitizens, especially lawfully resident aliens. some constitutional rights extend to all persons; thus, the supreme court ruled as early as 1896 (and has repeatedly reafrmed as recently as 1982) that aliens could invoke the equal protection clause against invidious discrimination as readily as could u.s. citizens.19 but some protections (such as privileges and immunities) 19 the 1982 reafrmation is found in plyler v. doe, 457 u.s. 202, 102 s. ct. 2382 (1982), which also provides a plethora of historical court citations supporting the notion that even aliens engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 281apply only to citizens; indeed the supreme court has held that states may, if they wish, make u.s. citizenship an essential qualication for certain occupations (notably teaching in the public schools20 and being police ofcers21) if the qualication has a rational basis.the problem arises with respect to rights and liberties that are neither expressly conned to citizens nor available alike to citizens and aliens. in fact, most of the safeguards of the bill of rights fall into this third category, leading to intense debate over such issues as whether a lawfully resident alien may be deported for advocacy or political activity for which a citizen could not be punished under the first amendment. limited precedent may be cited on both sides of that debate, and the issue is one that the supreme court seems consciously to have avoided.when it comes to information gathering, even citizens have few rights to object to the placement of their sensitive personal information into a government database, regardless of whether the information is obtained legally or illegally.22 however, even in cases where such an objection is raised, it is not clear that the citizens have any recourse on the gathering of that information. if that is true for citizens, it is at least equally true for noncitizens, even those who have long and lawfully resided in the united states. moreover, a noncitizen who is not physically present in this countryševen though formerly a lawful residentšhas severely attenuated legal claims (as, for example, would have been the fate of the guantanamo detainees absent the agreement between the united states and cuba that gave the naval base quasidomestic status). thus, the grounds on which a noncitizen might object to information gathering and data storage in the interests of national security seem remote. the issues of focus for this report are those that might be raised by u.s. citizens. and as a practical matter, the committee is concerned only about information gathering within the united states (i.e., information gathering on subjects located on u.s. soil), though noting that citizens do retain certain rights even when they are out of country.the distinction between the rights of citizens and those of others matches the perception (and, perhaps, the historical reality) that the gravest national security threats originate beyond our borders. until relawhose presence in this country is unlawful are ﬁpersonsﬂ guaranteed due process of law by the fifth and fourteenth amendments.20 ambach v. norwick, 441 u.s. 68, 99 s. ct. 1589, 60 l. ed. 2d 49 (1979).21 foley v. connelie, 435 u.s. 291, 98 s. ct. 1067, 55 l. ed. 2d 287 (1978).22 in bartnicki et al. v. vopper, 121 s. ct. 1753, 149 l. ed. 2d 787, 29 media l. rep. 1737 (2001), the supreme court held that a radio station could not be held liable for broadcasting the contents of an audio recording that had been obtained in an illegal wiretap. since it would be hard to argue that any information broadcast on the radio waves to the public is somehow private, it would seem that the contents of the audio recording could in fact be placed into a government databaseševen if the contents had been obtained illegally. how far the precedent of bartnicki et al. v. vopper extends remains to be seen.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.282 engaging privacy and information technology in a digital agetively recently, neither the military nor the u.s. foreign intelligence agencies were allowed to gather information about purely domestic activity, even if that activity seemed to pose a national security threat. under this premise, if actions of u.s. citizens and resident aliens within the united states evoke suspicion on security grounds, any investigation would be conducted by the fbi and other domestic law enforcement agencies. that precept was recently reinforced when the department of the army formally apologized for having interrogated participants at a university of texas conference on women and islam, making clear in the apology that any such inquiry should have been handled by the fbi and not by the military (or for that matter the central intelligence agency). this division of labor partly re˚ects the difculty of distinguishing legitimate and protected dissent from genuine security threats, and an abiding fear that government power of inquiry could be abused if the more secretive u.s. foreign intelligence agencies possessed such domestic authority.in this regard, as with the limits placed on the law enforcement agencies, the united states is somewhat different from other countries. outside the united states, it is common for a country to have a domestic intelligence service whose job it is to accumulate information on citizens and those within the borders of the country for the purposes of national security. there have been times that some parts of the u.s. federal government have performed this function within the united states, but such activities have been rare and either were discontinued after a period of national emergency or became the cause of major scandal when they were generally discovered. further, when such activities were undertaken, they were often undertaken as an adjunct activity for a law enforcement agency (such as the fbi) rather than as part of the activity of an organization whose primary charter was the gathering of domestic intelligence for the purpose of national security.an important part of the current legal framework for national security intelligence gathering in the united states was established by the foreign intelligence surveillance act (fisa). as noted in section 4.3.1, fisa was passed in order to regulate executive branch authority to conduct wiretaps in intelligence matters and thus could be fairly regarded as a privacy protection measure. fisa, and a series of executive orders based on it, cover the surveillance (both electronic and nonelectronic) of ﬁa foreign power or an agent of a foreign power,ﬂ including u.s. persons who fall under the denition of an agent of a foreign power. fisa establishes a special court of 11 federal district court judges who review requests for warrants. these warrants can cover electronic surveillance (including wiretapping and electronic eavesdropping) and covert physical searches.to obtain a warrant, law enforcement authorities must demonstrate to the fisa court that there is probable cause to believe that the target of the warrant is an agent of a foreign power. unlike standard search warrants engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 283obtained for criminal cases, applications for fisa warrants do not require a statement of what information is being sought through the warrant, nor is there a requirement that the party granted the warrant return to the court a listing of what information was obtained through the warrant. while fisa warrants cannot be granted for the purpose of criminal prosecution, information obtained secondarily via a fisa warrant has been allowed in criminal trials.since the intelligence process depends on gathering information, one premise of the current system is that the entities whose information is being obtained do not know the extent of what is known about them or the sources of that information. thus the fisa law forbids any person upon whom a fisa court subpoena is served from disclosing that fact to anyone other than a colleague or subordinate whose involvement is vital to obtain the subpoenaed information.23 moreover, the fisa procedure for information gathering differs sharply from what is allowed under standard law enforcement search and seizure rules. while judicial approval of the fisa court is required for national security searches, the proceedings of that court (and even the identity of its members) are secret. the substantive standard required for issuance of such a secret warrant is also said to be far lower than for a regular warrant, requiring no specic evidence of actual complicity in or even specic contribution to any terrorist activity.23 nondisclosure orders are not unique to fisa. indeed, ve other federal statutes authorize the government to issue a nondisclosure order pursuant to a ﬁnational security letterﬂ that requests communications providers, nancial institutions, and credit bureaus to provide to appropriate intelligence agencies certain types of customer business records, including subscriber and transactional information related to internet and telephone usage, credit reports, and nancial records. these laws include 12 u.s.c. 3414 (access to nancial records); 15 u.s.c. 1681u (access to credit reports for the fbi), 15 u.s.c. 1681v (access to credit reports for u.s. government intelligence agencies), 18 u.s.c. 2709 (access to stored wire and electronic communications and transactional records for the fbi), and 50 u.s.c. 436 (access to nancial information for purposes of law enforcement, counterintelligence, or security determination). section 115 of the usa patriot improvement and reauthorization act of 2005 created a mechanism for judicial review of a national security letter as well as any associated nondisclosure order. see brian yeh and charles doyle, ﬁusa patriot improvement and reauthorization act of 2005: a legal analysis,ﬂ order code rl 33332, congressional research service, washington, d.c., march 24, 2006. according to the associated press, the fbi sought information on 3,501 u.s. citizens and legal residents in 2005 from their banks and their credit card, telephone, and internet companies using the national security letter mechanism. it also received fisa court approval under section 215 for the examination of business records.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.284 engaging privacy and information technology in a digital age9.2.4 recent trendstraditionally, as noted in the previous section, the separation between intelligence gathering for national security purposes and law enforcement surveillance has served to protect the privacy at least of u.s. citizens and to some degree that of permanent resident aliens while they are in the united states. gathering information on such persons had been generally forbidden except in aid of law enforcement or if a person was determined to be an agent of a foreign power. this meant that the gathering of information could happen only in an attempt to investigate the breaking of a particular law, and the obtaining of information was subject to the kinds of restrictions and thirdparty judicial reviews that have characterized law enforcement information gathering.the events of september 11, 2001, and the subsequent efforts to identify, nd, and eliminate the threat from both the terrorists directly responsible and others who support groups that have been identied with similar tactics have caused many to call into question the traditional separation of law enforcement and national security intelligence gathering. national security was traditionally seen as served by gathering information about threats from other countries; suddenly the highest level of threat seemed to be from nongovernmental entities. national security intelligence was gathered from outside the borders of the united states; suddenly the threat seemed to be within those borders as well as without. the domestic collection of information was bound to the prosecution of crimes; suddenly there was a perceived need for the domestic collection of information for intelligence purposes. the traditional notion of limiting intelligence gathering to outside the borders of the united states and to other than u.s. persons appeared to be dangerously out of date.one indication of this trend is the adoption, in october 2001, of the uniting and strengthening america by providing appropriate tools required to intercept and obstruct terrorism (usa patriot) act. this act is seen by its supporters as an overdue response to restrictions on intelligence gathering that had impeded cooperation and collaboration among agencies, and that needed to be relaxed or removed if the nation was to protect itself from the new threats to national security, identied not as other governments but as smaller, nongovernmental organizations willing to launch suicide attacks. opponents of the act, however, charge that many of its provisions seriously threaten or erode basic rights and liberties enshrined in the constitution, as well as jeopardizing privacy to an unprecedented degree.one of the difculties of judging between these two viewpoints is the complexity of the act itself, which is a collection of amendments and additions to other laws rather than a standalone act. in some cases, the act denes limitations on technologies that had not been addressed in law engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 285before; in other cases the act expands or claries the scope of previously existing law.in general, the usa patriot act eased a number of restrictions on foreign intelligence gathering within the united states and granted the u.s. intelligence community somewhat greater access to information unearthed during a criminal investigation.24 for example, the usa patriot act authorizes the release to federal intelligence and immigration ofcials of information obtained during the course of a grand jury investigation, whereas such information was previously protected under very strict disclosure rules. the act codied the use of trapandtrace devices and pen registers, already established under longstanding fisa court practices, for treating electronic communications such as email in a similar way to telephone communications. section 215 of the usa patriot act also allowed the fisa court to issue orders granting access to any records and tangible items from any entity (e.g., bookstores, libraries, department stores, schools), not just common carriers, public accommodation facilities, physical storage facilities, and car rental facilities, as under previous law; this provision substantially enlarged the range of items subject to fisa jurisdiction. finally, the act also allowed ﬁrovingﬂ surveillance of a subject, where previously fisa had required the identication of a particular scope (e.g., a specic telephone number or physical location) where the surveillance would occur.to guard against ofcial abuse, the usa patriot act established a claim against the united states for certain communications privacy violations by government personnel and expanded the prohibition against fisa orders based solely on the exercise of an individual™s first amendment rights. in addition, the usa patriot improvement and reauthorization act of 2005 provided greater congressional oversight, enhanced procedural protections, more elaborate application requirements, and a judicial review process for the exercise of section 215 authorities. finally, the usa patriot act additional reauthorizing amendments act of 2006 establishes a judicial review procedure for section 215 nondisclosure orders that allows recipients of a section 215 production order to challenge the nondisclosure requirement 1 year after the issuance of the production order. in response to such a challenge, the fisa court judge has the discretion to modify or set aside a nondisclosure order, unless the attorney general, deputy attorney general, an assistant attorney general, or the director of the fbi certies that disclosure may endanger the national 24 this discussion of the usa patriot act™s impact on fisa is based on charles doyle, ﬁthe usa patriot act: a sketch,ﬂ order code rs 21203, congressional research service, washington, d.c., april 18, 2002.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.286 engaging privacy and information technology in a digital agesecurity of the united states or interfere with diplomatic relations (unless the judge nds that the certication was made in bad faith).25from a fisa perspective, more important than any of the particular sections of the usa patriot act is the fact that the law encourages the sharing of information from law enforcement with intelligence agencies. the success of the september 11, 2001, attacks has been seen by many as a result of the distinction drawn between law enforcement and intelligence gathering; in this view if all of the relevant information held by both the law enforcement agencies (such as the fbi) and the intelligence community had been put together and seen correctly, the attacks could have been predicted and stopped. not sharing such information was faulted as a re˚ection of the distinction between law enforcement and intelligence gathering for national security, a distinction that had historically been drawn in part to ensure the privacy of u.s. citizens.it is in this context that the sharing with law enforcement ofcials of information derived from intelligence operations has proven controversial. under the usa patriot act, fisa court orders need no longer serve the primary purpose of gathering foreign intelligence information, but may now be authorized by the fisa court under a less stringent standard of serving a ﬁsignicant purposeﬂ of obtaining such information. generally, the concern about such sharing has been that the privacy (and other) protections embedded in the processes of domestic law enforcement may be circumvented or mooted by the use of intelligence processes that are less subject to such protections.for example, an airline (jetblue) acknowledged a september 2003 incident in which it violated its stated privacy policy by sharing personal information on 1.1 million customers with a pentagon contractor investigating issues in connection with the capps ii airline security program.26 a few months later, northwest airlines acknowledged that it had also provided months of reservation data to nasa™s ames research center, after asserting in september 2003 that it ﬁdid not provide that type of information to anyone.ﬂ in its acknowledgment, northwest airlines said it participated in the nasa program to assist the government™s search for technology to improve aviation security, and denied that its actions violated its privacy policy, which it said was aimed at preventing the 25 see yeh and doyle, ﬁusa patriot improvement and reauthorization act of 2005,ﬂ 2006.26 michelle maynard, ﬁjetblue moves to repair its image after sharing files,ﬂ new york times, september 23, 2003, available at http://www.nytimes.com/2003/09/23/business/23air.html?ex=1379649600&en=1e13d100496b900d&ei=5007&partner=userland.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 287sale of passenger information to third parties for marketing purposes.27 another example is the recently revealed (late 2005) wiretaps of communications involving certain u.s. persons in pursuit of intelligence related to alqaeda without the approval of the fisa court (box 9.3). as this writing, the program is still controversial amidst many calls for further investigation.the quest for more and better technologies for analyzing information for national security purposes also raises privacy concerns. in particular, one common view of the failure to foresee and stop the events of september 11, 2001, is that the failure was not one of a lack of information, but rather a lack of putting together the information that was already available. in this view, better analysis tools are needed more than (or in addition to) the ability to gather more information.one attempt at creating such tools taken by the dod™s defense advanced research projects agency (darpa) was the total (later terrorist) information awareness (tia) program (box 9.4). the exact goals of this program are difcult to determine, as they shifted signicantly over the time the program was active. however, the goals were always centered on developing and providing technology that would allow the detection and tracking of terrorist or suspected terrorist activities by aggregating data that are collected by both government and nongovernment agencies and then mining that data to nd patterns of behavior that are highly correlated with future terrorist actions.a full analysis of the privacy implications of the tia program has appeared elsewhere and is not repeated here.28 the point that is important to make is that one of the legacies of the september 11 attacks is the willingness of the intelligence agencies charged with the national defense to gather information about u.s. persons in their attempt to track and nd terrorists. in addition, the tia program shows the willingness of these agencies to use or invent technologies that will help them in that undertaking, even when those technologies may be privacy invasive.27 sara kehaulani goo, ﬁcondential passenger data used for air security project,ﬂ washington post, january 17, 2004, available at http://www.washingtonpost.com/ac2/wpdyn/a260372004jan17.28 technology and privacy committee (tapac), safeguarding privacy in the fight against terrorism, department of defense, washington, d.c., march 1, 2004. this report (1) concluded that tia was a ˚awed effort to achieve worthwhile ends; (2) argued that although data mining is a vital tool in the ght against terrorism, it could present signicant privacy issues if used in connection with personal data concerning u.s. persons; (3) stressed the importance of government actions to protect privacy in developing and using datamining tools; and (4) noted that existing legal requirements applicable to the government™s datamining programs were numerous, disjointed, and often outdated, with the possible effect of compromising privacy protection, public condence, and the nation™s ability to craft effective and lawful responses to terrorism. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.288 engaging privacy and information technology in a digital agebox 9.3 national security agency domestic surveillance and data mining of calling records in 2002, the president authorized the national security agency (nsa) to begin conducting surveillance of electronic communications in the united states without a courtapproved warrant. since the public became aware of this program late in 2005,1 many questions have been raised about both its legality and its constitutionality. according to what has been revealed publicly in news reports, the classied nsa program has focused on intercepting, without a warrant, phone calls and emails of u.s. persons that are believed to be linked, directly or indirectly, to the alqaeda terrorist organization. it is further said to be limited to only domestictointernational communication; warrants are obtained when both parties in the communication are within u.s. borders. although ofcial sources have not provided an authoritative description of the activities and scope of this program, the administration has defended itšand its ability to monitor possible terrorist group activityšas both legal and within the authority granted to the president under the authorization for use of military force (aumf) against alqaeda,2 passed by congress on september 14, 2001. the aumf authorized the president to ﬁuse all necessary and appropriate force against those nations, organizations, or persons he determines planned, authorized, committed, or aided the terrorist attacks that occurred on september 11, 2001, or harbored such organizations or persons, in order to prevent any future acts of international terrorism against the united states by such nations, organizations or persons.ﬂ additionally, the administration contends that the president™s inherent constitutional authority as commander in chief authorizes the president to take whatever action is necessary to combat terrorism.3 critics, however, debate the legality and constitutionality of the program that was authorized outside the foreign intelligence surveillance act (fisa) of 1978, which provides explicit legal guidance on how domestic surveillance can be conducted.4 recently amended in 2001 by the usa patriot act, fisa was passed to balance the needfor foreign intelligence surveillance for national security purposes with an individual™s constitutional rights. it established procedures for the oversight of domestic surveillance activities conducted by u.s. intelligence agencies, including the creation of the foreign intelligence surveillance act court, an independent body designed to grant surveillance authority rather than its being determined by the intelligence agency itself. additionally, the legislation addressed circumstances in which surveillance could be conducted without a warrant, including after a declaration of war for a period of 15 days and in times of emergency when warrants could be obtained ex post facto within 72 hours. critics argue that changes to domestic surveillance procedures should be authorized by congress and should take place through amendments to fisa. furthermore, critics underscore that fisa legislation was drafted on the basis that the president™s constitutional power is ﬁinherentﬂ but should not be exclusive, and that congress, rather than the executive branch, has the power to regulate the exercise of that authority. a number of analysts have also raised a variety of concerns about the implications of this program and the legal basis used to authorize it. among the concerns is the reliance on aumf as a legal basis for electronic domestic surveillance activities, which could also be used to authorize warrantless physical search and seizures. related questions have been raised in terms of the admissibility in a court of law of information obtained without a warrant.5 the inclusion in the program of phone and internet trafc from u.s. telecommunications companies has also raised concerns that the scope of the program was not limited to domestictointernational communication as initially described by the administration.6 broader constitutional questions also have been raised by the authorization of this program that has taken place outside a system of checks and balances designed to protect individuals™ rights from possible abuses by government authorities.7 similar concerns have arisen as the result of an nsa program to use the calling records of the customers of at&t, verizon, and bellsouth. reported in usa today on may 11, 2006,8 the program supposedly uses these data to analyze calling patterns in an effort to detect terrorist activity. calling records do not involve the content of the calls themselves, but do include, at a minimum, the originating number, the called number, the duration of the call, and the time of day of the call. such records are usually protected less stringently than the content of phone calls, but their disclosure to government authorities has historically entailed an explicit legal authorization, albeit with lower standards of cause, to produce such records. as in the case of content surveillance, controversy arises because the carriers in question may have provided the records without such authorization in hand.1james risen and eric lichtblau, ﬁbush lets u.s. spy on callers without courts,ﬂ new york times, december 16, 2005, available at http://www.nytimes.com/2005/12/16/politics/16program.html?ex=1292389200&en=e32072d786623ac1&ei=5090&partner=rssuserland&emc=rss. additionally, the new york times did not release the story for over a year at the request of the administration for national security concerns.2 p.l. 10740, 115 stat. 224 (2001); for the legislative history, see congressional research service, ﬁauthorization for use of military force in response to the 9/11 attacks (p.l. 10740): legislative history,ﬂ january 4, 2006, available at http://www.fas.org/sgp/crs/natsec/rs22357.pdf.3 the department of justice response to the house and senate intelligence committees defending the program is available at http://www.fas.org/irp/agency/doj/sa/doj122205.pdf. see also a white paper released by the department of justice, ﬁlegal authorities supporting the activities of the national security agency described by the president,ﬂ january 19, 2006, available at http://les.ndlaw.com/news.ndlaw.com/hdocs/docs/nsa/dojnsa11906wp.pdf.4 among the sources of criticism of the program are american bar association, ﬁtask force on domestic surveillance in the fight against terrorism,ﬂ february 15, 2006, available at http://www.abanews.org/docs/domsurvrecommendationnal.pdf. also see ﬁa response to the department of justice on warrantless surveillance,ﬂ by a group of 14 constitutional scholars and former government ofcials, january 9, 2006, available at http://www.fas.org/irp/agency/doj/sa/dojresponse.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 289box 9.3 national security agency domestic surveillance and data mining of calling records in 2002, the president authorized the national security agency (nsa) to begin conducting surveillance of electronic communications in the united states without a courtapproved warrant. since the public became aware of this program late in 2005,1 many questions have been raised about both its legality and its constitutionality. according to what has been revealed publicly in news reports, the classied nsa program has focused on intercepting, without a warrant, phone calls and emails of u.s. persons that are believed to be linked, directly or indirectly, to the alqaeda terrorist organization. it is further said to be limited to only domestictointernational communication; warrants are obtained when both parties in the communication are within u.s. borders. although ofcial sources have not provided an authoritative description of the activities and scope of this program, the administration has defended itšand its ability to monitor possible terrorist group activityšas both legal and within the authority granted to the president under the authorization for use of military force (aumf) against alqaeda,2 passed by congress on september 14, 2001. the aumf authorized the president to ﬁuse all necessary and appropriate force against those nations, organizations, or persons he determines planned, authorized, committed, or aided the terrorist attacks that occurred on september 11, 2001, or harbored such organizations or persons, in order to prevent any future acts of international terrorism against the united states by such nations, organizations or persons.ﬂ additionally, the administration contends that the president™s inherent constitutional authority as commander in chief authorizes the president to take whatever action is necessary to combat terrorism.3 critics, however, debate the legality and constitutionality of the program that was authorized outside the foreign intelligence surveillance act (fisa) of 1978, which provides explicit legal guidance on how domestic surveillance can be conducted.4 recently amended in 2001 by the usa patriot act, fisa was passed to balance the needfor foreign intelligence surveillance for national security purposes with an individual™s constitutional rights. it established procedures for the oversight of domestic surveillance activities conducted by u.s. intelligence agencies, including the creation of the foreign intelligence surveillance act court, an independent body designed to grant surveillance authority rather than its being determined by the intelligence agency itself. additionally, the legislation addressed circumstances in which surveillance could be conducted without a warrant, including after a declaration of war for a period of 15 days and in times of emergency when warrants could be obtained ex post facto within 72 hours. critics argue that changes to domestic surveillance procedures should be authorized by congress and should take place through amendments to fisa. furthermore, critics underscore that fisa legislation was drafted on the basis that the president™s constitutional power is ﬁinherentﬂ but should not be exclusive, and that congress, rather than the executive branch, has the power to regulate the exercise of that authority. a number of analysts have also raised a variety of concerns about the implications of this program and the legal basis used to authorize it. among the concerns is the reliance on aumf as a legal basis for electronic domestic surveillance activities, which could also be used to authorize warrantless physical search and seizures. related questions have been raised in terms of the admissibility in a court of law of information obtained without a warrant.5 the inclusion in the program of phone and internet trafc from u.s. telecommunications companies has also raised concerns that the scope of the program was not limited to domestictointernational communication as initially described by the administration.6 broader constitutional questions also have been raised by the authorization of this program that has taken place outside a system of checks and balances designed to protect individuals™ rights from possible abuses by government authorities.7 similar concerns have arisen as the result of an nsa program to use the calling records of the customers of at&t, verizon, and bellsouth. reported in usa today on may 11, 2006,8 the program supposedly uses these data to analyze calling patterns in an effort to detect terrorist activity. calling records do not involve the content of the calls themselves, but do include, at a minimum, the originating number, the called number, the duration of the call, and the time of day of the call. such records are usually protected less stringently than the content of phone calls, but their disclosure to government authorities has historically entailed an explicit legal authorization, albeit with lower standards of cause, to produce such records. as in the case of content surveillance, controversy arises because the carriers in question may have provided the records without such authorization in hand.5 chitra ragavan, ﬁthe letter of the law,ﬂ u.s. news and world report, march 27, 2006, available at http://www.usnews.com/usnews/news/articles/060327/27fbi.htm.6 james risen and eric lichtblau, ﬁspy agency mined vast data trove,ﬂ new york times, december 24, 2005, available at http://www.nytimes.com/2005/12/24/politics/24spy.html?ex=1293080400&en=016edb46b79bde83&ei=5090.7 see american bar association, ﬁreport of the task force on domestic surveillance in the fight against terrorism,ﬂ february 15, 2006, available at http://www.abanet.org/op/greco/memos/abahouse3020206.pdf.8 leslie cauley, ﬁnsa has massive database of americans™ phone calls,ﬂ usa today, may 11, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.290 engaging privacy and information technology in a digital agebox 9.4 the total information awareness program the total information awareness (tia) program caused considerable worry among many americans across the political spectrum, much of it provoked by bad public relations and the political concerns raised over those in charge of the program. notably absent from the debate over the tia program was any discussion of exactly what technology was being sought by the program, and whether or not the technology being sought was actually possible. this was in part due to a constant changing of the goals articulated for the program; it was hard to determine exactly what the technology being developed was supposed to do. but even the various alternatives that were proposed at different times were not examined in the light of their technological possibilities or the repercussions of that technology if it were possible. this is especially odd given that the agency sponsoring the tia program, darpa, is a research agency charged with just this kind of technical evaluation. a number of the proposed components of the tia program were never the focus of controversy; these had to do with automated translation aids and tools for standardizing the format of information being gathered by intelligence agencies. more controversial were the proposed tools that would allow discovery of patterns of activity. these tools would mine a consolidated database built from the information gathered by governmental and nongovernmental entities, which would include data on commercial transactions. in one version of the tia statement of goals, the analysis tools would scan this database for events or sets of events of interest (such as the purchase of oneway rental trucks coupled with the purchase of large amounts of fertilizer) and identify persons who had participated in such transactions, allowing those persons to come to the attention of the national security agencies. the result would be an automated mechanism for ﬁconnecting the dots.ﬂ such a system would solve the problem of not seeing the patterns in the information that had been acquired, which some thought was the main failure that made the attacks of september 11, 2001, possible. such a system is not technically feasible, however. to aggregate the information from the various sources into a single database would require a solution to the problem of data integration (section 3.9). different databases store data in different forms, meaning that the information held in one database cannot be read or manipulated by programs that understand the second database. to allow a program to use both databases requires some form of data integration, which in turn requires converting one (or both) of the database formats into some common format that can be manipulated and understood by a single program. this problem has existed in industry for the past 40 years; all attempts to solve the problem even on a small scale have succeeded only for very simple aggregations and have proven to be exceptionally expensive. to hypothesize a single aggregation, whether virtual or physical, of all of the databases, both public and private, as is done in this version of the tia program, is to hypothesize a general solution to the stillunsolved data integration problem. even if the data integration problem could be solved, the solution sought by the tia program would require the ability to evaluate arbitrary sets of events in that database to nd patterns. however, the set of possible events grows at a pace that makes the general evaluation of all of those sets computationally infeasible. the number of sets of events that can be formed from a group of individual events is equal to 2 to the power of the number of events; that is, for 20 different events the number of distinct sets of those events is 220, or more than 1,000,000 different sets of events. if we were to look at each commercial transaction in the united states as a separate event, the set of possible sets made up of those events is far larger than the number of atoms in the universe. a second version of the tia goal avoided this problem of computational complexity by stating that the tools would allow analysts to identify a person of interest, and then use the tools to track all of the activities of that person that were traced in all of the databases that had been aggregated. this approach eliminated the problem of the prior goal by concentrating on a particular subject or set of subjects and picking out the events associated with that subject. by starting with a subject of interest, the events in the database could be examined individually to see if they involved that individual, thus keeping the complexity of the search proportional to the size of the database (rather than growing exponentially with the size of the database). this goal still assumed that the aggregation of databases into a single search set would be possible, but even if only a small number of databases were aggregated, this goal could provide a more complete picture of an individual than could be found in any of the single databases. the problem with this narrower goal is that, even if it can be achieved, it is unlikely that it will help disrupt terrorist attacks before they are carried out. the ability to nd out more information about known persons does not help in the identication of potential terrorists with no previous records of such involvement or other reason to fall under suspicionšand there is no shortage of such individuals in the world.while the usa patriot act, the warrantless national security agency surveillance of certain u.s. persons, and the total information awareness program are perhaps the most obvious examples of changes in law and attitude on the balance between privacy and national security after the events of september 11, they are hardly the only examples. the establishment of ﬁdo not boardﬂ watch lists by the department of homeland security, in which information from unknown sources can be used engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 291box 9.4 the total information awareness program the total information awareness (tia) program caused considerable worry among many americans across the political spectrum, much of it provoked by bad public relations and the political concerns raised over those in charge of the program. notably absent from the debate over the tia program was any discussion of exactly what technology was being sought by the program, and whether or not the technology being sought was actually possible. this was in part due to a constant changing of the goals articulated for the program; it was hard to determine exactly what the technology being developed was supposed to do. but even the various alternatives that were proposed at different times were not examined in the light of their technological possibilities or the repercussions of that technology if it were possible. this is especially odd given that the agency sponsoring the tia program, darpa, is a research agency charged with just this kind of technical evaluation. a number of the proposed components of the tia program were never the focus of controversy; these had to do with automated translation aids and tools for standardizing the format of information being gathered by intelligence agencies. more controversial were the proposed tools that would allow discovery of patterns of activity. these tools would mine a consolidated database built from the information gathered by governmental and nongovernmental entities, which would include data on commercial transactions. in one version of the tia statement of goals, the analysis tools would scan this database for events or sets of events of interest (such as the purchase of oneway rental trucks coupled with the purchase of large amounts of fertilizer) and identify persons who had participated in such transactions, allowing those persons to come to the attention of the national security agencies. the result would be an automated mechanism for ﬁconnecting the dots.ﬂ such a system would solve the problem of not seeing the patterns in the information that had been acquired, which some thought was the main failure that made the attacks of september 11, 2001, possible. such a system is not technically feasible, however. to aggregate the information from the various sources into a single database would require a solution to the problem of data integration (section 3.9). different databases store data in different forms, meaning that the information held in one database cannot be read or manipulated by programs that understand the second database. to allow a program to use both databases requires some form of data integration, which in turn requires converting one (or both) of the database formats into some common format that can be manipulated and understood by a single program. this problem has existed in industry for the past 40 years; all attempts to solve the problem even on a small scale have succeeded only for very simple aggregations and have proven to be exceptionally expensive. to hypothesize a single aggregation, whether virtual or physical, of all of the databases, both public and private, as is done in this version of the tia program, is to hypothesize a general solution to the stillunsolved data integration problem. even if the data integration problem could be solved, the solution sought by the tia program would require the ability to evaluate arbitrary sets of events in that database to nd patterns. however, the set of possible events grows at a pace that makes the general evaluation of all of those sets computationally infeasible. the number of sets of events that can be formed from a group of individual events is equal to 2 to the power of the number of events; that is, for 20 different events the number of distinct sets of those events is 220, or more than 1,000,000 different sets of events. if we were to look at each commercial transaction in the united states as a separate event, the set of possible sets made up of those events is far larger than the number of atoms in the universe. a second version of the tia goal avoided this problem of computational complexity by stating that the tools would allow analysts to identify a person of interest, and then use the tools to track all of the activities of that person that were traced in all of the databases that had been aggregated. this approach eliminated the problem of the prior goal by concentrating on a particular subject or set of subjects and picking out the events associated with that subject. by starting with a subject of interest, the events in the database could be examined individually to see if they involved that individual, thus keeping the complexity of the search proportional to the size of the database (rather than growing exponentially with the size of the database). this goal still assumed that the aggregation of databases into a single search set would be possible, but even if only a small number of databases were aggregated, this goal could provide a more complete picture of an individual than could be found in any of the single databases. the problem with this narrower goal is that, even if it can be achieved, it is unlikely that it will help disrupt terrorist attacks before they are carried out. the ability to nd out more information about known persons does not help in the identication of potential terrorists with no previous records of such involvement or other reason to fall under suspicionšand there is no shortage of such individuals in the world.to place even u.s. citizens on lists that make it difcult or impossible to board commercial airline ˚ights, has come to light because of recent cases of people being placed on such a list erroneously. one problem with such watch lists, as they now appear to be implemented, is that it is difcult to nd out if a particular person has been placed on such a list and, if placed on the list, to nd out the information that caused that placement. there is no formal mechanism for challenging either the placement on the list or engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.292 engaging privacy and information technology in a digital agethe information that was used to make the determination. even edward kennedy, senior senator from massachusetts, has had problems getting his name off the watch list.29even if corrective mechanisms were in place, lists such as these suffer from a cluster of problems having to do with establishing the identity of those who are being compared to the list. if a list is kept in terms of names, its usefulness is limited by the fact that a single name can be shared by many different people. a combination of name and address may be better, but falls prey to the ease with which people move from place to place, and the time lag between such a move and the time at which all relevant records have been updated to re˚ect the new address. indeed, such lists seem to presume, contrary to fact, that there is a way (or set of ways) to uniquely identify each person who might appear on such a list. there is no such mechanism available today, and establishing such a mechanism is far from simple.309.2.5 tensions between privacy and national securityin many ways, the tension between privacy and national security parallels the tension between privacy and law enforcement. both law enforcement and national security require government to amass large amounts of information about people, including much information that the subject or target might want to keep private and information that will ultimately not prove useful for any missionrelated function. both law enforcement and national security require that that information be analyzed to try to infer even more about a person. both are heavy users of technology, and both use technology to gather information, identify individuals, and analyze that information.national security differs from law enforcement, however, in two signicant ways. first, law enforcement authorities are usually (though not always) called in when a criminal act has been committed, and the criminal act itself serves to focus investigative resourcesšthat is, they tend to be reactive. national security authorities are most interested in preventing hostile acts from taking placešthey tend to be proactive. second, most of the information gathered by law enforcement and used to prosecute a person for the violation of a law will eventually be made public, along with the mechanisms used to gather that information. intelligence gathering 29 rachel l. swarns, ﬁsenator? terrorist? a watch list stops kennedy at airport,ﬂ new york times, august 20, 2004.30 see national research council, who goes there? authentication through the lens of privacy, stephen t. kent and lynette i. millett, eds., the national academies press, washington, d.c., 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 293for the purposes of national security, on the other hand, is an intrinsically nonpublic activity. the mechanisms used to gather information, along with the information itself, are not made public, even when the information is used in a way that has an impact on the life of the subject of that information.this greater need for secrecy makes it unlikely that citizens will be able to discover if the agencies charged with national security are violating their privacy. the mechanisms for gathering information are often unknown, so those wishing to ensure privacy may not know the techniques against which they must guard. the information gathered must remain secret, and so there is no easy way to know what information is gathered, if that information is accurate, whether it might be subject to different interpretations, or how to correct the information if it is inaccurate or incomplete. the only thing known with certainty is that there is an entity that is capable of gathering information about foreign governments, and it is reasonable to presume that such an entity can easily gather information about private citizens in the united states.because of the secret nature of the information gathered by national security agencies, it can be difcult to establish a trust relationship if one does not already exist between the citizens about whom the information is gathered and the agencies doing the gathering. there are few in the united states who would worry about the gathering of information even within the borders of the united states and about u.s. citizens if they could be assured that such information was only being used for genuine national security purposes, and that any information that had been gathered about them was accurate and appropriately interpreted and treated. how to obtain that assurance is a public policy issue of the utmost importance. this is why oversight is so important, all the more so in times of crisis. accountability need not mean indiscriminate transparency; rather, trusted agents such as members of congress or special commissions should be entrusted with offering, and hopefully can be trusted to offer, needed assurances.9.3 law enforcement, national security, and individual privacyeven before the formation of our nation, government was seen as posing the principal threats to individual privacy. many of the grievances against the english crown that were detailed in the declaration of independence re˚ected an erosion of the right to be left alone, and many provisions of the bill of rights sought to codify limitations on government power which the framers saw as vital to the new nation. while the constitution nowhere expressly recognizes a ﬁright to privacy,ﬂ several engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.294 engaging privacy and information technology in a digital ageprovisions (especially, but not only, the fourth amendment) unmistakably limit the power of government to invade the lives of citizens.when law enforcement and national security are concerned, the sources of concern about privacy rights are readily apparent. on the one hand, law enforcement must be able to gather information about individuals in order to identify and apprehend suspects and to enforce criminal law and regulatory standards. national security agencies gather and analyze information about individuals and organizations in order to protect and enhance national security. on the other hand, the very process of gathering and using such information may pose serious risks to individual privacy.a somewhat similar set of tensions apply to data that have already been collected for some purpose other than law enforcement or national security. as noted in earlier chapters, a wide variety of personal information on individuals is collected for a wide variety of purposes by both government agencies (e.g., the internal revenue service, the census bureau) and private sector organizations such as banks, schools, phone companies, and providers of medical care. in some instances (such as survey data collected by the census bureau), such information has been collected under a promise, legal or otherwise, that it would be used for a certain purpose and only for that purpose, and would otherwise be kept condential.31 if and when external circumstances change (e.g., the nation comes under attack), some would argue strongly that it is criminal to refrain from using all resources available to the government to pursue its law enforcement and national security responsibilities. others would argue just as strongly that the legal restrictions in effect at the time of data collection effectively render such data unavailable to the government, legally if not physically.according to scholars william seltzer and margo anderson,32 an example of such government use of privileged data occurred during world war ii, when the bureau of the census assisted u.s. law enforcement authorities in carrying out the presidentially ordered internment 31 one exception is that the usa patriot act of 2001 allows the attorney general to obtain a court order directing the department of education to provide to the department of justice data collected by the national center for education statistics (nces) if such data are relevant to an authorized investigation or prosecution of an offense concerning national or international terrorism. however, the law also requires the attorney general to protect the condentiality of the data, although the standards used for such protection are formulated by the attorney general ﬁin consultation withﬂ the department of education. prior to the passage of the usa patriot act, nces data were to be used only for statistical purposes.32 william seltzer and margo anderson, ﬁafter pearl harbor: the proper role of population data systems in time of war,ﬂ paper presented at the annual meeting of the population association of america, los angeles, california, march 2000, available at the american statistical association™s statisticians in history web site.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 295of japaneseamericans. in a meeting of the census advisory committee held in january 1942, j.c. capt, director of the census, was reported to say, ﬁwe™re by law required to keep condential information by [sic] individuals. but in the end, [i]f the defense authorities found 200 japs missing and they wanted the names of the japs in that area, i would give them further means of checking individuals.ﬂit is not known if the census bureau actually provided information on individual japaneseamericans, but seltzer and anderson cite documents indicating that the census bureau clearly did provide mesodata (i.e., census results tabulated for very small geographic units, some as small as a city block) that did facilitate the internment process. indeed, on the monday after the december 7 attack on pearl harbor (which occurred on a sunday), the census bureau initiated the production of reports on the distribution of japaneseamericans across the united states based on macrodata (data from the 1940 census aggregated in terms of large geographic units).seltzer and anderson note also that the census bureau has recognized possible threats to privacy arising from certain kinds of mesodata, and in response has progressively introduced stricter disclosure standards. indeed, the bureau has indicated that under the standards now in place the release of mesodata from the 1940 census on japaneseamericans would have been severely restricted.a number of points are worth noting about this example. first, whether or not the census bureau provided information on individuals, the use of census data violated the spirit of the condentiality law in the sense that respondents provided information under promises of condentiality33šinformation that was subsequently used against them. second, capt™s remarks suggest a willingness to exploit legal loopholes in order to cooperate with the internment order. third, even if the actual wording of the condentiality promise made a ﬁne printﬂ provision for ﬁother legally authorized uses,ﬂ it would still have left survey respondents with the impression that their responses were condential.33 for example, president herbert hoover™s proclamation in 1929 for the 15th census said that ﬁthe sole purpose of the census is to secure general statistical information regarding the population and resources of the country. . . . no person can be harmed in any way by providing the information required. the census has nothing to do with . . . the enforcement of any national, state, or local law or ordinance. there need be no fear that any disclosure will be made regarding any individual person or his affairs. . . .ﬂ in addition, the 1940 census enumeration form itself said that ﬁonly sworn census employees will see your statements. data collected will be used solely for preparing statistical information concerning the nation™s population, resources, and business activities. your census reports cannot be used for purposes of taxation, regulation, or investigationﬂ [capitalization in the original]. see thomas f. corcoran, ﬁon the condential status of census reports,ﬂ the american statistician 17(3):3340, 1963.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.296 engaging privacy and information technology in a digital ageissues related to privacy in a law enforcement or national security context are hard for citizens to assess. citizens are not told what information these agencies are capable of gathering or what they do gather, because that knowledge being made public can limit the very information that agencies will be able to gather. in addition, the stakes are higher because these agencies can use information they gathered to imprison citizens. citizens are asked to trust that abuses are not occurring and to trust in the oversight mechanisms that often require one part of the government to ensure that another is not generally overstepping appropriate bounds.similarly, law enforcement and national security agencies are put into a difcult position regarding the gathering and analysis of information. if these agencies fail to gather enough information to accomplish their missions, they are faulted for not using the latest techniques and technologies. however, if these agencies are perceived as gathering too much information about ordinary citizens, they are faulted for invasion of privacy.unfortunately, it is often impossible to determine, before the fact, who is going to be a law breaker or terrorist in the future. there is no way for law enforcement and national security agencies to determine about whom they should gather information without requiring that these agencies also know the future. the conundrum is further accentuated by a declaratory national policy that emphasizes prevention of terrorist attacks rather than prosecution or retaliation after they occur. that is, law enforcement activities must take placešsuccessfullyšin the absence of the primary event that usually focuses such activities. with few denitively related clues to guide an investigation, a much more uniform spread of attention must be cast over those who might have some contact or connection, however tenuous, to a possible terrorist event in the future.the best that can be expected is that these agencies put into place the appropriate safeguards, checks, and balances to minimize the possibility that they gather information in an inappropriate way about citizens. but the more such safeguards are in place, so the argument goes, the more likely it is that mistakes are made in the opposite direction, and that these agencies will miss some piece of information that is vital for the performance of their function.yet areas of overlap between privacy and law enforcement and national security also exist. for example, citizens who have faith in their government and who believe that it generally follows democratic rules (one re˚ection of which is respect for privacy) will be more likely to cooperate with law enforcement in providing information and other forms of support. in that sense, just as it is sometimes said that privacy is a good business practice, it might also be said that a law enforcement agency™s respect for a citizen™s privacy, rather than necessarily being in opposition to, can be supportive of law enforcement goals.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 297an important in˚uence on the process of balancing governmental and societal needs for safety and security and individual privacy is the fact that public safety isšalmost by denitionša collective benet, while government infringements of privacy in the name of public safety tend to affect individuals or relatively small or politically marginal groups of people, at least in the short term. under such circumstances, it is easier for public safety ofcials to dismiss or minimize privacy concerns that their actions might raise. as an illustration of the sentiment, harvard law school professor william stuntz has asserted that ﬁreasonable people can differ about the balance, but one could plausibly conclude that the efciency gains from proling outweigh the harm from the ethnic tax that postseptember 11 policing is imposing on young men of middle eastern origin.ﬂ34the ˚ip side of this sentiment, of course, is that community involvement and good will may well be an essential element, perhaps the most important element, of a strategy that seeks to counter terrorists concealing themselves in the nation™s communities. that is, tips about unusual and suspicious behavior are most likely to emerge when the communities in which terrorists are embedded are allied with, or at least not suspicious of, law enforcement authoritiesšand singling out young men of middle eastern origin for special scrutiny is not an approach that will create a large amount of good will in the affected communities.these tensions have been magnied since the terrorist attacks of  september 11. there are many who feel that if the right information had been available, along with the right tools to analyze that information and the right governmental structures that would allow the sharing of the information between law enforcement and national security agencies, those attacks could have been avoided. part of the reaction to those attacks was the passing of laws and the creation of policies that made it easier for agencies to collect and share information and the weakening of some traditional checks and balances in the hope of enhancing national security.at the same time, there is worry that the increasingly sophisticated technology available for surveillance, data sharing and analysis, and data warehousing, when joined with the weakening of rules protecting individual information, will allow law enforcement and national security agencies a vastly expanded and largely unseen ability to monitor all citizens. the potential for abuse given such an ability is easy to imaginešfor example, a law enforcement agency might be able to monitor the group gatherings of citizens objecting to a certain government policy, identifying who they meet with and perhaps what they talk about. most citizens do not know what is technically possible, either now or in the near future. because of this, there is often a tendency to believe that the technology 34 see william stuntz, ﬁlocal policing after the terror,ﬂ yale law journal 111:2137, 2002.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.298 engaging privacy and information technology in a digital ageis capable of far more than it can actually do, either currently or in the foreseeable future. the problem may not be in what these government agencies are capable of doing with technology, but rather with what the citizens believe those agencies can do.these comments should not be taken to suggest that policy makers in government agencies are unaware of privacy interests. for example, under the egovernment act of 2002, any federal agency contemplating a substantially revised or new information technology system is required to develop a privacy impact assessment (pia; box 9.5) for such a system before work on that system begins in earnest. in the case of the department of homeland security (dhs), dhs ofcials indicate that ndings of pias are, to some extent, folded into the requirements development process in an attempt to ensure that the program or system, when deployed, is at least sensitive to privacy considerations. (it should also be noted that dhs ofcials reject the paradigm that privacy trades off against security; they assert that the challenge is enhancing security while protecting privacy.) nevertheless, the concern from the privacy advocates remains regarding the extent to which privacy considerations are taken into account, and the specic nature of the privacydriven system or program adaptations.box 9.5 the department of homeland security privacy impact assessment a privacy impact assessment (pia) is an analysis of how personally identiable information is collected, stored, protected, shared, and managed. ﬁpersonally identiable informationﬂ is dened as information in a system or online collection that directly or indirectly identies an individual whether the individual is a u.s. citizen, legal permanent resident, or a visitor to the united states. the purpose of a pia is to demonstrate that system owners and developers have consciously incorporated privacy protections throughout the entire life cycle of a system. this involves making certain that privacy protections are built into the system from the start, not after the fact when they can be far more costly or could affect the viability of the project. personally identiable information is information in a system, online collection, or technology (1) that directly identies an individual (e.g., name, date of birth, mailing address, telephone number, social security number, email address, zip code, address, account numbers, certicate and license numbers, vehicle identiers including license plates, uniform resource locators, internet protocol addresses, biometric identiers, photographic facial images, or any other unique identifying number or characteristic), or (2) by which an agency intends to identify specic individuals in conjunction with other data elements, that is, indirect identication. these data elements may include a combination of gender, race, birth date, geographic indicator, and any information that reasonably can be foreseen as being linked with other information to identify an individual. in some cases the technology might only collect personal information for a moment. for example, a bodyscreening device might capture the full scan of an individual, and even if the information was not retained for later use, the initial scan might raise privacy concerns, and thus the development and deployment of the technology would require a pia. questions asked by the pia include the following:section 1.0 information collected and maintained1.1 what information is to be collected?1.2 from whom is information collected?1.3 why is the information being collected?1.4 what specic legal authorities, arrangements, or agreements dene the collection of information?1.5 privacy impact analysis: given the amount and type of data being collected, discuss what privacy risks were identied and how they were mitigated.section 2.0 uses of the system and the information2.1 describe all the uses of information.2.2 does the system analyze data to assist users in identifying previously unengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 299finally, the discussion in this chapter raises the question of what must be done when law enforcement authorities or intelligence agencies invade the privacy of americans who are lawabiding or who pose no threat to national security. it is unrealistic to expect that the number of false positives (i.e., the number of people improperly implicated) can be reduced to zero, and thus public policy must necessarily anticipate that some such cases will arise. one option is to minimize the number of false positives, and in the event of a false positive, the person improperly implicated simply absorbs the cost and consequences of the false positive (e.g., loss of privacy and any consequential costs, such as personal embarrassment, nancial loss, and so on) on behalf of the rest of society. but these costs and consequences can be dire indeed, and at least in principle our society has generally adopted the principle that individuals suffering the consequences of improper or mistaken government behavior are entitled to some kind of compensation. providing recourse for citizens improperly treated by government authorities is generally thought to make government authorities more careful and more respectful of rights than they might otherwise be.box 9.5 the department of homeland security privacy impact assessment a privacy impact assessment (pia) is an analysis of how personally identiable information is collected, stored, protected, shared, and managed. ﬁpersonally identiable informationﬂ is dened as information in a system or online collection that directly or indirectly identies an individual whether the individual is a u.s. citizen, legal permanent resident, or a visitor to the united states. the purpose of a pia is to demonstrate that system owners and developers have consciously incorporated privacy protections throughout the entire life cycle of a system. this involves making certain that privacy protections are built into the system from the start, not after the fact when they can be far more costly or could affect the viability of the project. personally identiable information is information in a system, online collection, or technology (1) that directly identies an individual (e.g., name, date of birth, mailing address, telephone number, social security number, email address, zip code, address, account numbers, certicate and license numbers, vehicle identiers including license plates, uniform resource locators, internet protocol addresses, biometric identiers, photographic facial images, or any other unique identifying number or characteristic), or (2) by which an agency intends to identify specic individuals in conjunction with other data elements, that is, indirect identication. these data elements may include a combination of gender, race, birth date, geographic indicator, and any information that reasonably can be foreseen as being linked with other information to identify an individual. in some cases the technology might only collect personal information for a moment. for example, a bodyscreening device might capture the full scan of an individual, and even if the information was not retained for later use, the initial scan might raise privacy concerns, and thus the development and deployment of the technology would require a pia. questions asked by the pia include the following:section 1.0 information collected and maintained1.1 what information is to be collected?1.2 from whom is information collected?1.3 why is the information being collected?1.4 what specic legal authorities, arrangements, or agreements dene the collection of information?1.5 privacy impact analysis: given the amount and type of data being collected, discuss what privacy risks were identied and how they were mitigated.section 2.0 uses of the system and the information2.1 describe all the uses of information.2.2 does the system analyze data to assist users in identifying previously uncontinuedengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.300 engaging privacy and information technology in a digital ageknown areas of note, concern, or pattern (sometimes referred to as ﬁdata miningﬂ)?2.3 how will the information collected from individuals or derived from the system be checked for accuracy?2.4 privacy impact analysis: given the amount and type of information collected, describe any types of controls that may be in place to ensure that information is used in accordance with the above described uses.section 3.0 retention3.1 what is the retention period for the data in the system?3.2 has the retention schedule been approved by the national archives and records administration (nara)?3.3 privacy impact analysis: given the purpose of retaining the information, explain why the information is needed for the indicated period.section 4.0 internal sharing and disclosure4.1 with which internal organizations is the information shared?4.2 for each organization, what information is shared and for what purpose?4.3 how is the information transmitted or disclosed?4.4 privacy impact analysis: given the internal sharing, discuss what privacy risks were identied and how they were mitigated.section 5.0 external sharing and disclosure5.1 with which external organizations is the information shared?5.2 what information is shared and for what purpose?5.3 how is the information transmitted or disclosed?5.4 is a memorandum of understanding (mou), contract, or any agreement in place with any external organizations with whom information is shared, and does the agreement re˚ect the scope of the information currently shared?5.5 how is the shared information secured by the recipient?5.6 what type of training is required for users from agencies outside dhs prior to receiving access to the information?5.7 privacy impact analysis: given the external sharing, describe what privacy risks were identied and how they were mitigated.section 6.0 notice6.1 was notice provided to the individual prior to collection of information? if yes, please provide a copy of the notice as an appendix. (a notice may include a posted privacy policy, a privacy act notice on forms, or a systemofrecords notice published in the federal register notice.) if notice was not provided, why not?6.2 do individuals have an opportunity and/or right to decline to provide information?6.3 do individuals have the right to consent to particular uses of the information, and if so, how does the individual exercise the right?6.4 privacy impact analysis: given the notice provided to individuals above, describe what privacy risks were identied and how they were mitigated.section 7.0 individual access, redress and correction7.1 what are the procedures that allow individuals to gain access to their own information?7.2 what are the procedures for correcting erroneous information?7.3 how are individuals notied of the procedures for correcting their information?7.4 if no redress is provided, are alternatives available?7.5 privacy impact analysis: given the access and other procedural rights provided for in the privacy act of 1974, explain the procedural rights that are provided and, if access, correction, and redress rights are not provided, explain why not.section 8.0 technical access and security8.1 which user group(s) will have access to the system?8.2 will contractors to dhs have access to the system? if so, please submit to the privacy ofce with this pia a copy of the contract describing their role.8.3 does the system use ﬁrolesﬂ to assign privileges to users of the system?8.4 what procedures are in place to determine which users may access the system, and are they documented?8.5 how are the actual assignments of roles and rules veried according to established security and auditing procedures?8.6 what auditing measures and technical safeguards are in place to prevent misuse of data?8.7 describe what privacy training is provided to users either generally or that is specically relevant to the functionality of the program or system.8.8 are the data secured in accordance with fisma requirements? if yes, when were certication and accreditation last completed?8.9 privacy impact analysis: given access and security controls, describe what privacy risks were identied and how they were mitigated.section 9.0 technology9.1 was the system built from the ground up or purchased and installed?9.2 describe how data integrity, privacy, and security were analyzed as part of the decisions made for your system.9.3 what design choices were made to enhance privacy?source: department of homeland security, privacy impact assessments: ofcial guidance, dhs privacy ofce, available at http://www.dhs.gov/interweb/assetlibrary/privacypia guidancemarchv5.pdf.box 9.5 continuedengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.privacy, law enforcement, and national security 301known areas of note, concern, or pattern (sometimes referred to as ﬁdata miningﬂ)?2.3 how will the information collected from individuals or derived from the system be checked for accuracy?2.4 privacy impact analysis: given the amount and type of information collected, describe any types of controls that may be in place to ensure that information is used in accordance with the above described uses.section 3.0 retention3.1 what is the retention period for the data in the system?3.2 has the retention schedule been approved by the national archives and records administration (nara)?3.3 privacy impact analysis: given the purpose of retaining the information, explain why the information is needed for the indicated period.section 4.0 internal sharing and disclosure4.1 with which internal organizations is the information shared?4.2 for each organization, what information is shared and for what purpose?4.3 how is the information transmitted or disclosed?4.4 privacy impact analysis: given the internal sharing, discuss what privacy risks were identied and how they were mitigated.section 5.0 external sharing and disclosure5.1 with which external organizations is the information shared?5.2 what information is shared and for what purpose?5.3 how is the information transmitted or disclosed?5.4 is a memorandum of understanding (mou), contract, or any agreement in place with any external organizations with whom information is shared, and does the agreement re˚ect the scope of the information currently shared?5.5 how is the shared information secured by the recipient?5.6 what type of training is required for users from agencies outside dhs prior to receiving access to the information?5.7 privacy impact analysis: given the external sharing, describe what privacy risks were identied and how they were mitigated.section 6.0 notice6.1 was notice provided to the individual prior to collection of information? if yes, please provide a copy of the notice as an appendix. (a notice may include a posted privacy policy, a privacy act notice on forms, or a systemofrecords notice published in the federal register notice.) if notice was not provided, why not?6.2 do individuals have an opportunity and/or right to decline to provide information?6.3 do individuals have the right to consent to particular uses of the information, and if so, how does the individual exercise the right?6.4 privacy impact analysis: given the notice provided to individuals above, describe what privacy risks were identied and how they were mitigated.section 7.0 individual access, redress and correction7.1 what are the procedures that allow individuals to gain access to their own information?7.2 what are the procedures for correcting erroneous information?7.3 how are individuals notied of the procedures for correcting their information?7.4 if no redress is provided, are alternatives available?7.5 privacy impact analysis: given the access and other procedural rights provided for in the privacy act of 1974, explain the procedural rights that are provided and, if access, correction, and redress rights are not provided, explain why not.section 8.0 technical access and security8.1 which user group(s) will have access to the system?8.2 will contractors to dhs have access to the system? if so, please submit to the privacy ofce with this pia a copy of the contract describing their role.8.3 does the system use ﬁrolesﬂ to assign privileges to users of the system?8.4 what procedures are in place to determine which users may access the system, and are they documented?8.5 how are the actual assignments of roles and rules veried according to established security and auditing procedures?8.6 what auditing measures and technical safeguards are in place to prevent misuse of data?8.7 describe what privacy training is provided to users either generally or that is specically relevant to the functionality of the program or system.8.8 are the data secured in accordance with fisma requirements? if yes, when were certication and accreditation last completed?8.9 privacy impact analysis: given access and security controls, describe what privacy risks were identied and how they were mitigated.section 9.0 technology9.1 was the system built from the ground up or purchased and installed?9.2 describe how data integrity, privacy, and security were analyzed as part of the decisions made for your system.9.3 what design choices were made to enhance privacy?source: department of homeland security, privacy impact assessments: ofcial guidance, dhs privacy ofce, available at http://www.dhs.gov/interweb/assetlibrary/privacypia guidancemarchv5.pdf.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.303part ivfindings and recommendationsengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.30510findings and recommendations10.1 coming to termsfinding 1. the meaning of privacy is highly contextual, and it can vary depending on the specic circumstances at hand, such as the situation and relationships at issue, the intentions of the parties involved, and the historical context, technology, and political environment.chapters 1 and 2 of this report take note of the fact that in both everyday discourse and in the scholarly literature, a commonly agreedupon abstract denition of privacy is elusive (section 1.2). for example, ﬁprivacyﬂ under discussion may involve protecting the condentiality of information; enabling a sense of autonomy, independence, and freedom to foster creativity; wanting to be left alone; or establishing enough trust that individuals within a given community are willing to disclose data under the assumption that it will not be misused.nevertheless, it is often possible to nd agreement on the meaning of privacy in specic contexts (section 2.4). in other words, the meaning of privacy depends on many specics about the situation at hand, e.g., the situation and relationships at issue, the intentions of the parties involved, and the historical context, technology, and the political environment. for example, informational privacy involving political and religious beliefs raises different issues than does health information with respect to a contagious disease. a conversation with one™s attorney is different from a speech in a public park or a posting on an internet bulletin board. agreement on the meaning of ﬁprivacyﬂ outside the specied context is engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.306 engaging privacy and information technology in a digital agenot necessary, but for making progress in a specic context, a common understanding is essential. in many cases, simply clarifying the terms constitutes progress in itself, and indeed may on occasion be sufcient to reduce the need for further argument.because the committee found that common to almost all notions of privacy is a privileged status for personal information (privileged in the sense of information that is not immediately known or accessible to others), this report has focused on the meaning and implications of privacy as it relates to the gathering, aggregation, analysis, distribution, and use of personal information. a successful discussion about privacy policies requires the clear identication of both the nature of the personal information in question and the relevant contextual factors.regarding the nature of the personal information, it is important to probe in several areas discussed in section 2.1.3:ł data capture, which includes the type(s) of personal information in question (e.g., social security number, medical information, publicly available information) and the circumstance and means of its capture;ł data storage, which includes the time period for which data will be retained and available for use and the circumstances and means of storage (e.g., media used), and the protections for personal information while it is available for a specic use;ł data analysis and integration, which includes the nature of the process through which the information is analyzed and the links that might be made to other data; andł data dissemination, which includes the parties who will have access to the information, the form(s) in which the information is presented, the type of harm that might result from unwelcome disclosure or dissemination, and the extent to which this information has privacy implications for other individuals.regarding the relevant contextual factors, it might be useful to probe about the following:ł what is the relevant and applicable social and institutional context? for example, are rewards or benets offered for sharing personal information? is coercion used in the form of withholding benets when personal information is not shared? does the individual retain control over the initial and potential future uses of her information? does she have the opportunity to review and correct personal information?ł who are the actors and institutions involved? these might include the subject of the information, the provider of the information (which may not be the subject), the original recipients of the information, subsequent engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 307recipients, and other individuals who might be affected without their active involvementšand the relationships among them.ł what are the stated and unstated motivations, goals, or purposes of the actors? why do the recipients of the information want it? how might the information be repurposedšused for a purpose other than that for which it was originally collectedšin the future?ł how are decisions made when there are competing interests regarding personal information, for example, public health needs versus individual privacy or national security versus civil rights interests?ł what are the informational norms in question? as noted in chapter 2, informational norms specify how different kinds of information about various actors in the given context can ˚ow. these norms can be illuminated in many instances through the technique of applying anchoring vignettes as described in chapter 2. relevant issues concerning these norms might include: šthe extent to which information is provided voluntarily (e.g., is the providing of information required by law, is the information acquired covertly or deceptively); šthe extent to which information can be passed along to third parties and the circumstances of such passing (e.g., is it part of a nancial transaction); šthe extent to which reciprocity exists (is the subject entitled to receive information or other benets from the recipient); šthe extent to which the gathering of information is apparent and obvious to those to whom the information pertains; šlimitations on the use of the information that are implied or explicitly noted; šwhether or not the act of subsequently providing information is known to the subject; and šthe extent to which collected information can/might be used for or against others (e.g., relatives, other members of a class).one important corollary of finding 1 is that policy debates are likely to be sterile and disconnected if they are couched simply in abstract terms. it should thus be expected that policy debates involving privacy will be couched in the language of the specic context involvedšand such contextdependent formulations are desirable. the reason is that even if the issues themselves seem to carry over from one context to another, the weighting of each issue and hence the relationships of issues to each other are likely to depend on the specic context.a second corollary is that because privacy has meaning only in context, the incidence of privacy problems (e.g., violations of privacy) is poorly dened outside specic contexts, and overall quantitative measures of engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.308 engaging privacy and information technology in a digital ageprivacy are not particularly meaningful. what may be more meaningful is careful delimitation of claims that are made based on domainspecic data. an example from the identity theft domain might involve hypothesizing the number of individuals per year whose names and social security numbers were potentially compromised by a security breach, rather than asserting these numbers as indicating identity theft.a third corollary is that privacy is not primarily a technological issueštechnology cannot violate or guarantee privacy. technology can enhance or detract from the secrecy of information or the anonymity of an actor, but these are not the same as privacy. the nature and extent of privacy in any given context are tied to many factors, including the way in which information is accessed, the intentions of those accessing the information, and the trust relationships between the user of the information and the subject of the information.10.2 the value of privacyfinding 2. privacy is an important value to be maintained and protected, although it is not an absolute good in itself.as noted in chapter 2, privacy is an important value to be maintained and protected. certain types of privacy (e.g., those involving religious beliefs and political ideas or certain aspects of the body) approach the status of fundamental human rights. they are related to our most cherished ideals of the dignity of the person, the family, liberty, and democracy.at the same time, the committee does not view privacy as an intrinsic and absolute good independently of particular situations. there are times when crossing the informational borders of the person is appropriate and to fail to do so would be irresponsible. that is, the committee recognizes situations and contexts in which society negotiates appropriate tradeoffs between privacy and other values (as discussed below) such as public health and safety. to note this is not to deny the centrality of privacy to human dignity, candor, and intimacy as well as to a democratic society. privacy is thus also a means as well as an end, and the committee recognizes considerable instrumental value in privacyšprivacy in the service of other important goals. beyond instrumentality, privacy has important symbolic value in demonstrating societal respect for the individual.finding 3. loss of privacy often results in signicant tangible and intangible harm to individuals and to groups.in one obvious example, protecting the privacy of one™s personal information helps to make one safer from crimes such as fraud, identity theft, and stalking. (when undertaken on a large scale, identity theft can engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 309also have important and negative effects on society, as suggested by the use of identity theft as an element in the nancing of terrorist groups and their operations (see box 4.1).) but such tangible harms, striking though they are, affect far fewer people compared with those who suffer less tangible harms (as suggested in section 1.3). these intangible harms could be regarded as the consequential damages to individuals and to society that result from the loss or compromise of privacy, and they are no less real or signicant for being intangible rather than tangible. consider:ł a person whose personal information (name, address, social security number, and so on) may have fallen into the hands of identity thieves may not in fact suffer from an actual fraudulent purchase made in her name. but if the breach is identied and the subject learns of it, she will likely worry about being victimized and thus must look over her shoulder for a very long period of time. she may have to scrutinize her credit card statements more carefully; she may have to subscribe to a creditmonitoring service; she may have to put a freeze on her credit report and thereby deny herself the convenience of obtaining instant credit at a store. she may live in fear of assault, public embarrassment, or defamation, not knowing who has the information or how it might be used. thus, absent the protection of her information, she stands to lose real benets and the intangible peace of mind that she would otherwise enjoy, even if no actual direct harm occurs, not to mention the many dozens of hours needed to repair her records and relationships. furthermore, it takes only a few such wellpublicized incidents (i.e., a small number compared with the number of possible instances where it could happen) to cause a very large number of people to lose trust in electronic commerce and related mattersšand thus to refrain from engaging in such commerce. such broader impacts have larger consequences for the economy as a whole than simply the impact on the individuals directly affected by identity theft.ł under public surveillance, many people change their behavior so that they are not seen as acting anomalously in any way, even if their behavior absent surveillance would be perfectly legal and ethical. for example, an interracial couple may walk down the road holding hands and even sneak a kiss. with surveillance cameras visibly trained on the road, they may not kiss, they may not hold hands, and they may even change their route so that they are not under video surveillance. public surveillance may reduce the likelihood that someone would attend a public demonstration in which he might otherwise participate. in short, surveillance often has the effect of in˚uencing the behavior of people in the direction of greater conformity and homogeneity. greater conformity is sometimes defensible, as might be the case when safe driving can be linked to automatic trafc camera surveillance. but surveillance in some engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.310 engaging privacy and information technology in a digital ageinstances has negative consequences, and in a culture and society that celebrate diversity and embrace tolerance, such chilling effects are not at all positive. in short, privacy supports many democratic societal values, such as the right to freely associate, the embrace of social diversity, and even the use of secret ballots in support of free elections, and consequently the loss of privacy can affect the entire society.ł through the analysis of a variety of personal information, the u.s. government has placed many individuals on ﬁwatch listsﬂ as suspected terrorists who should be denied airplane boarding privileges or entry into the united states. individuals on these watch lists cannot know of their status until they are denied boarding or entryšand if they are in fact not terrorists, they suffer the consequences of mistaken identity. further, they have no recoursešno way to be made wholešfor the consequences they suffer.ł workplace surveillance changes the workplace environment, almost by denition. but unlike most unfocused public surveillance, the very purpose of workplace surveillance is to change the behavior of everyone within its purview. from the standpoint of employees under poorly explained surveillance (which is often simply offered as a fait accompli), surveillance can result in a deadened work environment perceived as hostile and restrictive in which workers are not trusted and ﬁare treated like children.ﬂ ironically, work monitoring seen to be unreasonable is likely to be responded to in ways that undermine the goals of the organization, and such surveillance may raise the level of stress among workers in ways that limit their productivity.ł a voter without privacy is subject to coercion in casting his or her vote. indeed, it was for just this reason that the secret ballot was gradually introduced in the united states in the late 19th century. with a secret ballot, there is no way to prove how an individual voted, and thus a voter can cast his or her vote freely without fear of later retribution. secret ballots also impede vote buying, since a voter can vote one way and tell his or her paymaster that he voted the way he or she was paid to vote.ł the availability of personal information about an individual enables various organizations to provide him or her with information or product and service offerings customized to the interests and patterns re˚ected in such information. while such information and offerings do have benet for many people who receive them, they can have negative effects as well. for example, personal medical information made available to drug manufacturers may result in drug advertisements being targeted to individuals with certain diseases. receipt of such advertisements at one™s family home can compromise the privacy of the individual™s medical information if the diseases associated with such drugs are socially stigmatizing.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 311ł people who lose control of their personal information can be subject to discrimination of various kinds (section 2.3). as a society, we have made a choice that discrimination based on race and religion (among other things) should be illegal as a matter of public policy. but there are many other distinctions that can be made when detailed personal information is available that facilitates the classication and assignment of people to groupsšgroups dened not by race or religion but by some nameless statistical sorting on multiple dimensions. members of groups so dened can be denied services, information, opportunities, or employment to which they would otherwise be entitled if that personal information had been kept private. for example, political campaigns can use collections of personal information to tailor different messages to members of different groups that are designed to appeal to their particular views and attitudes. such practices work against full disclosure and a communitywide consideration of the issues.these examples underscore the committee™s categorical rejection of the notion that if you have done nothing wrong, you have nothing to fear from a loss of privacy.it should also be noted that the ability to put individuals under surveillance is often as signicant in changing behavior as the reality of such surveillance. from dummy surveillance cameras intended to deter crime to fellow diners in a cafeteria who might be listening to a private conversation, there are many ways in which potential surveillance can affect behavior.finding 4. privacy is particularly important to people when they believe that the entity receiving their personal information is not trustworthy and that they may be harmed by sharing that information.trust is an important issue in framing concerns regarding privacy. in the context of an individual providing personal information to another, the sensitivities involved will depend on the degree to which the individual trusts that party to refrain from acting in a manner that is contrary to his or her interests (e.g., to pass it along to someone else, to use it as the basis for a decision with inappropriately adverse consequences). as an extreme case, consider the act of providing a complete dossier of personal information on a stack of paperšto a person who will destroy it. if the destruction is veriable to the person providing the dossier (and if there is no way for the destroyer to read the dossier), it would be hard to assert the existence of any privacy concern at all.but for most situations in which one provides personal information, the basis for trust is less clear. children routinely assert privacy rights to their personal information against their parents when they do not trust engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.312 engaging privacy and information technology in a digital agethat parents will not criticize them or punish them or think ill of them as a result of accessing that information. (they also assert privacy rights in many other situations.) adults who purchase health insurance often assert privacy rights in their medical information because they are concerned that insurers might not insure them or might charge high prices on the basis of some information in their medical record. many citizens assert privacy rights against government, although few would object to the gathering of personal information within the borders of the united states and about u.s. citizens if they could be assured that such information was being used only for genuine national security purposes and that any information that had been gathered about them was accurate and appropriately interpreted and treated (as discussed in section 9.2.5). perversely, many people hold contradictory views about their own privacy and other people™s privacyšthat is, they support curtailing the privacy of some demographic groups at the same time that they believe that their own should not be similarly curtailed. this dichotomy almost certainly re˚ects their views about the trustworthiness of certain groups versus their own.in short, the act of providing personal information is almost always accompanied to varying degrees by a perceived risk of negative consequences ˚owing from an abuse of trust. the perception may or may not be justied by the objective facts of the situation, but trust has an important subjective element. if the entity receiving the information is not seen as trustworthy, it is likely that the individuals involved will be much more hesitant to provide that information (or to provide it accurately) than they would be under other circumstances involving a greater degree of trust.10.3 pressures on privacythe discussion in earlier chapters suggests that there are many pressures that are increasingly limiting privacy. among them are advancing information technologies; increasing mechanisms for obtaining information; the value of personal information to business and government; and changing social norms and needs.finding 5. although some developments in information technology (it) and other technologies do have considerable potential to enhance privacy, the overall impact of advancing technology including it has been to compromise privacy.one obvious pressure on privacy is the evolution of information technology writ large, an evolution that has resulted in greater capability to invade and compromise privacy more deeply and more easily than ever before. one might ask whether this result was inevitablešwhether under engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 313a different set of societal structures and different notions of power and privilege the evolution of it might have done more to enhance privacy. but even though some developments in it do indeed have the potential to enhance privacy, there is little doubt that the overall impact of advancing it has been to compromise privacy in important ways.for example, the rapidly decreasing cost of storing information has meant that personal information on an individual, once collected, may generally be available for potential use forever unless special measures are taken to destroy it (chapter 3). even when there is no particular need to keep information for a long time, it is often kept by default, because it is more expensive to decide on what to destroy or delete than to maintain it in storage. such information is easily if not routinely added to existing databases on the individual, which means that the volume of information about an individual only grows over time.1a second example is the proliferation of smaller, less expensive, and more easily deployed sensors that can readily obtain information in their ambient environment, information that is sometimes personal information about individuals.technology has also facilitated greater access to information (section 3.4). nominally public records stored on paper are vastly more inaccessible than if their contents are posted on a web site or are available online, and in that sense are more private apart from any rules regulating access to them. for example, property tax records have been available to the public in most municipalities for decades. the inconvenience of access has prevented widespread knowledge of neighbors™ property values, but when such information is available via the internet, it is disseminated much more broadly.more generally, information technology is a rapidly changing eld. new information technologiesšand new sensor, biometric, and life science technologies, toošoften offer capabilities poorly understood and considered in public debates or in individuals™ expectations of privacy. traditional expectations about information are in a sense under continuous bombardment from such changes, and prior beliefs, understandings, and practices are not necessarily an adequate guide or control with respect to the torrent of new developments. the net result is that the appearance 1 an example is a person™s medical history, much of which is irrelevant to an individual™s current medical status. (information regarding major medical events (surgeries, major diseases) and associated signicant data such as reports on operations, x rays, and pathology reports continue to be useful, but much of the medical record over time becomes lled with data that may be maintained for medical legal purposes but has little value to the treating physician long after the fact. such data might, for example, include lab work taken during a critical event or during routine care many years in the past.)engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.314 engaging privacy and information technology in a digital ageof new technologies rekindles debates and arguments that might otherwise have been regarded as settled.finding 6. businesses, researchers, and government agencies increasingly nd value in the exploitation of personal information, which leads to many pressures for repurposing of collected data.a second pressure is the fact that the itenabled exploitation of personal information has many benets for modern business in enhancing the economic bottom line (chapters 6 through 8). activities such as increasing consumer choice, reducing economic risks, directing customized product offerings to consumers, and hiring and placing employees in the most costeffective fashion become feasible as business strategies only when there is personal information available to support them. researchers rely on collections of personal information to derive statistical trends of importance to public policy makers. government authorities increasingly seek better and more ways of using personal information to provide services (section 6.8), administer benets, and enhance security (chapter 9).furthermore, the ways in which personal information can be exploited to benet the bottom line of businesses or the mission capabilities of government agencies seem to be limited only by the creativity of the human mind (section 6.1). this is signicant because data, once collected for a given purpose, can easily be used for a different purpose in the futurešthis is especially true because the data can be retained indenitely at little cost. today™s databases for the most part have not been designed to restrict the use of the data they contain to any specic purpose. many of the privacy concerns discussed in this report center on cases in which information gathered for one purpose is reused for a different purpose with neither notice nor consent. whether it is the use of medical information for the marketing of pharmaceuticals, the conversion of timestamps on tollroad tickets for the calculation of average speed (and the subsequent issuing of speeding tickets), or the reuse of information collected from patients in a longterm epidemiological research study, repurposing of previously collected data creates myriad privacy concerns.a particularly interesting kind of personal information is information that today is not easily personally identiable but may be more identiable in the future. for example, surveillance cameras in public places take many pictures of people. today, the automated recognition of facial images taken by such cameras is difcult and unreliablešbut the technology of facial recognition will almost certainly improve in the future. as the technology improves, and databases of facial images are populated, it is entirely possible that businesses and government will develop new ways of exploiting personal information that is not identiable today.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 315finding 7. privacy considerations are relevant throughout the life cycle of personal information that is collected, and not just at the beginning of the collection process.the collection and use of personal information is typically not a single event, but a process with considerable duration and organizational support. finding new ways to exploit alreadycollected information extends the life cycle even further. thus, privacy considerations need to be taken into account on a continuing basis.finding 8. businesses and government agencies have developed many mechanismsšboth voluntary and intrusivešfor obtaining personal information.because institutions both public and private nd high value in the itenabled largescale availability of personal information, they continually nd ways to maintain and expand the availability of such information from individuals. though there are many variants, such ways can be grouped in a few categories:ł mandated disclosure is, by denition, coercive. for example, taxpayers must provide detailed nancial information on income tax returns. convicted felons in a number of states must provide dna information for entry into a database to which law enforcement ofcials have access. convicted sex offenders must register with law enforcement authorities, and communities must be notied about the presence of such individuals living therein. most importantly, failure to provide such information is punishable by law.ł incentivized disclosure is arguably voluntary. individuals are persuaded to provide personal information by the offer of some incentivešan offer that may be difcult to refuse. for example, merchants often offer customers ﬁloyaltyﬂ cards, the presentation of which at the cash register entitles the customer to a discount on the merchandise being bought. in exchange, the merchant obtains a record of all purchases (and patterns over time) made using this loyalty card. the use of this data may enable the merchant to better tailor product offerings to its customers™ revealed preferences. customers who prefer that no record be made of their purchases need not present a loyalty card, and in some cases they may request that a generic loyalty card be used to provide the discount.ł conditioned disclosure lies between incentivized disclosure and mandatory disclosure. obtaining a certain good or service is conditioned on the recipient providing personal information. furthermore, the good or service in question is arguably very importantšperhaps nearly essentialšto the activities of one™s daily life or the obligations of citizenship. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.316 engaging privacy and information technology in a digital agedriving a car, traveling on an airplane, voting, and being employed are voluntary activities in some sense, but one must provide personal information in order to engage in them. walking in a public plaza watched by surveillance cameras is voluntary, but even if notices of surveillance are posted (which may not be the case), avoiding the plaza may not be particularly convenientšand thus surveillance photos of the walker may be taken. taking a drug test may be a requirement of keeping one™s jobšand the results of a urine test may be stored in an employee™s personnel le. thus, the disclosure of personal information is not quite mandated, because one may indeed make a choice to not obtain the good or service. but it is not quite voluntary either, because doing without the good or service in question would constitute a hardship or a substantial inconvenience for the individual.ł entirely voluntary disclosure. people engaged in social interactions with others often exchange information about themselves, but they themselves decide what they will share. a person may have a sense of the other person involved, or of the cultural norms that suggest the nature of the exchange, but for the most part they still decide if and how much information to provide. in other situations, people sometimes voluntarily provide information about themselves as a gesture of afliation or as evidence of competence, understanding, or empathy (ﬁyes, that happened to me too; i understand just how you feelﬂ). to the extent that these interactions do not re˚ect differential power relationships, these can be regarded as entirely voluntary disclosures, and they need not be governed by the expectation of tangible or direct personal benet or exchange.ł unannounced acquisition of information. in such situations, information is not even ﬁdisclosed,ﬂ since disclosure implies that the individual realizes that he or she is revealing information. but there are many situations in which people disclose personal information without realizing it. most individuals who make tollfree calls do not realize that the numbers from which they are calling are provided to the called party, and callerid services operate without notice to callers. web bugs and cookies covertly provide information about the web surng behavior of individuals. building entry is often recorded as individuals swipe their electronic id cards into an access control system. surveillance photos are often taken at a distance. in some of these cases, individuals subject to these acquisitions of information are in some sense given notice of that fact, but these notices are often provided in such a way that they are easy to ignore or forget.finding 9. changing social trends and sentinel events put strong pressures on privacy.some forms of privacy invasion that are technically possible may in practice not take place in certain social contexts. beyond formal law, for engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 317example, various professional codes of ethics require practitioners to preserve certain kinds of privacy, and in many cases these codes are sufcient to reassure individuals that personal information revealed to these practitioners will remain private and condential. social and cultural norms regarding propriety and civility have also tended to keep certain kinds of personal information that were nominally public from being widely circulated (e.g., information about a public gure™s divorce or extramarital affairs). manners and common sense can also be important in limiting disclosure and notice.nevertheless, a number of social trends have signicantly eroded much of the privacy protection that may have resulted from such norms (section 1.4.3). once information becomes public, it is virtually impossible to fully expunge it, no matter how privacy invasive, offensive, or incorrect it may be. personal information that is available is likely to be exploited by those who see economic, political, or other strategic value to its use, independent of societal approval or disapproval. dna evidence has led to the freeing of imprisoned individuals and convicted others, putting pressure on obtaining it. sexual offender notices have led to the harassment and murder of convicted offenders who have served their sentences.2sentinel events (i.e., dramatic changes in circumstance such as terrorist events and public health crises) often change the privacy environment (section 1.4.4). furthermore, the resulting media coverage and political rhetoric often lead to a political environment in which privacy can be reduced or curtailed in ways not previously accepted by the public. this was dramatically illustrated by the speed with which the usa patriot act was passed in the wake of the september 11, 2001, terrorist attacks.finding 10. the power of the state and large private organizations to gather personal information and to act on that information is much greater than the power of the individual to withhold personal information from the state or those organizations or to prevent improper or unjustied actions from being taken.as noted in section 9.1.6, there is almost always a substantial imbalance between the power of the state and that of the individual regarding the gathering of information about individuals. some regard this imbalance as dangerous and improper, and infer that external limits are thus necessary to constrain the ability of government ofcials to act improperly, even if such constraints complicate or impede the task of law enforcement agencies. others trust that government ofcials will use such power only 2 emily bazar, ﬁsuspected shooter found sex offenders™ homes on website,ﬂ usa today, april 18, 2006, available at http://www.usatoday.com/news/nation/20060416maineshootings x.htm.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.318 engaging privacy and information technology in a digital agein the interest of the citizenry and thus do not believe that such constraints are necessary, especially if these constraints complicate or impede the task of law enforcement agencies. whatever one™s views on this matter, it is a reality that must be factored strongly into the debate over privacy.similar comments apply to the balance between large private organizations and individuals, although the texture of that balance is different. it is difcult to withhold information from both government and many large private organizations with which individuals choose to do business. government and private organizations are subject to some degree of oversight, by the independent branches of government in the former case and by boards and ombudsmen in the latter case. but individuals have no choice in the government laws and regulations under which they live short of moving away,3 and they often have only some choices in the private organizations with which they interact. moreover, private organizations do not directly hold coercive powers such as imprisonment, which are reserved for the state. concerns regarding private organizations parallel those regarding government. that is, some people are highly concerned about the imbalance between individuals and private organizations, and thus infer that regulation is thus necessary to constrain their ability to act in ways that harm individuals, even if such constraints complicate or impede their business and operational missions. others believe that the power of the marketplace is sufcient to constrain their behavior, and reject external constraints because they would complicate or impede their business and operational missions.10.4 making tradeoffsfinding 11. privacy is a value that must often be traded off against some other desirable societal value or good.at the same time that the committee strongly believes privacy is central to notions of the dignity of the person and is a requisite for a decent and democratic society, it also recognizes the complexity of society and the existence of competing values (section 1.2). for example, the protection of privacy is sometimes detrimental to economic efciencyšin the absence of certain kinds of information, two otherwise equal parties may not make the most economically efcient decision. privacy claims can be 3 of course, citizens in a democracy can vote to support candidates who support changes in laws and regulations that they regard as objectionable. however, this does not change the fact that citizens are obligated to obey all applicable laws and regulations on the books at any given moment, and their only choices at that moment are to accept such responsibility or to move to a location where they are not subject to the reach of those laws or regulations.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 319used to shield criminal acts, and they can also be used to limit scrutiny of acts and behavior thatšthough not technically illegalšare arguably antisocial or otherwise disapproved.depending on one™s weighting of the values at stake, such tradeoffs may mean more privacy and less of x (x being the other value or values at stake) or vice versa. deciding the right mix of privacy and x in any given situation sometimes entails a tradeoff with respect to other values, and understanding the nature of those tradeoffs is necessary before one can think systematically about decisions involving tradeoffs.a central feature of many policy tradeoffs involving privacy is the fact that privacyšin the terms usually most relevant to the policy debatešrelates to the privacy of individuals, whereas the other x at stake relates to a collective value or good. that is, some individual members of society are asked to accept reductions in privacy in order to benet the entire society. if these individual members are politically marginalized (e.g., because they are few in number or have no vocal advocates), the political process will similarly marginalize their privacy concerns. (in the past, such groups have included japaneseamericans in world war ii and the u.s. citizens and organizations subjected to national security agency communications surveillance in the decade beginning in the early 1960s, many of whom among the latter were active in the antiwar and civil rights movements.4) whether the actions taken are viewed as desirable or undesirable, or as necessary or unnecessary, will vary depending on the conditions, but they should be recognized for what they are.a similar tradeoff occurs when researchers seek to obtain statistical information from large aggregations of personal information from many individuals. for example, epidemiologists often use personal health information of many individuals to understand patterns of disease propagation. although personal health information is generally collected for the benet of individual patients, epidemiological research generally does not require the identities of these patients. society as a whole benets from epidemiological research, but the potential costs of using putatively anonymized personal health information are borne by the individuals whose identities might be compromised inadvertently. it is for this reason that the nature and the scope of privacy assurance regarding personal health information are so important from a policy perspective.the fact that tradeoffs are made is not new in public policy. but one implication of the information agešin which information is collected and 4 warrantless fbi electronic surveillance, book iii of the final report of the select committee to study governmental operations with respect to intelligence activities, united states senate, april 23, 1976.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.320 engaging privacy and information technology in a digital agedisseminated with increasing ease and individuals are more and more interconnectedšis that routine administrative and bureaucratic processes (one might even call these processes autonomic) for making many such decisions are no longer sufcient, and that engaged, re˚ective decision making, perhaps at higher levels than before, will become increasingly necessary.the reason is that in the absence of countervailing forces, privacy will tend to be eroded when considered in relation to some more tangible and immediate objective that is also desirable. indeed, privacy is something that is noticed mostly when it is gone or missing or compromised. people are much more likely to notice that their privacy is being violated than they are to notice that their privacy is being respected. thus, it is easy for autonomic decision making to sacrice a goodšprivacyšthat is noticeable mostly in its absence in favor of the more tangible and visible benet promised by those seeking another legitimate end. we must become aware of this tendency and be sure that decision makers give adequate weight to values having different characteristics.finding 12. in the public debate about balancing privacy and other societal interests, there is often a lack of clarity about the privacy interests involved and too often a tendency to downplay and to be dismissive of the privacy issues at stake.because policy makers recognize the political risks involved in appearing to compromise citizen privacy, they often offer assurances that legitimate citizen privacy will in fact be protected. that is, they assert that they have in fact guarded against sacricing privacy needlessly or inappropriatelyšwhether or not they have in fact done so.the committee believes that for public policy purposes, a vital element of making tradeoffs is the enhancement of transparency in the process. this strategy consists of two components. the rst is the provision of a clear statement of what meaning of ﬁprivacyﬂ is being used and why. the goal is to ensure that everyone in the discussion means the same thing by ﬁprivacyﬂ and/or by ﬁxﬂ (whatever privacy is being traded against). (by clarifying the meaning of privacy rather than obfuscating it, the public debate could also serve an educational role for the public that often does not appreciate the issues attendant to privacy.) from an analytical perspective, sections 10.1 and 2.4 (see box 2.2) describe one processšthe use of anchoring vignettesšfor coming to terms about meaning, and there are of course other ways of doing so as well.note that debates seeming to be about privacy can in fact involve very different matters. for example, the debate about access to dna information by insurance companies is actually a debate about access to health engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 321care, employment, or mobility and whether or not insurance companies should be allowed to deny coverage on the basis of one™s genetic prole. those making policy should take care to make sure that debates that seem to center on privacy do not, in fact, use privacy as a screen to cover other fundamental disagreements. this does not mean that privacy is irrelevant to such a discussionšfor example, individuals asserting a right to privacy may be using the only weapon that they have to protect their selfinterest in such a situation. but privacy may not be the only or even the primary issue at stake.indeed, the point about identifying the source of disagreement is worth expanding. although privacy considerations are generally important in policy discussions (both public and private), there are a number of logically prior antecedents. the most important of these antecedents is the desirability of any particular policy goal in the rst place. some particular contemplated action may have many and deep privacy implications, but if the goal to be served by that action is an inappropriate onešhowever that may be decidedšit may not be necessary to address the privacy implications at all. if health insurance were a right to be enjoyed by all citizens, the debate over access to dna information by insurance companies would have a much different character. a program that collects the personal information of elbonianamericans has denite privacy implications. but if the goal of the program is to enable the identication of elbonianamericans for possible deportation, it may make sense for the nation to assess whether or not the deportation of elbonianamericans is a good or a bad policy goal.the second component of a transparency strategy is discussed below.finding 13. when privacy is at issue, bland assurances that privacy will not be harmed offered by policy makers can do more to raise skepticism than would honest assessments of tradeoffs.transparency also requires that tension be recognized when it is present. recognizing that there is often tension in a ﬁprivacy versus xﬂ relationship (e.g., personal privacy versus video surveillance for transportation safety), it is important to make clear how the various stakeholders view the situation and the factors that decision makers consider. public debate and discourse are undermined when policy makers simply deny the existence of tradeoffs between privacy and other values and assert without evidence that it is possible to ﬁhave it all.ﬂ policy makers of good conscience and good will can legitimately come to different conclusions about the right balance in any given situation, but it is unreasonable to assert without evidence that there will be no diminution or narrowing engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.322 engaging privacy and information technology in a digital ageof privacy if and when these other values are given a new and higher priority.5it is true that in making a tradeoff, it is sometimes possible to develop privacyrespecting solutions that reduce the con˚ict between privacy and other values. for example, policy makers may decide to make greater use of a system that collects certain kinds of personal information on individuals in order to enhance energy efciency in a building. but the potential infringement on privacy may well come from the longterm retention of such informationšand so restructuring the system to erase that information after it is no longer necessary (e.g., after an hour, when it is no longer needed to manage the building heating and air conditioning system) might mitigate the privacy concerns substantially without damaging the goal of conserving energy. drivers on toll roads need to be charged, but the time at which they enter or leave a toll road is irrelevant to whether or not they have paid. thus, a toll system that does not record entry and exit times cannot be used to calculate the driver™s speed between those two points and thus cannot be used as a basis for issuing speeding tickets.6 in general, explicit attention to privacy considerations (e.g., collecting only information that is directly relevant, or showing only the degree of intrusiveness and invasiveness necessary for the stated goal) can reduce the privacy downside for some proposed action.if a solution is available or developed that does mitigate privacy concerns, it should be discussed explicitly, so that there is clear evidence for what would otherwise be an empty assertion made simply for public relations purposes. and even in the cases in which no mitigating solution is available, an explicit discussion of costs to privacy and benets regarding the other values would be much more credible than stock assertions.if the public is to give up some measure of privacy, there should be a reasonable expectation of public information about the benets in other dimensions that will result from that loss. because a loss is certain (by denition), it is not sufcient to offer speculative benets as justication. the benets themselves may be uncertain because they are probabilistic, 5 perhaps a prior issue is whether or not some proposed action should be taken at all, irrespective of privacy considerations. for example, if a proposed action is demonstrably not costeffective in achieving some goal, privacy considerations may not be relevant at all, since decision makers in both the private and the public sectors should not be taking costineffective actions in the rst place.6 of course, one might argue that the use of a toll system to catch speeders (but only certain types of speeders) is an appropriate and efcient use of technology designed for other purposes, and that such ﬁdual useﬂ should be encouraged rather than discouraged. from a public policy perspective, this may well be truešbut the committee believes that in such cases, both purposes ought to be openly discussed, and if the outcome of the public policy process is that both uses are determined to be desirable, then so be it.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 323but at the very least the analytical basis that led to the decision must be publicly articulated.put differently, it is necessary to make explicit the evidentiary or other basis for concluding that the action in question will serve a stated policy goal. while there is a reasonable debate to undertake about an action that compromises privacy to some extent and that demonstrably advances a stated policy goal, it makes little sense to take an action that does the former but not the latter. if some action does not demonstrably advance a stated policy goal, it may not be necessary to consider the privacy implications of that action at all, as the action may not make sense for reasons entirely unrelated to privacy. yet in the rush to ﬁdo somethingﬂ in response to a shocking event, privacycompromising actions are often taken that have little real relationship to advancing a stated goal.finding 14. privacyinvasive solutions to public policy problems may be warranted, but when they are implemented as measures of rst rather than last resort, they generate resistance that might otherwise be avoided if other alternatives were tried rst.privacyrespecting solutions that reduce the cost of making a tradeoff are often difcult to nd. but there is one type of solution that is worth special noticešthe approach in which privacyreducing actions are employed as a last rather than a rst resort. before demanding solutions that require that citizens provide more personal information, policy makers crafting solutions to problems would do well to x problems by making more effective use of the personal information to which they already have access. for example, if the bottleneck in processing intercepted phone calls is the lack of linguists that understand the language in which those calls are made, it may not make much sense to intercept even more calls until more linguists are available.10.5 approaches to privacy in the information ageas noted above, the pressures on privacy are many and the inherent protections for privacy few. it is thus worth considering explicit approaches that can be used to support privacy.10.5.1 principlesthe committee identied a number of principles that it believes should guide efforts to achieve an appropriate balance between privacy and other issues. these include the following:ł avoid demonization. most threats to privacy do not come from funengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.324 engaging privacy and information technology in a digital agedamentally bad people with bad intentions. rather, they are consequences of trying to address real needs (such as national security, law enforcement, open government, business efciency, fraud prevention, and so on) either without giving adequate thought to the privacy consequences, or because they assign to the other needs a higher priority than they assign to privacy. although demonization of an opponent is a staple of today™s political rhetoric, it tends to make compromise and thoughtful deliberation difcult.ł account for context and nuance. as noted in section 10.1 and elsewhere in this report, privacy is a complicated subject with many nuances. whose privacy is at issue? against what parties? what information is in question? what are the circumstances? what precedents may be created? in the policymaking process (whether for public policy or organizational policy), taking these nuances into account will often be necessary if common ground is to be found. without context and nuance, the debate quickly polarizes into ﬁproprivacyﬂ and ﬁantiprivacyﬂ/ﬂproxﬂ camps.7 (for x, substitute any issue of public importancešsecurity, law enforcement, the economy, for example.)ł respect complexity. privacy is a moving target, as the numerous social and technical factors with which it is intertwined change over time. many choices made today to settle some privacy issue will almost certainly lead to surprising results and require further adjustment, either by modifying the original choices, or by adding further mechanisms to compensate for newly discovered problems. thus, solutions to privacy problems are more likely to be successful if they can begin with modest and simple steps, guided by wellformulated principles that produce operational realworld experience and understanding that can then be used to shape further actions, always with an eye to the dynamic nature of the topic.ł be aware of longterm costs and risks. as noted in section 3.10, privacy protections arešin practicešbased on a mix of culture, technology, and policy. but all systems are deployed in a costsensitive environment, and it is important to consider how economic cost might have an impact on this mix. on the one hand, retrotting privacy protections to information systems or business practices is often more expensive than design7 an analogy from the world of computer security may be helpful. operating systems often have facilities for protecting the privacy of les. if the privacy question is formulated simply as, should other people be able to have access to a given user™s les?, most people would say no. but if the question is decomposed into ner questions such as, who can know about the existence of this particular le?, who has permission to read its contents?, who can change its contents?, and, who can change these permissions?, it becomes possible to have a more useful discussion about privacy requirements and the necessary system capabilities to support those requirements.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 325ing these systems or practices from the start to be privacyprotective or respecting. indeed, there is substantial empirical experience that indicates that this is the case. on the other hand, it is clearly simpler and less expensive to design systems or business practices without attention to privacy at all. because the policy process often seems easier to manipulate than technological development (particularly after the technology is in place), the temptation is great to rely heavily on policy to protect privacy. the committee believes that in the long run, policybased privacy protections introduced without providing for adequate technology enforcement are likely to result in unintended violations of privacy. (it is also axiomatic that absent an adequate policy framework for protecting privacy, the best technology is unlikely to succeed.) this scenario is likely to result in costly retrots and may also result in unfavorable publicity and perhaps signicant economic liability. thus, organizations that handle personal information are well advised to invest up front in adequate technological privacy protection from the very beginning.10.5.2 individual actionsfinding 15. individuals can take steps to enhance the privacy of their personal information. they can also become better informed about the extent to which their privacy has been compromised, although the effectiveness of these measures is bound to be limited.individuals have some ability to take steps to enhance the privacy of their personal information, and to be better informed about the extent to which their privacy may be compromised (section 3.8.1).8 most of these steps involve tradeoffs involving convenience, access, and cost. individuals can tailor their privacy protection practices to their specic situation. as in the physical world, people whose privacy has been compromised with harmful, costly, or inconvenient results will almost certainly increase the degree of inconvenience and cost they are willing to accept for greater protection in the future.to reduce the amount of personal information that may be compromised, individuals can:ł improve the security of their local computing environments using tools such as rewalls and encryption;ł make use of remailers, proxies, and other anonymization techniques if anonymity is desired;8 a fuller discussion of measures that individuals may take to thwart surveillance can be found in gary marx, ﬁa tack in the shoe: neutralizing and resisting the new surveillance,ﬂ journal of social issues 59(2):369, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.326 engaging privacy and information technology in a digital ageł use secure and encrypted email;ł take antiphishing measures to reduce the likelihood of identity theft;ł install software from reliable sources to block thirdparty cookies, web bugs, and other devices that enable the tracking of activity across various web sites; andł install software that reliably deletes all relevant information from one™s computer when one deletes a le.to reduce the amount of unwanted information that they receive, individuals can:ł block spam email;ł employ popup blockers and ad blockers;ł use special email addresses for important correspondents and faked or infrequently checked email addresses for others;ł take advantage of all optout opportunities, such as donotcall lists (for both home and mobile numbers) and options for not receiving postal or electronic mail;ł put credit freezes or fraud alerts on their credit reports; andł avoid using tollfree numbers and block callerid when making calls.to monitor one™s online privacy, individuals can:ł search the internet periodically for sensitive personal information, such as one™s social security number or an unlisted phone number from an anonymized account or a computer that cannot be traced to the individual. (socalled vanity searches, in which one searches the internet for references to one™s name, can also be revealing to many people.) one may (or may not) be able to do anything about the online existence of such information, but at least one would know that it was available in such a fashion;ł periodically monitor their credit ratings; andł use personal email addresses that are specically created to monitor the implementation of policies of a web site operator. for example, a site such as merchant.com might post a privacy policy that said, ﬁyour email address will never be given to anyone else.ﬂ given the volume of spam email that one receives, it would ordinarily be difcult to trace to a specic merchant the unauthorized release of one™s email address. however, if one used an email address that was tailored for the site in question, receipt of a marketing email from anyone else to that address would be convincing proof that the site did not adhere to its posted policy.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 327additional steps for individuals can be found on the web sites of the electronic frontier foundation,9 the center for democracy and technology,10 and the electronic privacy information center.11in general, the actions described above are technically orientedšthat is, they protect the individual only against technologically based intrusions of privacy (though they would do a better job of doing so if they were less cumbersome in actual use), and whether they are worth the trouble depends on the individual™s costbenet calculus about the value of privacy. but they cannot defend against intrusions of privacy that occur as a matter of policy or routine bureaucratic practice (e.g., routine sharing of information that is allowable under the law or policy). and they do not in general enable the user to know if these actions are effective in protecting one™s privacy.in such instances, the only privacyenhancing measure that one can take as an individual is to provide false or incomplete information when personal information is requested. of course, providing false information has other consequences. in some cases, it is illegal to provide false information (as on a tax return). in other cases, providing the false information may result in being denied certain benets that providing true information would enable. in addition, providing false information may not be an entirely reliable technique for protecting one™s identity, because some datacorrecting techniquesšintended to catch errors made when the data are recordedšmay also be able to correct false information under some circumstances. more to the point, an individual is unlikely to know if his or her attempt to provide false information is in fact succeeding in protecting his or her identity.it is important to note that in identifying actions that individuals can take to enhance their privacy, the committee is not ﬁblaming the victimﬂ or arguing that individuals who fail to take such actions are solely or even primarily responsible for invasions of their privacy. the fact that individuals can take steps to protect their personal information does not imply that other societal actors, such as government and private organizations, have no responsibility for privacy. indeed, private and personal actions are not equally available to all members of society, especially in contexts of inequality where the resources for selfprotection are not equally distributed, and so personal actions may need to be supported by the kinds of organizational and public policy actions considered below.9 see http://www.eff.org/privacy/effprivacytop12.html.10 see http://www.cdt.org/privacy/guide/basic/topten.html.11 see http://www.epic.org/privacy/2004tips.html.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.328 engaging privacy and information technology in a digital agerecommendation 1. if policy choices require that individuals shoulder the burden of protecting their own privacy, law and regulation should support the individual in doing so.if a policy choice is made that places the onus on individuals to fend for themselves, the individual™s ability to do so should be facilitated by law and regulation. that is, all reasonable efforts must be made to inform the individual about the options available and the consequences of selecting any of those options. (reasonableness necessarily takes into account an assessment of the relative costs and benets of providing such information.) such a precedent exists in the legislative mandate for credit monitoring agencies to provide free credit reports to consumers periodically and for consumers to demand corrections for erroneous entries in their credit reports. in the future (and simply for illustrative purposes), law and regulation could mandate requirements that published privacy policies be easily readable (e.g., at a 7thgrade reading level), that statements related to repurposing illustrate possible secondary purposes, and that information is well publicized about technical options for individuals to protect their privacy.10.5.3 organizationbased actionsfinding 16. selfregulation is limited as a method for ensuring privacy, although it nevertheless offers protections that would not otherwise be available to the public.organizations that use technology to manage large volumes of personal information (both in the private sector and in government) can establish privacy policies (e.g., on web sites) that specify selfimposed restrictions on their use of information that they collectšor could collectšabout those with whom they interact. the desire to maintain public trust and good will is a powerful motivator for many organizations to protect privacy on a voluntary basis.to strengthen the force of privacy assurances, as well as to make it easier for organizations to establish appropriate privacy protections, organizations that are committed to particular standards and to mutual policing have banded together in associations such as truste,12 bbbonline,13 and the direct marketing association14 in an attempt to improve their members™ public images by forming larger ﬁregions of trust.ﬂ in general, 12 see http://www.truste.org/.13 see http://www.bbbonline.org/.14 see http://www.dmaconsumers.org/.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 329members of these organizations agree to adhere to established privacy principles and agree to comply with a variety of oversight and consumer resolution procedures.some argue that selfregulating associations have at least the appearance and perhaps embody the fact of ﬁthe fox guarding the henhouse,ﬂ and even selfregulation advocates recognize that such associations cannot provide a complete solution. for example, the existence of a privacy policy per se does not indicate whether that policy actually protects privacy. membership is voluntary, and so organizations whose regular practices are very different from the voluntary guidelines may not even apply for membership or may have been kicked out because of violations. moreover, resources available for policing depend in part on dues paid by the members, and to encourage a large membership, there is a temptation to keep dues low and policing light. nevertheless, a declared policy is often an organization™s rst step toward a meaningful privacy protection regime.recommendation 2. organizations with selfregulatory privacy policies should take both technical and administrative measures to ensure their enforcement.an important next step is the enforcement of a declared privacy protection policy. this is a nontrivial task, and even the most stringent privacy policies cannot provide protection if they are subverted by those with access to the personal information, either legitimate access (the insider threat) or illegitimate access (the hacker threat). thus, data custodians almost always use some form of technical protection to limit access to, and use of, personal information (e.g., passwords and other access control devices to prevent unauthorized people from accessing protected data).sometimes this is as simple as using le or database system access controls, or encrypting the data and limiting access to the decryption keys, or even using physical measures such as guards and locks for a facility that houses personal information. but more sophisticated measures may be needed. section 3.8 describes several technologies relevant to maintaining the privacy of personal information in an organizational setting: auditing queries to databases containing personal information, designing systems whose data requirements and data retention features are narrowly tailored to actual needs, restricting access to information from which individual identities can be inferred, and implementing machinereadable privacy policies as a way of better informing users about the nature of those policies.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.330 engaging privacy and information technology in a digital ageadministrative measures are also necessary to support enforcement. for example, administrative actions are needed to promulgate codes of behavior and procedures that govern access to stored personal information. penalties for violating such codes or procedures are also needed, as technological enforcement measures sometimes fail or do not cover certain eventualities.recommendation 3. organizations should routinely test whether their stated privacy policies are being fully implemented.because automated privacy audits are rarely comprehensive (except at great expense), redteaming of an organization™s privacy policy and its implementation is often in order. in the security domain, redteaming refers to the practice of testing an organization™s operational security posture through the use of an independent adversary team whose job it is to penetrate the defenses of the organization. redteaming in a privacy context refers to efforts undertaken to compare an organization™s stated privacy policy to its practices. in general, redteaming for privacy will require considerable ﬁinsiderﬂ accessšthe ability to trace data ˚ows containing personal information. as in the case of security redteaming, results of a privacy redteaming exercise need to be reported to senior management, with a highlevel executive in place with responsibility for ensuring and acting as an advocate for privacy as an individual and a collective good.recommendation 4. organizations should produce privacy impact assessments when they are appropriate.it is often the case that information practicesšadopted entirely for nonprivacyrelated reasonsšhave unforeseen or surprising impacts on privacy that may not even have been considered in the adoption of those practices. inadvertent effects on privacy could be reduced if privacy were systematically considered before adopting new information practices or changing existing practices. privacy impact assessmentsšanalogous to environmental impact assessmentsšcan be established as a regular part of project planning for electronic information systems. explicit attention to privacy issues can be valuable even if these assessments remain internal to the organization. however, public review can encourage consideration from other perspectives and perhaps reduce unintended consequences that could generate additional rounds of feedback, costly retrotting, and/or unnecessary erosion of privacy.federal agencies are already required to produce privacy impact assessments (pias) under the egovernment act of 2002. illustrative pias engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 331produced by two agencies can be found at the department of homeland security and national science foundation web sites.15 but the advantages of producing pias are not limited to government agencies, and the committee believes that they may have considerable utility in the context of private organizations as well.recommendation 5. organizations should strengthen their privacy policies by establishing a mechanism for recourse if an individual or a group believes that they have been treated in a manner inconsistent with an organization™s stated policy.finally, the limits on selfregulation must be acknowledged. as noted in section 9.2.4, organizations are sometimes willing to violate their stated policies without advance notice under some circumstances, especially when those circumstances are both particularly exigent and also unanticipated. for these reasons, it is important to consider mechanisms other than selfregulation to protect privacy. public policy is one source of such mechanisms. but an organization that establishes a mechanism for recourse should its policy be violated does much to enhance the credibility of its stated policy.recommendation 6. organizations that deal with personal information should establish an institutional advocate for privacy.organizations that deal with personal information would benet from some kind of institutional advocacy for privacy, as many healthcareproviding organizations have done in response to the health insurance portability and accountability act of 1996 (section 7.3.4). by analogy to an organizational ombudsman who provides highlevel oversight of everyday activities conducted in the name of the organization that might not be entirely consistent with the organization™s stated policies or goals, an organizational privacy advocate could have several roles. for example, it might serve as an internal check for the organization, ensuring that the organization has and makes public some stated privacy policy. it might also help to ensure that the privacy policy is actually followed by the organization. internally, it might serve a redteam role, pushing on the 15 the nsf web site includes a pia for its personnel security system and photo identication card system (http://www.nsf.gov/publications/pubsumm.jsp?odskey=pia0503); the dhs web site includes a pia for the usvisit program (for the automatic identication of nonimmigrants exiting the united states at certain land points of entry; see http://www.dhs.gov/interweb/assetlibrary/privacypiausvisitupd1.pdf).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.332 engaging privacy and information technology in a digital ageprivacy mechanisms instituted by the organization and testing them for their adequacy. finally, it could be responsible for the generation and periodic review of privacy impact statements, which would be reviews of the privacy implications of new programs or policies being instituted by an organization. it could also help anticipate emerging privacy issues.some precedents for institutional advocates do exist, although their function and purpose vary. under the bankruptcy abuse prevention and consumer protection act of 2005, a consumer privacy ombudsman must be appointed by the bankruptcy court before certain kinds of consumer information are sold or leased. veried identity pass, inc., a private rm that offers a voluntary, biometric ﬁfast passﬂ system to support the transportation security administration™s registered traveler program for expedited security screening at airports, has an independent, outside privacy ombudsman whose responsibility is ﬁto investigate all privacy complaints, gather the facts, and respond to members, as well as to post responses publicly and prominently on [the rm™s] website.ﬂ16 bell canada has designated a privacy ombudsman to oversee compliance with the bell code of privacy.17a number of companies have created the position of chief privacy ofcer. in those companies where this title does not primarily designate a public relations position that puts the best face on company privacy practices or a legal position that merely ensures compliance with existing privacy laws, the chief privacy ofcer can serve as an effective organizational advocate who ensures highlevel management attention to privacy issues, serves as a liaison to other privacy expert stakeholders, and anticipates future needs. this role is symbolic as well as instrumental.10.5.4 public policy actionsfinding 17. governmental bodies have important roles to play in protecting the privacy of individuals and groups and in supporting and ensuring informed decision making about privacy issues.historically, privacy concerns in the united states have most often been tied to government infringement of privacy at various levels. many have also noted that government is at least willing, under many circumstances, to trade off privacy and other rights in pursuit of some other goal or objective. this has meant that in some cases government agencies have undertaken actions and activities that have violated citizen privacy and then subsequently noted the impropriety of such actions (e.g., the forced 16 see http://˚yclear.com/privacyombudsman.html.17 see http://www.bell.ca/support/prscsrvgnlprivacy.page.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 333relocation of japaneseamericans during world war ii and the use of census data to identify such individuals (section 9.3); the domestic surveillance in 1960s of participants in the civil rights movement). against this historical perspective, a certain skepticism about the role of government as a guarantor of privacy is not surprising and may be helpful.nevertheless, the committee believes that various governmental bodies have important roles to play in protecting the privacy of individuals and groups, and in ensuring that decisions concerning privacy are made in a more transparent and wellinformed fashion. as citizens become more concerned with privacy issues, it will become increasingly important for governmental agencies at all levels to address these concerns. perhaps more importantly, actions and decisions of governmental entities on a variety of issues are likely to have signicant privacy impacts. whether it is something as obvious as decisions or policies concerning national security or as seemingly minor as making publicrecord information available on the world wide web, a great many actions taken by governments have privacy implications. consequently, it is appropriate that privacy be at least a consideration if not a priority at all levels of government decision making.10.5.4.1 managing the privacy patchworkfinding 18. the u.s. legal and regulatory framework surrounding privacy is a patchwork that lacks consistent principles or unifying themes. a less decentralized and more integrated approach to privacy policy in the united states could bring a greater degree of coherence to the subject of privacy.the u.s. legal and regulatory framework surrounding privacy is a patchwork that lacks commitment to or guidance from a set of consistent principles or unifying themes. because of the ad hoc way in which privacy has been approached by most policy makers, the current sets of privacyrelated laws, rules, and regulationsšat all levels of governmentšare confusing at best and inconsistent at worst.given the decentralized manner in which the united states has dealt with privacy issues (section 4.4), this state of affairs is hardly surprisingšand yet it has major costs. this patchwork is more than just a source of frustration and confusionšit is also inefcient and expensive. the current regulatory patchwork, in which laws governing privacy differ across the jurisdictions in which rms engage in business transactions, increases the economic costs of attending to privacy that these rms must bear.the committee believes that a less decentralized approach to privacy policy in the united states could bring substantial benets for the understanding and protection of privacy. only with such an approach engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.334 engaging privacy and information technology in a digital agecan different priorities and tensions be reconciled. at the same time, the committee cautions that less decentralization can also lead to a lowestcommondenominator approach to privacy, which might well weaken privacy protections enjoyed by some states. further, the committee notes that in an increasingly global marketplace, some degree of harmonization of u.s. privacy law with the privacy laws and regulations of other nations is likely to be necessary when businessrelated data ˚ows between the united states and these other nations involve personal information.10.5.4.2 reviewing existing privacy law and regulationsrecommendation 7. the u.s. government should undertake a broad, systematic review of national privacy laws and regulations.as a rst step in the direction of a less decentralized approach to privacy policy, the u.s. government should undertake a systematic review of the laws and regulations that affect the level and quality of privacy that americans enjoy. this review should address:ł areas of overlap and con˚ict in current national privacy law and regulationšspecial attention should be paid to the relationship of national law to state and local law extensively enough to generate a representative picture of those relationships;ł assessment of the nature and extent of gaps between stated policies and implementation, and the causes of such gaps;ł areas of privacy concern that the current legal and regulatory framework leaves unaddressed, such as the gathering, aggregation, and use of personal information by companies and other organizations that are currently not covered to any signicant degree by any form of privacy regulation;ł a clear articulation of the value tradeoffs that are embedded in the current framework of laws and regulation, especially where those tradeoffs were not made explicit at the time of adoption;ł the economic and social impact, both positive and negative, of current privacy law and regulation;ł the extent to which the personal information of americans held by various parties is covered by the principles of fair information practices;ł the interplay between state and federal privacy laws, taking into consideration matters such as the scope and nature of state laws as compared to federal laws; andł the interplay between domestic and foreign privacy laws, taking into consideration matters such as the scope and nature of ˚ows of personal information to and from the united states and instances in engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 335which differences between foreign laws and domestic law might call for harmonization.if undertaken in an authoritative manner, such a review would simplify the task of knowing how to comply with privacy regulations and might also make such compliance less expensive. further, it would help individuals to understand their privacy rights, and it could facilitate such enforcement of those rights as is necessary for their enjoyment. by making the protection of privacy more efcient, more transparent, and more consistent, all members of the community should benet. by anticipating future developments, future problems might also be avoided or minimized.as to which part of the u.s. government should undertake this review, the privacy commissioner™s ofce (the subject of recommendation 14) is an obvious locus of such activity. but the recommendation for undertaking a review is independent of recommendation 14, and what part of the u.s. government undertakes this review is less important than that it be undertaken.10.5.4.3 respecting the spirit of the lawrecommendation 8. government policy makers should respect the spirit of privacyrelated law.the united states is a nation governed by law. it is thus axiomatic that the rule of law must be the supreme authority of the land. common discourse recognizes the distinction between the spirit and the letter of the law, and the committee believes that both the spirit and the letter of the law play important roles in the protection of privacy. conformance to the latter is what is needed ﬁto not break the law.ﬂ the spirit of the law is necessarily more imprecise than the letter of the law, but if fully respected, the spirit of the law has operational implications as well. for example, a number of laws provide for the condentiality of data collected by certain federal agencies (e.g., the census bureau, the internal revenue service, and so on). to the extent that government policy makers wish to merge protected data with commercial and other nonprotected data in order to identify individuals, the committee believes that such actions are not consistent with the spirit of data condentiality guarantees. respecting the spirit of the law would result in decisionmaking processes that give legal limitations and constraints a wide berth rather than ﬁpushing the envelopeﬂ and ﬁlooking for loopholes.ﬂ this approach supports policy makers who engage in open and public debate and discussion when engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.336 engaging privacy and information technology in a digital agecircumstances change rather than use such circumstantial changes to advance longstanding agendas that were previously blocked by public opposition.note, too, that these comments apply irrespective of any particular policy outcome or preference. they are a call for deliberation and moderation rather than hasty overreactionšwhether the issue is revelation of a government abuse (that might lead to excessive curtailment of law enforcement or national security authorities) or a terrorist incident (that might lead to excessive intrusions on privacy). and they also imply a need to build into policy some mechanisms, such as ﬁsunset requirements,ﬂ that facilitate the periodic revisiting of these issues.10.5.4.4 the relevance of fair information practices todayfinding 19. the principles of fair information practice enunciated in 1973 for the protection of personal information are as relevant and important today as they were when they were rst formulated.principles of fair information practice were rst enunciated in 1973 (section 1.5.4). at the time, they were intended to apply to all automated personal data systems by establishing minimum standards of fair information practice, violation of which would constitute ﬁunfair information practiceﬂ subject to criminal penalties and civil remedies. pending legislative enactment of such a code, the report also recommended that the principles be implemented through federal administrative action.in 1974, the privacy act (section 4.3.1) was passed, applying these principles to personal information in the custody of federal agencies. in addition, the fair credit reporting act (rst passed in 1970 and amended thereafter several times) applies these principles to the accuracy, fairness, and the privacy of personal information assembled by private sector creditreporting agencies. many other private sector organizations have also adopted privacy policies that trace their lineage to some or all of the principles of fair information practice.since 1973, the environment surrounding the gathering and use of personal information has changed radically. information technology is increasingly networked. private sector gathering and use of personal information have expanded greatly since the early 1970s, and many private sector organizations that manage personal information, such as data aggregators (section 6.5), are not covered by fair information practices, either under the law or under a voluntary privacy policy based on these principles. national security considerations loom large as well, and the risks of compromising certain kinds of personal information are arguably greater in an environment in which terrorism and identity theft go hand in hand (see box 4.1 in chapter 4).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 337for these reasons, the committee believes that the principles of fair information practice are as relevant todayšperhaps more sošfor the protection of personal information as they were when they were rst formulated.recommendation 9. principles of fair information practice should be extended as far as reasonably feasible to apply to private sector organizations that collect and use personal information.although some of the restrictions on government regarding the collection and use of personal information are not necessarily applicable to the private sector, the values expressed by the principles of fair information practice should also inform private sector policies regarding privacy.reasonableness involves a variety of factors, including an assessment of the relative costs and benets of applying these principles. this recommendation is thus consistent with the original intent behind the 1973 department of health, education, and welfare report covering all organizations handling personal information (not just government agencies),18 although the committee is explicitly silent on whether the legislative enactment of a code of fair information practices is the most appropriate way to accomplish this goal.for the sake of illustration, another approach to encourage the broad adoption of fair information practices might be based on the ﬁsafe harborﬂ approach described in section 4.7. that is, a private sector organization that collected or used personal information would selfcertify that it is in compliance with safe harbor requirements, which would be based on the principles of fair information practice. periodic assessment of the extent to which mechanisms for ensuring enforcement of these requirements have been developed and applied would be provided to the public. adherence to these requirements would similarly take the form of government enforcement of the federal and state statutes relevant to unfair and deceptive business practices. in return, complying organizations could be granted immunity from civil or criminal action stemming from alleged mishandling of personal information.within the domain of fair information practices, the committee calls attention to two particularly important topics: the repurposing of data and the notion of choice and consent.18 u.s. department of health, education, and welfare, records, computers and the rights of citizens, report of the secretary™s advisory committee on automated personal data systems, mit press, cambridge, mass., 1973.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.338 engaging privacy and information technology in a digital agerecommendation 10. to support greater transparency into the decisionmaking process regarding repurposing, guidelines should be established for informing individuals that repurposing of their personal information might occur, and also what the nature of such repurposing would be, and what factors would be taken into account in making any such decision.while repurposing is not necessarily privacy invasive (e.g., medical information gathered for clinical decision making can be used to conduct epidemiological research in ways that are privacy preserving), there is an unavoidable tension between a principle that one should know how personal information collected from him or her will be used before it is collected and the possibility that information collectors might want to use that information in the future for a purpose that cannot be anticipated today. while this tension cannot necessarily be resolved in any given instance, it should be possible to provide greater transparency into the resolution process. accordingly, guidelines should be established for informing individuals that repurposing might occur, and also about the nature of such repurposing and what factors would be taken into account in making any such decision. educating the public about the nature of this tension is also important, and might be undertaken as part of the effort described in recommendation 14.recommendation 11. the principle of choice and consent should be implemented so that individual choices and consent are genuinely informed and so that its implementation accounts fairly for demonstrated human tendencies to accept without change choices made by default.even with mandated disclosure, individuals have choices about whether or not they provide information. but only informed choicešchoice made when the deciding individual has an adequate amount of the important information that could reasonably affect the outcome of the choicešis morally and ethically meaningful. individuals are entitled to be informed about answers to the questions articulated in section 10.1šand parties acquiring personal information are morally and ethically obligated to provide such information to subjects. vague notices that obfuscate and presume high educational levels of their readers do not satisfy these obligations, even if they do technically comply with legal requirements. moreover, as the issues of data collection become more complex, the task of providing usable and comprehensible information increases in difculty.the importance of default choices has been empirically demonstrated. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 339as noted in section 2.2.5, the endless debate between the desirability of optin and optout regimes is a debate over which of these should be the information subject™s default choice. in fact, it is easy to circumvent this hobson™s choice by requiring the individual to make an explicit choice to optin or to optout. recall that opting in means that the individual must afrmatively allow the primary data recipient to share his or her information, while opting out means that the individual must afrmatively disallow such sharing of information. but consent requirements could be formulated so that the individual had to choose one of these options explicitlyšeither ﬁi choose to share informationﬂ or ﬁi choose to not share informationﬂšand so that the selection of one of these options would be as essential to processing the form as the individual™s social security number would be for a nancial institution. absent a choice, the form would be regarded as null and void, and returned to the individual for resubmission.recommendation 12. the u.s. congress should pay special attention to and provide special oversight regarding the government use of private sector organizations to obtain personal information about individuals.as noted in chapter 6, government use of private sector organizations to obtain personal information about individuals is increasing. fair information practices applied to data aggregation companies would go a long way toward providing meaningful oversight of such use. however, even if data aggregation companies are not covered by fair information practices in the future (either directly or indirectlyšthat is, through the extended application of fair information practices to government agencies that use such companies), the committee recommends that such use receive special attention and oversight from the u.s. congress and other appropriate bodies so that privacy issues do not fall in between the cracks established by contracts and service agreements.to illustrate what might be included under attention and oversight, the committee notes that two oversight mechanisms include periodic hearings (in this case, into government use of these organizations) and reporting requirements for u.s. government agencies that would publicly disclose the extent and nature of such use.10.5.4.5 public advocates for privacyfinding 20. because the benets of privacy often are less tangible and immediate than the perceived benets of other interests such as public security and economic efciency, privacy is at an inherent disadvantage when decision makers weigh privacy against these other interests.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.340 engaging privacy and information technology in a digital ageas noted in section 10.4, privacy offers benets that are often less tangible, visible, or immediate than those benets offered by public safety, economic efciency, and so on. the consequence is that privacy is at an inherent disadvantage in the decisionmaking competition for priority and resources.for other issues in which shortterm pressures tend to crowd out longerterm perspectives, the mechanism of institutionalized advocacy has found some success. for example, the environmental protection agency was established to provide a bureaucratic counterweight to the forces of unrestricted economic development inside and outside government.today, a number of privately funded organizations, such as the electronic privacy information center and the electronic frontier foundation, act as generalized advocates for privacy in the public policy sphere. such groups, while an important ingredient in the debate concerning privacy, are generally focused at the national level, and resource limitations mean that they focus primarily on the most egregious threats to privacy if and when they come to notice. perhaps most importantly, they do not have institutionally established roles in the public policy process, and they achieve success primarily based on the extent to which they can mobilize public attention to some privacy issue. in contrast, an organizational privacy advocate would have better access to relevant information from government agencies and possibly private organizations under some circumstances, legal standing, and greater internal legitimacy, thus enabling it to play a complementary but no less important role.recommendation 13. governments at various levels should establish formal mechanisms for the institutional advocacy of privacy within government.institutionalized advocacy can take place at a variety of different levelsšat the level of individual organizations, local government, federal agencies, and so on. an example of institutionalized advocacy is the privacy ofce of the u.s. department of homeland security (dhs), whose mission is to minimize the impact of departmental activities on the individual™s privacy, particularly the individual™s personal information and dignity, while achieving the mission of the dhs.19 the dhs privacy ofce is the focal point of departmental activities that protect the collection, use, and disclosure of personal and departmental information. in addition, the privacy ofce supports the dhs data privacy and integrity advisory committee, which provides advice on programmatic, policy, 19 this description is based on the dhs description of its privacy ofce, available at http://www.dhs.gov/dhspublic/interapp/editorial/editorial0338.xml.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 341operational, administrative, and technological issues within dhs that affect individual privacy, as well as data integrity and data interoperability and other privacyrelated issues. the privacy ofce also holds public workshops to explore the policy, legal, and technology issues surrounding government™s, private sector™s, and individuals™ information and the intersection of privacy and homeland security.a common complaint about standards issued at a national levelšregardless of subjectšis that they do not take into account local contexts and perspectives, and a ﬁonesizetsallﬂ mentality can easily lead to absurdities that undercut both public support and the spirit of the original standard. but local communities can have their own institutional advocates, and it may make sense to consider the idea of local enforcement of national standards as a way to obtain some of the efciencies afforded by national standards and the benets of local awareness of how those standards might sensibly be implemented in practice.recommendation 14. a national privacy commissioner or standing privacy commission should be established to provide ongoing and periodic assessments of privacy developments.as discussed in earlier chapters (especially chapters 1 and 3), rapid changes in technology or in circumstances can and often do lead to changes in societal denitions of privacy and in societal expectations for privacy. solutions developed and compromises reached today may be solidly grounded a year from now, but 3 years is enough for a new ﬁkiller appﬂ technology to emerge into widespread use (thus changing what is easily possible in the sharing of information), and a decade is enough for today™s minority political party to become the majority in both the legislature and the executive branch. any of these eventualities coming true is bound to require a new and comprehensive examination of privacy issues. thus, it is unrealistic to expect that privacy bargains will become settled ﬁonce and for allﬂ or that expectations will be static. dynamic environments require continuous attention to privacy issues and readiness to examine takenforgranted beliefs that may no longer be appropriate under rapidly changing conditions.of signicance is the likelihood that the effects of changes in the environment will go unnoticed by the public in the absence of some wellpublicized incident that generates alarm. even for those generally knowledgeable about privacy, the total impact of these developments is difcult to assess because rapid changes occur in so many different sectors of the community and there are few vantage points from which to assess their cumulative effects.for these reasons, it makes sense to establish mechanisms to ensure engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.342 engaging privacy and information technology in a digital agecontinuing highlevel attention to matters related to privacy as society and technology change and to educate the public about privacy issues. although a number of standing boards and committees advise individual agencies on privacyrelated matters (e.g., the information security and privacy advisory board of the department of commerce, the data privacy and integrity advisory committee of the department of homeland security), their inputs arešby designšlimited to the concerns of the agencies with which they are associated. the committee believes that at the federal level, a ﬁprivacy commissionerﬂ type of ofce or a standing privacy commission would serve this role very well. a permanent governmental body with the charter of keeping discussions about privacy in the foreground of public debate and discussion could do much to reduce the number and intensity of unwanted privacyrelated surprises that occur in the future.areas of focus and inquiry for such an ofce could include the following:ł a comprehensive review of the legal and regulatory landscape, as described in section 10.5.4.2. such a review might be undertaken periodically so that changes in this landscape could be documented and discussed.ł trends in privacyrelated incidents and an examination of new types of privacyrelated incidents. prior to the widespread use of the internet, certain privacy issues, such as those associated with online ﬁphishing,ﬂ never occurred. because the deployment of new technologies is often accompanied by new privacy issues, warning of such issues could help the public to better prepare for them. documented trends in privacyrelated incidents would also provide some empirical basis for understanding public concerns about privacy. note also that ﬁincidentsﬂ should be dened broadly, and in particular should not be restricted to illegal acts. for example, ﬁincidentsﬂ might include testing of specic privacy policies for readability, and with an appropriate sampling methodology information could be provided to the public about whether the average readability level of privacy policies was going up or down.ł celebration and acknowledgment of privacy successes. much as the department of commerce celebrates the quality of private companies through its baldrige awards program, a privacy commissioner could acknowledge companies whose privacy protection programs were worthy of public note and emulation.ł normative issues in data collection and analysis. grounded in the information technology environment of the early 1970s, the principles of fair information practice generally presume that the primary source of personal information about an individual is that person™s active and engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 343consensual engagement in providing such information to another party. this source is still quite important, but new sources of personal information have emerged in the past 30 yearsšvideo and infrared cameras, internet usage monitors, biometric identication technology, electronic location devices, radiofrequency identication chips, and a variety of environmental sensors. in addition, new techniques enable the discovery of previously hidden patterns in large data setsšpatterns that might well be regarded as new information in and of themselves.these types of data acquisition devices and techniques have rarely been the subject of focused normative discussion. currently, there are no principles or standards of judgment that would help public policy makers and corporate decision makers determine the appropriateness of using any given device or technique. (for example, the use of a given device or technique for gathering data may not be illegal, perhaps because it is so new that regulation has yet to appear, but the lack of legal sanctions against it does not mean that using it is the right thing to do.) systematic attention to such principles by a privacy commissioner™s ofce might provide valuable assistance to these decision and policy makers.ł collective and group privacy. historically, privacy regulation in the united states has focused on personal informationšinformation about and collected from individuals. issues related to groups have generally been addressed from the important but nevertheless narrow perspective of outlawing explicit discrimination against certain categories of individuals (e.g., categories dened by attributes such as race, religion, gender, sexual orientation, and so on). but new statistical proling techniques, coupled with the increasingly ubiquitous availability of personal information about individuals, provide many new opportunities for sorting and classifying people in ways that are much less obvious or straightforward.originally undertaken to improve marketing, risk management, and strategic communications, statistical proling has served as the basis for decisions in these areasšand thus may have served to inappropriately exclude people from opportunities that might otherwise improve their ability to grow and develop as productive members of society (even as others may be inappropriately included). however, the nature and scope of such exclusions are not known today, nor is the impact of these exclusions on the cumulative disadvantage faced by members of population segments likely to be victims of categorical discrimination. at the same time, others argue that equitable, efcient, and effective public policy requires the development of data resources that might require such sorting. a future review of privacy might examine these issues, as well as the potential constraining effects on options available to individuals and their ability to make truly informed and autonomous choices in their roles as citizens and consumers in the face of unseen statistical sorting.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.344 engaging privacy and information technology in a digital ageł privacy, intimacy, and afliation. although matters such as personal intimacy and afliation are typically beyond the direct and formal purview of most public policy analysis, they are central to the good life. indeed, one might well argue that a life without intimacy or without the freedom to afliate with other people is a life largely shorn of meaning and fulllment. it is at least plausible that the sense of privacy enjoyed by individuals affects the range of activity and behavior that might be associated with expressions of intimacy and afliation. to the best of the committee™s knowledge, no review of privacy has ever considered these issues, and since almost all of the attention to privacy questions focuses on the behavior of governments and organizations, a future review might examine them.20ł informing and educating the public about privacy. the issues surrounding privacy are sufciently complex that it may be unrealistic to expect the average person to fully grasp their meaning. a privacy commissioner™s ofce could help to educate the public about privacy issues (in the management of health care data and in other areas). because this educational role would be institutionalized, it is reasonable to expect that the information such an ofce provided would be more comprehensible than the information offered by sources and parties with an interest in minimizing public concern about threats to privacy (e.g., difculttoread privacy notices sent by companies with economic interests in using personal information to the maximum extent possible).this educational role could have a number of components. for illustration only, it might include: šreview of and recommendations for how schools teach about privacy and how understanding of it could be improved in the face of recent rapid changes. for example, social networking, as might be found on facebook.com and myspace.com, continue to present challenges to the privacy and safety of many of the young people who use such sites and services. as relatively recent developments indicate, education about how these people should approach such services has been lacking. špromotion among the manufacturers of surveillance equipment (whether tools for adults or toys for children) to include warning messages similar to those on other products such as cigarettes (e.g., use of the tools unless certain conditions are met is illegal). instruction 20 among some recent work relevant to the issue, see j. smith, private matters, addison wesley, reading, mass., 1997; r. gurstein, the repeal of reticence, hill and wang, new york, 1996; c. calvert, voyeur nation, westview press, boulder, colo., 2000; gary t. marx, ﬁforget big brother and big corporation: what about the personal uses of surveillance technology as seen in cases such as tom i. voire?,ﬂ rutgers journal of law and urban policy 3(4):219286, 2006, available at http://garymarx.net.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.findings and recommendations 345booklets for such equipment might also brie˚y mention the value issues involved and, in the case of toys with a doubleedged potential, encourage parents to discuss the issues raised by covertly invading the privacy of others, even if such actions appear to be benign and are undertaken only in fun. šdevelopment of model discussions of privacy that could be used for instructional purposes.the committee acknowledges that the notion of a privacy commissioner is controversial in a number of ways, emanating from many points along the privacy policy spectrum. some believe that the establishment of such ofces is in reality a mechanism to avoid coming to grips with the real policy issues of privacy. others believe that the presence of such an ofce can be used to lend legitimacy to efforts that would otherwise be seen clearly as compromising privacy. still others believe that the success of such a commissioner would be contingent on the power given to the commissioner and the policy decisions concerning what kinds of privacy are important to protect, and that such commissioners are rarely given enough explicit authority to make substantive policy decisions regarding privacy.another camp believes that such ofces stultify real progress and are likely to be mismanaged. and there is no denying that such an ofce would mark a signicant movement in the direction of giving government an important role in protecting privacy. nonetheless, the committee believes that the value of having a national and institutionalized focal point for promoting public discourse about privacy outweighs these possible objections.10.5.4.6 establishing the means for recoursefinding 21. the availability of individual recourse for recognized violations of privacy is an essential element of public policy regarding privacy.even the best laws, regulations, and policies governing privacy will be useless unless adequate recourse is available if and when they are violated. in the absence of recourse, those whose privacy has been improperly violated (whether by accident or deliberately) must bear alone the costs and consequences of the violation. this is one possible approach to public policy, but the committee believes this approach would run contrary to basic principles of fairness that public policy should embody. the committee also believes that when recourse is available (i.e., when individuals can identify and be compensated for violations), those in a position to act inappropriately tend to be more careful and more respectful of privacy policies that they might inadvertently violate.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.346 engaging privacy and information technology in a digital agerecommendation 15. governments at all levels should take action to establish the availability of appropriate individual recourse for recognized violations of privacy.these comments apply whether the source of the violation is in government or in the private sector, although the nature of appropriate recourse varies depending on the source. in the case of government wrongdoing, the doctrine of sovereign immunity generally protects government actors from civil liability or criminal prosecution unless the government waives this protection or is statutorily stripped of immunity in the particular kinds of cases at hand. that is, against government wrongdoers, a statute must explicitly allow civil suits or criminal prosecution for recourse to exist.against private sector violators of privacy, a number of recourse mechanisms are possible.21 one approach is for legislatures (federal or state) to create causes for action if private organizations engage in certain privacyviolating practices, as these legislatures have done in the case of unfair and deceptive trade practices. such laws can be structured to allow government enforcement actions to stop the practice and/or individual actions for damages brought by individuals harmed by the practices.there are other possibilities as well. when local privacy commissioners or advocates have been legislatively chartered, their charge could include standing to take action on behalf of individuals who have been harmed, either tangibly or intangibly, by some privacyviolating action. mediators or privacy arbitration boards might be established that could resolve privacy disputes; while this would still require those who thought their privacy had been violated to bring action against the violator, it might reduce the overhead of such actions in a way that would be acceptable to all.21 in pursuing remedies against private sector invasions of privacy by the news media, publishers, writers, photographers, and others, caution is in order respecting freedoms of speech and press, as noted in section 4.2.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendixesengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.349aa short history of surveillance and privacy in the united statesa.1 introductionroutine surveillance is an inescapable feature of daily life in the united states at the start of the 21st century. we all leave a trail of electronic traces that are picked up for processing by a variety of organizations and agencies. constant exchanges thus occur in which personal information is involved. sometimes people are able to negotiate the amount of data they are willing to disclosešfor instance when lling out a product registration form for a new computer. at other times, an individual™s leverage over the organization is minimal, as when people apply for business or government services such as loans or insurance. the interaction becomes even more unidirectional when personal data are collected from a distance, without the direct participation of the citizen or consumer.ﬁsurveillanceﬂ may be thought of as systematic attention to personal details for the purposes of in˚uence, management, or control. some surveillance is personal, facetoface supervision, but the main concern in what follows is situations in which data are routinely collected. such systematic collection of personal information is not a new phenomenon in american society. as far back as the colonial era, organizations were actively interested in the details of people™s daily lives. while the intennote: this appendix is based largely on work performed on contract to the committee by david lyon, queen™s university, canada (with extensive research assistance from bart bonikowski, sociology, duke university).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.350 engaging privacy and information technology in a digital agesity and scope of surveillance have varied since the 17th century, the same factors shape them: the interests of those in positions of power, the technology available to them, and the legal frameworks within which they operate.the history of surveillance in the united states can be divided into ve time periods, each characterized by particular political, legal, and technological developments. while these divisions are arbitrary, they highlight some of the main trends that have characterized the institutional collection of information and the corresponding moral and legal responses:ł the rst phase, which spans the decades from the mid17th century to the american revolution, is dominated by the puritan ethic of colonial new england, with its emphasis on the enforcement of a strict moral code by means of neighborly ﬁwatchfulness.ﬂł the second covers the early american republic, from its confederation to the civil warša time of rapid social and political change and of a marked shift in surveillance from being an informal practice based in religious dogma to becoming an embryonic political tool of the government.ł the third era stretches from the civil war to the mid20th century and is characterized by rapid technological growth, an increased reliance of government and business on surveillance, and the initial formulations of privacy as a legal right.ł the fourth stage is that of postœworld war ii america from 1950 to 1980, which gave rise to computerized and centralized surveillance but also to a rst concerted social effort at developing a legal right to privacy as an effective countermeasure.ł the fth period encompasses the main technological and political developments in surveillance and privacy from 1980 to the present, including the growth of computer interconnectivity, wireless technology, and the emergence of antiterrorism as the primary justication for intensied surveillance.a.2 colonial new england (ca. 16501776)tensions between privacy and information gathering were present during the earliest colonial times. in new england, for example, the physical conditions of frontier life played an important role in shaping surveillance and privacy in the late 17th and early 18th centuries. the population of the colonies in the 17th century was scattered among small settlements. large families lived in small, crowded homes, many of which faced the town square or the main road, and frequently opened their engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 351doors to servants and lodgers, further reducing the amount of personal space available. it is not difcult to imagine how little personal information the inhabitants of new england were able to keep secret. in small, isolated communities where every face was familiar and information from the outside world was largely unavailable, people were involved primarily with one another™s lives.surveillance and privacy were also affected by the strict adherence to the form of religious morality that lay at the heart of colonial new england™s puritan ethic. members of the community were expected to divide their time between their occupation (usually farming), family obligations, and religious duties. tobacco use, card playing, cursing, idleness, premarital and extramarital sex, breaking the sabbath, and excessive drinking were seen as sinful and met with religious and criminal sanctions. the moral stigma also extended to solitary activities such as ﬁnightwalkingﬂ and living alone. puritan congregations expected their followers not only to eschew those vices themselves, but also to keep watch on others to prevent them from wrongdoing. this mutual watchfulness was central to the colonial system of law enforcement and church discipline. ironically, given the puritans™ aversion to the involvement of the state in religious matters, stemming from their persecution by english authorities in the 17th century, church and government law were closely intertwined in colonial new england.it would seem reasonable, based on the description thus far, to conclude that the lives of new england settlers were under constant and intense surveillance. however, surveillance was partly restricted by the legal system of colonial new england. as early as 1647, rhode island adopted the principle that ﬁa man™s house is his castle,ﬂ originally formulated by english jurist sir edward coke. the colony outlawed ﬁforcible entry and detainerﬂ into a private dwelling, except by law enforcement ofcers acting under exceptional circumstances.1 massachusetts followed suit in 1659.meanwhile, a slow shift away from forced and selfincriminating testimony in the courtroom and the church, which laid the groundwork for the eventual construction of the fifth amendment of the bill of rights, was symptomatic of deeper changes in colonial society. america was gradually abandoning the strict ethic of the puritan movement, a slow transition that continued well into the 19th century. during the 18th century, the colonies also experienced rapid population growth, which increased the size of most towns, thereby altering the physical conditions that once facilitated mutual surveillance.1 david h. flaherty, privacy in colonial new england, university press of virginia, charlottesville, va., 1972, p. 86.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.352 engaging privacy and information technology in a digital ageit is also important to note that the type of surveillance widely conducted within the puritan society differed signicantly from surveillance in the 19th and 20th centuries. the political and religious institutions of colonial america were largely informal and unstructured. as a result, surveillance was less an institutional practice than a communal one. no organized police force was charged with investigating individuals, and no widespread enumeration of the populace took place. in fact, ofcial records were nearly nonexistent, with the exception of court les, internal administrative records, and vital records (such as birth and death certicates). instead, surveillance was an unsystematic activity carried out by particularly zealous members of the community, with varying repercussions for those under its gaze. unlike its more concentrated bureaucratic form, which emerged in the following centuries, the power of colonial surveillance was widely dispersed among the population.2a.3 the early republic (17761861)the in˚uence of puritan values on surveillance and privacy in america diminished throughout the 18th and early 19th centuries. the increasing mobility of individuals and the growth of urban centers made keeping tabs on one™s neighbors increasingly difcult. furthermore, improvements in literacy and education, combined with the ready availability of the press, meant that the interest of some also went beyond neighborhoods to include the national or international political forum. although these privileges were principally limited to white males,3 they contributed to changes in the social priorities of society as a whole. after all, these white males set social norms and government policies. the turning point in this phase of surveillance and privacy history was the american revolution and the subsequent formation of an independent republic of the united states of america.the origins of institutional surveillance in western society can be generally traced back to the establishment of the modern bureaucracy, which had its beginnings in the military organization, the bureaucratic state, and 2 this is not to say that some members of the community were not more disadvantaged than othersšwomen, children, and ethnic minorities certainly had less power than white males, as was the case in all eras of american history. however, institutions had less surveillance power visàvis individuals than they did in the later republic.3 when the constitution was voted on in 1787, the vast majority of people in america were still illiterate. among 4,250,000 inhabitants of the republic, 600,000 were slaves and 2,000,000 were womenšboth groups were denied the privileges of education. of the remainder, about 250,000 were estimated to be literateša number roughly equal to the total voter turnout for the vote on the constitution. see morris l. ernst and alan u. schwartz, privacy: the right to be let alone, macmillan, new york, 1962.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 353the capitalist enterprise.4 all three of these modern institutions came into existence in the united states at the end of the 18th century.the escalating tensions between the colonies and the british government over the arbitrary levying of taxes and the stationing of british troops in new england led to the outbreak of the rst skirmishes of the revolutionary war at lexington, concord, and bunker hill. in response, the rst modern american army was born, under the command of george washington and by direction of the continental congress, the newly established system of revolutionary selfgovernment. the new army replaced the scattered militia and came complete with army drill, regular roll call, and punishment for disobedience.5a year earlier, in 1774, the early bureaucratic structure of american government had emerged with the first continental congress, which organized local committees in most towns, cities, and counties of the colonies.6 during the constitutional convention of 1787, which followed the war of independence, this temporary structure was replaced by the presentform u.s. government, with three branches of power and a hierarchical organizational structure. the u.s. government soon became the primary site of institutional surveillance, as it gradually developed recordkeeping practices to monitor its citizens.while u.s. industry did not take shape until the latter half of the 19th century, the roots of capitalist enterprise in the united states can be found in early19thcentury shipping trade, the southern plantations, the emergence of banking, and the westward search for gold. as u.s. businesses continued to grow, they developed bureaucratic recordkeeping practices to keep track of contracts, loans, assets, and taxable revenues. these records of course included some information that referred to identiable individuals.the revolutionary era also marked the rst instance of politicalloyalty surveillance in the interest of national security. in the past, american colonists had felt endangered almost exclusively by ﬁoutsideﬂ forces, such as native american tribes or the french and the spanish. this sense of endangerment shifted during the revolution, as the perceived threat began emanating from within the ranks of colonial society. as the tensions between the colonists and the british mounted in the 1770s, resentment against domestic supporters of british rule (tories or loyalists) became widespread. with the commencement of the revolution, this antipathy 4 christopher dandeker, surveillance power and modernity, polity press, cambridge, mass., 1990.5 richard w. stewart, ed., american military history, volume i: the united states army and the forging of a nation, 17751917, army historical series, center for military history, publication 3021, government printing ofce, washington, d.c., 2005, pp. 4850.6 stewart, american military history, volume i, 2005, p. 50.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.354 engaging privacy and information technology in a digital agetransformed into overt discrimination and abuse, as most tories were ostracized and many fell victim to mob violence. the revolutionaries also persecuted quakers, many of whom were pacists opposed to the revolution on moral and religious principle.the surveillance capabilities of the new state were also used for other purposes. since the constitution of the united states called for the establishment of democratic popular elections and mandated a decennial census, the government needed to create organizational procedures that would regulate the proper fulllment of these responsibilities. while electoral registration was an erratic practice whose application varied from state to state, the popular census of 1790 was the rst attempt by the u.s. government to conduct systematic and universal gathering of information about its citizens. the census collected basic data on the gender, color, and identity of free males above the age of 16 years.7 with time, this crude enumeration tool evolved into a sophisticated source of demographic information employed by social scientists, policy makers, and government ofcials throughout the country.while the postrevolution era gave rise to early surveillance practices by the government and the military, its primary contribution to the history of surveillance in the united states was the codication in the constitution and the bill of rights of rules restricting invasive information gathering. although the ideological bases for the american republic are complex, some of the basic values contained in the constitution require mention, since they bear directly on surveillance in the new republic. drawing largely on the philosophy of john locke and the heritage of puritanism, the u.s. constitution sought to protect the rights of the individual, to ensure the limited role of government in american society, and to reinforce the central importance of private property for the exercise of individual liberty.8 the bill of rights that emerged from these values was intended to shield citizens from unrestricted surveillance by those in positions of power and thus to avoid the development of authoritarian society, such as that of feudal europe. the judicial interpretation of the bill of rights throughout the 19th and early 20th centuries rarely found solid grounds (especially based on the vague right to privacy) for curtailing government and corporate surveillance. nonetheless, the sentiment of the founders against institutional intrusion in the life of citizens is unmistakable.it must be stressed that the laws described above pertained to those 7 joseph steinberg, ﬁgovernment records: the census bureau and the social security administration,ﬂ pp. 225254 in s. wheeler, ed., on record: files and dossiers in american life, sage foundation, new york, 1969.8 alan f. westin, privacy and freedom, atheneum, new york, 1967, p. 330.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 355members of society who were viewed by the state as free citizens, which generally meant white male adults. the plight of those deprived of citizenship rights, such as african american slaves and native americans, was drastically different. their individual rights were not protected by u.s. laws, since the former were seen as private property belonging to slaveholders, while the latter were treated as savages not worthy of legal protection. consequently, slaves continued living in a state of almost total surveillance in which their every action was subject to scrutiny by overseers. undesirable behavior was punished severely, with no legal recourse. native americans were banished to reservations and faced persecution and death if they resisted. thus, when constitutional protections and restricted practices of state surveillance after the revolution are spoken of, it must be remembered that such conditions were the norm only for a limited fraction of the u.s. population.a.4 the modern republic (18611950)between the revolution and the civil war, surveillance and individual rights coexisted in a fragile balance. the growing desire of u.s. bureaucracies to keep track of citizens was offset by limited technological means of information gathering and by the constitutional, statutory, and commonlaw regulations developed in the new republic. this is not to say that surveillance did not exist in those decades; however, its scope and intensity were relatively limited. the average free male™s interaction with surveillance systems rarely went beyond reporting basic information in census surveys and furnishing land deeds during elections. this changed drastically in the years that followed the civil war. the balance of surveillance and individual rights was upset by unprecedented technological development, the rapid growth of bureaucratic institutions (both governmental and commercial), and the failure of lawmakers to formulate adequate legal protections against surveillance practices.many contemporary surveillance technologies owe their existence to late19thcentury american enterprise. the steam engine enabled unprecedented rates of travel, and mechanization shifted work from the farm to the factory, a harbinger of greater mobility to come. yet no technological developments had as much impact on the practice of surveillance in the 19th century as the inventions of the telegraph, the dictograph recorder, the instantaneous photographic camera, and the punchcardtabulating machine.the telegraph, invented in the 1850s, created a completely new means of communication. for the rst time, communication was separate from transport. however, as would be the case through much of u.s. history, the new medium also facilitated the interception of information sent engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.356 engaging privacy and information technology in a digital agethrough its channels. as early as the civil war, during which the telegraph was rst used on a wide scale, confederate and union forces tapped each other™s telegraph lines to remain informed of their adversary™s strategic decisions.9photographic and soundrecording technology made it possible to record people™s actions and words from a distance and, on occasion, without their consent.10 photographic images also replaced the easily forged signature as a common identier for bureaucracies eager to keep track of growing urban populations. with time, however, an efcient source of bodily identicationšthe ngerprintšfurther revolutionized the identication of citizens.by 1902, ngerprints were systematically used by u.s. authorities, beginning with the new york civil service commission. the practice quickly spread to prisons, the u.s. military, and police departments throughout the country. in 1924, the federal bureau of investigation (fbi) received a legislative mandate to manage a national ngerprint card database, which contained 100 million records by 1946. since that time, ngerprinting has been the predominant method of identication used by u.s. law enforcement agencies.the nal technological development of this era that had a marked impact on surveillance practices was the punchcardtabulating machine. invented by herman hollerith in 1889, the machine was designed to streamline the processing of the census. hollerith™s invention, which aggregated information from patterns of holes punched into cardboard cards, was rst tested in the 1890 census, shortening its tabulation and analysis from 18 to 6 weeks. the device was an instant success, as it revolutionized record keeping, enabling quick information input and retrieval and decreasing the amount of space necessary for storing records.the new surveillance technology was both a driving force in the growth of institutional surveillance and a product of increasing bureaucratic needs for information gathering. both the bureaucratic institutional model and the technologies that it employed were the products of the pervasive pursuit of efciency that dominated modern american society. the social fabric of the country changed dramatically in the late 19th century owing to immigration and industry, and a continentwide railroad system allowed increasing mobility. workers seeking employment were looking beyond their neighborhoods and towns, and the proportion of 9 alan f. westin, privacy and freedom, 1967, p. 172.10 with older photographic technology, the subject had to stay still for some time in order for the camera to produce a sharp image, which limited the use of cameras for capturing candid moments.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 357those who could provide for themselves and their families by living off their land decreased rapidly.u.s. bureaucracies began relying more heavily on records to keep track of the growing, increasingly mobile population. they collected vital records, school records, employment records, land and housing records, bank and credit records, professional licensing records, military records, church records, law enforcement records, and many others. some of these information practices were not newšbirth and death data and church records had been collected as far back as during the colonial era. however, the compilation of records became signicantly more sophisticated at the end of the 19th century. record keeping became more universal, more systematic, and more thoroughgoing than ever before in american history. yet the records of this era differed from those of the mid20th century in an important way: they were maintained predominantly at the local level. the lack of centralized management of record keeping limited its social control function, since a person could move to a different area to escape bad credit or a criminal investigation, although to do so would require the necessary resources.despite the predominance of uncoordinated local records in 19thcentury america, it would be a mistake to conclude that no national surveillance practices existed before the 20th century. the decennial census had been the site of widespread information collection since 1790. by 1880, it was a sophisticated demographic tool under the jurisdiction of a newly established census ofce within the department of the interior.11,12 while the early surveys collected only the most rudimentary information regarding the classes of people inhabiting a household, the 1880 census featured questions about the age, gender, marital status, place of birth, education, occupation, and literacy status of all household members.loyalty surveillance also played a role during the civil war, and it reemerged during world war i, although this time the lens of surveillance was focused on german americans and antiwar activists.13 concerns about the war caused the government to pass the espionage act in june 1917. peace protests were put down by police and the military; newspapers publishing antiwar articles were refused circulation by the post ofce department; lms with ostensible antiwar content were banned; and many professors critical of their universities™ prowar stance were 11 in 1902 the census ofce, a permanent agency, was established in its place.12 joseph steinberg, ﬁgovernment records: the census bureau and the social security administration,ﬂ pp. 225254 in s. wheeler, ed., on record: files and dossiers in american life, sage foundation, new york, 1969.13 morris janowitz, ﬁthe evolution of civilian surveillance by the armed forces,ﬂ pp. 6973 in m.b. schnapper, ed., uncle sam is watching you: highlights from the hearings of the senate subcommittee on constitutional rights, public affairs press, washington, d.c., 1971.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.358 engaging privacy and information technology in a digital agered. interestingly, the espionage act remains coded in u.s. law to this day, though enforcement of its provisions has been reserved for times of war.14after world war i, similar loyaltysurveillance tactics were used against socialists and labor unions, and such tactics later reemerged in full force during world war ii against japaneseamericans. according to scholars william seltzer and margo anderson,15 the bureau of the census assisted u.s. law enforcement authorities in carrying out the presidentially ordered internment of japaneseamericans. thus, a surveillance practice established for ostensibly benign statistical purposes was used for the implementation of the most oppressive domestic government action in u.s. history, aside from the negative treatment meted out against african american slaves and native americans. although loyalty surveillance would never reach such overt extremes again, its presence would continue to dominate american political life from the 1950s to the late 1970s.another government agency highly dependent on gathering information from most u.s. citizens was the bureau of internal revenue (which became the internal revenue service in 1952). initially set up as the ofce of the commissioner of internal revenue, the agency was responsible for the collection of the rst income tax in the united states between 1862 and 1872. however, the authority of the u.s. congress to levy an income tax was not established until 1913, with the passage of the sixteenth amendment. income tax in that year was graduated, and so the commissioner needed to keep track of the income of all taxpayers, giving rise to one of the rst centralized document databases of the u.s. government.by the 1930s, personal identication documents, whose proliferation was initially prompted by the outbreak of world war i, were important means for distinguishing those who were eligible for state programs from those who were not. franklin d. roosevelt™s new deal offered americans new benets, including social security and labor standards, in order to pull the country out of the great depression. yet, at the same time, the new deal substantially increased the government™s administrative burden, requiring new surveillance procedures to keep track of the millions of new benet recipients and minimize fraudulent claims. this uneasy combination of social benets and regulatory mechanisms would come 14 it was used again during the civil rights con˚icts of the 1960s, since the united states was ofcially in a state of perpetual emergency from the time of the korean war. see howard zinn, a people™s history of the united states, harpercollins, new york, 2003, pp. 542544.15 william seltzer and margo anderson, ﬁafter pearl harbor: the proper role of population data systems in time of war,ﬂ paper presented at the annual meeting of the population association of america, los angeles, calif., march 2000; also available at the american statistical association™s statisticians in history web site.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 359to dene the nature of bureaucratic surveillance in the 20th century, as it continually oscillated between the provision of care and the exercise of control. the social security board (later to become the social security administration), established in 1936 under the new deal, embodied both of these contradictory values.the development of surveillance was not limited to the political arena. in fact, some of the most overt uses of workplace behavior monitoring and record keeping took place in the burgeoning private sector. as would be the case for the remainder of the 20th century, early business surveillance focused on two distinct objectives: the monitoring of the worker and, increasingly, the investigation of consumer behavior. one could add a third objective, credit reporting, although this task was quickly taken over from individual businesses by a dedicated industry. whatever the objective, private businesses were quick to recognize the potential prots to be made from consumer information.public policy and jurisprudence posed few constraints on the intensication of surveillance in bureaucratic record keeping, immigration, law enforcement, and the workplace. whatever resistance to surveillance was mounted by private property rights before the civil war largely failed to slow the spread of surveillance in industrial america. new surveillance technologies often did not breach private property. microphones could be installed in adjacent apartments, telephone taps could be installed outside the home, and photographs could be taken from afar, thus upholding property rights. in the meantime, the lessintrusive forms of surveillance, such as bureaucratic record keeping, were simply seen by the law as necessary elements of a developing nationstate and were afforded few protective regulations.the period from the late 19th to the early 20th centuries was a formative period for considering privacy rights. a key moment was samuel warren and louis brandeis™s denition of privacy as the ﬁright to be left alone.ﬂ16 the article described the progression of common law from the protecting of property and persons to the defending of spiritual and emotional states, as well as making the innovative observation that technology would soon make such discussions a more urgent concern.17 it is not clear that their warning was heeded until the 1960s, 70 years after they offered it.another important development was the passage of the telecommunications act of 1934, specically section 605, which provided that ﬁno 16 samuel d. warren and louis d. brandeis, harvard law review iv (december 15, no. 5):195, 205, 1890, available at http://www.lawrence.edu/fac/boardmaw/privacybrandwarr2.html.17 alan f. westin, privacy and freedom, 1967, p. 246.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.360 engaging privacy and information technology in a digital ageperson not being authorized by the sender shall intercept any communication and divulge or publish the existence, contents, substance, purport, effect, or meaning of such intercepted communication to any person.ﬂ in two subsequent decisions, the u.s. supreme court held that the plain language of this section applied to federal agents,18 that evidence obtained from the interception of wire and radio communications was inadmissible in court,19 and that evidence indirectly derived from such interceptions was inadmissible as well.20 note, however, that the federal government subsequently continued to use wiretapping for purposes other than the collection of evidence to be introduced in court.21a.5 cold war america (19501980)the three decades that followed world war ii brought issues of surveillance and privacy into the light of serious public debate for the rst time in u.s. history. stories of excesses of government surveillance were featured prominently in the mass media, congressional hearings resulted in the passage of privacy laws, and new regulations emerged to govern the information practices within some private industries. movies featured surveillance, and social scientists started to analyze it.22amidst all the attention given to privacy, surveillance was becoming ever more ubiquitous. fueled by unprecedented rates of consumption, a new relationship developed between the individual and the retail sector, one governed by credit lending and surveillancebased marketing practices. despite the advances of organized labor in the 1930s, the vast new middle class was under pressure in the workplace from hiring practices that demanded personal information and strict performance monitoring after the point of hiring. the political loyalty of citizens was questioned on a scale never before witnessed in american society as the anticommunist mood swept the united states. and all these surveillance practices were facilitated by rapid technological development.beginning in the late 1950s, the computer became a central tool of organizational surveillance. it addressed problems of space and time in the management of records and data analysis and fueled the trend of cen18 nardone v. united states, 302 u.s. 397 (1937).19 nardone v. united states, 302 u.s. 397 (1937).20 nardone v. united states, 308 u.s. 338 (1939).21 warrantless fbi electronic surveillance, book iii of the final report of the select committee to study governmental operations with respect to intelligence activities, united states senate, u.s. government printing ofce, washington, d.c., april 23, 1976. (the select committee is popularly known as the church committee, after its chair, frank church, senator from idaho.)22 vance packard, the naked society, david mckay, new york, 1964.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 361tralization of records. the power of databases to aggregate information previously scattered across diverse locations gave institutions the ability to create comprehensive personal proles of individuals, frequently without their knowledge or cooperation. the possibility of the use of such power for authoritarian purposes awakened images of orwellian dystopia in the minds of countless journalists, scholars, writers, and politicians during the 1960s, drawing widescale public attention to surveillance and lending urgency to the emerging legal debate over privacy rights.one of the sectors that immediately beneted from the introduction of computer database technology was the creditreporting industry. as was the case with most bureaucratic record systems, credit reporting began as a decentralized practice. in 1965, the newly established credit data corporation (cdc)ša forprot, computerized central agencyšbecame the rst national creditreporting rm in the united states. it was soon followed by other rms, such as the retail credit company, hooperholmes, and the medical information bureau (mib), which served the insurance industry.but the credit and insurance industries were not alone. banks, utility companies, telephone companies, medical institutions, marketing rms, and many other businesses were compiling national and regional dossiers about their clients and competitors in quantities never before seen in the united states. the public sector was equally enthusiastic about the new capabilities of computers. most federal, state, and local government agencies collected growing volumes of data and invested vast resources in the computerization of their systems. the u.s. military, the internal revenue service, the social security administration, and the bureau of the census were among the largest consumers of information and were thus some of the rst to become computerized.while record keeping was growing in all segments of society, the federal government continued its longstanding practice of loyalty surveillancešnow increasingly computerassisted. in the 1950s, the enemies were communists; in the 1960s, black rights activists; and in the late 1960s and early 1970s, antiwar protesters. the existence of these groups was believed to justify the federal government™s development of security records to monitor anyone deemed a threat. it used these security records for two purposes: to monitor the suitability of federal employees and to monitor subversive activity outside the government.during the 1950s and 1960s, negative reactions to the growing centralization and computerization of records and the continued abuse of surveillance power by law enforcement authorities began to mount. critics emerged from all sectors of society, including the academy, the mass media, churches, the arts community, and even the corporate world. some politicians, who received increasing numbers of complaints from their engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.362 engaging privacy and information technology in a digital ageconstituents, began raising the issue in congress. as a result, over the course of the 1960s and early 1970s a number of groundbreaking congressional committees began investigating the use of surveillance practices by the federal government and the private sector, most notably in connection with the watergate scandal. under the leadership of political leaders such as senator sam j. ervin, representative cornelius gallagher, and senator edward long, the committees interviewed hundreds of public and privatesector ofcials and analyzed thousands of internal documents, revealing the immense scope of surveillance in american society.aside from direct impacts on practices, the work of the congressional committees helped create public awareness and support for resisting surveillance. as a result of the hearings, the legislation of surveillance became one of the priorities of the u.s. government. with continued lobbying by individuals like senator ervin and alan westin, a leading expert on information privacy, the rst concrete federal antisurveillance statutes were passed. beginning in 1966, congress began responding to the widespread calls for the regulation of surveillance. the freedom of information act (foia), passed in 1966 and amended in 1974 and 1976; the omnibus crime control and safe streets act of 1968; and the fair credit reporting act of 1970 were important steps, respectively, in giving people control over their information, placing limits on police surveillance, and legislating accuracy and condentiality for credit bureaus.23in 1974, the privacy act was passed. for the rst time, legislation explicitly identied and protected the right to privacy as a fundamental right. although the original draft called for the regulation of information practices in federal, state, and local government as well as in the private sector, the nal bill extended only to the federal government and the private companies with which it does business.24 this continues to be the case, since private corporations generally only have to answer to selfgovernment or sectorspecic laws. the privacy act governed the collection of personal information and outlawed its disclosure without the consent of the individual in question. the exceptions to the antidisclosure clause included standard intraagency use, disclosure under foia, routine use for original purposes, and use for the purposes of the census, statistical research, the national archives, law enforcement, health and safety administration, congress, the comptroller general, and court orders.25a major challenge faced by the new privacy legislation was its proper enforcement. even senator ervin, whose work led directly to the passing 23 richard f. hixson, privacy in a public society: human rights in con˚ict, oxford university press, new york, 1987, pp. 186, 197, 219.24 hixson, privacy in a public society, 1987, p. 223.25 hixson, privacy in a public society, 1987, p. 224.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 363of the privacy act, was less than enthusiastic about its impact: ﬁthe privacy act, if enforced, would be a pretty good thing. but the government doesn™t like it. the government has an insatiable appetite for power, and it will not stop usurping power unless it is restrained by laws they cannot repeal or nullify.ﬂ26 indeed, failures to comply with surveillance regulations penetrated even the top tiers of the federal government. during the presidential campaign of 1972, ve burglars with links to the nixon administration were caught breaking into the democratic national committee ofces in order to install surveillance equipment. the resulting watergate affair revealed a wide array of secret government surveillance practices aimed at political opponents, journalists, and antiwar activists.27 all this took place 4 years after the enactment of the omnibus crime control and safe streets act.court cases continued to bring privacy and freedom of information issues to the fore. in the 1965 supreme court case of griswold v. connecticut, the court rejected a statute forbidding the distribution of birth control information. using this case as a basis, the roe v. wade ruling of 1973 eased the way to legal abortion, arguing that it was a privacy issue. regardless of whether it was directly or indirectly related, privacy would continue dominating the surveillance discourse. over the next two decades its role would become ever more crucial, as government and business surveillance continued to increase in intensity and scope, despite the modest legal victories of the 1960s and 1970s.a.6 globalized america (1980present)the end of the 20th century was a time of increasing globalization of america™s economy. computer interconnectivity allowed the leading corporations to expand their manufacturing and marketing bases to countries around the world, forming immense, multinational business networks, coordinated in real time.28 this process was bolstered by the consolidation of many industries, as countless mergers and takeovers created business conglomerates in many sectors. with the convergence of corporate management came the convergence of company records and technologies. in the meantime, the rise of the personal computer in the 1980s, and networking along with wireless communication in the 1990s, were contributing to change in the daily lives of americans. people™s 26 hixson, privacy in a public society, 1987, p. 207.27 howard zinn, a people™s history of the united states, harpercollins, new york, 2003, pp. 542544.28 manuel castells, the rise of the network society, blackwell publishing, malden, mass., 1996.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.364 engaging privacy and information technology in a digital ageinteractions with technology became routine, allowing them to accomplish many tasks from a distance. the growth of the electronics industry added momentum to continually growing consumerism, which too was facilitated by computer networking, popularizing credit and debit purchases. since virtually all nancial transactions became electronic, they were automatically tracked and recorded by computer databases.advances in science and technology redened the human body as a site of information, making it a prime tool for surveillance practices. closedcircuit cameras emerged in many retail locations to monitor customer and employee behavior. with time, they also became commonplace in public areas for the purpose of crime control. in the 1990s, the development of biometrics, the automatic identication technique based on bodily characteristics, suggested the possibility of identifying people without the need for documents. the emergence of dna analysis and the subsequent mapping of the human genome promised revolutionary possibilities for identication and medical testing.the marketing industry was transformed by information gathering. the development of demographic proling based on consumerbehavior records led to the development of targeted marketing, which allowed companies to focus their promotional dollars on consumers they deemed desirable. detailed information about the preferences and habits of consumers that facilitated such targeted marketing practices became a valuable commodity. socalled customer relationship marketing, which relies on sophisticated proles based on purchasing and preference data,was developed as a major software tool for matching consumers to products and services.in all its applications, surveillance was becoming increasingly rhizomic.29 no longer were national data centers necessary, since information from decentralized databases could be aggregated and analyzed through the use of computer networks. and the rhizomes of surveillance systems were permeating every facet of american society. highway toll systems, automatic teller machines, grocery store checkouts, airport checkins, and countless other points of interaction with surveillance systems automatically fed information into computer systems, although not in ways that are interoperable or that allow easy data correlation among systems.against the backdrop of intensifying practices, congress passed a number of laws to regulate surveillance within specic sectors, as described in section 4.3.1. these bills have restricted the disclosure and misuse of personal information within particular industries, but such 29 kevin haggerty and richard ericson, ﬁthe surveillant assemblage,ﬂ british journal of sociology 51:60522, 2001.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix a 365legislation has generally been narrowly drawn, and so problems outside of the specic purview of these bills have gone unaddressed.despite these limited attempts at bolstering the surveillance power of the government, many commentators believed that the role of the state in surveillance was weakening in the 1990s. some went as far as to dismiss the very concept of a nationstate as an anachronism that would not survive the age of globalization. however, both arguments became moot after september 11, 2001. after the terrorist attacks on new york and washington, d.c., the bush administration forcefully reasserted the power of the state, launching the united states on a ﬁwar against terrorism.ﬂ30 one of the major components of this war was statesponsored surveillance.in the days immediately after september 11, the power of rhizomic surveillance was demonstrated to the public as the actions of the terrorists before the attack were reconstructed from bank records, closedcircuit television cameras, and airport systems. in order to enhance the existing surveillance infrastructure, the president and the congress enacted the usa patriot act of 2001. the act gave the government greater surveillance power over citizens of the united states in order to increase security.30 david lyon, surveillance after september 11, polity press, cambridge, mass.; blackwell publishing, malden, mass., 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.366binternational perspectives on privacythis appendix presents a global overview of how various countries, regions, and cultures address privacyrelated concerns about the processing of personal information. it outlines the principal similarities and differences among various national and regional regulatory measures for addressing these concerns. comparison is made not only of regulatory strategies but also of various national, regional, and cultural conceptualizations of the ideals and rationale of privacy protection.1b.1 conceptualizations of privacy and related interestsas noted in chapters 2, 4, and 5 of this report, there has long been interest in the united states in privacy, and ﬁprivacyﬂ is a frequently used concept in public, academic, and judicial discourse.2 the concept has been especially prominent in discussion in the united states about the implications of the computerized processing of personal data. when this discussion took off in the 1960s, privacy was invoked as a key term for summing 1 much of the information on international conceptions of the rationale for privacy protection presented in this appendix is based on the work of lee bygrave. see, for example, l.a. bygrave, data protection law: approaching its rationale, logic and limits, kluwer law international, the hague/london/new york, 2002 (hereinafter cited as bygrave, data protection law, 2002). a full bibliography is available at http://folk.uio.no/lee/cv.2 see, generally, priscilla regan, legislating privacy, university of north carolina press, 1995 (hereinafter cited as regan, legislating privacy, 1995).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 367up the congeries of fears raised by the (mis)use of computers.3 however, privacy has not been the only term invoked in this context. a variety of other, partly overlapping concepts have also been invokedšparticularly those of ﬁfreedom,ﬂ ﬁliberty,ﬂ and ﬁautonomy.ﬂ4the u.s. debate, particularly in the 1960s and early 1970s, about the privacyrelated threats posed by computers exercised considerable in˚uence on debates in other countries. as hondius writes, ﬁ[a]lmost every issue that arose in europe was also an issue in the united states, but at an earlier time and on a more dramatic scale.ﬂ5 naturally, the salience of the privacy concept in u.s. discourse helped to ensure its prominence in the debate elsewhere. this is most evident in discourse in other englishspeaking countries6 and in international forums where english is a working language.7 yet also in countries in which english is 3 see, for example, alan f. westin, privacy and freedom, atheneum, new york, 1967. in this pioneering work that prompted global privacy movements in many democratic nations in the 1970s, dr. alan westin, professor of public law at columbia university, dened privacy as the claim of individuals, groups, and institutions to determine for themselves when, how, and to what extent information about them is communicated to others. see also arthur r. miller, the assault on privacy: computers, data banks, and dossiers, university of michigan press, ann arbor, 1971 (hereinafter cited as miller, the assault on privacy, 1971).4 the title of westin™s seminal work privacy and freedom (1967) is a case in point. indeed, as pointed out further below, ﬁprivacyﬂ in this context has tended to be conceived essentially as a form of autonomyšthat is, as one™s ability to control the ˚ow of information about oneself.5 frits w. hondius, emerging data protection in europe, north holland publishing, amsterdam, 1975, p. 6 (hereinafter cited as hondius, emerging data protection in europe, 1975). even in more recent times, discourse in the united states often takes up such issues before they are discussed elsewhere. for example, systematic discussion about the impact of digital rights management systems (earlier termed ﬁelectronic copyright management systemsﬂ) on privacy interests occurred rst in the united states: see particularly, julie cohen, ﬁa right to read anonymously: a closer look at ‚copyright management™ in cyberspace,ﬂ conn. l. rev. 28:981, 1996, available at http://www.law.georgetown.edu/faculty/jec/readanonymously.pdf. similar discussion did not occur in europe until a couple of years lateršthe rst instance being l.a. bygrave and k.j. koelman, ﬁprivacy, data protection and copyright: their interaction in the context of electronic copyright management systems,ﬂ institute for information law, amsterdam, 1998; later published in p.b. hugenholtz, ed., copyright and electronic commerce, kluwer law international, the hague/london/boston, 2000, pp. 59124.6 see, for example, united kingdom, committee on privacy (younger committee), report of the committee on privacy, cm. 5012, her majesty™s stationery ofce, london, 1972; canada, department of communications and department of justice, privacy and computers: a report of a task force, information canada, ottawa, 1972; australian law reform commission, privacy, report no. 22, australian government publishing service (agps), canberra, 1983; and w.l. morison, report on the law of privacy to the standing committee of commonwealth and state attorneysgeneral, report no. 170/1973, agps, canberra, 1973.7 as is evident, for example, in the titles of the early council of europe resolutions dealing with information technology threats. see council of europe resolution (73)22 on the engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.368 engaging privacy and information technology in a digital agenot the main language, much of the same discourse has been framed, at least initially, around concepts roughly equating with or embracing the notion of privacyšfor instance, ﬁla vie privéeﬂ (french),8 ﬁdie privatsphäreﬂ (german),9 and ﬁprivatlivets fredﬂ (danish/norwegian).10nevertheless, the eld of law and policy that emerged from the early discussions in europe on the privacyrelated threats posed by information technology (it) has increasingly been described using a nomenclature that avoids explicit reference to privacy or closely related terms. this nomenclature is ﬁdata protection,ﬂ deriving from the german term ﬁdatenschutz.ﬂ11 while the nomenclature is problematic in several respectsšnot least because it fails to indicate the central interests served by the norms to which it is meant to apply12šit has gained broad popularity in europe13 and to a lesser extent elsewhere.14 its use, though, is being increasingly supplemented by the term ﬁdata privacy.ﬂ15 arguably, the latter nomenclature is more appropriate, as it better communicates the central interest(s) at stake and provides a bridge for synthesizing north american and european policy discussions.at the same time, various countries and regions display terminological idiosyncrasies that partly re˚ect differing jurisprudential backgrounds for the discussions concerned. in western europe, the discussion has often drawn on jurisprudence developed there on legal protection of personalprotection of the privacy of individuals visàvis electronic data banks in the private sector, adopted sept. 26, 1973; and council of europe resolution (74)29 on the protection of the privacy of individuals visàvis electronic data banks in the public sector, adopted sept. 24, 1974.8 see, for example, g. messadié, la n de la vie privée, calmannlévy, paris, 1974.9 see, for example, the 1970 proposal by the (west) german interparliamentary working committee for a ﬁlaw for the protection of privacy against misuse of database information,ﬂ described in h.p. bull, data protection or the fear of the computer, piper, munich, 1984, p. 85.10 see, for example, denmark, registerudvalget [register committee], delbetænkning om private registre [report on private data registers], no. 687, statens trykningskontor, copenhagen, 1973.11 for more on the origins of ﬁdatenschutz,ﬂ see simitis, kommentar zum bundesdatenschutzgesetz, 2003, pp. 34.12 moreover, it tends to misleadingly connote, in u.s. circles, concern for the security of data and information or maintenance of intellectual property rights; see p.m. schwartz and j.r. reidenberg, data privacy law: a study of united states data protection, michie law publishers, charlottesville, va., 1996, p. 5 (hereinafter cited as schwartz and reidenberg, data privacy law, 1996).13 see generally, hondius, emerging data protection in europe, 1975; and bygrave, data protection law, 2002.14 see, for example, g.l. hughes and m. jackson, hughes on data protection in australia, 2nd ed., law book co. ltd., sydney, 2001.15 see, for example, schwartz and reidenberg, data privacy law, 1996; and c. kuner, european data privacy law and online business, oxford university press, oxford, 2003 (hereinafter cited as kuner, european data privacy law and online business, 2003).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 369ity. thus, the concepts of ﬁpersönlichkeitsrechtﬂ (personality right) and ﬁpersönlichkeitschutzﬂ (personality protection) gure centrally in german and swiss discourse.16 norwegian discourse revolves around the concept of ﬁpersonvernﬂ (protection of person[ality]),17 while swedish discourse focuses on ﬁintegritetsskyddﬂ (protection of [personal] integrity).18 by contrast, latin american discourse in the eld tends to revolve around the concept of ﬁhabeas dataﬂ (roughly meaning ﬁyou should have the dataﬂ). this concept derives from due process doctrine based on the writ of habeas corpus.19many of the abovementioned concepts are prone to denitional instability. the most famous case in point relates to denitions of ﬁprivacy.ﬂ debates in the united states over the most appropriate denitions of privacy20 have counterparts in other countries centering on similar concepts.21 some of the nonu.s. debate concerns whether privacy as such is best characterized as a state/condition, or a claim, or a right. that issue aside, the debate reveals four principal ways of dening privacy.22 one set of denitions is in terms of noninterference,23 another in terms of limited accessibility.24 a third set of denitions conceives of privacy as informa16 see, for example, germany™s federal data protection act of 1990 (bundesdatenschutzgesetzšgesetz zum fortentwicklung der datenverarbeitung und des datenschutzes vom 20. dezember 1990 (as amended in 2001) §1(1)), stipulating the purpose of the act as protection of the individual from interference with his/her ﬁpersonality rightﬂ (persönlichkeitsrecht); and switzerland™s federal law on data protection of 1992 (loi fédérale du 19. juin 1992 sur la protection des données/bundesgesetz vom 19. juni 1992 über den datenschutz), article 1, stating the object of the act as, inter alia, ﬁprotection of personalityﬂ (schutz der persönlichkeit).17 see bygrave, data protection law, 2002, pp. 138143 and references cited therein.18 see bygrave, data protection law, 2002, pp. 126129 and references cited therein.19 see further, a. guadamuz, ﬁhabeas data vs. the european data protection directive,ﬂ journal of information, law and technology, 2001; and fried, rapporteur, organization of american states (oas), interamerican juridical committee, 2000, p. 107 et seq.20 for overviews, see chapter 2 of julie c. inness, privacy, intimacy, and isolation, oxford university press, new york, 1992; and chapters 2 and 3 of j. decew, in pursuit of privacy: law, ethics, and the rise of technology, cornell university press, ithaca, n.y., 1997.21 see, e.g., en ny datalag [a new data law], statens offentlige utredningar [state ofcial reports], no. 10, pp. 150161, 1993 (documenting difculties experienced in swedish data privacy discourse with respect to arriving at a precise denition of ﬁpersonlig integritetﬂ).22 see generally bygrave, data protection law, 2002, pp. 128129.23 see especially samuel d. warren and louis d. brandeis, ﬁthe right to privacy,ﬂ harvard law review iv (december 15, no. 5):195, 205, 1890 (arguing that the right to privacy in  angloamerican law is part and parcel of a right ﬁto be let aloneﬂ).24 see, for example, r. gavison, ﬁprivacy and the limits of law,ﬂ yale law journal 89:428436, 1980, claiming that privacy is a condition of ﬁlimited accessibilityﬂ consisting of three elements: ﬁsecrecyﬂ (ﬁthe extent to which we are known to othersﬂ), ﬁsolitudeﬂ (ﬁthe extent to which others have physical access to usﬂ), and ﬁanonymityﬂ (ﬁthe extent to which we are the subject of others™ attentionﬂ).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.370 engaging privacy and information technology in a digital agetion control.25 a fourth set of denitions incorporates various elements of the other three sets but links privacy exclusively to intimate or sensitive aspects of persons™ lives.26denitions of privacy in terms of information control tend to be most popular in discourse dealing directly with law and policy on data privacy,27 both in the united states and elsewhere. in europe, though, the notion is not always linked directly to the privacy concept; it is either linked to related concepts, such as ﬁpersonal integrityﬂ (in the case of, e.g., swedish discourse),28 or it stands alone. the most signicant instance of the latter is the german notion of ﬁinformation selfdeterminationﬂ (informationelle selbstbestimmung), which in itself forms the content of a constitutional right deriving from a landmark decision in 1983 by the german federal constitutional court (bundesverfassungsgericht).29 the notion and the right to which it attaches have had considerable impact on development of data privacy law and policy in germany30 and, to a lesser extent, other european countries.despite the general popularity of notions of information control and information selfdetermination, these have usually not been viewed in terms of a person ﬁowningﬂ information about him/herself, such that he/she should be entitled to, for example, royalties for the use of that information by others. concomitantly, property rights doctrines have rarely been championed as providing a desirable basis for data privacy rules.31 the relatively few proponents of a property rights approach have 25 see, for example, westin, privacy and freedom, 1967, p. 7 (ﬁprivacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to othersﬂ).26 see, for example, inness, privacy, intimacy, and isolation, 1992, p. 140 (dening privacy as ﬁthe state of possessing control over a realm of intimate decisions, which includes decisions about intimate access, intimate information, and intimate actionsﬂ).27 see generally bygrave, data protection law, 2002, p. 130, and references cited therein.28 see, for example, en ny datalag [a new data law], statens offentlige utredningar [state ofcial reports], no. 10, p. 159, 1993 (noting that the concept of ﬁpersonlig integritetﬂ embraces information control).29 decision of december 15, 1983, bverfge (entscheidungen des bundesverfassungsgerichts), vol. 65, p. 1 et seq. for an english translation, see human rights law journal 5:94 et seq., 1984.30 cf. s. simitis, ﬁauf dem weg zu einem neuen datenschutzkonzept,ﬂ pp. 714 ff. in datenschutz und datensicherheit, 2000 (detailing the slow and incomplete implementation of the principles inherent in the right).31 opposition to a property rights approach is expressed in, inter alia, miller, the assault on privacy, 1971, p. 211 ff.; hondius, emerging data protection in europe, 1975, pp. 103105; s. simitis, ﬁreviewing privacy in an information society,ﬂ university of pennsylvania law review 135:707, 718, 735736, 1987 (hereinafter cited as simitis, ﬁreviewing privacy in an information society,ﬂ 1987); k. wilson, technologies of control: the new interactive media for the home, university of wisconsin press, madison, 1988, pp. 9194; r. wacks, personal information: engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 371tended to come from the united states,32 although sporadic advocacy of such an approach also occurs elsewhere.33b.2 conceptualizations of the values served by privacyin the united states, the discourse on privacy and privacy rights tends to focus only on the benets that these have for individuals qua individuals. these benets are typically cast in terms of securing (or helping to secure) individuality, autonomy, dignity, emotional release, selfevaluation, and interpersonal relationships of love, friendship, and trust.34 they are, in the words of westin, largely about ﬁachieving individual goals of selfrealization.ﬂ35 the converse of this focus is that privacy and privacy rights are often seen as essentially in tension with the needs of wider ﬁsociety.ﬂ36 this view carries sometimes over into claims that privacy rights can be detrimental to societal needs.37casting the value of privacy in strictly individualistic terms appears to be a common trait in the equivalent discourse in many other countries.38 however, the grip of this paradigm varies from country to country  privacy and the law, clarendon press, oxford, 1989, p. 49; y. poullet, ﬁdata protection  between property and libertiesša civil law approach,ﬂ pp. 161181 in h.w.k. kaspersen and a. oskamp, eds., amongst friends in computers and law: a collection of essays in remembrance of guy vandenberghe, kluwer law and taxation publishers, deventer/boston, 1990; j. litman, ﬁinformation privacy/information property,ﬂ stanford law review 52:12831313, 2000; and bygrave, data protection law, 2002, p. 121.32 see, most notably, westin, privacy and freedom, 1967, pp. 324325; k.c. laudon, ﬁmarkets and privacy,ﬂ communications of the association for computing machinery 39:92104, 1996; j. rule and l. hunter, ﬁtowards property rights in personal data,ﬂ pp. 168181 in c.j. bennett and r. grant, eds., visions of privacy: policy choices for the digital age, university of toronto press, toronto, 1999; and l. lessig, code and other laws of cyberspace, basic books, new york, 1999, pp. 159163.33 see, for example, p. blume, ﬁnew technologies and human rights: data protection, privacy and the information society,ﬂ paper no. 67, institute of legal science, section b, university of copenhagen, 1998.34 see generally, bygrave, data protection law, 2002, pp. 133134 and references cited therein.35 westin, privacy and freedom, 1967, p. 39.36 see generally, regan, legislating privacy, 1995, chapters 2 and 8 and references cited therein.37 as exemplied in r.a. posner, ﬁthe right to privacy,ﬂ georgia law review 12:393422, 1978 (criticizing privacy rights from an economic perspective); and a. etzioni, the limits of privacy, basic books, new york, 1999 (criticizing privacy rights from a communitarian perspective).38 see generally, c.j. bennett and c.d. raab, the governance of privacy: policy instruments in global perspective, ashgate, aldershot, 2003, chapter 1 (hereinafter cited as bennett and raab, the governance of privacy, 2003).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.372 engaging privacy and information technology in a digital ageand culture to culture. the variation is well exemplied when comparing the jurisprudence of the german federal constitutional court with that of u.s. courts. the former emphasizes that the value of data privacy norms lies to a large degree in their ability to secure the necessary conditions for active citizen participation in public life; in other words, to secure a ˚ourishing democracy.39 this perspective is underdeveloped in u.s. jurisprudence.40one also nds increasing recognition in academic discourse on both sides of the atlantic that data privacy norms are valuable not simply for individual persons but for the maintenance of societal civility, pluralism, and democracy.41a related development is increasing academic recognition that data privacy laws serve a multiplicity of interests, which in some cases extend well beyond traditional conceptualizations of privacy.42 this insight is perhaps furthest developed in norwegian discourse, which has elaborated relatively sophisticated models of the various interests promoted 39 see, especially, the decision of december 15, 1983, bverfge (entscheidungen des bundesverfassungsgerichts), vol. 65, p. 1 et seq. for an english translation, see human rights law journal 5:94 et seq., 1984.40 see further, the comparative analyses in p.m. schwartz, ﬁthe computer in german and american constitutional law: towards an american right of informational selfdetermination,ﬂ american journal of comparative law 37:675701, 1989; p.m. schwartz, ﬁprivacy and participation: personal information and public sector regulation in the united states,ﬂ iowa law review 80:553618, 1995; and b.r. ruiz, privacy in telecommunications: a european and an american approach, kluwer law international, the hague/london/boston, 1997.41 see, for example, s. simitis, ﬁauf dem weg zu einem neuen datenschutzrechtﬂ [on the road to a new data protection law], informatica e diritto 3:97116, 1984; simitis, ﬁreviewing privacy in an information society,ﬂ 1987; r.c. post, ﬁthe social foundations of privacy: community and self in the common law,ﬂ california law review 77:9571010, 1989; r. gavison, ﬁtoo early for a requiem: warren and brandeis were right on privacy vs. free speech,ﬂ south carolina law review 43:437471, 1992; regan, legislating privacy, 1995; b.r. ruiz, privacy in telecommunications: a european and an american law approach, kluwer law international, the hague/london/new york, 1997); p.m. schwartz, ﬁprivacy and democracy in cyberspace,ﬂ vanderbilt law review 52:16091702, 1999; bygrave, data protection law, 2002; and bennett and raab, the governance of privacy, 2003.42 see, for example, o. mallmann, zielfunktionen des datenschutzes: schutz der privatsphäre, korrekte information; mit einer studie zum datenschutz im bereich von kreditinformationssystemen [goal functions of data protection: protection of privacy, correct information; with a study of data protection in the area of credit information systems], alfred metzner verlag, frankfurt am main, 1977; h. burkert, ﬁdataprotection legislation and the modernization of public administration,ﬂ international review of administrative sciences 62:557567, 1996; l.a. bygrave, ﬁwhere have all the judges gone? re˚ections on judicial involvement in developing data protection law,ﬂ pp. 113125 in p. wahlgren, ed., it och juristutbildning, nordisk årsbok i rättsinformatik, 2000, jure ab stockholm, 2001; also published in privacy law and policy reporter 7:1114, 3336, 2000; and bygrave, data protection law, 2002, chapter 7.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 373by data privacy laws.43 these interests include ensuring adequate quality of personal information, ﬁcitizenfriendlyﬂ administration, proportionality of control, and rule of law. in norway, the insight that dataprivacy laws are concerned with more than safeguarding privacy extends beyond the academic community and into regulatory bodies. indeed, norway™s principal legislation on data privacy contains an objects clause specically referring to the need for ﬁadequate quality of personal informationﬂ (tilstrekkelig kvalitet på personopplysninger) in addition to the needs for privacy and personal integrity.44the equivalent laws of some other european countries also contain objects clauses embracing more than privacy. the broadestšif not boldestšexpression of aims is found in the french legislation: ﬁdata processing shall be at the service of every citizen. it shall develop in the context of international cooperation. it shall infringe neither human identity, nor the rights of man, nor privacy, nor individual or public liberties.ﬂ45also noteworthy is the express concern in the data privacy legislation of several german länder for maintaining state order based on the principle of separation of powers, and, concomitantly, for ensuring socalled information equilibrium (informationsgleichgewicht) between the legislature and other state organs. this ﬁequilibriumﬂ refers principally to a situation in which the legislature is able to get access to information (personal and/or nonpersonal) that is available to the executive.46at the same time, however, considerable uncertainty still seems to reign in many countries about exactly which interests and values are promoted by data privacy laws. this is re˚ected partly in academic discourse,47 partly in the absence in some laws of objects clauses formally 43 see generally, bygrave, data protection law, 2002, p. 137 et seq. and references cited therein.44 see norway™s personal data act of 2000 (lov om behandling av personopplysninger av 14. april 2000 nr. 31), §1(2).45 see france™s act regarding data processing, files and individual liberties of 1978 (loi no. 7817 du 6. janvier 1978 relative à l™informatique, aux chiers et aux libertés), §1.46 see further, bygrave, data protection law, 2002, p. 39; s. simitis, ed., kommentar zum bundesdatenschutzgesetz [commentary on the federal data protection act] 5th ed., nomos verlagsgesellschaft, badenbaden, 2003, p. 11.47 see, for example, d. korff, ﬁstudy on the protection of the rights and interests of legal persons with regard to the processing of personal data relating to such persons,ﬂ nal report to e.c. commission, october 1998, available at http://europa.eu.int/comm/internalmarket/en/dataprot/studies/legalen.htm (accessed oct. 10, 2003), p. 42 (ﬁ[t]here is a lack of clarity, of focus, over the very nature, aims and objects of data protection in the [european union] member states which is, not surprisingly, re˚ected in the international data protection instrumentsﬂ); and b.w. napier, ﬁinternational data protection standards and british experience,ﬂ informatica e diritto, nos. 12, pp. 83100, 1992, p. 85, hereinafter cited as napier, ﬁinternational data protection standards and british experience,ﬂ 1992) (claiming that, in britain, ﬁthe conceptual basis for data protection laws remains unclearﬂ).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.374 engaging privacy and information technology in a digital agespecifying particular interests or values that the legislation is intended to serve,48 and partly in the vague way in which existing objects clauses are often formulated.49b.3 societal and cultural support for privacy: a comparisonthis section addresses the issue of whether some nations and cultures are more supportive of privacy than others are. it also addresses the factors that might contribute to such differences.making accurate comparisons of the degree to which given countries or cultures respect privacy is fraught with difculty,50 which is partly due to the paucity of systematically collected empirical data51 and partly to the fact that concern for privacy within each country or culture is often uneven. in the united kingdom (u.k.), for example, proposals to introduce multipurpose personal identication number (pin) schemes similar to those in scandinavia52 have generally been treated with a great deal of antipathy, yet video surveillance of public places in the united kingdom53 seems to be considerably more extensive than that in scandinavian countries.48 see, for example, the u.k. data protection act of 1998 and denmark™s personal data act of 2000 (lov nr. 429 af 31. maj 2000 om behandling af personoplysninger).49 see, for example, council of europe convention for the protection of individuals with regard to automatic processing of personal data (european treaty series no. 108; adopted january 28, 1981), article 1 (specifying goals as protection of ﬁrights and fundamental freedoms, and in particular . . . right to privacyﬂ).50 this difculty obviously carries over into comparative assessment of various countries™ legal regimes for privacy protection. see, for example, c.d. raab and c.j. bennett, ﬁtaking the measure of privacy: can data protection be evaluated?ﬂ international review of administrative sciences 62:535556, 1996. equally problematic is the accurate comparison of privacy levels across historical periods. yet another issue, over which relatively little has been written, concerns discrepancies between various classes of persons within a given society in terms of the respective levels of privacy that they typically enjoy. for further discussion, see generally, bennett and raab, the governance of privacy, 2003, chapter 2.51 as bennett and raab (the governance of privacy, 2003, p. 15) remark, ﬁ[u]nfortunately, we have little systematic crossnational survey evidence about attitudes to privacy with which to investigate the nature and in˚uence of wider cultural attributes. much of th[e] argumentation tends, therefore, to invoke anecdotes or cultural stereotypes: ‚the englishman™s home is his castle,™ and so on.ﬂ52 further on the scandinavian pin schemes, see, for example, a.s. lunde, j. huebner, s. lettenstrom, s. lundeborg, and l. thygesen, the personnumber systems of sweden, norway, denmark and israel, u.s. department of health and human services, vital and health statistics, series 2, no. 84, dhhs publication no. (phs) 801358, 1980; also available at http://www.cdc.gov/nchs/data/series/sr02/sr02084.pdf (accessed oct. 4, 2003).53 for more on this surveillance, see, for example, s. davies, ﬁsurveillance on the streets,ﬂ privacy law and policy reporter 2:2426, 1995; der spiegel, july 5, 1999, pp. 122124; and a. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 375it is clear that levels of privacy across nations and cultures and across broad historical periods are in constant ˚ux. moreover, the ways in which human beings create, safeguard, and enhance their respective states of privacy and the extent to which they exhibit a desire for privacy vary from culture to culture according to a complex array of factors.54 at the same time, the desire for some level of privacy appears to be a panhuman trait. even in societies in which apparently little opportunity exists for physical or spatial solitude, human beings seem to adopt various strategies for cultivating other forms of social distance.55to the extent that a panhuman need for privacy exists, it appears to be rooted not so much in physiological or biological as in social factors. according to moore, the need for privacy is, in essence, socially created. moore™s seminal study indicates that an extensive, highly developed concern for privacy is only possible in a relatively complex society with a strongly felt division between a domestic private realm and public spherešﬁprivacy is minimal where technology and social organization are minimal.ﬂ56however, technological and organizational factors are not the sole determinants of privacy levels. also determinative are ideological factors. central among these are attitudes to the value of private life,57 attitudes webb, ﬁspy cameras vs. villains in britain,ﬂ united press international, march 8, 2002, available at http://www.upi.com/view.cfm?storyid=080320020208134448r (accessed nov. 6, 2003).54 see further, b. moore, privacy: studies in social and cultural history, m.e. sharpe, publishers, armonk, n.y., 1984 (hereinafter cited as moore, privacy, 1984); j.m. roberts and t. gregor, ﬁprivacy: a cultural view,ﬂ pp. 199225 in j.r. pennock and j.w. chapman, eds., privacy: nomos xiii, atherton press, new york, 1971; i. altman, ﬁprivacy regulation: culturally universal or culturally specic?,ﬂ journal of social issues 33:6684, 1977; westin, privacy and freedom, 1967; and flaherty, privacy in colonial new england, university press of virginia, charlottesville, 1972 (hereinafter cited as flaherty, privacy in colonial new england, 1972).55 see, for example, moore™s study (privacy, 1984) of the siriono indians in bolivia; flaherty™s study (privacy in colonial new england, 1972) of colonial society in new england; and r. lunheim and g. sindre, ﬁprivacy and computing: a cultural perspective,ﬂ pp. 2540 in r. sizer, l. yngström, h. kaspersen, and s. fischerhübner, eds., security and control of information technology in society, northholland, amsterdam, 1993, a study of a village society in rajasthan, northwest india (hereinafter cited as lunheim and sindre, ﬁprivacy and computing,ﬂ 1993).56 moore, privacy, 1984, p. 276. cf., inter alia, lunheim and sindre, ﬁprivacy and computing,ﬂ 1993, p. 28 (ﬁprivacy is a cultural construct encountered in virtually every society of some economic complexityﬂ); raes, 1989, p. 78 (noting that privacy today ﬁis as much a result of modern technology as technology is a threat to the private lives of citizensﬂ). for a particularly incisive sociological analysis of historical changes in levels and types of privacy, see shils, 1975, chapter 18.57 see, for example, h. arendt, the human condition, university of chicago press, 1958, p. 38 (noting that, in ancient athenian culture, the private sphere was often regarded as a domain of ﬁprivationﬂ). see also moore, privacy, 1984, p. 120 et seq. moore, however, disengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.376 engaging privacy and information technology in a digital ageto the worth of persons as individuals,58 and sensitivity to human beings™ noneconomic and emotional needs.59 concern for privacy tends to be high in societies espousing liberal ideals, particularly those of mill, locke, constant, and madison. as lukes notes, privacy in the sense of a ﬁsphere of thought and action that should be free from ‚public™ interferenceﬂ constitutes ﬁperhaps the central idea of liberalism.ﬂ60the liberal affection for privacy is amply demonstrated in the development of legal regimes for privacy protection. these regimes are most comprehensive in western liberal democracies. by contrast, such regimes are underdeveloped in most african and asian nations. it is tempting to view this situation as symptomatic of a propensity in african and asian cultures to place primary value on securing the interests and loyalties of the group at the expense of the individual. however, care must be taken not to pigeonhole countries and cultures in static categories, and provision for privacy rights is increasingly on the legislative agenda of some african and asian countries.it is also important to note that the united statesšoften portrayed as the citadel of liberal idealsšhas not seen t to protect privacy as extensively as some other nations have, notably canada and the member states of the european union (e.u.). consider, for example, the absence of comprehensive legislation on data privacy regulating the u.s. private sector and the lack of an independent agency (a data protection authority or a privacy commissioner) to specically oversee the regulation of data privacy matters.61 thus, within the western liberal democratic ﬁcamp,ﬂ cerns growing enthusiasm and respect for private life among athenians over the course of the 4th century b.c.; see moore, privacy, pp. 128133.58 see, for example, m. ethan katsh, the electronic media and the transformation of the law, oxford university press, new york, 1989, p. 192 (ﬁpart of the reason there was less privacy and less concern with privacy in earlier times is that the individual, the principal beneciary of a right to privacy, did not have the same status in the ancient world as in the modern eraﬂ). see further, f.d. schoeman, privacy and social freedom, cambridge university press, cambridge, 1992, chapters 6 and 7 (describing factors behind the emergence of individualism and a concomitant concern for privacy in western societies).59 see, for example, s. strömholm, right of privacy and rights of the personality: a comparative survey, p.a. norstedt and söners förlag, stockholm, 1967, pp. 1920 (viewing the development of legal rights to privacy as part and parcel of a ﬁhumanizationﬂ of western law; i.e., a trend toward greater legal sensitivity to the nonpecuniary interests of human beings).60 lukes, 1973, p. 62. cf. bennett and raab, the governance of privacy, 2003, pp. 2223 (ﬁthe political theory of privacy, in both the us and europe, has largely operated within a liberal paradigmﬂ).61 see also section b.4.2. for more on the differences between u.s. and european regulatory approaches in the data privacy eld, see, for example, a. charlesworth, ﬁclash of the data titans? us and eu data privacy regulation,ﬂ european public law 6(2):253274, 2000; j.r. reidenberg, ﬁresolving con˚icting international data privacy rules in cyberspace,ﬂ stanford law review 52:13151371, 2000; j.b. ritter, b.s. hayes, and h.l. judy, ﬁemerging engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 377considerable variation exists in legal regimes and readiness for safeguarding privacy.62a variation in legal regimes need not re˚ect differences in the support for privacy in various nations. for example, the variation might be due, at least in part, to differences in the extent to which persons in respective countries can take for granted that others will respect their privacy (independently of legal norms).63 in other words, it can be attributable to differences in perceptions of the degree to which privacy is or will be threatened. for instance, the comprehensive, bureaucratic nature of data privacy regulation in europe64 undoubtedly re˚ects traumas from relatively recent, rsthand experience there of totalitarian oppression.65 this heritage imparts both gravity and anxiety to european regulatory policy. conversely, in north america and australia, for example, the paucity of rsthand domestic experience of totalitarian oppression tends to make these countries™ regulatory policy in the eld relatively lax.variation between the privacy regimes of western states can also be symptomatic of differences in perceptions of the degree to which interests that compete with privacy, such as public safety and national security, warrant protection at the expense of privacy interests. in other words, the variation can be symptomatic of differing perceptions of the need for trends in international privacy law,ﬂ emory international law review 15:87155, 2001; and d.h. flaherty, protecting privacy in surveillance societies, university of north carolina press, chapel hill/london, 1989 (hereinafter cited as flaherty, protecting privacy in surveillance societies, 1989).62 see, generally, section b.4.63 it is claimed, for instance, that this difference accounts for the lack of judicial support in the united kingdom for a tort of breach of privacy, in contrast to the willingness of u.s. courts to develop such a tort: see, e.g., j. martin and a.r.d. norman, the computerized society, englewood cliffs, n.j., 1970, p. 468. however, other explanations have also been advanced for the nondevelopment of a right to privacy in english common law: see, e.g., napier, ﬁinternational data protection standards and british experience,ﬂ 1992, p. 85 (emphasizing the ﬁnarrowmindednessﬂ of english judges). for further detail on the divergent paths taken by english and american courts in developing a specic right of privacy under common law, see, inter alia, l. brittan, ﬁthe right of privacy in england and the united states,ﬂ tulane law review 37:235268, 1963; g. dworkin, ﬁprivacy and the law,ﬂ p. 113 et seq. in j.b. young, ed., privacy, wiley, chichester, 1978. in a decision of october 16, 2003, the house of lords unanimously held that a tort of invasion of privacy is not part of english law, thus dealing a serious if not fatal blow to the development of a separate privacy tort under u.k. common law: see wainwright v. home ofce [2003] u.k.h.l. 53, especially paragraphs 3035, available at http://www.bailii.org/uk/cases/ukhl/2003/53.html (accessed nov. 5, 2003). for an overview of other recent u.k. case law on privacy, see r. jay and a. hamilton, data protection: law and practice, sweet and maxwell, london: 2003, pp. 5669.64 see further, section b.4.2.65 see also k.s. selmer, ﬁelektronisk databehandling og rettssamfunnetﬂ [electronic data processing and legal society], pp. 4153 in forhandlingene ved det 30. nordiske juristmøtet, oslo 15.œ17. august 1984, part ii, oslo, 1984. engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.378 engaging privacy and information technology in a digital agesurveillance and control measures. this is seen most clearly in the impact on u.s. regulatory policy of the terrorist attacks of september 11, 2001. in the wake of those attacks, the united states has been more willing to place limitations on privacy rights.66yet other factors can play a role too. for instance, u.s. and, to a lesser extent, australian eschewal of omnibus data privacy legislation for the private sector is due partly to a distrust of a strong state role in in˚uencing the economy, combined with skepticism toward legally regulating the private sector except where ˚agrant imbalances of power are proven to exist between private partiesšimbalances that cannot be corrected except by legislative intervention.67the above differences aside, concern and support for privacy on the part of the general public seem to be broadly similar across the western world.68 there is abundant evidence from public opinion surveys that these levels of concern and support are relatively high,69 at least in the 66 see generally, electronic privacy information center and privacy international, privacy and human rights 2003: an international survey of privacy laws and developments, epic/pi, washington, d.c., 2003.67 with respect to u.s. attitudes, see, e.g., schwartz and reidenberg, data privacy law, 1996, p. 6 et seq.; and j.h. yurow, ﬁnational perspectives on data protection,ﬂ transnational data report 6(6):337339, 1983. for further analysis of the causes of divergence between western countries™ respective regimes for data privacy, see generally, c.j. bennett, regulating privacy: data protection and public policy in europe and the united states, cornell university press, ithaca, n.y., 1992, chapter 6 (hereinafter cited as bennett, regulating privacy, 1992). 68 as bennett notes, ﬁin nature and extent, the public concern for privacy is more striking for its crossnational similarities rather than for its differencesﬂ (bennett, regulating privacy, 1992, p. 43). it is, nevertheless, noteworthy that germans seem often to take data privacy issues a great deal more seriously than other nationalities do. a remarkable case in point is the high response rate of germanbased organizations and individuals to a paneuropean union questionnaire issued by the commission of the european communities in 2002 regarding certain data privacy issues. respondents registering germany as their place of residence accounted for approximately 40 percent of the total number of respondents for each questionnaire. see http://europa.eu.int/comm/internalmarket/en/dataprot/ lawreport/docs/consultationcontrollersen.pdf (accessed nov. 4, 2003); and http://europa.eu.int/comm/internalmarket/en/ dataprot/lawreport/docs/consultationcitizensen.pdf (accessed nov. 4, 2003).69 see generally bygrave, data protection law, 2002, p. 110 and references cited therein; and bennett and raab, the governance of privacy, 2003, pp. 5665 and references cited therein. the survey material referenced there derives mainly from the united states, canada, australia, norway, denmark, and the united kingdom. survey material from hungary seems largely to t with the ndings from the other countries: see i. székely, ﬁnew rights and old concerns: information privacy in public opinion and in the press in hungary,ﬂ informatization and the public sector 2:99113, 1994 . note, though, that surveys of public attitudes to privacy can suffer from methodological weaknesses that make it unwise to rely on their results as wholly accurate indications of public thinking: see further, for example, william h. dutton and robert g. meadow, ﬁa tolerance for surveillance: american public opinion concerning engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 379abstract.70 the concern for privacy is often accompanied by considerable pessimism over existing levels of privacy, along with a lack of trust that organizations will not misuse personal information.71 privacy concern tends to cut across a broad range of political leanings (within liberal democratic ideology),72 although there are occasional indications of statistically signicant variation in attitudes to privacy issues based on party or political attachments.73 in terms of the roles played by other demographic variables, such as age, sex, and income level, results appear to vary a great deal from country to country and survey to survey.74the survey evidence points toward increasing public sensitivity to the potential misuse of personal information. certainly, one nds, for example, concrete instances in which items of information that previously were routinely publicized are now subject to relatively stringent requirements of condentiality.75 perhaps more interesting, however, is whether indications exist of an opposite developmentšthat is, an increasing acclimatization of people to situations in which they are required to divulge personal information and a concomitant adjustment of what they privacy and civil liberties,ﬂ pp. 147170 in karen b. levitan, ed., government infostructures, greenwood press, westport, conn., 1987.70 privacy concerns tend often to be of secondorder signicance for the public, with problems such as public safety, unemployment, and nancial security being ranked as more important: see bygrave, data protection law, 2002, p. 110 and references cited therein.71 bygrave, data protection law, 2002, p. 111 and references cited therein.72 see further, bennett, regulating privacy, 1992, especially p. 147.73 see, for example, h. becker,ﬁbürger in der modernen informationsgesellschaftﬂ [citizens in the modern information society], pp. 343490 in informationsgesellschaft oder überwachungsstaat, hessendienst der staatskanzlei, wiesbaden, 1984; pp. 415416 cite survey results from (west) germany showing that supporters of the green party (die grünen) were more likely to view data privacy as important than were supporters of the more conservative political parties.74 compare, for example, i. székely, ﬁnew rights and old concerns: information privacy in public opinion and in the press in hungary,ﬂ informatization and the public sector 2:99113, 1994 (hungarian survey results appear to show that demographic variables play little role in determining public attitudes to privacy issues), with australian federal privacy commissioner, community attitudes to privacy, information paper 3, australian government publishing service, canberra, 1995 (demographic variables play a signicant role in australian survey results). compare also, e.g., the latter study (privacy of personal information found to be more important to highincome than lowincome earners) with l. harris and associates in association with a.f. westin, harrisequifax health information privacy survey 1993, equifax, atlanta, ga., 1994, p. 15 (lowincome earners express higher concern about privacy than highincome groups, except in relation to medical privacy issues).75 see, for example, h. torgersen, ﬁforskning og personvernﬂ [research and privacy], pp. 223239 in r.d. blekeli and k.s. selmer, eds., data og personvern, universitetsforlaget, oslo, 1977; p. 237 notes that, in norway, the quantity and detail of information publicly disclosed in connection with student matriculation were far greater in the 1960s than in the mid1970s and onward.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.380 engaging privacy and information technology in a digital ageperceive as problematic for their privacy. unfortunately, there seems to be little survey evidence addressing this point.nevertheless, it is pertinent to note that public concern for privacy has rarely resulted in mass political movements with privacy protection per se high on their agenda.76 in most western countries and even more so on the international plane, the actual formulation of law and policy on data privacy has typically been the project of a small elite.77it is tempting to draw a parallel between this state of affairs and the way in which privacy concerns were articulated and politically pushed in the 19th century, at least in the united states and germany. the movement for the legal recognition of privacy rights in those countries and at that time had largely genteel, elitist traits. it was, as westin observes, ﬁessentially a protest by spokesmen for patrician values against the rise of the political and cultural values of ‚mass society.™ﬂ78 this would be, however, an inaccurate (and unfair) characterization of the modern ﬁdata privacy elite.ﬂ the agenda of the latter is strongly democratic and egalitarian; it is much more concerned about the welfare of the citoyen (citizen) than simply about that of the bourgeois. and it selfconsciously draws much of its power from the privacy concerns of the general public.79b.4 regulatory policy on protection of privacy and personal information (data privacy)a number of legal instruments exist at both international and national levels that deal directly with data privacy.80 in addition, some instruments 76 see generally, bennett, regulating privacy, 1992, pp. 146, 243.77 bennett, regulating privacy, 1992, p. 127 et seq.78 westin, privacy and freedom, 1967, pp. 348349. see further, james barron, ﬁwarren and brandeis, the right to privacy (1890): demystifying a landmark citation,ﬂ suffolk u.l. rev. 13:875, 1979; and d.w. howe, ﬁvictorian culture in america,ﬂ pp. 328 in d.w. howe, ed., victorian america, university of pennsylvania press, philadelphia, 1976. for a similar critique with respect to the ideological and class roots of german ﬁpersönlichkeitsrecht,ﬂseepersönlichkeitsrecht,ﬂsee,ﬂ see p. schwerdtner, das persönlichkeitsrecht in der deutschen zivilordnung, j. schweitzer verlag, berlin, 1977, especially pp. 7, 85, and 92.79 see also bennett, regulating privacy, 1992, p. 129.80 at the risk of stating the obvious: to describe these instruments as dealing directly with ﬁdata privacyﬂ is to indicate that they specically regulate all or most stages in the processing of personal dataši.e., data that relate to, and facilitate identication of, an individual, physical/natural person (or, sometimes, collective entity)šwith a principal formal aim of safeguarding the privacy and/or related interests of that person. the main rules applied to the processing of such data embody a set of largely procedural, ﬁfair informationﬂ principles stipulating, e.g., the manner and purposes of data processing, measures to ensure adequate quality of the data, and measures to ensure transparency of the processing in relation to the person to whom the data relate (ﬁdata subjectﬂ). for more detail, see generally, bygrave, data protection law, 2002, particularly chapters 1, 3, 5, 18, and 19.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 381are not legally binding in a formal sense but are nevertheless highly in˚uential in the development of regulatory policy with respect to privacy.the legal systems of many, if not most, countries contain a variety of rules that embody elements of the basic principles typically found in data privacy instruments or that can otherwise promote these principles™ realization, albeit in incidental, ad hoc ways.81 however, what is primarily of interest in the following overview is the degree to which countries have adopted rule sets that are directly concerned with promoting data privacy. also of primary interest is the degree to which countries provide for the establishment of independent agencies (hereinafter termed ﬁdata privacy agenciesﬂ) specically charged with overseeing the implementation and/or further development of these rule sets.b.4.1 international instrumentsthe formal normative basis for data privacy laws derives mainly from catalogues of fundamental human rights set out in certain multilateral instruments, notably the universal declaration of human rights (udhr)82 and the international covenant on civil and political rights (iccpr),83 along with the main regional human rights treaties, such as the european convention on human rights and fundamental freedoms (echr)84 and the american convention on human rights (achr).85 all of these instrumentsšwith the exception of the african charter on human and people™s rights86šexpressly recognize privacy as a fundamental human right.87 not all human rights catalogues from outside the western, liberaldemocratic sphere repeat the african charter™s omission of privacy. for example, the cairo declaration on human rights in islam88 expressly recognizes a right to privacy for individuals (see the declaration™s article 18[b][c]).the right to privacy in these instruments is closely linked to the ideals and principles of data privacy laws, although other human rights, such as 81 rules concerning computer security, breach of condence, defamation, and intellectual property are examples.82 united nations (un) general assembly resolution 217 a (iii) of dec. 10, 1948.83 un general assembly resolution 2200a (xxi) of dec. 16, 1966; in force march 23, 1976.84 european treaty series no. 5; opened for signature nov. 4, 1950; in force sept. 3, 1953.85 oas treaty series no. 36; adopted nov. 22, 1969; in force july 18, 1978.86 oau doc. cab/leg/67/3 rev. 5; adopted june 27, 1981; in force oct. 21, 1986.87 see universal declaration of human rights (udhr), article 12; international covenant on civil and political rights (iccpr), article 17; european court of human rights (echr), article 8; american convention on human rights (achr), article 11. see also article v of the american declaration of the rights and duties of man (oas resolution xxx; adopted 1948).88 adopted aug. 5, 1990 (un doc. a/45/421/5/21797, p. 199).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.382 engaging privacy and information technology in a digital agefreedom from discrimination and freedom of expression, are relevant, too. the special importance of the right to privacy in this context is re˚ected in the fact that data privacy laws frequently single out protection of that right as central to their formal rationale.89 it is also re˚ected in case law developed pursuant to iccpr article 17 and echr article 8: both provisions have been authoritatively construed as requiring national implementation of the basic principles of data privacy laws.90 indeed, these provisions function, in effect, as data privacy instruments in themselves. however, case law has yet to apply them in ways that add signicantly to the principles already found in other data privacy laws, and in some respects the protection that they are currently held to offer falls short of the protection afforded by many of the latter instruments.91in terms of other international legal instruments, there does not exist a truly global convention or treaty dealing specically with data privacy. calls for such an instrument are occasionally made, although there are no concrete plans underway to draft one. the closest to such an instrument is the council of europe convention for the protection of individuals with regard to automatic processing of personal data (hereinafter termed the ﬁcoe conventionﬂ).92 while this is a european instrument, it is envisaged to be potentially more than an agreement between european states, as it 89 see, for example, article 1 of the council of europe convention on data privacy (note 49 above), article 2 of belgium™s 1992 act concerning the protection of personal privacy in relation to the processing of personal data (wet van 8. december 1992 tot bescherming van de persoonlijke levensfeer ten opzichte van de verwerkung van persoonsgegevens/loi du 8. décembre 1992 relative à la protection de la vie privée à l™égard des traitements de  données à caractère personnel); and the preamble to (and title of) australia™s federal privacy act of 1988.90 in relation to article 17 of the iccpr, see general comment 16 issued by the human rights committee on march 23, 1988 (un doc. a/43/40, pp. 180183), paragraphs 7 and 10. in relation to article 8 of the echr, see the judgments of the european court of human rights in, e.g., klass v. germany (1978), series a of the publications of the european court of human rights (ﬁaﬂ), 28; malone v. united kingdom (1984), a 82; leander v. sweden (1987), a 116; gaskin v. united kingdom (1989), a 160; kruslin v. france (1990), a 176a; niemitz v. germany (1992), a 251b; amann v. switzerland (2000), reports of judgments and decisions of the european court of human rights 2000i. see further, l.a. bygrave, ﬁdata protection pursuant to the right to privacy in human rights treaties,ﬂ international journal of law and information technology 6:247284, 1998.91 for instance, the right of persons to gain access to information kept about them by others is more limited under article 8 of the echr than it usually is under ordinary data privacy laws. further, uncertainty surrounds the degree to which article 8 may be applied in cases involving dataprocessing practices of the private sector. see further, l.a. bygrave, ﬁdata protection pursuant to the right to privacy in human rights treaties,ﬂ 1998.92 european treaty series no. 108; adopted jan. 28, 1981; in force oct. 1, 1985. further on the coe convention, see, for example, f. henke, die datenschutzkonvention des europarates [the data protection convention of the council of europe], peter lang, frankfurt am main/bern/new york, 1986; and bygrave, data protection law, 2002, especially p. 32.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 383is open to ratication by states not belonging to the council of europe (see article 23 of the coe convention). however, it has yet to be ratied by a nonmember state.93within the european union, several directives on data privacy have been adopted, the rst and most important of which is directive 95/46/ec on the protection of individuals with regard to the processing of personal data and on the free movement of such data (hereinafter termed the ﬁe.u. directiveﬂ).94 this instrument is binding on e.u. member states. it is also binding on nonmember states (norway, iceland, and liechtenstein) that are party to the 1992 agreement on the european economic area (eea). it is further binding on the 10, largely east european states (slovak  republic, czech republic, malta, poland, hungary, lithuania, latvia, estonia, slovenia, and cyprus) that became full˚edged members of the union on may 1, 2004. in other words, the directive is primarily a european instrument for european states. nevertheless, it exercises considerable in˚uence over other countries, not least because it prohibits (with some qualications) the transfer of personal data to those countries unless they provide ﬁadequateﬂ levels of data privacy (see articles 2526 of the e.u. directive).95 as shown below, many noneuropean countries are passing legislation in order to meet this adequacy criterion at least partly.96 93 note, though, that the european union, or, more accurately, european communities, has signaled a wish to accede to the coe convention. amendments to the convention were adopted on june 15, 1999, in order to permit accession by the european communities, but they are not yet in force. see further, bygrave, data protection law, 2002, p. 32.94 adopted oct. 24, 1995, ofcial journal of the european communities (o.j.), l 281, nov. 23, 1995, p. 31 et seq. two sectoral directives on data privacy have also been adopted. the rst of these was directive 97/66/ec of dec. 15, 1997, concerning the processing of personal data and the protection of privacy in the telecommunications sector (o.j. l 24, jan. 30, 1998, p. 1 et seq.). this has now been replaced by directive 2002/58/ec of july 12, 2002, concerning the processing of personal data and the protection of privacy in the electronic communications sector (o.j. l 201, july 31, 2002, p. 37 et seq.). further on the general directive, see, for instance, d.i. bainbridge, ec data protection directive, butterworths, london/dublin/edinburgh, 1996; s. simitis, ﬁfrom the market to the polis: the eu directive on the protection of personal data,ﬂ iowa law review 80:445469, 1995; u. damman and s. simitis, egdatenschutzrichtlinie: kommentar [e.c. directive on data protection: commentary] nomos verlagsgesellschaft, badenbaden, 1997; and bygrave, data protection law, 2002.95 see further, e.g., p.m. schwartz, ﬁeuropean data protection law and restrictions on international data flows,ﬂ iowa law review 80:471496, 1995, especially p. 483 et seq.; european union, data protection working party, ﬁtransfers of personal data to third countries: applying articles 25 and 26 of the eu data protection directive,ﬂ working document adopted july 24, 1998, available at http://europa.eu.int/comm/internalmarket/privacy/docs/wpdocs/1998/wp12en.pdf (accessed oct. 11, 2003); c. kuner, european data privacy law and online business, oxford university press, oxford, 2003, chapter 4; and bennett and raab, the governance of privacy, 2003, pp. 8185.96 further on this in˚uence: p.p. swire and r.e. litan, none of your business: world data flows, electronic commerce, and the european privacy directive, brookings institution press, engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.384 engaging privacy and information technology in a digital agefurthermore, the e.u. directive stipulates that the data privacy law of an e.u. state may apply outside the european union in certain circumstances, most notably if a data controller,97 based outside the european union, utilizes ﬁequipmentﬂ located in the state to process personal data for purposes other than merely transmitting the data through that state (see e.u. directive article 4[1][c]).98 all of these provisions give an impression that the european union, in effect, is legislating for the world.99apart from the above legal instruments, there exist numerous international and regional instruments on data privacy that take the form of guidelines, recommendations, or codes of practice. although ﬁsoft lawﬂ only, some of them carry a great deal of political and/or commercial weight; accordingly, they exercise considerable in˚uence on the development of data privacy law. for advanced industrial states generally, the most signicant of these instruments are the 1980 guidelines governing the protection of privacy and transborder flows of personal data (hereinafter termed ﬁoecd guidelinesﬂ), adopted by the organisation for economic cooperation and development (oecd).100 the oecd guidelines contain a set of data privacy principles similar to those stipulated in the coe convention. these guidelines have been very in˚uential in the drafting of data privacy laws and standards in noneuropean jurisdictions washington, d.c., 1998; g. shaffer, ﬁglobalization and social protection: the impact of e.u. and international rules in ratcheting up of u.s. privacy standards,ﬂ yale journal of international law 25:188, 2000; and n. waters, ﬁthe european in˚uence on privacy law and practice,ﬂ privacy law and policy reporter 9:150155, 2003.97 a ﬁdata controllerﬂ is a person or organization that determines the purposes and means of processing personal data: see e.u. directive, article 2(d).98 see further, l.a. bygrave, ﬁdetermining applicable law pursuant to european data protection legislation,ﬂ computer law and security report 16:252257, 2000; kuner, european data privacy law and online business, 2003, chapter 3; and a. charlesworth, ﬁinformation privacy law in the european union: e pluribus unum or ex uno plures?,ﬂ hastings law journal 54:931969, 2003.99 equally, they nourish accusations of ﬁregulatory overreaching.ﬂ see particularly the criticism of article 4(1)(c) in bygrave, ﬁdetermining applicable law pursuant to european data protection legislation,ﬂ 2000. see also the more general criticism (from u.s. and australian quarters) in a. lukas, ﬁsafe harbor or stormy waters? living with the eu data protection directive,ﬂ trade policy analysis paper no. 16, cato institute, washington, d.c., oct. 30, 2001; p. ford, ﬁimplementing the ec directive on data protectionšan outside perspective,ﬂ privacy law and policy reporter 9:141149, 2003.100 adopted by oecd council on sept. 23, 1980 (oecd doc. c(80)58/final). for further discussion of the guidelines, see p. seipel, ﬁtransborder flows of personal data: re˚ections on the oecd guidelines,ﬂ transnational data report 4:3244, 1981. the oecd has issued other guidelines also relating, albeit more indirectly, to data privacy: see guidelines for the security of information systems (adopted nov. 26, 1992)šnow replaced by guidelines for the security of information systems and networks: towards a culture of security (adopted july 25, 2002); guidelines for cryptography policy (adopted march 27, 1997); and guidelines for consumer protection in the context of electronic commerce (adopted dec. 9, 1999).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 385such as australia, new zealand, and canada.101 they have also been formally endorsedšbut not necessarily implementedšby numerous companies and trade associations in the united states.102 furthermore, they constitute an important point of departure for the ongoing efforts by the asiapacic economic cooperation (apec) to draft a set of common data privacy principles for jurisdictions in the asiapacic region.103of potentially broader reach are the united nations (un) guidelines concerning computerized personal data files (hereinafter termed ﬁun guidelinesﬂ), adopted in 1990.104 the un guidelines are intended to encourage the enactment of data privacy laws in un member states lacking such legislation. these guidelines are also aimed at encouraging international organizationsšboth governmental and nongovernmentalšto process personal data in a responsible, fair, and ﬁprivacyfriendlyﬂ manner. however, the un guidelines seem to have had little practical effect relative to the oecd guidelines and the other instruments canvassed above.105 nevertheless, their adoption underlines the reality that data privacy is not simply a ﬁfirst world,ﬂ western concern. moreover, in several respects, the principles in the un guidelines go farther than some of the other international instruments.106note should also be taken of the numerous recommendations and codes that are of sectoral application only. the coe convention, for 101 reference to the oecd guidelines is made in the preambles to both australia™s federal privacy act of 1988 and new zealand™s privacy act of 1993. further on the oecd guidelines™ importance for australian policy, see ford, ﬁimplementing the ec directive on data protectionšan outside perspective,ﬂ 2003. in canada, the oecd guidelines formed the basis for the canadian standards association™s model code for the protection of personal information (can/csaq83096), adopted in march 1996. the model code has been incorporated into canadian legislation as schedule 1 to the personal information protection and electronic documents act of 2000.102 see, for example, r.m. gellman, ﬁfragmented, incomplete, and discontinuous: the failure of federal privacy regulatory proposals and institutions,ﬂ software law journal 6:199238, 1993.103 see generally, the documentation collated at http://www.apecsec.org.sg/apec/documents reports/electroniccommercesteeringgroup/2003.html (accessed nov. 8, 2003). see also g. greenleaf, ﬁaustralia™s apec privacy initiative: the pros and cons of ‚oecd lite,™ﬂ privacy law and policy reporter 10:16, 2003; g. greenleaf, ﬁapec privacy principles version 2: not quite so lite, and nz wants oecd full strength,ﬂ privacy law and policy reporter 10:4548, 2003. further on apec generally, see http://www.apecsec.org.sg (accessed nov. 2, 2003).104 on the background to the oecd guidelines, see, for instance, j. michael, privacy and human rights: an international and comparative study, with special reference to developments in information technology, unesco/dartmouth publishing company, paris/aldershot, 1994, pp. 2126.105 this is partly re˚ected in the fact that they are frequently overlooked in data privacy discourse, at least in scandinavia; see bygrave, data protection law, 2002, p. 33 and references cited therein.106 for details, see bygrave, data protection law, 2002, pp. 73, 350.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.386 engaging privacy and information technology in a digital ageinstance, has issued a large range of sectorspecic recommendations to supplement and extend the rules in its convention on data privacy. these recommendations cover, inter alia, the police sector,107 employment,108 research and statistics,109 and telecommunications.110 another noteworthy instance is the code of practice issued by the international labor organization (ilo) on data privacy in the workplace.111the principal international instruments dealing specically with data privacy tend to be aimed at encouraging not just the enactment of national rules but also the harmonization of these rules. in turn, the harmonization objective has several rationales, some of which are concerned not so much with enhancing data privacy as with facilitating the ˚ow of personal data across national borders in order to maintain international commerce, freedom of expression, and intergovernment cooperation.112 the latter concerns arise because many national data privacy lawsšmainly europeanšhave long operated with rules providing for restrictions of data ˚ow to countries not offering levels of data privacy similar to those of the ﬁexportingﬂ jurisdiction.113while the practical effect of such rules on actual transborder data ˚ow tends to have been negligible for the most part,114 the potential impact of these rules has caused much consternation, particularly for business interests. concern to minimize this impact in order to safeguard trade is most prominent in the oecd guidelines and e.u. directive.115 the 107 recommendation no. r (87) 15 regulating the use of personal data in the police sector, adopted sept. 17, 1987.108 recommendation no. r (89) 2 on the protection of personal data used for employment purposes, adopted jan. 18, 1989.109 recommendation no. r (83) 10 on the protection of personal data used for scientic research and statistics, adopted sept. 23, 1983, and recommendation no. r (97) 18 on the protection of personal data collected and processed for statistical purposes, adopted sept. 30, 1997.110 recommendation no. r (95) 4 on the protection of personal data in the area of telecommunications services, with particular reference to telephone services, adopted feb. 7, 1995.111 protection of workers™ personal data, i.l.o., geneva, 1997.112 see generally, bygrave, data protection law, 2002, p. 40, and references cited therein.113 see further, inter alia, a.c.m. nugter, transborder flow of personal data within the ec, kluwer law and taxation publishers, deventer/boston, 1990; r. ellger, der datenschutz im grenzüberschreitende datenverkehr: eine rechtsvergleichende und kollisionsrechtliche untersuchung [data protection with respect to crossborder data trafc: a comparative law and con˚ictoflaws study], nomos verlagsgesellschaft, badenbaden, 1990 (hereinafter cited as ellger, der datenschutz im grenzüberschreitende datenverkehr, 1990); and schwartz, ﬁeuropean data protection law and restrictions on international data flows,ﬂ 1995.114 see, for example, the extensive survey in ellger, der datenschutz im grenzüberschreitende datenverkehr, 1990.115 see bygrave, data protection law, 2002, p. 40 and references cited therein.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 387latter goes the farthest in securing transborder data ˚ow by prohibiting e.u. member states from instituting privacyrelated restrictions on data transfer to other member states (see e.u. directive, article 1[2]). this prohibition is primarily grounded in the need to facilitate realization of the european union™s internal market.116 at the same time, however, the e.u. directive goes the farthest of the international instruments in restricting transborder data ˚ow, through its qualied prohibition of data transfer to none.u. states that fail to provide ﬁadequateﬂ levels of data privacy (e.u. directive article 25).the adequacy criterion could be regarded as evidence that economic protectionism forms part of the e.u. directive™s agendašthat is, it re˚ects a desire to protect european industry from foreign competition. allegations of economic protectionism have been directed at earlier european data privacy regimes,117 but little solid evidence exists to support them.118 while there is perhaps more evidence linking the origins of the e.u. directive to protectionist concerns, the linkage is still tenuous.119 considerably moresolid grounds exist for viewing the adequacy criterion as prima facie indication that the directive is seriously concerned with safeguarding privacy interests and rights. this concern is also manifest in the preamble to the directive,120 in recent case law from the european court of justice,121 and increasingly in the e.u. legal system generally. particularly noteworthy is the growing recognition in the european union that the protection of data privacy is in itself (i.e., separate from the broader right to privacy) a basic human right.122despite their harmonizing objectives, the international instruments tend to leave countries a signicant degree of leeway in the development 116 see particularly recitals 3, 5, and 7 in the preamble to the e.u. directive.117 see, e.g., k.r. pinegar, ﬁprivacy protection acts: privacy protectionism or economic protectionism?ﬂ international business lawyer 12:183188, 1984; r.p. mcguire, ﬁthe information age: an introduction to transborder data flow,ﬂ jurimetrics journal 20:17, 19791980; j.m. eger, ﬁemerging restrictions on transborder data flow: privacy protection or nontariff trade barriers,ﬂ law and policy in international business 10:10551103, 1978.118 see the discussion in bygrave, data protection law, 2002, pp. 114115 and references cited therein.119 see the discussion in bygrave, data protection law, 2002, pp. 114115 and references cited therein.120 see particularly, recitals 2, 3, 10, and 11.121 see judgment of may 20, 2003, in joined cases c465/00, c138/01, and c139/01,  österreichischer rundfunk and others [2003] ecr i0000, particularly paragraph 71 et seq.122 see charter of fundamental rights of the european union, adopted dec. 7, 2000 (o.j. c 364, dec. 18, 2000, p. 1 et seq.), article 8 (providing for a right to protection of personal data) and article 7 (providing for the right to respect for private and family life). see also the right to protection of personal data in article 50 of the draft treaty establishing a constitution for europe (conv. 850/03, brussels, july 18, 2003; available at http://europeanconvention.eu.int/docs/treaty/cv00850.en03.pdf, accessed oct. 25, 2003).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.388 engaging privacy and information technology in a digital ageof their respective data privacy regimes. this is especially the case with the ﬁsoft lawﬂ instruments, but the legally binding instruments also allow for considerable national ˚exibility. the coe convention is not intended to be selfexecuting, and it permits derogations on signicant points.123 the e.u. directive has more prescriptive bite than its counterparts, but it is still aimed only at facilitating an ﬁapproximationﬂ as opposed to the complete uniformity of national laws (see particularly recital 9 in its preamble). accordingly, it leaves e.u. member states considerable margin for maneuver.124of all of the instruments canvassed above, the e.u. directive has become the leading trendsetter and benchmark for data privacy around the world. not only is it shaping national data protection regimes, it is also shaping international instruments. for example, the coe convention has recently been supplemented by a protocol containing rules that essentially duplicate the rules in the e.u. directive dealing respectively with the ˚ow of personal data to nonmember states and with the competence of national data privacy authorities.125 outside europe, clear traces of the e.u. directive are to be found in the draft guidelines on the protection of personal information and privacy drawn up by the asia pacic telecommunity (apt)126 and in the draft asiapacic privacy charter drawn up by the asiapacic privacy charter council (appcc).127nevertheless, the leadership status of the e.u. directive could face a serious challenge in the asiapacic region if apec is able to agree on a common set of data privacy principles for its 21 member states. there are indications that the principles are likely to be inspired more by the oecd guidelines than by the e.u. directive, and at the same time they are likely to be less privacyprotective than the directive and possibly than the guidelines.128 work on the principles signals a readiness among 123 see p. henke, die datenschutzkonvention des europarates, 1986, especially pp. 5760; and bygrave, data protection law, 2002, p. 34.124 see further, bygrave, data protection law, 2002, p. 34 and references cited therein. see also section 4.6.125 additional protocol to the convention for the protection of individuals with regard to automatic processing of personal data (ets no. 108) regarding supervisory authorities and transborder data ˚ows (adopted may 23, 2001; not yet in force).126 draft of september 2003; on le with author but not publicly available. further on the apt, see http://www.aptsec.org (accessed oct. 26, 2003).127 see version 1.0 of the charter, dated sept. 3, 2003; on le with author but not publicly available. for more on the appcc and its work, see g. greenleaf, ﬁthe asiapacic privacy charter council: a regional ‚civil society™ initiative,ﬂ privacy law and policy reporter 10:4950, 2003; and the appcc home page at http://www.austlii.edu.au/au/special/cyberlpc/appcc (accessed oct. 25, 2003).128 see g. greenleaf, ﬁaustralia™s apec privacy initiative: the pros and cons of ‚oecd lite™,ﬂ privacy law and policy reporter 10:16, 2003. cf. g. greenleaf, ﬁapec privacy prinengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 389many of the apec states to forge their own approach to data privacy without necessarily conforming to european norms. this approach would appear to foster data privacy regimes less because of concern to protect basic human rights than over concern to engender consumer condence in business.129b.4.2 national instrumentswell over 30 countries have enacted data privacy laws, and their number is growing steadily.130 most of these countries are european. indeed, europe is home to the oldest, most comprehensive, and most bureaucratically cumbersome data privacy laws at both national and provincial levels. moreover, as shown above, europešthrough its supranational institutionsšis also a springboard for the most ambitious and extensive international initiatives in the eld.common points of departure for national data privacy regimes in europe are as follows:ł coverage of both public and private sectors;ł coverage of both automated and manual systems for processing personal data, largely irrespective of how the data are structured;ł application of broad denitions of ﬁpersonal dataﬂ;ł application of extensive sets of procedural principles, some of which are rarely found in data privacy regimes elsewhere;131ł more stringent regulation of certain categories of sensitive data (e.g., data relating to philosophical beliefs, sexual preferences, ethnic origins);ciples version 2: not quite so lite, and nz wants oecd full strength,ﬂ privacy law and policy reporter 10:4548, 2003 (noting that more recent drafts of the principles have been strengthened, though certainly not to the level of the e.u. directive).129 see r. tang, ﬁpersonal data privacy: the asian agenda,ﬂ speech given at 25th international conference of data protection and privacy commissioners, sydney, sept. 10, 2003; available at http://www.privacyconference2003.org/program.asp#psa (accessed oct. 10, 2003).130 see generally, electronic privacy information center and privacy international, privacy and human rights 2003, electronic privacy information center and privacy international, washington, d.c., 2003, which gives a fairly uptodate overview of the state of data privacy regimes in more than 50 countries. a complementary, though less comprehensive, overview is given in m. henry, ed., international privacy, publicity and personality laws, butterworths, london, 2001.131 an example of a principle that is unique to european laws concerns fully automated proling. the principle is that fully automated assessments of a person™s character should not form the sole basis of decisions that impinge on the person™s interests. the principle is embodied in article 15 of the e.u. directive: see further, bygrave, data protection law, 2002, pp. 319328.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.390 engaging privacy and information technology in a digital ageł restrictions on the transborder ˚ow of personal data;ł establishment of independent data privacy agencies with broad discretionary powers to oversee the implementation and development of data privacy rules;ł channeling of privacy complaints to these agencies rather than to the courts;ł extensive subjection of data processing to the notication and/or licensing requirements administered by the data privacy agencies;ł extensive use of ﬁoptinﬂ requirements for valid consent by data subjects; andł little use of industrydeveloped codes of practice.132the majority of these characteristics were originally typical for data privacy laws in west european countries. owing largely to the e.u. directive, they are now also typical for the laws of most east european countries. nevertheless, it is important to note that each country has its own unique mix of rules;133 concomitantly, a good deal of variation exists in the degree to which each country shares the abovelisted traits.134 for example, the netherlands has always made relatively extensive use of 132 see further, for example, bygrave, data protection law, 2002, especially chapters 2 through 4, and kuner, european data privacy law and online business, 2003. for older accounts, see, for example, hondius, emerging data protection in europe, 1975; and h. burkert, ﬁinstitutions of data protectionšan attempt at a functional explanation of european national data protection laws,ﬂ computer/law journal 3:167188, 19811982.133 for indepth treatment of, e.g., u.k. law, see r. jay and a. hamilton, data protection: law and practice, sweet and maxwell, london, 2003; of german law, see s. simitis, kommentar zum bundesdatenschutzgesetz [commentary on the alliance data protection law], 2003; of italian law, see g. buttarelli, banche dati e tutela della riservatezza: la privacy nella società dell™informazione [data banks and the protection of condentiality: the privacy of information in society], giuffrè editore, milan, 1997; of swiss law, see u. maurer and n.p. vogt., eds., kommentar zum schweizerischen datenschutzgesetz [commentary on the swiss data protection act], helbing and lichtenhahn, basel/frankfurt am main, 1995. for overviews of the data privacy laws of denmark, finland, norway, and sweden, see p. blume, ed., nordic data protection, djøf publishing, copenhagen, 2001. otherwise, see the more detailed analyses of danish law in p. blume, personoplysningsloven [the personal data act], greens§jura, denmark, 2000; and k.k. nielsen and h. waaben, lov om behandling af personoplysningeršmed kommentarer [act on processing of personal datašwith commentary], juristg økonomforbundets forlag, copenhagen, 2001; of norwegian law in m. wiik johansen, k.b. kaspersen, and å.m. bergseng skullerud, personopplysningsloven. kommentarutgave [personal data act. commentary edition], universitetsforlaget, oslo, 2001; of swedish law in s. öman and h.o. lindblom, personuppgiftslagen: en kommentar [personal data act: a commentary], norstedts juridik, stockholm, 2001. english translations of the principal data privacy laws of all current e.u. member states are collated in s. simitis, u. dammann, and m. körner, eds., data protection in the european community: the statutory provisions, nomos verlagsgesellschaft, badenbaden, 1992 (looseleaf, continually updated).134 see further, korff, 2002.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 391industrybased codes of practice, and the e.u. directive itself encourages greater use of such codes (see e.u. directive, article 27). moreover, data privacy regimes in each country are far from static. for example, swedish legislation originally operated with relatively extensive licensing and notication requirements; now it has dispensed entirely with a licensing scheme and cut back notication requirements to a minimum. there is movement too at a broader european level. for instance, while west european data privacy regimes have traditionally relied heavily on paternalistic control mechanisms,135 they now show greater readiness to rely more on citizen action, supplemented by greater readiness to embrace market mechanisms for the regulation of data processing. this notwithstanding, european jurisdictions (in contrast to, say, the united states) generally still maintain a relatively nonnegotiable legislative baseline for the private sector.across the atlantic, canada comes closest of the north american countries to embracing the european approach. there is now federal legislation in place in canada to ensure the comprehensive protection of data privacy in relation to both the public and private sectors.136 some canadian provinces have already enacted data privacy legislation in relation to provincial and local government agencies and/or the private sector.137 data privacy agencies exist at both federal and provincial levels. the commission of the european communities (hereinafter termed ﬁeuropean commissionﬂ) has formally ruled that, in general, canada offers ﬁadequateﬂ protection for data privacy pursuant to article 25 of the e.u. directive.138by contrast, the u.s. legal regime for data privacy is much more atomized. while there is fairly comprehensive legislation dealing with federal government agencies,139 omnibus legislative solutions are eschewed with respect to the private sector. legal protection of data privacy in relation 135 that is, control exercised by government bodies (primarily data privacy agencies) on behalf and supposedly in the best interests of citizens (data subjects).136 see privacy act of 1982; personal information protection and electronic documents act of 2000.137 see, for example, quebec™s act on protection of personal information in the private sector of 1993.138 decision 2002/2/ec of 20.12.2001 pursuant to directive 95/46/ec of the european parliament and of the council on the adequate protection of personal data provided by the canadian personal information protection and electronic documents act (o.j. l 2, jan. 4, 2002, p. 13 et seq.).139 most notably the privacy act of 1974 (p.l. 93579) and the computer matching and privacy protection act of 1988 (p.l. 100503). note also the limited protection of data privacy afforded under the constitution as construed by the supreme court: see especially whalen v. roe, 429 u.s. 589 (1977). see further, for instance, schwartz and reidenberg, data privacy law, 1996, chapter 4.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.392 engaging privacy and information technology in a digital ageto the latter takes the form of ad hoc, narrowly circumscribed, sectorspecic legislation, combined with recourse to litigation based on the tort of invasionofprivacy and/or breachoftradepractices legislation.140 europeanstyle data privacy agencies do not exist in the united states. at the same time, however, a ﬁsafe harborﬂ agreement has been concluded between the united states and the european union allowing for the ˚ow of personal data from the european union to u.s.based companies that voluntarily agree to abide by a set of ﬁfair informationﬂ principles based loosely on the e.u. directive. the scheme, which so far has attracted approximately 400 companies,141 has been held by the european commission to satisfy the e.u. directive™s adequacy test in article 25.142in south america, argentina has come the farthest in developing a comprehensive legal regime for data privacy. it enacted legislation in 2000143 modeled on the e.u. directive and equivalent spanish legislation and formally based on the right of habeas data provided in its constitution (article 43).144 the european commission has formally ruled that argentina satises the adequacy criterion of the e.u. directive.145 other south american countries, such as brazil and chile, also provide constitutional protections for privacy rights and habeas data, but otherwise their legislation on data privacy is relatively scant. they lack also data privacy agencies.146in the asiapacic region, there exist a handful of relatively comprehensive legislative regimes on data privacyšmost notably those in 140 see generally, the overview in schwartz and reidenberg, data privacy law, 1996, especially chapters 9 through 14.141 see http://web.ita.doc.gov/safeharbor/shlist.nsf/webpages/safe+harbor+list (accessed nov. 6, 2003).142 decision 2000/520/ec of july 26, 2000, pursuant to directive 95/46/ec of the european parliament and of the council on the adequacy of the protection provided by the safe harbor privacy principles and related frequently asked questions issued by the u.s. department of commerce (o.j. l 215, aug. 25, 2000, p. 7 et seq.).143 law for the protection of personal data of 2000.144 see further electronic privacy information center and privacy international, privacy and human rights, 2003, pp. 132139 (hereinafter cited as electronic privacy information center and privacy international, privacy and human rights 2003, 2003). the right of habeas data is, in general, designed to protect the image, privacy, honor, information selfdetermination, and freedom of information of a person. enforcement of the right is provided by granting an individual the right to petition a court to nd out what information is being held or to request the correction, updating, or destruction of the personal information being held.145 decision c (2003) 1731 of june 30, 2003, pursuant to directive 95/46/ec of the european parliament and of the council on the adequate protection of personal data in argentina (o.j. l 168, july 5, 2003).146 see further, electronic privacy information center and privacy international, privacy and human rights 2003, 2003, pp. 167171, 195197.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 393australia, new zealand, hong kong, korea, and japan.147 most of these jurisdictionsšbut not japanšhave also established data privacy agencies. new zealand has been the fastest and perhaps most ambitious of these jurisdictions in the data privacy eld; it was the rst to enact data privacy legislation spanning the public and private sectors.148 australian, korean, and japanese legislation in the eld was initially limited largely to regulating the dataprocessing activities of government agencies,149 but it has recently been extended to cover the private sector as well.150 however, some of these extensions still leave large gaps in private sector coverage.151 other aspects of the laws in question also diverge from the e.u. model(s).152 not surprisingly, none of the countries concerned has yet been formally recognized by the european commission as offering adequate protection pursuant to the e.u. directive.data privacy regimes in other asiapacic jurisdictions tend to be rather patchy in coverage and enforcement levels. thailand, for instance, 147 further on australian law, see, e.g., g.l. hughes and m. jackson, hughes on data protection in australia, 2001; on new zealand law, see e. longworth and t. mcbride, the privacy act: a guide, gp publications, wellington, 1994 (hereinafter cited as longworth and mcbride, the privacy act, 1994); and p. roth, privacy law and practice, butterworths/lexisnexis, wellington, 1994 (looseleaf, regularly updated) (hereinafter cited as roth, privacy law and practice, 1994); on hong kong law, see m. berthold and r. wacks, hong kong data privacy law: territorial regulation in a borderless world, 2nd edition, sweet and maxwell, asia, 2003; on korean law, see c.b. yi and k.j. ok, ﬁkorea™s personal information protection laws,ﬂ privacy law and policy reporter 9:172179, 2003; and h.b. chung, ﬁantispam regulations in korea,ﬂ privacy law and policy reporter 10:1519, 2003; on japanese law, see d. case and y. ogiwara, ﬁjapan™s new personal information protection law,ﬂ privacy law and policy reporter 10:7779, 2003.148 see privacy act of 1993. further on the act, see longworth and mcbride, the privacy act, 1994; and roth, privacy law and practice, 1994.149 for australia, see privacy act of 1988; for japan, see act for protection of computerprocessed personal data held by administrative organs of 1988; for korea, see act on protection of personal information maintained by public agencies of 1994.150 for australia, see privacy amendment (private sector) act of 2000; for japan, see privacy law of 2003; for korea, see act on promotion of information and communications network utilization and information protection . . . of 1999. note, too, that several of the australian states have enacted data privacy laws covering their respective government agencies and, to a lesser extent, the health sector. see, for example, victoria™s information privacy act of 2000 and health records act of 2001.151 for example, with a few exceptions, the australian legislation does not apply to ﬁsmall business operators,ﬂ that is, businesses with an annual turnover of aud$3 million or less (see federal privacy act, sections 6c1, 6d, 6da, and 6e). another major gap is that the legislation does not cover the processing of data by employers about their present and past employees (as long as the processing is directly related to the employment relationship) (section 7b(3)).152 the japanese laws, for example, do not formally operate with a distinction between sensitive and nonsensitive data, and they make relatively extensive use of ﬁoptoutﬂ consent mechanisms.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.394 engaging privacy and information technology in a digital agehas inserted data privacy rules covering the government sector in legislation dealing primarily with freedom of government information.153 singapore has so far decided to establish a data privacy regime based on voluntary, selfregulatory schemes that are linked with its national trust mark program.154 the primary catalyst for the schemes seems to be commercial concerns.155 the people™s republic of china lacks any credible data privacy regime. some legal rules have been adopted that potentially provide indirect protection for data privacy,156 but their operational potential is rendered nugatory by a political culture that traditionally shows scant respect for personal privacy.157 moreover, there is little, if any, sign that china is ready to adopt more effective data privacy rules in order to meet e.u. adequacy standards. by contrast, india is reported to be considering the enactment of a data privacy law modeled on the e.u. directive largely owing to a fear that its burgeoning outsourcing industry will ˚ounder without such legislation in place.158legal regimes for data privacy are least developed in the african countries, taken as a whole. as noted above, the african charter on human and people™s rights of 1981 omits mentioning a right to privacy in its catalog of basic human rights. moreover, none of the african countries has enacted comprehensive data privacy laws.nevertheless, some countries display increasing interest in legislating on data privacy. this interest is partly due to the obligations imposed by iccpr article 17. it is also probably due partly to a desire to meet the adequacy requirements of e.u. directive articles 25 and 26. in some cases, stimulus is also provided by recent rsthand experience of mass oppression. the republic of south africa has come farthest along the path to establishing a comprehensive legal regime on data privacy. express provision for a right to privacy is made in section 14 of the south african bill of rights set out in chapter 2 of its constitution of 1996. also included (in section 32) is a broad right of access to information held in both the public and private sectors. freedomofinformation legislation 153 see ofcial information act of 1997, described in c. opassiriwit, ﬁthailand: a case study in the interrelationship between freedom of information and privacy,ﬂ privacy law and policy reporter 9:9195, 2002.154 see model data protection code for the private sector of 2002; industry content code of 2002.155 for criticism of the schemes, see g. greenleaf, ﬁsingapore takes the softest privacy options,ﬂ privacy law and policy reporter 8:169173, 2002.156 see further, electronic privacy information center and privacy international, privacy and human rights 2003, 2003, pp. 197200.157 electronic privacy information center and privacy international, privacy and human rights 2003, 2003, pp. 200210.158 see a. pedersen, ﬁindia plans eustyle data law,ﬂ privacy laws and business, may/june, no. 68, pp. 1, 3, 2003.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 395based on the latter right was enacted in 2002,159 and work is proceeding on a bill for separate data privacy legislation.160 kenya is also drafting a new constitution containing rights similar to those in the south african constitution.161b.4.3 relative impact of regulatory regimesa comparative evaluation of the impact of the various regulatory regimes canvassed above is both complex and beset by numerous potential pitfalls. the complexity of the task arises partly from the multiple facets of impact measurement: impact needs to be evaluated in terms of economy (i.e., the cost of setting up the regime), efciency (i.e., the cost of the regime measured against its practical results), effectiveness (i.e., the extent to which the practical results of the regime fulll its ultimate aims), and equity (i.e., the extent to which the regime extends protection equitably across social groups).162further complicating matters is that each country™s data privacy regime consists of more than formal legal rules. while the latter, together with formal oversight mechanisms, are important constituents of a data privacy regime, they are supplemented by a complex array of other instruments and institutionsšinformation systems, industry codes, standards, and so onšthat concurrently in˚uence the practical impact of the legal rules. the functioning of a data privacy regime (including, of course, the extent to which ﬁlaw in booksﬂ equates with ﬁlaw in practiceﬂ) will also be shaped by a myriad of relatively informal customs and attitudes that prevail in the country concernedšfor example, the extent to which the country™s administrative and corporate cultures are imbued with a respect for authority or respect for ﬁfair informationﬂ principles.163 it goes without saying that many of these factors can be easily overlooked or misconstrued. their existence means, for instance, that it cannot be assumed that a data privacy agency with strong formal powers will necessarily have 159 see i. currie and j. klaaren, the promotion of access to information act commentary, siber ink, south africa, 2002, pp. 11, 18 (hereinafter cited as currie and klaaren, the promotion of access to information act, 2002). a unique feature of the legislation is that it provides, as a point of departure, for freedomofinformation rights not just in relation to information held by government agencies but also information held in the private sector.160 see currie and klaaren, the promotion of access to information act, 2002. see also electronic privacy information center and privacy international, privacy and human rights 2003, 2003, p. 450.161 see sections 14 (right of privacy) and 47 (rights of information access and rectication) of the draft bill for the constitution of the republic of kenya (version of sept. 27, 2002).162 this classication of criteria is based on bennett and raab, the governance of privacy, 2003, p. 193 et seq.163 see generally, flaherty, protecting privacy in surveillance societies, 1989.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.396 engaging privacy and information technology in a digital agegreater success in fullling its objectives than that achieved by an agency with weaker formal powers.164yet another complicating element is that the regulatory approach of many data privacy agencies can obscure their positive achievements. agencies frequently prefer to resolve con˚ict in a relatively quiet way, through ﬁbackroomﬂ negotiation rather than by publicly striking out with the threatened use of punitive sanctions.165 further, agencies are often equally concerned, if not more so, about curbing an unrealized potential for privacyinvasive activity as about providing a remedy after such activity occurs. measuring the impact of anticipatory forms of control can be more difcult than for reactive, ex post facto control forms.166these problems notwithstanding, a large degree of consensus exists among experts in the eld regarding the relative strengths of certain data privacy regimes. part of this consensus is a view that the u.s. data privacy regime is weaker in fundamental respects than the equivalent regimes in many other countries, particularly those in europe, which have had some in˚uence in restricting certain dataprocessing practices and raising awareness of the importance of privacy safeguards.167 for example, one conclusion of a comparative study of the data privacy regimes of germany, the united kingdom, sweden, canada, and the united states is that ﬁthe united states carries out data protection differently than other countries, and on the whole does it less well.ﬂ168 the major reasons for this nding are the lack of a u.s. federal data privacy agency, together with the paucity of comprehensive data privacy legislation covering the u.s. private sector. while the nding stems from the late 1980s, it is still pertinent and is supported by more recent analyses.169 a basic premise of all these analyses is that the gaps in the u.s. regime are not adequately 164 again, see flaherty, protecting privacy in surveillance societies, 1989. note particularly flaherty™s nding that the german federal data protection commissioner (bundesdatenschutzbeauftragter)šwhich has only advisory powersšhad, at least up until the late 1980s, a more profound impact on the federal public sector in (west) germany than sweden™s data inspection board (datainspektionen)šwhich can issue legally binding ordersšhad on the swedish public sector (flaherty, protecting privacy in surveillance societies, 1989, p. 26).165 flaherty, protecting privacy in surveillance societies, 1989.166 for further discussion on the difculties of comparative assessment of data privacy regimes, see bennett and raab, the governance of privacy, 2003, chapter 9; c.d. raab and c.j. bennett, ﬁtaking the measure of privacy: can data protection be evaluated?,ﬂ international review of administrative sciences 62:53556, 1996.167 see, for example, bygrave, data protection law, 2002, chapter 18 and examples cited therein; see also flaherty, protecting privacy in surveillance societies, 1989, particularly part 1.168 flaherty, protecting privacy in surveillance societies, 1989, p. 305.169 the most extensive being schwartz and reidenberg, data privacy law, 1996šsee especially their conclusions at pp. 379396.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 397lled by other measures, such as industry selfregulation and recourse to the courts.170by contrast, the german data privacy regime is often viewed as one of the most successful.171 it has a comprehensive, wellestablished legislative platform with a rm constitutional footing. one such feature is a legal requirement that organizations appoint internal privacy ofcers.172 another such feature is the regime™s extensive encouragement of ﬁsystemic data protectionﬂ (systemdatenschutz): that is, integration of data privacy concerns in the design and development of information systems architecture.173german privacy legislation is backed up by comparatively effective oversight and enforcement mechanisms. the effectiveness of these mechanisms appears to be the result of a combination of factors, most notably the seriousness with which germans generally take data privacy issues; the relatively conformist, legalistic nature of german administrative and corporate cultures; and the strong, persuasive personalities of the individuals who have been appointed data privacy commissioners, together with the considerable talents of their staff.174all this said, the data privacy regime in germany does have weak points. one weakness is the federal data protection commissioner™s lack of authority to issue legally binding ordersša feature that is arguably at odds with the thrust of directive 95/46/ec. another, more signicant, weakness is the sheer mass of rules on data privacy; the regulatory framework is so dense as to be confusing, nontransparent, and unwieldy.175 these weaknesses mean that, despite its relative success, the german regime still falls short of meeting its policy objectives.data privacy regimes in most other, if not all, jurisdictions display a 170 see, for example, d.a. anderson, ﬁthe failure of american privacy law,ﬂ pp. 139167 in b.s. markesinis, ed., protecting privacy, oxford university press, oxford, 1999.171 see, e.g., flaherty, protecting privacy in surveillance societies, 1989, especially pp. 2122.172 see federal data protection act, sections 4f4g.173 see particularly, federal data protection act, sections 3a, 9; federal teleservices data protection act of 1997 (gesetz über den datenschutz bei telediensten vom 22. juli 1997) (as amended in 2001). for further discussion, see bygrave, data protection law, 2002, particularly pp. 346, 371.174 see generally, flaherty, protecting privacy in surveillance societies, 1989, part 1.175 see generally, a. rossnagel, a. ptzmann, and h. garstka, modernisierung des datenschutzrechts [modernization of data protection law], report for the german federal ministry of the interior (bundesministerium des innern), september 2001, available at http://www.bmi.bund.de/downloadde/11659/download.pdf (accessed aug. 20, 2003). see also, e.g., s. simitis,ﬁdas volkzählungsurteil oder der lange weg zur informationsaskeseš(bverfge 65, 1)ﬂ [the census judgment or the long road to information asceticism], kritische vierteljahresschrift für gesetzgebung und rechtswissenschaft 83:359375, 2000 (highlighting gaps between legal principle and practice in the data privacy eld).engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.398 engaging privacy and information technology in a digital agesimilar shortfall. european regimes in general are a case in point. there is sporadic evidence that many of these do not outperform the u.s. regime in all respects even if they are, on paper at least, far more comprehensive and stringent than their u.s. counterpart.176 more signicantly, the european commission has recently found that while the e.u. directive (95/46/ec) has created a ﬁhigh levelﬂ of data privacy in europe, implementation of the directive is af˚icted by major problems. not only has national transposition of the directive often been slow,177 there appear to beševen after transpositionšlow levels of enforcement, compliance, and awareness with respect to the national regimes. data privacy agencies in europe are found, in general, to be underresourced, leading in turn to the underresourcing of enforcement efforts. concomitantly, the commission nds that compliance by data controllers is ﬁvery patchy,ﬂ while data subjects apparently have ﬁlowﬂ awareness of their dataprotection rights. moreover, there remain differences between the various national laws that run counter to the harmonizing objective of the e.u. directive.178 particularly problematic from an international perspective is that e.u. member states™ respective implementation of articles 25 and 26 in the e.u. directive is found to be very broadly divergent; indeed, in many cases, it is inconsistent with the directive. further, the commission nds that a substantial amount of transborder data ˚ow is not being subjected to regulation at all.finally, account should be taken of several strands of criticism of data privacy regimes generally. one line of criticism concerns the regimes™ underdevelopment of a systemic focusšas manifested, for instance, in the paucity of direct legislative encouragement for privacyenhancing technologies.179 another line of criticism relates to marginalization of the 176 for example, a survey in 2000 of privacy policies posted on u.s. and e.u.based internet sites that sell goods or services to consumers found the policies on the e.u. sites to be no better than the policies on u.s. sites; indeed, some of the latter sites displayed the best policies. see k. scribbins, privacy@net: an international comparative study of consumer privacy on the internet, consumers international, 2001, available at http://www.consumersinternational.org/documentstore/doc30.pdf (accessed oct. 20, 2003). see, too, results of a more recent survey published in april 2003 by world it lawyers. this survey canvassed 420 commercial web sites across seven countries (france, germany, the netherlands, portugal, switzerland, spain, and the united kingdom) and found that approximately half of these sites did not display a privacy policy; see zdnet uk, ﬁuk web sites fare badly on consumer rights,ﬂ april 30, 2003, available at http://news.zdnet.co.uk/business/0,39020645,2134138,00.htm (accessed oct. 29, 2003).177 several e.u. member states have been tardy in transposing the e.u. directive into national law, the principal ones being france, ireland, luxembourg, and germany. further on implementation status, see http://europa.eu.int/comm/internalmarket/privacy/law/implementationen.htm (accessed oct. 25, 2003).178 see also charlesworth, ﬁinformation privacy law in the european union,ﬂ 2003.179 see especially bygrave, data protection law, 2002, part iv.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix b 399judiciary; in many countries, the courts have played little, if any, direct role in developing and enforcing data privacy norms. this situation not only results in a scarcity of authoritative guidance on the proper interpretation of the relevant legislation, but it contributes to the marginalization of data privacy as a eld of law.180still another line of criticism is that data privacy regimes so far have tended to operate with largely procedural rules that do not seriously challenge established patterns of information use but seek merely to make such use more efcient, fair, and palatable for the general public. in this view, legislators™ motives for enacting data privacy laws are increasingly concerned with engendering public acceptance for new information systems, particularly in the area of electronic commerce. concomitantly, it is argued that the regimes are incapable of substantially curbing the growth of mass surveillance and control.181180 see especially bygrave, ﬁwhere have all the judges gone?,ﬂ 2001.181 see especially j. rule, d. mcadam, l. stearns, and d. uglow, the politics of privacy: planning for personal data systems as powerful technologies, elsevier, new york, 1980; see also flaherty, protecting privacy in surveillance societies, 1989.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.400cbiographiesc.1 committee memberswilliam h. webster, chair, is a senior partner at milbank, tweed, hadley and mccloy llp™s washington, d.c., ofce and heads the litigation department there. he is also involved in the rm™s international corporate, banking, trade, and administrative law practices. prior to joining milbank, tweed in 1991, judge webster had been, since 1987, director of central intelligence, where he headed all the foreign intelligence agencies of the united states and directed the central intelligence agency. earlier, he had served as director of the federal bureau of investigation, from 1978 to 1987; judge of the u.s. court of appeals for the eighth circuit, from 1973 to 1978; and judge of the u.s. district court for the eastern district of missouri, from 1970 to 1973. a practicing attorney with a st. louis law rm from 1949 to 1959, judge webster served as u.s. attorney for the eastern district of missouri from 1960 to 1961. he returned to private practice in 1961. from 1964 to 1968, he was a member of the missouri board of law examiners. judge webster graduated from amherst college and received his juris doctor from washington university law school. he is a member of the american bar association, the council of the american law institute, order of the coif, and a fellow of the american bar foundation. he has received numerous honorary degrees and awards, including the freedoms foundation national service medal (1985), the presidential medal of freedom (1991), the national security medal (1991), and the 2001 justice award of the american judicature society. he is a past chair of the american bar association business law engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix c 401section and past president of the institute of judicial administration. he is a trustee of washington university in st. louis.james waldo, vice chair, is the lead architect for jini, a distributed programming system based on java. before joining jini, dr. waldo worked in javasoft and sun microsystems laboratories, where he did research in the areas of objectoriented programming and systems, distributed computing, and user environments. before joining sun, dr. waldo spent 8 years at apollo computer and hewlettpackard (hp) working in the areas of distributed object systems, user interfaces, class libraries, text, and internationalization. while at hp, he led the design and development of the rst object request broker and was instrumental in getting that technology incorporated into the rst omg corba specication. he edited the book the evolution of c++: language design in the marketplace of ideas (mit press), and was the author of the ﬁjava advisorﬂ column in unix review™s performance computing magazine. dr. waldo is an adjunct faculty member of harvard university, where he teaches distributed computing in the department of computer science. he received his ph.d. in philosophy from the university of massachusetts (amherst). he also holds m.a. degrees in both linguistics and philosophy from the university of utah. he is a member of the institute of electrical and electronics engineers (ieee) and the association for computing machinery (acm). he served on the computer science and telecommunications board™s (cstb™s) committee on networked systems of embedded computers, which produced the report embedded, everywhere: a research agenda for networked systems of embedded computer (national academy press, washington, d.c., 2001).julie e. cohen is a professor of law at the georgetown university law center. she teaches and writes about intellectual property law and information privacy law, with particular focus on digital works and on the intersection of copyright and privacy rights. she is a member of the advisory board of the electronic privacy information center and the advisory board of public knowledge. prior to joining the law center faculty, professor cohen was an assistant professor of law at the university of pittsburgh school of law. she previously practiced with the san francisco rm of mccutchen, doyle, brown and enersen, where she specialized in intellectual property litigation. professor cohen is a graduate of harvard university (a.b., 1986) and the harvard law school (j.d., 1991). she is a former law clerk to the hon. stephen reinhardt of the united states court of appeals for the ninth circuit.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.402 engaging privacy and information technology in a digital ageoscar gandy, jr., is professor emeritus at the annenberg school for communication at the university of pennsylvania. previously he was director of the center for communication research at howard university. his ph.d. in public affairs communication was awarded by stanford university in 1976. he is author of the panoptic sort and beyond agenda setting, two books that explore issues of information and public policy. his most recent work is in the area of communication and race and the ways in which the media frame racial comparisons. his most recent book, communication and race, explores the structure of media and society, as well as the cognitive structures that re˚ect and are reproduced through media use. a book in progress, if it weren™t for bad luck, explores the ways in which probability and its representation affect the lives of different groups in society. he has been an active member of several professional organizations, serving as head of the minorities and communication division and chair of the standing committee on research for the association for education in journalism and mass communication, and as a member of the international council of the international association for media and communication research. he also served as chair of the board of directors of the electronic privacy information center. he was awarded the dallas smythe award in 1999 from the union for democratic communication.james horning is chief scientist and director of west coast operations at network associates laboratories. he was the founder of intertrust™s strategic technologies and architectural research laboratory (star lab) in 1997 and its director through october 2001. previously, he was a founding member and senior consultant at digital™s systems research center (dec/src), a research fellow at xerox™s palo alto research center (parc), and a founding member and chair of the university of toronto™s computer systems research group (csrg). he is a member and past chair of the international federation for information processing™s (ifip™s) working group 2.3 (programming methodology). he is a coauthor of two books, larch: languages and tools for formal specication (1993), and a compiler generator (1970). he wrote his rst computer program in 1959 and received his ph.d. in computer science from stanford university 10 years later. he is a fellow of the acm.gary king is the david florence professor of government at harvard university. he also serves as director of the institute for quantitative social science. dr. king has been elected fellow of the american association for the advancement of science (aaas) (2004), fellow of the american academy of arts and sciences (1998), fellow of the american academy of political and social science (2004), president of the society engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix c 403for political methodology (19971999), and vice president of the american political science association (apsa) (20032004). he was also appointed a fellow of the guggenheim foundation (19941995), visiting fellow at oxford (1994), and senior science adviser to the world health organization (19982003). dr. king has won the mcgrawhill award (2006), the durr award (2005), the gosnell prize (1999 and 1997), the outstanding statistical application award (2000), the donald campbell award (1997), the eulau award (1995), the mills award (1993), the pi sigma alpha award (2005, 1998, and 1993), the apsa research software award (2005, 1997, 1994, and 1992), the okidata best research software award (1999), and the okidata best research web site award (1999), among others. his more than 100 journal articles, 10 public domain software packages, and 7 books span most aspects of political methodology, many elds of political science, and several other scholarly disciplines. dr. king™s work is cited widely across scholarly elds and beyond academia. his work on legislative redistricting has been used in most american states by legislators, judges, lawyers, political parties, minority groups, and private citizens, as well as by the u.s. supreme court. his work on ecological inference has been used in as many states by these groups, and in many other practical contexts. his contributions to methods for achieving crosscultural comparability in survey research have been used in surveys in more than 80 countries by researchers, governments, and private concerns. the statistical methods and software that he developed for addressing many problems are used extensively in academia, government, consulting work, and private industry.lin e. knapp is currently an independent consultant. previously, she was the vice chair of pricewaterhousecoopers (and one of its predecessor rms) for 10 years and, before that, a senior partner in the management consulting practice. as a vice chair, ms. knapp has held the positions of global chief information ofcer (cio) and global chief knowledge ofcer (cko). a wellknown authority on the strategic use of both intellectual capital and technology, she has been a member of the rm™s global leadership teamšits management committee and board of partners. ms. knapp has received worldwide recognition for her work in technology, knowledge management, and the new economy. she served as a member of the national research council™s study team examining computer technology and its impact on service sector productivity. she is a frequent keynote speaker; her recent addresses include those at the european business information conference, harvard university™s women in leadership conference, the world congress on information technology, and the white housesponsored critical infrastructure assurance conference. she is a member of harvard university™s global women™s leadership engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.404 engaging privacy and information technology in a digital ageboard and was recently recognized by crain™s new york business as one of new york™s 100 most in˚uential women in business.brent lowensohn has served, during the course of this study, as director of the it advanced technologies department and director of it research at the kaiser permanente medical care program, the largest health maintenance organization in the country, with more than 100,000 employees serving 9 million members from a $28 billion annual budget. dr. lowensohn has also served as a visiting scientist at the massachusetts institute of technology™s (mit™s) media laboratory. his ph.d. in social psychology was awarded by syracuse university in 1976. his research, which opened up a new area in environmental psychology, won his induction into sigma xi, the scientic research society. dr. lowensohn led his department in the identication, creation, evaluation, and implementation of innovative, hightechnology applications for health care management and operations. as a result, the department has been on the forefront of many technologybased issues such as electronic clinical information systems, biometrics, intelligent spaces, and automated authentication systems. his current activities are focused on social and technological support for homebased health monitoring and chronic disease management. dr. lowensohn is a founding member of the gartner group advanced technologies best practices group; was a member of three mit consortia (things that think, center for bits and atoms, and changing places), a member of the biometrics working group of the biometrics consortium, and a member of cross industry working team of the center for national research initiatives. his background in the social sciences, health care, and technology provides a unique perspective on contemporary issues.gary t. marx is professor emeritus at the massachusetts institute of technology. he has written, among other works, protest and prejudice: a study of belief in the black community; undercover: police surveillance in america; and undercover: police surveillance in comparative perspective. his work has appeared or has been reprinted in more than 250 books, monographs, and periodicals and has been translated into many languages. he received his ph.d. from the university of california at berkeley. he has taught there, at harvard university, at the university of colorado, and in belgium, spain, austria, and china. he has lectured throughout the world. he has served in an advisory capacity for many government and nonprot organizations and on many editorial boards. he has a book in progress on new forms of surveillance.helen nissenbaum is associate professor in the department of culture and communication and a senior fellow of the information law instiengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix c 405tute at new york university. she specializes in social, ethical, and political dimensions of technology, with a focus on information technology. her published works on privacy, property rights, electronic publication, accountability, the use of computers in education, and values embodied in computer systems have appeared in scholarly journals of philosophy, applied ethics, law, and computer science. she is the author of emotion and focus (university of chicago press), coeditor (with d.j. johnson) of computers, ethics and social values (prenticehall), and a founding coeditor of the journal ethics and information technology (kluwer academic press). grants from the national science foundation (nsf) and the ford foundation have supported her work, including an interdisciplinary study of human values in webbrowser security with batya friedman and edward felten, and an internship for undergraduates to promote the public interest in information technology. she has served on committees of the national research council, nsf, unesco, aaas, and acm. professor nissenbaum was a member of the school of social science, institute for advanced study (20002001); served as associate director of princeton university™s center for human values; and held a postdoctoral fellowship at the center for the study of language and information at stanford university. she earned a b.a. (honors) from the university of the witwatersrand, johannesburg, and a ph.d. in philosophy from stanford university.robert m. o™neil became the founding director of the thomas jefferson center for the protection of free expression in august 1990, after serving 5 years as president of the university of virginia. he continues as a member of the university™s law faculty, teaching courses in constitutional law and a new course on free speech and cyberspace. in 1963, after serving as law clerk to supreme court justice william j. brennan, jr., professor o™neil began three decades of teaching about free speech and press at the university of california, berkeley, and the universities of cincinnati, indiana, wisconsin, and virginia. in addition to teaching, he has had a distinguished career in highereducation administration, serving as provost of the university of cincinnati, vice president of indiana university for the bloomington campus, and president of the university of wisconsin, before coming to virginia. he has chaired the national association of state universities and landgrant colleges and served on the executive committee of the association of american universities. from 1992 to 1999, he chaired committee a (academic freedom and tenure) of the american association of university professors (aaup), of which he was general counsel from 1970 to 1972 and again from 1990 to 1992. he has also served as a trustee or director of the commonwealth fund, the fort james corporation, the media institute, and teachers insurance engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.406 engaging privacy and information technology in a digital ageand annuity association (tiaa). he chairs special committees of the aaup on academic freedom and national security in time of crisis, and on hurricane katrina and new orleans universities, and directs the ford foundation™s difcult dialogues initiative. in virginia he serves as chairman of the board of wvptpublic television, as a trustee and former president of the council for america™s first freedom, and is the rst president of virginia™s coalition for open government. he is the author of several books, including free speech: responsible communication under law, the rights of public employees (2nd edition, 1993), and classrooms in the crossre, as well as many oped pieces and articles on free speech and press in law reviews and other journals. his latest book, free speech in the college community (march 1997), is published by the indiana university press. on numerous occasions, professor o™neil has testied before state legislatures and congressional committees on the first amendment implications of proposed legislation.janey place is ceo of digitalthinking, a business strategy, technology, innovation, and payment systems consulting company based in new york and los angeles. prior to starting digitalthinking in 2004, she was executive vice president of ecommerce strategy for mellon financial corporation, responsible for mellon™s ecommerce strategy and customer information management. she was president of mellonlab and a member of mellon™s senior management committee. formerly, she was the executive vice president for bank of america™s strategic technology group, which was responsible for internet initiatives, advanced technology research and development, and information technology architecture. previously, ms. place was senior vice president in charge of internet strategy and research and development at wells fargo bank. she was information technology manager at hughes aircraft company and served as corporate manager of strategic technology planning for tosco corporation. ms. place also was a lecturer in systems and communication theory at the university of california, santa cruz. she is a published author of two books and many articles, editor of a communications magazine, producer and director of lm and video programs, and a frequent speaker. she has served on a number of corporate boards and currently is a director for portblue, an information management company. ms. place earned a bachelor™s degree from the university of california at los angeles. she holds a master™s degree and a doctorate in systems theory and attended the graduate school of management at the university of california at los angeles.ronald l. rivest is a member of the massachusetts institute of technology™s computer science and articial intelligence laboratory, a member of the laboratory™s theory of computation group, and a leader of its engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix c 407cryptography and information security group. he is also a founder of rsa data security. (rsa was bought by security dynamics; the combined company has been renamed rsa security.) professor rivest has research interests in cryptography, computer and network security, and algorithms. he is a fellow of the association for computing machinery and of the american academy of arts and sciences and is also a member of the national academy of engineering. together with adi shamir and len adleman, he was awarded the 2000 ieee koji kobayashi computers and communications award and the secure computing lifetime achievement award. professor rivest received an honorary degree (the ﬁlaurea honoris causaﬂ) from the university of rome. he is an inventor of the rsa publickey cryptosystem. he has extensive experience in cryptographic design and cryptanalysis and has published numerous papers in these areas. he has served as a director of the international association for cryptologic research, the organizing body for the eurocrypt and crypto conferences, and as a director of the financial cryptography association.teresa schwartz is the j.b. and maurice c. shapiro professor emeritus of public interest law at the george washington university law school. from 1995 to 2001, she was deputy director of the federal trade commission™s bureau of consumer protection. at the commission, she participated in and oversaw critical, growing work on privacy policy as a consumer protection issue. prior to joining the commission, she was a member of the law faculty at george washington university law school. during her 25 years on the faculty, she served as the academic dean; taught and published in the areas of administrative law, torts, and product liability; and was named the j.b. and maurice c. shapiro professor of public interest law. ms. schwartz began her legal career in 1971 as an attorney adviser to federal trade commissioner mary gardiner jones. in 1978, she was awarded a white house fellowship. ms. schwartz has served on the board of directors of consumers union, the food and drug law institute, and the district of columbia bar. she also has served on the editorial advisory board of the administrative law review. ms. schwartz earned her b.a. from stanford university in 1965 and her j.d. (with highest honors) from george washington university in 1971. she is a member of the bar of the district of columbia.lloyd n. cutler, of wilmer, cutler and pickering, was cochair until he passed away on may 8, 2005.robert w. crandall, brookings institution, resigned on april 4, 2006.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.408 engaging privacy and information technology in a digital agec.2 staff membersherbert s. lin is senior scientist and senior staff ofcer at the computer science and telecommunications board (cstb), national research council (nrc) of the national academies, where he has been the study director for major projects on public policy and information technology. these studies, published by the national academy press, include a 1991 study on the future of computer science (computing the future), a 1996 study on national cryptography policy (cryptography™s role in securing the information society), a 1999 study of department of defense systems for command, control, communications, computing, and intelligence (realizing the potential of c4i: fundamental challenges), and a 2000 study on workforce issues in hightechnology (building a workforce for the information economy). prior to his nrc service, he was a professional staff member and staff scientist for the house armed services committee (1986 to 1990), where his portfolio included defense policy and arms control issues. he also has signicant expertise in math and science education. he received his ph.d. in physics from mit in 1979. avocationally, he is a longtime folk and swing dancer and a poor magician. apart from his cstb work, a list of publications in cognitive science, science education, biophysics, and arms control and defense policy is available on request.lynette i. millett is a senior program ofcer at the computer science and telecommunications board of the national research council. she is currently involved in several cstb projects, including a comprehensive exploration of privacy in the information age, a study on certication and dependable software systems, an assessment of biometrics technologies, and an examination of the social security administration™s electronic services strategy. her portfolio includes signicant portions of cstb™s recent work on software and on identity systems and privacy. she was the study director for the cstb project that produced the reports who goes there? authentication through the lens of privacy and idsšnot that easy: questions about nationwide identity systems. she has an m.sc. in computer science from cornell university, along with a b.a. in mathematics and computer science with honors from colby college, where she was elected to phi beta kappa. her graduate work was supported by both an nsf graduate fellowship and an intel graduate fellowship.kristen batch is an associate program ofcer with the computer science and telecommunications board of the national research council. she is currently involved with several projects focusing on emerging wireless technology and spectrum policy, biometrics technologies, and privacy in the information age. while pursuing an m.a. in international communications from american university, she interned at the national telecomengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.appendix c 409munications and information administration in the ofce of international affairs and at the center for strategic and international studies in the technology and public policy program. she also earned a b.a. from carnegie mellon university in literary and cultural studies and spanish, and received two travel grants to conduct independent research in spain.david padgham (re)joined cstb as an associate program ofcer in the spring of 2006, following nearly 2 years as a policy analyst in the association for computing machinery™s (acm™s) washington, d.c., ofce of public policy. while at acm, he worked closely with that organization™s public policy committee, usacm. previously, he spent nearly 6 years with cstb in positions ranging from project assistant to research associate working on, among other things, the studies that produced trust in cyberspace, funding a revolution, and realizing the potential of c4i. more recently, he has assisted with the research and production of broadband: bringing home the bits, lc21: a digital strategy for the library of congress, the internet™s coming of age, looking over the fence at networks, and information technology research, innovation, and egovernment. he holds a master™s degree in library and information science (2001) from the catholic university of america in washington, d.c., and a bachelor of arts degree in english (1996) from warren wilson college in asheville, n.c.jennifer m. bishop, program associate, began working with the computer science and telecommunications board of the national research council in 2001. she was involved in several studies, including those on telecommunications research and development, digital archiving and the national archives and records administration, and information technology and creativity. she also maintained cstb™s contact database, handled updates to the cstb web site, coordinated the layout and design of update, the cstb newsletter, and designed book covers and promotional materials. prior to her move to washington, d.c., she worked for the city of ithaca, new york, coordinating the police department™s transition to a new sqlbased time accrual and scheduling application. her other work experience includes designing customized hospitality industry performance reports for realtime hotel reports, llc.; maintaining the police records database for the city of ithaca; and freelancing in publication design. she is a visual artist working in oil and mixed media. she holds a b.f.a. from cornell university.janice m. sabuda is a senior program assistant at the computer science and telecommunications board of the national research council. she currently supports all board activities and is involved in several studies, including improving cybersecurity research in the united states, engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.410 engaging privacy and information technology in a digital ageinformation technology and the states: public policy and public interests, planning meeting on fundamental research challenges in computer graphics, privacy in the information age, and radio frequency identication (rfid) technologies: a workshop. previously, she focused on the congressionally requested study that resulted in youth, pornography, and the internet (2002) and the project that resulted in global networks and local values (2001). prior to joining cstb in august 2001, she worked as a customer service representative at an online fundraising company and as a client services analyst at a prospect research rm. she is currently pursuing a certicate in event management from the george washington university center for professional development. she received her bachelor of science degree (1999) in business administration from the state university of new york college at fredonia.engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.aaccess to health data, 216œ227 hipaa legislation, and privacy, 138, 145, 172, 219œ223, 331 industry selfregulation, 216œ219, 391 patient perspectives on privacy, 223œ226access to information controlling, 7, 115 to data elements, 41 improper, by law enforcement, 7 insider, 330 literature on equitable, viiaccountability, 68achr. see american convention on human rightsaclu. see american civil liberties unionacquisti, alessandro, 76œ77ad blockers, 326advocates. see privacy advocatesafnity cards, 5african charter on human and people™s rights, 381, 394aggregators. see data aggregatorsaids. see hiv statusalqaeda, 23, 140, 288algorithms for data mining, 6 strong encryption, 267allencastellito, anita, 62, 68altman, irwin, 81ama. see american medical associationamerica online (aol), 104œ106american civil liberties union (aclu), 135, 165american convention on human rights (achr), 381american law institute, 130american library association, 235, 238, 240, 244 bill of rights, 236œ237 code of ethics, 231œ233american medical association (ama), ethical force program, 216œ218, 221anchoring vignettes, 86œ87, 179œ182, 191œ192, 202, 211œ215, 218œ219, 228œ229, 254œ255, 307anderson, margo, 294, 358411indexengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.412 indexanonymity, 2, 24, 45œ48, 46n.20, 59, 62 kanonymity, 110anonymizers, 6, 109, 220œ221, 325 pressures to resist use of, 108antiwar movement, surveillance focused on, 357, 361aol. see america onlineapec. see asiapacic economic cooperationappcc. see asiapacic privacy charter councilashcroft, john, 133asiapacic economic cooperation (apec), 385, 389asiapacic privacy charter council (appcc), 388asia pacic telecommunity (apt), guidelines on the protection of personal information and privacy, 388assault on privacy, the, 167assignment of property rights, to individuals, 73œ74audits automated, 330 to uncover improper access by law enforcement, 7aumf. see authorization for use of military forceaustralia, 377, 379n.74, 385, 393, 393n.151authorization for use of military force (aumf), 288œ289avian (bird) ˚u, 38bbank secrecy act, 134banking act, 190bankruptcy abuse prevention and consumer protection act, 332bartnicki v. vopper, 126, 281n.22barton, joe, 159bbbonline, 328behavioral economics, privacy and, 75œ78bell code of privacy, 332bill of rights, 123, 260, 293, 351, 354. see also individual amendmentsbiometric identication, 32, 106œ107, 268œ271, 270n.14 debate over, 271biotechnologies, viii, 106œ107blank and impute process, 112ﬁboilerplateﬂ language, in notices, 78book checkout systems, selfservice, 238bork, robert h., 139, 159, 171n.53bowers v. hardwick, 128boyd v. united states, 123brandeis, louis d., 30, 88, 129, 147, 359breard v. alexandria, 126brin, david, 159buckley amendment. see family educational rights and privacy actbureau of labor statistics, 111ccable communications policy act, 135œ136cairo declaration on human rights in islam, 381calea. see communications access for law enforcement actcalifornia security breach information act, 150california supreme court, 125callerid, blocking, 326calling records, 289canspam act, 139, 142canada, 127, 332, 376, 385, 391, 396capt, j. c., 295cctv. see closedcircuit televisioncdc. see credit data corporationcell phones, 31, 256 e911 service on, 89, 256 networks of, 94, 262census. see u.s. census bureaucenter for democracy and technology, 165, 327engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 413center for social & legal research, 172centers for disease control and prevention, 111certied information privacy professional credentialing program, 172charities. see nonprot organizationschild online protection act (copa), 104œ105, 104n.13children™s internet protection act,  240children™s online privacy protection act, 139, 144œ145, 169china, people™s republic of, 394choicepoint, 25œ26, 197œ198, 198n.19, 199, 206choices default, 338 informed, 338church, frank, 167church committee hearings, 3, 163, 163n.25, 167cipsea. see condential information protection and statistical efciency actcircuitbased networks, 265civil rights movement, 319civil war, 350, 355œ357, 359claims, verifying, 34closedcircuit television (cctv), 256n.3, 364code of fair information practices, 48œ49coe convention. see council of europe convention for the protection of individuals with regard to automatic processing of personal datacoherence, in the concept of privacy, 14, 62œ66, 333œ336coke, sir edward, 351cold war, america during, 350, 360œ363collective privacy, 343columbia university, 241commission of the european communities (european commission), 391commodication, of personal information, 27, 69œ70commodity futures trading commission, 144common law, 129œ131common rule, 222n.6communications, and data storage, 259œ266communications access for law enforcement act (calea), 136, 263œ264communitarian view of privacy, 68complexity of privacy issues, 4œ5, 13 and interdependency, ixœx respecting, 324computer fraud and abuse act, 139computer matching and privacy protection act, 167computing power, advances in, 90œ91, 91n.1, 360concealing information, 72concepts related to privacy, 38œ52, 366œ371 coherence in, 14, 62œ66, 333œ336 fair information practices, 15, 48œ50, 334, 395 false positives, false negatives, and data quality, 43œ45, 120, 270, 299 personal information, sensitive information, and personally identiable information, 39œ43, 42n.15 privacy and anonymity, 2, 24, 45œ48, 59, 62 reasonable expectations of privacy, 50œ52, 328, 337conceptual underpinnings of privacy, 55, 57œ87 an integrating perspective, 84œ87 economic perspectives on privacy, 1, 69œ78 philosophical theories of privacy, 1, 58œ69 sociological approaches, 1, 79œ84engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.414 indexconcerns. see privacy concerns; psychological concerns; social concerns; unconcern over privacyconditioned disclosure, 315œ316condon decision. see reno v. condoncondential information protection and statistical efciency act (cipsea), 142œ143condentiality, 2 an application of cryptography, 107œ108 federal laws relevant to, 142œ143 guarantees of, 335conformity, 309congressional research service, 242n.16connecticut, 162connectivity. see also interconnectedness increased, ix, 20œ21, 97œ100 ubiquitous, 99consent, 15, 49, 77, 206, 217œ218, 338constitutional convention, 353constitutional foundations, 57, 122œ129, 149, 275œ276, 293œ294, 354. see also bill of rights; individual amendments first amendment, 125œ127, 201, 240 fourth amendment, 51, 122œ125, 258n.5, 260œ261, 294 fifth amendment, 351 ninth amendment, 127œ129 fourteenth amendment, 123 sixteenth amendment, 358 voting on, 352n.3consumer credit reporting reform act, 134œ135consumer proprietary network information (cpni), 78n.38consumers, 164 of information, 361 worries of, vii, 60œ61content distribution industries, mass media and, 201œ203ﬁcontextual integrity,ﬂ 63œ64contextual issues, 85, 324. see also privacy contextcontinental congress, 353continuity. see discontinuities in circumstance and current eventscookies, 173, 316, 326cooley, thomas, 131copa. see child online protection actcorporate policy, formulation of, 171œ173costs associated with unfavorable publicity, 14 computational, 118, 325, 327council of europe convention for the protection of individuals with regard to automatic processing of personal data (coe convention), 367n.7, 382œ383, 388counterterrorism, 23, 96cox broadcasting corp. v. cohn, 126cpni. see consumer proprietary network informationcredit granting of, 34, 43œ44, 360 reporting of, 359credit bureaus, 197, 326credit card information, 200credit data corporation (cdc), 361criminal databases, 7, 11œ12cruzan v. missouri health dep™t, 129cryptography, 267 condentiality application of, 107œ108 techniques for, 107, 112œ113, 119cryptosystems, publickey, 267customer loyalty cards, 192ddarpa. see defense advanced research projects agencydata. see also microdata analysis and integration of, 306 deidentication of, 220œ221 individuallevel, 163 projected persistence of, 32n.8 seemingly innocuous, 31data accountability and trust act, 150engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 415data aggregators, 26, 116, 196œ200, 334, 361 data mining by, 271œ275data collections, protected, 24datacorrecting techniques, 327data dissemination, 306data elements accessibility of, 41 transience of, 41œ42 values of, 40data ˚ows, transborder, 153, 398data gathering, 306 for national security, legal limitations on, 280œ284datagathering systems largescale public, 6 technologies combined into, 94, 101œ102data minimization, 6œ7data mining, 32, 95œ96 algorithms for, 6 by data aggregators, 271œ275data quality, 119œ120 false positives and false negatives, 43œ45data search companies, 102œ106data storage, 306 communications and, 259œ266databanks in a free society: computers, recordkeeping and privacy, 167œ168databases aggregating information, 361 customer, 201deidentication of data, 220œ221death of privacy, the, 167decew, judith, 63declaration of independence, 293deep privacy, 77default choices, 338defense advanced research projects agency (darpa), 287, 290denitions of privacy, 1œ4, 21œ25, 39œ40, 59œ62, 305œ308 connotations, 1 context dependency of, 3œ4demonization, avoiding in discussion, 13, 323œ324denmark, 368, 390n.133descriptive identication, 82œ83details, limiting, 111dhhs. see u.s. department of health and human servicesdhs. see u.s. department of homeland securitydigital millennium copyright act (dmca), 246œ247digital rights management technologies (drmts), 9œ10, 99œ100, 100n.9, 203, 242, 244, 246, 249œ250ﬁdigital shadows,ﬂ 272digitized information, 30, 116, 203direct marketing association, 172, 328directive on data protection (european commission), 152disasters, natural, 96disclosure limitation, 2, 11, 61 statistical techniques for, 111œ112discrimination, 84 associated with certain medical conditions, 11disease, and pandemic outbreak, 37œ38distribution industries, for content, mass media and, 201œ203dmca. see digital millennium copyright actdna analysis, 10œ11, 32, 40œ41, 106œ107, 214œ215, 269, 317, 320, 364donotcall lists, 201, 326doj. see u.s. department of justicedomestic wiretapping, 147dorman, david, 248doubleclick, 173douglas, william o., 128dppa. see driver™s privacy protection actdriver™s licenses, 33, 182driver™s privacy protection act (dppa), 137œ138, 149engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.416 indexdrmts. see digital rights management technologiesdrug testing, 34, 316due process clause, 123, 128dynamics of privacy, 27œ38 discontinuities in circumstance and current events, 36œ38 the information age, 27œ29 information transformed and the role of technology, 29œ33 societal shifts and changes in institutional practice, 33œ36ee911 service, on cell phones, 89,  256ecommerce, permitting collection of personal information, viiegovernment act, 142œ143, 298, 330echr. see european convention on human rights and fundamental freedomseconomic perspectives on privacy, 1, 69œ78. see also behavioral economics the economic impact of privacy regulation, 74œ75 privacy and behavioral economics, 75œ78 privacy and the assignment of property rights to individuals, 73œ74 privacy as fraud, 71œ73 privacy literature oriented toward, vii rationale for, 69œ71ecpa. see electronic communications privacy acteducational and academic research institutions, 183œ188 personal information collected for research purposes, 187œ188 student information collected for administrative purposes, 183œ187eea. see european economic areaelectronic communications privacy act (ecpa), 136electronic fare cards, 31electronic freedom of information act (efoia) amendments, 137electronic frontier foundation, 165, 327, 340electronic medical records, 230electronic privacy information center (epic), 165, 327, 340, 392n.144eligibility, establishing, 34emerging technologies, and privacy in libraries, 244œ248employee polygraph protection act of 1988, 167employers, seeking information about employees, 34œ35encryption, 6œ7, 107, 115, 259œ260, 264œ266, 325œ326, 329enforcement, 143, 329œ330, 397. see also law enforcementenvironmental protection agency, 227, 340epic. see electronic privacy information centerepidemiological research, 228, 319, 338equifax, 197ervin, sam, 159, 362espionage act, 358, 358n.14ethical force program, 216œ218, 216n.2,3, 217n.5, 221ethics of privacy, 186. see also puritan ethicetzioni, amitai, 67œ68e.u. directive. see protection of individuals with regard to the processing of personal data and on the free movement of such dataeuropean commission, 152, 398. see also commission of the european communitieseuropean convention on human rights and fundamental freedoms (echr), 381œ382european court of justice, 387european economic area (eea), 383engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 417european union (e.u.), 151œ152, 152n.20, 157, 376, 398n.176 ﬁlegislating for the world,ﬂ 384exclusionary rule, 276executive order 13145, 146executive order 13181, 146executive orders, 146œ147expectations of privacy, reasonable, 50œ52experian, 197ffaceidentication systems, 106œ107, 269œ270facebook.com, 344fair and accurate credit transactions act, 144fair credit reporting act (fcra), 134, 144, 188œ189, 197, 336, 362fair information practices, 15, 48œ50, 167, 334, 395false information, providing, 5, 327false light, 130false positives and negatives, 43œ45, 120, 270, 299family educational rights and privacy act (ferpa), 139, 160œ161, 184fare cards, electronic, 31fbi. see federal bureau of investigationfcra. see fair credit reporting actfederal aviation administration, 204federal bureau of investigation (fbi), 243, 275, 356 library awareness program, 244federal laws relevant to condentiality, 142œ143 relevant to individual privacy, 133œ142federal register, 146œ147ferpa. see family educational rights and privacy actfifth amendment, 280n.19, 351financial crimes enforcement network, 189financial institutions, 144n.15, 188œ191financial modernization act. see grammleachbliley actfinancial privacy rule, 144fingerprinting, 32, 53, 106, 268œ269, 271fip. see fair information practices guidelinesfirewalls, 325first amendment, 125œ127, 201, 240fisa. see foreign intelligence surveillance actthe florida star v. b.j.f., 126foia. see freedom of information actforeign intelligence surveillance act (fisa), 135, 167, 243, 282œ283, 283n.23, 288œ289foucault, michel, 81fourteenth amendment, 123, 280n.19fourth amendment, 51, 51n.27, 122œ125, 258n.5, 260œ261, 294france, 368free speech movement, 132freedom of information federal laws relating to condentiality, 142œ143 federal laws relating to individual privacy, 133œ142 and open government, 131œ146 regulation of, 143œ146freedom of information act (foia), 132œ133, 137, 204, 362ftc act, 133. see also u.s. federal trade commissionﬁfundamentalistﬂ approach to privacy, 60fusion of information, 95œ96ggag provisions, 127gait analysis, 32, 270gallagher, cornelius, 362gavison, ruth, 62genome. see human genomegeodemographic targeting, 36german americans, surveillance focused on, 357engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.418 indexgermany, 151, 160n.18, 368œ370, 372œ373, 396œ397giddens, anthony, 81glasssteagall act. see banking actglobal networks and local values, 161global positioning system (gps) locators, 89, 256 automobiles containing, 94google, 102, 104œ105gorman, michael, 238œ239government abuse, postwatergate revelations of, 3, 29, 163, 167, 363gps. see global positioning system locatorsgrammleachbliley act, 135, 144, 159, 172, 190, 222the great depression, 358griswold v. connecticut, 61, 127, 363group privacy, 83, 343guidelines governing the protection of privacy and transborder flows of personal data (oecd guidelines), 384, 385n.101, 388guidelines on the protection of personal information and privacy, 388hhabeas data, 392, 392n.144hardware advances, 90œ95harm, intangible, 26harvard law review, 30, 129health care services, 34 receiving, spillover privacy implications of, 226health data, 214œ215 access to, 216œ227health insurance, availability of, 228health insurance portability and accountability act (hipaa) privacy regulations, 138, 145, 172, 331 improper interpretation and unintended consequences of, 225œ226health privacy, viiœviii, 175œ176, 209œ230 addressing issues in access to and use of health data, 216œ227 information and the practice of health care, 209œ211 open issues in, 227œ230hew report. see u.s. department of health, education, and welfarehipaa. see health insurance portability and accountability act privacy regulationshippocratic databases, 113history. see also medical history; mental health history lessons from, 52œ53hiv status, 162œ163, 214 stigma attached to, 41, 48 unlawful disclosure of, 127hollerith, herman, 33n.9, 356hondius, frits w., 367n.5human genome, mapping of, 215, 364humidity sensors, 97iiccpr. see international covenant on civil and political rightsidentication. see also deidentication of data biometric, 32 descriptive, 82œ83 indexical, 82 nominal, 82 technologies and, 266œ271 unique, 40, 47ﬁidentity,ﬂ dening, 47n.21identity theft, 140œ141, 308œ309identity theft and assumption deterrence act, 139ilo. see international labor organizationimmunity, doctrine of sovereign, 346incentivized disclosure, 315indexical identication, 82india, 394individuallevel data, 163engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 419individual privacy. see also recourse and the assignment of property rights to, 73œ74 federal laws relevant to, 133œ142 law enforcement and national security, 293œ301 technologies for enhancing, 107œ109 unilateral actions for, 5individuals accountability of, 108 actions of, 325œ328 direct interests of, 9 lawabiding, 12, 176, 299 liberty of, 354 participating in everyday life, 33 protecting their own privacy, 14industry selfregulation. see selfregulationinformation. see also access to information; electronic information; personal information analysis of, 31 concealing, 72 consumers of, 361 creation of, 30 credit card, 200 databases aggregating, 26, 116, 196œ200, 197n.16, 198n.19, 334, 361 digitized, 30, 116, 203 fusion of, 95œ96 institutional use of, 178œ183 keeping private, x manipulation of, 30œ31 proprietary, 2 providing false, 5, 327 providing incomplete, 327 searches for, 30 seemingly innocuous, 31 specic uses for, 4 storage of, 31œ32 storing electronic, 91œ93 unannounced acquisition of,  316 withholding, 5, 72ﬁinformation age,ﬂ 27œ29, 178n.1 contemporary infrastructures of, 26 and growing privacy concerns, 19information collection, 31, 72n.22, 74, 193n.12 cryptographic techniques, 112œ113 negrained, 10 information ˚ow analysis, 114 information security tools, 115œ116 privacyenhancing technologies for use by, 109œ116 privacysensitive system design, 114œ115 query control, 109œ110 statistical disclosure limitation techniques, 111œ112 user notication, 113information security and privacy advisory board, 342information technology and law enforcement, 252œ277 and national security, 277œ293 and the practice of health care, 209œ211 role of, 29œ33information technology for counterterrorism, 278informed choice, 338infrared detectors, 258infrastructures, of the contemporary ﬁinformation age,ﬂ 26insiders access by, 330 threats to privacy from, 329œ330institutions advocacy by, 14, 227 changes in practice, and societal shifts, 33œ36 private sector, 34 use of information by, 178œ183instrumentalist view of privacy, 66œ67insurance companies. see also health insurance information used to deny coverage, 11integrity. see ﬁcontextual integrityﬂengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.420 indexintellectual approaches to privacy, 55, 57œ87 an integrating perspective, 84œ87 economic perspectives on privacy, 1, 69œ78 philosophical theories of privacy, 1, 58œ69 sociological approaches, 1, 79œ84intellectual property, literature on, viiintelligence activities. see church committee hearingsinternal abuses, prevention of, 7internal revenue service, 204, 294, 335, 358, 361international association of privacy professionals, 172international biometric group, 270international covenant on civil and political rights (iccpr), 381œ382international labor organization (ilo), 386international perspectives on privacy, 366œ399 on privacy policy, 151internet, 30, 172, 239œ241, 262 sexually explicit material on, 240 spread of, vii, 159interpretation, of hipaa privacy regulations, improper, 225œ226intimacy, 59intrusion, 129islam. see cairo declaration on human rights in islamjjapan, 393japaneseamericans, internment of, 294œ295, 319, 332œ333judicial decisions, 170œ171junk mail, 178kkanonymity, 110kalven, harry, 131kastenmeier, robert, 159katz v. united states, 50, 52, 123kennedy, anthony m., 128kennedy, edward, 290œ291kenya, 395key escrow systems, 266, 266n.10kilbourn v. thompson, 123korea, 393kyllo v. united states, 258n.5llamont v. postmaster general, 125law enforcement, 23œ24 aggregation and data mining, 271œ275 audits to uncover improper access by, 7 background, 252œ254 communications and data storage, 259œ266 and information technology, 252œ277 national security and individual privacy, 37, 293œ301 potential abuses by, 275 and privacy concerns, 275œ277 technology and identication, 266œ271 technology and physical observation, 254œ259 use of criminal databases by, 7law of privacy. see privacy lawslawrence v. texas, 128legal landscape in the united states, 14, 56, 122œ154 common law and privacy torts, 129œ131 constitutional foundations, 122œ129 executive orders and presidential directives, 146œ147 freedom of information and open government, 131œ146 impact of nonu.s. law on privacy, 151œ154 international perspectives on privacy policy, 151 state perspectives, 147œ150engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 421legal limitations, on national security data gathering, 280œ284legislation. see also u.s. congress; individual laws hipaa and privacy, 219œ223liberal ideals, 376liberty, 367 individual, 354libraries, 176, 235œ250 emerging technologies in, 244œ248 mission of, 233œ234 and privacy, 7œ9, 235œ238, 235n.6, 245n.20 privacy since september 11, 2001, 242œ244 technology in, 9, 238œ242licensing practices, 33locke, john, 354, 376long, edward, 362los angeles police department v. united reporting publishing co., 132lunt, teresa, 109lyon, david, 80mmadison, james, 376ﬁmail cover,ﬂ 260n.7mandated disclosure, 315marketable rights, and privacy, viimarketing personal information, collecting for, viimarketplace, global, 334markey, ed, 159markle foundation, 169marx, gary t., 64œ65mass media, and content distribution industries, 201œ203mcintyre v. ohio elections comm™n, 125medical history, 214, 313n.1medical information bureau (mib), 361medical privacy, 4, 211œ216 addressing issues in access to and use of health data, 216œ227 information and the practice of health care, 209œ211 open issues, 227œ230medical records, electronic, 230megan™s law, 138mental health history, 214metcalfe™s law, 98, 98n.6mib. see medical information bureaumicrodata, 47mill, john stuart, 376miller, arthur, 167misappropriation, of name or likeness, 130money laundering, inhibiting, 34myspace.com, 344nnaacp v. alabama, 201national center for education statistics (nces), 143, 204, 294n.31national center for health statistics, 204national credit union administration, 144national education statistics act, 143national privacy commissioner, establishing, 15, 341œ342national research council, viii, xi, 20, 161national science foundation, 331national security, viii and law enforcement, 23œ24, 37 law enforcement and individual privacy, 37, 293œ301 tensions with privacy, 292œ293national security agency (nsa), 288œ291, 319national security and information technology, 277œ293, 279n.18 background, 277œ280 legal limitations on national security data gathering, 280œ284 national security and technology development, 280 recent trends, 284œ292 tensions between privacy and national security, 292œ293nces. see national center for education statisticsengaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.422 indexnegatives, false, 43œ45, 120netherlands, the, 390œ391networks, of cell phones, 94new deal era, 358œ359new england, colonial, 350œ353ﬁnewﬂ surveillance, 101œ102new york civil service commission, 356new zealand, 385, 393ninth amendment, 127œ129nissenbaum, helen, 63œ64noise, adding, 111nominal identication, 82nonu.s. law, impact on privacy, 151œ154nonprot organizations, 200œ201 privacy advocates in, viiinormative theories of privacy, 66œ69norway, 368œ369, 372œ373notices ﬁboilerplateﬂ language in, 78 difculttoread, 344notication of privacy policy, 223œ224 of users, 78, 113, 223œ224nsa. see national security agencynuremberg code, 187n.8oodor recognition, 270oecd. see organisation for economic cooperation and developmentoecd guidelines. see guidelines governing the protection of privacy and transborder flows of personal dataofce of civil rights, 222ofce of technology assessment, 167olmstead v. united states, 123, 261omnibus crime control and safe streets act, 135, 362œ363online privacy dearth of analytical work on, viii practices of businesses and government agencies, viionline privacy alliance, 165online service providers (osps), 246œ247open government federal laws relevant to condentiality, 142œ143 federal laws relevant to individual privacy, 133œ142 and freedom of information, 131œ146 and regulation, 143œ146ﬁoptinﬂ or ﬁoptoutﬂ approaches, 70, 77, 339, 393n.152organisation for economic cooperation and development (oecd), 48, 50, 153, 167 guidelines governing the protection of privacy and transborder flows of personal data, 384organizations. see also institutions; private foundations actions based in, 328œ332 nonprot, 200œ201osps. see online service providersoversight, 397 u.s. congress providing special,  15pp3p. see platform for privacy preferencespacketbased networks, 265pandemic outbreak disease and, 3, 37œ38 global, 3paperwork reduction act, 204patient perspectives on privacy, 223œ226 improper interpretation and unintended consequences of hipaa privacy regulations, 225œ226 notications of privacy policy, 223œ224engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 423 privacy implications of greater patient involvement in health care, 224œ225 spillover privacy implications of receiving health care services, 226patients accessing their own records, 217 cooperation from, 211paul v. davis, 124pcs. see personal computerspearl harbor attack, 3, 29, 295penalties, for improper access, 7pentagon attack. see september 11, 2001, attacksﬁpenumbralﬂ protection for privacy, 127people™s republic of china, 394persistence of data. see also transience of data elements projected, 32npersonal computers (pcs), 89personal identication number (pin) schemes, 374personal information, 39œ43 collected by business and management experts, vii collected by economists, vii collected for research purposes, 187œ188 collecting for marketing, vii commodication of, 27, 69œ70 demand for and supply of, viii, 33 ecommerce and technologies permitting collection of, vii as an economic good, 70 exploitation of, 13, 86n.56, 314 life cycle of, 13 multidimensional nature of, 65 new sources of, 343 protection of, 380œ399, 380n.80, 392n.91 repurposing of, 15, 180, 214, 270, 314, 338 threats to, viii, 20personally identiable information (pii), 39œ43personnel security system and photo identication card system, 331nﬁpersons of interest,ﬂ 253, 271pew internet and american life project, 166pgp. see pretty good privacyphillips, david, 82philosophical theories of privacy, 1, 58œ69, 58n.1 coherence in the concept of privacy, 62œ66 normative theories of privacy, 66œ69 privacy as control versus privacy as restricted access, 59œ62ﬁphishingﬂ attacks, 108, 108n.22, 224, 326, 342photoediting software, 30œ31photo identication, 226physical observation, technologies and, 254œ259, 266pias. see privacy impact assessmentspii. see personally identiable informationpin. see personal identication number schemesplatform for privacy preferences (p3p), 113policy. see corporate policy; privacy policy; public policypoliticalloyalty surveillance, 353politics of privacy policy in the united states, 56, 155œ173 formulation of corporate policy, 171œ173 formulation of public policy, 155œ162 judicial decisions, 170œ171 public opinion and the role of privacy advocates, 162œ166 the role of reports, 166œ169 shifts in, 8popup blockers, 326pornography on the internet, 240 privacy issues concerning, 8portia project, 112engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.424 indexpositives, false, 43œ45, 120post, robert, 62potential surveillance, 311power relationships, differential, 316pragmatic approach to privacy, 60preference factor, 76, 218, 364presidential directives, executive orders and, 146œ147pressures on privacy, 312œ318ﬁpretexting,ﬂ 135pretty good privacy (pgp), 267principles of privacy, xi, 13œ14, 38œ52, 323œ325 anonymity, 45œ48 choice and consent, 338œ339 fair information practices, 48œ50 false positives, false negatives, and data quality, 43œ45 personal information, sensitive information, and personally identiable information, 39œ43, 42n.15 reasonable expectations of, 50œ52privacy and anonymity, 45œ48 assessing, viii, 61, 206œ207 and the assignment of property rights to individuals, 73œ74 and behavioral economics, 75œ78 benets of, 340 coherence in the concept of, 14, 62œ66, 333œ336 collective, 343 compromising, vii current environment for, 4 dening, 1œ4, 21œ25, 39œ40, 59œ62, 305œ308, 367n.4, 369n.24 dynamics of, 27œ38 economic perspectives on, 1, 69œ78 emerging technologies and libraries, 244œ248 ethics of, 186 group, 83, 343 guarantees of, 75 in health and medicine, viiœviii, 209œ230 impact of nonu.s. law on, 151œ154 impact of technology on, 88œ90 important concepts and ideas related to, 38œ52 individuals protecting their own, 14 as instrumental, 66œ67 international perspectives on, 366œ399 largescale factors affecting, 28 law enforcement and information technology, 252œ277 law enforcement and national security, 251œ301 libraries and, 231œ250 managing the patchwork of approaches, 14, 161, 333œ334 marketable rights in, vii multidimensional nature of, 22 national security and information technology, 277œ293 pressures on, 312œ318 protecting, viii, 33, 121 public debates about, 13 reasonable expectations of, 50œ52 as restricted access, 59œ62 tensions with national security, 292œ293 of thoughts, 90 threats to, viii, 20 in the united states, short history of, 349œ365 value of, 66, 308œ312, 324n.7, 327privacy & american business, 172privacy act, 137, 159, 159n.14, 165, 168, 170, 204, 336, 362œ363privacy advocates groups, vii institutional, 14, 331œ332 public, 339œ345 role of, and public opinion, 162œ166privacy and freedom, 59œ61, 167privacy and organizations, 175, 177œ208 data aggregation organizations, 26, 116, 196œ200, 334, 361 education and academic research institutions, 183œ188engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 425 nancial institutions, 188œ191 institutional use of information, 178œ183 mass media and content distribution industries, 201œ203 nonprots and charities, 200œ201 retail businesses, 35, 191œ196 statistical and research agencies, 203œ205privacy approaches in the information age, 323œ346 individual actions, 325œ328 organizationbased actions, 328œ332 principles, 323œ325 public policy actions, 332œ346privacy backdrop, 55œ173 intellectual approaches and conceptual underpinnings, 57œ87 legal landscape in the united states, 122œ154 politics of privacy policy in the united states, 155œ173 technological drivers, 88œ121privacy commission, establishing a standing, 15, 341œ342, 344œ345privacy concerns analyzing causes for, viii, 20 growing in the united states, vii in the ﬁinformation age,ﬂ 19 and law enforcement, 275œ277 over pornography, 8privacy context, 3œ4, 175œ301 in health and medicine, 4, 209œ230 in law enforcement and national security, 251œ301 and libraries, 231œ250 in organizations, 177œ208 social, 63 taking into account, 13privacy enhancers technologies for, 107œ116 unsolved problems as, 116œ118 for use by individuals, 107œ109 for use by information collectors, 109œ116privacy fundamentalists, 60privacy impact assessments (pias), 298œ301, 330œ331privacy implications of greater patient involvement in health care, 224œ225 of receiving health care services, 226privacy international, 392n.144privacy laws. see also common law nonu.s., 151œ154 respecting the spirit of, 14, 335œ336 reviewing existing, 334œ335 by state, 148 state and local, 334privacy literature, vii economicsoriented, viiprivacy policy, 6œ7, 206œ207. see also politics of privacy policy in the united states; public policy correction of, 7 creation of, ix, 153œ154 international perspectives on, 151, 153œ154, 374n.50, 377n.63, 378n.68 limiting information collected and stored, 6œ7 limiting outsider access to information, 7 making easily readable, 179n.2, 328 notications of, 7, 223œ224 prevention of internal abuse, 7privacy pragmatists, 60privacy protection act, 167privacy regulation, 143œ146 economic impact of, 74œ75, 75n.29 hipaa, 225œ226privacy rights assertions of, 311œ312, 359 as marketable, viiprivacy rights clearinghouse, 165privacysensitive system design, 114œ115, 114n.32privacy torts, common law and, 129œ131private foundations, privacy advocates in, viiiprivate sector institutions, 34, 294engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.426 indexprobable cause standard, 124problems incidence of actual, viii unsolved, as privacy enhancers, 116œ118ﬁprolingﬂ of people, 21, 389n.131 statistical techniques for, 343property rights, privacy and the assignment of, to individuals, 73œ74proprietary information, 2propriety, social and cultural norms regarding, 317prosser, william, 129œ130protection of individuals with regard to the processing of personal data and on the free movement of such data (e.u. directive), 383œ384, 388, 390, 398, 398n.177protests, protecting the right to plan and participate in, 12proxies, 325pruning methods, 118n.35psychological concerns, 26public advocates, for privacy, 339œ345public datagathering systems, largescale, 6public debates about privacy, 13public disclosure of private facts, 129œ130public education, 338, 344public health service act, 143publickey cryptosystems, 267public opinion, and the role of privacy advocates, 162œ166public policy controversy since september 11, 2001, 12 formulation of, 155œ162public policy actions, 322n.6, 323, 332œ346 establishing the means for recourse, 345œ346 managing the privacy patchwork, 14, 161, 333œ334 public advocates for privacy, 339œ345 relevance of fair information practices today, 336œ339 respecting the spirit of the law, 335œ336 reviewing existing privacy law and regulations, 334œ335public protest. see protestspublic surveillance, 309public trust, maintaining, 328publicity, costs associated with unfavorable, 14punchcardtabulating machine, 356puritan ethic, 350œ351qquality of data. see data qualityquery control, 109œ110rradiofrequency id (rfid) tags, 31, 95, 194œ196, 194n.13, 195n.15, 206, 242, 244, 248œ249real id act, 142recoding, 111œ112records bureaucracies relying heavily on, 357 keeping private, 259records, computers and the rights of citizens, 48, 188recourse, establishing the means for, 15, 299, 331, 345œ346redteaming, 330œ331regan, priscilla m., 80, 156, 158registered traveler program, 332regulations framework within united states, 14 restricting information access, 7 reviewing existing, 334œ335regulatory agencies. see also privacy regulation work on privacy from, viirehnquist, william, 171reiman, jeffrey, 61engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 427remailers, 325remote identication techniques, 269reno v. condon, 149œ150reports, role of, 166œ169repurposing of personal information, 15, 180, 214, 270, 314, 338research agencies, 203œ205research purposes, personal information collected for, 187œ188reserve, 59restatement of the law of torts, 130œ131restrictions on information access, 7retail businesses, 35, 191œ196retail credit company, 361retinal pattern scans, 32revolutionary war, 352œ355rfid. see radiofrequency id tagsrfpa. see right to financial privacy actrhizomic surveillance, 364œ365right to financial privacy act (rfpa), 134, 167, 189rights. see privacy rightsrisks, longterm, 13, 324roe v. wade, 61, 363roosevelt, franklin d., 358rosenberg, jerry, 167rosenfeld v. department of justice, 132sﬁsafe harborﬂ approach, 152, 337, 392safeguards rule, 144sarbanesoxley act, 189n.10sars. see suspicious activity reportssars outbreak, 3, 38scam letters, 224scandinavia, 374, 390n.133schaefer, rebecca, 137, 182schema denitions, 116search engine services, 102, 196, 224secrecy, 62 greater need for, 293secret ballots, 310secret courts, 245secure email, 326secure shell (ssh) utilities, 267securities and exchange commission, 144security screening, expedited, 332security tools, for information, 115œ116selfhelp for privacy, personal unilateral actions, 5ﬁselfrealization,ﬂ 371selfregulation, 14 by industry, 216œ219, 328œ332, 391selfservice book checkout systems, 238seltzer, william, 294, 358semayne™s case, 122sensing technologies, 93œ94, 97, 106œ107sensitive information, 39œ43september 11, 2001, attacks, 23, 37, 51, 64, 132œ133, 163, 169, 242, 297, 317, 365, 378. see also usa patriot act libraries and privacy since, 242œ244 public policy controversy since, 12 as a sentinel event, 13sexual offender status, 35, 317sexually explicit material, on the internet, 240singapore, data privacy regime of, 394sixteenth amendment, 358social networking, 35, 344social norms, 317social science data archives, 24social security number (ssn), 40, 142, 339, 358œ359, 361 inappropriate use of, 185, 326social sorting, 84societal shifts, 5, 28 and changes in institutional practice, 3, 33œ36sociological approaches to study privacy, 1, 79œ84, 79n.39,40software advances, 95œ97solitude, 59, 62sorting. see social sortingsoundediting technologies, 30œ31south african bill of rights, 394engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.428 indexsouth african constitution, 395sovereign immunity, doctrine of, 346spam email, 75, 108, 326speech, freedom of, 90spyware programs, 108ssh. see secure shell utilitiesssn. see social security numberstate perspectives on privacy regulation, 147œ150statesponsored surveillance, 365statistical agencies, 203œ205statistical disclosure limitation techniques, 111œ112statistical proling techniques, 343stigma, 310 associated with certain medical conditions, 11, 41storing electronic information, expansion of capabilities for, 91œ93strong encryption algorithms, 267student information, collected for administrative purposes, 183œ187stuntz, william, 297surveillance. see also antisurveillance statutes bureaucratic, 359 dening, 349 evolution of, over time, 103 ﬁnew,ﬂ 101œ102, 255 political loyalty, 353 potential, 311 public, 265n.4, 309 rhizomic, 364œ365 routine, 349 statesponsored, 365 thermalimaging, 124, 258n.5 traditional, 101 video, 4œ5, 31, 34œ35, 94, 106, 251n.1, 255œ258, 256n.3, 309, 321, 374 workplace, 181n.4, 276n.16, 310surveillance in the united states, short history of, 349œ365surveillance technologies, 359suspicious activity reports (sars), 189sweden, 369, 390n.133, 396swift banking communications network, 180n.3switzerland, 369ttalley v. california, 125targeted suppression, 111technological drivers, 2œ3, 6, 28, 55œ56, 88œ121 biological and other sensing technologies, 106œ107 data search companies, 102œ106 hardware advances, 90œ95 impact of technology on privacy, 88œ90 increased connectivity and ubiquity, 97œ100 privacyenhancing technologies, 107œ116 risks to personal information, viii software advances, 95œ97 unsolved problems as privacy enhancers, 116œ118technologies. see also emerging technologies; information technology combined into a datagathering system, 101œ102 cryptographic, 112œ113 fears about, 120 and identication, 266œ271 impact on privacy, 88œ90 in libraries, 238œ242 permitting collection of personal information, vii and physical observation, 254œ259 for protecting privacy, 33 for surveillance, 359technology development, national security and, 280telecommunications act, 136, 359telemarketing and consumer fraud and abuse prevention act, 136telephone consumer protection act, 136engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.index 429temperature sensors, 97terrorism, 11œ12, 51. see also counterterrorism ﬁwar against,ﬂ 365terrorist operations. see also september 11, 2001, attacks identifying, 96 preventing, 292 reactions to, 336thailand, 393thermalimaging surveillance, 124, 258n.5thompson, judith jarvis, 62threats to privacy, viii, 20 insider, 329œ330tia. see total information awareness programtitle iii wiretap act, 135tollfree numbers, 326topcoding, 111torts. see privacy tortstotal information awareness (tia) program, 287, 287n.28, 290œ291trade associations, work on privacy from, viitrade practices, 346trade secrets, 2tradeoffs, 4œ5, 7œ11, 12œ13, 20œ24, 228, 320 clear articulation of, 334 and interactions, viii, 325 making, 2, 318œ323traditional surveillance, 101transborder data ˚ows, 153, 398trans union corporation, 197transformation of information, and the role of technology, 29œ33transience of data elements, 41œ42transparency, enhancing, 320œ321, 338transportation security administration, 332treatise on the law of torts, 131trust, 311œ312 public, maintaining, 328truste, 328ﬁtrusted travelerﬂ cards, 21uubiquitous connectivity, 97œ100udhr. see universal declaration of human rightsunconcern over privacy, 60unfavorable publicity, costs associated with, 14unintended consequences, 21 of hipaa privacy regulations, 225œ226unique identiers, 40, 47united kingdom, 194, 374, 396united nations (un) guidelines concerning computerized personal data files, 385united states department of justice v. reporters committee for freedom of the press, 132universal declaration of human rights (udhr), 381unlisted phone numbers, 326u.s. census bureau, 111, 204, 272, 294, 295n.33, 335, 357, 361 constitutional call for decennial, 354 publicuse les, 24u.s. congress, 145œ146, 149, 189, 220, 358, 362 continental, 353 providing special oversight, 15, 339u.s. constitution. see constitutional foundationsu.s. department of commerce baldrige awards program, 342 information security and privacy advisory board, 342u.s. department of defense, 194u.s. department of health, education, and welfare, 48, 167, 337u.s. department of health and human services (dhhs), 145, 220 ofce of civil rights, 222u.s. department of homeland security (dhs), 290, 298œ301, 331engaging privacy and information technology in a digital agecopyright national academy of sciences. all rights reserved.430 index data privacy and integrity advisory committee, 340, 342 privacy ofce, 340œ341u.s. department of justice (doj), 104, 133u.s. department of state, 278u.s. department of the interior, 357u.s. department of treasury, 189u.s. federal trade commission (ftc), 25, 49, 78, 133œ134, 134n.11, 141, 143, 169u.s. military, 361. see also authorization for use of military forceu.s. national security agency, 146u.s. postal service, 260u.s. supreme court, 57, 122œ129, 132, 149œ150, 160, 170œ171, 201, 258, 261, 360, 363usvisit, 331n.15usa patriot act, 23, 136, 138, 143, 189, 243œ244, 250, 288œ290, 294n.31, 317, 365 additional reauthorizing amendments act, 242n.16 improvement and reauthorization act, 243 librarian™s view of, 245user notication, 113vvalue of privacy, 66, 308œ312, 327veried identity pass, inc., 332video privacy protection act (vppa), 139, 160video surveillance, 4œ5, 31, 34œ35, 94, 106, 255œ258, 309, 321, 374vignettes. see anchoring vignettesvoiceoverip phone service, 136, 262voice recognition technologies, 270voluntary disclosure, 316vote buying, 310vppa. see video privacy protection actwwalking. see gait analysiswar. see also antiwar movement civil liberties in times of, 53warranty cards, 163warren, samuel, 30, 359washington, george, 352n.3washington post, 223washington v. glucksberg, 128watch lists, 310ﬁwatchfulness,ﬂ neighborly, 350watchtower bible & tract soc™y v. stratton, 126watergate scandals, 3, 163, 167, 363web bugs, 316, 326weber, max, 81westin, alan, 59œ61, 165, 167, 362, 367n.3, 371wilson, james q., 157wiretapping, 155, 155n.1, 254 domestic, 147 warrantless, 23withholding information, 5, 72workplace surveillance, 310world trade center. see september 11, 2001, attacksworld war i, 357œ358world war ii, 294, 319, 333, 350, 358world wide web, 8, 29, 102, 104, 239œ240, 262, 333yyahoo!, 102, 104, 152œ153, 152n.22zzip code, 36, 39, 40n.14