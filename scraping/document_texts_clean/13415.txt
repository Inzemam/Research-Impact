detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/13415computing research for sustainability172 pages | 6 x 9 | hardbackisbn 9780309387699 | doi 10.17226/13415lynette i. millett and deborah l. estrin, editors; committee on computingresearch for environmental and societal sustainability; computer science andtelecommunications board; division on engineering and physical sciences;national research councilcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.computing research for sustainabilitycommittee on computing research for  environmental and societal sustainabilitycomputer science and telecommunications boarddivision on engineering and physical scienceslynette i. millett and deborah l. estrin, editorscomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, nw washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.support for this project was provided by the national science foundation under award 1150950451. any opinions, ndings, conclusions, or recommendations expressed in this publication are those of the authors and do not necessarily re˚ect the views of the organization that provided support for the project.international standard book number13: 9780309257589international standard book number10: 0309257581copies of this report are available from:the national academies press500 fifth street, nw, keck 360washington, dc 20001(800) 6246242 or(202) 3343313 http://www.nap.educopyright 2012 by the national academy of sciences. all rights reserved.printed in the united states of americacomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. charles m. vest is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. charles m. vest are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.vcommittee on computing research for  environmental and societal sustainabilitydeborah l. estrin, university of california, los angeles, chairalan borning, university of washingtondavid culler, university of california, berkeleythomas dietterich, oregon state universitydaniel kammen, university of california, berkeleyjennifer mankoff, carnegie mellon universityroger d. peng, johns hopkins bloomberg school of public healthandreas vogel, sap labsstafflynette i. millett, senior program ofcervirginia bacon talati, associate program ofcershenae bradley, senior program assistant computing research for sustainabilitycopyright national academy of sciences. all rights reserved.vicomputer science and telecommunications boardrobert f. sproull, oracle (retired), chair prithviraj banerjee, abbsteven m. bellovin, columbia universityjack l. goldsmith iii, harvard law schoolseymour e. goodman, georgia institute of technologyjon m. kleinberg, cornell universityrobert kraut, carnegie mellon universitysusan landau, radcliffe institute for advanced studypeter lee, microsoft corporationdavid liddle, u.s. venture partnersdavid e. shaw, d.e. shaw researchalfred z. spector, google, inc.john stankovic, university of virginiajohn swainson, silver lake partnerspeter szolovits, massachusetts institute of technologypeter j. weinberger, google, inc.ernest j. wilson, university of southern californiakatherine yelick, university of california, berkeleystaffjon eisenberg, directorrenee hawkins, financial and administrative managerherbert s. lin, chief scientistlynette i. millett, senior program ofceremily ann meyer, program ofcervirginia bacon talati, associate program ofcerenita a. williams, associate program ofcershenae bradley, senior program assistanteric whitaker, senior program assistantfor more information on cstb, see its web site at http://www.cstb.org, write to cstb, national research council, 500 fifth street, nw, washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.viiprefacecomputer science and information technologies offer a wide range of tools for examining sustainability challenges. advances in computer science have already provided environmental and sustainability researchers with a valuable tool setšcomputational modeling, data management, sensor technology, machine learning, and other toolsšand additional research in computer science may provide advanced approaches, tools, techniques, and strategies toward understanding, addressing, and communicating sustainability challenges.the present study emerged from an informal request to the national research council™s computer science and telecommunications board (cstb) from the directorate for computer and information science and engineering, national science foundation (nsf). the project was funded by the national science foundation. the statement of task for the committee on computing research for environmental and societal sustainability, established by the national research council to carry out this study, is as follows:computing has many potential ﬁgreenﬂ applications including improving energy conservation, enhancing energy management, reducing carbon emissions in many sectors, improving environmental protection (including mitigation and adaptation to climate change), and increasing awareness of environmental challenges and responses. an ad hoc committee would plan and conduct a public workshop to survey sustainability challenges, current research initiatives, results from previouslyheld topical workshops, and related industry and government development computing research for sustainabilitycopyright national academy of sciences. all rights reserved.viii prefaceefforts in these areas. the workshop would feature invited presentations and discussions that explore research themes and specic research opportunities that could advance sustainability objectives and also result in advances in computer science and consider research modalities, with a focus on applicable computational techniques and longterm research that might be supported by the national science foundation, and with an emphasis on problem or userdriven research. the committee would obtain additional inputs through briengs to the committee and solicitations of comments and white papers from the research community. it would use additional deliberative meetings of the committee to develop a consensus report identifying promising research opportunities, cataloging applicable computational techniques, laying out an overall framework for ﬁgreenﬂ computing research, and recommending longterm research objectives and directions. the committee™s consensus report will include a summary of the workshop as an appendix.the committee reviewed current efforts underway in industry (and other opportunities for the immediate application of existing information technology) and explored research themes and specic research opportunities that could advance sustainability (energy and environmental) objectives and also result in advances in computer science. the committee considered research modalities, with a focus on applicable computational techniques and longterm research. the report, which includes as appendix a the summary of the workshop on innovation in computing and information technology for sustainability, identies promising research opportunities, catalogs applicable computational techniques, lays out an overall framework for computing research for sustainability, and recommends longterm research objectives and directions. chapter 1 provides examples of domains of potential impact, chapter 2 describes methods and approaches, and chapter 3, which is aimed primarily at computer science researchers, articulates why the interplay between addressing sustainability challenges and computer science research merits attention.meeting these challenges will involve advances in a number of computing research areas, including the following: scalability; robustness; reliability; realtime observation and processing; lowpower computing, and sensing and actuation; and human interaction with the environment, observations, and feedback systems. a number of specic areas of computer science and topics addressed in current research programs of nsf™s directorate for computer and information science and engineering are relevant.this report represents the cooperative effort of many people. the members of the study committee, after substantial discussions, drafted computing research for sustainabilitycopyright national academy of sciences. all rights reserved.preface ixand worked through several revisions of the report. the committee would like to thank jeannette wing, sampath kannan, and douglas fisher for their encouragement and support of this study. the committee also appreciates the insights and perspective provided by the following experts who presented briengs:adjo amekudzi, georgia institute of technology,peter bajcsy, national institute of standards and technology,eli blevis, indiana university, bloomington,david brown, duke university,randal bryant, carnegie mellon university,david douglas, national ecological observatory,john doyle, california institute of technology,chris forest, pennsylvania state university,thomas harmon, university of california, merced,neo martinez, pacic ecoinformatics and computational ecology lab,vijay modi, columbia university,shwetak patel, university of washington,robert pfahl, international electronics manufacturing initiative,david shmoys, cornell university, andbill tomlinson, university of california, irvine.finally, i thank cstb staff members lynette millett and virginia bacon talati for their efforts in steering the committee™s work, coordinating the meetings and speakers, and drafting, editing, and revising report material. deborah l. estrin, chaircommittee on computing research for  environmental and societal sustainability computing research for sustainabilitycopyright national academy of sciences. all rights reserved.xxacknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national research council™s report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:alice agogino, university of california, berkeley,ruzena bajcsy, university of california, berkeley,jeff dozier, university of california, santa barbara,brian gaucher, t.j. watson research center, ibm,roger ghanem, university of southern california,marija ilic, carnegie mellon university,david shmoys, cornell university, andbill tomlinson, university of california, irvine.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by katharine computing research for sustainabilitycopyright national academy of sciences. all rights reserved.acknowledgment of reviewers xifrase, ibm. appointed by the national research council, she was responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.xiiicontentssummary 1 relevance of information technology and computer science to sustainability, 2 the value of the computer science approach to  problem solving, 5 systemsšscale, heterogeneity, interconnection, optimization,  and human interaction, 5 iteration, 6 computer science research areas, 7 strategy and pragmatic approaches, 9 emphasize bottomup approaches and  concreteness, 9 use appropriate evaluation criteria for proposals  and results, 9 apply cs philosophy and approach, 10 foster sustainability research through funding  initiatives, 10 foster needed multidisciplinary approaches, 11 blend sustainability and education, 12computing research for sustainabilitycopyright national academy of sciences. all rights reserved.xiv contents1 roles and opportunities for information  13 technology in meeting sustainability  challenges opportunities to achieve signicant sustainability  objectives, 17 built infrastructure and systems, 18 ecosystems and the environment, 20 sociotechnical systems, 21 illustrative examples in information technology and  sustainability, 22 toward a smarter electric grid, 23 sustainable food systems, 36 sustainable and resilient infrastructures, 44 conclusion, 502 elements of a computer science research  51 agenda for sustainability measurement and instrumentation, 55 coping with selfdening physical information, 57 the design and capacity planning of physical information services, 59 software stacks for physical infrastructures, 60 informationintensive systems, 61 big data, 62 heterogeneity of data, 63 coping with the need for data proxies, 64 coping with biased, noisy data, 65 coping with multisource data streams, 66 analysis, modeling, simulation, and optimization, 70 developing and using multiscale models, 70 combining statistical and mechanistic models, 71 decision making under uncertainty, 72 humancentered systems, 77 supporting deliberation, civic engagement, education,  and community action, 79 design for sustainability, 81 human understanding of sensing, modeling, and  simulation, 82 tools to help organizations and individuals engage  in more sustainable behavior, 82 mitigation, adaption, and disaster response, 83 using information from resourceusage sensing, 83 conclusion, 85computing research for sustainabilitycopyright national academy of sciences. all rights reserved.contents xv3 programmatic and institutional  86 opportunities to enhance computer  science research for sustainability computer science approaches for addressing  sustainability, 87 toward universality, 93 education and programmatics, 96 evaluation, viability, and impact analysis, 100 conclusion, 103appendixesa summary of a workshop on innovation in computing and 107 information technology for sustainabilityb biographies of committee members and staff 149computing research for sustainabilitycopyright national academy of sciences. all rights reserved.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summarya broad and growing literature describes the deep and multidisciplinary nature of the sustainability challenges faced by the united states and the world. despite the profound technical challenges involved, sustain ability is not, at its root, a technical problem, nor will merely technical solutions be sufcient. instead, deep eco nomic, political, and cultural adjustments will ultimately be required, along with a major, longterm commitment in each sphere to deploy the requisite technical solutions at scale. nevertheless, technological advances and enablers have a clear role in supporting such change, and information technology (it)1 is a natural bridge between technical and social solutions because it can offer improved communication and transparency for fostering the necessary economic, political, and cultural adjustments. moreover, it is at the heart of nearly every largescale socioeconomic systemšincluding systems for nance, manufacturing, and the generation and distribution of energyšand so sustainabilityfocused changes in those sys tems are inextricably linked with advances in it. in short, innovation in it will play a vital role if the nation and the world are to achieve a more sustainable future. although the greening of itšfor example, the reduction of electronic waste or of the energy consumed by computersšis an important goal of the computing community and the it industry, the focus of this report is 1ﬁinformation technologyﬂ is dened broadly here to include both computing and communications capabilities.1computing research for sustainabilitycopyright national academy of sciences. all rights reserved.2 computing research for sustainabilityﬁgreening through it,ﬂ that is, the application of computing to promote sustainability broadly. the aim of this report is twofold: to shine a spotlight on areas where it innovation and computer science (cs)2 research can help, and to urge the computing research community to bring its approaches and methodologies to bear on these pressing global challenges. the focus is on addressing medium and longterm challenges in a way that would have signicant, measurable impact. the ndings and recommended principles of the committee on computing research for environmental and societal sustainability concern four areas: (1) the relevance of it and cs to sustainability; (2) the value of the cs approach to problem solving, particularly as it pertains to sustainability challenges; (3) key cs research areas; and (4) strategy and pragmatic approaches for cs research on sustainability. relevance of information technology  and computer science to sustainabilityan oftencited denition of ﬁsustainabilityﬂ comes from our common future, the report of the brundtland commission of the united nations (un): ﬁ[s]ustainable development is development that meets the needs of the present without compromising the ability of future generations to meet their own needs.ﬂ3 the un expanded this denition at the 2005 world summit to incorporate three pillars of sustainability: its social, environmental, and economic aspects.4 this report takes a similarly broad view of the term. although much of the focus in sustainability has been on mitigating climate change, with efforts aimed at managing the carbon dioxide cycle and increasing sustainable energy sources, there are other important sustainability challenges (such as water management, improved urban planning, supporting biodiversity, and food production) that can also be transformed by advances in computing research and are thus considered in this report. it is natural when viewing sustainability through the lens of computer science to take a systems view. an elaboration on the broad denition of 2 ﬁcomputer scienceﬂ is dened broadly here to include computer and information science and engineering.3united nations general assembly, march 20, 1987, report of the world commission on environment and development: our common future; transmitted to the general assembly as an annex to document a/42/427šdevelopment and international cooperation: environment; our common future, chapter 2: towards sustainable development; paragraph 1, united nations general assembly. available at http://www.undocuments.net/ocf02.htm. 4united nations general assembly, 2005 world summit outcome, resolution a/60/1, adopted by the general assembly on september 15, 2005.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summary 3sustainability above is that a system is not sustainable unless it can operate indenitely into the future. for a system to do so inevitably requires optimization over time and spacešgoals that are central to much of computer science.the report smart 2020: enabling the low carbon economy in the information age5 usefully groups opportunities for applying it to sustainability into three broad areas: (1) built infrastructure and systems, (2) ecosystems services and the environment, and (3) sociotechnical systems. the following describes each of these areas and outlines applications of it and opportunities for computer science research:. this area includes buildings, transportation systems (personal, public, and commercial), and consumed goods (commodities, utilities, and foodstuffs). it contributes to sustainable solutions in built infrastructure in numerous ways, from improved sensor technologies (e.g., in embedded sensors in smart buildings) and improved system models, to improved control and optimization (e.g., of logistics and smart electric grids), to improved communications and humancomputer interfaces (enabling people to make more effective decisions). . this area encompasses assessing, understanding, and positively affecting (or not affecting) the environment and particular ecosystemsšthese efforts represent crosscutting challenges for many sustainability efforts. the scale and scope of efforts in this area range from local and regional efforts examining species habitats, to watershed management, to understanding the impacts of global climate change. the range of challenges itself poses a problem: how best to assess the relative importance of various sustainability activities with an eye toward signicant impact. additionally, computational techniques will be valuable for developing scientic knowledge and engineering technologies, including improved methods for datadriven science, modeling, and simulation to improve the degree of scientic understanding in ecology.. sociotechnical systems encompass society, organizations, and individuals, and their behavior as well as the technological infrastructure that they use. large and longlived impacts on sustainability will require enabling, encouraging, and sustaining changes in behavioršon the part of individuals, organizations, and nationstates over the long term. it, and in particular realtime information and tools, can better equip individuals and organizations to make daily, ongo5 the climate group, smart 2020: enabling the low carbon economy in the information age (2008). available at http://www.smart2020.org/publications/. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.4 computing research for sustainabilitying, and signicant changes in response to a constantly evolving set of circumstances. there are, of course, many points of intersection across these areas. for example, ecofeedback devices within the home (a sociotechnical system) interact with the larger, smart grid system (part of the built infrastructure); personal mobile devices (relying on built infrastructure and deployed in a sociotechnical context) provide data that feed into more robust modeling (a crosscutting methodology itself); and so on. in addition, better information about what is happening at an individual or local level can inform broader policy making and decision making. smarter energy grids, sustainable agriculture, and resilient infrastructure provide three concrete and important examples of the potential role of it innovation and cs research in sustainability.  moving toward smarter and more sustainable ways of providing electricity will require a rethinking of many aspects of society, including the fundamental electric grid. a forwardlooking, sustainable grid scenario presents a fundamentally more cooperative interaction between demand and supply, as well as greater transparency throughout the energy supply chain, with the goal of achieving both deep reductions in peak demand and reductions in overall demand as well as deep penetration of renewables in the supply blend. information and data management with regard to both time (demand, availability, and so on) and space are essential to making progress toward a smarter, more sustainable electric grid. computer science research and methodological approaches (in areas including user interfaces and improved modeling and analytical tools) will be needed at all levels to address the broad systems challenges presented by the smart grid. with respect to agriculture, there is growing concern regarding whether agricultural productivity can keep pace with human needs. a sustainable food system will be key to ensuring that the world™s population receives necessary nutrition without additional damage being done to the environment and society. as with the electric grid, it is in the systems issues in sustainable agriculture that the opportunities for it seem most salient. approaches to a sustainable food system include taking a systems view of the challenge; developing methods for measuring the costs, benets, and impacts of different agricultural systems; assisting in the use of precision agriculture to minimize needed inputs; making information accessible for informed consumption; and developing social networks for local food sourcing. as with the smart electric grid, information and data management are essential to making progress toward a smarter, more sustainable, global food system. computer science research computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summary 5and methodological approaches will be needed to address the broad systems challengesšencompassing the environment and ecosystems, social and economic factors, and personal and organizational behaviors affecting food production, distribution, and consumption. the development of sustainable and resilient infrastructures poses crosscutting challenges, especially when a broad view of sustainability is taken that encompasses economic and social issues. contributing to the challenges of increasing the resilience of societal and physical infrastructures is the growing risk of natural and humanmade disasters. enhancing society™s resilience and ability to cope with inevitable disasters will con tribute to sustainability. even apart from climate change and resource consump tion, the sheer magnitude of earth™s population means that crises, when they happen, will be at scale. sustainability challenges in this area involve planning and modeling infrastructure, and the anticipation of and response to disasters and the ways in which information technology can assist with developing sustainable and resilient infrastructures. sustainability, of course, encompasses much more than the areas and examples outlined above, which are used here to illustrate the breadth of the challenges that need to be faced and the role that computer science and information technology can play.the value of the computer  science approach to problem solving as the sections below discuss, several key underlying philosophical and methodological approaches of computer science are well matched to key characteristics of sustainability problems. systemsšscale, heterogeneity,  interconnection, optimization, and human interactionsustainability problems often share challenges of scalešsometimes due to the size of the problem space (e.g., geographic or planetary scale), sometimes due to the potential range of impact (e.g., widespread potential health or economic impacts), and often due to both. sustainability problems are also typically heterogeneous in naturešthere is almost never just one variable contributing to the challenge, or one avenue to a solution. inputs, solutions, and technologies that can be brought to bear on any given problem vary a great deal. most sustainability challenges emerge in part due to interconnectionšmultiple interlocking pieces of a system all having effects (some expected, some not) on other pieces of the system. solutions to sustainability challenges typically involve nding nearcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.6 computing research for sustainabilityoptimal tradeoffs among competing goals, typically under high degrees of uncertainty in both the systems and the goals. hence, methods for nding robust solutions are critical. and nally, human interaction with systems can play a role in both developing solutions and contributing to challenges.6in addition to systems challenges, many sustainability challenges, particularly those related to infrastructure such as smarter transportation or electric systems, involve architecture. architecture encompasses not just structural connections among subsystems, but also expectations regarding what a system will do, how it will perform, what behaviors are within bounds, and how subsystems (or external actors) should interact with the system as a whole. a system™s architecture instantiates early design decisions and has a signicant effect on the uses, behaviors, and effects of the system over its life cycle long past the time when those decisions were made. as a result, largerscale systems of necessity merit signicant attention and resources devoted to architecture. as computer and information systems have become global in scale, the disciplines of computer science and software engineering have grappled with the challenges of architecture as they pertain to largescale systems working over large geographic areas with countless inputs and millions of users. lessons from architecting hardware, software, networks, and information systems thus have broader applicability to the processes of the structuring, designing, maintaining, updating, and evolving of infrastructure in pursuit of sustainability.finding: although sustainability covers a broad range of domains, most sustainability issues share challenges of architecture, scale, heterogeneity, interconnection, optimization, and human interaction with systems, each of which is also a problem central to cs research. iterationgiven the scope and scale of many of the sustainability challenges faced today, it is very likely that no one solution or approach will sufce, even for those challenges that are comparatively easy to state (such as, ﬁreduce greenhouse gas emissionsﬂ). thus, multiple approaches from multiple angles will need to be tried. moreover, the urgency of acting in the face of threats to biodiversity and consequences of global climate change means that the bestknown options need to be deployed quickly 6of course, many other scientic disciplines offer useful methodological approaches to sustainability, some of which overlap with what computer science offers. this report focuses on computer science, as directed in the study committee™s statement of task (see the preface).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summary 7while the adaptive redesign of the deployed system continues to be supported as advances in scientic understanding, changes in technology, and evolution in political and economic systems are incorporated. thus iterationšadjusting, rening, and learning from ongoing effortsšwill be essential, and it will often have to be done at a societal and planetary scale.iteration is another core strength of computer science, and learning from iterative approaches to largescale software systems and applications, and largescale software engineering and system deployment generally, can help with largescale sustainability challenges. the approach has been demonstrated in such specic applications as the engineering of the global internet and the deployment of web search and has been used effectively in a wide array of successful software engineering projects. because sustainability challenges involve complex, interacting systems of systems undergoing constant change, a datadriven, iterative approach will be essential to making progress and to making needed adjustments as situations change. one approach is to deploy technology in the eld, using reasonably wellunderstood techniques, at rst to explore the space and map gaps that need work. data and models developed on the basis of this initial foray can then help provide context for developing qualitatively new techniques and technologies for contributing to even better solutions.finding: fastmoving iterative, incrementally evolving approaches to problem solving in computer science, which were critical to building the internet and web search engines, will be useful in solving sustainability challenges.computer science research areasdespite numerous opportunities to apply wellunderstood technologies and techniques to sustainability, there are also hard problemsšfor example, the mitigation of climate changešfor which current methods offer at best partial solutions and the pressing nature of the challenges motivates rapid innovation. this section describes some salient technical research areas and outlines a broad research agenda for cs and sustainability. finding: although current technologies can and should be put to immediate use, cs research and it innovation will be critical to meeting sustainability challenges. effectively realizing the potential of cs to address sustainability challenges will require sustained and appropriately structured and tailored investments in cs research. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.8 computing research for sustainabilitythe committee selected four broad cs/it research areas meriting attention in order to help meet sustainability challengesšall of which contain elements of sensing, modeling, and action. the following list is not prioritized. efforts in all of these areas will be needed, often in tandem.the areas correspond well to measurement, data mining, modeling, control, and humancomputer interaction, which are wellestablished research areas in computer science. this overlap of selected research areas with established research areas has positive implications: research communities are already established, and it will not be necessary to develop entirely new areas of investigation in order to effectively address global sustainability challenges. nonetheless, nding a way to achieve that impact may require new approaches to these problems and almost certainly new ways of conducting and managing research. the ultimate goal of much of computer science in sustainability can be viewed as informing, supporting, facilitating, and sometimes automating decision making that leads to actions with signicant impacts on achieving sustainability objectives. the committee uses the term ﬁdecision makingﬂ in a broad sensešencompassing individual behaviors, organizational activities, and policy making. informed decisions and their associated actions are at the root of all of these activities. finding: enabling and informing actions and decision making by both machines and humans are key components of what cs and it contribute to sustainability objectives, and they demand advances in a number of topics related to humancomputer interaction. such topics include the presentation of complex and uncertain information in useful, actionable ways; the improvement of interfaces for interacting with very complex systems; and ongoing advances in understanding how such systems interact with individuals, organizations, and existing practices. principle: a cs research agenda to address sustainability should incorporate sustained effort in measurement and instrumentation; informationintensive systems; analysis, modeling, simulation, and optimization; and humancentered systems. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summary 9strategy and pragmatic approachesfor computer science to play an effective part in meeting global sustainabil ity challenges, priority should be given to research that addresses one or more important sustainability challenges and that offers the prospect of tangible impact, either directly or through gamechanging contributions that offer leveraging opportunities for other domains. the research areas listed in the section above are the committee™s recommended starting place.an ongoing challenge is for it experts and cs researchers to ensure that technologies and approaches represent usable and appropriate solutions, that they are highly effective, and that they take advantage of the deepest and most powerful insights that can be brought to bear. emphasize bottomup approaches and concretenessthe committee believes that cs research on sustainability is generally best approached not by striving for universality from the start, but instead by beginning from the bottom up: that is, by developing wellstructured solutions to particular, critical problems in sustainability, and later seeking to generalize these solutions. indeed, this has been a fruitful approach in many other application areas. progress in many needed advances will require cs research (as described earlier), but those advances may not be immediately evident as universal approaches.  rather, to be judged as a signicant contribution at the intersection of cs research and sustainability, the contribution must rst have the potential to make a real difference in moving toward a more sustainable future.  embracing the concrete will help researchers hone and lter their approaches, and multiple and adapted applications will emerge.  many potential new applications are developed and nd their ultimate universality through bottomup cycles of change and through the iterative process of design that promotes those cycles of change. past successful examples of this approach include internet protocols, machine learning, objectoriented languages, and databases.use appropriate evaluation criteria for proposals and resultsa premature focus on universality would be damaging to highimpact sustainability solutions. however, to be considered successful, cs research on sustainability must ultimately contribute to generalizable knowledge about sustainability, and the contribution or proposed solution should, at the same time, require new computational techniques or thinking beyond the current state of the art in computing. establishing metrics for multidisciplinary work that are both actionable and meaningcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.10 computing research for sustainabilityful across participating disciplines is challenging, and the specic criteria for judging research success should evolve over time, with members of the community proposing and debating what constitutes the most worthy research. the committee emphasizes, however, the criterion of having the potential to make a real differencešthat is, to make signicant progress on social, economic, and environmental sustainability challenges.principle: there should be strong incentives at all stages of research for focusing on solving real problems whose solution can make a substantial contribution to sustainability challenges, along with indepth metrics and evaluative criteria to assess progress.apply cs philosophy and approachthe solutions for real problems referred to in the principle above should be designed such that they embed the best of cs design and systems learningsšmodularity, isolation, simplicity, and so on. then researchers and practitioners should experiment with, apply, and pilot solutions to specic problems, looking for the successes and reapplying and adapting them to other applications and developing universality, while building the applicability and impact. such work will need to be done across disciplinary boundaries and involve experts from many elds. just as specic proposed solutions will need to be assessed in an iterative fashion, so too the research enterprise will need to have informed checkpoints and evaluative criteria in order to ensure that the goal of having a real impact is being met.  thus the committee urges an emphasis on interdisciplinarity, iteration, and highlevel information sharing to assess progress. foster sustainability research through funding initiativesprogrammatically, traditional computer science research funding approaches are unlikely to be adequate to address the need discussed here. the national science foundation (nsf) is a primary funder of research in computer science in the united states. the former information technology research programs at nsf and the current cyberenabled discovery and innovation program are good examples of multidisciplinary programs, demonstrating that such efforts are feasible. but such programs are still a small minority among funding programs, and in the committee™s view most review panels on most of the programs related to cs research are not generally favorable toward funding domainspecic projects. the committee is encouraged by the establishment of science, engineering, and education for sustainability (sees) as an nsfwide computing research for sustainabilitycopyright national academy of sciences. all rights reserved.summary 11area of investment. sees aims for a systemsbased approach to ﬁadvance science, engineering, and education to inform the societal actions needed for environmental and economic sustainability and sustainable human wellbeingﬂ7 and places an emphasis on interdisciplinary efforts. it provides a programmatic opportunity to put the recommended principles of this report into practice at nsf. for the eld of computer science, efforts such as this can serve as a model for conceptualizing funding structures in order to take the greatest advantage of the depth of it and cs innovation that the core discipline can offer to the rich and globally important problem space of sustainability. foster needed multidisciplinary approachesthe type of work described above will have to be done across disciplinary boundaries and to involve experts from many disciplines, as well as individuals who themselves have deep expertise in more than one discipline. among the several opportunities for enhancing multidisciplinary approaches are scholarships that emphasize the development of expertise in complementary disciplines, and regular, highlevel summits involving cs and sustainability expertsšpractitioners and researchersšto inform shared research design, assess progress, and identify gaps and opportunities. research institutionsšboth universities and funding  organiza  tionsšcould better address the needs of authentic multidisciplinary research, in terms of adjustments to how individuals are evaluated and in terms of publications, funding, criteria for promotion, infrastructure for sustained collaboration, and cross training. principle: encourage research at and across disciplinary boundaries, well informed by specics and well structured to handle scale, data, integration, architecture, simulation, optimization, iteration, and human and systems aspects. cs research in sustainability should be an interdisciplinary effort, with experts in the various elds of sustainability being equal partners in the research.principle: rene funding and programmatic options to reinforce and provide incentives for the necessary boundary crossing and integration in cs research to address sustainability challenges. in particular, funding, promotion, and review and assessment (peer 7sees mission statement. available at http://www.nsf.gov/funding/pgmsumm.jsp?pimsid=504707. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.12 computing research for sustainabilityreview) models should emphasize indepth integration with data and deployments from the constituent domains. blend sustainability and educationa shifting of the culture of cs to embrace sustainability more fully as an important and fruitful application area for research needs to include educating cs students about ways to have an impact with computing, computation, and systems approaches in important areas. such a shift in culture would encourage students to develop domain expertise and to collaborate directly with domain experts while in graduate school or in preparing for graduate work. such a shift also requires a culture of experimentation and innovation in the application of computer science.adjusting education within the target domains is as important as shifting the culture in cs. information and data are critical to understanding the challenges, to formulating and deploying solutions, to communicating results, and to facilitating learning and new behaviors based on the results of the work. thus a signicant component of meeting virtually all sustainability challenges is to infuse computational thinking and approaches that are rich in cs and it into the deploying industry and agencies.  this component needs to include cross training students in multiple elds to create ﬁchampionsﬂ who can bring a cs perspective into other arenas.  sustainability is a challenge that will persist for generations; sustained commitment will be necessary, as well as continuing innovation in support of efforts to meet sustainability challenges.principle: undergraduate and graduate education in computer science should provide experience in working across disciplinary boundaries. graduate training grants and postdoctoral fellowships should support training in multiple disciplines. undergraduate and graduate programs should include tracks that offer introductory and intermediate course work in such sustainability areas as lifecycle analysis, agriculture, ecology, natural resource management, economics, and urban planning. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.1roles and opportunities for information technology in meeting sustainability challengesinnovation in computing, information, and communications technology is at the heart of nearly every largescale socioeconomic system. computing underlies and enables systems that affect our lives every dayšfrom nancial and health systems to manufacturing, transportation, and energy infrastructures. one important consequence is that advances in computing are critical enablers of change for addressing the growing sustainability challenges facing the united states and the world. a key nding of this report is that information technology (it)1 will play a vital role in achieving a more sustainable future and that research and innovation in computing, information, and communications technologies are consequently critical to addressing the broad range of sustainability challenges (box 1.1). the critical global challenges in sustainability are deep, and solutions will require input from many disciplines. fortunately, there are numerous opportunities to apply it innovations in ways that will have a profound in˚uence on sustainability efforts across many areas, including the ecological and environmental sciences, numerous engineering elds, public policy and administration, and many other areas. the national research council™s (nrc™s) committee on computing research for environmental and societal sustainability is aware that there is signicant effort aimed at making it itself ﬁgreenerﬂ and recognizes that these efforts are important. 1the committee uses the familiar acronym ﬁitﬂ (information technology) to encompass computing, information, and communications technologies broadly.13computing research for sustainabilitycopyright national academy of sciences. all rights reserved.14 computing research for sustainabilitythe greening of it, through efforts such as reducing datacenter energy consumption and electronic waste, should be and is an important goal of the computing community and it industry.2 however, the focus of this report is on what could be termed ﬁgreening through it,ﬂ the use of 2the 2010 oecd report ﬁgreener and smarter: icts, the environment and climate changeﬂ (in oecd, oecd information technology outlook 2010, oecd publishing) notes that impacts from ict life cycles (including not just use but also production and end of life) need to be considered in order to understand complete impacts. a recent mckinsey quarterly article, ﬁclouds, big data, and smart assets: ten techenabled business trends to watch,ﬂ by jacques bughin, michael chui, and james manyika, offered some cause for optimism regarding green it: ﬁelectricity produced to power the world™s data centers generates greenhouse gases on the scale of countries such as argentina or the netherlands, and these emissions could increase fourfold by 2020. mckinsey research has shown, however, that the use of it in areas such as smart power grids, efcient buildings, and better logistics planning could eliminate ve times the carbon emissions that the it industry produces.ﬂ mckinsey quarterly 5(3):114.box 1.1 a note on the definition of  ﬁsustainabilityﬂ and the focus of the committeean oftencited denition of ﬁsustainabilityﬂ comes from the brundtland commission of the united nations (un): ﬁ[s]ustainable development is development that meets the needs of the present without compromising the ability of future generations to meet their own needs.ﬂ1 the un expanded this denition at the 2005 world summit to incorporate three pillars of sustainability: its social, environmental, and economic aspects.2 this report takes a similarly broad view of the term. although much focus in sustainability has been on mitigating climate change, with efforts aimed at managing the carbon dioxide cycle and increasing sustainable energy sources, the committee recognizes that there are numerous additional sustainability challenges that could be assisted by advances in computing and information technology and computing3 research. the committee™s focus is on addressing medium and longterm challenges in a way that has signicant and ideally, measurable, impact. 1united nations general assembly (march 20, 1987). report of the world commission on environment and development: our common future; transmitted to the general assembly as an annex to document a/42/427šdevelopment and international cooperation: environment; our common future, chapter 2: towards sustainable development; paragraph 1. united nations general assembly. available at http://www.undocuments.net/ocf02.htm.2united nations general assembly, 2005 world summit outcome, resolution a/60/1,  adopted by the general assembly on september 15, 2005.3the term ﬁcomputingﬂ is used generally in this report and is meant to encompass information and communications technologies (icts). thus ﬁcomputingﬂ and ﬁictsﬂ are used interchangeably throughout the report.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 15computing and it across disciplines to promote sustainability in areas and systems in which advances in information and communications technology (ict) could have signicant positive impact.3 the committee believes that some of the most profound fundamentals within the eld itself are suggestive of the unique contributions that computer science (cs) and icts can make to sustainability. for instance, the very notion of automated ﬁqueryableﬂ structured data is at the heart of much of computer science. the scope and scale of the sustainability challenge are coupled with vast amounts of relevant data, which makes deep insights into the challenges of collecting, structuring, and understanding those data essential. computational thinking is critical to solving almost any large problem. the committee™s focus is on problems that are intellectually challenging, grounded in it and cs, and important for sustainabilityšthat is, a kind of ﬁpasteur™s octant.ﬂ see figure 1.1. despite the profound technical challenges presented by sustainability and the huge potential role for it and cs, the committee recognizes that sustainability is not, at its root, a technical problem, nor will merely technical solutions be sufcient. instead, solutions ultimately will require deep economic, political, and cultural adjustments, as well as major, longterm commitment in each sphere in order to put technical advancements and enablers in operation at scale. nevertheless, technological advances and enablers can be developed and shaped to support such change, while continuing to support enduring human values in the process. information technology can serve as a bridge between technical and social solutions 3the community has already begun addressing this challenge. bill tomlinson™s book greening through it: information technology for environmental sustainability (cambridge, mass.: mit press, 2010) explores how it can address sustainability challenges at scale. a 2009 article by carla gomes, ﬁcomputation sustainability: computational methods for a sustainable environment, economy, and societyﬂ in the bridge 39(4):513, provides examples of computational research being applied to domain elds (biodiversity and renewable energy sources). gomes™s work is an important component of computational sustainability; the present report explores the broader potential for research and innovation in cs and it to have an impact on sustainability. additionally, the national science foundation™s directorate for computer and information science and engineering and the computing community consortium (ccc) jointly sponsored a workshop on the role of information sciences and engineering in sustainability. the full report of the workshop, science, engineering, and education of sustainability: the role of information sciences and engineering, which discusses research directions for it as it relates to sustainability, is available at http://cra.org/ccc/docs/risesworkshopfinalreport5102011.pdf. this report is well aligned, in terms of research areas, with the ccc report. additionally, the committee concurs with the ccc report section 4, titled ﬁthe power of useinspired (collaborative) fundamental research.ﬂ the present report expands on this theme in chapter 3, especially in regard to the strength of computer science as a discipline and what it can contribute to sustainability objectives. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.16 computing research for sustainabilityby enabling improved communication and transparency for fostering the necessary economic, political, and cultural adjustments.4 furthermore, sustainability problems are typically heterogeneous in naturešthere is almost never just one variable contributing to the challenge or one avenue to a solution. inputs, solutions, and technologies that can be brought to bear on any given problem vary themselves a great deal. most sustainability challenges emerge in part due to interconnectionša result of multiple interlocking pieces of a system all having effects (some expected, some not) on other pieces of the system. solutions to sustainability challenges typically involve nding nearoptimal tradeoffs among competing goals, typically under high degrees of uncertainty in both the systems and the goals.in addition to noting the crosscutting nature of many sustainability challenges, it is important to recognize the emergent qualities that typify the sorts of systems being discussed here. some projections of what might 4e. ostrom. a general framework for analyzing sustainability of socialecological systems, science 325:419422 (2009). figure 1.1 the committee™s focus is on problems at the intersection of signicant intellectual merit, relevance to computer science (cs), and importance to sustainability.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 17be accomplished with the savvy application of known technologies or nearterm research are straightforward, even in systems and domains as complex as these. however, in such complex systems and domains there are likely to be emergent behaviors and properties as wellšboth toward and away from desired outcomes. it practitioners have proven remarkably adept at innovating ˚exibly when previously unanticipated systems behaviors have demanded responses. the complexity and unpredictability of the results of unsustainable human activities require an innovative and ˚exible approach to solving or mitigating sustainability problems and their impacts, and it researchers and practitioners are skilled at innovating and developing ˚exible solutions in dynamic environments. the committee believes that computing researchers and research approaches will be essential to grappling with current and future systems challenges in sustainability. this report has three chapters. chapter 1 elaborates on domains of potential impact in order to illustrate the role and the available opportunities of it on the broader path toward sustainability. it address the question, in what ways and where can computing research have measurable, signicant impact? chapter 2 describes methods and approaches in discussing the questions, how do fundamental research questions and approaches in computing intersect with sustainability challenges, and how can problem solving and research methodologies in computing research and it innovation be brought to bear on sustainability? in particular, the committee views one important goal of computer science in sustainability as informing, supporting, facilitating, and sometimes automating decision makingšdecision making that leads to actions that will have signicant impacts on achieving sustainability objectives. aimed primarily at computer science researchers, chapter 3 articulates why the interplay between addressing sustainability challenges and computer science research merits attention, and how that interplay offers deep and compelling opportunities for progress in multiple dimensions. appendix a summarizes presentations and discussions at the workshop on innovation in computing and information technology for sustainability, organized by the committee. biographies of the committee members are presented in appendix b.opportunities to achieve  significant sustainability objectivesforwardlooking it innovations and sustained research can have signicant positive impact for sustainability across many areas. for the purposes of this report, the areas are clustered as follows: built infrastructure and systems, ecosystems services and the environment, and computing research for sustainabilitycopyright national academy of sciences. all rights reserved.18 computing research for sustainabilitysociotechnical systems.5 each of these is described brie˚y below. there are obvious multiple intersection points in these three distinct areas of opportunity. for example, ecofeedback devices (tools that provide instant information on environmental impact) within the home, a sociotechnical system,6 interact with the larger smart grid system, part of the built infrastructure; personal mobile devices, relying on built infrastructure and deployed in a sociotechnical context, provide data that feed into more robust modeling, a crosscutting methodology, and so on. in all of these domains, as potential solutions are deployed, careful attention will need to be paid to iterate over and evaluate solutions to ensure that progress made in one dimension of a given sustainability problem is not later offset by an unanticipated outcome or side effect in another dimension. the next major section, ﬁillustrative examples in information technology and sustainability,ﬂ provides crosscutting examples of domains in which it can support and strengthen sustainability efforts.  built infrastructure and systemsbuilt infrastructure and systems include buildings (residential and commercial), transportation systems (personal, public, and commercial), and consumed goods (commodities, utilities, and foodstuffs). the climate group™s smart 2020 report examined the use of information and communication technology in built infrastructure in several key areas, including smart buildings, smart logistics, and smart electric grids. according to that report, these three areas alone provide a potential reduction in greenhouse gas (ghg) emissions of 15 percent of global ﬁbusiness as usualﬂ emissions in 2020.7buildings account for up to 40 percent of energy use in industrialized countries and 40 percent of ghg emissions; in the united states they consume more than 70 percent of the electricity produced.8 smart buildings use it systems to make better use of energy while maintaining indoor health and comfort. the embedded it monitors and controls environ5other clusterings are of course possible. the choice of these three was inspired in part by global esustainability initiative, smart 2020: enabling the low carbon economy in the information age (2008). available at http://www.smart2020.org/publications/.6ﬁsociotechnical systemsﬂ encompass society, organizations, and individuals, and their behavior as well as the technological infrastructure that they use. 7global esustainability initiative, smart 2020: enabling the low carbon economy in the information age (2008). available at http://www.smart2020.org/publications/.8world business council for sustainable development, energy efciency in buildings: facts and trendsšfull report (2008). available at http://www.wbcsd.org/pages/edocument/edocumentdetails.aspx?id=13559&nosearchcontextkey=true. see also http://www.eesi.org/buildings. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 19mental and electrical systems in the building by means of computerized, intelligent networks of sensors and electronic devices.9 according to the smart 2020 report, smart buildings could reduce carbon dioxide emissions by an estimated 15 percent in 2020.10 the sustainability of structures generally goes well beyond energy, and involves the reuse and recycling of materials, sustainable construction processes, improved indoor air quality, effective water use, and so on.11 smart logistics use it for more effective supply chains (those dealing with journey and load planning and with personal transportation), both in daily operational use and in longterm planning. examples of it contributions include better geographic information systems and design software to promote more effective transport networks, collaborative multi institutional planning tools to lower the logistical demands associated with desired lifestyles, and better inventorymanagement tools. computing innovation can also lead to better management of consumed resources. smart electric grids use it tools throughout the power networks to enable optimization. (potential smart grid applications are described in greater detail in the section ﬁtoward a smarter electric grid,ﬂ below.) in addition to reductions that can be achieved in energy consumption, smarter water and sewagemanagement systems in the built infrastructure can decrease water consumption and waste. furthermore, largescale agriculture necessitates water and supplychain management; advanced it can enhance precision agriculture, including the incorporation of technologies to predict crop yields more accurately.12 (see the section ﬁsustainable food systems,ﬂ below, for more on food systems broadly.)transportation and city and regional planning also provide important opportunities for more sustainable development; computation and it will be needed to enable signicantly more complex planning for the optimizing of investment in new infrastructure. and, changes to manufacturing itself (which incorporates logistics, sensing, transportation, and manipulation) can help with sustainability goals by reducing environmental impacts, conserving energy and resources, and improving safety 9national research council, achieving highperformance federal facilities: strategies and approaches for transformational change, washington, d.c.: the national academies press (2011).10global esustainability initiative, smart 2020: enabling the low carbon economy in the information age (2008). available at http://www.smart2020.org/publications/.11for an introduction to some of the issues related to achieving highperformance ﬁgreenﬂ buildings, see national research council, achieving highperformance federal facilities: strategies and approaches for transformational change, washington, d.c.: the national academies press (2011).12national research council, toward sustainable agricultural systems in the 21st century, washington, d.c.: the national academies press (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.20 computing research for sustainabilityfor the individuals and communities affected by it. it has a central role in these efforts. ecosystems and the environment assessing, understanding, and positively affecting (or not affecting) the environment and particular ecosystems are crosscutting challenges for many sustainability efforts.13 the scale and scope of such efforts range from local and regional activities examining species habitats, to watershed management, to efforts to increase understanding of the impacts of global climate change. the range of challenges itself poses a problem: how best to assess the relative importance of various sustainability activities with an eye toward signicant impact. nonetheless, in virtually every activity related to meeting sustainability challenges, a critical role is required of data, information, and computation. climate science, for example, has been able to take huge leaps forward due to advances in computing research.14 computational modeling and simulation of earth, the atmosphere, oceans, and biota and of their many interactions have long been at the heart of understanding how changes in carbon cycles and hydrological cycles give rise to global climate change and the estimating of future impacts. sensing, data management, and model formation connect these computational analyses to a vast body of empirical observation and to one another. such tools allow for the continual improvement of delity and can help improve the basic understanding of ˚ows of carbon, nitrogen, and other emissions of interest. these tools also improve the understanding of water and resource usage, of species distributions and biodiversity, and of ways in which human activity perturbs these. analyses of environmental and ecosystem responses to disturbances (those from ghgs, re, invasive species, disease) are important to meeting a range of sustainability objectives. modeling also plays a crucial role in guiding decision makers, by connecting ecological science and research to ongoing ecosystem policy and management. for 13a recent national research council report ﬁcapture[s] some of the current excitement and recent progress in scientic understanding of ecosystems, from the microbial to the global level, while also highlighting how improved understanding can be applied to important policy issues that have broad biodiversity and ecosystem effect.ﬂ national research council, twentyfirst century ecosystems: managing the living world two centuries after darwin, washington, d.c.: the national academies press (2011), p. ix.14d.a. randall, r.a. wood, s. bony, r. colman, r. fichefet, j. fyfe, v. kattsov, a. pittman, j. shukla, j. srinivasan, r.j. stouffer, a. sumi, and k.e. taylor. the physical science basis. contribution of working group i to the fourth assessment report of the intergovernmental panel on climate change, s. solomon d. qin, m. manning, z. chen, m. marquis, k.b. averyt, m.tignor and h.l. miller (eds.), cambridge, united kingdom: cambridge university press (2007). available at http://www.ipcc.ch/publicationsanddata/ar4/wg1/en/ch1s153.html. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 21example, models that jointly capture the interrelationships of multiple variables and their joint uncertainty can support improved understanding and more robust decision making.sociotechnical systemslarge and longlived impacts on sustainability will require enabling, encouraging, and sustaining desired human behavioršthat of indi viduals, organizations, municipalities, and nationstatesšover the long term. sociotechnical systems designed to aid in behavioral assistance and reinforcement and to provide information about progress are a critical element for global sustainability efforts. such systems and associated tools are needed at every scale and can be applied to a range of problems, from enabling effective response in times of acute crisis management, to urban planning, to promoting the understanding of behavioral impacts (sometimes referred to as footprint analysis) on carbon, water, and biodiversity.  institutional behaviors will need to shift in order to realize continuous, longterm environmental changes. marketing and public education initiatives are important and can contribute to individual and institutional knowledge on best practices. however, realtime information and tools can better equip individuals and organization to make daily, ongoing, and signicant changes in response to a constantly evolving set of circumstances. information dashboards accessible to key decision makers are an example of how it can be used to collect, analyze, curate, and informatively present critical information quickly to those who need it most. for example, if the nancial incentives for energy utilities shift from an emphasis on delivering more power more cheaply to an emphasis on improving the ghg emissions efciency of a given level of service, new information will be needed. gathering such information will require greater visibility and understanding of the dynamics of customer demand, grid capacity, and supply availability. in addition, each of the stakeholders will need more effective means of communicating needs and tradeoffs. similarly, in order for urban planning to promote, say, the reduction of liquid fuel consumption for personal transportation, the processes of street design, zoning, planting, business development, water and waste management, and public transportation need to be coordinated across multiple governing bodies and constituencies. personal devices, most notably sensorrich smartphones, not only provide information and services to their users, but also can provide scientists and researchers with information that may have been missed by traditional operational networks. furthermore, citizen scientists are increasingly engaged in scientic problem solving, for example by docucomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.22 computing research for sustainabilitymenting species locations, air quality, and other indicators.15 in addition, environmental challengesšthose caused by damage to the environment from rising ocean water levels and temperatures or those created by the search for and extraction of materialsšcan be monitored, assessed, and tracked. information about environmental challenges can also be disseminated using smarter it. further advances in the ability to analyze data collected by a wide array of sources will facilitate a better understanding of how environmental crises begin and how to avoid them in the future. illustrative examples in  information technology and sustainabilitythis section contains three illustrative examples of sustainabilityrelated domains in which it can have signicant impact and in which there is both some current activity as well as prospects for signicant progress and impact in the future. this set of examples is not meant to be comprehensive and does not re˚ect a prioritization. rather, these examples were chosen to illustrate how itšboth currently understood technologies as well as new onesšcould be brought to bear on sustainability challenges and also to show the range and variability of what is meant by sustainability. each example area listed below cuts across the three broad areas outlined above. the smart grid. in this rst example, the grid is clearly part of built infrastructure, but it also has the potential to affect regional ecosystems dramatically as new sources of renewable energy are brought online (for example, solar facilities deployed in deserts will affect the desert ecosystem). managing the smart grid, from both the supply and the consumption side (which may not be as easily separable in any event) will require sociotechnical systems, such as data management, for humans and human organizations. food systems. this second example also encompasses built environments (including the transportation system), the environment, and ecosystems (in various aspects from macro effects on watersheds to strategies for precision agriculture), and, like the smart grid, it requires sophisticated tools and data management to be most effective. the development of sustainable and resilient infrastructures. this third example poses crosscutting sustainability challenges, especially when considering a broad view of sustainability that encompasses economic 15w. willett, p. aoki, n. kumar, s. subramanian, and a. woodruff, common sense community: scaffolding mobile sensing and analysis for novice users, pp. 301318 in proceedings of the 8th international conference on pervasive computing (pervasive ‚10) (may 2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 23and social issues. these challenges include planning and modeling infrastructure and anticipating and responding to increasingly frequent natural and humanmade disasters.toward a smarter electric grid being able to meet the planet™s energy needs in a sustainable fashion is fundamentally interwoven with foundational transformations in the design, deployment, and operation of the world™s electric grids. the problem is large and complicated, and the committee™s framing in this discussion is for descriptive purposes, and is not meant to be complete, to be prescriptive, or to con˚ict deliberately with other approaches to characterizing the problem.16 with regard to the electric grid, most analyses of potential paths to stabilizing ghg concentrations involve three interrelated advances: deep efciency gains, electrifying the demand, and decarbonizing the supply.17 as a prime example, the united states currently consumes roughly 100 quadrillion british thermal units (btu) (about 100 exajoules) of energy per year, with ˚ows from supply to demand as illustrated graphically in figure 1.2. roughly half of the energy supply goes into the production of electricity. of that, the largest share is provided by coal, which has the worst ghg intensity of the supplies and is the cheapest and fastest way to increase supply in developing economies. by contrast, essentially all of the renewable and zeroemission supplies also go into electricity production, but these account for a tiny fraction of the energy mix. their share must increase substantially in order to 16for instance, a survey paper developed by ibm research on the computational challenges of the evolving smart grid is oriented around the challenges of data, grid simulation, and economic dispatch: j. xiong, e. acar, b. agrawal, a. conn, g. ditlow, p. feldmann, u. finkler, b. gaucher, a. gupta, fl. heng, j. kalagnanam, a. koc, d. kung, d. phan, a. singhee, and b. smith, framework for largescale modeling and simulation of electricity systems for planning, monitoring, and secure operations of next generation electricity grids, special report in response to request for information: computation needs for the nextgeneration electric grid, doe/lbnl prime contract no. deac0205ch11231, subcontract no. 6940385 (2011); m. ilic, dynamic monitoring and decision systems for enabling sustainable energy services, proceedings of the ieee 99:5879 (2011), notes the fundamental role of a manmade power transmission grid and its it in enabling sustainable socioecological energy systems. j. kassakian, r. schmalensee, k. afridi, a. farid, j. grochow, w. hogan, h. jacoby, j. kirtley, h. michaels, i. pérezarriaga, d. perreault, n. rose, and g. wilson, the future of the electric grid: an interdisciplinary mit study, available at http://web.mit.edu/mitei/research/studies/theelectricgrid2011.shtml#report, aims to provide an objective description of the grid today and makes recommendations for policy, research, and data for guiding the evolution of the grid. 17california council on science and technology, california™s energy future: a view to 2050, sacramento (2011). available at http://www.ccst.us/publications/2011/2011energy.pdf.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.24 computing research for sustainabilityreduce the ghg intensity of the delivered electricity. doing so will dramatically change the nature of the supply, however, since the availability of these resources varies with natural factors, such as wind and sun, rather than being dispatched as needed to meet demand. furthermore, the geographic placement of these supplies is governed by natural factors, and so the points at which they attach to the grid, and therefore the pattern of ˚ow from supply to demand and hence the power lines, stations, and devices used to convey these ˚ows of electricity, may be quite different from the ˚ows associated with traditional power plants. this has implications for it, since the informationmanagement problem for distributed energy production is fundamentally different from that for more centralized production. managing electricity produced by a half million windmills requires advanced itšdata management, algorithms, and analyticsšwhereas managing a few hundred coalred power plants is a much simpler proposition from an it perspective. already a signicant fraction of the supply in the u.s. national energy ˚ow is wasted in the generation, transportation, and conversion of this electrical energy, and of that delivered into residential and commercial buildings and industrial processes, much is wasted through inefcient or ineffective usage. moreover, reducing the ghg emissions associated with transportation and industrial processes, which are currently dominated figure 1.2 current u.s. national energy ˚ow. roughly half of the 100 quads (1015 btu) is lost, most coal goes to electricity, electricity goes almost equally to residential buildings, commercial buildings, and industrial processes. source: lawrence livermore national laboratory (2010). data are based on doe/eia0384 (2009). available at https://˚owcharts.llnl.gov/.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 25by liquid fossil fuels, will involve electrication (e.g., plugin hybrid or electric vehicles) and hence will further increase demand. major efciency gains, the accommodation of variable supplies, and electrication are all likely to involve change in the patterns and practices of the institutions and individuals that represent the demand, which in large part rests on access to actionable information. innovation in it and its use underlie all aspects of such a transformation, as described below.electric grids can be characterized by their key components: generation, transmission, distribution, and load. typically, each of these components has been addressed in isolation. although multiple approaches to transforming electric grids t within the term ﬁsmart grid,ﬂ the fundamental change in the future will likely be to treat the key components together, as an interrelated system. whereas other disciplines will contribute primarily to the advance of the physical components comprising the elements of the energy supply chain, it is expected to govern how these elements behave and how the complex system as a whole functionsšthat is, what properties it exhibits. the section below rst describes several challenges presented by smart grids and then outlines approaches to addressing these challenges, especially from an it perspective. finally, a discussion of the specic role of computer science research and innovation in it is offered. challenges for the modern electric gridfour main challenges for the modern electric grid are discussed below:  grid; dispatched on the basis of realtime power demand, with coarse predictive analytics deployed to ensure that enough will be available; demand is managed to better match the available supply; andincreased consumption increased productivity and improved standards of living correlate closely with increased energy consumption. even in the united states, where the energytogross domestic product (gdp) ratio has been steadily improving through technological improvements and efciency measures, especially since the oil crisis in 1973, overall energy consumption continues to increase. this is an especially serious problem in recently industrialized nations, such as china. continuing increases in consumption pose multiple challenges.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.26 computing research for sustainabilityin terms of generation, rapid increase in electricity production tends to skew the supply blend toward carbon and particulateheavy sources such as coal, because such supplies are currently easier to bring online quickly when needed. this trend further compounds the ghg emission problem. lowercarbon options, such as nuclear power, present other hazards, and renewable sources cannot typically be dispatched on demand, impose other environmental impacts, or are remote from areas of dense consumption. wasteful production and manufacturing practices, especially in newly industrialized or rapidly growing economies, further compound the climate impact. it cannot provide generation, but it can enable more effective use of generation facilities to meet increased demand, facilitate the shift toward more desirable supplies, and help manage the increasing demand. in addition to providing adequate supply to meet growing demandšwhich clearly cannot continue indenitelyšit must be possible to deliver the generated energy through the transmission grid and distribution tree reliably and safely. each power line and each piece of electrical equipment has limited capacity and lifetime.18 steering actions or switches do not determine the amount of power transferred along each line explicitly, as is done in networks involving transportation, communications, or even water distribution. instead, the amount of power is determined implicitly, by the underlying physics associated with a distributed collection of loads, connected to a differently distributed collection of generators, through a particular interconnection of wires and transformers. individual consumers decide independently how much to draw at each load point, and a centralized system operator orchestrates the production at each of the generators in order to match the supply to the demand in real time within the capacity limits of each line and transformer, and within emissions limits set for each generator. this constrained optimization problem is relatively tractable if the transmission and distribution infrastructure is sufciently overprovisioned. but, as more of its capacity is demanded, the problem becomes substantially more difcult. a network of communicating sensors is overlaid onto the grid to monitor its distributed state, and sophisticated algorithms are used to predict demand, model the ˚ows, schedule generation, and adjust the limited set of control points that are present. thus, the ability to meet increased demand through the physical 18for example, as more power is transferred along a line, more heat is generated, causing the line to stretch, become thinner, and sag. this increases the resistance of the line, causing it to heat further, and increases parasitic losses due to capacitance to the ground, which increases demand. all of these factors contribute to failures, which eliminate portions of the transmission or distribution infrastructure and thereby place potentially excessive demand on remaining portions. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 27infrastructure that exists at any particular time is almost entirely through advances in it.these challenges are further complicated by the changing nature of the load and the broader introduction of distributed generation. unlike purely resistive loads, such as heating elements and incandescent bulbs, complex loads effectively cause a portion of the delivered power (called reactive power) to be returned through the grid to the generator. historically, such ﬁnonunit power factorﬂ loads were predominantly induction motors, which introduce a fairly simple phase shift in the alternating current (ac) waveform. but switching power supplies, such as those used in computers, ˚uorescent bulbs, battery chargers, and electronics direct current (dc) adapters, introduce complex distortions on the ac waveforms. residential gridtie solar installations reverse the ˚ow of electricity within portions of the local distribution tree. and the introduction of electric vehicles potentially introduces high point loads during recharging. many of these new complex loads already possess communications and computations capabilities, and so they could potentially be a vanguard of using it to condition demand in order to be ﬁgood citizensﬂ of the grid.compounding all of these issues still further are the economic structures that impinge on all aspects of generation, delivery, and demand at a range of timescales. on an operational basis, collections of suppliers, consumers, and brokers typically participate in highly volatile wholesale energy markets at various granularities and timescalesša day ahead, an hour ahead, a minute ahead. meanwhile, consumers typically experience relatively stable retail pricing. compounding all of these issues further, utilities and the utility supply industry are still largely incentivized to produce and deliver more energy, not less. economic or other incentives to curb growth are lacking in most parts of the world. a notable exception to this is netmeteringšmechanisms that allow electricity consumers to offset their usage of electricity provided by the grid, and thus to lower their cost, by generating their own electricity onsite, typically through rooftop solar photovoltaic installation. basically, this can be thought of as the meter spinning backward when local generation exceeds local demand. although netmetering is comparatively common, its penetration is modest enough that it can be incorporated as offsetting demand in the neighborhood distribution tree, without appreciable impact on transmission needs. broader, lesstangible incentives include the personal satisfaction of obtaining a zeronet lifestyle, potentially opening paths toward the decoupling of quality of life from energy usage. it has an important role in doing the complex accounting and providing visibility into the consumption and production of otherwise invisible resources.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.28 computing research for sustainabilitycurrent model of loadfollowing supply grid operation predominantly involves orchestrating a portfolio of dispatchable supplies, including baseline (nuclear, coal, and hydroelectric power), intermittent (combinedcycle gas turbine), and peaker (simplecycle natural gas) power plants to supply precisely the realtime power demand across normal variations, spikes, and infrequent peaks in the load. of course, the demand is not specied explicitly, but implicitly in the use of electricity. typically, independent service operators perform dayahead demand prediction for their entire grid, with hourahead and even minutesahead adjustments, to drive scheduling and market mechanisms while providing adequate generation capacity at all specic points in the transmission grid over time. a certain fraction of online capacity is retained as ﬁspinning reserveﬂ and is used to match shortterm changes in demand. an imperfect matching of supply to demand manifests in degraded power quality (such as voltage sags or surges, and frequency variation). challenges include the following: high cost of peak demand. since generation and transmission capabilities must be built out to meet the peak demand, this peak drives overall investment. however, because there is signicant variation in demand, a substantial portion of this investment experiences very low utilization. fundamentally, load following relies on statistical multiplexing of independent loads; even though the individual loads are very bursty, the aggregate of many such loads is relatively smooth and predictable. however, correlations in the loads, such as air conditioning on hot summer afternoons or refrigerator compressor cycles at breaks in superbowl action, generate very large aggregate peak demand. means of power generation with short rampup times tend to have low efciency and high ghg emissions and operating costs. prediction accuracy and market volatility. a mismatch of predicted and actual demand leads to large and rapid ˚uctuations in wholesale energy prices. each new broadbased usage change (for example, the increased uptake of plasma television sets, compact ˚uorescent lamps, electric vehicles, and so on) raises concerns of prediction accuracy. paradoxically, by eliminating waste, energyefciency measures can lead to larger peaktoaverage ratios and potentially lower prediction accuracy, making the grid harder to manage.storage limitations. gridlevel storage exists in the form of pumpedstorage hydroelectricity, compressed air, thermal energy storage, batteries, and a few other possibilities, but storage capacities remain limited. storage is typically expensive, and turnaround efciencies (the energy extracted from storage relative to the amount stored) tend to be low. smallscale battery storage is prevalent but expensive, and the number of computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 29recharge cycles, and hence battery lifetime, is limited. when the effects of manufacturing and the disposal of batteries are taken into account, such storage may have a net negative environmental impact. midscale storage (say, 1 to 100 kilowatthours) is almost nonexistent, although ˚ow batteries and electrolysis/fuel cell options remain in development.19 nondispatchable supplies. most renewable sources of energy, such as wind, solar, and wave, are nondispatchable. that is, they are available only at certain times and in magnitudes determined by various environmental factors; they cannot be summoned on demand. gross features, such as the incident solar radiation over the course of the day or the seasonal patterns in wind, are much more predictable than ne features, such as occlusion due to passing clouds or gusts and lulls, and the latter can cause very rapid changes in supply. much of the growth of power generation in highly industrialized nations in recent years is in renewable supplies. but the penetration of those sources is fundamentally limited in a loadfollowing regime (i.e., one in which power output is adjusted to demand). many smart grid proposals focus on increasing the capacity and sophistication of the transmission system to reduce constraints imposed by transmission in matching supply to demand. these include longdistance lines, in many cases using highvoltage dc, in order to access remote renewable supplies both for increased availability and to obtain geographic decorrelation. within a grid, especially with distributed renewable resources, there may be sufcient supply to serve the load but inadequate capacity to route the power from points of generation to points of use. better prediction, monitoring, and scheduling seek to prevent such bottlenecks. ﬁsmart meters,ﬂ which are currently being rolled out in many regions, provide 15minuteinterval readings, rather than monthly accounting. their use enables more accurate prediction and more effective scheduling as well as introducing incentives, such as timeofuse pricing or critical peak pricing, to nudge the demand toward a more gridfriendly form. these efforts introduce a degree of observability into this complex system and thus open the way to decision making and action. as the it in the grid evolves to embody monitoring, communication, embedded processing, and intelligence at various levels of the grid, it can provide a foundation for an interactive relationship between supply and demand that increases the penetration limit for renewable sources.19for instance, sandia national laboratories just announced the development of a new family of liquid salt electrolytes that could lead to devices that could better incorporate renewable sources of energy on the grid. see, for instance, http://www.sciencecodex.com/sandianationallaboratoriesresearchersndenergystoragesolutionsinmetils86320.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.30 computing research for sustainabilityimplementing a supplyfollowing model the dynamics and economics of grid operation can be fundamentally altered if the demand can be shaped to match available supply and supplychain constraints, such as congestion or outages. this approach is referred to as supply following, in contrast to load following. load following has developed over the past century with a great body of typically centralized, utilityside intelligence to permit consumers to use energy whenever and however they desire; however, supply following typically requires distributed, customerside intelligence in order to manage energy demands while delivering desired services. ﬁdemand managementﬂ is typically taken to mean an explicit modulation of customer demand (for example, thermostat setpoint adjustment, lighting adjustment, production curtailment) by the utility, according to prior arrangement, to ˚atten the duration curve. numerous such measures have been employed for peak shaving and shifting load into valleys, but adoption tends to be low. prevalent utilitydriven measures involve automated voluntary adjustment to thermostat set points, especially for cooling during hot summer days. many industrydriven proposals emphasize smart appliances, including dishwashers, dryers, and ice makers that can defer operation until less costly times of use. plugin hybrid or fully electric vehicles are seen as presenting a prime opportunity for the programming of demand. while naïve charging could be potentially destabilizing to the grid or even cause local, aging distribution equipment to fail (for example, if multiple electric vehicles charge on the same block), welltimed charging could provide increased stability while relieving petroleum demand.20 dynamic variable pricing (as opposed to set schedules) introduces nancial incentives for end users to shift demand so that the overall demand is more easily met. typically, residential demand is shifted into nights and weekends away from industrial demand. often the schedules are complex and difcult for individual users to keep track of. charging for power according to more sophisticated pricing schedules requires more sophisticated metering, along with usable and understandable 20there are also many proposals for utilizing electric vehicle batteries as grid storage, providing power back into the grid when demand is high. while certainly attractive in concept, such usage modes present pragmatic challenges. batteries for vehicles are optimized to be extremely light, dense, and collisionresistant, with high power density. the number of recharge cycles of the battery that could occur before a costly battery replacement is a fundamental constraint. utilizing this precious resource to improve the management of utility capital investment and potentially having driving range unexpectedly curtailed represents adoption challenges, whereas scheduling overnight charging ˚attens the duration curve without such impediments. stationary bulk energy storage need not obtain the very high level of energy density and power density demanded for the mobile case; it can potentially be designed instead for large recharge capacity and high turnaround efciency.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 31controls. the modern advanced metering infrastructure rollout aims to achieve some of these possibilities.21peak pricing extends dynamic variable pricing to include aspects of a particular consumer™s demand and to take into account how hard it is to meet that demand. in many regions, major industrial customers are on timeofuse, peakbased pricing schedules, in which the product of usage and peak demand determines the cost over a past interval. this creates an incentive for individual users to limit their peak as well as their overall demand. finally, an approach known as demand response typically involves load shedding in response to a critical peakpricing notication event from the utility. manual demand response has been used in many nonresidential markets for many years. automatic demand response couples an internet notication event to a preprogrammed set of demandmitigation responses and thus involves considerably greater it. signicant information processing, modeling, and control issues need to be addressed to carry out demandresponse issues in large commercial buildings. signicant humancomputer interaction issues need to be addressed to realize fully the potential of this infrastructure, particularly for residential use. for example, if new electric water heaters are equipped with an automatic demandresponse facility but the default setting is to ignore notications, then without a good interfacešand consumer educationšthe likely result is that the default setting will not be touched and there will be no benet. however, if the default setting is to respond to a notication by waiting until late at night to turn the heater on, when electricity demand is lower, one can anticipate large numbers of consumers wondering why their hot water systems seem to run out of hot water at unexpected times.peak energy reduction is extremely important for reducing the capital investment in generation and transmission assets and in reducing risk in wholesale markets. also, peak energy has the greatest ghg emissions per unit of electric power because it is generated by lessefcient plants with shorter rampup times. however, reducing peak energy has limited impact on reducing the overall energy demand or impact on climate, which are dominated by nonpeak demand. reducing overall demand and reducing the impact on climate require much broader efciency and reduction measures. in some cases, lowcarbon renewable generationšfor example, summer solar productionšaligns well with peak demand; in other cases, such as relying on the prevalence of nighttime wind, it does not.21for more information on the deployment of advanced metering technologies, see national energy technology laboratory, advanced metering infrastructure: netl modern grid strategy (2008). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.32 computing research for sustainabilityaccounting for externalized costs another challenge to developing sustainable electric grids has to do with economic incentives and externalities. various approaches have been articulated, including a carbon tax, fee and dividend models, and socalled capandtrade mechanisms (placing a cap on emissions but providing ˚exibility with mechanisms such as tradable permits). to truly represent the cost of externalities, any of these would require dramatically more precise accounting for environmental costs throughout the energy supply chain. in principle these offer a common metric around which optimization measures at all tiers can be integrated. today, under a utilitycentric approach, crude weightings of the energy blend appear to sufce. if a smarter grid were deployed, the task of accounting for all aspects of lifecycle costs would introduce tremendous it challenges. the same would be true if, for instance, end users were to access information about the realtime mix in the blend to enable them to make more informed decisions about when to consume energy (assuming the presence of signicant penetration of noncarbon supply). consideration of computer security should be integral to work on the smart grid. as just one example of the security risks, an attack that injected malicious code into smart electrical energy control systems in millions of homes might be used to manipulate demand and prices, or just to create chaos by turning on or shutting down large numbers of appliances unnecessarily. there are also legitimate potential privacy concerns with such control systems that will need to be addressed in ways that are both usable and technically sound.approaches to a more sustainable electric grida forwardlooking sustainable grid scenario presents a fundamentally more cooperative interaction between demand and supply and fundamentally greater transparency22 throughout the energy supply chain, with the goal of achieving deep reduction in demand and deep penetration of renewables in the supply blend.23 22for this particular goal, transparency is required for technical reasons: that is, to support a more cooperative interaction between demand and supply. however, transparency is also essential for reasons of trust, accountability, and fairness, to avoid the potential for enronstyle market manipulations to be multiplied many times with the new grid technologies.23today, major industrial customers with substantial inhouse generation are able to take advantage of the volatility of the wholesale market by running inhouse generation when prices are high, tailoring its use to meet business goals, and shutting it down completely when prices ﬁgo negativeﬂšwhich they do at times in the u.s. midwest grid, in the european union, and elsewherešthereby getting paid to consume power.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 33the introduction of storage aims to decouple generation and consumption, enabling either to take place at times that are most effective. (but even with hypothetical vast storage capacities, inefciencies in storing and generating electricity mean that complete decoupling will not be possible.) equally important is the ability to coordinate loads, often through the utilization of nonelectrical forms of energy storage such as thermal, but also often exploiting ˚exibility in the actual task. in short, opportunities to improve the sustainability of the electric grid can be clustered as follows: (1) sculpt demand to match the supply of renewable power more closely; when abundant renewable power is available, use it for shiftable power needs (such as ice makers, hot water, dishwashers, electric car charging); (2) sculpt demand to smooth out spikes so that less highspeed dispatchable supply is needed; (3) reduce total demand by improved efciency in transmission and use; and (4) apply instrumentation and modeling to measure carbon emissions as part of carbon pricing and capping policies.electricity is currently the most invisible of utilitysupplied resources. to make progress on the opportunities available will require new forms of visibility, including visibility with respect to price and ghg emissions, consumption, and performance. it can contribute in key ways: for example, pervasive instrumentation, monitoring, and analysis enable visibility into electric power consumption and resulting load performance. increased visibility is an important component of developing integrated home or building energymanagement systems that can make wise decisions about how to shift energy use. these systems need ˚exible user interfaces and sensing systems so that they can receive information about when it is appropriate to, say, delay electric car charging, heating up a building, and so on. for example, such systems could be integrated with users™ calendars as well as connected to pricing and other generationside signals (e.g., sun and wind forecasts). research is needed on user interfaces, predictive models of user and appliance behavior, and perhaps auction and pricing mechanisms.integrated energymanagement systems could also address spiking, by heating and cooling buildings more gradually or by making offsetting powerconsumption choices. making the effects of such choices visible to the user (e.g., by clarifying when the building will achieve the desired temperature, when it will be possible to turn on a particular machine, etc.) will be critical for user acceptance. price mechanisms (e.g., charging more for sudden changes) could be explored as well.it research is needed for developing methods for sensing, modeling, and intelligent control of buildings. most ofce buildings, for instance, exhibit chronic poor performance (some parts of the building are too hot, others too cold; some parts are poorly ventilated, others too breezy). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.34 computing research for sustainabilityimproved modeling at design time and during operations has promise of reducing such problems and saving energy.24 there is a signicant role for it to play in making opportunities for waste reduction manifest and in automating its reduction in buildings and also throughout the grid as a whole. the role of information technology and computer science in achieving the smart electric gridinformation and data management are essential to making progress toward a smarter, more sustainable electric grid, as discussed above. computer science research and methodological approaches will be needed at all levels to address the broad systems challenges presented by the smart grid. initial forays into both research and applications ﬁwinsﬂ in this area include energy efciency and smart minigrid and distributed energy management,25 energyefciency planning and building management,26 and the integration of smart grids and smart electric vehicle planning and operation.27 in many of these areas, savings of onethird to onehalf in terms of overall energy consumption, with improved service and signicant environmental gains, are possible. in many of these areas, a critical step is that of envisioning how the energy system could function if greater information and realtime data analysis were possible as embedded components of the system. this would require greater attention to integration of sensor technology with energy, transport, and building systems; to sensor data management; and to the role of distributed computing in processing far greater ˚ows of information (and of forecasted performance and outcomes) than is typically the case today.user interfaces are needed that make it straightforward for people to express preferences regarding aspects such as prices, comfort, timing, and ﬁgreennessﬂ of their power mix. these preferences could be very complex and difcult to capture, requiring visualization techniques, 24national research council, achieving highperformance federal facilities: strategies and approaches for transformational change, washington, d.c.: the national academies press (2011).25c. casillas and d.m. kammen, the energypovertyclimate nexus, science 330:11811182 (2010).26g. crabtree l. glicksman, d. goldstein, d. goldston, d. greene, d.m. kammen, m. levine, m. lubell, b. richter, m. savitz, and d. sperling, energy future: think efciencyšhow america can look within to achieve energy security and reduce global warming, report of the american physical society on the potential for energy efciency in a lowcarbon society, american physical society (2008).27l. schewel and d.m. kammen, smart transportation: synergizing electried vehicles and mobile information systems, environment: science and policy for sustainability 52(5): 2435 (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 35increased understanding of human behavior with regard to energy, pervasive interfaces, and so on. information technologies may prove useful in encouraging energy consumers to shift their consumption patterns to offpeak hours, when consumption is generally more stable and comes from more sustainable sources of energy generation. in order to identify specic customers (with shiftable consumption patterns) to target with timeofuse rates, utilities could use more sophisticated predictive analysis through statistics. information dispersal, social networking, and marketing through the internet are other avenues that utilities are looking into, and with which computer science may be able to help. additionally, with timeofuse rates, consumption data are increased signicantly for each customer, and the complexity of tariffs and calculations with multiple tiers becomes an issue with which better analytical software could help.28 improved statistical models and database management would be invaluable additions to the capabilities of utilities all over the country.improved modeling and analytical tools would help with demand forecasting that takes into account the adaptive nature of the demands (e.g., to answer questions such as: how far will people be willing to timeshift demand this thursday?). with the help of predictive analysis and weather data, utilities could use estimated capacity to improve their consumption forecasts, which would signicantly improve their cost structure.more generally, economic mechanism design tools for designing pricing within a controlled system will be needed. sophisticated statistical models could help validate the models through hypothesis testing. a goal might be to bring factories with energyproduction capacity into the supply chain to supplement peakhour supply, assuming that the ghg output was not made worse. this goal would also require creating an economic situation that is agreeable to both the utilities and the owners of cogeneration plants. calculating the cost and benet from both the utilities™ perspective and the cogenerators™ perspective, optimizing the best rate scheme to encourage sellback, and factoring in transmission losses and efciency present a complicated and interesting optimization problem that could be greatly aided with the use of sophisticated decision analysis tools and statistical models. looking further ahead, if appropriate cs research is undertaken, the ability to mitigate the intermittency of renewables through computational approaches will be greatly enhanced. these resources could be made more dispatchable without the need for 1:1 matching of renewables and 28shwetak patel, university of washington, described a technology to monitor inhome electricity consumption at the committee™s workshop on innovation in computing and information technology for sustainability. see appendix a for a summary of the workshop. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.36 computing research for sustainabilitytraditional sources or storage backup and optimized infrastructure investment. the success of the smart grid will, in part, be about the ability of the industry to shift from its current static operational, management, and planning models to a model that is increasingly dynamicša scenario that cs research and it are well poised to address. whole new situational awareness tools are required to observe, monitor, and control the smart grid. the computational burden of doing this is signicant, and the industry relies almost exclusively on vendors to supply solutionsšvendors who typically do not invest a great deal in research and development. switching from static balanced optimal power ˚ow to dynamic transient analysis that can be solved in real time and at scale is not achievable today, but this ability will be a requirement for managing the future bidirectional, rapidly changing nature of the smart grid. it and cs approaches will have a fundamental role in aligning the temporal and spatial characteristics of resources and users and in reducing the need for the close alignment between supply and demand. different methods and approaches will be needed for sustainable energy systems in small developing countries, for the microgrid in developed countries, and for a continentalscale energy system. major cs research is required to address these and related challenges. sustainable food systemsagriculture in the united states and other parts of the world over the past century has been characterized by a dramatic increase in productivity, resulting in relatively affordable and available food. some of the driving factors for this increase include the relatively inexpensive availability of fossil fuels and abundant fertilizer and water; concentration and specialization in farm production, including the increased use of automation and robotics in meat processing; the increased mechanization of farming and the availability of new technologies; advances in plant breeding; government programs and subsidies; and the expansion and commercialization of markets. these developments have allowed for food to be produced at unprecedented volumes and have supported signicant population growth.29 the increase in output from agriculture, unlike that in many other industries, has not been associated with a similar increase in inputs. for example, the acreage of cropland used in 2005 was comparable to 29indeed, a recent issue of the economist carried a ﬁdebateﬂ about whether computing was the most signicant technological advance of the 20th century, and the ﬁantiﬂ side, articulated by vaclev smil, argued that the transformation of agriculture enabled by the production of sufcient nitrogen for fertilizer with the haberbosch process of nitrogen xation was much more signicant. see http://www.economist.com/debate/days/view/598. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 37the acreage used in 1910. thus, there has been a tremendous increase in productivity in u.s. agriculture, with more food being produced with signicantly less capital, land, labor, and materials.30however, current agricultural practices pose challenges to the sustainability of the food system, as well as to the broader social, economic, and environmental systems within which they are embedded. much of the focus of agriculture has been on maximizing production to satisfy human food, feed, and ber needs while secondarily considering environmental and societal impacts. there is a growing concern regarding the negative consequences of current trends in agricultural productivity and a concern that these trends cannot continue indenitely. increases in agricultural productivity have spawned hypoxia in coastal and inland waters around the world because of increased concentrations of nitrogen and phosphorus, altering the planet™s biogeochemistry. a sustainable food system will be key to ensuring that the world™s population receives necessary nutrition without contributing additional damage to the environment and society. as with the electric grid, the opportunities for it seem most salient in the systems issues in sustainable agriculture. the recent report of the national research council on sustainable agriculture denes a ﬁsustainable agriculture systemﬂ as one that  (1) satises human food, feed, and ber needs and contributes to biofuel; (2) enhances environmental quality and the resource base; (3) sustains the economic viability of agriculture; and (4) enhances the quality of life of farmers, farmworkers, and society as a whole.31 the rst point naturally requires both sufcient food production and a population sized appropriately for the food that can be produced. the american public health association, in its policy statement on sustainable food systems, builds on these ideas, dening a sustainable food system as one that ﬁprovides healthy food to meet current food needs while maintaining healthy ecosystems that can also provide food for generations to come with minimal negative impact to the environment.ﬂ32 a sustainable food system will need to address simultaneously all four of the objectives listed above rather than optimizing over any individual dimension. a 2012 nrc report of two workshops provides a broad exploration of food security, agriculture, and related sustainability chal30national research council, toward sustainable agricultural systems in the 21st century, washington, d.c.: the national academies press (2010). 31national research council, toward sustainable agricultural systems in the 21st century, washington, d.c.: the national academies press (2010).32american public health association, ﬁtoward a healthy, sustainable food systemﬂ (2007). available at http://www.apha.org/advocacy/policy/policysearch/default.htm?id=1361. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.38 computing research for sustainabilitylenges. it notes that ﬁneither the modern food systems nor the traditional systems assure long term food security for allﬂ and examines availability, access, and utilization as well as barriers to expanding production (without damaging future capacity) and policy, technology, and governance interventions that could help.33 this section brie˚y explores the challenges facing the creation of a sustainable food system that promotes public health and identies potential areas in which it and research in computer science can have an impact.challenges to developing a sustainable food systema few of the many challenges to creating a sustainable global food system are highlighted below. they include increasing demand, environmental impacts, and public health impacts. increasing demand the u.s. population increased by approximately 9 percent from 2000 to 2009, and total consumption of food has increased in parallel. in addition to the increase in the total amount of food consumed, the composition of the nation™s diet has shifted toward an increased consumption of meat beyond levels recommended by federal guidelines. since 1960, there has been an increase in the use of grains for livestock feed, and so a shift toward meat consumption produces a greater strain on the agricultural system.34 rising incomes in emerging markets such as mexico and china have produced greater demands on u.s. agricultural exports, and such demand is likely to increase in the future. the emerging biofuels and bioenergy elds have also placed further demands on agriculture to provide materials for alternative energy production. in 2007 and 2008, 23 percent of the u.s. corn harvest and 17 percent of the soybean harvest were used to produce ethanol and biodiesel. the various demands on agriculture today increasingly strain the natural resources of land and water that are required to satisfy global food needs.environmental impacts agriculture is a contributor to greenhouse gas (primarily methane and nitrous oxide) emissions through various soilmanagement activities and livestock operations. through biomass burning and windblown dust, farms also serve as sources of air pollutants, such as particulate matter. conventional industrial agriculture applies 33national research council, a sustainability challenge: food security for all: report of two workshops, washington d.c.: the national academies press (2012), p. 2.34food and agriculture organization of the united nation, ﬁlivestock™s long shadowﬂ (2006). available at http://www.fao.org/docrep/010/a0701e/a0701e00.htm.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 39large amounts of nitrogenbased fertilizers in order to replenish nutrients in the soil and substantial quantities of herbicides and pesticides to control both plant and insect pests. the increased use of such fertilizers and pesticides leads to runoff during ˚oods or heavy rains, which pollutes rivers, streams, and bays. tilling of the soil contributes to land degradation, and farming in dry regions consumes water resources for irrigation. it is estimated that in the united states, 80 percent of available potable water is used for agricultural irrigation, and overdrafting of underground aquifers (when the rate of extraction exceeds the rate of natural recharge) threatens agricultural activity in a large swath of the u.s. midwest.35 public health impacts in addition to the environmental impacts of modern agriculture, there are public health impacts from current agricultural practices. air and water pollution from farms damages not just the environment but also the health of the individuals living and working in or near the damaged environment. factory farming of food animals has also increased the risk of foodborne pathogens, in part due to the close quarters of animals kept in conned animal feeding operations (cafos). the interplay between supply and demand of highly processed foods has health implications as well, even as debate continues about the specic mechanisms and contributors to diseases such as diabetes and heart disease. approaches to developing sustainable food systemscreating a more sustainable global food system will not be easy. this section outlines several approaches, none of which is sufcient alone, although each contributes to increased sustainability and could benet from the contributions of computer science and it. the approaches include taking a systems view; developing methods for measuring the costs, benets, and impacts of different agricultural systems; the use of precision agriculture; information for informed consumption; and the development of social networks for local food sourcing. taking a systems view overall, there is a need to take a systems view of agriculture (much like taking a systems view in other areas of sustainability, such as the smart grid, described previously) in order to understand and analyze the total impact of agriculture on the environment, economy, and society. a systems perspective is relevant at all points in the sys35national research council, toward sustainable agricultural systems in the 21st century, washington, d.c.: the national academies press (2010). also see http://ga.water.usgs.gov/edu/wuir.html.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.40 computing research for sustainabilitytem. at the farm itself, individual farms can combine crop and livestock production so as to reduce the need for synthetic fertilizers. traditional agriculture has focused on controlling the farm ecosystem by simplifying it (e.g., through monoculture) and applying external inputs (e.g., water, fertilizer, pesticides, and herbicides). the systems view seeks to reduce or eliminate those external inputs (and their associated carbon and pollution emissions) by, for instance, designing and managing a more complex ecosystem involving a larger variety of species.36 a systems view can provide guidance on how to develop ways to make the system as a whole more sustainable. for instance, rather than viewing a farm (or farms) in isolation and having inputs and outputs, one could view the entire cycle of food production and consumption as providing natural resources for growing food that is consumed by people. this cycle includes land, water, and other farm inputs, crops, transportation, processing, retailing, consumption, and recycling or waste. at each stage, there are effects on the environment and society; thus it is important to consider the connections between farms, the ecosystem, and communities (local, regional, and global). an important role for it is to enable farmers to manage these more complex systems through mechanisms such as sensing, predictive modeling, and precision machinery.methodology for measuring costs, benets, and impacts there is a substantial need for the development of methods and tools to measure the total costs, benets, and impacts of different agricultural systems. for example, comparative studies of ghg emissions from different eldmanagement practices for animal wastes would allow for better quantication of the environmental impacts of agricultural systems and, just as with the smart grid scenario, allow for prices to re˚ect costs and value better. in general, evaluating different farming systems will require assessing how each system balances productivity and efciency with environmental and societal impacts and will require analyzing the behavior of complex highdimensional and highly interactive systems. in addition to the technical challenges of developing such measures, there are also signicant challenges in helping them to be seen as accurate and legitimate by both producers and consumers. novel visualization techniques, explanation facilities, interactive simulations, and other techniques may help here.36the control of pests provides an example of moving from a traditional view to a systems view. the traditional way of controlling pests is to apply pesticides, which requires little knowledge of the pests. a more sustainable approach may be to use benign control measures, which require an understanding of the pest™s life cycle and its interaction with other parts of the farm ecosystem.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 41precision agriculture the use of information and computing technology in agriculture has greatly increased in the past 50 years. it has allowed farmers to assess variation within elds and to generally maintain or increase yields while reducing inputs (particularly water, nutrient, and pesticide application). technologies used here include the global positioning system, realtime kinematics, and geographic information systems, especially satellites. it already plays a substantial role in this area and will continue to play a critical role in the future. there is also a connection with methodologies for measuring costs and benets: if the cost of water for agricultural use re˚ects its true cost, there may be much more incentive to use precision agriculture to reduce the consumption of water.information for informed consumption increasing the information available to individuals regarding the nature of the food that they buy and how it was produced can assist them in making sustainable choices about food. already there is an emerging market for foods that have been produced in a sustainable manner.37 an important method by which such information is currently conveyed is through the development of standards, certications, or other ecolabel programs. each of these programs outlines a set of criteria for food producers and distributors in an effort to address various environmental, sustainability, or health goals.38 perhaps the most wellestablished food standard in the united states is the organic agriculture certication, which focuses primarily on health and environmental goals and does not address the broader goals of sustainable agriculture. foodlabeling requirements in the united states provide some information, for example, on the country of origin of meats and fruits, but general information about sustainability and food transport (which has implications for fossil fuel usage) is not available. current standards and certications are typically communicated using logos or other print labeling on food packaging. however, potential exists for providing much richer information regarding sustainability and information to help consumers sort through the proliferation of ecolabels in the market. the wider adoption of smartphones may allow for easier dissemination of this information, as users could search for sustainability information at the point of purchase. one example of empowering individuals with information is the monterey bay aquarium™s seafood watch guide39 that 37national research council, toward sustainable agricultural systems in the 21st century, washington, d.c: the national academies press (2010). chapter 6.38ecolabel index. available at http://www.ecolabelindex.com/.39the monterey bay aquarium™s seafood watch guide is available at http://www.montereybayaquarium.org/cr/seafoodwatch.aspx. the guide provides a list computing research for sustainabilitycopyright national academy of sciences. all rights reserved.42 computing research for sustainabilityprovides detailed and uptodate information about what types of seafood are caught or farmed in a sustainable manner. in addition to a web site, the guide also is available as a smartphone application so that consumers can have portable access to its vast database. social networks for local food sourcing it could be used to increase networking among individuals and organizations, encouraging locally and regionally sourced food consumption. communitysupported agriculture (csa) already benets from the organizing power of online networks to distribute relevant information, create markets for local farm producers, make it easier to place orders, and help connect consumers with local food. generally, it could be used to help make a more effective market for local foods.40 beyond efciency, there is little argument that humans have emotional connections to food; techniques to strengthen the farmer/consumer connection could also be valuable. it could also be useful for gathering information on regional surpluses or decits, allowing fresh foods to be allocated to areas where they are most needed and diminishing reliance on processed foods with longer shelf lives.the role of information technology and computer  science in achieving a sustainable food systemas with the smart electric grid, information and data management are essential to making progress toward a smarter, more sustainable, global food system. computer science research and methodological approaches will be needed at all levels to address the broad systems challengesšencompassing the environment and ecosystems, social and economic factors, and personal and organizational behaviorsšaffecting food production, distribution, and consumption. three critical areas are described brie˚y below: information integration; education and reform; and systems modeling, prediction, and optimization. information integration information integration can help individuals and organizations on both the demand and the supply side of the food system of sustainable choices and the least sustainable choice of sh to consume. legal sea foods has questioned the value of the guide. see http://www.nrn.com/article/legalseafoodsdeesaquarium%e2%80%99swatchlist.40as one example of an effort in this area, see http://www.urbaninformatics.net/projects/food/ regarding a project exploring ﬁubiquitous technology for sustainable food culture in the city.ﬂ another example is locallygrown.net, which seeks to provide an online infrastructure and organizational capacity for local farmers™ markets and csas, particularly smallscale growers with few or no employees. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 43make sustainable choices regarding the production and consumption of food. providing consumers with information about the sustainability of food production, in addition to other aspects of sustainable food systems such as health and environmental impacts, will require the sharing and integration of information across producer and consumer platforms. developing and optimizing the infrastructure and architecture for such information integration will be an important contribution of it. more generally, areas in which it could be of substantial help include the creation of databases of information and the maintenance of the currency of that information as well as connecting farmers and consumers through social networks and the internet. the development of analytical software for optimizing sustainable food purchasing choices for both consumers and largescale purchasers (such as supermarkets) is another rich area of it contributions.education and reform tools are needed to help both consumers and policy makers understand the tradeoffs posed by the global food system and to navigate those tradeoffs toward increased sustainability. the role of it here is not just in providing information on availability and techniques, but also in allowing access to communities of individuals with similar interests. there are numerous opportunities to effect change through demandside modication of food consumption.41 efforts to encourage the preparation and even the growing of food at home could have a signicant impact on overall distribution needs. increasing the availability of fresh, healthful foods in certain communities (e.g. lowincome communities) would also help. additional challenges exist in predicting the information that purchasers and individuals will need, displaying information that will encourage more sustainable consumption habits, educating consumers about sustainable choices without overwhelming them, and so on. systems modeling, prediction, and optimization improving the efciency of the food system in general will require modeling a complex and interactive system and methods for predicting food shortages and surpluses in order to help ensure that food is available in different regions at 41andrea grimes, martin bednar, jay david bolter, and rebecca e. grinter, eatwell: sharing nutritionrelated memories in a lowincome community, proceedings of the 2008 acm conference on computer supported cooperative work (2008); andrea grimes and richard harper, celebratory technology: new directions for food research, proceedings of the twentysixth annual sigchi conference on human factors in computing systems (2008); and t. aleahmad, a. balakrishnan, j. wong, s. fussel, and s. kiesler, fishing for sustainability: the effects of indirect and direct persuasion, extended abstracts from conference on human factors in computing systems (2008).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.44 computing research for sustainabilityreasonable costs. in addition, the transportation of food to various markets could be optimized according to sustainability cost functions if a comprehensive model of the food system were available. given a model of the food system, one could also assess the costs and benets of various agricultural and farming strategies, the design of food sheds, and distribution systems.sustainable and resilient infrastructuresthe resilience of the nation™s societal and physical infrastructures poses deep and crosscutting sustainability challenges, especially when one takes a broad view of sustainability that encompasses economic and social issues. for example, although transportation is a major source of ghg emissions and urban sprawl consumes open space and farmland, competing incentives in the realm of societal sustainability include the need for workers to commute to jobs, for people to have access to whole foods, and for available space that allow businesses to change and adapt over time. contributing to the challenges of resilience of societal and physical infrastructures is the increasing risk of natural and humanmade disasters. sustainability concerns related to climate change, resource consumption, and land use are closely linked to natural and humanmade disasters.42 there will inevitably be more disasters, and enhancing society™s resilience and ability to cope with them will contribute to sustainability. even apart from climate and resource consumption, the sheer magnitude of the world™s population means that crises, when they happen, will be at larger scale. this section examines the sustainability challenges around planning and modeling infrastructure and anticipating and responding to increasing disasters and the ways in which information technology can assist with developing sustainable and resilient infrastructures. the section focuses on cities as centers of large human populations, but many of the issues discussed apply generally. challenges to developing more sustainable and resilient infrastructurescities are highly complex, evolving systems, involving the interaction of numerous people and processes, as well as natural and built infrastructure, legal and regulatory frameworks, and much else. the diversity of use within the systems adds another level of complexity. each building™s use and design are unique within a particular city; each city™s infrastructure has distinctive characteristics. the heterogeneity of structures within any 42national research council, adapting to the impacts of climate change, washington, d.c.: the national academies press (2010). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 45given city poses challengesšand because cities are often quite different from one another, the extrapolation of lessons learned is also challenging. just as cities are increasingly complicated, the challenges of coping with disasters are compounded by their heterogeneity. there are acute natural disasters (such as hurricanes, earthquakes, and ˚oods), acute engineering and other humanmade disasters (such as the 2010 deepwater horizon gulf oil spill), as well as ﬁslowﬂ or chronic disasters (such as droughts, refugee crises, and rising sea levels). in addition, whether acute or chronic, there are the ongoing processes of cleanup and recovery from disasters. many situations are best described as combinations of natural and humanmade disasters with both acute and chronic time frames.43 the problems associated with the resilience of societal and physical infrastructures have complicated time lines. for instance, urban, suburban, and rural areas are developed over long periods of time and are almost constantly being shifted into new uses. these long time lines create legacy systems that may not be compatible with newer systems or that could be costly to update. planning becomes increasingly complicated as new infrastructure, often costly and timeconsuming to implement, must anticipate the future needs of a particular area. similarly, the time needed and the ability to prepare an area for potential emergencies vary and depend not just on characteristics of the area, but also on the anticipated types of disasters and crises. some disasters, like hurricanes, come with at least some advance warning, and others, like earthquakes, strike at unpredictable times. some events cause intense damage only in limited areas, while others affect enormous geographical regions. an additional challenge is that the frequency of disastrous events is such that recovery after one event (itself a major sustainability challenge) may well not be complete before the next major disaster strikesšeither in the same region, as happened with hurricane katrina and the deepwater horizon oil spill, or different regions competing for resources and attention, as in the earthquake in haiti in 2010 that was followed by severe ˚ooding in pakistan. the role of information technology in  developing sustainable and resilient infrastructuresinformation and communications technologies offer a range of methodologies, approaches, applications, and tools that will be integral to the 43author bruce sterling coined the term ﬁwexelblat disasterﬂ to refer to disasters caused by the interaction of natural disasters and failures of humanengineered technology. the 2011 earthquake and tsunami that destroyed a nuclear power plant in japan leading to core meltdowns is an example. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.46 computing research for sustainabilitydevelopment of sustainable and resilient infrastructure and to coping with disasters when they occur. several such technologies are highlighted below.modeling and simulation urban regions can be modeled with varying degrees of spatial detail and behavioral realism. for a highly disaggregate, behaviorally realistic model,44 the process of modeling a new region is timeconsuming, often requiring personyears of effort. a major factor is difculties in collecting and readying the needed data. further, problems of missing datašcommon in u.s. metropolitan regions and even more so in developing countriesšmake the task much more challenging. modeling the development of cities over periods of 20 or more years, under different alternatives, can provide important information to inform public deliberation and debate about alternate plans and possible futures. transportation modeling, and more comprehensively integrated modeling of urban land use, transportation, and environmental impacts, have a substantial history and are in operational use in many regions. nevertheless, there are major limitations in current knowledge, and new research is needed to address the coming challenges adequately. in addition to the scientic challenges of the modeling itself, it is important to consider how the modeling work ts into the larger political and organizational process of making major decisions (often a contentious process), and to shape the technology to respond to these contextual challenges. turning from simulations of longterm development to immediate support for coping with disasters: during a disaster copious amounts of information can be collected; however, more does not always mean better or more helpful information.45 sorting out how to manage and use it capabilities at hand most effectively and, perhaps even more importantly, the vast amounts of data that can be made available by those capabilities, is a nontrivial exercise.46,47 44for example, urbansim (http://www.urbansim.org), currently the most widely employed land use model in the united states.45bruce lindsay, social media and disasters: current uses, future options, and policy considerations, congressional research service (2010). available at http://www.fas.org/sgp/crs/homesec/r41987.pdf.46see ﬁdisaster relief 2.0: the future of information sharing in humanitarian emergencies,ﬂ available at http://www.unocha.org/topstories/allstories/disasterrelief20futureinformationsharinghumanitarianemergencies, for an early assessment of crowdsourcing information and data ˚ows in a humanitarian crisis. in this case the haiti earthquake of 2010 was a primary example. 47dan reed, vice president of microsoft research, discussed some of the computational challenges posed by the 2010 gulf oil spill, noting that the disaster stemmed from a ﬁcomplex multidisciplinary system with emergent behaviors across a wide range of temporal and spatial computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 47in addition to modeling the effects of current disasters, it offers opportunities for indepth simulation of potential disasters and for individuals to exercise and manage a given organization™s response to a crisis to hone and rene their skills and approach. communication it provides the communications capabilities before, during, and after a crisis for coordinating activities and for delivering alerts and warnings to affected populations. it provides critical capabilities for the other phases of crisis response as well, such as modeling and simulation to predict likely consequences or to contribute to the understanding of the effectiveness of particular mitigation measures. as discussed in a 2007 nrc report, it provides capabilities that can help people make better sense of information, grasp the dynamic realities of a disaster more clearly, and help them formulate better decisions more quickly. it provides the tools to capture knowledge and share it with disaster management professionals and the public. it can help keep better track of the myriad details involved in all phases of disaster management.48the role of information technology and computer science research in developing sustainable infrastructure and fostering resilienceadvances will be needed in it and computer science research and methodological approaches to enable better simulations and better understanding of the uncertainties associated with achieving more sustainable development that is also more resilient in the face of disaster. advances are also needed in the areas of encouraging citizen participation, developing indicators of resilience and future outcomes, and improving it infrastructures themselves. performance running a simulation for a highend, behaviorally realistic model for a major metropolitan region is a slow process, currently often requiring days, even on today™s fast computers. similarly, the process of constructing a new scenario (i.e., a package of infrastructure improvements, zoning changes, tax incentives, and perhaps such things as tolling scales.ﬂ he described some of the challenges in modeling such a system: ﬁwe lack the software engineering and programming methodologies to assemble, test and verify an integrated solution . . . the computational demands of an integrated, fully multidisciplinary, parametric simulation study of the oil spill and its effects would make accurate climate modeling seem like child™s play on an abacus by comparison.ﬂ dan reed, lessons from the gulf of mexico (2010), available at http://www.hpcdan.org/reedsruminations/2010/08/lessonsfromthegulfofmexico.html.48national research council, improving disaster management: the role of it in mitigation, preparedness, response, and recovery, washington, d.c.: the national academies press (2007).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.48 computing research for sustainabilityor congestion pricing) can require months of work by experts in transportation, land use modeling, and other disciplines. creating far more efcient algorithms for modeling systems that are increasingly complex presents an important challenge. one natural approach is parallelizing the algorithms. in a number of cases this is quite feasible: for example, when modeling residential location choice (where will people decide to live, given characteristics both of the household and the possible dwellings), one can use massive parallelism, with each household making its decisions independently. one must then undo some assignments if two households attempt to move into the same place simultaneously (perhaps mirroring what happens in real life with several people all trying to rent or buy the same dwelling). however, new or improved algorithms are likely a richer source of performance gain, which will be important because many of the applications envisioned require huge performance increases (for example, using a simulation in real time in a meeting, or running a simulation many, many times to compute information about uncertainty). the precomputing of key scenarios and interpolating among the results (when the changes are smooth rather than abrupt), rather than computing the results from each scenario from scratch, should also be investigated. in terms of algorithms, one class of new algorithms that should be investigated is multiscale models, in which the simulation is rst run at a relatively coarse grain (e.g., a zonal level), and the results from this are fed to further simulation runs within each zone, and so forth. (see chapter 2 for more on modeling.) in this case the reason for using a multiscale model is performance. heterogeneous models are also relevant for urban simulationšfor example, coupling urbansim (a regionalscale model) with statewide freight mobility models. this could be further optimized by simulating only within zones that have changed signicantly from the prior simulation period or that are of particular policy interest, and otherwise remaining at the coarser level. managing uncertainties urban modeling is rich with uncertainties on many levels, including future population, global economic conditions, the price of energy, the impact of climate change, and many others. there have been some successes in propagating uncertainty through the modeling process and capturing it in the indicators that the system produced,49 but much more needs to be done in terms of both statistical techniques and effective presentation of the results.49hana −evcíková, a. raftery, and p. waddell, assessing uncertainty in urban simulations using bayesian melding, transportation research part b: methodology 4:652659 (2007).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.roles and opportunities for information technology 49citizen participation to date, citizen science (or citizen information gathering) is being used for such activities as open mapping projects, but much of this type of activity has not been integrated with modeling work. harnessing the energies and interests of citizen scientists has strong potential, both as a source of additional data and as an avenue for public participation and the legitimation of the modeling activity. leveraging existing technology (such as mobile applications, cloud services, mapping and location services, microcommunications platforms, social media, and so on) offers numerous opportunities to improve approaches to emergency and disaster management.50 some organizations are experimenting with gathering situational awareness from citizens, and in particular citizen use of social media.51 at the same time, there are signicant challenges with regard to data quality, coverage, and institutional acceptance, among other things. technical approaches here may include reputation systems that let staff at institutions build up condence in particular observers, and ways to correlate data from multiple observers and to detect outliers.during disasters, more attention should be paid to the information and resources held by the public because members of the public collectively have a richer view of a disaster situation, may possess increasingly sophisticated technology to capture and communicate information, and are an important source of volunteers, supplies, and equipment. again, the information provided by the public will not always be correct; further, making full use of it may require considerable changes to existing practices. it is likely that the development of new, automated, and mixedinitiative techniques to manage and process the potential ˚ood of information will be needed. another important factor is how to engage the entire population, given the existence of groups with cultural and language differences and other special needs.indicators of future outcomes simulations already produce indicators of such outcomes as ghg emissions, consumption of open space, and comparative measures of compact versus lowdensity development, all for multiple years and under different scenarios. however, as discussed above, it is also necessary to anticipate disruptions and potentially even disasters, due to climate change, mass movement of refugees, and other 50national research council, public response to alerts and warnings on mobile devices: summary of a workshop on current knowledge and research gaps, washington, d.c.: the national academies press (2011).51sarah vieweg, amanda hughes, kate starbird, and leysia palen, microblogging during two natural hazards events: what twitter may contribute to situational awareness, proceedings of the 2010 acm conference on computer human interaction, pp. 10791088.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.50 computing research for sustainabilityfactors. a research challenge is to develop indicators of community resilience in the face of such events.52 these might include the percentage of electrical energy generated locally (or that could be generated locally if need be), the redundancy of the transportation system and the food supply chain and their ability to cope with a sharp increase in fuel prices or even rationing, the ability to cope with sealevel rise (if relevant), the ability to walk to the most signicant destinations if need be, the availability of food produced nearby, and so forth. these indicators need to be accepted by decision makers and the community to be useful in the political process. more abstract and much more difcult, if not impossible, to incorporate into a predictive model (but nevertheless important) are the civic capital and connectedness of the community.it infrastructure improvements large disasters upset physical infrastructure, such as the electric grid, transportation, and health carešas well as it systems. it infrastructures themselves need to be more resilient; it can also improve the survivability and can speed the recovery of other infrastructure by providing better information about the status of systems and advance warning of impending failures. finally, it can facilitate the continuity of disrupted societal functions by providing new tools for reconnecting families, friends, organizations, and communities.conclusionit and computer science could have a major impact in a wide diversity of sustainability challenges. the examples above illustrate some of the efforts that are needed. individual problems are highly multidimensional, requiring innovation in different areas of computing as well as deep domain knowledge. finding: although sustainability covers a broad range of domains, most sustainability issues share challenges of architecture, scale, heterogeneity, interconnection, optimization, and human interaction with systems, each of which is also a problem central to cs research. the next chapter explores more specically the potential for computing and it research and innovation to help address these challenges. 52an example of this is the climate change habitability index. for a description, see yue pan, chit meng cheong, and eli blevis, the climate change habitability index, interactions 17(6):2933 (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.2elements of a computer science research agenda for sustainabilitythe discussion of sustainability challenges in chapter 1 shows that there are numerous opportunities for information technology (it) to have an impact on these global challenges. a chief goal of computer science (cs) in sustainability can be viewed as that of informing, supporting, facilitating, and sometimes automating decision makingšdecision making which leads to actions that will have signicant impacts on achieving sustainability objectives. the committee uses the term ﬁdecision makingﬂ in a broad sensešencompassing individual behaviors, organizational activities, and policy making. informed decisions and their associated actions are at the root of all of these activities. a key to enabling informationdriven decision making is to establish models and feed them with measurement data. various algorithmic approaches, such as optimization or triggers, can be used to support and automate decisions and to drive action. sensingšthat is, taking and collecting measurementsšis a core component of this approach. in many cases, models are established on the basis of previous work in the various natural sciences. however, in many cases such models have yet to be developed, or existing models are insufcient to support decision making and need to be rened. to discover models, multiple dimensions of data need to be analyzed, either for the testing of a hypothesis or the establishing of a hypothesis through the identication of relationships among various dimensions of measured data. dataanalysis and datamining toolsšsome existing and some to be developedšcan assist with this task.51computing research for sustainabilitycopyright national academy of sciences. all rights reserved.52 computing research for sustainabilityonce a model is established, ﬁwhatifﬂ scenarios can be simulated, evaluated, and used as input for decision making. modeling and simulation tools vary widely, from spreadsheets to highly sophisticated modeling environments. when a model reaches a certain maturity and trust level, algorithms, such as optimizations or triggers, can be deployed to automate the decision making if automation is appropriate (for example, in terms of actuation). alternatively, information can be distilled and presented in visual, interactive, or otherwise usable ways so that other agentsšindividuals, organizations and businesses, and policy makers and governmentsšcan deliberate, coordinate, and ultimately make appropriate, betteroptimized choices and, ultimately, actions. all of the steps described above must be done in an iterative fashion. given that most sustainability challenges involve complex, interacting systems of systems undergoing constant change, all aspects of sensing, modeling, and action need to be rened, revised, or transformed as new information and deeper understandings are gained. a strong approach is to deploy technology in the eld using reasonably well understood techniques to explore the space and to map where there are gaps needing work. existing data and models then help provide context for developing qualitatively new techniques and technologies for even better solutions. finding: enabling and informing actions and decision making by both machines and humans are key components of what cs and it contribute to sustainability objectives, and they demand advances in a number of topics related to humancomputer interaction. such topics include the presentation of complex and uncertain information in useful, actionable ways; the improvement of interfaces for interacting with very complex systems; and ongoing advances in understanding how such systems interact with individuals, organizations, and existing practices. many aspects of computer science and computer science research are relevant to these challenges. in this chapter, the committee describes four broad research areas, listed below, that can be viewed as organizing themes for research programs and that have the potential for signicant positive impact on sustainability. the list is not prioritized. efforts in all of the areas will be needed, often in tandem. measurement and instrumentation; informationintensive systems; analysis, modeling, simulation, and optimization; and humancentered systems. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  53for each area, examples of research problems focused on sustainability opportunities are given. the discussions do not provide a comprehensive list of problems to be solved, but do provide exemplars of the type of work that both advances computer science and has the potential to advance sustainability objectives signicantly. in examining opportunities for research in cs and sustainability, questions that one should attempt to answer include these: what is the potential impact for sustainability? what is the level of cs innovation needed to make meaningful progress? as discussed in chapter 1, complete solutions to global sustainability challenges will require deep economic, political, and cultural changes. with regard to those changes, the potential role for cs and it research discussed in this chapter is often indirect, but it is still important. for example, cs research could focus on innovative ways for citizens to deliberate over and to engage with government and with one another about these issues, with the deliberations closely grounded in data and scientic theory. for some critical sustainability challenges, such as the anticipated effects of global population growth, the potential cs research contribution is almost entirely of this indirect character. for instance, there is potential for using the results of modeling and visualization research toward the aim of improved education and better understanding of population and related issues. in addition, advances in it in the areas of remote sensing, network connectivity services, adaptive architectures, and approaches for enhanced health diagnosis and care deliveryšespecially in rural areasšalso have a bearing on population concerns. other contributions from cs and it research toward meeting such challenges could be aimed at developing tools to support thoughtful deliberation, with particular emphasis on encompassing widely differing views and perspectives.the research areas described in this chapter correspond well with the broader topics of measurement, data mining, modeling, control, and humancomputer interaction, which are, of course, wellestablished research areas in computer science. this overlap with established research areas has positive implicationsšin particular, the fact that research communities are already established making it unnecessary to develop entirely new areas of investigation. at the same time, the committee believes that there is real opportunity in these areas for signicant impacts on global sustainability challenges. finding a way to achieve such impacts effectively may require new approaches to these problems and almost certainly new ways of conducting research.in terms of a broad research program, an important question is how to structure a portfolio that spans a range of fundamental questions, pilot efforts, and deployed technologies while maintaining focus on sustainability objectives. for any given research area in the sustainability space, computing research for sustainabilitycopyright national academy of sciences. all rights reserved.54 computing research for sustainabilityefforts can have an impact in a spectrum of ways. first, one can explore the immediate applicability of known techniques: what things do we know how to do already with computational techniques and tools, and how can we immediately apply them to a given sustainability challenge? second, one can seek opportunities to apply known techniques in innovative ways: where are the opportunities in which the straight forward application of a known technique will not work but where it seems promising to transform or translate a known technique into the domain of a particular sustainability challenge? this process tends to transform the techniques themselves into new forms. finally, one can search for the areas in which innovation and the development of fundamentally new computer science techniques, tools, and methodologies are needed to meet sustainability challenges. while endorsing approaches across this spectrum, the committee urges emphasis on solutions that have the potential for signicant impacts and urges the avoidance of simply developing or improving technology for its own sake. the advancing of sustainability objectives is central to the research agenda outlined in this report. as in any solutionoriented research space, there is a tension between solving a substantive domain problem, perhaps creating tools, techniques, and methods that are particularly germane to the domain, and tackling generalized problems, perhaps motivated by the domain, for which solutions advance the broader eld. (chapter 3 discusses this challenge in more detail and provides the committee™s recommendations on structuring research programs and developing research communities in ways that constructively address these issues.) when focusing on the challenges presented in a particular domain, it is often essential that the details are right in order for the work to have meaningful impact. for the work to have broader impact, it must be possible to transcend the details of a particular problem and setting. much of the power in computer science derives from the development of appropriate abstractions that capture essential characteristics, hide unnecessary detail, and permit solutions to subproblems to be composed into solutions to larger problems. a focus on getting the abstraction right for large impact, appropriability, and generalizability is important. simultaneously, it is important to characterize aspects of the solution that are not generalizable. finding: although current technologies can and should be put to immediate use, cs research and it innovation will be critical to meeting sustainability challenges. effectively realizing the potential of cs to address sustainability challenges will require sustained and appropriately structured and tailored investments in cs research. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  55principle: a cs research agenda to address sustainability should incorporate sustained effort in measurement and instrumentation; informationintensive systems; analysis, modeling, simulation, and optimization; and humancentered systems. measurement and instrumentationhistorically, sensors, meters, gauges, and instruments have been deployed and used within the vertically integrated context of a single task or system. for example, a zone thermostat triggers the in˚ow of cold or hot air into specic rooms when the measured air temperature deviates from the target set point by an amount in excess of the guard band; the manifold pressure sensor in a car dictates the engine ignition timing adjustment; the household electric meter is the basis for the monthly utility bill; water temperature, salinity, and turbidity sensors are placed at particular junctures in a river to determine the effects of mixing and runoff; and so on. examples of specic scenarios are innumerable and incredibly diverse, but they have in common the following: the selection of the measurement device, its placement and role in the encompassing system or process, and the interpretation of the readings it produces are all determined a priori, at design time, and the resulting system is essentially closedšsensor readings are not used outside the system.1this situation has changed dramatically over the past couple of decades owing to the following key factors:embedded computing. until the 1990s, the electronics associated with the analogtodigital conversion, the rescaling to engineering units, and the associated storage and the data processing dwarfed the size and cost of the transducer used to convert the physical phenomenon to an electrical signal. consequently, these electronics were shared resources wired to remote sensors. over the past 20 years, digital electronics have shrunk to a small fraction of their former size and cost, have been integrated directly into the sensor or actuator, and have expanded in function to include quite general processing, storage, and communication capabilities. the 1in settings in which the transducer is physically and logically distinct from the enclosing system, typied by the highway addressable remote transducer (hart) for process control and building automation and control networks (bacnet) for building automation, readings are obtained over a standardized protocol, but their interpretation remains entirely determined by the context, placement, and role of the device in the larger process. the use of the information produced by the physical measurement, and hence its semantics, are contained within the enclosing system.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.56 computing research for sustainabilitycongurable, selfcontained nature of modern instrumentation reduces the costs of deployment and enables broader use.informationrich operation. the primary control loop of operational processes (typically represented in manufacturing as plantsensor controlleractuatorplant) is usually augmented with substantial secondary instrumentation to permit optimization. for example, in renery process control, such additional instrumentation streams help to tune controllers to increase yield or reduce harmful byproducts. in semiconductor manufacturing, they are employed in conjunction with smallscale process perturbation and largescale statistical analysis in order to shorten the learning curve and reach a nal conguration more quickly. in environmental conditioning for buildings, multiple sensing points are aggregated into zone controllers. automotive instruments are fused to present realtime mileage information to the driver.crosssystem integration. measurements designed for one system are increasingly being exploited to improve the quality or performance of others. for example, light and motion sensors are installed to modulate the amount of articially supplied lighting in many ﬁgreen buildings.ﬂ but those motion detectors are then also available to serve as occupancy indicators in sophisticated heating, ventilation, and air conditioning (hvac) controls. rather than simply isolating indoor climate from external factors, modern design practice may seek to exploit passive ventilation, heating, and cooling; to do so requires the instrumentation of building conguration (such as open and closed window and door states) and of external and internal environmental properties (temperature, humidity, wind speed, etc.). all of these sources of information may also be exploited for longitudinal analysis, to drive recommissioning, retrotting, and rening operations. interval utility meter readings are used not just for timeofuse pricing but also to guide energyefciency measures. trafc measurements and contentcondition instrumentation are applied to optimize logistics operations. the factors described above have changed the role of instrumentation and measurement from a subsidiary element of the system design process to an integrative, largely independent process of design and provisioning of physical information services. for many sustainability challenges, methodologies are needed that can start with an initial model that is based on modest amounts of data collected during the design process; those methodologies would then include the development of an incremental plan for deploying sensors that progressively improves the model and exploits the improvements to achieve the goals of the system. in many sustainability applications, such as climate modeling and building modeling, the most effective approach may involve combining mechanistic computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  57modeling with datadriven modeling. in these applications, mechanistic models can capture (approximately) the main behaviors of the system, which can then be rened by datadriven modeling. classically, models may be developed from rst principles based on the behavior laws of the system of interest, given sufciently complete knowledge of the design and implementation of the system. such approaches are re˚ected not just in the instrumentation plan, but in simulation tools and analysis techniques. however, for most aspects of sustainability, the system may not be rigorously dened or carefully engineered to operate under a narrow set of welldened behaviors. examples include watersheds, forests, sheries, transportation networks, power networks, and cities. new technical opportunities for addressing the challenges presented by such systems as well as opportunities in instrumentation and measurement are emerging, several of which are discussed below.coping with selfdening physical information rather than simply drawing its semantics and interpretation from its embedding in a particular system, each physical information service could be used for a variety of purposes outside the context of a particular system and hence should have an unambiguous meaning. the most basic part of this problem is the conversion from readings to physical units and the associated calibration coefcients and correction function.2 the much more signicant part of the problem is capturing the context of the observation that determines its meaning.3 for example, in a building environment, supply air, return air, chilled water supply, chilled water return, outside air, mixing valve inputs, economizer points, zone set point, guard band, compressor oil, and refrigerated measurement all have physical units of temperature, but these measurements all have completely 2these aspects have been examined and partially solved over the years with electronic data sheets, such as the ieee [institute of electrical and electronics engineers] p1451 family, isa [instrumentation systems and automation society] 104 electronic device description language, or open geospatial consortium sensor model language (sensorml). however, many variations exist within distinct industrial segments and scientic disciplines; the standards tend to be very complex, and adoption is far from universal.3one example of this problem is a streamwater temperature sensor that is normally submerged but under lowwater conditions becomes an airtemperature sensor instead. how should this contextual change in semantics be captured? one possibility might be a subsequent datacleaning step that determines in what ﬁmodeﬂ the sensorcontext combination was (in this case, perhaps by using a stream˚ow sensor or by correlating with a nearby airtemperature sensor). another example is a soilmoisture sensor whose accuracy can increase with time when more is known about the soil compositionšthe parameterized equations used by the sensors can be tuned to the soiltype details.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.58 computing research for sustainabilitydifferent meanings. the same applies to the collection of measurements across many scientic experiments. typically, contextual factors are captured on an ad hoc basis in naming conventions for the sense points, the presentation screens for operations consoles, or the labels in dataanalysis reports. the straightforward application of known techniques can be employed to collect the diverse instrumentation sources and deposit readings into a database for a specic setting or experiment. similarly, electronic records can be made of the contextual information to permit an analysis of the data. the collection, storage, and queryprocessing infrastructure can be made to scale arbitrarily; processes can be run to validate data integrity and to ensure availability; and visualization tools can be introduced to guide various stakeholders.to provide these capabilities in general rather than as a result of a design and engineering process for each specic domain or setting, however, requires either signicant innovation in the techniques deployed or the development of new techniques. there are, for instance, well developed techniques for dening the meaning, context, and interpretation of information directly affected by human actions, where these aspects are inherently related to the generation process.4 to cope with many largescale sustainability challenges, similar capabilities need to be developed for physical or nonhumangenerated information. closely related to this denitional problem is the family of problems related to registration, lookup, classication, and taxonomy, much as for humangenerated information, as one moves from physical documents to interconnected electronic representations. when an application or system is to be constructed on the basis of a certain body of physical information, how is the set of information services discovered? how are they named? if such information is to be stored and retrieved, how should it be classied? if physical information is to be accessed through means outside such classications, how is it to be searched? keyword search can potentially apply to the metadata that capture context, type, and role, but what about features of the data stream itself? today one addresses these problems by implicitly relying on the enclosing system for which the instrumentation is collected. as physical information is applied more generally, it becomes necessary to represent the model of the enclosing system explicitly if it is to be used to 4for example, the inventory of products in a retail outlet is quite diverse, but schemas are in place to capture the taxonomy of possible items, locations in the supply chain or in the store, prices, suppliers, and other information. actions of ordering, shipping, stocking, selling, and so on cause specic changes to be made in the inventory database. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  59give meaning to the physical instrumentation. however, general model description languages and the like are still in their infancy.the design and capacity planning of physical information services once the physical deployment of the instrumentation capability is decoupled from the design and implementation of the enclosing system, many new research questions arise. each consumer of physical information may require that information at different timescales and levels of resolution. furthermore, the necessary level of resolution can change dynamically depending on the purpose of the measurements. in principle, one could measure everything at the nest possible resolution, but this is rarely practical because of limitations in power consumption, local memory, processing capacity, and network bandwidth. what is needed for many sustainabilityrelated challenges is a distributed system by which information needs can be routed to relevant sensorsšfor the purposes of this discussion, comparatively high bandwidth sensors are meantšand those sensors can then modulate their sampling rates and resolution as necessary.5 recent advances in compressed sensing (to help conserve bandwidth and power) and network coding (to take advantage of network topologies for increasing throughput) add to the complexity of such a distributed system. one can imagine tools that take as input a collection of information consumers, a set of available sensors, and an understood network topology and produce as output a set of sensing and routing procedures that incorporate compressed sensing and network coding. however, this perspective assumes that the locations of the sensors and the network topology are already known. in virtually all practical situations, determining the number, location, and capabilities of individual sensors is an important design step. to support these design decisions, algorithms are needed for sensor placement and sizing. these algorithms require models of the phenomena being measured and of the information needs of each consumer. how will such models be provided and in what representation?as mentioned above, system architecture has traditionally been organized as a cycle: plantsensorcontrolleractuatorplant. in this model, sensor readings are centralized and aggregated to produce an estimate of the 5consider, for example, a thermometer in a freshwater stream. for purposes of hydrological analysis, it might sufce to measure only the daily maximum and minimum temperatures and report them once per week. but suppose that one seeks to detect sudden temperature changes that might indicate the dumping of industrial wastewater. then the thermometer may need to measure and report temperatures at 15second intervals.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.60 computing research for sustainabilitystate of the plant. the controller then determines the appropriate control decisions, which are transmitted to the actuators. however, as the ﬁplantﬂ becomes a large, spatially distributed system (e.g., a city, a power grid, an ecosystem) and the volume of data becomes overwhelming, it is no longer feasible to integrate centrally the state estimation and decision making. a recent international data corporation study6 suggests that there will be more than 35 zettabytes of data stored in 2020. distributed algorithms are needed that can push as much computation and decision making as possible out to the sensors and actuators so that a smaller amount of data needs to be moved and stored. at the same time, these algorithms will need to avoid losing the advantages of data integration (reduction of uncertainty and improved forecasting and decision making). finally, tools are needed to support the planning and design process. these tools need to provide the designer with feedback on such things as the marginal benet of additional sensing and additional network links, the robustness of the design to future information needs, and so forth. in summary, all aspects of capacity planning present in highly engineered systems, such as data centers and massive internet services, arise in the context of the physical information service infrastructure. software stacks for physical infrastructures potential solutions to the problems delineated above suggest that sophisticated modeldriven predictive control and integrated crosssystem optimization will become commonplace rather than rare. as discussed in chapter 1, on the electric grid today, the independent service operator attempts to predict future demand and to schedule supply and transmission resources to meet it, with possibly coarsegrained timeofuse rates or, in rare cases, critical peak notication to in˚uence the demand shape. in the future, environmental control systems for buildings may be able to adapt to the availability of nondispatchable renewable supplies on the grid, using the thermal storage inherent in a building to ﬁgreenﬂ the electricity blend and ease the demand prole. distributed generation and storage may become more common in such a cooperative grid. various analysis, forecasting, and planning algorithms may operate over the physical information and humangenerated information associated with the grid, the building, the retail facility, the manufacturing plant. it becomes important to ask what the execution environment is for such control algorithms and analytical applications. what are the convenient abstractions 6international data corporation, ﬁthe 2011 digital universe study: extracting value from chaosﬂ (june 2011), available at http://www.emc.com/collateral/demos/microsites/emcdigitaluniverse2011/index.htm.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  61of physical resources that ease the development of such algorithms, and how is access to sharedresource protected and managed? in effect, what is the operating system of the building, of the grid, of the plant, of the ˚eet, of the watershed? today these operating systems are rudimentary and consist of ad hoc ensembles of mostly proprietary enterprise resource planning systems, building management systems, databases, communication structures, operations manuals, and manual procedures. an important challenge for computer science research is to develop the systems and design tools that can support effective and ˚exible management of these complex systems.informationintensive systemssustainability problems raise many research questions for informationintensive systems because of the nature of the data sources and the sheer amount of data that will be generated.7 computer science has applied itself broadly to problems related to discrete forms of human generated information, including transaction processing, communications, design simulation, scheduling, logistics tracking and optimization, document analysis, nancial modeling, and social network structure. many of these processes result in vast bodies of information, not just from explicit data entry but through implicit information collection as goods and services move through various aspects of the supply chain or as a result of analyses performed on such underlying data. the proliferation of mobile computing devices adds not just new quantities of data, but new kinds of data as well. some dataintensive processes are extremely high bandwidth event streams, such as clickstreams from millions of web users. in addition, computer science is widely applied to discretized forms of continuous processes, including computational science simulation and modeling, multimedia, and humancomputer interfaces. in both regimes, substantial data mining, inference, and machine learning are employed to extract specic insights from a vast body of often lowgrade, partially related information. all of the techniques described above can and must be applied to problems associated with sustainability. nonetheless, several aspects of sustainability, even in addition to the vast quantities of data that will 7given the vast amounts of data expected to be generated in the near future, traditional approaches to managing such amounts of data will not themselves be sustainable. bandwidth will become a signicant barrier, meaning that approaches to computation (such as moving computational resources to the data, or computing on data in real time and then discarding them, or other new techniques), different from simply storing the data and computing on them when necessary, will need to become more widespread. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.62 computing research for sustainabilityhave to be managed, demand greater innovation, or even wholly new techniques, particularly as ever more unstructured data are generated. to a large extent, these challenges arise from the need to understand and manage complex systems as they exist rather than to engineer systems for a particular behavior. big datanotions regarding the coming wave of ﬁbig dataﬂšthe vast amounts of structured and unstructured data created every day, growing larger than traditional tools can cope withšand how science in general must cope with it were articulated in the fourth paradigm: dataintensive scientic discovery,8 which posits an emerging scientic approach, driven by dataintensive problems, as the evolutionary step beyond empiricism, analyses, and simulation. useful data sets of large size or complicated structure exceed today™s capacity to search, validate, analyze, visualize, synthesize, store, and curate the information. the complexity of the transformations that must be applied to render some kinds of observations useful to the scientist or decision maker makes better infrastructure imperative. it is necessary so that one can build on the work of others and so that the population of those with useful insight can expand as data products of successively higher levels of integration and synthesis are constructed. unfortunately, there is a growing disparity between available software tools and the ability to leverage those on the scale referred to above. solutions to many complex systems do not parallelize well, and new tools, algorithms, and likely hybrid systems will be needed. computer science research is needed to go beyond the embarrassingly parallel problems and to nd new approaches, methods, and algorithms for solving these problems. more parallel programming tools, methods, and algorithms are needed to leverage these largescale systems.9 progress in cs is needed in order to move from descriptive views of data (reporting on ﬂwhat happened, where, how many?ﬂ) to more predictive views (ﬁwhat could happen, what will happen next if . . .?ﬂ), and nally to more prescriptive 8tony hey, s. tansley, and k. tolle (eds.), the fourth paradigm: dataintensive scientic discovery, seattle, wash.: microsoft research (2009).9a 2011 report from the national research council elaborates on the challenge of and increasingly urgent need for signicant advances in parallel programming methods that are coupled with advances up and down the traditional computing stackšfrom architecture to applications: national research council, the future of computing performance: game over or next level?, washington, d.c.: the national academies press (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  63approaches (ﬁhow can the best outcomes be achieved in the face of variability and uncertainty?ﬂ). in order to handle big data, new approaches or improvements will be required in data mining, including clustering, neural networks, anomaly detection, and so on. for example, the smart grid will grow in terms of complexity and uncertainty, especially as renewables are made a more signicant element of the energy mix. this increasing complexity will create an increasingly complex system of equations that will need to be solved on a shrinking timescale in order to create secure and dispatchable energy over larger geographies. this challenge implies a need for improvements in computational capabilities to cope with problems ranging from relatively simple n ˛ 1 contingency analysis, to n ˛ x, to an ability to parallelize the solution to very large systems of sparsely populated matrices and equations that run on highperformance computing systems. in addition, appropriate semantic layers will be needed to bridge the various data sources with a common vocabulary and language, in such a way as to make them more universally applicable. heterogeneity of databecause sustainability problems involve complex systems, the data relevant to those systems are typically very heterogeneous. challenges lie not just with huge quantities of data, but stem also from the heterogeneity of their structure and the number of data sets often needed to study a topic. in the management of ecosystems (sheries, forests, freshwater systems), relevant data sources range from detailed groundbased measurements (catchandrelease surveys, tree core data), to transactional data (sh harvest, timber sales), to hyperspectral and lidar data collected by aircraft and satellites. as discussed above, data for smart buildings include not only energyconsumption and outdoorweather data, but also data on room occupancy, the state of doors and windows (open or closed), thermostat settings, air˚ows, hvac operational parameters, building structure and materials, and so on. dealing with such diverse forms of information arises, to a lesser degree, in multimodal multiphysics simulations, which typically stitch together multiple major simulation capabilities using specialized adapters and a deep understanding of the algorithms employed in each subsystem. similar situations arise in data fusion problems and largescale logistics, such as airtrafc control. but such management of vastly heterogeneous information and processing is typically done on a domainspecic basis. new techniques will be required to do so systematicallyšsay, with transformation and coordination languages to orchestrate the process, or automatic transformation computing research for sustainabilitycopyright national academy of sciences. all rights reserved.64 computing research for sustainabilityand coordination derived from declarative description of the constituent data and processes. in some cases, ﬁcitizen scienceﬂ datašsuch as those provided by birdwatchers (project ebird10), gardeners (project budburst11), and individuals who participate in sport shing and huntingšmay be the only available data about particular regions or events. heterogeneity extends as well to the provenance, ownership, and control of the data. these data are typically not under the control of a single organization. access (either onetimeonly or ongoing) must be negotiated, and there are important security, privacy, and proprietary data issues. such authorization and access are generally not transitive, and so new techniques must be developed to manage information ˚ow as information services are composed out of other services.coping with the need for data proxiesa persistent challenge in sustainability is the meaningful translation of physical, biological, or social variables into an electric signal. more generally, the data of use with respect to sustainability often do not directly measure the quantities of interest, but instead are surrogates. for example, occupancy in a building may be derived from motion detection, infrared signatures, appliance usage, acoustics, imaging, vibration, disruptions, or other factors, but to varying degrees these may provide only a noisy indication of room occupancy. ecology focuses on the interactions among organisms (e.g., mating, hatching, predation, infection, defense), but these interactions are virtually never observed directly. an animal (or a disease) may be present in an ecosystem and yet fail to be detected by observations or instruments. weather radar can detect the movement of birds but not the species or the full direction of motion. overthecounter drug sales and web queries can be proxies for the prevalence of ˚u. as another example, measuring snowwater equivalent is normally estimated by sensor pressure at the snowsoil interface. however, snow is not a ˚uid and thus may bridge over a sensor. other challenges arise from the sensors, which themselves may affect the thing needing to be measured. this may not be chie˚y an it problem, but it creates barriers to useful data creation.supervised and unsupervised machine learning techniques, as well as those used for gesture recognition, intrusion detection, and preference characterization, may be applied to infer quantities of interest from 10see http://ebird.org/content/ebird/.11see http://neoninc.org/budburst/. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  65available surrogates, but the scale and delity needed to make substantial headway on sustainability problems require signicant transformations of these techniques. moreover, as these quantities would feed into an extensive process of modeling and automated decision making rather than providing a onetime suggested action, it would be necessary to propagate the uncertainty quantication along with such derived metrics (see below the section ﬁdecision making under uncertaintyﬂ).coping with biased, noisy datamany data sources are biased (in a statistical sense) and noisy. for example, weather and radar data are collected at special locations (e.g., airports) that were likely chosen to re˚ect the primary purpose of the data, which may be far from ideal for assessing other topics of interesting, such as climate effects. carbon˚ux towers are usually deployed in ˚at areas where the models that guide instrument interpretation are well understood, but not necessarily representative of important topography. many citizen scientists make their observations near their place of residence, rather than by following a carefully designed spatiotemporal sampling plan. data from sensors can be very noisy. indeed, the sensor network revolution aims to transition from deploying a small number of expensive, highly accurate sensors to much larger numbers of inexpensive (and less reliable) ones. moreover, sustainability problems often involve the analysis of longitudinal data (e.g., historical weather records, historical power consumption, historical carbon dioxide concentrations) that have been produced by multiple technical generations of sensors and datacollection protocols. hence, the data are not of uniform quality. each new generation of sensor and each change in the protocol may affect the biases and noise properties of the data.as one signicant example, many aspects of climate change center on the increase in global surface temperature. although there is now broad scientic consensus that human activity is a signicant contributor to global climate change, there is much continuing debate about the exact nature of the phenomenon and (more importantly) about the prognosis for the future. regarding the global surface temperature in particular, earth™s temperature is a very complex phenomenon that varies widely over the surface at any point in time and varies in complex ways over time. there has been assembled over the past hundred years a data set of over 1.6 billion temperature readings at various points over land and seas, using various instruments, by various methodologies, at over 39,000 computing research for sustainabilitycopyright national academy of sciences. all rights reserved.66 computing research for sustainabilityunique stations.12 signicant algorithmic work must take place in order to allow the development of a meaningful temperature reconstruction from this complex, noisy, incomplete data set.most existing machine learning and datamining tools make assumptions that are not valid for these kinds of data. they assume that the data are collected at a single temporal and spatial resolution; methods are needed that can work with heterogeneous data. existing machine learning and predictive datamining tools typically were designed under the assumption that the data directly measure the desired inputoutput relationship rather than measuring surrogates. finally, existing methods assume that the data can be cleaned and rationalized so as to remove noise, impute missing values, and convert multigeneration and multisource data into a common format. however, this process tends to be manual and carried out relative to a particular study of interest by individuals highly trained in the area of study. even so, it tends to result in a leastcommondenominator data set in which numerical, spatial, and temporal resolution are all set to the coarsest level observed in the data. this process may fail to address the different sampling biases and error properties of different data sources, and hence it has the potential to introduce errors into the data. a fundamental computer science challenge is to automate this cleaning and rationalization process as much as possible and to make it systematic, able to scale to vast streams of continuous data, and able to retain the full information content. a related challenge is to provide tools that support the visual detection of data anomalies and, once an anomaly is found, fast methods for nding and repairing all similar anomalies. an analyst would like to ask, ﬁare there other data that look like this plot?ﬂ and obtain useful answers despite variations in underlying sampling rate, delity, and format. coping with multisource data streamsmost early machine learning and predictive datamining tools were designed for the analysis of a single data set under the assumption that the data directly measure the desired inputoutput relationship; the goal was to learn a mapping from inputs to outputs. increasingly these techniques 12the goddard institute for space studies (giss) maintains a record of global surface temperatures as well as information on their analysis and on giss publications, which is available at http://data.giss.nasa.gov/gistemp/. see also national research council, surface temperature reconstructions for the last 2,000 years, washington, d.c.: the national academies press (2006), according to which historical temperature measurements go back to about 1850, and proxy temperature measurements go back millions of years but are most prevalent for the past two millennia. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  67are applied in realtime settings, such as in massive internet services both for the adaptive optimization of the complex distributed system providing the service and in adapting the service to optimize the user experience, the prot derived, and so on. one path for cs research in dealing with the reality of noisy, multigeneration, multisource data streams is to develop machine learning and datamining algorithms that explicitly model the measurement process, including its biases, noise, resolution, and so on, in order to capture the true phenomenon of interest, which is not directly observed. such methods should treat the data in their original, raw form so that they can capture and take account of different properties of each generation of instrumentation. in some cases, it is possible to focus on empirical model development by applying unsupervised learning methods to extract relationships between inputs and outputs without establishing a specic physical interpretation of the input values. this way of proceeding can sometimes provide insight without the need to isolate the bias, eliminate noise, and calibrate readings.the eld of statistics has studied latent variable models, such as that described in box 2.1, in which the phenomenon of interest is modeled by one or more latent (hidden) variables (e.g., zs). however, existing statistical methods rely on making strong parametric assumptions about the probability distributions governing the latent variables. an important research challenge is to transform these statistical methods into the kinds of ˚exible, nonparametric methods that have been developed in computer science (support vector machines, ensembles of tree models, and so on).13 such a transformation should also result in methodologies that are easy to apply by nonstatisticians and noncomputerscientists.the use of these techniques may in some circumstances sharpen the tension between information quality and privacy. if the raw data have been obfuscated to enhance privacy, the latent variable model will seek to undo this and infer the unobfuscated form. when is it appropriate to do this? are there effective and broadly applicable ways to preserve privacy and proprietary rights while still applying these methods?a further challenge raised by these problems is how to validate hiddenvariable models. traditional statistical methods rely on goodness of t of a highly restricted parametric model; modern machine learning methods rely on having separate holdout data to test the model. neither of these approaches will work herešat least not in their standard form. one promising direction is to develop simulation methodologies to evaluate the identiability of the model; another is to develop methods for 13r.a. hutchinson, l.p. liu, and t.g. dietterich, incorporating boosted regression trees into ecological latent variable models, twentyfifth aaai conference on articial intelligence, pp. 13431348 (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.68 computing research for sustainabilitybox 2.1  understanding the gap between observation and truththe reality of noisy, multigeneration, multisource data streams requires new machine learning and datamining algorithms that explicitly model the measurement process, including its biases, noise, and resolution, and so on, in order to capture the true phenomenon of interest, which is not directly observed.1 such methods should treat the data in their original, raw form so that they can capture and take account of different properties of each generation of instrumentation.in general, there is a gap between observation and underlying truth. in a basic sense, this gap exists whenever a transducer is used to measure a phenomenonšin addition to the mapping from input stimulus to output reading, there is a question of how the transducer is coupled to the underlying phenomenon generating the stimulus. how is the accelerometer bonded to the vibrating beam? how does the soilmoisture sensor disturb the hydrological behavior of the surrounding soil? a phenomenological gap may exist regardless of the precision of the sensor.for example, consider the case of an observer conducting a biodiversity survey. the observer visits a site and lls out a checklist of all of the species observed. the resulting data provide a record of detections rather than a record of the true presence or absence of the species. the latter can be captured by an occupancy/detection model,2 as shown in figure 2.1.1.figure 2.1.1 probabilistic graphical model representation of the occupancy/detection model. observed variables are shaded; s is the number of sites; j is the number of visits to each site. an observer visits site s at time j and reports ysj = 1 if the species is detected and 0 if not. the hidden variable zs = 1 if the species is present at site s and 0 otherwise. xs is a vector of attributes of the site, and the xz relationship predicts whether, based on these attributes, the species will be present. this is the occupancy model that is of primary interest. wsj is a vector of attributes that in˚uence detectability (e.g., the level of expertise of the observer, the density of the foliage, the weather, how much time the observer spent, etc.). the zy˚w relationship represents the detection model, which predicts the probability that the species will be detected given that it is actually present (and the probability that it will be falsely reported, given that it is actually absent).1s.k. thompson and g.a.f. seber, adaptive sampling, washington, d.c.: wiley interscience (1996) offers researchers in elds ranging from biology to ecology to public health an introduction to adaptive sampling.2d.i. mackenzie, j.d. nichols, j.a. royle, k.h. pollock, j.e. hines, and l.l. bailey, occupancy estimation and modeling: inferring patterns and dynamics of species occurrence, san diego, calif.: elsevier (2005).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  69visualization that permit the inspection and manipulation of the various components of the model.although hiddenvariable models can address the challenges of multiple generations of sensors and heterogeneous data sources, they do not solve the problem of biases in sampling. there is a need for new methods that can explicitly capture the differences between the spatiotemporal distribution of the sampling process and the desired spatiotemporal distribution of the model.14 an additional challenge is to make all of these methods fast enough for interactive use. current practice in machine learning modeling harkens back to the days of batch processing. each iteration of model development and evaluation takes several days, because the data are so voluminous that the management tools, algorithms, and visualization methods require several hours to run. data volumes will continue to explode as the number of deployed sensors multiplies. can cs researchers develop integrated datamining and visualization systems that can support interactive model iteration? such systems would produce a qualitative change in the sophistication of the models that can be applied and the thoroughness with which they can be evaluated.1514one promising direction is to build on recent advances in covariate shift methods. see j. quiñonerocandela, m. sugiyama, a. schwaighofer, and n.d. lawrence (eds.), data shift in machine learning, cambridge, mass.: mit press (2009). there is also a growing literature in handling preferential sampling for modeling geostatistical processes: see, for example, p.j. diggle, r. menezes, and t. su, geostatistical inference under preferential sampling, journal of the royal statistical society, series c, 59(2) (march 2010).15such integrated datamining and interactive model iteration will be critical to transforming the electric grid. m. ilic, dynamic monitoring and decision systems for enabling sustainable energy services, proceedings of the ieee, vol. 99, pp. 5879 (2011), offers a possible framework in which distributed models evolve as more information becomes available and box 2.1 continuedin settings in which the observation process can be designed in advance, optimal methods exist for determining the spatial layout of sites and the number of visits to each site.3 when the data are collected by an uncontrolled observation process (e.g., by citizen scientists) or when the underlying process is poorly understood, more ˚exible machine learning methods are needed.3s.k. thompson and g.a.f. seber, adaptive sampling, washington, d.c.: wiley interscience (1996).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.70 computing research for sustainabilityanalysis, modeling, simulation, and optimization one key role of computer science in sustainability is to provide technology for model development. models permit the extraction of meaningful information from contextdependent, potentially noisy measurements and observations of complex, at best partially engineered, systems in the physical world. models allow the many interrelated aspects to be decomposed into facets so that progress can be made in a somewhat incremental fashion. models provide a frame of reference for the many distinct but interrelated streams of information. computational resources and cs techniques can be brought to bear in several ways: to rene the grid size and time step, to improve the model™s representation of processes (making it more complex), and to run the model over multiple scenarios (varying the time period, input values, and so on). this section discusses three interrelated topics: multiscale models, the combining of mechanistic and statistical models, and optimization under uncertainty.developing and using multiscale models multiscale models, the rst of the three interrelated topics, represent processes at multiple temporal and spatial scales. for example, a biological population model might include the agentlevel modeling of each organism within a landscape, coupled with the ˚ocklevel modeling of group behavior at a regional scale, and populationlevel modeling at a continental scale. forest re models could include models of individual tree growth and burning, coupled with the standlevel and landscapelevel modeling of fuel load, coupled with regional models of re ignition and weather. global multiscale weather models can operate at low resolution over the entire planet but with higher resolution over regions of interest (e.g., for forecasting hurricanes). in a sense, most sustainability problems arise because behavior at one scale (e.g., energy use in automobiles, land use along migration ˚yways) affects phenomena at very different scales (e.g., global climate change, species extinctions), and those largerscale phenomena then enter a feedback cycle affecting activities at lesser scales. multiscale models are important for understanding these sorts of problems.the complexity of the interactions among layers is minimized. the complexity of decision making is internalized to the (groups of) system users instead of burdening the system operator with overwhelming complexity. iterative learning through binding technical and/or economic information exchange is implemented for learning the interdependencies and aligning them with the objectives of the system as a whole. signicant effort is needed to make such frameworks and system designs more concrete.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  71one standard approach seeks to capture all phenomena by modeling only at the nest scale in space and time. however, there are both computational and informationtheoretic reasons why this approach often fails. computationally, nescale models are extremely expensive to run; multiscale methods allow computational savings while still providing nescale predictions. from the perspective of information, largescale emergent phenomena may not be well modeled by aggregating nescale models. small errors at the ne scale may lead to large errors at larger scales. with limited data available to calibrate nescale models (clouds, land surface, human dimensions, etc.), it may not be possible to get a good t to largerscale phenomena (global or regional climate change). hence, it is often preferable, both for computational and representational reasons, to model systems at multiple scales while coupling the models so that they in˚uence one another.homogeneous multiscale models, such as models based on fourier or wavelet analysis and models that employ adaptive grid sizes (e.g., multiscale meteorology models), are reasonably well understood. however, heterogeneous multiscale models, in which models at different scales employ very different representation and modeling methods, are not as well studied. methods of upscaling, that is, summarizing nescale information at coarser scale (e.g., ﬁparameterizationsﬂ in climate models), and methods of downscaling, that is, extending coarsescale models with nescale information, have only recently been developed and still require much additional research. among the questions to be addressed are these: what is the design space of upscaling and downscaling methods? are there best practices? can these be encapsulated in generalpurpose modeling packages (e.g., as middleware services)? to the extent that upscaling is primarily performed for computational reasons, can it be automated? how do upscaling and downscaling interact with parallel implementations of the models? in addition, how should mismatches in scale (e.g., mismatches in temporal scale in areas such as coupled oceanatmospheric models) best be handled? combining statistical and mechanistic modelsthe second of three interrelated modeling challenges is that of combining statistical and mechanistic models. (the former are empirical and the latter are derived from rst principles.) in many sustainability settings, some aspects of the problem can be captured by mechanistic modelsšfor example, of physics, chemistry, and so on. however, often it is not tractable to construct models with sufcient delity to capture the aspects of the phenomena of interest. for example, consider managing the heating, ventilation, and air conditioning of an ofce building. mechanistic models computing research for sustainabilitycopyright national academy of sciences. all rights reserved.72 computing research for sustainabilityof air˚ow and heat transport can provide a good rst approximation of how a building will behave under different hvac congurations. however, in actual operation, the outdoor environmental conditions, status of doors and windows (open or closed), position of furnishings, installation of other equipment (e.g., space heaters, digital projectors, vending machines), and number and behavior of occupants can produce very different operational behaviors. introducing all of these secondary and tertiary factors into a mechanistic model may be very demanding; these factors are typically in ˚ux. alternatively, as more sensors are incorporated into building environments there may be enough data to t a statistical model of building behavioršthat is, to develop an empirical model. however, such statistical models must in effect rediscover aspects of the physics in the mechanistic models, and this can require an immense amount of data. an attractive alternative is to integrate one or more datadriven modeling components with the mechanistic model. a mechanistic model would be modied by inserting statistically trained components with the goal of these components being to transform the inputs (initial state and forcings), dynamics, and outputs so that the model produces more accurate predictions. virtually all existing work on the integrating of statistical models into mechanistic models has taken place outside of computer science. a key challenge is to bring these methods into computer science and generalize and analyze them. among the research questions are the following: what generalpurpose algorithms work well for tting the statistical components of an integrated model? how can overtting be detected and prevented (i.e., what are appropriate regularization penalties for such integrated models)? what are good methodologies for evaluating the predictive accuracy of such models? many algorithms for evaluating mechanistic models employ adaptive meshes; how can statistical methods be integrated with mesh adaptation? the tting of statistical models typically requires evaluating the mechanistic model hundreds or thousands of times. running global climate models even once at full resolution can require many days of time on the world™s largest supercomputers. can experimental designs that make efcient use of and minimize expensive model runs be implemented? can the statistical models be tted on upscaled versions of the mechanistic models and then downscaled for fullresolution runs? under what conditions would this work?decision making under uncertainty actually addressing sustainability problems requires that one move beyond observation and analysis to action. but there is inherent uncertainty every step of the wayšin the decision making informed by modcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  73eling and simulation, in the measurements, in the modeling and simulation itself, and possibly in the basic characterizations of the factors that comprise the system. in terms of sciencebased decision making, a central challenge is thus the making of (optimal or at least good) decisions under uncertainty. there are many sources of uncertainty that must be taken into account. first, the scientic understanding of many systems is far from complete, and so many aspects of these systems are unknown. second, even for those aspects for which good mechanistic models exist, the data needed to specify the boundary conditions with sufcient accuracy are often lacking, especially when human decisions and activity need to be included. third, the lack of data and the computational cost of running the models often require a coarsening of the scale and the introduction of other approximations. finally, today™s sustainability risks are timecritical, and so just waiting for additional scientic and engineering research in order to address these uncertainties is not an option. action must be taken even as research continues. therefore, the choice of actions should also take into account the fact that scientic understanding (and computing power) is expected to improve over time, and future decisions can be made with a better scientic basis. in effect, uncertainty must be treated as a quantity that persists and is accounted for at every stage. it is a product of measurement, data collection, and modeling, along with the data themselves. it is both an input and an output of the analysis, modeling, and simulation efforts. and nally, decisions must be made based not just on expected outcomes, but also on the uncertainty associated with the various alternatives.16 there are three areas that pose interesting research challenges for computer science with respect to uncertainty: assessment, representation, and propagation of uncertainty; robustoptimization methods; and models of sequential decision making.assessment, representation, and propagation of uncertainty many models employed in global climate change, natural resource management, and ecological science are deterministic mechanistic mod16regarding the challenge of the propagation of uncertainties and, nevertheless, how best to use models to help decision making, a paired set of papers on the climate sensitivity problem appeared in 2007 in science: one was a research article and the other a perspective (g.h. roe and m.b. baker, why is climate sensitivity so unpredictable? science 318(5850):629632 [2007]; m.r. allen and d.j. frame, call off the quest, science 318(5850):582583 [2007]). their main point, in the general context, is that decision making based on models of future scenarios must be adaptive. another point is that estimating the distribution function of model uncertainty requires knowledge of the distributions of the input data.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.74 computing research for sustainabilityels that provide no measures of uncertainty. recently, there has been substantial interest in assessing the uncertainty in these models. the primary method is to perform monte carlo runs in which the model parameters and inputs are varied in order to re˚ect uncertainty in their values, and the propagation characteristic of the uncertainty is re˚ected in the degree of variation in the outputs. although valuable, this does not assess uncertainty due to modelformulation decisions and computational approximations. research questions include the following: how can one minimize the cost of monte carlo uncertainty assessment? for example, can programanalysis methods determine that uncertainty in some sets of parameters interact in wellbehaved ways (independently, additively, multiplicatively)? can convenient and efcient tools be provided for authoring, debugging, and testing alternative modeling choices so that the uncertainty engendered by these choices can be assessed? can existing tools for automated software diversityšwhich were developed for software testing and security17šbe extended to generate model diversity?models are often part of a sensortodecisionmaking pipeline in which sensor measurements are cleaned and rationalized, then fed to a set of models that simulate the effects of different policy choices and assess their outcomes. however, it is often the case that uncertainty in one stage (e.g., data cleaning) is not retained and propagated to subsequent stages. existing scientic work˚ow tools (e.g., kepler18) do not provide explicit representations of uncertainty or standard ways of propagating uncertainty along such pipelines. additional work is needed to develop such representations and to provide support for automating the endtoend assessment of uncertainty. for example, it should be possible to automate endtoend monte carlo uncertainty assessment. one can also imagine extending methods of belief propagation from probabilistic graphical modeling in order to propagate uncertainty along dataanalysis pipelines automatically. coupled with modules for representing policy alternatives and modules for computing objective functions, such work˚ow tools could provide important support for decision making under uncertainty.robustoptimization methods the assessment of explicit uncertainty aims to address the ﬁknown unknowns.ﬂ classical models of decision making typically involve selecting the actions that maximize the expected utility of the outcomes accord17for a review, see a. gherbi, r. charpentier, and m. couture, software diversity for future systems security, crosstalk: the journal of defense software engineering 25(5):1013 (2011).18for more information on kepler, see https://keplerproject.org/. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  75ing to some underlying statistical model. unfortunately, experience with ecological modeling and environmental policy suggests that there are many ﬁunknown unknownsﬂšphenomena that are unknown to the modelers and decision makers and therefore not accounted for in the models.19 one possible safeguard is robust optimization.20 rather than treating model parameters as known, this approach assumes instead that the parameters lie within some uncertainty set and optimizes against the worstcase realization within these sets. the size of these uncertainty sets can be varied to measure the loss in the objective function that must be sustained in order to achieve a given degree of robustness. robustoptimization approaches can greatly improve the ability to sustain signicant departures from conditions in the nominal model. existing robustoptimization methods generally assume that the decision model can be expressed as an optimization problem with a convex structure (e.g., linear or quadratic programs). robust optimization is sometimes considered overly conservative. convex constraints over multiple uncertainty sets can be introduced to rule out simultaneous extreme events and reduce the overconservatism of rstgeneration robustoptimization methods.21 an open theoretical question is that of determining the best ways to use data in optimization problems. in some problems in which there are insufcient data, the question becomes one of how to properly incorporate subjective opinion about the data and what the best way is to characterize uncertainty. another research challenge is to develop robustoptimization methods that are applicable to the kinds of complex nonlinear models that arise in sustainability applications.optimal sequential decision making most sustainability challenges will not be addressed by a decision made at a single point in time. instead, decisions must be made iteratively over a long time horizon since a system is not sustainable unless it can be operated indenitely into the future. for example, in problems involving natural resource management, every year provides a decisionmaking opportunity. in sheries, the annual allowable catch for each species must be determined. in forests, the location and method for tree harvesting 19d.f. doak et al., understanding and predicting ecological dynamics: are major surprises inevitable? ecology 89(4):952961 (2008).20a. bental, l. el ghaoui, and a. nemirovski, robust optimization, princeton, n.j.: princeton university press (2009).21d. bertsimas and a. thiele, robust and datadriven optimization: modern decisionmaking under uncertainty, informs tutorials in operations research: models, methods, and applications for innovative decision making, pp. 139 (2006). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.76 computing research for sustainabilitymust be specied, as well as other actions such as mechanical thinning to reduce re risk. in energy generation and distribution, the location of new generation facilities and transmission lines must be chosen. in managing global climate change, the amount of required reduction in greenhouse gas emissions each year must be determined. the state of the art for solving sequential decision problems is to formalize them as markov decision problems and solve them by means of stochastic dynamic programming. however, an exact solution through these methods is only feasible for processes whose state space is relatively small (tens of thousands of states). recently, approximate dynamic programming methods have been developed in the elds of machine learning and operations research.22 these methods typically employ linear function approximation methods to provide a compact representation of the quantities required for stochastic dynamic programming.an important aspect of sustainability problems is that they often involve optimization over time and space. for example, consider the problem of designing biological reserves to protect threatened and endangered species and ecosystems. many con˚icting factors operate in this problem. large, contiguous reserves tend to protect many species and preserve biodiversity. however, such reserves are also more vulnerable to spatially autocorrelated threats such as re, disease, invasive species, and climate change. the optimal design may thus involve a collection of smaller reserves that lie along environmental gradients (elevation, precipitation, etc.). the purchase or preservation of land for reserves costs money, and so a good design should also minimize cost. another factor is that reserves typically cannot be designed and purchased in a single year. instead, money becomes available (through government budgets and private donations) and parcels are offered for sale over a period of many years. finally, the scientic understanding and the effectiveness of previous land purchase decisions can be reassessed each year, and that should be taken into account when making decisions. the solution of large spatiotemporal sequential decision problems such as those described above is far beyond the state of the art. striking the right balance between complexity and accuracy, especially in the context of complex networked systems, is critical. new research is needed to develop methods that can capture the spatial structure of the state each year and the spatial transitions (e.g., re, disease) that occur. there are sustainability problems in which all three of these factorsšuncertainty, robustness, and sequential decision makingšcombine. for example, in 22w. powell, approximate dynamic programming: solving the curses of dimensionality (2nd ed.), new york, n.y.: wiley (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  77reserve design, models of suitable habitat for threatened and endangered species are required. these are typically constructed by means of machine learning methods and hence are inherently uncertain. this uncertainty needs to be captured and incorporated into the sequential decisionmaking process. finally, existing stochastic dynamic programming methods are designed to maximize expected utility. these methods need to be extended in order to apply robustoptimization methods. a research opportunity is to integrate the training of the machine learning modelsšwhich can itself be formulated as a robustoptimization problemšwith the robust optimization of the sequential decision problem. this integration would allow the machine learning methods to tailor their predictive accuracy to those regions of time and space that are of greatest importance to the optimization process and could lead to large improvements in the quality of the resulting decisions.formulating problems in terms of sequential decision making can sometimes make the problems more tractable. for example, roe and baker23 show that structure inherent in the sensitivity of the climate system makes it extremely difcult to reduce the uncertainties in the estimates of global warming. however, by formulating the problem as a sequential decisionmaking problem, allen and frame24 show that it is possible to control global warming adaptively without ever precisely determining the level of climate sensitivity.humancentered systemsit is critical, for realworld applicability, to situate technology innovation and practice within the contextspecic needs of the people beneting from or otherwise affected by that technology. for example, in the context of introducing intelligence into the electric grid in order to increase sustainability, the essential measures and relevant information are very different when considered from the differing perspectives of the utility, supplier, and customer. the utility may be interested in introducing payment schedules that in˚uence customer behavior in a manner that reduces the need to build plants that run for only a tiny fraction of the time (to serve just the diminishing tail of the demand curve). avoiding such construction does reduce overall ghg emissions, but the primary goal is to avoid capital investment. trimming the peak does little to reduce overall energy use, but it reduces the use of the most costly supplies. a consumercentric perspective is likely to focus on overall energy savings 23g.h. roe and m.b. baker, why is climate sensitivity so unpredictable? science 318 (5850):629632 (2007)24m.r. allen and d.j. frame, call off the quest,ﬂ science 318(5850):582583 (2007). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.78 computing research for sustainabilityand efciency measures, not just on criticalpeak usage. thus, greater emphasis may be placed on visualizing usage, understanding demand, reducing waste, curbing energy consumption and less important usage, and (if there is dynamic variable pricing) helping to move easily rescheduled uses (e.g., water heating) to offpeak times. a gridcentric perspective, by contrast, may focus on the matching of supply and demand, as well as on the utilization of the key bottlenecks in the transmission and distribution infrastructure. all of these stakeholders need to be considered, and ideally involved, to substantially increase the penetration limit of nondispatchable renewable supplies, because of the need to match consumption to supply. and, all stakeholders have substantial needs for monitoring usage data, determining causal relationships between activities and usage, and managing those activities to optimize usage. in addition to the needs and values of these direct stakeholders in the technology, the indirect stakeholders should also be consideredšthat is, those who are affected by the technology but do not use it. in the smart grid example, the set of indirect stakeholders is broad indeed, since everyone is (for example) affected by climate change. the ability to understand such needs and to guide the development of technology on that basis constitutes a natural application of techniques developed in the area of humancomputer interaction (hci).more generally, a humancentered approach can and should be integrated with each of the topics discussed above. issues such as humanintheloop training of machine learning systems, the interpretability of model results, and the possible use (or abuse) of large volumes of sensed data become particularly salient with a humancentered viewpoint. indeed, with the vast quantities of data to be generated and used as described earlier, privacy becomes a rstorder concern. the role of computer science in sustainability is predicated on the ability to capture and analyze data at a scale without precedent. the understanding and mitigating of privacy implications constitute an area in which fundamental cs research can play a rolešin both formalizing the questions in an appropriate way (and indeed this is research well underway) and potentially in providing solutions that can help mitigate the loss of privacy that is, to some extent, inherent in taking full advantage of the power of informationgathering at a global scale with high resolution. it is essential that a humancentered approach be integrated with more traditional security approaches: not only should the techniques for preserving privacy be technically sound, but they should also be accessible, understandable, and convincing to the users of these systems. historically, much of the research on sustainability in hci has focused on individual change. perhaps one of the bestrecognized examples is ecocomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  79feedback technology, which leverages persuasive interface techniques25 and focuses primarily on residential settings. reduced individual use can socialize people to the issues at hand, and can, at scale, have a direct if limited effect on overall energy use.26 however, population growth alone may outstrip the gains realized by such approaches. in response, the committee notes the importance of signicantly increased attention to social, institutional, governmental, and policy issues in addition to issues of individual change. a challenging public policy question, for example, is how to verify compliance with ghg emissions requirements. reliably validated carbon reductions, for instance, are important not just to global progress; they would be also invaluable for guiding sustainability efforts at a macro level.27 this report emphasizes opportunities for research, in addition to the data and privacy challenges mentioned earlier, on humancentered systems both at the individual level and beyond (at the organizational and societal levels). examples of such research areas include visualization and userinteraction design for comprehensibility, transparency, legitimation, deliberation, and participation; devices and dashboards for individuals and institutions; expanding the understanding of human behaviors, empowering people to measure, argue for, and change what is happening; and education. following are brief discussions of each of these.supporting deliberation, civic engagement,  education, and community action as noted in chapter 1, moving toward a more sustainable society will require massive cultural, social, political, and economic changesšand today™s technologies are deeply intertwined with many of these changes. technology can help to support an informed and engaged citizenry. currently, civic engagement is uneven at best, and thoughtful public deliberation about major issues is often challenging to accomplish. however, the ease of information access, the existence of communitybased knowledge 25for example, see j. froehlich, l. findlater, and j. landay, the design of ecofeedback technology, in proceedings of the 28th international conference on human factors in computing systems, new york, n.y.: association for computing machinery, pp. 19982008 (2010).26for a provocative essay on this issue, see p. dourish, print this paper, kill a tree: environmental sustainability as a research topic for hci, luci2009004, laboratory for ubiquitous computing and interaction, university of california, irvine (2009), and a related article: p. dourish, hci and environmental sustainability: the politics of design and the design of politics, in proceedings of the 2010 acm conference on designing interactive systems, aarhus, denmark, pp. 110 (2010).27see national research council, verifying greenhouse gas emissions: methods to support international climate agreements, washington, d.c.: the national academies press (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.80 computing research for sustainabilityrepositories, and the search and social networking capabilities online are transforming the manner in which humans learn, make decisions, and interact. these techniques can be adapted for a research program on designing, deploying, and testing innovative ways for citizens to deliberate and to engage with government and one another, particularly with those who may hold very different views in the context of sustainability. these deliberations should be closely coupled to data (gathered both by professional scientists and citizenscientists) and simulation resultsšaffordances should be provided to help ground the discussion in the scientic evidence. similarly, online curricula for students in kindergarten through grade 12 and for adults can explore, for instance, ongoing scientic and policy discussions related to sustainability; and educational initiatives can contribute to societal changes needed to meet sustainability goals. in addition to opportunities with respect to tools for engaged citizens generally, there are also promising areas of research in helping scientists provide more effective input into these broader discussions and debates on sustainability and potential initiatives. the intellectual merit of this research would center on the issues of how to facilitate largescale online deliberation about contentious issues; the broader impacts would be in making the results of scientic inquiry more widely seen and discussed. as an example, suppose that there was a network supporting online deliberation among scientists concerned with sustainability for developing key points, areas of strong consensus, areas of disagreement, and supporting evidence. those deliberations would produce a sustainability action agenda that could be introduced to the public by means of interesting interactive environments designed to appeal to those of all ages. these sites could feed information by means of different media outlets (both traditional and emerging) as well as providing interactive scenarios that people could use to answer questions and debate solutions. one highlight of this system would be a series of consensus news stories, perhaps on a weekly basis. these stories could be based on agenda items created by scientists and rated by public interest.a core component of such a public education system could be a forum for discussing scientic data, for voicing views on which stories to present and when, and for suggesting how to frame them (deliberative forums for the science community for building consensus positions). a key research issue here is the development of technologies that help organize the discussion, both for longstanding participants and for people who are interested in entering into a longrunning discussion but could use help in understanding it and in making useful contributions. the forum should include affordances that make it easy and natural to classify suggestions, pro and con arguments, and so on, to keep this type of exchange from degenerating into just a freeform discussion computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  81board. another important kind of affordance would be hooks for giving sources for assertions (tools to encourage grounding arguments in the scientic data).another project might be a highly visible forum for exchanges between groups with quite divergent views in a deliberative setting. again, the system should include affordances that make it easy and natural to classify arguments and perspectives and tools that encourage the grounding of arguments in the scientic data.basic research in educational technology is also crucial to increasing the relevance and effectiveness of tools for a culturally and economically diverse population. arguably, better support for deliberation and engagement will not be enough. supporting community action is also essential. in recent years technology has become more and more salient as an enabler of successful social change.28 in another example, on a local scale, citizen sensing of environmental indicators (e.g., pollutants) has in˚uenced the ability of individuals to advocate for change. as the cost of sophisticated sensors comes down, one can expect to see more and more of them employed by end users. a citizenry that engages with and helps to track this information is important to progress on the issues at stake, and this engagement leads to increased education and engagement in addition to increasing the amount of information available in crucial areas. however, this raises fundamental research problems ranging from the creation of these sensors to our ability to use the data effectively despite the inherent uncertainties that arise from its production.design for sustainability techniques developed to design for manufacturing, design for mass customization, and usercentric design can expand on the understanding of what it means to design for sustainability. techniques such as energy star ratings for appliances and leadership in energy and environmental design (leed) ratings for buildings have had some success in reorienting industry providers and consumers alike toward more sustainable practices. these efforts can be substantially informed by the measurement, informationcollection, and modeldevelopment techniques described earlier, but can also use hci techniques for appropriation, reuse, and endtoend design for technology products. this research can be expanded to shed light on process, distribution, middleware, and other aspects of the production and distribution of products. technological advances can 28t. hirsch and j. henry, txtmob: text messaging for protest swarms, in extended abstracts on human factors in computing systems, new york, n.y.: association for computing machinery, pp. 14551458 (2005). doi: http://doi.acm.org/10.1145/1056808.1056940.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.82 computing research for sustainabilityalso contribute to the tracking, monitoring, and analysis of the source materials, production processes, distribution, and eventual disposal of products. this information in turn can help to inform purchase decisions, provide better accounting, and otherwise improve the sustainability of the consumer economy.human understanding of sensing, modeling, and simulationas the availability of sophisticated sensors, information collection, modeling, and dissemination increase, techniques need to be developed to provide in meaningful forms rich, highly disaggregate information to households, small groups, and organizations regarding resource usage (e.g., for electricity or water consumption). in addition to supporting improved decision making about energy use at the organizational and individual levels, this information could provide civil and environmental engineers with a picture at a new level of detail about how and why these resources are being consumed, allowing their science and practice to advance. at the same time, this possibility raises challenging research questions regarding appropriate amounts of information, how to deal with the inherent uncertainties in the data, techniques for evaluating such systems, coupling with other systems on the supply side (e.g., the smart grid), and important value questions regarding fairness, representativeness, security, and privacy. better data can also drive modeling and simulation, which can help with such activities as predicting important trends, assessing how well proposed policies would meet objectives, and optimizing resource use. modeling climate change is an obvious example, but there are many others, including a simulation of the evolution of urban areas, freight transport, and natural environments such as forests or rivers. however, to be effective and relevant to policy making and decision making, such modeling work must include careful consideration of how it integrates with deliberation and the political process. this raises issues of design for transparency, legitimation, appropriability, and participation. tools to help organizations and  individuals engage in more sustainable behaviors another area for research concerns tools that make it easier and perhaps even enjoyable for people to engage in more sustainable behaviors. some of the many examples in this area are the providing of realtime public transit arrival and route information (particularly on mobile devices), online rideshare matching, geowikis for bicycling, zipcar, freecycle, and the like. another class of tools provides ecofeedback: targeted informacomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  83tion about resource consumption (perhaps in real time), integrated with suitable visualization techniques and appropriate persuasive technology, for example to show progress toward personal or group goals. this area is also related to the previous opportunity regarding the use of information from resourceusage sensing. it is important to recognize the limits of these technologies: better transit information is great if a good underlying transit system exists, but it is not so useful without that. similarly, ecofeedback regarding energy use can be helpful, but it does not address the more fundamental, underlying energy challenges in some situationsšsuch as lowincome households in which comparatively expensive upgrades would be a nancial hardship, or homes that contain inefcient appliances or poor insulation. for such challenges, alternative solutions would be needed. many of the techniques described here are relevant to organizations as well. for example, a large organization might similarly provide targeted information about resource consumption, in real time, to show progress toward goals for different branches of the organization.mitigation, adaptation, and disaster response even under optimistic climate change scenarios, weather disasters are likely to increase in number and severity, resulting in both the need for immediate disaster relief and likely the need to assist large numbers of refugees (e.g., from lowlying regions).29 also, unfortunately, human actions are likely to continue to contribute directly to environmental disasters such as oil spills. there are research challenges with respect to developing plans that can be revised rapidly under conditions of great uncertainty, making use of vast numbers of citizen observations (such as microcontent posted from disaster areas by individuals), coordinating supply efforts, and others. one challenge for this line of work is recognizing that there are huge uncertainties about the future and thus also in developing tools and infrastructure that are ˚exible, adaptable, and appropriate. using information from resourceusage sensingrecent work has opened the possibility of providing rich, highly disaggregate information to households, small groups, and organizations regarding resource usage. for example, immediate feedback can now be 29national research council, adapting to the impacts of climate change, washington, d.c.: the national academies press (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.84 computing research for sustainabilityprovided on electrical energy use at the appliance or individual lighting circuit level. a number of possibilities arise as a result, including detailed ecofeedback about usage and tighter coupling with smart grid technology on the supply side. similar feedback is possible for other resources such as water and natural gas.this possibility does, however, raise a number of challenging research questions. for example, what is the appropriate amount of information to provide to households? clearly there is the possibility of overwhelming them with information. how are the inherent uncertainties in the data to be dealt with? how are such systems to be evaluated? the traditional hci evaluation techniques of laboratory studies and smallscale deployments are inadequate, but massive deployments over long periods are slow and expensive, implying that one can only try a small number of alternatives (in tension with the need for rapid prototyping and iteration). how can these systems be coupled with smart grid technology on the supply side? for example, the grid could signal to the household that the system was close to capacity and that lowering energy use for the next hour would be very helpful (or perhaps would result in a lower bill); or, conversely, the household could be signaled that this would be an opportunity for some nontimecritical activity. this arrangement would be a combination of automated actions, with the scripts under the household™s control, and explicit actions. another set of issues concerns fairness and representativeness. for example, the majority of households in the united states are lowincome and many households rent, although most work in this area focuses on relatively af˚uent homeowners. can systems and policies be designed that do not unfairly disadvantage some households, particularly ones that can least afford additional charges? another set of challenges concerns security and privacy. such systems offer the potential for reducing resource consumption and making better use of resources, but there are clear security and privacy risks if the system is compromised. related to that issue are questions of responsibility and power around available infrastructure that must be addressed. not everyone owns a home or pays for energy use, and the relationships between landlords, residents, laws (incentives, disincentives, and so on), available services (green contractors), and other factors in˚uence energy use outcomes and may bear on the design of technology (for example, in terms of authenticating who has access to what data). it is difcult to get good information about the negrained use of energy right now. buildings are not generally instrumented to produce these data, yet a true understanding of the forces driving energy use is impossible without better data. better information about which appliances are in use and when they are in use can help in developing a more complete computing research for sustainabilitycopyright national academy of sciences. all rights reserved.elements of a computer science research agenda  85understanding of human behavior, and perhaps in identing interventions that can have an impact on energy use. even a modest advance such as analysis based on the segmentation of a building™s energy use among hvac, lighting, and plug load could yield useful results. although this may seem like a pure sensing problem, the process of deploying sensors, labeling data, and interpreting the results involves people, and computer science researchers are at the forefront of some of the innovations in this area.30 despite these advances, the problem of labeling data and interpreting the results is one that requires more attention. conclusionthis chapter provides examples of important technical research areas and outlines a broad research agenda for computer science and sustainability. although there are numerous opportunities to apply wellunderstood technologies and techniques to sustainability, there are also hard problemsšsuch as mitigating climate changešfor which current methods offer atbest partial solutions, and rapid innovation is essential in light of the pressing nature of the challenges. the areas highlighted in this chapteršmeasurement and instrumentation; informationintensive systems; analysis, modeling, and simulation; optimization; and humancentered systemsšare counterparts to wellestablished research areas in computer science. this overlap has clear positive implications. however, nding a way to have a signicant impact may require new approaches to these problems and almost certainly new ways of conducting and managing research. chapter 3 explores ways of conducting and managing research so that computer science research can have an even greater impact on sustainability challenges.30for example, patel and others have developed comparatively lightweight methods to acquire reasonably negrained data in homes; see j. froehlich, e. larson, s. gupta, g. cohn, m. reynolds, and s.n. patel, disaggregated enduse energy sensing for the smart grid, ieee pervasive computing, special issue on smart energy systems, januarymarch (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.3programmatic and institutional opportunities to enhance computer science research for sustainability the challenges of achieving a sustainable society are truly global, with complex interdependencies that affect risk assessments, technical and social opportunities for solutions, and economic and political feasibility. no one eld or discipline on its own could possibly be expected to ﬁsolveﬂ even one aspect of this problem. however, information is central to making progress on many fronts. thus computer science (cs)šwhich couples information and innovationšis vital to sustainability. for computer science to play its part in meeting global sustainability challenges, priority should be given to research that addresses one or more important sustainability challenges (examples were described in chapter 1) and that offers signicant impact. this impact may be direct, or it may be through gamechanging contributions that offer signicant leveraging opportunities for other domains. in either case, priority should be placed on opportunities to address the sustainability challenge to a tangible degree. this chapter explores some of the potential impediments within the eld of computer science to making signicant progress on issues pertinent to sustainability. it considers how to bridge the gap between the traditional research quest for universality1 and the imperative to have a specic impact on sustainability challenges. the chapter is aimed pri1the committee uses the term ﬁuniversalityﬂ to encompass the related notions of generalizability (solutions that are amenable to relatively straightforward abstractions in order to address more general versions of a given problem) and breadth (solutions that can be revised to be applicable to broad problem domains and spaces). the quest for universality captures the traditional cs research goals of abstractability and broad applicability. 86computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 87marily at the cs research communityšincluding both researchers and funders. first, it discusses some of the fundamental aspects of cs research and computational thinking and how these aspects are also critical to the sustainability problem space. then it explores the challenge of universality and emphasizes that a bottomup approach is not only necessary in the sustainability space but also has precedent in many other areas of deep computer science. it describes the connection between universality, bottomup approaches, and sustainability. it then offers suggestions on how to structure research to promote meaningful impact on sustainability. finally, the chapter identies methodological opportunities for optimizing research outcomes and impacts. computer science approaches  for addressing sustainability chapter 2 highlighted the centrality of data and information to sustainability. given this centrality, computer science and information technology (it) are essential to meeting sustainability challenges. the challenge for it experts and cs researchers is in ensuring that technologies and approaches represent usable, appropriate solutions; that they are highly effective; and that they take advantage of the deepest and most powerful insights that can be brought to bear. it has been and continues to be a critical enabler of progress in vast arenas of society. sustainability is no exception: it offers a powerful tool to assist in addressing sustainability challenges. moreover, fundamentals of the computer science eld itself offer unique and important contributions to sustainability. to name just a few such fundamentals, consider abstraction design, algorithms, operating systems and layering, realtime systems, machine learning, human computer interaction (hci), and databases. for instance, the very notion of queryable structured data is at the heart of much of computer science; at the same time strides are being made to cope with the vast amounts of unstructured data now available. given the scope and scale of sustainability challenges along with the vast amounts of relevant data, the structuring and understanding of these data present many challenges. the lens of computational thinking is essential to solving many complex problems,2 and there are key opportunities within computer science that are clearly 2see national research council, report of a workshop on the scope and nature of computational thinking, washington, d.c.: the national academies press (2010); and national research council, report of a workshop on the pedagogical aspects of computational thinking, washington, d.c.: the national academies press (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.88 computing research for sustainabilityapplicable, even beyond those highlighted in chapter 2. a sampling of these areas is outlined in box 3.1. as one example, many sustainability challenges, particularly those related to infrastructure, make salient the importance of architecture. architecture encompasses not just structural connections among subsystems, but expectations regarding what a system will do, how its perforbox 3.1 additional areas of promising computer science  and related research for sustainabilityin addition to the research areas discussed in chapter 2 of this report, following is a list presenting a sampling of topics and areas that arise in computer science and information technology more generally that are likely opportunities for making progress in sustainability.  this is a likely area of opportunity especially as it applies to selfregulating processes, biodiversity, and metrics of adaptability. (for instance, designing for averageuse cases and building in techniques for degradation, as opposed to designing for peaks with safety margin). this is a likely area of opportunity for many levels of programming, at many stages of the life cycle. one cannot understand how technology will affect sustainability without understanding what people will do with it. the emphasis in computer science on extensibility in system design takes into account the fact that technology as used matters, not just as designed.  this area is involved with the invention of things that people will use and engage with, which is crosscutting for multiple domains. what is the equivalent of search in the physical world? how do we deal with unstructured search, taxonomy, structured query processingšsearch for data relevant to scientic discovery?  this eld offers likely opportunity as a modality for searching and understanding the physical world.  this is an area of opportunity in terms of representation of the physical world and of sustainability problems.  this area of opportunity relates to information support and sharing, building community, structured argumentation, sensing, modeling, and observation. this is an area of opportunity that includes the development of capabilities to cope with challenges where there is functional decompositioncomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 89mance will scale, what behaviors are within bounds, and how subsystems (or external actors) should interact with the system as a whole. this type of challenge can be seen perhaps most clearly in the smart grid example discussed in chapter 1. however, the other illustrative examples in chapter 1šfood systems and the development of sustainable and resilient infrastructurešalso make clear that early architectural choices (such as the expected role and behavior of individual farms in the global food system, or the anticipated communications capabilities of rst responders in a crisis) can have longlasting repercussions. a system™s architecture instantiates early design decisions and has a signicant effect on the uses, behaviors, and effects of the system long past the time when those decisions were made. moreover, requirements inevitably change over time, necessitating ˚exible or evolvable designs. because of this large effect of a system™s architecture on almost all aspects of the system over its life cycle, the architecture of largerscale systems of necessity merits signicant attention and resources. as systems have become global in scale, the disciplines of computer science and software engineering have grappled with the challenges of architecture as they pertain to largescale systems working over large geographic areas, with countless inputs and millions of users. lessons from architecting hardware, software, network, and information systems thus have broader applicability to the processes of structuring, designing, maintaining, updating, and evolving of infrastructure in pursuit of sustainability.3one question not yet addressed in this report is how well the cs research community is poised to play its part in meeting global sustain3for an indepth examination of the importance of architecture in softwareintensive systems, see chapter 3 of the following report: national research council, critical code: software producibility for defense, washington, d.c.: the national academies press (2010). it describes the importance of architecture as follows (pp. 6869): ﬁarchitecture represents the earliest and often most important design decisionsšthose that are the hardest to change and the most critical to get right. architecture makes it possible to structure require ments based on an understanding of what is actually possible from an engineering standpointšand what is infeasible in the present state of technology. it provides a mechanism for communications among the stakeholders, including the infrastructure providers, and managers of other systems with require ments for interoperation. it is also the rst design artifact that addresses the socalled nonfunctional attributes, such as performance, modiability, reliability, and security that in turn drive the ultimate quality and capability of the system. architecture is an important enabler of reuse and the key to system evolution, enabling management of future uncertainty. in this regard, architecture is the primary determiner of modularity and thus the nature and degree to which multiple design decisions can be decoupled from each other. thus, when there are areas of likely or potential change, whether it be in system functionality, performance, infrastructure, or other areas, architecture decisions can be made to encapsulate them and so increase the extent to which the overall engineering activity is insulated from the uncertainties associated with these localized changes.ﬂ computing research for sustainabilitycopyright national academy of sciences. all rights reserved.90 computing research for sustainabilityability challenges. in the committee™s view, one perceived barrier to its doing so is the sense that aiming research toward sustainability challenges may con˚ict with ultimate scientic aims of universality.4 this question is explored below in more detail. the most powerful and important computer science innovations to date share the characteristic of universality. indeed, it is their utility across a wide range of domains that makes their aggregate impact so great. see box 3.2 for a short list of just some of computer science™s most signicant achievements. universities, research laboratories, departments, and funding agencies increasingly recognize the value of multidisciplinary research. however, as the eld has matured, there has been comparatively less emphasis on domaindriven approaches to innovation in favor of research that attempts to go directly to universalityšthat is, abstractability and breadth. nevertheless, it is a strength of computer science that the eld can, and does, ground its advances in realworld problems. as described in chapters 1 and 2, cs can contribute signicantly and critically to sustainability. in this section it is argued that to have the biggest impact on the pressing challenges facing the world today, cs research must be informed with deep knowledge, input, and context from domain experts. in some areas of computer science, universality is built into the problem denition. much of theoretical computer science, of course, begins by representing the target problem in abstract, symbolic language. other examples of research with universality as the focus from the start include the von neumann computer model itself, programming languages such as fortran and algol, and early humanfactors research (such as that of doug englebart and alan kay) that created new modes of human computer interaction. in other equally consequential areas, however, broad applicability has only emerged years or even decades later, as researchers began with domainspecic problems and developed solutions and then later were able to generalize and understand deeper truths from this panoply of specic contributions. examples of important contributions that began as highly specic projects include the world wide web (originally conceived as a means to share research papers and scientic information) and objectoriented programming (early objectoriented languages were developed to address specic problems such as discrete event simulation or graphical interaction). in this chapter it is argued that cs research on sustainability is best approached from the bottom up: that is, by developing wellstructured 4the integration of computer science with domain sciences was a central tenet of a 1992 national research council report: national research council, computing the future: a broader agenda for computer science and engineering, juris hartmanis and herbert lin (eds.), washington, d.c.: national academy press (1992). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 91box 3.2 universality and computer science™s greatest achievementsthe list below offers one view of some of computer science™s most signicant achievements over the years. ﬁcomputer scienceﬂ is construed broadly here, to encompass information and communications technologies.1 most of the achievements listed below were accomplished by focusing on developing domainspecic solutions with an eye toward eventual abstraction and universality.ersalityšthe turing machinetion, computeraided engineering (design, simulate, build, test, measure, use)tems productionture of graphs1there are, of course, other takes on this question. the computer science and telecommunications board™s (cstb™s) wellknown ﬁtire tracksﬂ diagram (as seen in national research council, , washington, d.c.: the national academies press [2003]) explores innovations in computer science and information technology from the perspective of spawning billiondollar industries. that list includes timesharing, client/server computing, entertainment, internet, local area networks, workstations, graphical user interfaces, verylargescale integration design, and reduced instruction set computing processors. a cstb report published in 2004 articulated the essential character of computer science, and focused on seven key themes: computer science (1) involves symbols and their manipulation, (2) involves the creation and manipulation of abstractions, (3) creates and studies algorithms, (4) creates articial constructs, (5) exploits and addresses exponential growth, (6) seeks the fundamental limits on what can be computed, and (7) focuses on the complex, analytic, rational action that is associated with human intelligence. (national research council, computer science: reections on the field, reections from the field, washington, d.c.: the national academies press [2004].) the differences in these lists are less important than noting the power of focused problem solving in a eld whose core strengths include abstraction and adaptability.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.92 computing research for sustainabilitysolutions to particular, critical problems in sustainability and later seeking to generalize these solutions, as opposed to striving for universality from the start. many advances will require cs research for progress, as described earlier, but those advances may not be immediately evident as universal approaches. the committee believes that demanding evidence of clear universality from the start is likely to inhibit close interdisciplinary collaboration and, ultimately, major advances. moreover, many sustainability challenges need to be addressed sooner rather than later, even if imperfectly. at the same time, the fact that the problems associated with sustainability are complex, multifaceted, and in some cases poorly dened means that close attention to experimental robustness and underlying mathematical rigor will be essential. previous chapters illustrate this overall approach. for example, the hypothesized research on the smart grid takes an approach to the problem that is fundamentally a computer networks perspective (inspired by the success of the internet), but it is not initially intended to make universal contributions to the theory of networks. rather, by focusing on the problem at handšthat of integrated control of power generation, distribution, and usešthere is the potential for breakthrough advances on this critical issue at the same time that new computational techniques are being developed. there are clearly general lessons to be learned about these issues. the committee suggests that the best way to learn them is to start with the particular sustainability challenge at hand, make progress on that, and later seek to generalize.this approach does not mean, however, that any application of computation or it to problems in sustainability should automatically be seen as computer science research for sustainability. rather, to be judged as a signicant contribution within the intersection of cs research and sustainability, the contribution rst must have the potential to make a real difference in moving toward a more sustainable future. second, the contribution must have the potential, if it is successful, to add to generalizable knowledge about sustainability, and the contribution or proposed solution should, at the same time, require new computational techniques or thinking beyond the current state of the art in computing. the specic criteria for judging research success should of course evolve over time, with members of the community themselves proposing and debating what constitutes the most worthy research. the committee emphasizes, however, the criterion of having the potential to make a real difference. an open research question in its own right is how best to assess and evaluate impacts and how to isolate the effects of any particular sets of interventions, given the scales and time frames of many sustainability challenges. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 93principle: encourage research at and across disciplinary boundaries, well informed by specics and well structured to handle scale, data, integration, architecture, simulation, optimization, iteration, and human and systems aspects. cs research in sustainability should be an interdisciplinary effort, with experts in the various elds of sustainability being equal partners in the research.toward universalityalthough the committee emphasizes that a premature focus on universality would be detrimental to the kind of highimpact sustainability solutions so desperately needed, universality should not be ignored. indeed, domainspecic research can lead toward universality. a challenge, though, is how to pursue the universality that contributes so much to the power of computer science. in this section, it is argued that the purposes of domain specicity and contextualization are not at odds with ultimately producing universality in results, and that universality is not achieved directly in most cases in any event. consider the development of important advances in cs and it. achieving universality typically involves developing wellstructured innovative solutions, applying them to the problem at hand, evaluating their efcacy, and using this evaluation to guide further improvement, enhancement, and new directions. successful approaches are then rened and applied in other areas, perhaps similar to the original problem domain, perhaps more remote. as the iterations of application proceed, the universality of the approach is discovered and rened. why has this approach worked so well in computer science? despite the fact that computer science has information at its heart, tools and methods are ultimately instantiated in software. software is malleable and well disposed to iteration. software technology is developed, deployed, used, and modied in continuous iterative cycles. developing modern software is not done through implementing a perfect software system once, at the start. instead, the state of the art in software engineering urges iteration and architectural ˚exibility. software is designed to be updated on a frequent basis over its entire life cycle. this approach to the creation of software systems has developed for many reasons. for one reason, the work required to discover all or even most of the bugs before release in noncritical systems far exceeds the value of that approach. similarly, feature sets are expanded through use. the range and number of possible features of any particular target system are larger than what is implementedšif that were not the case, the systems would be even more complex and difcult to use and would take even longer to roll out. thus systems are rolled out with a modest feature set, computing research for sustainabilitycopyright national academy of sciences. all rights reserved.94 computing research for sustainabilityand new features are then added over time. this approach allows products to get to market sooner and helps to avoid or reduce the development of features that are not really needed, as well as revealing what actually works in practice. in short, after initial deployment, reality (instead of anticipated or modeled reality) guides the evolution of the feature set. the understanding of the human systems into which all computing systems are deployed is highly limited (not least because the understanding and modeling of humans and organizations are highly incomplete and ˚awed at best). thus one cannot generally anticipate and simulate all uses. the world of computer systems has grown to evolve features that are adapted to what the users of those systems demand. a virtuous cycle has resultedšusers have come to expect ˚exibility and malleability, thus ensuring that feedback loops occur. systems have versions that are rolled out as available and as features are demanded. change management is a basic fabric of these systems, which are designed for ongoing change. these systems have innovation and expectations of innovation literally encoded within them. another way to think about the inherent adaptability of computer science is to consider an ﬁend to endﬂ argument for the inclusion of authentic applications in systems research. the original endtoend argument put forward by saltzer, reed, and clark was as follows: [f]unctions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. . . . the argument appeals to application requirements, and provides a rationale for moving function upward in a layered system, closer to the application that uses the function.5 this same logic has implications for systems research and innovation. authentic applications should be included as part of systems research exploration at as high a level as possible in order to keep functional and performance requirements on a purposeful track. for the purposes of this report, notions of authenticity must encompass highimpact applicability to sustainability challenges. these fundamentals in computer science are relevant to the way that cs research is done and the way in which research and development investment is approached. this ﬁbuilt for changeﬂ characteristic also facilitates the transition from one application to another. algorithms and their instantiations can be adaptive, iteratively modied to t a new 5j.h. saltzer, d.p. reed, and d.d. clark, ﬁendtoend arguments in system design,ﬂ proceedings of the second international conference on distributed computing systems, paris, france, april 810, 1981. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 95context. more importantly, such iterations are not a signicant departure from what occurred in their initial creation; the expectation of iteration is part of the core of the technology. building for change is done through modularity, through system designs resulting from hard thinking about where to place functionality, through the isolation of errors and details. change to software happens as the software is developed, and as it is deployed, debugged, and iteratively improved; and it happens as it is applied to a new problem. as a given technique is applied to a new problem, and yet another new problem, and so on, the universality of the technique emerges. for each new application, the characteristics of generality are exposed, and the possibility for further abstraction and broad applicability grows. in the best case, an ﬁexponentialﬂ process emerges in which techniques that are broadly applicable are exposed as each successful reapplication enables multiple new adaptations to come to light. not all potential new applications are developed, of course, but those that are nd their ultimate universality through bottomup cycles of change and through the iterative process of design which promotes that process. past successful examples of this approach include language translation, internet protocols, machine learning, objectoriented languages, and databases. the approaches discussed in chapter 2 were not described in their most general terms. the committee does not suggest that they be pursued generally. but universality is often seen as the ultimate win of computer science techniques. although universality is important and must be the goal because some big wins are needed in order to attack the unprecedented challenges of sustainability, the challenges should be approached through the concrete. there are opportunities for cs research to take on the key challenges in sustainability, learn about them, and design focused solutions that work. the design of those solutions should embed the best of cs design and systems learningsšmodularity, isolation, simplicity, and so on. then cs researchers and practitioners should experiment with, apply, and pilot solutions to specic problems; look for the successes and reapply and adapt them to other applications; and develop universality while seeking to increase applicability and impact. if the concrete is embraced across the range of infrastructure, ecosystems, and human systems, reality will help hone and lter possible approaches, and multiple and adapted applications will emerge.finding: fastmoving iterative, incrementally evolving ap proaches to problem solving in computer science, which were critical to building the internet and web search engines, will be useful in solving sustainability challenges.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.96 computing research for sustainabilityeducation and programmaticsthe vision described above implies a broadening of what it means to be a computer scientist. a signicant opportunity for change is in the area of education. this change should include educating computer science students to achieve impact with computing, computational methods, and systems approaches in important domainspecic areas. such a shift in culture would encourage these students to develop domain expertise and to collaborate directly with domain experts while in graduate school or in preparing for graduate work6 and to address such topics as modeling and predicting energy use and designing for reuse.making such a shift successfully will also require a culture of experimentation and innovation in the application of computer science. further, it will require a research infrastructure in order to make progress. that infrastructure should include the following: (1) available standard data sets, models, and challenge problems to the community in order to assist in developing a common discourse and target for innovation, analogous to grand challenges in robotics, speech, vision, and so on; and (2) the building of shared infrastructure through open architectures and testbeds that allow for grounded iterative experimentation in the context of real components, both human and technical. such architectures could go a long way to increasing the feasibility and impact of experimental research in academia and to creating an ecosystem that supports iterative innovation.education and training within the target domains constitute an equally important goal. one challenge is in the translation of problems from one domain or eld to anotheršfor instance, describing the power and electric grid systems as a dynamical system and control problemšand then translating sometimes newly exposed assumptions back to the problem domain. information and data are critical to understanding the challenges, formulating solutions, deploying solutions, communicating results, and facilitating learning and new behaviors that are based on results of the work. thus a signicant component of meeting virtually all sustainability challenges is to infuse computational thinking and computer science and informationrich approaches into the deploying industry and the research and mission agencies.principle: undergraduate and graduate education in computer science should provide experience in working across disciplinary boundaries. graduate training grants and postdoctoral fellowships should support training in multiple disciplines. undergraduate and 6these shifts are already underway in various eldsšfor example, biocomputing. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 97graduate programs should include tracks that offer introductory and intermediate course work in such sustainability areas as lifecycle analysis, agriculture, ecology, natural resource management, economics, and urban planning.research institutionsšboth universities and the funding organizationsšcould better address the needs of authentic multidisciplinary research, in terms of publication venues, funding, criteria for promotion, research infrastructures that help enable sustained collaboration, and crosstraining. the latter include the crosstraining of students in multiple elds to enable them to bring a computer science perspective into other arenas. authentic multidisciplinary work is challenging.7 work will need to be done across disciplinary boundaries and incorporating experts from many disciplines, as well as individuals with deep expertise themselves in more than one discipline. examples of opportunities to enhance multidisciplinary approaches are described below: the creation of certicate programs, extension programs, and online programs for professionals in the target industries and agencies through professional societies and lifelong learning and training; scholarships and fellowships both for computer science graduate students and for earlycareer professors that provide nancial support for taking the time to develop expertise in a complementary discipline;the development of crossagency initiatives (such as the collaboration of the national science foundation [nsf] with the environmental protection agency8) that encourage interdisciplinary collaboration in relevant elds;support for the development of new, crossdiscipline structures (perhaps departments or institutes) between computer science and other elds that can create a new generation of students who are agile both in computer science and in elds relevant to sustainability;7for a discussion of some of the challenges, see sean eddy™s essay on ﬁantedisciplinaryﬂ science (public library of science, computational biology 1(1), doi: 10.1371/journal.pcbi.0010006), in which he notes: ﬁfocusing on interdisciplinary teams instead of interdisciplinary people reinforces standard disciplinary boundaries rather than breaking them down. an interdisciplinary team is a committee in which members identify themselves as an expert in something else besides the actual scientic problem at hand, and abdicate responsibility for the majority of the work because it™s not their eld.ﬂ8an example is the joint national science foundation/environmental protection agency establishment of two centers to study the environmental implications of nanotechnology, described in a 2008 press release: see http://www.nsf.gov/news/newssumm.jsp?cntnid=112234.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.98 computing research for sustainabilityinstitutional structures that support multidisciplinary and interdisciplinary teams focused on a problem or set of problems over an appropriately long period of time;9 internships and career paths and placement programs that encourage computer science students and postdoctoral researchers to work in relevant government agencies, nongovernmental organizations, and industries;coordination between academic research in computer science and nontraditional industrial partnersšthat is, beyond the large it companiesšto scope problems, help train students, and crossfertilize ideas; and regular, highlevel summits involving computer science and sustainability expertsšpractitioners and researchersšto inform shared research design, assess progress, and identify gaps and opportunities. the conceptualization of the bottomup emergence of universality is relevant to researchers, university systems, and funding agencies in the following respects:researchersšemphasizing a bottomup approach affects how researchers select and approach their problems and how they approach the training of their students. crosstraining, learning other languages and vocabularies, immersion, and intensive and sustained collaboration are all important aspects of how research will need to be done. although it may be essential to making real progress with respect to sustainability challenges, longterm commitment to a specic domain area is typically inherently risky for a cs researcher, because specic problems in sustainability may be addressed successfully but universal ideas or techniques may not necessarily materialize. university systemsša focus on bottomup approaches affects how universities incentivize and create the infrastructure for faculty to pursue sustained multidisciplinary efforts. the computer science community has made progress in tenure and in the promotion of individuals who straddle disciplinary boundaries. is such boundary crossing sufciently encouraged and explicitly incentivized? publication rates and pressures are higher than ever. publication is essential to a successful r&d ecosystem, but does an emphasis on frequent publication have a negative effect on the pursuit of r&d which tackles difcult application domains that have not previously been processed and translated into computer science problems? 9one successful example of such an effort was the collaboration between computer scientist james gray and astrophysicist alexander shalay on the multiyear effort (which, of course, involved many others) to develop the sloan digital sky survey (http://www.sdss.org/). computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 99moreover, much truly multidisciplinary work will require large teams and collaborations; is there appropriate recognition of cs contributions to large, multiauthor publications? also, an evaluation of the productivity of junior faculty may need to extend to evaluating the impact of the researcher in the realm of sustainability in addition to the eld of computer science. related to promotion is the question of appointmentsšin what departments are multidisciplinary researchers appointed, and how can such appointments be handled so that the multidisciplinary nature of the researchers™ work does not count against them in their home departments?funding agenciesšemphasizing bottomup approaches may affect how agencies structure multidisciplinary programs. the national science foundation is a primary funder of research in computer science in the united states. the former information technology research programs at nsf and its current cyberenabled discovery and innovation program have demonstrated the feasibility of programs with signicant multidisciplinary aspects and the impacts that can result. but such programs provide for a minority of cs research, and in the committee™s view, the sense of the community, as seen in review panels, program structures, review criteria, and so on, is not generally favorable toward funding domainspecic projects. one challenge is that typical reviewers of prospective research in computer science tend to want to see universality from the start, which presents a fundamental problem for the cs research community; funding agencies such as nsf can do little about this matter if the community does not adapt. the committee is encouraged by the establishment of science, engineering, and education for sustainability (sees) as an nsfwide area of investment. sees aims for a systemsbased approach to ﬁpromote the research and education needed to address the challenges of creating a sustainable human futureﬂ and places an emphasis on interdisciplinary efforts. with its emphasis on interdisciplinarity and the involvement of nsf™s directorate for computer and information science and engineering, the sees program offers an opportunity to demonstrate the depth of it and cs innovation that the core discipline can offer and the rich and globally important problem space of sustainability. there are ongoing opportunities for nsf to take advantage of the signicant domain expertise in other agencies in order to pursue a strategy broader than programs that are crosscutting with other research directorates within nsf. such a broadened strategy would involve programs that connect researchers with domain experts, practitioners, and projects in relevant mission agencies (such as the department of energy, department of transportation, department of the interior, and department of health computing research for sustainabilitycopyright national academy of sciences. all rights reserved.100 computing research for sustainabilityand human services).10 furthermore, it is critical to ensure that funding structures support data sharing, encourage citability, and so on, but at the same time, an emphasis on sharing should be balanced with the need for researchers actually to collect data and to begin solving problems.another role that funding agencies can play is to fund longerterm projects and to be tolerant of risk, particularly in these multidisciplinary and crossdisciplinary, potentially highimpact research areas. it may be useful to target special funds that encourage the switching of focus to sustainability challenges and to incentivize grounded, domainspecic collaboration and training.11 principle: rene funding and programmatic options to reinforce and provide incentives for the necessary boundary crossing and integration in cs research to address sustainability challenges. in particular, funding, promotion, and review and assessment (peer review) models should emphasize indepth integration with data and deployments from the constituent domains. principle: there should be strong incentives at all stages of research for focusing on solving real problems whose solution can make a substantial contribution to sustainability challenges, along with indepth metrics and evaluative criteria to assess progress.another critical issue for structuring research is to build in evaluation tools for prioritizing efforts and evaluating meaningful impact. the committee offers an evaluative framework below. evaluation, viability, and impact analysisone of the greatest challenges in multidisciplinary research is to establish evaluation metrics that are both actionable and meaningful across the constituent disciplines. this chapter concludes by identifying methodological opportunities for optimizing research outcomes and impacts. each of the recommended areas for evaluation necessarily incorporates 10an example of such a program is nsf™s industry/university cooperative research centers program.11an illustrative example is the national institutes of health mentored quantitative research development award (k25), which serves to fund quantitatively trained researchers so that they can learn about an area of biomedical science (see http://grants.nih.gov/grants/guide/pales/pa06087.html). these awards require the identication of a mentor in the substantive area and a plan for training; they provide funding for a commitment of at least 75 percent time.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 101interdisciplinary team members to assess accurately and to guide the potential for positive and signicant impact. one set of validation metrics would ensure that sustainabilityoriented efforts related directly to key components of sustainability and were making signicant progress on one or more of the legs of social, economic, and environmental impacts.12 specic metrics might include the following: metrics for analysis of environmental impact (life cycle, energy needed to create and execute a solution, as well as energy saved, and so on); metrics for analysis of economic impact (cost of implementation, resources used to create intervention, externalities); and metrics for equity and engagement across different stakeholder groups, taking into account their interests, values, and concerns, during both design and execution processes. many of these metrics involve humans, and so the assessment of research using such metrics will often involve techniques from the social sciences.13 they also involve techniques drawn from other elds, such as lifecycle analysis from civil and environmental engineering. any solution that claims to engage with and increase sustainability should be able to make an argument that addresses possible ways in which it may also negatively impact sustainability in any of its three overarching components (social, environmental, and economic). moreover, proposals for projects that aim to make an impact should include a lifecycle analysis, and such analyses should be accounted for in the projects™ budgets, as such analyses are a nontrivial effort to do well.scale analysis is critical to most information technology designs; it includes spatial scaling, temporal scaling, location scaling, and computational scaling. as demonstrated by the classic computer science talk 12as an example, although the challenges of sustainability are much broader than those related to climate change alone, in that domain a measurable impact is the goal of decreasing emissions so that carbon dioxide levels in the atmosphere are at or below a certain threshold. being as specic as possible in terms of the anticipated impact on sustainability is critical. more broadly, one might consider the areas addressed in lifecycle analysis: global warming, stratospheric ozone depletion, acidication, eutrophication, smog, terrestrial toxicity, aquatic toxicity, human health, resource depletion, and land use. see u.s. environmental protection agency, ﬁlife cycle assessment: principles and practice,ﬂ available at http://www.epa.gov/nrmrl/lcaccess/lca101.html.13this is a characteristic of much of the evaluation done in humancomputer interaction research and practice. also very relevant here are design methodologies and approaches that seek to account for human values: for example, value sensitive design, as discussed in b. friedman, p.h. kahn, jr., and a. borning, ﬁvalue sensitive design and information systems,ﬂ in p. zhang and d. galletta (eds.), humancomputer interaction in management information systems: foundations, armonk, n.y.: m.e. sharpe (2006), pp. 348372, reprinted in k.e. himma and h.t. tavani (eds.), the handbook of information and computer ethics, hoboken, n.j.: wiley (2008), pp. 69101. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.102 computing research for sustainabilityquestion ﬁbut does it scale?,ﬂ an early measure of the potential for the impact of a solution or system relates to scale. as sensors become more powerful (being able to measure many parameters at high frequency) and cheaper, a massive increase in the amount of data is expected. each step or component of a proposed solution should be designed to work at scale. however, scale has new connotations with respect to sustainability that must be considered. in particular, many of the most problematic phenomena involved in sustainability challenges play out over timescales that are difcult for humans to comprehend, and many of the solutions make sense only when applied at scale. here are some of the scalability questions that should be considered when evaluating a project:spatial scaling requires articulating the minimal scale that can have impact (for example, touch points or density, geographic coverage, and so on).temporal scaling incorporates realtime, humantime, and planningtime considerations; duration; timescale of relevance (onset, persistence, resilience); and the very challenging issue of addressing multiplehuman lifespan timescales.14location scaling addresses the applicability of the approach across a range of locationrelated contexts.computational scaling refers to the tractability of the problem in terms of data generated and in terms of the anticipated footprint of the approach with respect to energy and dollars expended.for each of these dimensions, the impact of a targeted innovation may well be difcult to quantify precisely. but it is the responsibility of the researcher at least to estimate and justify the anticipated, rstorder measurable savings and efciency improvements, or mitigated damages, from its realization. is the proposed approach fundamental infrastructure? a game changer? the introduction of new computing technologies and concepts should be coupled with impact assessment (positive and negative) and followup study/assessment along with plans to integrate and iterate learning. quantifying sustainability results as contributed by computational methods is a daunting challenge, especially given the current lack of data for realworld systems. focused efforts toward creating publicly available data repositories that could be used to compare the effect of methods on the performance metrics chosen may prove useful in some domains. without such data, there is little common ground for 14b. friedman and l.p. nathan, multilifespan information system design: a research initiative for the hci community, proceedings of the 2010 acm conference on human factors in computing systems, new york: acm press (2010), pp. 22342246.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.programmatic and institutional opportunities 103systematically comparing different methods and their potential benets. it is particularly important for researchers to estimate outcomes and for the community to develop ways to assess impact, as these steps may have a dramatic impact on whether or not an approach can be appropriated and applied in other contexts. conclusionmeeting the challenges of sustainability, as noted in chapter 1, will require more than information technology, applications of clever technology, and computer science research. indeed, at the heart of many global sustainability challenges are questions of resource consumption and standards of living. (see box 3.3.) nevertheless, the committee believes that box 3.3 toward an informationrich, sustainable futurenumerous analyses make clear that resource consumption is at the heart of many global sustainability challenges. at the same time, populations around the world are striving to improve their standard of livingšand despite the efciency improvements that also accompany development, that has inevitably meant increased resource consumption. efforts to improve efciencies and substitute more sustainable for less sustainable materials and methods are what underlie much of the discussion in this report. however, there may be a broader sense in which information technologies and computational approaches can alleviate or mitigate the problem. efforts to shift standardofliving metrics from resourceintensive to informationintensive have the potential to be a signicant lever in addressing global sustainability, although such shifts will increase the need for everﬁgreenerﬂ information technology solutions themselves. in an increasingly informationrich and carbonrestricted world, nding ways to use information so that it both enhances perceptions and realities of standard of living and reduces resource consumption will be critical. examples of shifting to informationrich, less resourceintensive lifestyles include adjustments to transportation practices such as: information infrastructures that transform the convenience and trust of shared and alternative transportation modalities instead of private automobiles; improved technology in vehicles; transportation displacement such as telecommuting, social media, and ecommerce; and so on.although such examples emphasize opportunities to shift what counts as improvements in the standard of living for individuals, ultimately it is the policy choices and decisions, at local, regional, and federal levels, that will determine how many, if any, of these shifts are possible. thus, organizational and governmental actions and decisions will have signicant impact on whether a shift to informationintensive choices can happen in order to produce a shift in the way that society operates, to engender more sustainable outcomes. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.104 computing research for sustainabilitycs and it research has deep and fundamental contributions to make to these challenges. this chapter has argued for a bottomup approach to research that values applicationdriven results while also supporting the iterative process that eventually leads to more universally useful contributions. the committee has argued for a series of validation metrics that explicitly explore the true impact of a piece of work in the arena of sustainability. such validation metrics should include those that deal directly with humans, economics, and ecosystems and those metrics that engage with the concept of scale (a good rstorder proxy for the universality that may not yet be present).information technology is at the heart of nearly every largescale socioeconomic systemšnancial systems, manufacturing systems, energy systems, and so on. one important consequence, which has been the focus of this report, is that advances in it have become critical enablers of change in these systems. the goal of this report has been to shine a spotlight on areas where information technology innovation and computer science research can help, and to urge the computer research community to bring its approaches and methodologies to bear on these pressing global challenges.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendixescomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.asummary of a workshop  on innovation in computing  and information technology  for sustainability introduction on may 26, 2010, the committee on computing research for environmental and societal sustainability held the workshop on innovation in computing and information technology for sustainability in washington, d.c. the goal of the workshop was to survey sustainability challenges, current research initiatives, and results from previously held topical workshops and related industry and government development efforts in these areas. the workshop featured invited presentations and discussions that explored research themes and specic research opportunities that could advance sustainability objectives and also could result in advances in computer science (cs). participants were also asked to consider research modalities, with a focus on applicable computational techniques and longterm research that might be supported by the national science foundation (nsf), with an emphasis on problem or userdriven research. this appendix summarizes the discussion of the workshop panelists and the attendees. the summaries of the four workshop sessions provided in this appendix are a digest both of the presentations and of the subsequent discussion, which included remarks offered by others in attendance. although this summary was prepared by the committee on the basis of workshop presentations and discussions, it does not, in keeping with the guidelines of the national research council on the development of workshop summaries, necessarily re˚ect a consensus view of the committee. 107computing research for sustainabilitycopyright national academy of sciences. all rights reserved.108 computing research for sustainabilitythe sessions at the workshop were entitled: session 1: expanding science and engineering with novel cs/it methods: ﬁthe need to turn numbers into knowledgeﬂ; session 2: understanding, tracking, and managing uncertainty throughout the sciencetopolicy pipeline;session 3: creating institutional and personal change with humans in the loop; session 4: overcoming obstacles to scientic discovery and translating science to practice. the workshop agenda is provided at the end of appendix a. session 1: expanding science and  engineering with novel cs/it methods:  ﬁthe need to turn numbers into knowledgeﬂ discussions during the rst session of the workshop focused on the role of computer science in helping solve sustainability challenges. a broad denition of sustainability was employed. vijay modi, columbia university, provided examples of sustainability areas where computer science could help address some challenges; robert pfahl, international electronics manufacturing initiative, discussed changes in electronic systems and products to improve sustainability; neo martinez, pacic  ecoinformatics and computational ecology lab, explored the role of computer science in improving ecological sustainability; adjo amekudzi, georgia institute of technology, examined planning and management issues around infrastructure; and thomas harmon, university of  california, merced, discussed water challenges.following are examples given of the ways in which computer science can play a role in addressing sustainability challenges:urban electricity consumption. gathering negrained accurate measurements and statistics on energy usage of individual buildings can be difcult, due in part to the variety and diversity of building types. with better measurements, one could develop a useful model of energy usage over the course of a day and nd opportunities, for instance, to store extra energy throughout the day for use at peak times. infrastructure planning. the planning and development of effective infrastructure are very difcult to do at scale for the time span required. compounding these challenges is a dearth of data on how and where people actually live and what their movements are throughout the day. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 109this limited knowledge of the movement of people and the limited understanding of where infrastructure needs exist make it difcult to plan infrastructure accordingly. advances in remote sensing, to improve understanding of the use of current infrastructure, can help cities and utilities to formulate better infrastructure planning. clean water. access to clean water is an ongoing and increasingly challenging problem worldwide. one of the more difcult components of this challenge is detecting water below the surface of earth. although detection of water at and just below the surface is well understood, technology for nding water at deeper levels is limited. better sensing technologies are needed to help differentiate between sand, wet sand, water that is ˚ooding the sand, and so on. the examples above are a just a few of the areas in which computer science has contributions to make to sustainability. workshop participants examined a wide array of sustainability challenges in which specic cs/information technology (it) advances could contribute to resolving these challenges. in many cases, it is a matter of developing new approaches for turning raw data (numbers) into knowledge and, ultimately, prompting action that results in more sustainable outcomes. research opportunities cited by workshop participants in the areas of ecological sustainability (that is, relating to diverse and productive biological systems), transportation, and water resources are described below, along with associated computer science challenges. the rst session concluded with a brief examination of the policy challenges of interdisciplinary work and of turning knowledge into actionable items. electronic systems and products and sustainabilitythe international electronics manufacturing initiative (inemi) is a consortium of electronics manufacturers and afliates focused on environmental issues in electronics.1 every 2 years, inemi creates a roadmap that charts future opportunities for and challenges to electronics manufacturing for reaching sustainability objectives.2 the inemi efforts began by focusing on hazardous materials. the early goals of the consortium were aimed at eliminating chloro˚uorocarbons from the cleaning of electronics, removing lead from electronics, and reducing the use of halogenated ˚ame retardants and polyvinyl chloride (pvc) materials. more recently, the focus has been on the complete energy use of products, as discussed 1a list of inemi members is available at http://www.inemi.org/news/councilmembers. 2the 2011 inemi roadmap is available at http://www.inemi.org/2011inemiroadmap. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.110 computing research for sustainabilitybelow. sound scientic methodologies are needed to take into account total tradeoffs among con˚icting device requirements and to model longterm reliability and life of these devices.products that are recyclable, use nonhazardous materials, or minimize the use of energy and matter tend to be less harmful for the environment. often there are tradeoffs among these concerns. for example, using fewer hazardous materials may increase the resources needed to manufacture a certain type of equipment. when considering the size of items, there is often a tradeoff of size for function. for example, cellular telephones have grown larger in recent years as functionality has increased. this matters especially with regard to calculating potential waste over a product™s entire life cycle, although in the case of cell phones, the increased functionality may mean that other, even larger devices are no longer needed. digitization is another example in which the functionality of electronics has decreased the amount of hardware needed. as digital music players have become more ubiquitous, compact disc playersšand discsšare becoming less and less necessary. lifecycle analysis is key to understanding the complete energy use of products, including the energy used in mining raw materials, producing semiconductors and other components, assembly, transportation, and, ultimately, consumer use of the product. computing research can assist in the tracking and understanding of all of these inputs throughout the life cycle of products. ﬁgreen computingﬂšmaking computers themselves more environmentally friendlyšplays a role in the reduction of energy consumption. for example, basic assumptions about computers™ operating environments can be rethought, to yield signicant energy savings. the 2011 inemi roadmap recommends that server farms and machines be redesigned so that the temperatures of server rooms can be increased in order to reduce the amount of energy required for cooling.participants noted that a holistic approach to technology is needed to contribute further to sustainability in electronics. continued work in the following areas is needed: in digital semiconductor technology, work is needed in order to increase density and reduce cost; in the incorporation of sensor networks, work is needed to provide detailed energyuse data; in electronic packaging technology; and in innovation in cs and it algorithms and applications. additionally, participants suggested that standards may play an important role here.ecological sustainabilitythreats to ecological sustainability include loss of biodiversity, species extinction and invasion, and the exploitation of ecosystems. each of computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 111these threats has consequences for the robustness, resilience, and stability of the respective ecosystems. computer science can play an important role in enhancing the understanding of the consequences to ecosystems of particular courses of action by assisting in measuring the current impacts of actions and predicting future impacts on these ecosystems. databases play a crucial role in the understanding of ecosystems. for example, the global exvessel fish price database of the fisheries economics research unit is a valuable, large data set.3 the database provides information on hundreds of types of sh and their market prices over an extended period, thus enabling a better understanding of conditions in the oceans and of the potential effects of shing. computing will also play a vital role in helping researchers and decision makers understand collected data, which come from a variety of sources. hardware and software will be needed to help analyze large sets of heterogeneous data. advances in modeling and simulation will also contribute to the understanding of the information collected. ecological networks are complex, highdimensional, nonlinear systems. therefore, simpler mathematical representations are not adequate. ecological systems need to be simulated over time. participants noted that currently, the various time series and relevant data for the simulation of an ecological system can only be summarized. more accessible data including quantitative information from simulations is needed so that others can use the data and contribute to the work. some of the challenges created by large, heterogeneous data sets and researchers™ resource limitations have been resolved with remotecomputing capabilities (currently referred to as cloud computing). the shared resource of cloud computing can allow for simulations to be run much faster. additional advances are needed so that data simulations can be stored easier and computing power can be more easily shared. interdisciplinary research on networks has led to a greater understanding of food webs and other ecological systems. for example, paleontological food web analysis has provided a better understanding of the network structures of current food webs.4 gaining an understanding of food chains on the globe over vast timescales can help provide researchers with a sense of how some kinds of ecosystems evolved. if economic 3the global exvessel fish price database and its various uses are described in u. rashid sumaila, dale marsden, reg watson, and daniel pauly, global exvessel fish price database: construction, spatial and temporal applications, fisheries centre working paper #200501, vancouver, b.c., canada: university of british columbia (2005).4the pacic ecoinformatics and computational ecology lab has done much of the work related to paleontological food web analysis. a list of its publications is available at http://www.foodwebs.org/.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.112 computing research for sustainabilityinformation to account for things such as price and biomass can be incorporated into models based on the understanding of modern food webs, the effect of economic exploitation on ecological systems can be better understood. for example, in a simple threespecies food chain (such as large sh eating small sh eating plants), adding economic information to the model also allows for a separation of the effects of exploitation by humans for economic reasons from the effects of human exploitation for the purpose of subsistence. participants discussed how networkbased analyses might be useful in other areas of sustainability. rules derived about ecological networks, for instance, may also apply to energy and economic networks. can useful comparison be made between economic and food networks? does food function like money in any sort of actionable way? computingenabled ﬁcitizen scienceﬂ provides ways for volunteers to collect and report information from their own environments and to contribute to the sustainability of those environments. citizen science programs have existed since the early 1900s, beginning with the audubon society™s christmas bird count.5 now, new mobile technologies and social networking tools make collecting and reporting much easier. volunteers can easily collect data, for example, on a particular invasive species and send the information to experts to examine. transportation and social sustainabilityparticipants discussed the connections between traditional measures of sustainability, which may typically be functions of space and time, and measures of social sustainability. with social sustainability, as shown in figure a.1, the sustainability footprint becomes the rate of change of quality of life as a function of one™s impact on the environment. participants argued that social sustainability can be and needs to be more rigorously accounted for in discussions about other forms of sustainability. social sustainability can be considered when looking at transportation sustainability, for instance. denitions of ﬁtransportation sustainabilityﬂ typically focus on moving items (people, goods, and information) in ways that reduce the impact on the environment, economy, and society. transportation plans have been required in all major metropolitan areas since the 1960s. although customer satisfaction has been included in transportation planning for some time, assumptions regarding customer needs are often incorrect. traditionally satisfaction has been seen as a 5for information on and a history of the audubon christmas bird count, see http://birds.audubon.org/christmasbirdcount.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 113linear function of performance: for example, if a road is twice as smooth, customers are supposedly twice as happy. research in this space has found, however, that this curve does not apply to all performance attributes. gains in positive performance often have less of an impact on satisfaction, whereas reductions in negative performance are often more important to customers. in this case, to build transportation plans that are sustainable both in the traditional sense and socially, customer satisfaction data, both subjective and objective, need to collected and woven into these plans. data need to be collected on a wide range of attributes (safety, quality of life, smoothness), on the relative importance of the different factors, and on how customers rate the different attributes. such information allows planners to distinguish between performance improvements that have positive and negative effects on quality of life and to negotiate the tradeoffs between the two. figure a.1 achieving quality of life within the means of nature. source: jamie montague fisher and adjo amekudzi, quality of life, sustainable civil infrastructure, and sustainable development: strategically expanding choice, journal of urban planning and development 137(1):3978 (2011). reprinted with permission from the american society of engineers.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.114 computing research for sustainabilitycomputer science can contribute to such efforts by developing effective systems for collecting data from the public and providing better dataanalysis tools to help, for instance, in the assessment of different choices regarding routes and other planning decisions. realtime data processing and tools for planning and forecasting transportation needs can help urban planners and decision makers balance economic and policy challenges in planning future infrastructure. sustainable sources of watercomputer science research can help with the complicated problems of nding, tracking, and monitoring the sources of, need for, and sustain able use of water. better sensors for measuring, better models for analyses, and better algorithms for optimization are all areas in which cs research can contribute. for example, more hydrological data and better models could help scientists to create a virtual watershed that would allow for quick studies of impacts and could potentially enable forecasts of the amount and quality of water available, much like weather forecasts.in addition to creating virtual watersheds for analysis, areas in which improvements in cs and it are needed in order to add to the understanding of water resources include the following:remote sensing. because it is not feasible to have sensors everywhere, models will continue to be important. research is still needed on modeloriented science. sensors, however, can be used to calibrate and netune these models. a multiscale observation network can combine coarsegrained collection with more densely nested sensors deployed at a smaller scale. hyperspectral signal processing. a wealth of information can be garnered from the re˚ected visible and nonvisible energy from plants and water. although much has already been learned from analyzing this information, more can be learned through a better understanding of the re˚ective spectrum patterns. spatial analyses. geographic information systems (gis) and spatial analysis could be used for novel recognition and classication techniques and to identify the characteristics of an ecosystem. gis imagery could also be used to detect shifts in an ecosystem.heterogeneous data integration. data combined from embedded sensors in rivers and from satellite images could provide a valuable picture of resources. work˚ows. tools are needed that are adept at scraping data from a variety of sources and combining them with spatial data repositories. the software tools could create input les and capture the history of simulacomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 115tions so that researchers need not start from scratch. see the discussion in the section entitled ﬁscientic work˚ows,ﬂ below.computation. nontrivial optimization tools are needed in order to search for solutions to sustainability problems and to manage tradeoffs. powerful computing is needed to facilitate the scaling up of systems and to couple these with other contributing factors (economics, subsistence, and so on).policy shiftsalthough the solving of computing challenges will be one bridge to reaching further sustainability goals, challenges in interdisciplinary partnerships and in turning research into action and policy will need to be addressed as well. participants noted that the traditional ways of building models tend to be incredibly timeconsuming and isolating. steps include the following: collecting the data, archiving the data, and selecting an individual (typically a doctoral student) to learn the model and then to deploy the model. a result of such an endeavor tends to be that several years later, only one person knows how to use the model effectively. some progress might be achieved in this way, but to have a larger impact, computing support involving large data sets and complicated work˚ows will be needed. but such progress can only take place as far as unique partnerships across disciplines will push it. participants noted that there tends to be a limited connection between the cs researchers and domain practitioners. more and better communication between the eld and the laboratory could inform more useful research.better partnerships with computing and software experts could move research toward higherimpact results more quickly. as noted throughout the workshop, science and engineering are becoming increasingly dependent on software development. fostering close collaboration between software experts and domain scientists is likely to be more effective than forcing domain scientists to learn advanced software engineering. in addition to the computing research opportunities discussed above, participants urged that shifts be made in how research is translated into policy and action. more bridges need to be built between computer scientists and other disciplines, between researchers and practitioners, and between the academic and the industrial and the consumer settings. technology from academic laboratories needs to move more quickly to the industrial and consumer world. this change would require collaboration and coordination at the research and development (r&d) level and the intervention of the research supply chain. with fewer and fewer  industrymanaged research labs, participants suggested that there has been a reduction in the integration of research and consumer products computing research for sustainabilitycopyright national academy of sciences. all rights reserved.116 computing research for sustainability(of the sort that used to exist at bell labs) and that collaboration tends not to happen as smoothly. this lack of collaboration may prevent new technologies that would improve sustainability from reaching consumers.furthermore, planning and design are frequently done by economists, urban planners, and other decision makers, not by domain scientists or sustainability experts. participants noted that these domain scientists need to be part of the process in order to provide feedback and more timely data, and they urged that academics more actively engage with policy makers.session 2: understanding, tracking,  and managing uncertainty throughout  the sciencetopolicy pipelinewhen scientic information is provided to decision makers by the scientic community, explicit representation of uncertainty is rare. the loss of uncertainty information along the sciencetopolicy pipeline begins with the initial measurements, which may be recorded into databases just as numbers and without any additional information on how the data were captured or intercepted. from such a data set one might produce a predictive map, and any uncertainty that was captured may then be lost by means of an optimization process. workshop participants noted that outputs from predictive and simulation models are often treated as exact or overly precise and accurate during policy making. in the end, without careful consideration of uncertainty, policy and decision mechanisms cannot be expected to achieve results. the goal of the second session of the workshop was to explore some of the computational methods available to address loss of information about uncertainty, to consider what additional methods are needed, and to outline a potential research agenda. panelists were asked to examine the following questions in relation to sustainability challenges during their talks: what are the sources of uncertainty that should be explicitly captured?what methods are suitable for explicitly representing uncertainty?is the technological state of the art sufcient to model the many different ˚avors of uncertainty present in largescale sustainability problems? if not, what characterizes the types of uncertainty that are insufciently modeled? what methods are suitable for assessing uncertainty in each stage of the pipeline? what shortcomings need to be addressed?computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 117is the state of the art in human factors, interfaces, and computersupported cooperative work sufcient to support the largescale systems, models, and data sets that are necessary to tackle largescale sustainability problems? if not, what needs are unmet? what are the appropriate techniques for working with uncertain data in data fusion, data assimilation, predictive modeling, simulation modeling, and policy optimization?how can explicit uncertainty representations be integrated into scientic work˚ow tools?are there alternatives to explicit uncertainty representations that can improve the robustness of management policies to all of these sources of uncertainty?chris forest, pennsylvania state university, provided information on the sources of uncertainty and the tracking of uncertainty in climate models; peter bajcsy, national institute of standards and technology, discussed the development of scientic work˚ows for tracking uncertainty through the science process; david brown, duke university, highlighted new methods for optimization problems under uncertainty; and john doyle, california institute of technology, explored theories for analyzing ﬁrobustyetfragileﬂ systems.assessing uncertainty in climate modelsassessment and understanding of climate change and its impacts are critical to meeting many sustainability challenges. scientists use a variety of techniques, including a variety of climate models, to assess and understand climate change. the potentially high impact of climate change means that policy makers are faced with hard choices, including but not limited to the reduction of emissions, adaption to climate change, and/or geoengineering that might help mitigate the effects of climate change.6 participants discussed the role of uncertainty in the development and understanding of climate models. scientists working on the problem of climate prediction must also address uncertainty. this could be done using a work˚ow plan that captures uncertainty information at each stage of the climateprediction process. within each stage, there are data, a model, predictions, assessment of likely impacts, and decision making. at each point there are sources of uncertainty that have to propagate 6national research council, america™s climate choices, washington, d.c.: the national academies press (2011).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.118 computing research for sustainabilitythrough the system, ultimately leading to an estimate of the probability of the outcomes. uncertainty analysis is driven by multiple goals, including the mitigation of climate change, adaption to changing environmental conditions stemming from climate change, and vulnerability assessments. assessing uncertaintythere are two types of uncertainty in climate models: structural and parametric. (the level of uncertainties within each model creates a hierarchy of climate models, as described in box a.1. box a.2 then presents data summarized from the highly complex models used by the intergovernmental panel on climate change [ipcc].) structural uncertainty stems from the hierarchy of models and attempts to balance the speed of the model with the complexity and components of individual models. models take signicant time to build; their complexity increases as more components are added. modern tools and approaches in software systems, such as modularity, are important in creating current models. however, several of the models were built in the 1960s and 1970s before these tools existed. for example, participants observed that it is not possible to do comparisons between several of the older models, such as that of the united kingdom™s met ofce hadley centre and the national center for box a.1 hierarchy of climate modelsthe rst climate change assessments were done using the global energy balance model. over the past 50 years, a number of additional types of climate models have been developed, creating a hierarchy of climate models. each model typically has ve major componentsšatmosphere, ocean, ice, land, ecosystems, and human actionšand each component can be incorporated at various levels in the models, making the models signicantly complex. the most basic of the models is the energy balance model, which is very fast to run but lacks a lot of detail. in terms of complexity, the next level up includes earthsystem models of intermediate complexity (emics), which are reasonably fast and able to explore feedback and uncertainty. fifteen years ago, the massachusetts institute of technology created one of the rst emics, which included all of the major components listed above. the model is very fast and can explore feedbacks between systems, is ˚exible enough to do uncertainty analysis, and can propagate uncertainty through the different stages. at the next complexity level are the atmosphereocean general circulation models and earthsystem models, which are used by the intergovernmental panel on climate change (ipcc) (and from which the data for box a.2 were drawn).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 119atmospheric research™s community climate model, or the geophysical fluid dynamics laboratory climate models, by swapping in different components from each model; the software is too in˚exible. parametric uncertainty encompasses the adjustable parameters in a particular model. model complexity and model expense limit the ability to do a full sampling of the parametric uncertainty space. there are numerous uncertainties in each modelšthose in observations, those stemming from box a.2 climate change observations and climate model hindcasts figure a.2.1 figure a.2.2figure a.2.1 shows a summary of the output from intergovernmental panel on climate change (ipcc)class atmosphereocean general circulation models that were run for the fourth assessment report of the ipcc. the widest bar represents the prediction of climate change of the 20th century, with the range of values representing 20 different climate models. the lowest bar represents predictions for the same models if anthropogenic climate forces are not included. the black line is observed temperatures. the comparison of these two lines provides the capability to assess the ability of the models to predict history. figure a.2.2 moves the models to the regional or continental level. the widest band, which represents the uncertainty in the predictions, widens. the bands still match the observational records, but this comparatively crude set of graphics typies the extent to which uncertainty information tends to be portrayed to policy makers. source: intergovernmental panel on climate change (ipcc). summary for policymakers, in . contribution of working group i to the fourth assessment report of the intergovernmental panel on climate change (s. solomon, d. qin, m. manning, z. chen, m. marquis, k.b. averyt, m. tignor, and h.l. miller [eds.]), cambridge, united kingdom: cambridge university press (2007).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.120 computing research for sustainabilitynatural variability in the climate system, and those in the model components themselves. as each of these parameters is added to the model, the model becomes less ˚exible. various techniques have been tried for incorporating each of the uncertainties. however, these techniques have limited use because building adjunct models is as complicated as building a climate model itself.example: integrated global system modelthe massachusetts institute of technology™s (mit™s) integrated global system model (igsm) (figure a.2), a coupling of a human systems model and earthsystem model, illustrates how uncertainty analysis is being applied to climate models.7 the model uses several components: human activity; atmospheric, ocean, land, and ecosystem interactions; and biogeochemical exchanges. the model also runs comparatively fast. the following uncertainties are included in the igsm: emissions uncertainty from mit™s economic, emissions, and policy cost model; climate system response (climate sensitivity,8 rate of heat uptake by deep ocean, and radiative forcing); carbon cycle uncertainty; and trends in precipitation frequency. climate sensitivity and ocean heat uptake, part of climate response, are a large source of uncertainty. observational data can be used to calculate a probability distribution for climate sensitivity and the rate of ocean heat uptake. this calculation can be included in the mit igsm, and researchers can examine the resulting probability distribution of global average surfacetemperature changes. explaining these uncertainties to decision makers is also a challenge that computer science may be able to help with. for example, researchers have compared the resulting global average surface temperatures with no greenhouse gas (ghg) policy intervention, or businessasusual policies, and the resulting global average surface temperatures from implementation of ghg policy that limits carbon dioxide (co2) concentration to about 550 parts per million. to communicate the resulting difference in temperatures and the probability of the prediction, researchers created the 7a.p. sokolov, c.a. schlosser, s. dutkiewicz, s. paltsev, d.w. kicklighter, h.d. jacoby, r.g. prinn, c.e. forest, j.m. reilly, c. wang, b. felzer, m.c. sarom, j. scott, p.h. stone, j.m. melillo, and j. cohen, mit integrated global system model (igsm) version 2: model description and baseline evaluation, joint program report series (july 2005), available at http:// globalchange.mit.edu/research/publications/696.8 ﬁclimate sensitivityﬂ is the measure of how responsive the temperature of the climate system is to changes in radiative forcing; it is usually represented as the temperature change associated with a doubling of the concentration of carbon dioxide in the atmosphere. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 121greenhouse gamble roulette wheels (figure a.3). this gure allows easy communication of prediction and uncertainty to decision makers.potential contributions by computer scientistsuncertainty analysis at the global scale is reasonably well understood, but increasingly there is a need to understand uncertainty at the regional and local scales. a better understanding of regional impacts of climate figure a.2 massachusetts institute of technology™s (mit™s) integrated global system model. note: carbon dioxide (co2); methane (ch4); carbon monoxide (co); nitrous oxide (n2o); nitrogen oxides (nox); sulfur oxides (sox); ammonia (nh3); chloro˚uorocarbon (cfcs); hydro˚uorocarbons (hfcs); per˚uorochemicals (pfcs); sulfur hexa˚uoride (sf6); volatile organic compounds (vocs); black carbon (bc). source: a.p. sokolov, c.a. schlosser, s. dutkiewicz, s. paltsev, d.w. kicklighter, h.d. jacoby, r.g. prinn, c.e. forest, j.m. reilly, c. wang, b. felzer, m.c. sarom, j. scott, p.h. stone, j.m. melillo, and j. cohen, mit integrated global system model (igsm) version 2: model description and baseline evaluation, joint program report series (july 2005), available at http://globalchange.mit.edu/research/publications/696. reprinted with permission. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.122 computing research for sustainabilitychange allows for better management of water resources, ecosystem changes, and air quality issues. the climate modeling community does not currently have the tools to sample the models for regional uncertainty information. computer scientists are needed, for instance, to help determine what parameters in the climate system are driving uncertainty at the regional level, which are not the same parameters that drive uncertainty at the global level.as noted in the section above entitled ﬁassessing uncertainty,ﬂ several models are quite old. simulation code dates back to the 1960s and 1970s, much of it written in fortran. this code needs to be redesigned to take advantage of advances in computing language, software modules, and interoperability. expert decision making is imperative to the climate modeling process. although researchers seek to be as objective as possible in examining data and determining probability, the number of systems involved means that much calibration is done by hand. experts must identify and rank uncertainties at each stage of the process, but experts have limited knowledge and will focus on what is known, while the edges and boundaries of the modeling system may be left unexplored. figure a.3 the greenhouse gamble. uncertainty can be represented by roulette wheels: (left) what could happen if no policies are adopted to lower greenhouse gas (ghg) emissions; (right) what might happen if ghg reduction policies are enacted. the size of each slice represents the probability that the coordinating temperature change will happen. source: massachusetts institute of technology joint program on the science and policy of global change, available at http://globalchange.mit.edu/. reprinted with permission.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 123scientic work˚owsparticipants discussed the typical nature of scientic work˚ows and the importance of uncertainty analysis to their effectiveness. uncertainty information about data collected and generated for analysis is often unavailable. when it is available, there are no standardized data structures for sharing and managing this information. due to the complexity of uncertainty modeling, there are very few software tools that can incorporate, compute, and propagate uncertainty information. if information regarding uncertainty can be propagated somehow, there are still challenges in visualizing and disseminating the uncertainty information.one example of the difculty of tracking uncertainty is in the use of multiple sensing and datacollection instruments. often more than one type of instrument, such as a camera and a point sensor, is used in the same area or space to measure the same phenomenon. a question then arises: which measurement is more accurate, where, and at what time? using multiple instruments introduces several types of uncertainty, including that related to the transformation that researchers apply in order to display measurements, that related to spatial registration, and that related to the temporal synchronization. in order to grapple with these uncertainties, a theory of uncertainty is developed on the basis of a formalized framework that describes how to compute uncertainty. researchers select a measurement based on the uncertainty level of each type of uncertainty. as the uncertainty framework is built and used, the error propagation rules and methodology allow one to build work˚ows that can be applied to future models and calculation. a second example of the difculty of tracking uncertainty is in managing and tracking data. data often come from a variety of sources and are then processed by various computing techniques. as data move from analog instrumentation to a visual representation of research ndings, uncertainty generally increases. for example, visualization features may be derived or elevation and/or slope may be computed. moreover, there may be many users of the collected data, and each one may be using a different suite of software tools to process and analyze the data. these examples provide some sense of the complexity involved in tracking and accounting for uncertainty. some lessons become apparent. first, uncertainty information is vaguely dened; typically it is either a range or a distribution set. second, the complexity of uncertainty modeling using error propagation is greater than that of the underlying phenomenon itself. third, and most importantly, scientic work˚ows are suitable for managing uncertainty modeling; software modules could be reused and could track how collected data are being manipulated. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.124 computing research for sustainabilitydening work˚owsthe traditional objective of scientic work˚ows is to automate a science process leading to a science product, usually a data set or a visualization. work˚ows make it easier for scientists to manipulate, communicate, and reuse or repurpose data sets. work˚ows also allow the computation to be done locally, or, when managing especially large or complicated data sets, scientists can take advantage of remote computational resources. as noted earlier, work˚ows can be used to track and manage uncertainty propagation and need to become part of the general scientic infrastructure. capturing the work˚ow and managing the computation are particularly useful if all of the calculated information, including uncertainty information, can be delivered to third parties and end users. work˚ows can become a communication mechanism for the management of uncertainty. using dynamic visualization and the sharing of work˚ows, scientists can more readily engage policy makers. work˚ows can be designed with sharing in mind. for example, social media concepts such as tagging and networking can be incorporated into the designs of work˚ows, making them more accessible.research questions and challengesseveral open questions regarding the tracking and managing of uncertainty will have to be addressed before these uncertainties can be effectively calculated and, importantly, communicated using scientic work˚ow mechanisms. these include the following:how can uncertainty and information loss due to data translations best be captured? how can provenance information about uncertainty methods and parameters best be gathered automatically during computations? how can uncertainty best be propagated in computation work˚ows, or perhaps, how can uncertainty propagation rules best be offered for software tools without such rules?how can uncertainty best be delivered and presented to decision makers, who may require a customizable view so as to increase its effectiveness, as well as a universal viewer for other interested parties, who may require more widely accessible information?can work˚ow services managing the uncertainty be integrated with other web services, such as mapping or sharing tools, to deliver uncertainty to scientists and policy makers?participants argued that a cs research agenda for sustainability needs to support research on the representations and propagation of uncertainty. in the past there has been little information on uncertainty. concomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 125tent managers should be encouraged to include uncertainty with data, use work˚ows to manage and track uncertainty, and incorporate other informationsharing services, ultimately leading to better information on which decisions can be made.robust optimization under uncertaintyoptimization has progressed rapidly in recent decades due in part to the rapid improvement of computer systems generally and to the development of increasingly sophisticated algorithms. the solving of largescale, linear problems, with millions of variables, is computationally feasible. however, the inclusion of and calculations regarding the uncertainty in these optimization problems is still a challenge. for policy decisions, for instance, models and calculations are run many times, and changes are made during each iteration. because uncertainty has to be calculated at each iteration, running models that include uncertainty is extremely inefcient. the goal is to make accounting for uncertainty computationally tractable so that each model can be run faster and more efciently. robust optimization is one method for coping with uncertainty in optimization problems. robust optimization provides computational tractability and supports parsimonious modeling demandsšone does not have to worry about the specics of probability distribution. robustness is an inherent and essential feature of many important methods across many disciplines, including machine learning and decision theory.robust optimization is different from sensitivity analysis. although robust optimization and sensitivity analysis are motivated by similar factors, sensitivity analysis is a postoptimization tool; if robustness is ensured beforehand, solutions will not be overly sensitive. robust optimization is also sometimes considered too conservative. the conservativeness relates to the uncertainty set that is used and on how large it is. an improved datadriven theory of optimization is needed. there are many approaches to building uncertainty sets, but there is the open theoretical question regarding the right way to use data in optimization problems. in some problems, when there are not enough data, the questions become these: how does one properly incorporate subjective opinion about the data? what is the right way to describe uncertainty? an additional challenge is that idealized problems tend to be studied without enough application to realworld problems. there is also the challenge of ensuring that uncertainty is acknowledged and taken into account in any decisionmaking process. theory and methodology of robustyetfragile systems analysis participants noted that fundamental research is needed to improve the understanding of the various tradeoffs in computational methodologies, computing research for sustainabilitycopyright national academy of sciences. all rights reserved.126 computing research for sustainabilitysuch as efciency versus robustness. complexities of real systemsšnot the complexity of the mechanisms used to study the systemsšembody these tradeoffs. some theories already exist for examining the tradeoffs among robustness, fragility, and efciency. for example, researchers know that efciency has hard limits and is bounded. robustness and fragility have conservation laws as well, and the tradeoffs between the two are tangible. theories from other disciplines, including systems engineering, control theory, information theory, and computational complexity theory, provide complementary approaches and can be integrated into theories on robustness, fragility, and efciency. efciency and robustness exist in many dimensions, and although each in itself is reasonably well understood, a theoretical framework is needed for conveying the interactions and examining the inherent tradeoffs. firm tradeoffs exist among the following:efcient use of resources (sustainability) š small amounts of resources consumed, small amounts of waste produced. šinexpensive components, small capital investment. š efcient processes: design, manufacture, maintenance, man agement.robustness to perturbations š rejection of external disturbance and suppression of internal noise. štolerance for component failures and uncertainty. šsecurity against malicious attack and hijacking. šscalability to large system size. ševolvability on long timescales to large changes. šhuman actors with aligned incentives.predictable, veriable, understandable šlimits on unintended consequences. šeasily reproducible experiments and data. šmodels (simple and analyzable), short theorems, proofs. šexperience that is a reliable guide to the future.9one can start building toward a theory with comparisons across disciplines. although efciency limits are understood, it is very difcult, if not impossible, to reach 100 percent efciency rates. by contrast, robust fragility is much less understood. robustness in one part of a system may induce fragility in another. fortunately, evolvability and robustness seem 9john doyle, ﬁtheory and methodology of robustyetfragile systems analysis,ﬂ presentation at the workshop on innovation in computing and information technology for sustainability, washington, d.c., may 26, 2010.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 127to be compatible. architectures and platforms that enable innovation well can also enable robustness well. examples were discussed of how new theories can be developed to encompass needed robustness requirements. network theory might be able to help sort out what is an accident of similarity and what is deeply structural. however, the fact that reasonably well understood networks exist in one domain does not mean that these understandings translate well to another domain. there may be useful knowledge to be gained by comparing network structures and properties in different domains (for example, contrasting and comparing climate history, cell systems, and internet architectures), but this knowledge needs to be validated rst. additionally, participants noted that a better understanding of what is meant by complexity, nonlinearity, modularity, architecture, and evolvability in different domains is needed so that scientists can communicate more effectively with policy makers and with one another. furthermore, big data and big models mean that many things can be demonstrated by means of data or models. as computational capacity has increased, in many ways research efforts have moved from coping with impoverished data and elegant models that are not well understood to coping with massive data sets and sophisticated simulations that are not well understood. in this new environment, larger gaps between the demonstration and the reality can be unintentionally created, and unanticipated fragilities may become overwhelming.session 3: creating institutional and  personal change with humans in the loopbehavioral changes at both the institutional and the individual level are needed in order to achieve sustainability objectives. important questions in designing and developing smarter systems involve the level of information and the interface design that will induce behavior change. humansystem interaction (hsi) issues arise both for individuals in homes and ofces and for administrators of larger systems and facilities. these interactions can occur at different timescales, encompassing both daytoday decisions made by users and operators and planning decisions involving longer periods of time. moreover, although there have been many advances in hsi, the literature is replete with failed cognitive models, serving as cautionary tales for hsi in sustainability applications.panelists were asked to examine the following questions in relation to sustainability challenges during their talks: computing research for sustainabilitycopyright national academy of sciences. all rights reserved.128 computing research for sustainabilityhow can data and information be presented at the appropriate granularity and time frame to be most effective? what system, application, and user factors bear on the humansystem interaction design choices? describe the potential impacts of the various contexts and tradeoff decisions that might need to be made, including the following: the impact of context (e.g., stakeholders, and so on), the impact of large versus small groups versus individuals, the impact of income, the impact of use by or for cities versus businesses versus individuals, the role of middleware, the supply chain, and so on.how do human factors affecting sustainability challenges drive the use and design of technology? how can this interaction be accounted for? when are power, networking, products, and other information and communication technologies (icts) really needed? discuss human choice and its impact on consumption, disposal, and reuse. bill tomlinson, university of california, irvine, examined current use and research on computing initiatives that provide information for more sustainable decision making; shwetak patel, university of washington, explored the challenges of providing utilityuse data to consumers; and eli blevis, indiana university, examined the possibility of incorporating sustainability ideas into the design process. better information for more sustainable decision makingone way to use information technology to lead to more sustainable outcomes is through the provision of information to individuals and organizations to assist in decision making. participants noted that this type of assistance can be provided at many levels. they discussed various types of tools ranging from those that can help inform comparatively simple sorts of personal decision making; to tools that can help people understand large, complex challenges and how their individual actions and behaviors might help; to tools that can assist in understanding and resolving complex challenges that require complex and/or coordinated responses. several examples of how it can be used to perform smallscale sustainabilityrelated tasks more effectively were described. they include the following:  cellular telephone use for coordinating the sale of sh catches. during the early 1990s, shermen in kerala, india, would typically have 6 to 8 percent waste from their catch. the waste was primarily due to lack of computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 129buyers for these sh. cell phone availability in the late 1990s quickly changed this mismatch. as they were coming ashore, shermen could more easily locate buyers, and waste was quickly eliminated. cell phones were not developed to tackle environmental issues, but did enable this unintended positive outcome. the use of various communication tools by nonprot and nongovernmental organizations in coordinating activities. the surfrider foundation10 organizes beach cleanups using various it infrastructures, including text messages, email campaigns, and social media tools. consumer tools for a smart grid. researchers are examining ways to apply internetinspired architectural principles to the energy grid. for consumers, questions are being explored regarding smart appliances that automatically run when electricity is in less demand or when renewable sources are available. another class of tools is designed to help educate the public on their choices regarding sustainability. examples discussed by participants range from tools for educating schoolage children about ecological interdependency, to those for helping consumers make more sustainable purchases at the market. the social code group, which bill tomlinson leads, has developed several of these tools. a selection of these tools and projects was discussed:ecoraft.11 this application was designed, with contributions from ecologists, to help 8 to 12yearold children learn about ecology in the museum environment. a large monitor and several tablets represent various ecosystems. the tablets allow interaction and can be used to simulate the transplanting of species from one ecosystem to another, encouraging children to explore the interdependencies among species and the interconnections between restoration and conservation. a key aspect of ecoraft is a button at the bottom of the main screen that would remove all species from the simulation. in science museums, the rst thing that children tend to do with interactive displays is to push whatever buttons are available. in this case, the button was not labeled, which meant that current users had to guard the button or educate newcomers to the game, simulating the value of education and activism. 10information about this organization is available at http://www.surfrider.org/.11bill tomlinson et al., the ecoraft project: a multidevice interactive graphical exhibit for learning about restoration ecology, in chi™06, extended abstract on human factors in computing systems, new york, n.y.: association for computing machinery (2006). doi: 10.1145/ 1125451.1125717.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.130 computing research for sustainabilitygreenscanner.12 this tool was developed to help consumers when making purchasing decisions to understand the environmental impact from the growing, processing, and transporting of their foodstuffs. the vision was that using cell phone cameras and large databases that linked universal product codes (upcs) to environmental data, consumers could quickly identify which available foods had the least environmental impact. when greenscanner was rst developed as a web application in 2006, sufciently capable hardware was not in wide use to make this tool feasible for everyday consumer use. however, as cell phones have advanced, a tool similar to greenscanner has become commercially available through the company good guide.13trackulous.14 this tool was designed to help people track their activities and the environmental impact of those activities. people may be aware that they often travel by airplane or car, but they might not understand the cumulative time spent doing these activities in a year or the cumulative impact that such travel can have. by tracking their activities, people can better understand their carbon footprint and where the opportunities are for lessening that footprint. better carbon.15 this web application uses collaborative ltering techniques to reduce the amount of information that a user needs to input into carbonfootprint calculators. with current carbonfootprint calculators, users have to enter a great deal of information before receiving an answer. with collaborative ltering, they can enter much less information (which is compared to similar information provided by other users) and then be provided with meaningful defaults for the additional information required.16 participants noted that tools such as these can help individuals better understand their contributions to sustainability problems as well as to sustainability solutions. however, a complete toolbox for resolving large, complex environmental problems does not yet exist. the scale of environmental challenges on the planet todayšincluding global climate change, biodiversity loss, sealevel rise, and various kinds of pollutionšis much greater than the scale of other challenges that humans typically face. people are generally good at cooperation in smallscale tasks and at understanding and resolving smaller challenges, especially those with 12the web application, greenscanner, is available at http://www.greenscanner.net/.13the tool is available at http://www.goodguide.com/.14the tool is available at http://trackulous.com/.15the tool is available at http://www.bettercarbon.com/.16collaborative ltering systems are used in other contexts; for example, amazon uses such tools to recommend products based on past purchases, and net˚ix uses them to recommend movies that users might like.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 131smaller scales of time, space, and complexity. however, the largest and most challenging environmental problems are not at scales that people can readily understand. examples of the complex scales involved in sustainability include the following:the timescale of a rise in sea level. consider the prospect of the sea level rising, perhaps 40 centimeters, over the course of 120 years. how can the general population understand the risks and consequences? the geographical scale of the supply chain. another example of a scale that is difcult to comprehend is global supply chains. products purchased in the united states arrive through a supply chain that may begin as far away as a palm oil plantation in sumatra. how does one communicate to the consumer the potential environmental repercussions of the manufacture, transport, and life cycle of products that they purchase? climate change. the complexity of climate change stems from the large number of factorsšsuch as cloud cover, carbon dioxide emissions, rainforest depletionšand the interaction of these factors that make up the global climate system. how can itšand the way that sustainability information is communicated using itšassist in developing an understanding of the increasing scales of time, space, and complexity that characterize climate change?17 there may be lessons to learn from general it and cs approaches when it comes to these complex problems. good architecture design can remove extraneous decisionmaking requirements and afford consumers the ability to select sustainable options quickly and easily. when the internet works well, for example, users do not typically know or need to know where the information they are receiving is coming from: emails move through various wires, routers, and servers around the globe; web pages are populated by widgets whose data could be sourced from anywhere. one attendee suggested that analogous architectural approaches may be applicable to certain sustainability challenges. another big challenge in sustainability issues is the legacy and xed nature of our utilities and infrastructure. there is a great deal of leg17there are several challenges in educating the public on climate and sustainability issues, one of which involves differentiating between weather and climate. it is too easy to overinterpret extremely hot or cold days. interactive design techniques could help communicate the difference as well as the subtle scale changes, such as highlighting the shifting state of alaskan glaciers or the sea level. the climate research community also struggles to dene what is ﬁnormalﬂ for weather and climate: ﬁnormalﬂ from 1950 to 1980 is different from what would be considered normal from 1980 to 2010. some advocate taking a rstorder linear trend of the past 30 years as an estimate of a baseline to use to compare changes. computing research for sustainabilitycopyright national academy of sciences. all rights reserved.132 computing research for sustainabilityacy infrastructure in most systems that pose signicant challenges. for example, one can certainly contemplate autonomous vehicles, which are much more environmentally friendly, but moving from a highway of all individually controlled vehicles to a highway of all autonomous vehicles is difcult; the upgrade path is bumpy, to say the least. residential energy measurement and disaggregated dataparticipants discussed how better information can assist consumers in making effective changes in their use of home resources such as power, water, and gas. current literature suggests that highgranularity or highresolution datašfor example, information about the usage patterns of individual appliancesšare the most useful. participants observed that literature from the past several decades suggests that if this information were provided to consumers, a 15 to 20 percent reduction in consumption would be possible.in the past, the technologies that collected and provided this information were typically tedious to install and required installation by trained technicians. such difculties make them impractical for largescale deployment. tools were not successful in the past because too much burden was placed on the individuals who were installing them in their homes. new technologies, such as embedded systems and sensors, can make information gathering and feedback tools much more practical. an ongoing research challenge is to determine what information and interfaces work best. one cannot start answering more indepth questions about the effectiveness of novel, engaging, and persuasive feedback applications, however, until there are more information and data from end users. sensing and feedback work hand in hand in creating the most effective tools for consumers. challenges of collecting usage dataconsumers, appliance manufacturers, and utility companies can all benet from any data collected from inhome deployment of sensors. consumers could use disaggregated data to understand their utility use and to make changes in it. by contrast, what is typically available to consumers is only simple endofmonth billing, which provides very little actionable information. if consumers knew the consumption of resources by individual devices, they might start to tailor their behavior for more efcient consumption. use data could also help manufacturers gain a better understanding of the use of their appliances. manufacturers do not have a lot of information on how often their appliances are used. better computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 133understanding of typical duty cycles could be incorporated into future designs. to the extent that utilities are motivated to promote energyconservation activities, they have few ways to assess or validate whether those activities are working. relevant data for utilities would include device use over time and any regional difference in use. currently utilities tend to use selfreporting and polling to determine whether or not their initiatives in˚uenced consumer activities. another challenge is that utilities have little experience in deploying technologies inside the home. moreover, utilities do not want the added expense of installing monitoring tools in the home. sensors that are easily deployable by end users could provide validation and verication of usage for utilities as well as for consumers. once validation and verication are widely available, utilities would be able to provide better incentives to customers for conservation. additionally, the information could allow utilities to create better demandresponse models. better usage models could also be developed by researchers. one goal would be to create a national energy data corpus, which would be very useful to researchers across disciplines as well as in helping meet largescale energy and sustainability information needs.the research discussed in this session of the workshop focused on the creation of technology that (1) provides highly granular, disaggregated data on home energy use and (2) is deployable by end users. the traditional way of collecting such data would be to deploy a network of sensors at each outlet, light, or water xtureša method that is cumbersome, expensive, and, as past experience shows, something that consumers are unlikely to do. this suggests the need to nd an approach that is easier from the perspective of the consumer and, ideally, is a device that plugs in to a single outlet yet monitors electrical consumption or events that occur in the home at the appliance level.18 below are examples of research being done along these lines to collect data on three main resources: power, water, and gas.research is being done to examine the propagation of electrical noise over power lines to infer what devices are being activated. this research incorporates work in signal processing, machine learning, and embedded systems. these types of devices are better than smart meters, which may only provide information every 15 or 20 minutes. in certain circumstances, homeowners or researchers may want shorter time inter18tools built directly in to appliances are not particularly helpful because the timescale for replacing many inhome appliances is often measured in decades.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.134 computing research for sustainabilityvals. to provide realtime consumption, a magnetoresistive sensor was developed that attaches outside the breaker panel, but can be read inside the home. this tool has been eldtested with some success by utilities to determine whether consumers are capable of installing it. measuring and tracking water usage provides similar challenges. obviously, any sensor whose installation requires cutting into pipe will not work for consumers. a singlepoint watersensing solution, attached to a washingmachine hose spigot, could look at the water hammer phenomenon that occurs when a valve is opened and closed, which could infer which water xture was being used inside the house. because the hot and coldwater systems are interconnected, one could even begin to discern hot and coldwater use with a single sensor. in apartment complexes, individual units may not have hose spigots. in that case, the hotwater heater would be another location for installing a sensor.collecting gas data is much more difcult. there is not typically a good place to locate a single sensor that determines when an appliance is activated, and there are safety concerns about customerinstallation of gas xtures. however, a sensor could be installed by clipping it to the nationally mandated regulator on appliances. the acoustic vibrations of the diaphragm are linearly proportionate to ˚ow. by measuring these vibrations, realtime consumption information can be determined. in addition, transient events that occur from the opening and closing of gas valves manifest themselves through the valve itself. this information can be used to determine exactly what appliance is being used. interfaces for actionable feedbackparticipants noted that interfaces for providing the disaggregated sorts of data and feedback discussed above are critical to the successful and effective deployment of sensors. the typical ﬁinterfaceﬂ is the simple electric bill and meter in homes. the meter was not designed for consumers to read, and the bill, which is for the consumer, usually provides only an endofcycle reading. even the units used in the typical electric bill are not very userfriendly: do most consumers understand, for example, what a kilowatthour means? water bills are typically even more aggregated; most include up to 3 months of water use. if a spike occurred in water usage due to, for instance, a leaky valve, the consumer would not have any knowledge of it until the end of the billing cycle. clearly there are opportunities for interface design to play a role in communicating better and more actionable information. unfortunately, there are currently only limited examples of interfaces that provide disaggregated feedback in approximately real time. one obvious example is gaselectric hybrid computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 135automobiles, which display approximate instantaneous mileage while the car is running, as well as relative use of engine and battery. given more information about their own driving habits in accessible and understandable fashion, consumers can (and do) alter their behavior and conserve gas, participants observed. participants described how research that validates the functionality of the devices described earlier has started with inhome trials. in order to evaluate the installation process, researchers have observed consumers selfinstalling devices. once the devices are in place, researchers can evaluate the effectiveness of the energymanagement systems provided to users. some of the questions being asked by researchers are: can you elicit behavior change, up to 15 to 20 percent reduction in usage, with disaggregated feedback, and does the behavior change really hold over time? as more data have been collected on how users react to various interfaces, researchers have begun to iteratively rene individual interfaces. some of the deployed devices were also being integrated with microsoft hohm and google™s powermeter projects.19 before devices and systems such as those exemplied here can be deployed commercially, largescale studies are needed. utilities are open to participating in largescale studies, but when deploying research technology it can be a challenge to create enough devices to do even smallscale deployments in 20 or 30 homes; research laboratories are not often equipped for production. one solution has been to commercialize the technologies being used in research settings so that devices are available from retail stores as well as directly from the utilities. for example, belkin international, which sells a wide array of computer peripherals and other consumer electronics, recently purchased a demandside monitoring solution developed at a university research laboratory.20 the timescales and complexity of general sustainability issues are difcult to understand. feedback mechanisms are being developed, and there is some evidence that information does change behavior. additional knowledge is still needed on how much this feedback will in˚uence behaviors and what the best feedback over what timescale produces the most change. 19in june 2011, both microsoft and google announced the discontinuation of these projects. both cited the slow market adoption of the services as the reason for the termination.20for additional information, see http://seattletimes.nwsource.com/html/technologybrier dudleysblog/2011667981uwgetssliceofprofsstartup.html. examples of the belkin products can be seen at http://www.belkin.com/conserve/.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.136 computing research for sustainabilitysustainable interaction designparticipants also discussed some general highlevel principles regarding sustainable interaction designšthe notion that the design of systems should incorporate sustainability considerations. a few design principles for sustainable interaction design, including the following, were discussed:the connecting of invention and disposal. any new design should also include information on what will happen to the materials or products that it replaces.encouragement of renewal and reuse. humancomputer interaction (hci) research can play a large role by highlighting the future value of objects.encouragement of quality and equality. the second and third user of any product should receive the same satisfaction as the original owner.21a number of projects incorporate at least some aspects of sustainable interaction design, and several are described in the previous sections. additional examples include corporate research done by sap, inc., and academic work done by hci researchers at carnegie mellon university (cmu). sap has developed sourcemap,22 which provides a way to track and improve supply chains. using an opendata platform, users can track where each of their foodstuffs comes from. for example, a catering company can provide a map showing the route by which of all of its products were shipped, or individuals can determine how far each of their breakfast items traveled. stepgreen,23 created by cmu™s hci researchers, is another example that allows users to track the benets of making sustainable choices. users can identify sustainable actions that they are already taking, such as turning off lights not being used or walking to locations less than a mile away, or they can commit to future sustainable choices. stepgreen tracks the amount of savings in dollars and carbon dioxide emissions for each action. interaction design can also be used to encourage dialogues among scientists, decision makers, and citizens. interaction designers can help bridge the gap between scientic knowledge and public perception, can build support, and can promote discourse leading toward solutions. par21eli blevis, sustainable interaction design: invention and disposal, renewal, and reuse, in proceedings of the sigchi conference on human factors in computing, new york, n.y.: association for computing machinery (2007).22see http://www.sourcemap.org/.23see http://www.stepgreen.org/.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 137ticipants noted that bridging this gap has been a particular challenge in climate science and that there is an opportunity for interaction design to play a role. for instance, whereas some of the previously mentioned tools can help people make more informed choices about reducing their negative impact on the climate, tools are also needed that inform people™s preparation and responses to climate change as a chronic sustainability challenge. interaction systems are also needed to deal with the likely increase in the severity of natural disasters and crises due to climate change.24 participants discussed the concept of a ﬁdashboard earthﬂ that could be used to provide information about what is happening and where. interaction design can also be used to develop interactive systems that could help with orderly evacuation in a natural disaster, for example, providing the information to local, regional, national, and intergovernmental policy makers about who can go where and how many people each location can absorb. interaction design can be used to persuade and show people how to live with fewer resources, as matters of sustainability and preparation and adaptation. the interaction design of tools like social media is needed to help persuade people and various levels of organizations to care for others in the face of climate change and its effects. interaction design can also assist in the public discourse about and support for certain sorts of solutions and in fostering public understanding. participants argued that all of these tools and more need to provide information at the local, regional, national, and global level and to help people respond efciently during crises.session 4: overcoming obstacles to scientific  discovery and translating science to practicecommittee member david culler, university of california, berkeley, and david douglas, national ecological observatory network, led the discussion during the nal session, which highlighted some of the impediments to developing and deploying innovative information technologies for sustainability challenges. guiding questions for this session were as follows: what are the motivations for and impediments to applying innovative information technologies to sustainability challenges and how do they differ by domain?24national research council, adapting to the impacts of climate change, washington, d.c.: the national academies press (2010).computing research for sustainabilitycopyright national academy of sciences. all rights reserved.138 computing research for sustainabilityhow can largescale science addressing realworld problems be made credible, if reproducibility is not possible? what lessons can be applied from the transformation of the internet into a critical infrastructure that must avoid ossication? what is the appropriate mix of empiricism, innovation, and application in order for computer science to have an impact in the area of environmental sustainability?the energy challengeparticipants suggested considering broad sustainability challenges in the context of the energy challenge. the interconnected nature of people™s basic resource needs, such as water, energy, and transportation, and the economic arrangements among these resources create a very complex problem. however, these interactions also mean that the energy challenge can serve as a useful proxy for sustainability challenges related to other limited resources.the primary function of the electric grid is to deliver highquality, lowcost power to millions of customers who are geographically distributed over thousands of miles. the fact that consumers have been able to make use of the grid without needing much knowledge about their own consumption patterns, or about where the power is coming from, has contributed to rapid economic and industrial growth. people have been able to use a comparatively inexpensive resourcešenergy created mostly through the burning of fossil fuelsšessentially indiscriminately to expand the production of products that spur the economy. additionally, enabling a usage model in which consumers could remain ignorant of their own consumption patterns meant that the grid has been tasked with delivering a highquality commodity at extremely low cost. moreover, the expectation has been that power would be delivered immediately as needed. the power grid is expected to meet these goals with minimal forecasting or anticipation of that need, except at very coarse granularity, and without inventory storage along the energy supply chain. the current energy model is increasingly complex, with numerous sources of energy, a variety of stakeholders and consumers, and a not insignicant fraction lost during transport. a pressing sustainability challenge revolves around these questions: how can energy use be reduced, and can it be done without signicant economic hardship? the following question was discussed: where and how can computer science t into this picture? figure a.4 shows the percentage of energy use in the united states by type. each of these types represents an opportunity for reduction in computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 139demand. commercial light use and residential heating make up the bulk of their respective building types, but several other smaller items make up the rest of the energy usage. perhaps reductions in several of these ﬁlowhanging fruitﬂ items can contribute signicantly in reducing total energy consumption. impediments to changing the energy systeminsufcient scope and scale of research and development  funding to fuel itenabled innovation in the electricity sectorchallenged to consider opportunities for it and cs research to contribute to sustainability, participants re˚ected on the history of it successes and on whether those successes might offer important lessons. the enormous payoffs from it r&d investment have been investigated by several studies of the national research council™s computer science and telecommunications board, including evolving the high performance computing and communications initiative to support the nation™s infrastructure (1995); funding a revolution: government support for computing research (1999); making it better: expanding information technology research to meet figure a.4 energy consumption in the united states, by type of use. source: lawrence berkeley national laboratory.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.140 computing research for sustainabilitysociety™s needs (2000); and innovation in information technology (2003).25 these reports have shown how research partnerships between the federal government and industry ultimately led to the creation of many wellknown multibilliondollar industries. these results suggest the potential sustainability payoffs from the right investments in it. many of the advancements presented in the cstb reports, such as those in processors or networking, required signicant nancial investment from both industry and government. the software industry spends approximately 13.5 percent of revenues on r&d, the health care industry spends about the same, and the computer hardware industry spends about half of that.26 by contrast, r&d spending by the electric utility sector is about 0.1 percent of revenues, perhaps due to the fact that the sector has been very stable, with little innovation or push for innovation, a context that seems to be changing rapidly.27 sustainability is a large, broadranging problem, and apportioning limited research dollars to effective ends is a difcult challenge. one consequence of this low level of support and the resulting small number of technical researchers at utility companies is that opportunities for partnership between academic researchers and utility companies are rare.government funding is also limited. in 2010, the u.s. department of energy provided $130 million and created three different energy hubs in innovation.28 however, a workshop attendee commented that even this amount is much smaller than would be needed if a signicant shift were to be made toward sustainable energy sources or if total energy consumption were to be decreased. misalignment of incentives for more sustainable generation and usethe energyutility market, as described earlier, has evolved to provide a critical resource, at low price, with supply almost instantaneously 25national research council, evolving the high performance computing and communications initiative to support the nation™s infrastructure, washington, d.c.: national academy press (1995); national research council, funding a revolution: government support for computing research, washington, d.c.: national academy press (1999); national research council, making it better: expanding information technology research to meet society™s needs, washington, d.c.: national academy press (2000); national research council, innovation in information technology, washington, d.c.: the national academies press (2003).26jill jusko, r&d spending: by the numbers. industryweek.com. january 2010. available at http://www.industryweek.com/articles/rdspendingbythenumbers17988.aspx.27 jusko, r&d spending, 2010, available at http://www.industryweek.com/articles/rdspendingbythenumbers17988.aspx.28department of energy, ﬁobama administration launches $130 million building energy efciency effort,ﬂ february 12, 2010, available at http://energy.gov/articles/obama administrationlaunches130millionbuildingenergyefciencyeffort.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 141matched to demand. although historically it required considerable innovation and tremendous capital investment to meet these constraints, there are additional market impediments to creating a more sustainable system. perhaps the most obvious is that, generally speaking, utility companies have historically charged for usage by the kilowatthour, resulting in little economic incentive to reduce the number of kilowatthours used. regulation prevents vertical monopolies, but there is often an interest in owning an entire vertical marketšone organization owning or operating both the production and the delivery systemsšand extracting marginal prot mostly by locking customers in to the system. participants observed that horizontal market stratication would help drive efcient markets. this limitedcompetition system means that the utility industry is not particularly motivated to shift technologies, which may drive up the cost of production in the short term. the question again is where the investment to drive new technologies is going to come from. while the utility companies have little incentive to encourage reductions in energy use, consumers themselves have undervalued energy. as noted earlier, consumers have become accustomed to inexpensive power and also have little understanding of how power is produced and of the resulting environmental damage. consumers have even less knowledge or easy insight into the energy costs of producing and transporting foods and goods. the energy cost, including the accompanying externalities such as environmental and social damage, is not easily re˚ected in the price of goods. if these costs were re˚ected directly in the price, more energyefcient choices might be made. infrastructural and organizational impedimentsimpediments to making progress on sustainability in addition to those discussed above include infrastructural and organizational realities. the scale of the sustainability problem is immense, and the infrastructure systems that bear on sustainabilityšsuch as energy, water, and food distributionšare just as massive. in addition, diversity of use within the system adds a level of complexity. the use and design of each building site and the water distribution and transportation system of each city have unique characteristics that make a onesizetsmost solution impractical. furthermore, the traditional production cycle does not apply; infrastructures are not projects that are developed, improved, and shipped; they are built once. cities are developed over a span of 100 years or more, with renements, changes, and ﬁdebuggingﬂ taking place little by little. once these systems are rolled out, even if they do not function as well as they could, they become, in effect, stranded assets. the market structure also creates impediments to better technological change. the market is highly fragmented; energy sources vary, and computing research for sustainabilitycopyright national academy of sciences. all rights reserved.142 computing research for sustainabilityenergy use is even more dispersed. each industry that participates in the energy market has its own unique needs, regulatory requirements, and certication programs. individual industries and companies create their own technology standards. unique industry and corporate technology standards also make onesizetsmost solutions impractical. efforts to deploy, say, monitoring and datacollection tools in these sorts of environments are challenged. equipment used for monitoring the use of each resource systemšenergy, water, foodšwithin cities becomes difcult to build and deploy. additionally, these monitoring devices, if built in to the initial infrastructure, need to be able to collect a wide variety of data and be sturdy enough to function over long periods of time. research impedimentsthe critical nature of the sustainability problem and energy crisis combined with their scale and complexity often means that researchers are dedicating entire careers working to address pieces of the problem. this scale and complexity mean that choosing avenues of investigation is a highrisk proposition. if a path that a researcher follows turns out to be incorrect or a dead end, the mistake can be career ending. furthermore, these sustainability and energy problems are inherently multidisciplinary, which adds another barrier to academic work often conned to single disciplines. in many subelds of computer science, the ultimate goals can be dened reasonably clearly, even if the description of the goal is as simple as: make computers faster. welldened goals also imply a clear denition of success. while there are some goals to work toward in addressing the sustainability problem, such as decreasing the levels of greenhouse gases in the atmosphere, they tend to be less well dened (should the focus be on lowering energy use or on the use of more sustainable energy sources?) and have less clear benchmarks for success. potential computer science contributionsin the fourth session of the workshop, participants brainstormed about potential further contributions of computer science to sustainability. computer science is well positioned to provide technical options that could help address some sustainability challenges. additionally, the distinctive culture, methodologies, and approaches of computer science may shed new light on methodologies, processes, and concepts that could be useful in sustainability. speakers discussed several such cultural attributes, including the following: computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 143culture of innovation. computer scientists are used to developing and deploying new tools almost constantly and to doing these things quickly. participants argued that this ˚exible, catchall approach allows for broader ideas and more creativity.largescale systems approach. computer scientists have experience building big things, such as massive integrated circuits, which have tens of millions of design points that need to be correct when built, and software artifacts that today measure in the millions of lines of code. computer scientists also understand system approaches. understanding of openinformation systems. computer scientists tend to understand the value of open systems and are often forced to engage with demands for systemlevel considerations such as compatibility and interoperability. distributed grid management, ecosystems understanding, crisis and disaster response, and resource tracking and optimization can all benet from open, interoperable information systems. with large amounts of data being collected, privacy and security become an issue, which, again, computer scientists have experience managing.29business transformation, often with efciency as a goal. as new technologies have become available, the computer science industry has transformed itself several times. for example, participants noted that data centers are drastically different now than they were just 2 years ago. this change has been driven partly by efciency concerns. furthermore, computer science has been fundamental in transforming other industries, for example, car ownership, media consumption, and banking, in interesting ways. advances in smartphones, the global positioning system, and humancomputer interaction have contributed to the success of shortterm caruse services, such as zipcar; advances in telecommunications networks and le compression have made internet video streaming a viable alternative to the video store; and computer and information security have encouraged condence in online banking. educating in a dynamic environment. because sustainability efforts are complex, multidisciplinary problems, universities will need new ways to teach scientists and engineers to resolve these problems. computer science has historically adapted to changes in curriculum and changes in the overall technological environment by shifting teaching techniques very 29the internet is an example in which computer science has incorporated openinformation systems, shared standards, and a complex understanding of intellectual property. although there have been questions and debates about appropriate infrastructure, standards, and intellectual property, especially as more of the internet has been commercialized, there is still copious knowledge that can be gleaned from the computer science community on building interdisciplinary, complex systems.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.144 computing research for sustainabilityrapidly. these educational tools, developed within the computer science discipline, can help develop the next wave of scientists and engineers. wrapup discussionthis session resulted in a wideranging discussion from the participants at the workshop. several key points raised are outlined below:within the information technology industry, signicant innovation has been accomplished at small businesses or startups, which then are often acquired by large corporations. this suggests that small amounts of money could fund highly innovative projects in sustainability, given the proper organizational structure and incentive. although sustainability can be viewed in many ways as a technical problem, it will not be solved through technological solutions alone. some people conjecture that in addition to major scientic and technical breakthroughs to meet sustainability challenges, largescale social change will be needed, perhaps even on the scale of the u.s. civil rights movement. computer scientists can contribute tools that encourage individual participation in addressing sustainability challenges.small businesses often require specialized information that can be hard to acquire. computational techniques and technologies can help by providing ways to collect, aggregate, distribute, and analyze data, as well as techniques for communication and coordination as appropriate.30 there are tradeoffs in discussing solutions. for example, raising temperatures in server rooms may reduce cooling loads but lead to higher failure rates. these tradeoffs and failure rates have to be fully understood so that the best tradeoffs can be made.domain scientists (such as ecologists, transportation specialists, civil and power engineers) need to share information and knowledge with people doing innovation, including computer scientists. the rst step for computer science might simply be nding a better way to present these data, which would help policy makers. decision makers need to understand the data more clearly before they can form policy. 30an example was given of a case in which a number of local coffee shops were interested in purchasing biodegradable products. today, biodegradable cups are more expensive and are only affordable if purchased in very large quantities; it can link companies willing to purchase and share large shipments. also, not all biodegradable cups are biodegradable to the same extent, an information gap that could be solved with more usable data. however, computer scientists typically have little knowledge about the chemical makeup of products, and so there is also a need for coordination across multiple disciplines and industries.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 145workshop agendamay 26, 2010  washington, d.c.8:308:35 a.m. welcome  deborah l. estrin, university of california, los angeles chair, committee on computing research for environmental and societal sustainability8:3510:45 a.m. session 1: expanding science and engineering with novel cs/it methods: ﬁthe need to turn numbers into knowledgeﬂ committee respondent: daniel kammen, university of california, berkeleywhat are some example areas of efforts in sustainability and related research where the interface of disciplinary and interdisciplinary research with new methods in computer and information science can generate new innovations and knowledge? one example is the smart grid, which provides a physical and information technology medium where new levels of efcient and clean energy and information management are possible, and where new levels of data security are needed. discussion topics range from grid management to the introduction of smart management and charging systems for lowcarbon electric vehicles. another example is ecological resilience and ecosystem function, which is the monitoring and modeling of ecological change and of the interactions related to ecological robustness and requires new tools for temporal and spatial resolution, new methods to explore the dynamics of connectivity in ecological systems, and teasing out the ranges of anthropogenic impacts.vijay modi, columbia university: ﬁcriticality of cs and it to sustainabilityﬂrobert pfahl, international electronics manufacturing initiative, inc.: ﬁtowards a sustainable world through electronic systems and itﬂ neo martinez, pacic ecoinformatics and computational ecology lab: ﬁnumbers: where they come from and what to do with them to live more sustainably on earthﬂ adjo amekudzi, georgia institute of technology: ﬁusing social sustainability measures as inputs in planning and designﬂ thomas harmon, university of california, merced: ﬁenvironmental cyberinfrastructure and data acquisitionﬂcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.146 computing research for sustainability11:00 a.m.1:00 p.m. session 2: understanding, tracking, and managing uncertainty throughout the sciencetopolicy pipeline committee respondent: thomas dietterich, oregon state universityexplicit representation of uncertainty is rare in the sciencetopolicy pipeline. data products resulting from fusing information from multiple instruments are often treated as exact when input to models. outputs from predictive and simulation models are often treated as exact when input to policy making. policy optimization for management (e.g., reserve design, shing quotas, habitat conservation plans) often is not robust to uncertainty in the problem formulation or the objectives. uncertainty about future decision making and imperfect implementation of policies injects additional uncertainty into planning for the future.what are the sources of uncertainty that should be explicitly captured?what methods are suitable for explicitly representing uncertainty?is the technological state of the art sufcient to model the many different ˚avors of uncertainty present in largescale sustainability problems? if not, what characterizes the types of uncertainty that are insufciently modeled? what methods are suitable for assessing uncertainty in each stage of the pipeline? what shortcomings need to be addressed?is the state of the art in human factors, interfaces, and cscw (computersupported cooperative work) sufcient to support the largescale systems, models, and data sets that are necessary to tackle largescale sustainability problems? if not, what needs are unmet? what are the appropriate techniques for working with uncertain data in data fusion, data assimilation, predictive modeling, simulation modeling, and policy optimization?is a pipeline architecture sufcient, or do we need a fully coupled architecture in which policy questions can reach all the way back to guide data collection and data fusion?how can explicit uncertainty representations be integrated into scientic work˚ow tools?are there alternatives to explicit uncertainty representations that can improve the robustness of management policies to all of these sources of uncertainty?peter bajcsy, national institute of standards and technology: ﬁinstruments and scientic work˚owsﬂcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix a 147chris forest, pennsylvania state university: ﬁassessing uncertainty in climate modelsﬂdavid brown, duke university: ﬁrobust optimization under uncertaintyﬂjohn doyle, california institute of technology: ﬁtheory and methodology of robustyetfragile systems analysisﬂ1:303:00 p.m. session 3: creating institutional and personal  change with humans in the loop committee respondent: alan borning, university of washingtonachieving sustainability objectives demands behavioral changes at the institutional and individual levels. in designing and developing smarter systems, an important question is how to embed interfaces that work. the humansystem interaction literature is replete with counterexamples and numerous failed cognitive models, serving as cautionary tales. complicating matters, humansystem interaction issues arise both with regard to individuals in homes and ofces and for administrators of larger systems or facilities. further, interactions occur at different scalesšon the one hand in a daytoday time frame for users and on the other in ways that allow incorporation of feedback from the system either to the system itself or to decision makers thinking about largerscale resource management considerations, for example.how can data and information be presented at the appropriate granularity and timescale to be most effective? what system, application, and user factors bear on the humansystem interaction design choices? describe the potential impacts of the various contexts and tradeoff decisions that might need to be made, including the impact of context (e.g., stakeholders, and so on); the impact of large versus small groups versus individuals; the impact of income; the impact of use by or for cities versus businesses versus individuals; the role of middleware, the supply chain, and so on.how do human factors affecting energy use drive the use and design of technology? how can this be accounted for? when are power, networking, products, and so on really needed? discuss human choice and its impact on consumption, disposal, reuse, and so on. bill tomlinson, university of california, irvine: ﬁgreening through itﬂshwetak patel, university of washington: ﬁresidential energy measurement and disaggregated dataﬂ eli blevis, indiana university: ﬁsustainable interaction designﬂcomputing research for sustainabilitycopyright national academy of sciences. all rights reserved.148 computing research for sustainability3:154:00 p.m. session 4: overcoming obstacles to scientic discovery and translating science to practice committee respondent: david culler, university of california, berkeleywhat are the motivations for and impediments to applying innovative information technologies to sustainability challenges, and how do they differ by domain?how can largescale science addressing realworld problems be made credible, if reproducibility is not possible? what lessons can be applied from the transformation of the internet into a critical infrastructure that must avoid ossication? what is the appropriate mix of empiricism, innovation, and application for computer science to have an impact in the area of environmental sustainability? david douglas, national ecological observatory network: ﬁthe role of cs in open, sustainability scienceﬂ4:005:00 p.m. capstone session and plenary discussion deborah l. estrin, committee chair randal bryant, carnegie mellon university computing research for sustainabilitycopyright national academy of sciences. all rights reserved.bbiographies of committee  members and staffdeborah l. estrin (nae), chair, is a professor of computer science with a joint appointment in electrical engineering at the university of california, los angeles; holds the jon postel chair in computer networks; and is a cofounder of the nonprot, open mhealth. professor estrin received her ph.d. (1985) in computer science from the massachusetts institute of technology and her b.s. (1980) from the university of california, berkeley. her early research (conducted while she was on the computer science department faculty at the university of southern california [usc] and the usc information sciences institute) focused on the design of network and routing protocols for very large, global networks, including multicast routing protocols, selfconguring protocol mechanisms for scalability and robustness, and tools and methods for designing and studying largescale networks. from 2002 to 2012 she founded and directed the multidisciplinary, national science foundation (nsf)funded science and technology center for embedded networked sensing (cens), which developed environmental monitoring technologies and applications (http://cens.ucla.edu). currently professor estrin explores participatory sensing and mhealth systems, leveraging the programmability, proximity, and pervasiveness of mobile devices; deployment contexts include health (http://openmhealth.org), community data gathering, and education (http://mobilizingcs.org). professor estrin has been a coprincipal investigator on numerous nsf and defense advanced research projects agency (darpa)funded projects and has been an active participant in several governmentsponsored studies. she 149computing research for sustainabilitycopyright national academy of sciences. all rights reserved.150 computing research for sustainabilitychaired a 19971998 darpa information science and technology study group study on sensor networks, and the 2001 national research council (nrc) study on networked embedded computing, which produced the report embedded, everywhere: a research agenda for networked systems of embedded computers. she later chaired the sensors and sensor networks subcommittee of the neon (national ecological observatory network) design committee (www.neoninc.org). professor estrin also served on the advisory committees for the nsf computer and information science and engineering (cise) and environmental research and education (ere) directorates, and is a former member of the nrc™s computer science and telecommunications board. she was an editor of the ieee/acm transactions on networking, and a program committee member for many networkingrelated conferences, including sigcomm (special interest group on data communication), infocom (international conference on computer communications), mobicom, and mobisys. she was the steering group chair and general cochair for the rst association for computing machinery (acm) conference on embedded networked sensor systems, sensys 2003, and served as one of the rst associate editors for the acm transactions on sensor networks. professor estrin is a fellow of the acm, the american association for the advancement of science, and the institute of electrical and electronics engineers. she was selected as the rst acmw athena lecturer in 2006, was awarded the anita borg institute™s women of vision award for innovation in 2007, was inducted into the women in technology international hall of fame in 2008, and awarded doctor honoris causa from école polytechnique fédérale de lausanne in 2008. professor estrin was elected to the american academy of arts and sciences in 2007 and into the national academy of engineering in 2009.alan borning is a professor in the department of computer science and engineering at the university of washington, an adjunct faculty member in the information school, and a fellow of the association for computing machinery. he received a b.a. in mathematics from reed college (1971) and an m.s. (1974) and a ph.d. (1979) from stanford university. his principal research interests are in humancomputer interaction and designing for human values. his current research projects include online tools to support civic engagement and participation, mobile tools to aid transit riders, and designing systems to support more effective public participation in land use and transportation deliberations, supported by sophisticated simulation data. earlier he worked on programming languages and ui (user interface) toolkits, including constraintbased languages and systems and on objectoriented languages.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix b 151david culler (nae), a professor and chair of computer science, associate chair of electrical engineering and computer sciences, and faculty director of i4energy at the university of california, berkeley, received his b.a. from the university of california, berkeley (1980) and an m.s. and a ph.d. from the massachusetts institute of technology (1985 and 1989, respectively). he joined the department of electrical engineering and computer science faculty in 1989, where he holds the howard friesen chair. he is a member of the national academy of engineering, a fellow of the association for computing machinery (acm), and an institute of electrical and electronics engineers fellow; he was selected for acm™s sigmod outstanding achievement award, and was named in the scientic american top 50 researchers and the technology review: 10 technologies that will change the world. he was awarded the national science foundation (nsf) presidential young investigator award in 1990 and the nsf presidential faculty fellowship in 1992. he was the principal investigator (pi) of the defense advanced research projects agency network embedded systems technology project that created the open platform for wireless sensor networks based on tinyos, a cofounder and the chief technology ofcer of arch rock corporation, and the founding director of intel research, berkeley. he has done seminal work on networks of small, embedded wireless devices, planetaryscale internet services, parallel computer architecture, parallel programming languages, and highperformance communication, including tinyos, planetlab, networks of workstations (now), and active messages. he has served on technical advisory boards for several companies, including people power, inktomi, expertcity (now citrix online), and docomo usa. he is currently focused on utilizing information technology to address the energy problem and is copi on the nsf cyberphysical systems projects local and actionwebs.thomas dietterich, professor at oregon state university (osu), focuses on interdisciplinary research at the boundary of computer science, ecology, and sustainability policy. he is the principal investigator (with carla gomes of cornell university) of a 5year national science foundation (nsf) expedition in computational sustainability. he is part of the leadership team for osu™s ecosystem informatics programs, including an nsf summer institute in ecoinformatics. dr. dietterich received his a.b from oberlin college (1977), m.s. from the university of illinois (1979), and ph.d. from stanford university (1984). he is professor and director of intelligent systems in the school of electrical engineering and computer science at osu, having joined the faculty there in 1985. in 1987, he was named a presidential young investigator for the nsf. in 1990, he published, with dr. jude shavlik, the book entitled readings in machine computing research for sustainabilitycopyright national academy of sciences. all rights reserved.152 computing research for sustainabilitylearning, and he also served as the technical program cochair of the national conference on articial intelligence (aaai90). from 1992 to 1998 he held the position of executive editor of the journal machine learning. he is a fellow of the association for the advancement of articial intelligence (1994), the association for computing machinery (2003), and the american association for the advancement of science (2007). in 2000, he cofounded the free journal of machine learning research and he is currently a member of its editorial board. he served as technical program chair of the neural information processing systems (nips) conference in 2000 and as general chair in 2001. he is past president of the international machine learning society (imls) and a member of the imls board, and he also serves on the advisory board of the nips foundation.daniel kammen is the class of 1935 distinguished professor of energy at the university of california, berkeley, with parallel appointments in the energy and resources group, the goldman school of public policy, and the department of nuclear engineering. he serves as an environment and climate partnership for the americas (ecpa) fellow for secretary of state hillary clinton. dr. kammen is the founding director of the renewable and appropriate energy laboratory (rael), codirector of the berkeley institute of the environment, and director of the transportation sustainability research center. he has founded or is on the board of more than 10 companies and has served the state of california and the u.s. government in expert and advisory capacities. dr. kammen was educated in physics at cornell university and harvard university, and held postdoctoral positions at the california institute of technology and harvard. he was assistant professor and chair of the science, technology and environmental policy program at the woodrow wilson school at princeton university before moving to the university of california, berkeley. dr. kammen has served as a contributing or coordinating lead author on various reports of the intergovernmental panel on climate change (ipcc) since 1999. the ipcc shared the 2007 nobel peace prize. during 20102011, dr. kammen served as the world bank group™s chief technical specialist for renewable energy and energy efciency. in this newly created position to which he was appointed in october 2010, he provided strategic leadership on policy, technical, and operational fronts. the aim is to enhance the operational impact of the world bank™s renewable energy and energyefciency activities while expanding the institution™s role as an enabler of global dialogue on moving energy development to a cleaner and more sustainable pathway. he has authored or coauthored 12 books, written more than 250 peerreviewed journal publications, testied more than 40 times at u.s. state and federal congressional briengs, and has provided various governments with more than 50 technical reports. dr. kammen also served computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix b 153for many years on the technical review board of the global environment facility. he is a frequent contributor to or commentator in international news media, including newsweek, time, the new york times, the guardian, and the financial times. dr. kammen has appeared on 60 minutes (twice), nova, and frontline, and he hosted the sixpart discovery channel series ecopolis. he is a permanent fellow of the african academy of sciences and a fellow of the american physical society. in the united states he serves on a board and a panel of the national academy of sciences. jennifer mankoff is an associate professor in the humancomputer interaction institute at carnegie mellon university. she earned her b.a. at oberlin college and her ph.d. in computer science at the georgia institute of technology. her research embodies a humancentered perspective on datadriven applications. her goal is to combine empirical methods with technological innovation to construct middleware (tools and processes) that can enable the creation of impactful datadriven applications. examples of such application areas include sensing and in˚uencing energysaving behavior, web interfaces for individuals with chronic illness, and assistive technologies for people with disabilities. dr. mankoff helped found the sustainablechi group (www.sustainablechi@googlegroups.com). her research has been supported by google, inc., the intel corporation, ibm, hewlettpackard, microsoft corporation, and the national science foundation. she was awarded the sloan fellowship and the ibm faculty fellowship.roger d. peng is an associate professor of biostatistics at the johns hopkins bloomberg school of public health. he received his ph.d. in statistics from the university of california, los angeles. he is a prominent researcher in the areas of air pollution and health risk assessment and statistical methods for spatial and temporal data. dr. peng is a national leader in the area of methods and standards for reproducible research; he is the reproducible research editor for the journal biostatistics. he has developed novel approaches to integrating complex national databases for assessing population health effects of environmental exposures and has developed software for efciently distributing data over the web for disseminating reproducible research. dr. peng™s research is highly interdisciplinary; his work has been published in major substantive and statistical journals, including the journal of the american medical association, journal of the american statistical association, journal of the royal statistical society, and american journal of epidemiology. dr. peng is the author of more than a dozen software packages implementing statistical methods for environmental studies, methods for reproducible research, computing research for sustainabilitycopyright national academy of sciences. all rights reserved.154 computing research for sustainabilityand data distribution tools. he has also given workshops, tutorials, and short courses in statistical computing and data analysis.andreas vogel is vice president in the global business incubator at sap labs in palo alto, california, where he currently works on virtual economies and recommender systems for online games. previously he incubated a product for analyzing smart meter data and developed the next generation of sustainabilityrelated software solutions, including those involving carbon accounting, energy management, and electried vehicles. he also helped to create and implement sap™s sustainability strategy. before joining sap, dr. andreas held various research, technology, and business positions around the worldšamong them, chief scientist at borland and chief technology ofcer and cofounder of mspect, where he developed monitoring solutions for mobile data networks. dr. andreas holds an m.sc. and a ph.d. in computer science from humboldt university, berlin, germany. he coauthored four books on common object request broker architecture (corba), enterprise java beans, and enterprise resource planning (erp) published by j. wiley and sons.stafflynette i. millett is a senior program ofcer and study director at the computer science and telecommunications board (cstb), national research council of the national academies. she currently directs several cstb projects, including an exploration of foundational science in cybersecurity. she recently completed the project that produced strategies and priorities for information technology at the centers for medicare and medicaid services. ms. millett™s portfolio includes substantial portions of cstb™s recent work on software, identity systems, and privacy. she directed, among other projects, those that produced the future of computing performance: game over or next level?, an examination of the causes and implications of the slowdown in the historically dramatic exponential growth in computing performance; software for dependable systems: sufcient evidence?, an exploration of fundamental approaches to developing dependable missioncritical systems; biometric recognition: challenges and opportunities, a comprehensive assessment of biometric technology; who goes there? authentication through the lens of privacy, a discussion of authentication technologies and their privacy implications; and idsšnot that easy: questions about nationwide identity systems, a post9/11 analysis of the challenges presented by largescale identity systems. she has an m.sc. in computer science from cornell university, where her work was supported by graduate fellowships from the national science foundation computing research for sustainabilitycopyright national academy of sciences. all rights reserved.appendix b 155and the intel corporation; and a b.a. with honors in mathematics and computer science from colby college.virginia bacon talati is an associate program ofcer at the computer science and telecommunications board, national research council of the national academies. she formerly served as a program associate with the frontiers of engineering program at the national academy of engineering. prior to her work at the academies, she served as a senior project assistant in education technology at the national school boards association. she has a b.s. in science, technology, and culture from the georgia institute of technology and an m.p.p. from george mason university with a focus in science and technology policy.shenae bradley is a senior program assistant at the computer science and telecommunications board, national research council of the national academies. she has provided support for the committee on sustaining growth in computing performance, the committee on wireless technology prospects and policy options, and computational thinking for everyone: a workshop series planning committee, to name a few. previously, she served as an administrative assistant for the ironworker management progressive action cooperative trust and managed a number of apartment rental communities for edgewood management corporation in the maryland/dc/delaware metropolitan areas. ms. bradley is in the process of earning her b.s. in family studies from the university of maryland at college park.computing research for sustainabilitycopyright national academy of sciences. all rights reserved.