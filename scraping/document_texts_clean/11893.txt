detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/11893humansystem integration in the system development process:a new look396 pages | 6 x 9 | hardbackisbn 9780309107204 | doi 10.17226/11893richard w. pew and anne s. mavor, editors; committee on humansystem designsupport for changing technology; committee on human factors; division ofbehavioral and social sciences and education; national research councilhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.committee on humansystem design support for changing technologyrichard w. pew and anne s. mavor, editorscommittee on human factorsdivision of behavioral and social sciences and educationnational research councilhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, d.c. 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.the study was supported by award nos. w911nf050150 and fa56500616610 between the national academy of sciences and the u.s. department of the army and the u.s. department of the air force. any opinions, ndings, conclusions, or recommendations expressed in this publication are those of the author(s) and do not necessarily re˚ect the view of the organizations or agencies that provided support for this project.library of congress cataloginginpublication datahumansystem integration in the system development process : a new look / committee on humansystem design support for changing technology ; richard w. pew and anne s. mavor, editors. p. cm. includes bibliographical references and index. isbn13: 9780309107204 (hardback : alk. paper) isbn10: 0309107202 (hardback : alk. paper) 1. human engineering. 2. systems engineering. 3. user interfaces (computer systems) i. pew, richard w. ii. mavor, anne s. iii. committee on humansystem design support for changing technology. ta166.h84 2007620.8'2šdc22 2007012835additional copies of this report are available from the national academies press, 500 fifth street, n.w., lockbox 285, washington, d.c. 20055; (800) 6246242 or (202) 3343313 (in the washington metropolitan area); internet, http://www.nap.eduprinted in the united states of americacopyright 2007 by the national academy of sciences. all rights reserved.cover images:  (1) the air force mq1 predator (unmanned aerial system) produced by general atomics aeronautical systems. (2) controllers in the combined air operations center at an air base on the arabian peninsula monitor the status of ongoing missions supporting operation iraqi freedom. the caoc was the nerve center for all u.s. central command air operations when the rst air strike occurred early march 20, 2003. (3) a generalpurpose intravenous infusion pump designed primarily for hospital use with secondary, limited feature use by patients at home. (the marketed name is the symbiqž iv pump.) (4) vehicle screening for port security.cover credits: unmanned aerial system: photo courtesy of u.s. army taken august 10, 2005. combined air operations center: photo by ministry of defenceroyal air force sgt. gareth davies. courtesy of u.s. air force. symbiqtm iv pump: photograph courtesy of hospira, inc.suggested citation: national research council. (2007). humansystem integration in the system development process: a new look. committee on humansystem design support for changing technology, r.w. pew and a.s. mavor, eds. committee on human factors, division of behavioral and social sciences and education. washington, dc: the national academies press.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. wm. a. wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. wm. a. wulf are chairman and vice chairman, respectively, of the national research council.www.nationalacademies.orghumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.vcommittee on humansystem design support for changing technologyrichard w. pew (chair), bbn technologies, cambridge, manigel bevan, university of york, londonbarry w. boehm, computer science department, university of southern californianancy j. cooke, department of psychology, arizona state universityshelley evenson, school of design, carnegie mellon universitydavid graeber, boeing phantom works, seattle, waedmond w. israelski, abbott laboratories, abbott park, ilbrian m. kleiner, grado department of industrial and systems engineering, virginia polytechnic institutemichael muller, ibm research, cambridge, mafrank e. ritter, college of information sciences and technology, pennsylvania state universityemilie roth, roth cognitive engineering, brookline, mathomas f. sanquist, battelle seattle research center, pacic northwest national laboratory, seattle, waanne s. mavor, study directorkristen a. butler, research assistantmatthew d. mcdonough, senior program assistanthumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.vicommittee on human factorswilliam s. marras (chair), institute for ergonomics, the ohio state universitydeborah a. boehmdavis, department of psychology, george mason university, fairfax, vadonald fisher, department of mechanical and industrial engineering, university of massachusetts, amherstjonathan grudin, microsoft research, redmond, wapeter hancock, department of psychology, university of central florida, orlandodaniel r. ilgen, department of psychology and department of management, michigan state university, east lansingkurt kraiger, department of psychology, colorado state university, fort collinsjohn lee, department of mechanical and industrial engineering, university of iowa, iowa cityraja parasuraman, department of psychology, george mason university, fairfax, varichard w. pew, bbn technologies, cambridge, marobert g. radwin, department of biomedical engineering, university of wisconsin, madisonwendy a. rogers, department of psychology, georgia institute of technology, atlantathomas b. sheridan, massachusetts institute of technologyjoel s. warm, department of psychology, university of cincinnatigregory l. zacharias, charles river analytics inc., cambridge, maanne s. mavor, directorhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.viiacknowledgmentswe are grateful to the many individuals who have made a signicant contribution to the committee™s work by providing information through briengs at our meetings. a complete list of these contributors and their afliations appears in appendix a.in the course of preparing the report, each member of the committee took an active role in drafting sections of chapters, leading discussions, and reading and commenting on successive drafts. we are deeply indebted to them for their hard work, their wiliness in critically weighting a variety of diverse perspectives, and their good spirit in working in concert to produce this volume. it has been a great pleasure and a learning experience to work with all of them. committee member biographies appear in appendix b.staff at the national research council (nrc) made important contributions to our work in many ways. we would like to extend our thanks to kristen butler, research assistant, for her support of the committee through her research, her writing, and her extensive work on the report manuscript. thanks are also due to matthew mcdonough, senior project assistant, who was indispensable in organizing meetings, arranging travel, assembling agenda books, assisting committee members, and preparing the nal report for publication. we are also indebted to christine mcshane, who edited the report.we are most grateful to our sponsors for their insights, encouragement, and support throughout the process. john lockett, human research and engineering directorate, army research laboratory, recognized the need for this study and provided early support in getting the committee humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.viii acknowledgmentsestablished. maris vikmanis and edward martin, air force research laboratory, added their support once the committee process was under way.this report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the nrc™s report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report: jonathan grudin, adaptive systems and interaction group, microsoft research, redmond, wa; patricia m. jones, human factors research and technology division, nasa ames research center, moffett field, ca; alex kirlik, human factors department, university of illinois at urbanachampaign; david c. nagel, independent consultant, ascona group, los gatos, ca; christopher nemeth, cognitive technologies laboratory, the university of chicago; mary beth rosson, department of information sciences and technology, pennsylvania state university; and andrew sage, system engineering and operations research department, george mason university. although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the nal draft of the report before its release. the review of this report was overseen by thomas b. sheridan, engineering and applied psychology, emeritus, massachusetts institute of technology. appointed by the nrc, he was responsible for making certain that an independent examination of this report was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.richard w. pew, chairanne s. mavor, study directorcommittee on humansystem design support for changing technologyhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.ixcontentsexecutive summary 1 principles for successful system development, 2 policy recommendations, 4 research agenda, 5 the future, 71 introduction 9 the problem, 11 charge and scope, 16 the context, 18 themes, 23 report organization, 27part i: humansystem integration in the context of system development2 the system development process 31 principles for successful system development, 32 the evolving nature of system requirements, 33 principlesbased comparison of alternative process models, 34 the incremental commitment model, 36 views of the incremental commitment model, 39 project experience with icm principles, 51 conclusion, 53humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.x contents3 humansystem integration and the system development  process 55 humansystem integration in the incremental commitment  model, 57 communicating hsi issues and opportunities through shared  representations, 61 conclusion, 66 appendix 3a, 674 managing risks 75 identifying and analyzing risk, 78 handling options assessment, 85 executing risk mitigation, 885 case studies 91 unmanned aerial systems, 92 port security, 97 ﬁnextgenerationﬂ intravenous infusion pump, 105part ii: humansystem integration methods in system development6 dening opportunities and context of use 135 organizational and environmental context, 139 field observations and ethnography, 150 task analysis, 157 cognitive task analysis, 161 participatory analysis, 169 contextual inquiry, 175 event data analysis, 1777 dening requirements and design 189 usability requirements, 191 work domain analysis, 197 workload assessment, 207 participatory design, 210 contextual design, 216 physical ergonomics, 217 situation awareness, 223 methods for mitigating fatigue, 226 scenarios, 230 personas, 233humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.contents xi prototyping, 235 models and simulations, 2408 methods for evaluation 253 risk analysis, 253 analysis of human error, 256 usability evaluation methods, 265part iii: the future: scenarios, conclusions, and recommendations9 scenarios for the future 277 an integrated methodology, 278 knowledgebased planning for humansystem integration, 286 user participation, 28810 conclusions and recommendations 296 research and policy recommendations, 301references 331appendixesa sponsors and contributors 357b biographical sketches of committee members and staff 358index  365humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.1executive summaryin april 1991 business week ran a cover story entitled, ﬁi can™t work this ?#!!@ thing,ﬂ about the difculties many people have with consumer products, such as cell phones and vcrs. today, more than 15 years later, the situation is much the same. at quite a different level of scale and consequence of the disconnect between people and technology are the major largescale systems accidents for which human error was paramount, such as those at three mile island and chernobyl. similarly, a major, expensive console update to the nation™s air trafc control operations was cancelled because the operational personnel concluded that it would be too complicated and difcult to operate. these examples illustrate the pressures on industry and government as the complexity of the systems they seek to develop increase at the same time they are challenged to shorten the development cycle for those systems. these problems are magnied by the increasing prevalence of systems of systems. systems of systems arise when a collection of different systems, originally designed for their own purposes, are combined and coordinated to produce a very large system with new issues and challenges.these problems can be traced to a signicant challengešthat human capabilities and needs must be considered early and throughout system design and development. one aspect of the challenge has been providing the background and data needed for the seamless integration of humans into the design process from various perspectives (human factors engineering, manpower, personnel, training, safety and health, and, in the military, habitability and survivability). this collection of development activities humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.2 humansystem integration in system developmenthas come to be called humansystem integration (hsi). a second aspect has been a lack of commitment by funders and program managers to assign priority to these activities. a third aspect has been a lack of effective communication between the system engineers and humansystem domain experts.to address these challenges, the army research laboratory and the air force research laboratory of the u.s. department of defense asked the national academies, through its committee on human factors, to undertake a study of the current state of methods, tools, and approaches for analyzing human capabilities and needs and to develop a vision for creating an integrated, multidisciplinary, generalizable, humansystem design methodology. the committee on humansystem design support for changing technology was specically charged with four tasks:1. provide a comprehensive review of issues involved in design throughout the system life cycle that need to be addressed by a consideration of human cognitive and physical performance characteristics. this review will be used as a framework for further analysis of methodologies.2. evaluate the state of the art in humansystem engineering and (a) product development processes, (b) product design methodologies, and (c) product design tools.3. develop a vision for an integrated, multidisciplinary, generalizable, humansystem design support methodology and tool set. identify a set of core methods and tools needed to support design activities associated with a variety of systems.4. recommend a research plan suggesting how to achieve this ideal.in carrying out its work, the committee™s goal was to make recommendations that are relevant not only to the project™s military sponsors, but also to other government departments and the private sector, including the process control, manufacturing, and service industries.principles for successful system developmentthe committee identied ve principles that are critical to the success of humanintensive system development and evolution: (1) satiscing1 the requirements of the system stakeholdersšthe buyers, developers (including engineers and human factors experts), and users; (2) incremental growth of system denition and stakeholder commitment; (3) iterative system deni1 satiscing occurs in consensus building when the group looks toward a solution that everyone can agree on, even if it may not be the best.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.executive summary 3tion and development; (4) concurrent system denition and development; and (5) management of project risk.after analysis of several candidate system development models in terms of the ve principles, the committee proposes the incremental commitment model as a useful systems engineering approach and as a framework for examining categories of methodologies and tools that provide information about the environment, the organization, the work, and the human operator at each stage of the design process. although it is not the only model that could be used on future humanintensive systems and systems of systems, it provides a reasonably robust framework for explaining the study™s hsi concepts. a central focus of the model is the progressive reduction of risk through the full lifecycle of system development, to produce a costeffective system that meets the needs of all the stakeholders. costeffectiveness is achieved by focusing resources on highrisk aspects of the development and deemphasizing aspects that are judged to pose a limited risk. all kinds of potential risk, including hardware, software, and hsi risks, must be assessed to identify riskreduction strategies at each stage in the system development process. the model recognizes that, in very large and complex systems, requirements change and evolve throughout the design process. the approach to acquisition is incremental and evolutionary: acquiring the most important and wellunderstood capabilities rst; working concurrently on engineering requirements and solutions; using prototypes, models, and simulations as ways of exploring design implications to reduce the risk of specifying inappropriate requirements; and basing requirements on stakeholder involvement and assessments. when tradeoffs among cost, schedule, performance, and capabilities are not well understood, the model provides a framework to specify priorities for the capabilities and ranges of satisfactory performance, rather than to require precise and unambiguous requirements.the incremental commitment model has ve lifecycle development phases: exploration, valuation, architecting, development, and operation. in each phase, every activity must be considered, from system scoping through goals and objectives requirements and evaluation through operations and retirement. the specic level of the effort on each activity is riskdriven and thus varies across lifecycle phases and from project to project.the committee concludes that a model such as the incremental commitment model that incorporates the ve principles can provide a signicant improvement in the design of major systems, particularly with regard to humansystem integration. our policy recommendations follow from this conclusion. these recommendations are followed by an overview of the committee™s recommended research agenda.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.4 humansystem integration in system developmentpolicy recommendationsrecommendation: the u.s. department of defense and other government and private organizations should rene and coordinate the denition and adoption of a system development process that incorporates the principles embodied in the incremental commitment model. it should be adopted as the recommended approach for realizing the full integration of humanrelated design considerations with systems engineering in organizational policies and process standards, such as the dod 5000 series and the iso systems engineering standards.recommendation: the u.s. department of defense and other government and private organizations should revise current system acquisition policies and standards to enable incremental, evolutionary, capabilitiesbased system acquisition that includes hsi requirements and uses riskdriven levels of requirements detail, particularly for complex systems of systems and for collaborationintensive systems.recommendation: the u.s. department of defense and other government and private organizations should put the operational requirements of humansystem integration on a par with traditional engineering requirements at the beginning of the initial requirements analyses to determine which requirements have priority and provide an opportunity for negotiation.recommendation: when developing system acquisition programs, the u.s. department of defense and other government and private organizations should dene potential means for verifying and validating hsi requirements to enable supplier program managers to establish clearly speciable hsi technical performance measures for contracts.recommendation: the u.s. department of defense and other government and private organizations should account for hsi considerations in developing the technical, cost, and schedule parameters in the business offer. in particular, contracts need to re˚ect an understanding of how humansystem integration affects the ability to reuse existing technical solutions or the feasibility of inserting new technologies, as well as an appreciation of how anticipated hsi risks may affect meeting program award fee criteria. it is also important that the contractor understand how hsi elements in their product offering contribute to achieving market capture goals and subsequently the viability of their business case.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.executive summary 5research agendathe committee makes research recommendations that the u.s. department of defense and other research funders support (1) the development of shared representations for facilitating effective communication among funders, developers, and users, (2) the extension and expansion of current humansystem methods and tools, and (3) the full integration of human systems and engineering systems. chapter 10 provides details.shared representationseffective and efcient design requires meaningful communication among hardware, software, and hsi designers; among professionals in the domains of humansystem design (e.g., personnel, manpower, training, human factors); and among the stakeholders. with a great deal of diversity among the groups tasked with the design of complex systems, the potential for communication and collaboration failures increases if assumptions (and their associated mind sets) are not made explicit. one approach to dealing with such diversity is through shared representations. the production of an explicit representation at various stages in the design process can provide a focus for people from different disciplines to document what they have accomplished and provide a plan for what they will do next. just as architects provide blueprints, perspective drawings, and physical models to communicate a design, when people from different perspectives collaborate in a design process, they bring the results of various methods and tools to the activity as a shareable representation to communicate design opportunities and constraints. shared representations can be stories, sketches, models, simulations, prototypes, spreadsheets, or reports in various levels of detail.the committee recommends research to identify the characteristics of shared representations that communicate effectively across hsi domains and engineering disciplines.methods and toolsthere are many humansystem methods that inform the system design and development process and many produce shared representations. in this report we review more than 20 categories of methods, many with several variations. examples include environmental and organizational analysis, task analysis, eld observation, participatory analysis and design, event data analysis, physical ergonomics, modeling and simulation, risk analysis, and usability evaluation. each method is described broadly in terms of genhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.6 humansystem integration in system developmenteral characteristics, types of use, shared representations, contributions to the system design process, and strengths, weaknesses, and gaps. our review is not exhaustive but presents stateoftheart examples in the categories of methods that the committee agreed are core contributors and central to the provision of needed information about humans and humansystem integration. besides the strength in terms of sheer number of methods, the methods as a whole can also be characterized as highly ˚exible, ˚uid, tailorable, scalable, or modiablešall characteristics that are critical given the current complexity of systems and their associated design uncertainty.the committee recommends a detailed agenda to extend existing methods and the development of new methods of humansystem integration. the recommendations cover seven major areas:1. the development of software tools to capture and disseminate the results of context of use analyses so that they can more easily by applied in various phases of system lifecycle development.2. the active participation of users in engineering design, the future of unobtrusive, passive data collection, and the ethical considerations of both.3. the further development and validation of humansystem models to increase usability and expand their application.4. the further development of prototypes for training and organizational design.5. the identication and communication of humansystem development risk.6. the further development of costeffective usability evaluation methods and the more frequent and effective use of usability objectives at the beginning of a system development effort.7. the identication and assessment of humansystem integration to system adaptability and resilience.full integration of human systems and systems engineeringthe committee recommends research in seven areas to support the full meshing of humansystem integration and systems engineering into the system design and development process. these include1. managing integrated system development.2. providing traceability of hsi design objectives, decision points, and the rationale for decisions across lifecycle design phases.3. developing approaches to humansystem integration in the context of systems of systems.4. estimating the size of the hsi development effort.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.executive summary 75. creating knowledgebased planning tools for including humansystem integration in complex system development efforts.6. developing humansystem integration as a discipline and preparing hsi specialists to be system development managers.7. fostering more synergy between research and practice.the futurewith the policy and research we recommend, we envision methodology for humansystem integration that will be based on anticipated advances in technology in which the products of each design and development activity are manifest in representations that may be shared across the development community. in this approach, each product builds on the reusable components of previous ones. common threads are provided by storyboards, use cases, scenarios, time lines, models, and system simulations. the stakeholders in a system will cooperate as an integrated team. the resulting design will accomplish much of system integration before implementation begins, and the result will represent a system that is truly responsive to the needs of its users, the ultimate goal of humansystem integration.in addition to the development and application of an integrated methodology, the future would hold the opportunity for the development of a discipline of humansystem integration and the opportunity for hsiled system development, the more active participation by users in system design through the use of new webbased approaches and other technologies, and the development of a set of knowledgebased planning aids to support the sharing of information across domains.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.91introductionalthough interest in understanding the role of humans in systems and accommodating that role in design has a history of more than 60 years, there has been a continuing concern that, in each phase of development, the human element is not sufciently considered along with hardware and software elements. when information about the performance characteristics and preferences of operators and users is not introduced early enough in the process, there are higher risks for both simple and catastrophic failures in the systems that are produced. this leads to additional costs required to revise the design late in the development cycle and even sometimes to revisions after it has been elded. humansystem integration (hsi) is concerned with ensuring that the characteristics of people are considered throughout the system development process with regard to their selection and training, their participation in system operation, and their health and safety. it is also concerned with providing tools and methods meeting these same requirements to support the system development process itself.this volume provides a vision for integrating an understanding of human capabilities and needs into system design using an incremental model of systems engineering development that continually assesses risks, including risks associated with the human element, at each phase of the system development effort. the chapters present a large variety of methods (1) for describing human capacities, limitations, and needs, their tasks, and the environments in which they work and (2) for characterizing and evaluating alternative designs that require some form of humansystem interaction. in the context of developing a single system, these methods are extremely efhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.10 humansystem integration in system developmentfective for providing needed information in a timely manner when applied by trained humansystem design professionals. ineffective and inappropriate application can be attributed, in part, to lack of communication within the organization and the development team and a dearth of fully trained professionals as team members. additional methods and approaches are needed to complement the existing methodology as systems become more complex and the focus shifts from the design and operation of individual systems to systems of systems.a brief history of key events in the development of human factors appears in box 11. some of these events were driven by the interest of the behavioral science community; others came about as a result of accidents box 11 events in the growth of human factors1.  bell laboratories established a human factors group in the late 1930s.2.  in great britain, a new medical research council laboratory, the applied psychology research unit, was created in 1944.3.  in the u.s. military, efforts began during world war ii. immediately after the war, each military service established one or more laboratories for the study and application of human performance principles to the design of military systems. terms like ﬁqualitative and quantitative personnel requirements inventoryﬂ and the ﬁpersonnel subsystemﬂ were coined. the military procurement community began requiring the analysis of human factors issues in responding to requests for system development proposals.4.  the human factors society of america (now the human factors and ergonomics society) was founded in 1957, and the rst issue of the human factors journal was published in 1958.5.  the rst conference in the united states that focused on humancomputer interaction was held in 1982.6.  the manprint program (manpower personnel integration) was introduced by the army in 1984.7.  over the years, interest in human factors issues was stimulated in new domains by safety crises and, sometimes, by the establishment of new government agencies to respond to these crises. some notable examples include ł the national transportation safety administration was established in 1970 in response to the public outcry generated by ralph nader™s book, unsafe at any speed. ł the occupational safety and health administration (osha) was established in 1970 in response to safety concerns of hazardous chemical exposure in industry. ł the consumer product safety commission was established in 1972 in response to concerns about child safety in the home.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 11and safety concerns. in recent years, efforts to effectively incorporate humans into the system have been referred to as humansystem integration. two important features of the hsi approach are (1) a user focus on all aspects of the systems denition, development, and deployment stages and (2) the combined application of humanrelated technologies to the hsi domains (booher, 2003a, p. 7). a key element of the hsi approach is the coordination and integration of the hsi domains at each system lifecycle phase (u.s. department of defense, 1999). the hsi domains cover issues of manpower, personnel, training, human factors engineering, safety, health, and survivability. while the committee pays particular attention to the integration of human factors engineering in the system life cycle, we also explore approaches to integration across the hsi domains. it is important to note that we are concerned with the application of humansystem integration in the commercial context as well as in the military context.in this report we use the term ﬁhumansystem integrationﬂ to refer to the design activities associated with ensuring that the humansystem domains described above are considered in concert with all the other design activities associated with the systems engineering process, so that the resulting designs are truly responsive to the needs, capacities, and limitations of the ultimate users of the systems. although human factors engineering is but one of the hsi domains, the one concerned with providing the methods and expertise to take account of human performance capacities and limitations in formulating effective system designs, it receives particular emphasis in this report because the methods appropriate to it are often the same methods needed for the other domains. humansystem integration is also concerned with the design process itself. the design process requires humansšstakeholders and design team membersšwith their own performance capacities and limitations, and with diverse interests, to work together. it is important to ensure that the tools and methods supporting that process meet the requirements of humansystem integration as well.the problemone motivation for undertaking this study now is that industry and government are nding profound changes in the nature and complexity of the systems they seek to develop and at the same time are challenged to shorten the development cycle for new systems. there is pressure to reduce the staff required to support system operation, and this leads to increases in automation. however, not all automation actually reduces required staffing. sometimes automation changes the job requirements and takes away the handson knowledge that has proved to be so useful for maintaining ﬁsituation awareness.ﬂ sometimes it actually creates more work because now the automation, as well as the system itself, must be monitored and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.12 humansystem integration in system developmentcontrolled. sometimes it reduces the reliability and trustworthiness of the overall system and increases the requirements for backup personnel. system designers, like people in general, can be subject to an ﬁovercondenceﬂ bias, focusing on the potential benets of new technology while failing to anticipate the complex interactions and new problems that may emerge (feltovich et al., 2004). this has been referred to as the ﬁenvisioned worldﬂ problem (woods and dekker, 2000). there is an urgent need for improved hsi methods and tools that will enable system designers to anticipate and head off potential problems earlier in the design process (woods, 2002).considering the design of individual interface workstations in isolation is no longer enough. today™s complex systems are operated by teams of individuals whose interactions must be taken into account. even considering single systems is not enough. currently there are requirements to operate multiple systemsšsystems of systemsšin interaction with each other. the military is particularly concerned with systems of systems, although they are of equal concern in civilian industry (e.g., hospital systems, complex interlinked communications systems). furthermore, many of these systems of systems are adding an organizational component and respective complexities to the technological and personnel complexities already inherent in complex systems. finally, the emergence of serviceoriented architectures and the approaches called ﬁweb 2.0ﬂ to combinations of functionalities add to the immediate complexity and potential interdependencies of systems and their services.the eld of design is also undergoing rapid change at this time. there is continued pressure to reduce the design cycle time. software and hardware development methodologies supporting the design process are proliferating, but there is little understanding of which tools and methods are best for which purposes. similar methods and tools are created by different communities of practice with little awareness of the tools and best practices in the related elds. there has been no comprehensive framework to organize competing methods, and, as a result, comparisons tend to be situational with correspondingly limited generalizability.in spite of this long history, and in part because design continually faces new challenges, there are many examples of systems that have either failed entirely or have been adopted despite their inadequacies because of the need for their capabilities. often the reasons these adopted systems were considered unsuccessful are because they failed to meet the requirements of the human usersšthey required unreasonable workload, induced psychological and physical stress, or resulted in costly human error. they failed because their developers had inadequate understanding of, or overlooked consideration of, the unique capacities and limitations of people. examples include (1) military command and control vehicles for which the requirement for operation on the move had to be dropped late in the program, because humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 13vibration and motioninduced sickness in the operational crew was found to be unacceptable; (2) the costly abandonment of a new air trafc control console before it was introduced into the workplace because it was unreasonably complex and difcult to operate; and (3) the confusion that arises from controlling a home media system with ve different remote controls, or even with one ﬁuniversalﬂ remote with ve different modes.by the same token, there are examples of effective systems that have succeeded specically because of the attention that was paid to humansystem integration during system development. a primary example is the current generation of navy tactical decision support systems that was designed as part of the tadmus (tactical decision making under stress) program. this successful program was initiated in response to the tragic downing of an iranian air bus in 1986 by the uss vincennes, caused in part by poor humansystem integration. tadmus was a success because it took a humancentered design approach; the research and development (r&d) supporting it was assigned high priority by senior ofcer staff, and it brought researchers together with operational personnel. the con˚uence of these considerations gave the project a high prole and has in˚uenced much subsequent design in the navy.another outstanding example of success is the army comanche helicopter program. by modifying the acquisition program specically to recognize humansystem interaction as an integral part and by introducing hsi requirements early and throughout the acquisition program, the governmentindustry team substantially improved overall humansystem performance while realizing a cost saving of 40 times the cost of the hsi investment. this program was abruptly cancelled in 2004, the cause being attributed to ﬁchallenges of software integrationﬂ not humansystem issues. the reader interested in more detail about the humansystem features of this program or further examples in army programs is referred to the excellent review by booher and minninger (2003).an example of the commercial importance of humansystem interaction in risk analysis and risk avoidance is the precise humanperformance modeling done by the nynex science and technology organization in the evaluation of a proposed new operator services workstation (gray et al., 1993). using keystrokelevel analysis and parameter estimation, the nynex team was able to show that the proposed new design would paradoxically reduce human productivity. this early analysis, as well as subsequent decisions regarding the product, was credited with saving $2 million annually. in a similar r&d project, hsi observations and analyses of over 500 directory assistance calls at us west helped to correct the rst voice recognition application for directory assistance (muller et al., 1995). initial outcomes showed that the technologyassisted calls took signicantly longer than conventional calls and resulted in extremely negahumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.14 humansystem integration in system developmenttive customer response. the information gained through qualitative and quantitative analyses showed how to reverse the negative work outcomes through a simple redesign of the dialogue between customers and the voice recognition technology. in addition to obtaining the labor savings that were promised by the technology, the redesign also improved the customer responses, leading to the voice recognition technology that is part of nearly all u.s. directory assistance calls today.the reasons some system designs fail are multidimensional and complex. here are a few that the committee has identied:ł failure to introduce human factors considerations early enoughšin some cases needs and requirements are forecast even before the formal system acquisition process begins.ł lack of effective methods and tools to predict direct impacts and ripple effects of envisioned future systems early in the design process, particularly in the case of largescale systems and systems of systems with diverse elements that can interact in complex, difcult to anticipate ways.ł a tendency to focus on people as the errorprone weak links in a system that needs to be ﬁautomated away,ﬂ rather than as important contributors to overall system resilience that enable systems to adapt to unanticipated situations in need of support in that role (hollnagel, woods, and leveson, 2006).ł failure to apply known good methods routinely in practice, such as those specied in department of defense (dod) and international quality standards (iso) and recommended practices.ł lack of ability to abstract generalizable concepts and principles, as well as transportable models, across application contexts, limiting the ability to grow a solid body of human factors design knowledge.ł lack of synergy between research and practice, with the result that practitioners are not sufciently aware of relevant research and research is not sufciently informed by the body of knowledge gained from practice (norman, 1995; woods and christoffersen, 2002).ł lack of adequate hsi metrics to support progress monitoring, pass/fail reviews, and systemlevel evaluation.ł inadequate or poorly documented data on relevant human task performance.ł lack of effective use of methods and tools to support the hsi process.ł difculty of costjustifying resource allocation to study and resolve humansystem integration issues.ł inadequate education and training of system developers to sensitize them to the hsi issues.ł limited opportunities for the education of hsi specialists.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 15ł failure to assign resources as a result of lack of awareness that specic resources are needed to address hsi concerns.ł con˚icting requirements of various stakeholders in the system development process.ł insufcient advocacy for consideration of humansystem integration at the top level of relevant organizations.this list, developed independently, is quite consistent with the list cited in booher and minninger (2003). as previously mentioned, an underlying issue regarding system failures and the inadequacies associated with current system development and humansystem integration may be that many systems should actually be regarded as systems of systems.a consensus view held by the fellows of the international council on systems engineering (incose) is that a system is a collection of different elements that together produce results not obtainable by the elements alone. the elements, or parts, can include people, hardware, software, facilities, policies, and documents; that is, all things required to produce systemlevel results. the results include systemlevel qualities, properties, characteristics, functions, behavior, and performance. furthermore, incose thinks the valueadded of the system as a whole, beyond that contributed independently by the parts, is primarily created by the relationship among the parts; that is, how they are interconnected. what has changed in recent years is that, increasingly, these parts are systems themselves.over a dozen different denitions of a system of systems have emerged, emphasizing different aspects of product, process, and personnel (jamshidi, 2005; lane and valerdi, 2005). two fairly denitive treatments, maier (1998) and sage and cuppan (2001), identify their distinguishing features as having component systems that (1) achieve wellsubstantiated purposes in their own right even if detached from the overall system; (2) manage, in large part, for their own purposes rather than the purposes of the whole, plus (3) exhibit behavior, including emergent behavior, not achievable by the component systems acting independently; and (4) involve the role of a lead systems integrator (lsi) with sufcient capability, authority, and responsibility to architect, acquire, and integrate the component systems into a satisfactorily performing system. levis (2006) adds a condition that component systems may be added or removed while other parts of the overall system are operating.systems of systems may differ in several aspects, such as the number of separately managed component system owners, the number of separate missions (emergency medical, search and rescue, crisis response, insurgency suppression, limited or fullscale warfare), and the degree to which the component systems are newly developed or already developed. particular challenges for humansystem integration are multiowner, multimission systems humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.16 humansystem integration in system developmentof systems with numerous alreadydeveloped systems, which are likely to have incompatible humansystem interfaces, operating modes, assumptions about operator capabilities and underlying infrastructure, and degrees of mission criticality or safety criticality.as systems become increasingly complex, there is a corresponding increase in complexity in the systems (i.e., enterprises) that develop, operate, and sustain these systems in a global context (nightingale and rhodes, 2004). traditional methods related to systems engineering, enterprise engineering, or enterprise architecting are inadequate for designing and managing systems within systems and systems within enterprises. broader and more holistic methods within an engineering systems perspective are needed (nightingale and rhodes, 2004). while hsi methods offer considerable contributions to analyzing and designing complex systems, methods related to systems of systems and enterprises are still inadequate.an example of a system of systems under development is the air force falconer air operations center in arizona; in central command, air operations center is described in the integrator (mayer, 2005) as follows:the electronic systems center developed falconer aoc ﬁsystem of systemsﬂ is the combined forces air component commander™s weapon system for commanding air and space forces. a falconer operating with a theater response packagešmeaning fully equipped and manned for a theater waršcan manage and control up to 3,000 air sorties a day.charge and scopemany methods, tools, and techniques are available in the literature for addressing various aspects of humansystem integration, and there are several methods textbooks and standards:ł handbook of human factors and ergonomics methods (stanton et al., 2005);ł handbook of human factors and ergonomics (salvendy, 2006);ł handbook of human systems integration (booher, 2003b);ł a guide to task analysis (kirwan and ainsworth, 1992);ł handbook of human factors testing and evaluation (charlton and o™brien, 2002);ł systems engineering: system life cycle processes (international organization for standardization, 2002);ł software engineering: software product quality requirements and evaluation (international organization for standardization, 2006); andł handbook of systems engineering and management, revised edition (sage and rouse, in press).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 17these claim to offer a systematic approach, but each has serious deciencies. the methods tend to exist in isolation. nemeth (2004) has assembled existing methods into a coherent book, but still there are gaps in the existing methods and tools, and more work is needed to improve their integration into a coherent methodology with a suite of tools that would support such an integrated methodology. these are the issues we address in this report. specically, the charge to the committee is toł provide a comprehensive review of issues involved in design throughout the system life cycle that need to be addressed by a consideration of human cognitive and physical performance characteristics. this review will be used as a framework for further analysis of methodologies.ł evaluate the state of the art in humansystem engineering and (1) product development processes, (2) product design methodologies, and (3) product design tools.ł develop a vision for an integrated, multidisciplinary, generalizable, humansystem design support methodology and tool set. identify a set of core methods and tools needed to support design activities associated with a variety of systems.ł recommend a research plan suggesting how to achieve this ideal.although the u.s. military requested this report, our goal is to provide recommendations that are also relevant to other government departments as well as industry, including the process control, manufacturing, and service industries. furthermore, the committee dened the scope of its review and analysis to include environmental factors, organizational and work context, and matching the system to users™ needs as well as taking account of human cognitive and physical capacities and limitations. many audiences have a vested interest in, or will benet from, better methodologies for making systems useful and relevant, such as the following:ł acquisition and program managers,ł developers/engineers/rstlevel managers,ł contractor management,ł human factors/usability professionals and those representing other manprint domains,ł policy makers and regulators, andł research funders.in preparing this report, we tried to remain sensitive to these different constituencies and are hopeful that various chapters and recommendations are relevant to different subsets of them.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.18 humansystem integration in system developmentthe contextthe military sectorboth the army and the navy have active hsi programs that were created to inform system development efforts about the human side of system performance and the decisions that are required throughout the development cycle to adequately consider human roles and contributions. the air force is in the process of implementing a similar system. the army™s program, known as manprint, has been operating since the early 1980s; the navy™s system, seaprint (systems engineering, acquisition, and personnel integration) was formalized in 2003 to establish a manprintlike approach to navy system design and acquisition. the military services have control over all decisions related to development, elding, stafng, and operation of their new systems.manprint is ﬁa comprehensive management and technical program designed to improve total system (leader, unit/soldier, and equipment) performance by focusing on the human requirements for optimal system performanceﬂ (u.s. army, 2000). it consists of seven domains: manpower, personnel, training, human factors engineering, system safety, health hazards, and soldier survivability. seaprint ﬁprovides the navy with a single, integrated performancebased process that addresses all aspects of humansystem integrationšfrom capability denition through personnel deliveryﬂ (u.s. navy, 2005). it also includes seven domains, differing from manprint by combining safety and health and adding a domain labeled habitability. both programs are compatible with the seven hsi domains listed in the dening dod instruction 5000.2 operation of the defense acquisition system (u.s. department of defense, 2003a).representatives of the army and the navy have specied two major problems in effectively applying these programs. the rst is getting inputs from the required specialists to be considered early enough and at all stages of the system development life cycle. the second is the inability to effectively integrate hsi efforts across domains. in addition, many hsi analyses are applicable to more than one domain, and decisions made in one can signicantly constrain or in˚uence decisions in another. despite these opportunities for integration, those working in each domain tend to function separately, applying their own methods and tools.the domains of manpower, personnel, and training (mpt) encompass both supply and demand issues. supply involves the sources of personnel, their background, and how they will be trained. demand involves the determination of the number and skill levels of personnel required for each job specialty. the committee™s focus is on the demand side, where manpower, personnel, and training impact design through their implications humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 19for human factors requirements. managing workload is a critical design issue in humansystem integration. the number and type of personnel are intimately tied to workload requirements. similarly, there are important tradeoffs between the usability of a system and the requirements for training. how does one consider the tradeoffs among stafng levels, personnel quality, personnel turnover, training requirements, and system design? complex systems represent a usability challenge that can be solved by better design or by more extensive training. both of these kinds of issues in˚uence the manpower, personnel, and training investment required in new system development. although we do not address the supply side directly, it is important to understand the approaches and decisions in supplying manpower, personnel, and training as a context for the committee™s work.manpower refers to the number and type of personnel who operate, maintain, support, and provide training for systems. input concerning the number of personnel needed comes from policy makers in the pentagon at the top and from manpower analysts at the unit and the system levels at the bottom. although manpower assessment techniques are available to determine the appropriate number of operators/people for each piece of equipment/task, these techniques are often not used because they are labor, skill, and knowledgeintensive. a good example is imprint (improved performance research and integration tool), a modeling tool developed by the army human engineering directorate and used by the army and the navy for manpower planning and to inform humansystem design decisions (allender et al., 2005). this tool requires substantial training to be used effectively, and personnel with this training are not always readily available.another issue concerning the adequacy of input from the bottom up is that results of the analyses are often politically inconvenient or are overshadowed by budget constraints or logistics requirements. furthermore, expertise in unitlevel manpower analysis is rare. decisions made regarding the number of personnel can have an important in˚uence on the requirements for personnel basic abilities, system features, and training.personnel refers to the human aptitudes, skills, and experiences required to perform the jobs of operators, maintainers, and support personnel. the services apply a standardized set of entry requirements that have changed little over the past decades. the supply of enlisted personnel to the military primarily comes from 18 to 24yearolds in the general population who have received a high school diploma and can achieve an acceptable score on the armed forces qualication test (afqt). the services are almost completely staffed by applicants with scores in the higher range on the afqt. the afqt score and scores on combinations of subtests in the full armed forces aptitude test battery (asvab) are used to determine qualications for various jobs. the actual assignment to a job is also driven humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.20 humansystem integration in system developmentby the availability of a position opening. it is important to note that the philosophy of the military services is to recruit motivated individuals with an appropriate ability levelšthe skill and the knowledge needed for each military job is then developed through military training.studies examining how well the asvab subset scores predict job performance have shown only a weak relationship (national research council, 1991). more recently, the level of prediction from the asvab to job performance has been further reduced by the fact that, although jobs are changing with the introduction of technology, the old job descriptions remain in place.training prepares personnel to perform the tasks necessary to meet the mission or goals and objectives of the system. development of training requirements, methods, curricula, and training system design are important parts of the overall system design process. the length and intensity of training depends on the background, ability levels, and learning styles of the personnel in the training class; the complexity of the system; and the level of skill and knowledge needed to ensure the desired level of performance speed and accuracy. some training is designed for individual task performance; some for team or unitlevel performance. an important input to effective training is a task analysis that identies the skills and knowledge needed for acceptable performancešthis analysis requires updating as the system conguration changes or as new automation is introduced. although there may be some task analysis requirements that are unique to the training domain, the methods for creating this task analysis are substantially the same as those used for other system development purposes discussed in this report. inadequate training can result when work and task descriptions are outdated. training deciencies may also result from failure to allocate the necessary training time and budget, lack of ˚exible training schedules needed to meet learning requirements, and lack of useful prociency criteria.manpower, personnel, and system design decisions should take into account the level of training needed and the feasibility of delivering that training in the allowable time frame.the private sectorthe private or commercial sector is more difcult to characterize because of the wide variety of systems and products, of the differences in approaches to humansystem design, the central role of marketing, and because in the commercial product environment projects are more likely to be cancelled if milestones are not met in the early stages of the development process. companies generally develop products for use by other companies, groups, or individuals. some products require extensive training, and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 21some are subject to safety regulations. development efforts are driven by market forces; competition; time constraints; safety and liability exposure; and by customer characteristics, requirements, and budgets. hsi activities in the private sector focus on a number of activities, including, but not limited to, market research, risk analysis, product planning, development of product lines and platforms, usability testing, and product evaluation (rouse, 2003).privatesector products cover a wide range of sizes, complexity, and level of human involvement. on one hand, for example, there are complex systems in manufacturing, process control plants, nuclear power plants, network management, and air trafc control systems. these systems include large numbers of personnel performing a highly structured set of jobs requiring technical skills and knowledge. in this context, considerations of manpower, personnel, and training are relevant. on the other hand, there are many smaller scale singleuser systems (e.g., commercial products) for which training is critical but manpower and personnel issues are less relevant. many commercial products are released for which user training is impractical, so they need to have selfevident, intuitive user interfaces to be successful; indeed, for webbased commercial services, user training is impossible, and ease of use becomes a signicant, makeorbreak attribute.many privatesector companies perform a user analysis, or a similar assessment of the intended user, in the early stages of design, using such methods as contextual inquiry, scenarios, task analysis, cognitive task analysis, ethnography, or participatory analysis (these are discussed in chapter 6). this analysis of users™ capabilities is similar to the military™s personnel assessment. for some products, such as hospital medical devices, the user can be expected to have advanced skills and knowledge. when designing products intended for use by the general population, companies must account for a wide range of skill levels. with increasing regulatory pressure, companies are also designing for people with a range of disabilities, including visual, auditory, motor, and cognitive/developmental disabilities. a product that is poorly matched to a user™s capabilities may create frustration for the user, lower sales, increased need for training and customer support, and an overall increased cost. a product that is created to serve multiple types of users often has additional and unanticipated reach into new markets or applications.training takes many forms in the private sector. most products include such training aids as user manuals, help menus, and product support help lines. for complex or difcult to operate systems, a formal training program may be required. alternatively, online training may be needed. training requirements may be established as part of the design process or may be put into place after a product is on the market.new developments challenge these simple, old ways of thinking about humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.22 humansystem integration in system developmentdevelopment and deploymentšespecially the concepts often referred to as web 2.0 (e.g., o™reilly, 2005), in which each application provides a standardized interface (typically xml) to other applications, and new services can be created as through simple interfaces among these existing applications (making a ﬁcallﬂ between applications, similar to a subroutine call in a conventional program architecture). the standardization of data formats and protocols among these services allows very rapid prototyping and testing of new service concepts, and these integrations can lead to user experiences that appear to be entirely new concepts and functionalities. each such web site or module uses these standardized formats to offer ﬁservicesﬂ that can be called from other web sites or modulesšhence the more formal description as serviceoriented architectures (erl, 2005; soa, 2006). we list ve classes of these new ﬁsocial softwareﬂ services here (allen, 2004; ibm, n.d.; teton and allen, 2007; see also chi et al., 2007):1. combinations of data from multiple services, creating new services and new user experiences.2. easily consumed updates or ﬁfeedsﬂ from usercreated dynamic pages called ﬁweblogs or ﬁblogs.ﬂ3. sharing of annotations of websites, pictures, music, and other webaddressable objects through ﬁsocial taggingﬂ of web resources in a shared database, as well as the evolution of usercreated ﬁfolksonomiesﬂ as lowmaintenance alternatives to highcost enterprise taxonomies.4. sharing of dynamically updated personal information through  personcentric shared databases.5. negotiation and cocreation of shared knowledge, accessible to millions of users, at userconstructed online encyclopedias.these new serviceoriented architectures present new challenges in several areas. first is the speed with which new services can be created: development time in this very open environment decreases from years to days. second is the rate of change of the data in these new services, which can amount to many thousands of updates daily. third is the decentralization of the ﬁsourcingﬂ and control of the information, which is typically contributed by thousands of people who do not necessarily have other ties or relationships to one another. fourth is the current very loose security model for these services, which is likely to be tightened as the commercial and governmental uses of these technologies increase. all of these challenges highlight the need for input from users and analysis of the implications of these design alternatives for their human users, either before or while they are implemented. without specic humansystem requirements, the ease and speed of creation makes it even easier for designers to pursue their own clever but often inappropriate designs.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 23themesin addressing the charge, the committee identied several major themes that are woven through the chapters of this report. these include adopting a riskdriven approach to determining the need for hsi activity; tailoring the selection of methods to meeting time and budget constraints; developing and using shared representations for communication of issues and results among domains and disciplines; designing systems that can accommodate changing conditions and requirements in the workplace; and integrating hsi inputs across humansystem domains as well as across lifecycle phases.the committee proposes an incremental commitment model as a useful approach to system development. although it is not the only model that could be used on future humanintensive systems and systems of systems, it serves as a reasonably robust framework for explaining hsi concepts and for evaluating these via a set of case studies presented in chapter 5.this model is based on ve principles that are critical to success:1. satiscing of system stakeholders (e.g., users, acquirers, developers);2. incremental growth of system denition and stakeholder commitment;3. concurrent system denition and development;4. iterative system denition and development; and5. risk management.the details of this model appear in chapter 2.adopting a riskdriven approacha central focus of the incremental commitment model is the progressive reduction of risk throughout the system development life cycle with the goal of producing a costeffective system in which all stakeholders are considered winners. risk reduction is accomplished through the application of all relevant disciplines. in the past, the risks associated with humansystem integration have often been neglected in the system risk analysis process. in this report we emphasize the importance of including human factors and hsi risk as an integral part of this process. costeffectiveness is achieved by focusing resources on highrisk aspects of the development while deemphasizing development phases for aspects of the system that are judged to pose a limited risk. key elements of the model are the anchor points at the end of each cycle that call for stakeholder evaluation and commitment. these anchor points correspond to dod system development milestone reviews.engineering development risks are realized when development is impeded by unforeseen difculties in implementation or costly overruns. in contrast, hsi risks may be realized only at the conclusion of a system dehumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.24 humansystem integration in system developmentvelopment life cycle when the system is elded. they may lead to (1) underutilization or disuse of a product or system because it is difcult, inefcient, or dangerous to use; (2) human error in the use of the product or system, resulting in delays, serious compromises in system performance, or higher operational costs; or (3) both. for safetycritical or defense systems, either of these risks can lead to catastrophic events, including serious injury or death. for the manufacturer of commercial products, loss of sales, product liability lawsuits, and product recalls are major potential results of failure to adequately consider hsi risks.these operational stage risks are traceable to failures to fully integrate user needs and capabilities at earlier phases of the development cycle. to be effective, all riskreduction approaches, including humansystem integration, must be applied to identify and address risk reduction during early and middle stages of development. the use of such riskreduction approaches allows developers (or stakeholders) to select one design approach over another, gain an understanding of unanticipated effects through simulation studies, and generally have a higher level of condence that system development efforts are on track to meet requirements and avoid the operational stage risks of disuse, error, high costs, and lack of sales.in this report we take the view that the analysis of hsi risks should be considered at the same level of importance as the risks that specic hardware or software functions will not be able to meet the required technical specications. this consideration places hsi issues at the level of priority required to produce systems that will not fail due to poor attention to the manprint variables of importance.tailoring methods to time and budget constraintsthe committee recognizes that humansystem integration is in competition with other system development activities for the resources controlled by the project manager. sometimes the resource demands of the hsi team seem incommensurate with the project manager™s perceived benets. this perception arises partly because much of the resource investment needs to occur very early in the process, yet the benets are not harvested until late in the development process. use of risk analysis to focus resources on critical development issues can help to ameliorate this concern. nevertheless, the committee thinks that it is incumbent on the hsi specialists to tailor the application of their methodologies to the specic needs of a project. most of the methods and tools described in this report are designed to be adjustable and scalable to meet the needs of specic projects.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 25creating shared representations for communicationeffective and efcient design requires meaningful communication among hardware, software, and humansystem integration designers; among professionals in the domains of humansystem design (e.g., personnel, manpower, training, human factors); and among designers, users, and other stakeholders. just as an architect provides blueprints, perspective drawings, or physical models to communicate a design, when people from different perspectives collaborate in a design process, they bring various methods and tools to communicate effectively with other experts in the activity. in addition, each group often has its own mind set, language, and work practices. with so much diversity among the groups tasked with complex systems design, the potential for communication and collaboration failures increases if assumptions (and their associated mind sets) are not made explicit. effective use of multiple shared representations to mediate the activities of these multidisciplinary teams can foster innovation and a more effective design process.shared representations ﬁstand inﬂ and mediate communication between and among people engaged in a collaborative process. from the hsi perspective, they can be stories, reports, spreadsheets, models/diagrams, prototypes, or simulations. physical or electronic models of aspects of the humanmachine system are shared representations that provide a bridge between research and design in complex systems. the act of modeling can help teams detect unintended relations and features and lead to new connections and ideas. prototypes are one form of model that make explicit an aspect of form, t, or functionalityšthey can range from simple sketches to full physical mockups. by predicting and highlighting potential performance limitations, computer simulations of the humanmachine system are another form of model that can support shared understanding by the development stakeholders.the committee thinks that a current impediment to effective identication of hsi issues and risks and utilization of the resultant recommendations is the often vague nature of the products of hsi analysis. we are therefore emphasizing the importance of shared representations that truly communicate effectively with the other engineering disciplines and project stakeholders.shared representations are useful at all phases of the system design life cycle and play an important role at the anchor points at which stakeholders are asked to make commitments and reach agreements. the chapters in part ii of the report describes a variety of shared representations, including stories and scenarios, prototypes, user models, and simulations. the use of these representations is further explored in later chapters.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.26 humansystem integration in system developmentdesigning to accommodate changing conditions and requirements in the workplacenew technologies provide new capabilities, and these often generate new expectations, roles, and ways of doing things that are not always anticipated ahead of time (woods and dekker, 2000). unanticipated complexities can arise through increased system interconnectedness and interdependency, which create new sources of workload, problemsolving challenges, and coordination requirements. in turn, individuals in the system will adapt. they will exploit the new power provided by the technology in unanticipated ways, and they will create clever workarounds to cope with technology limitations, so as to meet the needs of the work and human purposes. to accommodate changes and unintended effects, the system development process should be viewed as incremental and ongoing. it is important to continue observations and analysis, even after a system has been implemented, both to evaluate the validity of designers™ assumptions and to drive further discovery and innovation. for a system to remain workcentered over time, it must not only support the elements of work identied at the design stage, but it must also be able to accommodate elements that the initial design did not appropriately capture and be adaptable to meet the changing nature of the work. systems need to be designed in ways to enable users to adapt the system to evolving requirements.researchers have argued for the importance of creating systems that afford the potential for productive adaptation to enable users to ﬁnish the designﬂ locally in response to the situated context of work. this idea can be extended to include not only local responses, but also adaptation of systems to keep pace with a constantly evolving world. the technologies of web 2.0 represent an extreme version of this approach, emphasizing the importance of users as cocreators of information, coeditors of collections of information, and coimplementers of new features through the increasingly easy technologies that enable the aggregation of features and services into new functionalities, experiences, and utilities (referred to as ﬁmashupﬂ technologies). in the latter sense, the design is never really nished. a signicant challenge currently facing organizations is their ability to adapt to rapid and unpredictable change in more appropriate ways than their competitors, including the adoption of new technologies and business practices (crisp, 2006). changes in hardware and software must be accompanied by changes in the use of humans in the rapidly evolving systems.the notion of designing for evolvability is discussed in more detail in part ii.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.introduction 27integrating hsi contributions across lifecycle phases and humansystem domainsthe primary features of the hsi concept are consideration of humans in the decisions made in each system lifecycle phase and the integration of inputs across domains dealing with the various humanrelated development issues at each lifecycle phase. these features have been stated by our military sponsors as critical considerations in effectively applying their programs.throughout the report we examine the role of hsi methods at each development phase and discuss how many of these methods provide inputs at several phases. chapter 6 focuses on methods that are applied early in the life cycle to help identify opportunities, structure the scope, and characterize various aspects of the context of use from the perspective of human attitudes, capabilities, limitations, and needs. chapter 7 carries some of these methods over into the design phases as well as introducing an additional set of methods. chapter 8 focuses on evaluation methods and their role throughout each lifecycle phase. when possible, we provide examples of shared representations that can be used for communication among humanrelated domains as well as among those working with the human elements, the software elements, and the hardware elements.report organizationfollowing this introduction, the report is divided into three parts. part i: humansystem integration in the context of system development consists of four chapters. chapter 2 describes the system development process, chapter 3 focuses on humansystem integration in the system development process and the use of shared representations for communication, and chapter 4 addresses hsi program risk. chapter 5 introduces three case studies: uninhabited aerial systems, port security, and a commercial medical device. these cases were selected because they provide examples of an existing system, a developing system, and a vision for a future system. they are used throughout the report to highlight different approaches, methods, and tools.part ii: humansystem integration methods in system development contains three chapters characterizing hsi methods and tools. each of these chapters provides an overview of the relevant methods, how they are used, the shared representations they generate, and their strengths and limitations. it is important to note that these chapters do not provide an exhaustive review but rather focus on the classes of methods that the committee humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.28 humansystem integration in system developmentidentied as central contributors of information to the system development process about topics relating to people.part iii: scenarios, conclusions, and recommendations provides the committee™s vision for the future and our conclusions and recommendations.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.part ihumansystem integration in the context of system development29humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.2the system development processthe ultimate goal of system development is to deliver a system that satises the needs of its operational stakeholdersšusers, operators, administrators, maintainers, interoperators, and the publicšwithin satisfactory levels of the resources of its development stakeholdersšfunders, acquirers, developers, suppliers, and others. from the perspective of humansystem integration (hsi), satisfying operational stakeholders™ needs can be broadly construed to mean that a system is usable and dependable, permits few or no human errors, and leads to high productivity and adaptability. developing and delivering systems that simultaneously satisfy all these stakeholders usually requires managing a complex set of risks, such as usage uncertainties, schedule uncertainties, supply issues, requirements changes, and uncertainties associated with technology maturity and technical design. each of these areas poses a risk to the delivery of an acceptable operational system within the available budget and schedule. endstate operational system risks can be categorized as uncertainties in achieving a system mission, carrying out the work processes, operating within such constraints as cost or personnel, satisfying operational stakeholders, and achieving an acceptable operational return on investment.this chapter summarizes the committee™s analysis of candidate models of system design, development, and evolution processes with respect to a set of studyderived principles critical to the success of humanintensive system development. it presents the results of synthesizing the contributions of these models along with key human factors processes into an incremental commitment model (icm) that is used as a process framework for application of the study™s recommended processes, methods, and tools, as well as 31humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.32 humansystem integration in system developmentfor illustrating their successful application in three humansystem design case studies (see chapter 5).principles for successful system developmentthe ve principles critical to the success of humanintensive system development and evolution were evolved during the study and validated by analysis of the critical success factors of awardwinning projects and application to the case studies in chapter 5:1. stakeholder satiscing. if a system development process presents an operational or development stakeholder with the prospect of an unsatisfactory outcome, the stakeholder will generally refuse to cooperate, resulting in an unsuccessful system. stakeholder satiscing involves identifying the stakeholders critical to success and their value propositions; negotiating a mutually satisfactory set of system requirements, solutions, and plans; and managing proposed changes to preserve a mutually satisfactory outcome.2. incremental growth of system denition and stakeholder commitment. this characteristic encompasses the necessity of incremental discovery of emergent humansystem requirements and solutions via such discovery methods as prototyping, operational exercises, and the use of early system capabilities. requirements and commitment cannot be monolithic or fully prespeciable for complex, humanintensive systems; understanding, trust, denition, and commitment are achieved through a cyclic process.3. iterative system denition and development. incremental and evolutionary approaches lead to cyclic renements of requirements, solutions, and development plans. such iteration helps projects to learn early and efciently about operational and performance requirements.4. concurrent system denition and development. initially, this includes concurrent engineering of requirements and solutions, as well as integrated product and process denition. in later increments, changedriven rework and rebaselining of nextincrement requirements, solutions, and plans occur simultaneously with development of the currentsystem increment. this allows early elding of core capabilities, continual adaptation to change, and timely growth of complex systems without waiting for every requirement and subsystem to be dened.5. risk managementšriskdriven activity levels and anchor point milestones. the level of detail of specic products and processes will depend on the level of risk associated with them. if the user interface is considered a highrisk area, for example, then more design activity will be devoted to this component to achieve stakeholder commitments at particular design anchor points. if, however, interactive graphic user interface (gui) builder humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 33capabilities make it low risk not to document evolving gui requirements, much timeconsuming effort can be saved by not creating and continually updating gui requirements documents while evolving the gui to meet user needs.the evolving nature of system requirementstraditionally, requirements have served as the basis for competitive selection of system suppliers and subsequent contracts between the acquirer and the selected supplier. as such, they are expected to be prespecicably complete, consistent, unambiguous, and testable. frequently, progress payments and award fees are based on the degree to which these properties are satised.however, particularly as systems depend more and more on being parts of a networkcentric, collaborationintensive system of systems, the traditional approach to system requirements has encountered increasing difculties that these key icm principles have been evolved to avoid. these difculties includeł emergent requirements. the most appropriate user interfaces and collaboration modes for a humanintensive system are not speciable in advance but emerge with system prototyping and usage. forcing them to be prematurely and precisely specied generally leads to poor business or mission performance and expensive late rework and delays (highsmith, 2000).ł rapid change. specifying currentpointintime snapshot requirements on a costcompetitive contract generally leads to a big design up front and a pointsolution architecture that is hard to adapt to new developments. each of the many subsequent changes then leads to considerable nonproductive work in redeveloping documents and software, as well as in renegotiating contracts (beck, 1999).ł reusable components. prematurely specifying requirements (e.g., hasty specication of a 1second response time requirement when later prototyping shows that 4 seconds would be acceptable) that disqualify otherwise costeffective reusable components often leads to overly expensive, late, and unsatisfactory systems (boehm, 2000).these key principles focus on (1) incremental and evolutionary acquisition of the most important and bestunderstood capabilities; (2) on concurrently engineering requirements and solutions; (3) on using prototypes, models, and simulations as ways of obtaining information to reduce the risk of specifying inappropriate requirements; and (4) on basing requirements on stakeholder negotiations once their implications are better understood.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.34 humansystem integration in system developmentthese principles work best when stakeholders adopt a different vocabulary for dealing with requirements. the primary dictionary denition of a requirement is ﬁsomething required, i.e., claimed or asked for by right and authority.ﬂ it is much easier to make progress toward a mutually satisfactory negotiated solution if stakeholders use more negotiationoriented terms such as ﬁgoals,ﬂ ﬁobjectives,ﬂ or ﬁvalue propositionsﬂ rather than assuming that they are dealing with nonnegotiable ﬁrequirements.ﬂ and when tradeoffs among cost, schedule, performance, and capabilities are not well understood, it is better to specify prioritized capabilities and ranges of mutually satisfactory performance, rather than to insist on precise and unambiguous requirements. however, following principle 5 above on the riskdriven level of product detail, it is important to converge on precise requirements when the risk of having them be imprecise is high. some good examples are humancomputer interaction protocols for safetycritical systems and interfaces among separately developed missioncritical subsystems.principlesbased comparison of alternative process modelsour study included an analysis of candidate systems development process models with respect to the ve critical principles for success. the candidate models include the waterfall, v, spiral, and concurrent engineering process models discussed in the rst two chapters of the handbook of systems engineering and management (sage and rouse, 1999a, 1999b; patterson, 1999), plus emerging candidates, such as agile methods (beck, 1999; highsmith, 2000), vmodel updates (federal republic of germany, 2004), and 2001 extensions of the spiral model (boehm and hansen, 2001).our analysis, summarized in table 21, indicates that all of the models make useful contributions but exhibit shortfalls with respect to human factors considerations, particularly in explicit guidance for stakeholder satiscing. puresequential implementations of the waterfall and vmodels are not good matches for humanintensive systems. although they are becoming less frequent, they are still often encountered due to the imposition of existing contracting clauses and standards. more recently, the vmodel xt has adopted more riskdriven and incremental approaches that encourage concurrent engineering (federal republic of germany, 2004), but it takes some skill to build in stakeholder satiscing and to avoid overly heavyweight implementations and difculties in coping with rapid change. riskdriven evolutionary development is better at coping with rapid change, but it can have difculties in optimizing around early increments with architectures that encounter later scalability problems. concurrent engineering explicitly addresses incremental growth, concurrency, and iteration. although comhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 35table 21 principlesbased comparison of alternative process modelsprocess modelsprinciplesstakeholder satiscingincremental growthconcurrencyiterationrisk managementsequential waterfall, vassumed via initial requirements; no specicssequentialnonoonce at the beginningiterative, riskdriven waterfall, vassumed via initial requirements; no specicsriskdriven; missing specicsrisky partsyesyesriskdriven evolutionary developmentrevisited for each iterationriskdriven; missing specicsrisky partsyesyesconcurrent engineeringimplicit; no specicsyes; missing specicsyesyesimplicit; no specicsagilefix shortfalls in next phaseiterationsyesyessomespiral process 2001driven by stakeholder commitment milestonesriskdriven; missing specicsyesriskdrivenyesincremental commitmentstakeholderdriven; stronger human factors supportriskdriven; more specicsyesyesyespatible with stakeholder satiscing and risk management, it lacks much explicit guidance in addressing them.agile methods are even better at coping with rapid change, but they can have even more difculties with scalability and with missioncritical or safetycritical systems, in which xing shortfalls in the next increment is not acceptable. there is a wide variety of agile methods; some, such as lean and featuredriven development, are better at scalability and criticality than others. the version of spiral development in boehm and hansen (2001), with stakeholder satiscing and anchor point milestones, covers all of the principles, but it is unspecic about how risk considerations guide iteration and incremental growth. our analysis of these models indicates primary shortfalls in support of human factors integration and unproven ability to scale up to the future process challenges involving emergent, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.36 humansystem integration in system developmentnetworkcentric, massively collaborative systems of systems (maier, 1998; sage and cuppan, 2001).the committee undertook to integrate human factors considerations into the spiral 2005 process model (boehm and lane, 2006), a generalization of the winwin spiral model being used in the future combat systems system of systems (boehm et al., 2004). the result is the incremental commitment model, discussed in the next section. although, it is not the only model that could be used on future humanintensive systems of systems, it has served as a reasonably robust framework for explaining the study™s hsi concepts, and for evaluating these via the case studies presented in chapter 5.the incremental commitment modelan overview of the icm lifecycle process is shown in figure 21. it identies the concurrently engineered lifecycle phases; the stakeholder commitment review points and their use of feasibility rationales to assess the compatibility, feasibility, and risk associated with the concurrently engineering artifacts; and the major focus of each lifecycle phase. there are a number of alternatives at each commitment point: (1) the risks are concurrent riskandopportunitydriven growth of system understanding and definitionevaluation of evidence of feasibility to proceedstakeholder review and commitmentactivitiesicmlifecycle phasesexplorationvaluationarchitectingdevelopment1 architecting2operation1 development2 architecting3...explorationcommitmentreviewvaluationcommitmentreviewgeneral/dod milestonesarchitecturecommitmentreviewdevelopmentcommitmentreviewoperationscommitmentreviewoperationscommitmentreviewecrvcr/cdacr/adcr/bocr1 /c1dcr2 /b2ocr2 /c2dcr3 /b3too high, unaddressableadjust scope, priorities, or discontinueinitial scopingconcept definitioninvestmentanalysissystem architectingincrement 1developmentincrement 2architectingrebaselineincrement 1operationsincrement 2developmentincrement 3architectingrebaselinehigh, butaddressableacceptablenegligiblerisk?risk?risk?risk?risk?.........feasibility rationales............21figure 21 overview of the incremental commitment lifecycle process.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 37negligible and no further analysis and evaluation activities are needed to complete the next phase; (2) the risk is acceptable and work can proceed to the next phase; (3) the risk is addressable but requires backtracking; and (4) the risk is too great and the development process should be rescoped or halted. these risks are assessed by the system™s stakeholders, whose commitment will be based on whether the current level of system denition gives sufcient evidence that the system will satisfy their value propositions (see box 21).the incremental commitment model builds on the early verication and validation concepts of the vmodel, the concurrency concepts of the concurrent engineering model, the lighterweight concepts in the agile and lean models, the riskdriven concepts of the spiral model, the phases and anchor points in the rational unied process (rup) (royce, 1998; kruchten, 1999; boehm, 1996), and recent extensions of the spiral model to address systems of systems acquisition (boehm and lane, 2006). in comparison to the softwareintensive rup, the incremental commitment model also addresses hardware and human factors integration. it extends the rup phases to cover the full system life cycle: an exploration phase precedes the rup inception phase, which is refocused on valuation and investment analysis. the rup elaboration phase is refocused on architecting; the rup construction and transition phases are combined into development; and an additional operations phase combines operations, production, maintenance, and phaseout. an integration of the rup and the incremental commitment model is being prepared for use in the opensource eclipse process frameworks.in comparison to the sequential waterfall (royce, 1970) and vmodels (federal republic of germany, 2004), the incremental commitment model explicitly emphasizes concurrent engineering of requirements and solutions, establishes explicit feasibility rationales as pass/fail milestone criteria; explicitly enables riskdriven avoidance of unnecessary documents, phases, and reviews; and provides explicit support for a stabilized currentincrement development concurrently with a separate change processing and rebaselining activity to prepare for appropriate and stabilized development of the next increment. these aspects can be integrated into a waterfall or vmodel, enabling projects required to use such models to cope more effectively with systems of the future.the icm commitment milestones correspond fairly closely with the department of defense (dod) acquisition milestones as dened in dod instruction 5000.2 (u.s. department of defense, 2003a). for example, the icm milestone commitment to proceed into development based on the validated lifecycle architecture package (an operations concept description, requirements description, architecture description, lifecycle plan, working prototypes or highrisk elements, and a feasibility rationale providing humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.38 humansystem integration in system developmentbox 21 valuebased systems and software engineering in order for a system™s stakeholders to commit their personal material and nancial resources to the next level of system elaboration, they must be convinced that the current level of system elaboration provides evidence that their value propositions will be satised by the system. this success condition is consistent with the theory w (winwin) approach to valuebased systems and software engineering, which states that a project will be successful if and only if it makes winners of its successcritical stakeholders. if the project does not create a satisfactory value proposition for some successcritical stakeholders (a winlose situation), they will refuse to participate or will counterattack, generally creating a loselose situation for all stakeholders. the associated key valuebased principles for creating a successcritical stakeholder winwin outcome are (1) to identify the successcritical stakeholders and their value propositions; (2) to identify, confront, and resolve con˚icts among these value propositions; (3) to enable the stakeholders to negotiate a mutually satisfactory or winwin solution region or opportunity space; and (4) to monitor the evolution of the opportunity space and apply corrective or adaptive actions to keep the opportunity space viable or increase its value (boehm and jain, 2005). the associated key valuebased practices address these principles and also involve using alternative terminology to traditional project or system acquisition terminology: earlystage ﬁgoals, objectives, value propositions, or win conditionsﬂ rather than ﬁrequirementsﬂ; ﬁsolution spaceﬂ rather than ﬁsolutionﬂ; ﬁdesired and acceptable levels of serviceﬂ rather than ﬁthe required level of serviceﬂ; ﬁsatiscingﬂ rather than ﬁoptimizingﬂ; and ﬁsuccesscritical stakeholder or partnerﬂ rather than ﬁvendor, supplier, or worker.ﬂ key valuebased practices for identifying the successcritical stakeholders and their value propositions include ethnographic techniques, plus a technique called results chains (thorp, 1998) for identifying successcritical stakeholders. other useful techniques include scenarios, prototypes, brainstorming, quality function deployment, business case analysis, and participatory design, plus asking ﬁwhy?ﬂ for each ﬁwhatﬂ or ﬁhowﬂ identied by a stakeholder. key valuebased practices for identifying, confronting, and resolving con˚icts among stakeholder value propositions include inventing options for mutual gain (fisher and ury, 1981), expectations management, business case analysis, and groupbased techniques for prioritizing desired capabilities and for identifying desired and acceptable levels of service. key valuebased practices for enabling stakeholders to negotiate a mutually satisfactory or winwin solution region or opportunity space include the con˚ict resolution techniques just described, plus negotiation techniques (raiffa, 1982); riskbased techniques for determining how much of an activity, artifact, or level of service is enough, such as real options theory (black and scholes, 1973; amram and kulatilaka, 1999); and groupware support systems for negotiating stakeholder winwin requirements. key valuebased practices for monitoring and keeping the opportunity space viable or increasing its value include marketwatch and technologywatch techniques, incremental and evolutionary development, architecting to accommodate future change, adaptive control techniques, and businessvalueoriented earned value management systems.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 39evidence of their compatibility and feasibility) corresponds fairly closely with dod™s milestone b commitment to proceed into the development and demonstration phase.views of the incremental commitment modelthe following section provides multiple views of the incremental commitment model, including a process model generator view, a concurrent level of activity view, an anchor point milestone view, a spiral process view, and an incremental development view for incorporating rapid change and high assurance using agile and plandriven teams. it concludes with a comparison of the incremental commitment model with other oftenused process models.process model generator viewas shown by the four example paths through the incremental commitment model in figure 22, the incremental commitment model is not a single monolithic onesizetsall process model. as with the spiral model, it is a riskdriven process model generator, but the incremental commitment model makes it easier to visualize how different risks create different processes.in example a in the gure, a simple business application based on an appropriately selected enterprise resource planning (erp) package, there is no need for a valuation or architecting activity if there is no risk that the erp package and its architecture will not costeffectively support the application. thus, one could go directly into the development phase, using an agile method, such as a scrum/extreme programming combination. there is no need for big design up front (bduf) activities or artifacts because an appropriate architecture is already present in the erp package. nor is there a need for heavyweight waterfall or vmodel specications and document reviews. the fact that the risk at the end of the exploration phase is negligible implies that sufcient risk resolution of the erp package™s human interface has been done.example b involves the upgrade of several incompatible legacy applications into a serviceoriented webbased system. here, one could use a sequential waterfall or vmodel if the upgrade requirements are stable, and its risks are low. however, if for example the legacy applications™ user interfaces were incompatible with each other and with webbased operations, a concurrent riskdriven spiral, waterfall, or vmodel that develops and exercises extensive user interface prototypes and generates a feasibility rationale (described below) would be preferable.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.40 humansystem integration in system developmentexample a. simple enterprise resource planning (erp) based applicationactivities general/dod milestonesexample b. complex, but feasible product developmentexample c. stakeholders agree that more convergence of objectives is necessaryexample d. a superior product enters the markettoo high, unaddressablehigh, butaddressableacceptablenegligiblerisk?risk?risk?risk?risk?negligibleacceptableacceptableacceptable...acceptableacceptablerisk?risk?risk?risk?risk?acceptableacceptableacceptable...acceptableacceptablerisk?risk?risk?risk?risk?acceptableacceptableacceptable...acceptableacceptablerisk?risk?risk?risk?risk?too high, unaddressablehigh, butaddressablediscontinue icmlifecycle phasesexplorationvaluationarchitectingdevelopment1 architecting 2operation1 development2 architecting3...explorationcommitmentreviewvaluationcommitmentreviewarchitecturecommitmentreviewdevelopmentcommitmentreviewoperationscommitmentreviewoperationscommitmentreviewecrvcr/cdacr/adcr/bocr1 /c1dcr2 /b2ocr2 /c2dcr3 /b322figure 22 different risks create different icm processes.in example c, the stakeholders may have found during the valuation phase that their original assumptions were optimistic about the stakeholders having a clear, shared vision and compatible goals with respect the proposed new system™s concept of operation and its operational roles and responsibilities. in such a case, it is better to go back and ensure stakeholder value proposition compatibility and feasibility before proceeding, as indicated by the arrow back into the valuation phase.in example d, it is discovered before entering the development phase that a superior product has already entered the marketplace, leaving the current product with a nonviable business case. here, unless a viable business case can be made by adjusting the project™s scope, it is best to discontinue it. it is worth pointing out that it is not necessary to proceed to the next major milestone before terminating a clearly nonviable project, although stakeholder concurrence in termination is essential.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 41concurrent levels of activity viewthe concurrent levels of activity view shown in figure 23 is an extension of a similar view of concurrently engineered software projects developed as part of the rational unied process (kruchten, 1999). as with the rup version, it should be emphasized that the magnitude and shape of the levels of effort will be riskdriven and likely to vary from project to project. in particular, they are likely to have minirisk/opportunitydriven peaks and valleys, rather than the smooth curves shown for simplicity in the gure. the main intent of this view is to emphasize the necessary concurrency of the primary successcritical activity classes, shown as rows in figure 23. thus, in interpreting the exploration column, although system scoping is the primary objective of this phase, doing it well involves a considerenvisioning opportunitiessystem scopingunderstanding needsactivity categorysystemicmlifecycle phasesexplorationvaluationarchitectingdevelopment1 architecting 2operation1 development2 architecting3explorationcommitmentreviewvaluationcommitmentreviewgeneral/dod milestonesarchitecting and designing solutions a. system lifecycle planningevaluationnegotiating commitmentsdevelopment and evolutionmonitoring and controloperations and retirementorganizational capability improvementarchitecturecommitmentreviewdevelopmentcommitmentreviewoperationscommitmentreviewoperationscommitmentreviewoc1oc2oc3oc1oc2legacyb. human c. hardwared. softwaregoals/objectivesrequirements...ecrvcr/cdacr/adcr/bocr1 /c1dcr2 /b2ocr2 /c2dcr3 /b323levels of activityfigure 23 icm activity categories and level of effort.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.42 humansystem integration in system developmenttable 22 primary focus of hsi activity classes and methodsactivity classexamples of hsi methods described in this volumesystems engineering 1. envisioning opportunitiesœ field observations and ethnographyœ participatory analysisœ modelingœ change monitoring (technology, competition, marketplace, environment) 2. system scopingœ organizational and environmental context analysisœ field observations and ethnographyœ participatory analysisœ investment analysisœ system boundary denitionœ resource allocationœ external environment characterizationœ successcritical stakeholder identication 3. understanding needs œ organizational and environmental context analysisœ field observations and ethnographyœ task analysisœ cognitive task analysisœ participatory analysisœ contextual inquiryœ event data analysisœ prototypingœ models and simulationsœ usability evaluation methodsœ successcritical stakeholder requirementsœ competitive analysisœ market researchœ future needs analysis 4. goals/objectives and requirementsœ usability requirements methodsœ scenariosœ personas 5. architecting solutionsœ task analysisœ usability requirements methodsœ work domain analysisœ workload assessmentœ participatory designœ contextual designœ physical ergonomicsœ situation awarenessœ methods for mitigating fatigueœ prototypingœ models and simulationsœ usability evaluation methodsœ architecture frameworksœ commercial off the shelf/reuse evaluationœ legacy transformation analysisœ humanhardwaresoftware allocationœ quality attribute analysisœ synthesisœ facility/vehicle architectingœ equipment designœ component evaluation and selectionœ supplies/logistics planningœ construction/maintenance planningœ architectural style determinantsœ component evaluation and selectionœ physical/logical designœ evolvability designhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 43activity classexamples of hsi methods described in this volumesystems engineering 6. lifecycle planningœ usability requirements methods (common industry format)œ risk analysisœ phased objectives (increments, legacy transformations)œ milestones and scheduleœ roles and responsibilityœ approachœ resourcesœ assumptions 7. evaluationœ usability requirements methods (common industry format)œ prototypingœ models and simulationœ risk analysisœ usability evaluation methodsœ evidence of tness to proceedœ feasibility (usability, functionality, safety)œ other quality attributesœ cost/schedule riskœ business case mission analysisœ stakeholder commitmentœ simulations, models, benchmarks, analysis 8. negotiating commitmentsœ usability requirements methods (common industry format)œ risk analysisœ dependency/compatibility tradeoff analysisœ expectation management, prioritizationœ option preservationœ incrementing sequencing  9. development and evolutionœ usability requirements methods (common industry format)œ models and simulationœ risk analysisœ usability evaluation methodsmaterial/operational solution analysis; make or buy analysis; acquisition planning; source selection; contracting/incentivization; human/hardware/software element development and integration; legacy transformation preparation; incremental installation10. monitoring and controlœ organizational and environmental context analysisœ risk analysisprogress monitoring vs. plans; corrective action; adaptation of plans to change monitoring11. operations and retirementœ organizational and environmental context analysisplanned operations and retirement; ooda (observe, orient, decide, act) operations and retirement; adaptation of operations to change monitoring12. organizational capability improvementœ organizational and environmental context analysisorganizational goals and strategy denition; resource allocation; capability improvement activitiesnote: hsi methods often span multiple activity classes.table 22 continuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.44 humansystem integration in system developmentable amount of activity in understanding needs, envisioning opportunities, identifying and reconciling stakeholder goals and objectives, architecting solutions, lifecycle planning, evaluation of alternatives, and negotiation of stakeholder commitments. many hsi bestpractice tables conne each recommended practice to a single phaseactivity cell. experts treat these connements as suggestions that need not be followed, but nonexpert decision makers often follow such connements literally, seriously reducing their effectiveness.table 22 shows the primary methods and work products involved in each activity class. the second column of the table shows the primary hsi methods that are discussed in part ii. the third column shows the primary corresponding systems engineering methods. appendix table 31 in chapter 3 is a more detailed presentation of activities, methods, and best practices contained in iso/pas 18152 (international organization for standardization, 2003).the development commitment anchor point milestone reviewfigure 23 suggests that a great deal of concurrent activity is planned to occur within and across the various icm phases. this gives rise to two main questions. first, more specically than in figures 22 and 23, what are the main concurrent activities that are going on in each phase? second, how are the many concurrent activities synchronized, stabilized, and assessed for risk at the end of each phase? figure 24, an elaboration of figure 22, provides the nextlevel answer for the rst question.the elaboration of the concurrent engineering and feasibility evaluation activities makes it clearer just what is being concurrently engineered and evaluated in each phase. for example, at the development commitment review (dcr), the stakeholders and specialty experts review the lifecycle architecture (lca) package for the overall system and for each increment to assure themselves that it is worthwhile to commit their human, nancial, and other resources to the next phase of system development.during the architecting phase, the project prepares for the dcr by concurrently engineering the system™s operational aspects into a detailed operational concept and set of system requirements; the various commercial off the shelf, custom, and outsourced capabilities into a compatible buildto architecture; and the business case and resource constraints into a set of compatible plans, budgets, and schedules for each phase and for the overall system.the nextlevel answer for the second question on synchronization, stabilization, and risk assessment is provided by the contents of the icm architecture commitment review (acr) and dcr anchor point milestone feasibility rationales referred to in figure 24 and shown in box 22. the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 45concurrent riskandopportunitydriven growth of system understanding and definitionactivitiesicmlifecycle phasesexplorationvaluationarchitectingdevelopment1 architecting 2operation1 development2 architecting3...explorationcommitmentreviewvaluationcommitmentreviewgeneral/dod milestonesarchitecturecommitmentreviewdevelopmentcommitmentreviewoperationscommitmentreviewoperationscommitmentreviewecrvcr/cdacr/adcr/bocr1 /c1dcr2 /b2ocr2 /c2dcr3 /b3stakeholder review and commitmentevaluation of evidence of feasibility to proceedexploration andinitial scoping of technical, economic,sociopolitical, & managerial aspects of thenew initiative. environment competition mission needs stakeholder readinessdefinition & analysis ofscope & solution alternatives human, hardware, software factors mission analyses, business casestoplevel opsconcept, requirements, architecture, lifecycle plansdetailed missionscenarios,business work flows, macroergonomicsaspectscots, outsource partnerselectionssystem/human/hardware/software buildto architecturedetailed opsconcept,requirements,architecture, plans (systemincrement lifecyclearchitecturepackages)use lca1package forstabilized development,v&v of increment 1concurrent, agile changeprocessing,rebaselining oflca2 ...lcanpackagesuse lca2 package forstabilized development, v&v of increment 2concurrentagile changeprocessing,rebaselining oflca3 ...lcanpackagesoperations and usage monitoring ofincrement 1.........high, butaddressableacceptablenegligiblerisk?risk?risk?risk?risk?ethnographic,operationsanalysis, models,simulations,prototypestoplevelfeasibilityrationale, trade studies, business casedetailedfeasibilityrationale,business caseincrement1readiness for operations; lca2 feasibilityrationaleincrement2readiness for operations; lca3 feasibilityrationaletoo high, unaddressableadjust scope, priorities, or discontinue24figure 24 elaboration of the icm lifecycle process.contents indicate that the project is responsible not only for producing a set of artifacts, but also for producing the evidence of their compatibility and feasibility. this evidencešfrom models, simulations, prototypes, benchmarks, analyses, etc.šis provided to experts and stakeholders in advance of the milestone review. shortfalls in this evidence for compatibility and feasibility of the concurrently engineered artifacts should be identied by the system developer as potential project risks and addressed by riskmanagement plans. any further shortfalls in the evidence or the risk management plans found by the reviewers should be communicated to humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.46 humansystem integration in system developmentbox 22 icm architecture commitment review and development commitment review for the anchor point milestone feasibility rationale contentł evidence provided by the developer and validated by independent experts that if the system is built to the specied architecture, it will œ satisfy the requirements: capability, interfaces, level of service, and evolution œ support the operational concept œ be buildable within the budgets and schedules in the plan œ generate a viable return on investment œ generate satisfactory outcomes for all of the successcritical stakeholdersł all major risks resolved or covered by riskmanagement plansł serves as basis for stakeholders™ commitment to proceedthe developers in time for them to prepare responses to be presented at the dcr review meeting.at the dcr milestone review meeting for the lca package, the project then either provides adequate additional evidence of feasibility or additional riskmanagement plans to address the risks. the stakeholders then decide whether the risks are negligible, acceptable, high but addressable, or too high and unaddressable, and the project proceeds in the direction of the appropriate dcr risk arrow in figure 24.the other icm milestone reviewsthe architecture commitment review criteria and procedures are similar but less elaborate than those in the dcr, as the degree of stakeholder resource commitment to support the architecting phase is considerably lower than for supporting the development phase. the acr and dcr review procedures are adapted from the highly successful at&t architecture review board procedures described in marenzano et al. (2005). for the acr, only highrisk aspects of the operational concept, requirements, architecture, and plans are elaborated in detail. and it is sufcient to provide evidence that at least one combination of those artifacts satises the feasibility rationale criteria, in comparison to demonstrating this at the dcr for a particular choice of artifacts to be used for development.the review criteria and procedures for the exploration commitment review (ecr) and the valuation commitment review (vcr) are even less elaborate than those for the acr milestone, as the commitment levels for proceeding are considerably lower. but they will similarly have a riskdriven humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 47level of detail and riskdriven stakeholder choice of review outcome. for the ecr, the focus is on a review of an exploration phase plan with the proposed scope, schedule, deliverables, and required resource commitment by a key subset of stakeholders. the plan content is riskdriven and could be put on a single page for a small and noncontroversial exploration phase. for the vcr, the riskdriven focus is similar; the content includes the exploration phase results and a valuation phase plan and a review by all of the stakeholders involved in the valuation phase.the operations commitment review (ocr) is different, in that it addresses the often much higher operational risks of elding an inadequate system. in general, stakeholders will experience an increase in commitment level by a factor of 2 to 10 in going through the sequence of ecr to dcr milestones, but the increase in going from dcr to ocr can be much higher. the ocr focuses on evidence of the adequacy of plans and preparations with respect to doctrine, organization, training, material, leadership, personnel, and facilities, along with plans, budgets, and schedules for production, elding, and operations.a nonscientic analogy may be useful. the series of icm milestones has the advantage of re˚ecting other human lifecycle incremental commitment sequences, such as those of getting married and raising a family. the ecr might be considered similar to a nonexclusive commitment to go out on dates with a girlfriend or boyfriend. the vcr is similar to a more exclusive but informal commitment to ﬁgo steady,ﬂ and the acr is similar to a more formal commitment to get engaged. the dcr is similar to an ﬁuntil death do us partﬂ commitment to get married: if one marries one™s lifecycle architecture package in haste, one may repent in leisure. the ocr is similar to having one™s rst child: once the baby arrives, one™s lifestyle is changed by the need to maintain its health and wellbeing.another possibly relevant metaphor for the incremental commitment model is a poker game, such as texas hold™em. at each round of betting, each stakeholder looks at his or her own hole cards and the jointly visible community cards and decides whether it is worth adding further resources to the pot of resources on the table, in order to see further community cards and to win the pot based on having the best poker hand constructible from one™s own hole cards and the community cards. with the incremental commitment model, however, there will be negotiations designed to make win conditions for each successcritical stakeholder.the spiral viewa simplied spiral model view of the incremental commitment model appears in figure 25. it avoids sources of misinterpretation in previous versions of the spiral model and concentrates on the ve key spiral develophumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.48 humansystem integration in system development123456stakeholdercommitmentreview points:opportunities toproceed, skipphases, backtrack,or terminateexploration commitment reviewvaluation commitment reviewarchitecture commitment reviewdevelopment commitment reviewoperations1 and development2 commitment reviewoperations2 and development3 commitment reviewcumulative level of understanding, cost, time, product, andprocess detail (riskdriven)concurrentengineering ofproducts andprocesses2345architectingarchitectingvaluationdevelopment1 operation21625operationarchitectingexplorationfigure 25 simplied spiral view of the incremental commitment model.ment principles. stakeholder satiscing is necessary to pass the stakeholder commitment review points or anchor point milestones. incremental growth in system understanding, cost, time, product, and process detail is shown by the spiral growth along the radial dimension. concurrent engineering is shown by progress along the angular dimension. iteration is shown by taking several spiral cycles both to dene and develop the system. risk management is captured by indicating that the activities™ and products™ levels of detail in the angular dimension are riskdriven, and by the riskdriven arrows pointing out from each of the anchor point commitment milestones.these arrows show that the spiral model is not a sequential, unrollable process, but that it incorporates many paths through the diagram, including skipping a phase or backtracking to an early phase based on assessed risk. the fourth arrow pointing toward rescoping or halting in figure 24 humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 49is omitted from figure 25 for simplicity; it would be pointing down underneath the plane of the gure. other aspects of the spiral model, such as the specic artifacts being concurrently engineered and the use of the feasibility rationale, are consistent with their use in figure 24 and the other gures, in which they are easier to understand and harder to misinterpret than in a spiral diagram. also for simplicity, the concurrent operation of increment n, development of increment n + 1, and architecting of increment n + 2 are not shown explicitly, although they are going on. this concurrency is explained in more detail in the next section.incremental development for accommodating rapid change and high assurancemany future systems and systems of systems will need to simultaneously achieve high assurance and adaptation to both foreseeable and unforeseeable rapid change, while meeting shorter market windows or new defense threats. figure 26 shows an incremental view of the incremental commitment model for addressing such situations. it assumes that the organization has developed artifacts that have passed a development commitment review, includingł a besteffort denition of the system™s envisioned overall capability;agilerebaselining forfuture incrementsrapidchangeshort, stabilizeddevelopmentof increment nverification andvalidation (v&v)of increment nfuture increment baselinesincrement n transition/operations and maintenancehigh assuranceshortdevelopmentincrementsforeseeablechange(plan)increment baselinesunforeseeable change (adapt)artifactsconcernsdeferralsdin iocdin lcadin + 1 baseline lcadin + 1 rebaselined lcacontinuous v&vstable developmentincrementscauseeffect relationshipartifact flow26figure 26 riskdriven icm for accommodating rapid change and high assurance. adapted from boehm and lane (2006).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.50 humansystem integration in system developmentł an incremental sequence of prioritized capabilities culminating in the overall system capability; andł a feasibility rationale providing sufcient evidence for each increment and the overall system that the system architecture will support the increment™s specied capabilities; that each increment can be developed within its available budget and schedule; and that the series of increments create a satisfactory return on investment for the organization and mutually satisfactory outcomes for the successcritical stakeholders.the solid lines in the gure represent artifact ˚ows. for example, the baselined operational concept, requirements, architecture, and development plans for increment n enter the center box and guide the plandriven development of increment n to be transitioned into operations and maintenance. this development is stabilized by accepting only changes that have been architecturally anticipated (or occasional exceptional showstoppers). the corresponding baselines for future increments enter the top box, in which an agile team addresses unforeseeable changes and unavoidable content deferrals from increment n into future increments. the agile team™s output is a rebaselined set of specications and plans to be used in developing increment n + 1 and counterpart rebaselined specications and plans for future increments to be updated during increment n + 1.the dotted lines in figure 26 represent causeeffect relationships. for example, the need to deliver highassurance incremental capabilities on relatively short xed schedules (to avoid delivery of obsolete capabilities in an era of increasingly rapid change) means that each increment needs to be kept as stable as possible. this is particularly the case for very large systems of systems with deep supplier hierarchies (often 6 to 12 levels), in which a high level of inprocess change adaptation trafc can easily lead to the developers spending more time processing changes than doing development. in keeping with the use of the incremental commitment model as a riskdriven process model generator, the risks of destabilizing the development process make this portion of the project into a buildtospecication subset of the concurrent activities, in which the only changes accommodated are potential showstoppers or foreseeable changes that have been accommodated in the increment™s architecture. the need for high assurance of each increment also makes it costeffective to invest in a team of appropriately skilled personnel to continuously verify and validate the increment as it is being developed, as shown in the lower box in figure 26.in order to avoid delays and shortfalls in getting increment n + 1 specications and plans ready for development, the agile team is concurrently assessing the unforeseen change trafc and rebaselining the next increment™s lca package and feasibility rationale, so that the stabilized buildtospecications team will have all it needs to hit the ground running humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 51table 23 number of top5 projects explicitly using icm principlesyearconcurrent engineeringriskdrivenevolutionary growth2002433200343220042242005445total (of 20)141214in rapidly developing the next increment. more detail on this process and its stafng and contracting implications is provided by boehm (2006).project experience with icm principlesthe incremental commitment model uses the critical success factor principles to extend several current spiralrelated processes, such as the rational unied process, the winwin spiral process, and the lean development process, in ways that more explicitly integrate humansystem integration into the system lifecycle process. a good source of successful projects that have applied the critical success factor principles is the annual series of top5 softwareintensive systems projects published in crosstalk1 (20022005).the top5 quality software projects are chosen annually by panels of leading experts as role models of best practices and successful outcomes. table 23 summarizes each year™s record with respect to usage of four of the ve principles: concurrent engineering, riskdriven activities, and evolutionary and iterative system growth (most of the projects were not specic about stakeholder satiscing). of the 20 top5 projects in 2002 through 2005, 14 explicitly used concurrent engineering, 12 explicitly used riskdriven development, and 14 explicitly used evolutionary and iterative system growth, while additional projects gave indications of their partial use. table 24 provides more specics on the 20 projects.evidence of successful results of stakeholder satiscing can be found in the annual series of university of southern california eservices projects using the winwin spiral model as described in (boehm et al., 1998). since 1998 over 50 userintensive eservices applications have used the winwin 1 for examples of annually chosen top5 quality software projects, see http://www.stsc.hill.af.mil/crosstalk/2002/01/index.html; http://www.stsc.hill.af.mil/crosstalk/2003/07/index.html; http://www.stsc.hill.af.mil/crosstalk/2004/07/index.html; and http://www.stsc.hill.af.mil/crosstalk/2 005/09/index.html [accessed april 2007].humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.52 humansystem integration in system developmenttable 24 critical success factor (csf) aspects of top five software projectssoftware projectcsf degreeconcurrent requirements/ solution developmentriskdriven activitiesevolutionary, incremental deliverystars air trafc control*yeshci, safetyfor multiple sitesminuteman iii messaging (hac/rmpe)*yessafetyyes; block upgradesfa18 upgrades*not describedyesyes; block upgradescensus digital imaging (dcs2000)**yesyesno; xed delivery datefbcb2 army tactical c3i**yesyesyesdefense civilian pay (dcps) no; waterfallyesfor multiple organizationstactical data radio (eplrs)**yesyesyesjoint helmetmounted cueing (jhmcs)*yes; iptbasednot describedfor multiple aircraftkwajalein radar (kmar)*yes; iptbasednot describedfor multiple radarsone saf simulation test bed (otb)**yesyesyesadvanced field artillery (afatds) initially waterfallnot describedyes; block upgradesdefense medical logistics (dmlss) initially waterfallnot describedyes; block upgradesf18 hol (h1e scs) legacy requirementsdrivenyes; cots, displaynoone saf objectives system (oos)**yesyesyespatriot excalibur (pex)**yes; agilenot describedyeslightweight handheld fire control**yesyesyesmarines integrated pay (mctfs)initially waterfallnot describedyes; block upgradesnear imaging field towers (nifti)**yes; rupbasedyesyessmart cam virtual cockpit (sc3df)**yesyesyeswarsim army training**yesyesyesnote: cots = commercial off the shelf; hci = humancomputer interaction; ipt = integrated project team; rup = rational unied process. for csf degree: blank = ﬁgenerally not used,ﬂ * = ﬁgenerally used,ﬂ and ** = ﬁstrongly used.ﬂhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the system development process 53spiral model to achieve a 92percent success rate of ontime delivery of stakeholdersatisfactory systems.conclusionfuture transformational, networkcentric systems will have many usage uncertainties and emergent characteristics. their hardware, software, and human factors will need to be concurrently engineered, riskmanaged, and evolutionarily developed to converge on costeffective system operations. they will need to be both highly dependable and rapidly adaptable to frequent changes.this chapter has described the incremental commitment model, which builds on experiencebased critical success factor principles (stakeholder satiscing, incremental denition, iterative evolutionary growth, concurrent engineering, risk management) as well as the strengths of existing v, concurrent engineering, spiral, agile, and lean process models, to provide a framework for concurrently engineering human factors into the systems engineering and systems development processes. the chapter provides capabilities for evaluating the feasibility of proposed hsi solutions and for integrating hsi feasibility evaluations into decisions on whether and how to proceed further into systems development and operations. the chapter also presents several complementary views showing how the principles are applied to perform riskdriven process tailoring and evolutionary growth of a systems denition and realization; to synchronize and stabilize concurrent engineering; and to enable simultaneous highassurance development and rapid adaptation to change. the chapter analyzes the use of the critical success factor principles on the bestdocumented government software intensive system acquisition success stories, the 20022005 crosstalk top5 projects, and shows that well over half of them explicitly applied these principles. the next three chapters will elaborate on how hsi practices t into the icm process and provide case studies of successful projects that have used the principles and practices.the current path of least resistance for a government program manager is to follow a set of (existing) regulations, specications, and standards that select, contract with, and reward developers for doing almost the exact opposite. most of these legacy instruments emphasize sequential versus concurrent engineering; riskinsensitive versus riskdriven processes; early denition of poorly understood requirements versus better understanding of needs and opportunities; and slow, unscalable, contractual mechanisms for adapting to rapid change.this chapter has provided a mapping of the icm milestones to the current dod 5000.2 acquisition milestones, showing that they can be quite compatible. it also shows how projects could be organized into stabilized humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.54 humansystem integration in system developmentbuildtospecication increments that t current legacy acquisition instruments, along with concurrent agile changeadaptation and verication and validation functions that need to use alternative contracting methods. addressing changes of this nature will be important if organizations are to realize the large potential value offered by investments in hsi processes, methods, and tools.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.3humansystem integration and the system development processan important theme of this report is the integration of humansystem methods within the system development process, so that multiple humansystem integration (hsi) concerns can be addressed effectively with the least resource expenditure. this re˚ects the position of miller (1953) in his initial description of the task analysis method as a procedure that can serve design and training needs analysis equally well. the committee ndings indicate that a core set of human factors method classes can serve as integrating links across the diverse hsi concerns of human factors, manpower, personnel, training and system safety, health hazards, and survivability. furthermore, shared representations of the outputs of these methods can be developed that effectively will communicate ndings and conclusions among hsi domains as well with hardware and software developers and other stakeholders.three general classes of human factors methods provide a robust representation of the multiple hsi concerns, and are applicable at varying levels of effort throughout the development life cycle. these broad classes include methods to:ł dene opportunities and context of use: methods for analyses that contribute to early denitions of opportunities and requirements and that attempt to characterize the context of use, including characteristics of users, their tasks, and the broader physical and organizational environment in which they operate so as to build systems that will effectively meet the needs of users and their work and will function smoothly within the broader physical and organizational context.55humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.56 humansystem integration in system developmentł dene requirements and design solutions: methods to identify requirements and design alternatives to meet the requirements revealed by prior frontend analyses.ł evaluate: methods to evaluate the adequacy of proposed design solutions and propel further design innovation.these methods generate objective data concerning critical humansystem issues, leading to incremental growth of system denition and stakeholder commitment.in chapter 2 we showed how system development activities of the incremental commitment model (icm) were distributed across system lifecycle phases (see figure 23). here, figure 31 illustrates broadly how the four major classes of hsi activity relate to these phases. for example, activities related to understanding the context of use are likely be concentrated early in system development, when characteristics of the users, their work, and the environmental context are rst being understood. however, because the context of use is constantly evolving and introduction of new technology is likely to produce operational and organizational changes, not all of which will have been anticipated ahead of time, it is important to continue to devote some (albeit lower) level of effort to examination of the context of use and how it evolves throughout the system development and deployment process, both to guide midcourse design corrections and to lay the groundwork for nextgeneration system development.icmlifecycle phasesexplorationvaluationarchitectingdevelopment1 architecting 2operation1 development2 architecting3...levels of activityexplorationcommitmentreviewvaluationcommitmentreviewdod milestonesarchitecturecommitmentreviewdevelopmentcommitmentreviewoperationscommitmentreviewoperationscommitmentreviewrequirements and design solutionsactivity categoryhsievaluationand context of useecrvcr/cdacr/adcr/bocr1 /c1dcr2 /b2ocr2 /c2dcr3 /b331defining opportunitiesfigure 31 activity level of hsi methods across system lifecycle phases.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 57humansystem integration in the  incremental commitment modelin order to place humansystem integration and its associated methods in the risk management context that is central to the incremental commitment model, it is important to distinguish several types of risk. endstate operational system risks include low usability, high rates of human error, low productivity, and safety problems. these types of risks tend to become manifest during the development process as a failure to properly manage hsi risks. they include such problems as specifying the user interface too early in design (or alternatively not considering it all), poorly understood work domain constraints, insufcient stakeholder engagement, and lack of personnelœorganizational system interoperability in systems of systems. often these types of risks are simply accepted or minimized because they pose a threat to maintaining program cost and schedule (program management risks).properly balancing these various categories of risk can be accommodated in the incremental commitment model, as it is a riskdriven process that aims to identify and properly manage these various risk categories. by engaging appropriate hsi methods during the incremental development process, risks can be reduced throughout the engineering life cycle, increasing the likelihood of a system™s meeting user requirements and satiscing stakeholders. appendix table 3a1 lists best practices for humansystem integration taken from iso/pas 18152 (international organization for standardization, 2003) and categorized by activity category. each of these practices is valuable for successful humancentered design. examples of methods to use in implementing these practices are also shown in the table. a risk assessment can be used to decide how much effort is needed to implement each practice in the context of a particular project.ł are the objectives that the user or user organization wants to achieve through use of the system already known, or is some eld investigation necessary?ł how important is it to establish measurable usability criteria for the system in its intended context of use?ł what are the risks if endusers are not involved in each evaluation?figure 32 illustrates the links between desired system endstate (stakeholder satiscing), system phases, and hsi activities. this gure conveys the multiple determinants of the ultimate system design goal, stakeholder satiscing. the system development principles identied in chapter 2 are shown as inputs to the system engineering processes or phases. each of the phases is conducted iteratively, as described in the incremental comhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.58figure 32 linkage of system engineering principles to hsi activities that reduce risks.systems engineeringand hsi critical themes system phases with spiral approachto design activitystakeholder satisficingdevelopment...hsi activities that reduce risk and facilitatetransdiciplinary teamsexplorationvaluationarchitectinggoal of system developmentsuccesscritical stakeholder satisficing: this implies that the key decision makers in system development have agreed that particular design solutions are acceptable, if not optimal. tradeoffs have been made that may not maximize system performance but will result in acceptable performance within the cost and schedule constraints.this characteristic encompasses the necessity of gradual development through defining system requirements and obtaining agreement among stakeholders in a developmental way. requirements and commitment cannot be monolithic for complex systems; understanding, definition and commitment is achieved through a cyclic process.as with incremental growth, specific requirements and subsystem definition occur simultaneously with development of previously defined system components. this allows continual growth of complex systems without waiting for every requirement and subsystem to be defined.the incremental and concurrent approaches lead to cyclic refinements of requirements and specifications.such iteration is necessary to fully achieve comprehensive performance requirements.the intensity of specific design activities will depend on the level of risk associated with them. if the user interface is considered a highrisk area, for example, then more design activity will be devoted to this component to achieve stakeholder commitments at particular design anchor points.operation...evaluatedefine opportunities& requirementsdefine contextsof usedesignsolutionslandscape 32humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 59mitment model, and requires inputs from multiple hsi methods. this is illustrated by the network of links between hsi activities and the systems engineering phases. as with the level of activity diagram in figure 31, our main point is that hsi activities are concurrent, iterative processes carried out as needed to reduce development risks at various incremental stages of system design.the role of humansystem integration in the management of engineering development risk is a relatively new concept. human factors engineering methods are traditionally conceived as designaiding techniques, to be used when it is time to design or test very specic elements of the humansystem interface. however, this conception is too narrow for complex systems that increasingly involve multiple teams of distributed operational personnel. instead, human factors methods can be more broadly conceived both as designaiding techniques and as methods for progressive risk reduction during the life cycle. in this sense, human factors methods contribute to the development process in much the same way as, for example, prototyping or simulation is employed by systems engineers and can be used during the early to middle stages of development to evaluate alternatives and to narrow design choices based on various constraints. the use of such risk reduction approaches allows developers to select one design approach over another, gain an understanding of unanticipated effects based on simulation, and generally to have a higher level of condence that system development efforts are on track to meet requirements and avoid the operational stage risks of disuse, error, and high lifecycle costs.extensive experience with major system development efforts by committee members and colleagues in the profession suggests that human factors issues have often been underutilized during system development because of a perception by program managers that the risks of cost and schedule delay associated with humansystem integration exceed the benet to be delivered. part of this perception is associated with a standard waterfall model of design, in which specic milestones are set in time, and hsi analytic methods tend to be timeintensive if performed in a linear fashion. program managers often perceive human factors professionals as overly focused on comprehensive application of methods, while the art of engineering is to accommodate the realities of schedule and cost, conducting studies and analyses only as necessary to manage risks. it is thus important for hsi practitioners to adopt an incremental and iterative approach to analysis and design, recognizing that if there are no hsi risks associated with a particular aspect of a project, then it is unnecessary to apply various methods. the hsi profession has seen a trend in this direction with the development of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.60 humansystem integration in system developmentsuch approaches as quick look reports1 in which the precision of laboratory experiment or exhaustive observation is traded off with the expedience of providing the most critical design inputs through rapid prototyping, contextual inquiry, and various forms of participatory design.by incorporating humansystem integration as an integral thread within the incremental commitment model, the balance of program risks with hsi risks can be accommodated. this is especially true if hsi professionals are incorporated as members of an integrated product team structure that is involved continuously throughout the design cycle. early iterations of work domain analysis, for example, may be conducted at a fairly high level to ensure that all appropriate stakeholders are identied and represented. as designs become more elaborated, participatory techniques can be applied to the point of reaching stakeholder consensus for purposes of a specic increment. this linkage of hsi activities to incremental development permits the design and risk management process to serve as a way to select the most appropriate hsi methods (and their extent of application) for a particular phase of the engineering cycle. it is not necessary to apply hsi techniques in a monolithic fashion, and in some cases it may not be necessary at all because there is no risk associated with a particular hsi issue; alternatively, program managers may accept certain identied risks (e.g., commercial offtheshelf user interfaces) in order to preclude rejecting the use of certain technologies.an important aspect of the incremental commitment model and the spiral representation for hsi professionals is the notion that methods are not only progressive, but also iterative, and that risk analysis determines the frequency and extent of their application. this has important implications for sizing the hsi effort, since the resources devoted to hsi activities should re˚ect the requirements for their application. this is a difcult task to accomplish currently, since there are no wellestablished methods for estimating the resource requirements for humansystem integration. various systems engineering approaches to level of effort sizing include activitybased costing, comparison with previous projects of similar scope, applying a unitcost basis (as when a request for proposal species how many human factors engineers should work on a system), parametric models that link effort to project complexity, expert consensus, and risk tradeoff analysis. none of these approaches has been systematically examined for sizing hsi efforts, and this area represents a knowledge gap that could be addressed through research.1 quick look report is a term used primarily by the national aeronautics and space administration and the department of transportation to describe the results of a rapid eld observation or appraisal of a prototype system in a test situation. these appraisals are less detailed than formal operational test and evaluation procedures.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 61communicating hsi issues and opportunities through shared representationsa critical concern of hsi professionals and a major theme of the committee™s work is the need not only to communicate effectively within the specic hsi domain but to share ndings across all systems engineering domains. this can be a daunting challenge for groups tasked with complex systems design. in addition, there is a clear need to share design and process artifacts at all phases in the systems development process, especially with the software and hardware developers who are actually implementing the system, and who are not only relying on clear specications for development, but who are also expected to contribute to the generation of those specications at critical decision points in the process. as a consequence, the committee has pursued the concept of shared representations as a means of addressing this concern. shared representationsšparticularly diagrammatic models and other more visual, holistic representationsšcan serve as the fundamental medium for interactions among individuals, teams, and the organization.imagine a scenario from the commercial software development world. a team meets to kick off a new project. groups of people from business, technology, and human systems discuss the goals of the project, the timeline, and other variables. notes from the meeting are distributed within a few hours. each group works on its tasks for several weeks. at the next meeting, team members discover that each discipline has taken its interpretation of the goals in directions different from those of the other groups, and now weeks have gone by with little truly collaborative progress to show for their efforts. everyone attended the meeting and everyone read the notes, so what happened? the verbal description of goals and the written documentation of the events were not enough to provide common ground for the team. they lacked a shared representation of the event, their views, and what needed to be done by each of the groups.a shared representation is an artifact or experience that mediates the interaction between and among people coming from multiple perspectives (different organizational roles, distinct technical or business backgrounds, etc.). it can be useful for an individual, a team, or an organization (curtis, krasner, and iscoe, 1988). a representation can provide support or scaffolding for effective collaboration among people in transdisciplinary design teams, and at the same time be used at the organizational level to ﬁcommunicate upﬂ to forge understandings between and among the various project stakeholders. a shared representation is most powerful when used not only to facilitate activities, but also to make people™s assumptions and individual mind sets explicit.shared representations act as a means for synchronization, clarication, and grounding in the socially constructed process of design (d™astous humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.62 humansystem integration in system developmentet al., 2004; olson et al., 1992). in the process, solutions are negotiated, the representation acts as mediator, and subsequent modications made to the representation make explicit the result of those negotiations.why shared representations are usefulmodels, diagrams, and other, more visual shared representations are effective for people as they participate in design activities. don norman writes: ﬁwithout external aids, memory, thought, and reasoning are all constrained. but human intelligence is highly ˚exible and adaptive, superb at inventing procedures and objects that overcome its own limits.ﬂ he goes on to suggest that one can enhance cognitive ability by producing representations or artifacts to help one think (norman, 1993; see also hutchins, 1995; nardi, 1996; pasztory, 2005). when people externalize their thinking via representations (e.g., get their ideas out on paper or on screen), they produce a representation of their thinking that not only can be examined critically, but also can be used to reduce their working memory load (nardi, 1996; suwa and tversky, 2002).in addition, by producing the representation and taking the information beyond words into a new form or medium, relationships among meaningful elements of the design must either be made explicit or must emerge, by the simple act of creating an explicit shared representation of the component elements in a wellframed space (e.g., a twod sketch, a threed volumetric representation, or some higher dimensional parametric space characterizing the design elements). seeing these placements can not only lead the reader or the originators to recognize previously unacknowledged connections or relations, but also produce new connections and ideas. suwa and tversky (2002) call the activity detection of unintended relations and features. for example, in the applied cognitive work analysis (acwa) method, the functional abstraction hierarchy is designed to highlight critical domain relationships that dene the problemspace confronting domain practitioners. each subsequent artifact in the process builds on the original model and, through negotiation, points to a model of what the system should be in such a way that it can nally be prototyped.shared representations act as mediators in the collaborative and iterative construction of knowledge in the design process. when multiple people build, share, comment, and change a shared information base, they are collaboratively constructing new knowledge (bucciarelli, 1988; suthers, 2005). if participants produce different types of artifacts, representations, or models as they engage in the design and development processšthese should, as norman suggests, ﬁhelp them thinkﬂ and make their assumptions explicit. in a sense, shared representations work in the same way that blueprints work for architects in moving from what might be to what is built. many different views are produced. everyone involved in the prohumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 63cessšfrom stakeholders to the various disciplines involvedšis able to use the abstraction re˚ected in the blueprints to make meaningful decisions. for all these reasons, producing shared representations in transdisciplinary teams can be critical to creating innovative solutions because they help teams collectively see and communicate about novel connections, spawn new ideas, and facilitate a more effective design process (détienne, 2006; evenson, 2005).there is a dynamic between the representation™s role in facilitating externalization (making explicit the group™s assumptions and beliefs) and its role in acting as an environment for conversation, to facilitate subsequent negotiations and elaboration. the task of creating the representation initiates the process of making explicit the underlying goals, assumptions, and viewpoints of the different design team members; the process of updating the representation following design team negotiations captures the results of negotiating design meaning out of nonverbal, semiverbal, and verbal conversations engaged in by the various team members while discussing the current model or representation (suthers, 2005).attributes of good shared representationsnearly every activity in the system development life cycle results in some form of tangible design artifact, but it may not necessarily be a good shared representation. to be useful, a shared representation should1. establish a shared language that is appropriately aligned with the development or communication problem to be solved.2. provide a strategically chosen extent of ambiguity versus denition.3. facilitate the desired social process (e.g., critique and redesign versus accept/reject decisions).4. make differences and relationships apparent.5. facilitate group ﬁthinking withﬂ (norman, 1993) to transform knowledge and create new understandings (carlile, 2002).6. provide a meaningful structure, content, and appearance to both the creators of the shared representation and the consumers of that shared representation.of the six attributes listed above, the two most important are the shared language and facilitation of a social process.to establish the language, a shared representation should be easily read by all of its users (creators and recipients)šthat is, the structure and content should be easily perceived and comprehended, re˚ect the structure and content of the ideas or mental representation, and create a sort of resonance. the participants in the construction process should agree that humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.64 humansystem integration in system developmentthe thing produced adequately represents what they want it to (tversky, morrison, and betrancourt, 2002).to facilitate the social process, the representation must stand in and mediate communication between and among people engaged in the collaborative process (boland and collopy, 2004). in other words, the representation must be suitable for facilitating negotiation among the participants.shared representations in the design processwhat is useful as a shared representation can change over time in the systems development process. in practice, the process of constructing the shared representation may be more important for team building than the artifact itself. early on, mapping out the territory the system is expected to address can draw out existing preconceptions and knowledge held by the various team members, helping to bound research activities. a territory map is an example of a shared representation that captures more a gestalt or overview of the system. it is suggestive of everything the system is andšby virtue of what is left outševerything it is not. a good territory map accounts for all the stakeholder interests in the system; a great territory map provides a picture of the system that is comprehensive, cohesive, and visionary. completed early enough in the process, a territory map can even serve to mediate the communication of the participants in the acquisition process. teams that agree on what is in the territory have established common ground that can be carried forward throughout the design and development process.documentation that focuses on activities identied from a territory map often becomes successful shared representations. they are produced in the midst of extensive task, process, or environmental research and provide a way to discuss what currently happens and what should or could happen. a standard recording language (uml, activity diagrams, business process modeling notation, etc.) facilitates discussion and contributes to the production of the shared representation. a less common but often effective shared representation early in the process can be developed with a focus on the target users of the system. for example, the ndings from usergenerated eld journals (incorporating a standardized and embedded framework for users to record their observations) helps to extend the language of the team and build a model of system attributes important to the target user group.sometimes shared representations can function as a vehicle for the clarication of ideas (e.g., suthers, 2005) or as an opportunity for groups to combine their different perspectives and knowledge into new insights (muller, 2003; muller et al., 1994). this is often the case when a lowdelity prototype (such as a blank shape that is used symbolically ﬁin place ofﬂ a real device or prototype) is used as a candidate for eliciting different humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 65stakeholders™ ideas about what would be done with the product, system, or service, as well as for eliciting and exploring different stakeholder concepts and assumptions. this was successfully demonstrated in the utopia project, in which the implications for working relationships from a new print shop technology were explored by placing lowdelity mockups of the new technology in the existing print shop and by acting out the new work practices around those prototypes (ehn and kyng, 1991).erickson reviewed the importance of ﬁroughnessﬂ in a shared representation, noting that less formal and less nished representations were more likely to elicit useful comment, critique, and improvement, whereas more formalized or polished representations were more likely to lead to simple accept/reject decisions (erickson, 1996). people feel more open to participating in and rening ideas in sketches and than they do in nished prototypes.personas are also often an excellent shared representation category because they are composite user archetypes based on behavioral data gathered from many actual people during discovery research (see chapter 7). personas are useful because they build on people™s expectations about other people™s behavior from what is known about that person. developing solid proles or personas contributes to serving individual user needs, aids in integration with customer processes, and leads to a design that the various constituents can participate in coevolving. as a shared representation, personas and proles are a tool for making user needs explicit, differentiating between and among different stakeholders, and prioritizing different and sometimes competing goals (cooper, 2004).even physical spaces can become successful shared representation of the system or systems to be designed. for example, in a design project intended to reconceptualize 35mm pointandshoot cameras, a physical design space was built initially to contain the results of qualitative research conducted to understand the existing paradigm (rheinfrank and welker, 1994). the space contained images and relevant artifacts that characterized different aspects of use and users of cameras. initially, each wall of the space individually represented a particular aspect of the experience and was used more as a repository for the information about each dimension. over time, however, the space was seen as a whole and became a shared representation in the collaborative process to solve a multidimensional camera design problem (star, 1989). specically, the physical space evolved into a shared representation offering the internal and external design teams multiple views of possible 35mm camera futures, in which the view depended on its position on the ˚oor in juxtaposition to the walls of the room (rheinfrank and welker, 1994). in later cycles of development, scoping maps (1) illustrate the features, functionality, and content of the designed system, (2) illustrate anticipated user experiences, and (3) enable team members to prioritize a humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.66 humansystem integration in system developmentplan for staged release. these types of shared representations allow the stakeholders to make decisions about what can and should be produced from the potential things that could be built. eventually, a highdelity representation, such as a functional prototype, is a good candidate for validating what the team collectively knows about the system and for communicating a clear idea of the system from one design group to another, as well as ﬁupﬂ the organization.as the design and development process unfolds, and when groups shift from one type of shared representation to another or change the way they are using a shared representation, the shift signals a qualitative change in the knowhow needed for continuing to make progress in the design/development process (cook and brown, 1999; gasson, 2005).conclusioneffective use of shared representations depends on understanding the team or organization™s current issues and needs in communication, and in strategically choosing the right kind of shared representation to mediate at the right time.when used appropriately, shared representations enable the design team to coalesce around a shared view, while providing a capacity for increasing the conceptual complexity that can be attended tošactivities that are crucial in the design of complex systems.shared representations can provide a bridge among analysis, design, implementation, and training in complex systems design, development, and elding. the act of producing the representation can help teams detect unanticipated relations and features that can be exploited to lead to new connections and ideas.shared representations can be anything from a simple sketch, to a ﬁwizard of ozﬂ prototype, to a fully active simulation of system design and behavior. although conventional project planning schedules or spreadsheets can support the design and development process, they can never take the place of consciously planning, producing, and seeding discussion around shared representations to improve the quality of collaboration and productive outcomes of transdisciplinary design teams (carroll, 2002). shared representations provide a means for teams to transcend conventional project management paradigms and to coalesce around their ideas to produce work that is a re˚ection of their shared understanding of the mission to be supported, the user needs, and the best that technology can deliver.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 67appendix 3atable 3a1 best practices for risk mitigationactivity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques1.  envisioning opportunitiesœ identify expected context of use of systems [forthcoming needs, trends and expectations].œ analyze the system concept [to clarify objectives, their viability and risks]. œ field observations and ethnographyœ participatory analysis2.  system scopingœ describe the objectives which the user or user organization wants to achieve through use of the system.œ dene the scope of the context of use for the system. œ organizational and environmental context analysisœ field observations and ethnographyœ participatory analysiswork context analysis3.  understanding needs (a) context of use (b) tasks (c) usability needs (d) design optionsœ identify and analyze the roles of each group of stakeholders likely to be affected by the system.œ describe the characteristics of the users.œ describe the cultural environment/ organizational/management regime.œ describe the characteristics of any equipment external to the system and the working environment.œ describe the location, workplace equipment, and ambient conditions.œ decide the goals, behaviors, and tasks of the organization that in˚uence human resources.œ present context and human resources options and constraints to the project stakeholders.œ analyze the tasks and worksystem.œ perform research into required system usability.œ generate design options for each aspect of the system related to its use and its effect on stakeholders.œ produce usercentered solutions for each design option. œ organizational and environmental context analysisœ field observations and ethnographyœ task analysisœ cognitive task analysisœ participatory analysisœ contextual inquiryœ event data analysisœ prototypingœ models and simulationsœ usability evaluation methodssuccesscritical stakeholder identicationcontext of use analysiswork context analysisinvestigate required system usabilityusability benchmarkingcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.68 humansystem integration in system developmentactivity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques4.  goals/objectives and requirements (a) context requirements (b) infrastructure requirements (c) user requirementsœ analyze the implications of the context of use.œ present context of use issues to project stakeholders for use in the development or operation of the system.œ identify, specify, and produce the infrastructure for the system.œ build required competencies into training and awareness programs.œ dene the global numbers, skills, and supporting equipment needed to achieve those tasks.œ set and agree on the expected behavior and performance of the system with respect to the user.œ develop an explicit statement of the user requirements for the system.œ analyze the user requirements.œ generate and agree on measurable criteria for the system in its intended context of use. œ usability requirements methodsœ scenariosœ personasdene the intended context of use including boundariesidentify stafng requirements and any training or support needed to ensure that users achieve acceptable performancestoryboardsestablish performance and satisfaction goals for specic scenarios of usedene detailed user interface requirementsprioritize requirements (e.g., qfd)5.  architecting solutions (a) system architectingœ generate design options for each aspect of the system related to its use and its effect on stakeholders.œ produce usercentered solutions for each design option.œ design for customization.œ develop simulation or trial implementation of key aspects of the system for the purposes of testing with users.œ distribute functions between the human, machine, and organizational elements of the system best able to fulll each function.œ develop a practical model of the user™s work from the requirements, context of use, allocation of function, and design constraints for the system.œ produce designs for the userrelated elements of the system that take account of the user requirements, context of use, and hf data.œ produce a description of how the system will be used. œ task analysisœ work domain analysisœ participatory designœ prototypingœ models and simulationsfunction allocationgenerate design optionstable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 69activity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques (b) human  elementsœ decide the goals, behaviors, and tasks of the organization [that in˚uence human resources].œ dene the global numbers, skills, and supporting equipment needed to achieve those tasks.œ identify current tasking/duty.œ analyze gap between existing and future provision.œ identify skill requirements for each role.œ predict staff wastage between present and future.œ calculate the available stafng, taking account of working hours, attainable effort and nonavailability factor.œ identify and allocate the functions to be performed.œ functional decomposition and allocation of function.œ specify and produce job designs and competence/skills required to be delivered.œ calculate the required number of personnel.œ generate costed options for delivery of training and/or redeployment.œ evolve options and constraints into an optimal [training] implementation plan (4.3.5).œ dene how users will be reallocated, dismissed, or transferred to other duties.œ compare to dene gap and communicate requirement to design of stafng solutions. œ task analysisœ usability requirements methodsœ work domain analysisœ workload assessmentœ participatory designœ contextual designœ situation awarenessœ methods for mitigating fatiguehuman performance modeldesign for alertnessplan stafng (c) hardware elementssee (a) system architecting.œ participatory designœ physical ergonomicsœ prototypingœ usability evaluation methods (d) software elementssee (a) system architecting.œ participatory designœ prototypingœ usability evaluation methodsuser interface guidelines and standardstable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.70 humansystem integration in system developmentactivity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques6.  lifecycle planning (a) planning (b) risks (c) user involvement (d) acquisition (e) human resourcesœ develop a plan to achieve and maintain usability throughout the life of the system.œ identify the specialist skills required and plan how to provide them.œ plan and manage use of hf data to mitigate risks related to hs issues.œ evaluate the current severity of emerging threats to system usability and other hs risks and the effectiveness of mitigation measures.œ take effective mitigation to address risks to system usability.œ identify the hs issues and aspects of the system that require user input.œ dene a strategy and plan for user involvement.œ select and use the most effective method to elicit user input.œ customize tools and methods as necessary for particular projects/stages.œ seek and exploit expert guidance and advice on hs issues.œ take account of stakeholder and user issues in acquisition activities.œ implement the hr strategy that gives the organization a mechanism for implementing and recording lessons learned.œ enable and encourage people and teams to work together to deliver the organization™s objectives.œ create capability to meet system requirements in the future (conduct succession planning).œ develop and trial training solution to representative users.œ deliver nal training solutions to designated staff according to agreed timetable.œ provide means for user feedback [on human issues]. œ usability requirements methods (common industry format)œ risk analysisplan to achieve and maintain usabilityplan use of hsi data to mitigate risksidentify hsi issues and aspects of the system requiring user inputdevelop a plan for user involvementselect and use the most effective methodscustomize tools and methods as necessarytable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 71activity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques7.  evaluation (a) risks (b) plan and execute (c) validation (d) hsi knowledge (e) stafngœ assess the health and wellbeing risks to the users of the system.œ assess the risks to the community and environment arising from human error in the use of the system.œ evaluate the current severity of emerging threats to system usability and other hs risks and the effectiveness of mitigation measures.œ assess the risks of not involving end users in each evaluation.œ collect user input on the usability of the developing system.œ revise design and safety features using feedback from evaluations.œ plan the evaluation.œ identify and analyze the conditions under which a system is to be tested or otherwise evaluated.œ check that the system is t for evaluation.œ carry out and analyze the evaluation according to the evaluation plan.œ understand and act on the results of the evaluation.œ test that the system meets the requirements of the users, the tasks and the environment, as dened in its specication.œ assess the extent to which usability criteria and other hs requirements are likely to be met by the proposed design.œ review the system for adherence to applicable human science knowledge, style guides, standards, guidelines, regulations, and legislation.œ decide how many people are needed to fulll the strategy and what ranges of competence they need.œ develop and trial training solution to representative users.œ conduct assessments of usability [relating to hr].œ interpret the ndings.œ validate the data.œ check that the data are being used. œ usability requirements methods (common industry format)œ prototypingœ models and simulationœ risk analysisœ usability evaluation methodsobtain user feedback on usabilitycompare with requirementsperformance measurementhrtable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.72 humansystem integration in system developmentactivity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques8.  negotiating commitments (a) business case (b) requirementsœ contribute to the business case for the system.œ include hs review and signoff in all reviews and decisions.œ analyze the user requirements.œ present these requirements to project stakeholders for use in the development and operation of the system.œ identify any stafng gap and communicate requirement to design of stafng solutions. œ usability requirements methods (common industry format)œ risk analysisvaluebased practices and principles (identify success critical stakeholder requirements)environment/organization assessment9.  development and evolutionœ maintain contact with users and the client organization throughout the denition, development, and introduction of a system.œ evolve options and constraints into an implementation strategy covering technical, integration, and planning and manning issues. œ usability requirements methods (common industry format)œ models and simulationœ risk analysisœ usability evaluation methodsuser feedback on  usabilityperformance measurement10.  monitoring and controlœ analyze feedback on the system during delivery and inform the organization of emerging issues.œ manage the lifecycle plan to address hs issues.œ take effective mitigation to address risks to system usability.œ take account of user input and inform users.œ identify emerging hs issues.œ understand and act on the results of the evaluation.œ produce and promulgate a validated statement of stafng shortfall by number and range of competence. œ organizational and environmental context analysis analysisœ risk analysisuser feedbackwork context analysistable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.hsi and the system development process 73activity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques11.  operations and retirement (a) operations (b) retirementœ analyze feedback on the system during delivery and inform the organization of emerging issues.œ produce personnel strategy.œ review the system for adherence to applicable human science knowledge, style guides, standards, guidelines, regulations, and legislation.œ deliver training and other forms of awarenessraising to users and support staff.œ assess the effect of change on the usability of the system.œ review the health and wellbeing risks to the users of the system.œ review the risks to the community and environment arising from human error in the use of the system.œ take action on issues arising from inservice assessment.œ perform research to rene and consolidate operation and support strategy for the system.œ collect and analyze inservice reports to generate updates or lessons learned for the next version of the system.œ identify risks and health and safety issues associated with removal from service and destruction of the system.œ dene how users will be reallocated, dismissed, or transferred to other duties.œ plan breakup of social structures.œ debrieng and retrospective analysis for replacement system. œ organizational and environmental context analysiswork context analysistable 3a1 continuedcontinuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.74 humansystem integration in system developmentactivity categorybest practices for risk mitigation from iso/pas 18152example hsi methods and techniques12.  organizational capability improvement (a) hsi capability data collection, analysis, and improvement (b) organizational skill/career and infrastructure development planning and executionœ identify and use the most suitable data formats for exchanging hf data.œ have a policy for hf data management.œ perform research to develop hf data as required.œ produce coherent data standards and formats.œ dene rules for the management of data.œ develop and maintain adequate data search methods.œ feedback into future hr procurement, training, and delivery strategies.œ dene usability as a competitive asset.œ set usability, health, and safety objectives for systems.œ follow competitive situation in the market place.œ develop usercentered infrastructure.œ relate hs issues to business benets.œ establish and communicate a policy for humancenteredness.œ include hr and usercentered elements in support and control procedures.œ dene and maintain hcd and hr infrastructure and resources.œ increase and maintain awareness of usability.œ develop or provide staff with suitable hs skills.œ take account of hs issues in nancial management.œ assess and improve hs capability in processes that affect usability, health, and safety.œ develop a common terminology for hs issues with the organization.œ facilitate personal and technical interactions related to hs issues.œ feedback into future hr procurement, training, and delivery strategies.œ create capability to meet system requirements in the future (conduct succession planning).œ identify any opportunities for redeployment.œ develop a strategy for [hr] data gathering.œ organizational and environmental context analysisassess and improve hsi capabilitydevelop and maintain hsi infrastructure and resourcesidentify required hsi skillsprovide staff with hsi skillsestablish and communicate a policy on hsimaintain an awareness of usabilitynotes: italicized items are methods not covered in chapters 68. hf = human factors. hs = humansystem. hr = human resources. qfd = quality function deployment. hcd = humancentered design.table 3a1 continuedhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.4managing risksrisk management is one of the ve key principles underpinning the incremental commitment model of system development because understanding risks and managing them effectively are paramount to effective program execution. at a high level, the concept of risk encompasses subjective or objective determination of an event™s likelihood of occurrence and the detrimental impact of that event™s occurrence. typically, program execution risk is grouped into three primary categories: (1) technical (i.e., a product™s ability to meet technical requirements), (2) cost (i.e., executing the program within the contracted budget), and (3) schedule (i.e., executing the program within the contracted duration). risk can be dened as the product of estimated probability of each occurrence and the level of undesirable contingent consequences added across the set of events and consequences under consideration. essential to the concept of risk is that the probability of occurrence must fall between 0 (i.e., total successšrisk will never be realized) and 1 (i.e., total failure). in opposition to the concept of risk, but maintaining the same underlying principles and practices as risk management, is opportunity and opportunity management, wherein an opportunity™s consequence has a positive impact on technical, cost, or schedule program variables.humansystem integration (hsi) analyses to identify risks are typically conducted at two levels: the ner grain relating to aspects of system design (e.g., safety, product usability), and the coarser grain contributing to overarching program risk management, which is the focus of this chapter. to explain how humansystem integration ts into program riskmanagement efforts, an example methodology is presented; however, it should be noted 75humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.76 humansystem integration in system developmentthat other approaches may also be utilized. in addition, although a department of defense (dod) program is the context for discussion, we note that the riskmanagement concepts and hsi interwoven thread have direct applicability to commercial development as well. finally, although the chapter focuses on program risk management, the concepts can also be applied to managing opportunities that arise during program execution.before delving into hsi contributions to risk management, it is important to understand the dod acquisition program context in which these activities are carried out and must be integrated to be effective in achieving system performance goals. risk, issue, and opportunity management is a concept grounded in a continuous, forwardlooking, structured, informative approach that is planned early in the life cycle and aggressively executed. this affords an organized, comprehensive, and iterative means for identifying and assessing the risks and handling options required to ensure technical, schedule, and cost aspects are appropriately balanced and accounted for.an important aspect of the dod riskmanagement approach is the concept of cost as an independent variable (caiv) (u.s. department of defense, 2003b). in this concept, the highest priority in executing an acquisition program is reduction of procurement and inservice costs balanced by maintaining a high level of system performance for the user. in essence, caiv entails establishing aggressive cost objectives, bound by maximum acceptable risk, so that if costs are too great and viable opportunities exist to reduce them, then the user and developer may compromise system performance requirements to meet cost objections. the important aspect to glean is that, as hsi risks are identied, their subsequent prioritization must be presented in a manner that shows a pragmatic and balanced understanding of the risk/opportunity™s likelihood and consequence traded against acquisition and inservice cost impacts. in essence, the hsi eld must be able to concretely demonstrate the costbenet tradeoffs for the technical, cost, and schedule modications being proposed (sager and grier, 2005). figure 41 depicts an overview of a representative program risk management process. in each step, the hsi practitioner contributes valuable information enabling development and sustainment of a system that meets caiv objectives and user needs. these steps should be undertaken with a holistic system view covering hardware, software, the human element, and related systems.we have chosen to describe program risk management as applied to dod acquisition programs because of its applicability to development of highly complex systems and systems of systems. the methods can also be tailored and scaled for less complex military or commercial projects.in addition to the caiv concept, there are additional program management practices that should be considered to effectively manage hsi humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 77risks and opportunities during program execution. these aspects are not covered in detail in this report, but their importance and relationship to risk management and humansystem integration are summarized here. the rst practice relates to the business proposal on which the program™s execution is based. the business offer is critical because in this process estimates and assumptions are formulated and agreed on by all stakeholders: they cover the customer™s requirements and value proposition, measures of compliance with technical requirements (technical performance measures), schedule milestones, and requisite baseline program resources. if hsi specialists are not involved in the business offer process, their perspective and knowledge are not accounted for in formulating the program baselines, often making it necessary to use management reserve or negotiated requirements relief to resolve technical risks and issues that may have been otherwise accounted for during proposal activities.the second important program management practice is creating a program organizationšin particular, a productbased organization with clear team charters and integration teams at appropriate organizational levels. from a risk management perspective, understanding the organizational breakdown is important because it is a source of program execution risk figure 41 the riskmanagement process.process executioncommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine process management humansystem integration is an integral threadthroughout process management & execution41humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.78 humansystem integration in system developmentand may hinder proactive risk management if not done properly. from the point of view of humansystem integration, understanding where the team resides in the organization is critical because it in˚uences their ability to be effective. in addition, understanding the organizational composition affords the hsi team an opportunity to determine whether they should be represented in integration teams or in other organizational components to create the multidisciplinary skill set that is required to meet that component™s charter.the nal program management practice of interest is a culture of openness in which ﬁhelp neededﬂ (that ˚ows up the organizational structure) and independent reviews are viewed as positive elements. from a riskmanagement perspective, help needed and independent reviews are important because they encourage early identication and timely mitigation of risks and issues.the remainder of this chapter focuses on managing risks; however, it should be noted that considering opportunities is just as important and can be managed similarly to risks. in many cases, the hsi practitioner is well suited to identify and exploit opportunities that yield program execution benets.identifying and analyzing riskrisk identicationrisk identication is the problem denition stage at which risks are identied and quantied in terms of the likelihood of occurrence and detrimental consequences, forming the basis for most risk management actions (hall, 1998; boehm, 1991; u.s. department of defense, 2003b). assessments provide insight into the likelihood of achieving desired outcomes in terms of program cost, schedule, and technical objectives and inservice system performance requirements. the risk identication component entails screening candidate risks to ensure validity, deletion of duplicates, clear statement of the risk, and creation of records used to summarize and track risks throughout the program life cycle. due to the heterogeneity and nuances of program objectives, program lifecycle stages, and skill areas contributing to risk identication, detailed standard approaches are generally not promoted; however, some highlevel steps are universal. the steps presented in figure 42 are intended to provide insight into risk identication focus areas.to effectively identify risks, several qualities of the effort must be in place before focusing on external and internal sources of risk. in the committee™s collective experience, the qualities listed below have been found to be indicators of a healthy and dedicated riskmanagement commitment:humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 79process executioncommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine process managementprocess communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationprocess communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine define risk mgmt methodevaluate & refine 1.review programobjectives/plans tocatalog likely risk sources2.catalog specific candidaterisks3.validate candidate risk list42figure 42 steps in risk identication.ł involvement of all stakeholders and clear communication of program objectives.ł continual iteration of risk identication until program objectives are met.ł utilizing nonadvocate technical experts to assist with risk identification.ł program management culture encouraging risk identication and recording.ł riskmanagement processes that afford consistent documentation.as the hsi practitioner begins risk identication efforts, he or she should be aware that acquisition programs tend to have numerous, often interrelated, risks at all program levels and lifecycle stages that are not always obvious or understood by all skill areas. this can at times mask hsi risks or make it difcult to tease out the hsi component in a larger multiattribute risk. however, lessons learned from dod acquisition programs have revealed program aspects containing hsi risk sources that tend to be more critical and should receive heightened attention (u.s. department of defense, 2003b). these aspects includeł system performance (technical) requirements and characteristics that do not satisfy user requirements.ł mismatch of user manpower or skill proles with system design solutions.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.80 humansystem integration in system developmentł user interface problems (software and hardware).ł proper mix (experience, skills) of hsi personnel assigned to the program management ofce or contractor team (or both); frequent rotation of hsi personnel.listed below are additional program risk sources that hsi practitioners should be concerned about that may reside at the procuring agency™s program management ofce, contractor, and/or suppliers.ł missing, incomplete, insular, out of scope, or uncertain hsi activity plans, schedules, cost estimates, resources, and processes; hsi team budget/staff size.ł program management perspective on the hsi discipline and hsi technical risks.ł inclusion in risk review boards.ł working relationships with stakeholders; access to users.ł clarity and validation of hsi requirements and ability to verify compliance; appropriateness of cited standards.ł supplier hsi processes and requirements.when reviewing these hsi risk sources, one or more of the identication methods enumerated below can be used to populate a candidate risk list. these methods may be undertaken individually by the hsi practitioner, but they are most effective when multiple methods are executed in the setting of an integrated product team (ipt).ł riskidentication checklists and likelihood/consequence tables built on collective knowledge and lessons learned regarding processes, specic technologies, and design phases.ł earned value management metrics analyzed for plan deviations.ł product operations and program processes analyzed for potential failures/anomalies.ł program statement of work or work breakdown structure analyzed for risk sources in managed items (resources, deliverables, or events).once a candidate™s hsi risk has been identied, it is assigned to an hsi team member who becomes the ﬁrisk ownerﬂ and is responsible for managing it. in some instances, the interrelated nature of hsi risks may require that it is coowned by more than the hsi team. candidate risks are subsequently recorded in a riskmanagement database.the next step entails establishing a risk review board or riskmanagement ipt for screening and validating the candidate risk list to avoid duplication, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 81gaps, and inaccuracies. it is essential that hsi practitioners are actively involved in the risk review board or ipt that serves this purposešat the very least, a representative voice that understands the hsi perspective. without hsi involvement in this screening and validation step, it is possible that critical hsi risks may be marginalized or ignored. the completeness of the risk identication activity, as well as the candidate risk itself, should be validated using the following criteria:ł each organization of the program has contributed to risk identication; no gaps.ł candidate risks are deemed signicant by the owner and those affected by it.ł risks, their source, and consequence are well dened and consistent with known data. (this can be challenging for humansystem integration given the skill™s subjective nuances).ł risk consequences describe the unfavorable effects on the program objectives.upon completing the candidate risk validation process, hsi risks are included in a program risk watch list that serves as the deliverable for risk identication activities.risk analysisrisk analysis determines the levels of likelihood, consequence, and overall risk for each candidate risk, then categorizes (technical, schedule, or cost) and prioritizes the risks (low, moderate, or high) to select riskhandling actions (garvey and lansdowne, 1998; hall, 1998). the overarching intent is to zeroin on areas of high and moderate hsi risk for which riskhandling actions can have the greatest impact.figure 43 provides a synopsis of the risk analysis steps in which humansystem integration plays an important role championing an enduser™s perspective on risk likelihood and consequence. when progressing through these steps, risk analysis is rst conducted on individual risks followed by analysis of their effect on managed items (deliverables or scheduled events) and the entire program to prioritize riskhandling strategies. it is important that hsi engineers are part of the risk review board performing the analysis to describe the risks and lobby for appropriate resources to manage hsi risks effectively, as well as to coordinate with others where a hsi thread is woven into other risks.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.82 humansystem integration in system developmentprocess execution communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationcommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine define risk mgmt methodevaluate & refine process management 1.define analysis method2.for candidate risks & executed riskmitigation plans, determine:ÿlikelihood & consequenceÿrisk level3.assess impacts to program4.prioritize & denote significant risks43figure 43 steps in risk analysis.determine the risk analysis methodas noted in figure 43, the rst step in risk analysis is to determine the method of analysis for ﬁmeasuringﬂ the risk. methods of risk analyses range from simple, qualitative approaches to quantitative methods to hybrids combining qualitative and quantitative techniques. typically, qualitative and hybrid methods are utilized, whereas complex quantitative methods are applied to specialized, indepth risk analyses. this is particularly true for hsi risks in which subjective data predominates, thereby necessitating a qualitative approach, as explained below. when deciding which method to employ, it is important to consider the type of likelihood and consequence values that will be generatedšordinal (qualitative, relative values, not an actual numerical difference) or ratio (quantitative, calibrated to a known scale with a xed zero point). this is critical because mathematical operations performed on results from uncalibrated ordinal scales are meaningless and yield erroneous risk ratings (conrow, 1995). quantitative analyses should use only values from ratio scales having calibrated, measurable values.assess likelihood and consequence levelsthe second step in risk analysis is to determine the likelihood and consequence levels for each identied risk. for hsi risks, assessing their likelihood and consequence is particularly challenging for a number of reasons (subjective nature of the risk, lack of previous examples or analogies to reference, individual differences of endusers, etc.) and is an area in which hsi specialists may lack experience. aside from the risk that the hsi team may not adequately accomplish the risk analysis on time and within budget, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 83most hsi risks involve the potential failure of the system™s design specications or user interface specications to meet the performance requirements of the end users. quantifying these risks is difcult and requires the participation of the design team as well as the hsi specialist. in addition, it is paramount that method, tools, and criteria are consistently applied to create an equitable basis for comparison. chapter 8 discusses in more detail aspects of assessing the likelihood and consequence of a risk using failure modes and effects analysis and fault tree analysis.determine the risk levelnext, the risk level (i.e., a holistic ﬁmeasurementﬂ of risk) is determined based on combining the assessed likelihood and consequence levels. risk levels are described as high, moderate, or low and are often portrayed in risk grids (likelihood and consequence are the axes) with stoplight colors (red represents high risks, yellow for moderate risks, and green for low risks).assess program impactsthus far, risk owners have assessed individual risk levels, but individual risk impacts on the program need to be assessed. the program impact of the individual risks is determined by a risk review board that examines the relationships of individual risks to one another or a higher level program item (managed items, deliverables, or scheduled events) to perform a collective risk assessment. the risk review board also takes into account the dependencies of higher level program items to ensure a holistic programlevel risk assessment. hsi risks are often marginalized in this process due to the specialty engineering nature of humansystem integration, unless an hsi representative is present to elucidate the issue. if an hsi representative is not a part of the risk review board, the result may be inadequate resources being allocated to hsi risks or disregard of their potential impact when examining higher order dependencies because it is masked by other risks.the holistic, integrated perspective is important because individual risk analysis treats risks as mutually exclusive and independent of each other; typically this is not the case for hsi risks in complex system development. individual risks frequently have common elements that make them interdependent despite their independent occurrence; this is especially true for hsi risks. as a result, the potential relations of individual risks to higher level program items may have a collective effect of increasing the risk level of that higher level program itemšhence the importance of collective risk analysis in which the rst step in assessing program impacts is to determine the relationship of individual risks to higher level program items humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.84 humansystem integration in system developmentand then assessing their collective effect on the risk level of a higher level program item.the next step in assessing program impacts is an integrated risk analysis to determine risk interdependencies that may amplify one or more of the interrelated risks. in this analysis it is important for hsi practitioners to explain how disregarding hsi risks, particularly those masked by other risks or marginalized due to underappreciation of the hsi risk, may have implications later requiring rework to resolve or additional risk management activities. this need for clearly explaining how hsi risks may signicantly contribute to the program™s risk ﬁcritical pathﬂ is particularly crucial for software development, in which a ﬁwe can x that later, it™s softwareﬂ mind set, or the fallacy of reusing software to improve program cost and schedule metrics, at times prevails.once the risk review board has completed the collective and integrated risk analyses, the program risk critical paths may be determined. the risk critical path of a program can be identied only by determining the predecessor and successor relationships and success dependencies of managed items and conducting the integrated risk analysis. all individual risks in the riskcritical path should be given the highest priorities in the program for risk handling.prioritize risksindividual risks should be prioritized for their handling options by individual risk levels, effect on higher level program items, relationship to the program™s riskcritical path, and urgency based on time to when the risk may occur and/or customer priorities and preferences. prioritization is done by adjusting the risk priorities up or down from the risk level based on the risk prioritization factors. if the risk levels and prioritization factors all have ratio scales with absolute values, the risk level may be a calculated function of these quantities. otherwise, prioritization must be done by manually assessing the effect of the prioritization factors on risk level.successful completion of the risk analysis step culminates in the generation of individual risk likelihood and consequence assessments, risk levels (low, moderate, high) for individual risks and higher level program items, an identied program riskcritical path, and prioritized individual risks to steer subsequent riskhandling activities. given the extent of in˚uence that risk analysis has on resource allocation, it is important that hsi practitioners are actively involved in this component of risk management. the hsi team is typically working with suboptimal resources, and it is imperative they are not further diminished because the issues associated with hsi risks are not fully understood or appreciated by decision makers.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 85handling options assessmentassessing riskhandling options includes evaluating each signicant risk to determine the appropriate handling strategy (hall, 1998; boehm, 1991). typically, only moderately or highly prioritized risks require a riskhandling strategy, whereas lowpriority risks are monitored and periodically reassessed. the most appropriate handling strategy for each risk is selected based on its urgency, level of the risk, resources and schedule constraints, and customer satisfaction expectations. the riskhandling options to choose from include avoiding the risk, transferring the risk, assuming the risk, and mitigating the risk; these options are depicted in figure 44. the hsi practitioner is well suited to offer a range of riskhandling options given the ˚exibility in hsi techniques and bringing a mind set of the impact of those options on user and system performance when the system is operational.process execution communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine communicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationcommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine define risk mgmt methodevaluate & refine process management 1.undertake for significant risks only2.consider the following options in descending order:ÿavoid the risk (e.g., delete a requirement)ÿtransfer the risk (e.g., reallocate arequirement)ÿassume the risk (e.g., monitor & reassess)ÿmitigate the risk (e.g., risk mitigation plan with fallback options)44figure 44 decision ˚ow of riskhandling options.avoiding the riskavoiding the risk is an option that is usually viable only in the earliest phases of a program, when concept development permits redening plans and approaches with minimum impact. a decision to avoid the risk and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.86 humansystem integration in system developmentthe method of avoidance typically involves not only the team responsible for the risk, but also program management and the customer. the limited window of opportunity for avoiding the risk and the need for extensive coordination is illustrated by its associated options, which include (1) choosing an alternative approach with a lower risk, (2) deleting specic requirements, (3) changing specic requirements, (4) changing the overall technical solution, (5) modifying the program schedule, and (6) modifying the funding level or funding prole.an additional, yet untraditional, perspective is that hsi risks can often be avoided by further dening requirements to remove the nebulous (ﬁsoftﬂ) attributes (in chapter 7 see the section on usability requirements methods). traditionally, hsi requirements are vaguely dened and hard for the contractor to prove compliance; jointly rening them creates clarity in the development process. before deciding on a risk avoidance handling strategy, options of risk transfer, risk acceptance, and risk mitigation should be evaluated.transferring the risktransfer is a strategy to shift the risk elsewhere (e.g., another team, supplier, customer, or requirement) so that overall program risk is optimized and risk ownership is assigned to the party most capable of reducing or accepting the risk. options for transferring the risk includeł reallocating requirements to reduce overall program risk.ł developing a research and development (r&d) project that takes the risk with it and substitutes a lower risk contractual alternative with an option to evaluate the r&d results for later product improvement.ł pushing the risk to the next program phase and addressing it later if the current program is successful.deferring the risk can have dire consequences from an hsi perspective. delaying the handling of an hsi risk is often the option chosen because decision makers do not fully appreciate the importance of managing hsi risks proactively and early in the program life cycle. this is particularly true in software development and hardware design, in which ergonomic (anthropometry and biomechanics) and human factors (usability) aspects of the system design may necessitate costly xes because the hsi risks were not given appropriate attention at the proper program lifecycle phase, or it was deemed that transferring the risk by pushing it to a later program phase would be more effective. having assessed risk avoidance and transfer, the options of risk acceptance and risk mitigation should be evaluated.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 87assuming the riskrisk assumption is a deliberate decision to accept a known risk, and it should be based on costbenet analysis, showing that it is more benecial to assume the risk than it is to choose any of the other riskhandling options. this decision is made only when all relevant facts have been presented to the decision makers. if assuming the risk is the option chosen, then the risk owner needs to monitor the risk continuously for change, reassess it as appropriate, and take action as needed. as long as the risk™s parameters are within predetermined acceptable ranges, no action is needed. if they fall outside these predetermined acceptable ranges, action is triggered, and a decision must be made for how to bring the risk level back into the acceptable range. at this point, a reassessment of the possibilities of avoiding, transferring, or assuming the risk also is recommended.risk assumption is another oftenused approach for handling hsi risks, primarily because the decision makers do not fully grasp the implications, or the seriousness of the risk does not surface in demonstrable manner until the system is operational. humanintheloop evaluations of system prototypes and system build releases within the spiral life cycle are the most effective means for demonstrating when an hsi risk should not be assumed, but these activities require competing for highly utilized program resources. it is also crucial that the tolerable bounds for assuming an hsi risk are succinctly documented along with the impact of crossing them. after examining the alternative of assuming the risk, risk mitigation should still be evaluated, especially for risk items that exceed acceptable risk assumption parameters.mitigating the risksfor items judged to be signicant risks and avoiding, transferring, and assuming risks are not acceptable options, risk mitigation is chosen. risk mitigation is a strategy for developing options and alternatives that lower or eliminate the risk by reducing its likelihood or consequences. this usually applies to technical risks (e.g., subsystem design), but it may also apply to schedule risks (e.g., a supplier who has a signicant ontime delivery risk). for highrisk items, a fallback plan needs to be identied to cover the possibility of mitigation plans failing. the purpose of the fallback plan is to allow the program to continue while still meeting most of the program objectives.humansystem integration has an amalgam of tools and techniques for mitigating risk that are integrated into everyday practicesšfor example, software prototyping, anthropometric modeling, usability evaluations, and cognitive workload modeling. by effectively performing the role of an hsi humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.88 humansystem integration in system developmentengineer, the practitioner is continuously mitigating risk in the design and development of the system, with a focus on the risks that impact the operational effectiveness of both the system and the user.executing risk mitigationthe risk mitigation option, when chosen, establishes detailed plans for the risks that require them, covering required resources, schedules, tasks, success criteria, expected resulting risk level for each successfully completed task, and plan approval. in addition, this step creates fallback plans for all high risks, along with decision gates and criteria for their implementation (u.s. department of defense, 2003b). humansystem integration will execute mitigation strategies for its own risks; however, it is also important that humansystem integration is involved in dening the collateral impacts of its efforts and understanding the impacts on other skill areas™ risk mitigation activities, as well as theirs on humansystem integration. figure 45 is a representation of the risk mitigation activity.process executioncommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine process managementcommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationcommunicate/ track risksidentify risksanalyze risksevaluate handling optionsdevelop & execute mitigationdefine risk mgmt methodevaluate & refine define risk mgmt methodevaluate & refine 1.assess priority of significant risks & riskhandling strategies2.execute selected risk handling options3.monitor execution & assess effectiveness45figure 45 steps in risk mitigation.develop a planeffective risk mitigation entails reduction of the risk occurrence likelihood, its consequences if it occurs, or both to complete the effort. subsehumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.managing risks 89quently, clearly dening task success criteria is imperative to measure the effectiveness of the risk mitigation plan and determining when to invoke a fallback plan. for humansystem integration, dening the success criteria can be tricky due to the subjectivity inherent in a majority of the issues with which the discipline works. in essence, the hsi practitioner is trying to dene criteria akin to usability goals with gradations indicating degrees of success and when a fallback plan should be implemented.when creating a risk mitigation plan, an array of options exists, depending on the nature of the risk; hsi options may includeł trade studies; parallel prototyping; early development hsi evaluation; early and extensive simulation.ł system and/or task analysis; rening, modifying, or eliminating hsi requirements.ł working with suppliers to implement solid hsi processes.ł using an alternate design that already meets hsi requirements.ł extending the schedule; increasing the budget.when generating the risk mitigation plan, the items below should be explicitly and succinctly stated.ł task denitions with entry and exit criteria that denote starting and completion points (success criteria dening expected risklevel outcomes and subsequently removing the risk from the signicant risk list). planned start and stop dates with associated cost and required inputs.ł relationships between tasks in the risk mitigation plan and overarching program plan, as well as collateral impacts on required resources.ł means for tracking plan variance.identify fallback plansrisks that are categorized as high should have fallback plans as part of the risk mitigation strategy. fallback plans are requisite to ensure that an alternative approach is available to mitigate risks that have a signicant likelihood of occurrence, severe consequences, or both.incorporate into program schedulesapproved risk mitigation plans need to be a formal part of the program schedule and be re˚ected in the program™s metrics to garner the requisite attention needed to accomplish planned mitigation tasks. generally, ﬁoff the booksﬂ mitigation efforts suffer from lack of visibility, suboptimal coordination, and improper conguration management. it is extremely important humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.90 humansystem integration in system developmentthat hsi risk mitigation plans are integrated into the program scheduled because the discipline is often hampered by the perspective of some decision makers that humansystem integration is a specialty engineering resource utilized for consultancy purposes. by operating off the books, the hsi team is further isolating itself from the decision makers who control resources.evaluate success accomplishments and assess reductions achievedeach mitigation activity has predened success criteria associated with it. as mitigation tasks are accomplished, they must be evaluated to determine if the expected success criteria were met. in addition, the degree to which the predicted risk reduction was accomplished needs to be assessed. if not fully successful, the plan may need to be adjusted or fallback plan implemented to achieve the planned risk reduction.evaluate remaining plan activitiesupon completion of each risk mitigation task, the remaining tasks in the plan should be evaluated to ensure the overall required reduction is still attainable via the dened plan. decisions are made at this point whether to proceed with the plan as dened, modify it, or implement the fallback plan. as noted previously, any decisions to change the plan need to mandate proper coordination, approval, and incorporation into the program schedule.successful completion of the risk mitigation step culminates in detailed mitigation plans documented in team and program schedules, fallback plans, approved resources to execute the risk mitigation plan, and completion of the risk mitigation strategy resulting in the expected reduced level of risk.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.5case studiesthis chapter provides three examples of specic system development that illustrate application of humansystem integration (hsi) methods in the context of the incremental commitment model (icm). the examples are drawn from the committee™s collective experience and specic application of the concepts developed during our work to these particular projects. they represent projects at three stages of development: the early stages of planning, in middevelopment, and fully realized.the rst example involves the development of unmanned aerial systems and identies numerous hsi issues in these systems that will require solution. this example provides a ﬁnotionalﬂ application of human factors methods and potential implementation of the incremental commitment model. the case study illustrates the theme of designing to accommodate changing conditions and requirements in the workplace. specically, it addresses the issue of adapting current unmanned aerial systems to accommodate fewer operators, with individual operators controlling multiple vehicles. the hypothetical solutions to this problem reveal the potential costs of reliance on automation, particularly prior to a full understanding of the domain, task, and operator strengths and limitations. this case study also reveals the tight interconnection between the various facets of humansystem integration, such as manpower, personnel, training, and design. in other words, answering the ﬁhow many operators to vehiclesﬂ question necessarily impacts design, training, and personnel decisions.the second example focuses on a largescale government implementation of port security systems for protection against nuclear smuggling. the example discusses the hsi themes and incremental application of methods 91humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.92 humansystem integration in system developmentduring the iterative development of the system. this case is useful for illustrating application of human factors methods on a riskdriven basis, as they tend to be applied as needed over time in response to the iterative aspects of dening requirements and opportunities, developing design solutions, and evaluation of operational experience.the third example describes development of an intravenous infusion pump by a medical device manufacturer. this example is the most detailed and ﬁlinearﬂ of the three cases, in that it follows a sequential developmental process; the various systems engineering phases are discussed in terms of the human factors methods applied during each phase. this case study illustrates the successful implementation of wellknown hsi methods, including contextual inquiry, prototyping and simulations, cognitive walkthroughs for estimating useerrorinduced operational risks, iterative design, and usability evaluations that include testing and expert reviews. the importance of the incremental commitment model in phased decision making and the value of shared representations is also highlighted.each of these examples is presented in a somewhat different format, as appropriate to the type of development. this presentation emphasizes one broad nding from our study, which is that a ﬁone sizeﬂ system development model does not t all. the examples illustrate tailored application of hsi methods, the various tradeoffs that are made to incorporate them in the larger context of engineering development, and the overall theme of reducing the risk that operational systems will fail to meet user needs.unmanned aerial systemsunmanned aerial systems (uass) or remotely piloted vehicles (rpvs) are airplanes or helicopters operated remotely by humans on the ground or in some cases from a moving air, ground, or water vehicle. until recently the term ﬁunmanned aerial vehicleﬂ (uav) was used in the military services in reference to such vehicles as predators, global hawks, pioneers, hunters, and shadows. the term ﬁunmanned aerial systemﬂ acknowledges the fact that the focus is on much more than a vehicle. the vehicle is only part of a large interconnected system that connects other humans and machines on the ground and in the air to carry out tasks ranging from uas maintenance and operation to data interpretation and sensor operation. the recognition of the system in its full complexity is consistent with the evolution from humanmachine design to humansystem design, the topic of this report. it highlights an important theme of this book: the need for methods that are scalable to complex systems of systems.unmanned aerial systems are intended to keep humans out of harm™s way. however, humans are still on the ground performing maintenance, control, monitoring, and data collection functions, among others. reports humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 93from the army indicate that 22 people are required on the ground to operate, maintain, and oversee a shadow uas (bruce hunn, personal communication). in addition, there is a dearth of uas operators relative to the current need in iraq and afghanistan, not to mention the u.s. borders. the growing need for uas personnel, combined with the current shortage, points to another theme of this report: the need for humansystem integration to accommodate changing conditions and requirements in the workplace.in addition, this issue has strong ties to questions of manning. the manning questions are ﬁhow many operators does it take to operate each unmanned aerial system? can one modify the 2:1 human to machine ratio (e.g., two humans operating one uas) to allow for a single operator and multiple aircraft (e.g., 1:4)?ﬂ automation is often proposed as a solution to this problem, but the problem can be much more complex. automation is not always a solution and may, in fact, present a new set of challenges, such as loss of operator situation awareness or mode confusion. furthermore, the manning question is a good example of how hsi design touches other aspects of humansystem integration, such as manpower, personnel, and training. that is, the question of how many vehicles per operator is not merely one of automation, but also involves the number and nature of the operators in question.a hypothetical casethis example is based on an ongoing debate about the manning question, which has not been fully resolved. therefore some aspects of the case are hypothetical, yet not improbable. in this example we assume that the objective of the design is to change the operator to uas ratio from 2:1 to 1:4. that is, instead of two operators for one uas there will be one operator for four uass. this operator to uas ratio is a requirement of the type that may be promulgated by the department of defense with minimal hsi input. it could be too late for humansystem integration, which needs to be fully integrated into the engineering life cycle before system requirements have been determined. it could be too late in the sense that upfront analysis might have revealed that an effective 1:4 ratio is beyond the capabilities of current humans and technology under the best of circumstances. if this is the case, then there is a huge risk of designing a system that is doomed to fail. even worse, this failure may not reveal itself until the right operational events line up to produce workload that breaks the system.in our example, we present another scenario. the design of a uas with a 1:4 ratio of operator to system is carried through the icm development process to illustrate the potential role of humansystem integration and one of the themes of this book. the department of defense is one of many humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.94 humansystem integration in system developmentcritical stakeholders in this scenario, all of whom are to be considered in the satiscing process that ensues.humansystem integration in the context of the  incremental commitment modelin the earliest exploration phases of icm development, the problem space and concept of operations are dened, and concept discovery and synthesis take place. table 51 provides highlights of the entire example. it is often the case that humansystem integration is not brought into the development cycle at this point, although at great risk. upfront analyses, such as interviews of uas operators, observations of operations of 2:1 systems, examination of mishap reports, understanding of the literature and data, an analysis of the 2:1 workload, event data analysis targeted at communications in the 2:1 uas system, application of models of operator workload, and work ˚ow analysis are all methods that could be used to explore the hsi issues in the current uas system.there is much that could come from this kind of upfront analysis. one hypothetical possibility is that the upfront hsi analyses could determine that uas workload is not constant but peaks in target areas where photos need to be taken or in situations in which the route plan needs to change.one of the key principles of icm development is risk management, including riskdriven activity levels and anchor point commitment milestones. what are the risks if humansystem integration is not considered early in the development life cycle? in this case, the formal requirements that are established may target workload reduction incorrectly. for example, autopilot automation might be developed to help to get multiple uass from point a to point b and so on. this might have the effect of reducing workload when a reduction was not needed, while providing no relief from the highworkload tasks. ultimately the neglect of upfront humansystem integration could result in a system that is ineffective or prone to error. consideration of risks like these should guide system development.what if there is not enough time to interview uas operators and to do a thorough job in the exploration phase? there is also risk associated with application of costly upfront techniques. the upfront methods used often during the exploration phase of the life cycle can be tailored to meet time and budget constraintsšanother theme of this book. for example, in this case in which the manning question is the issue and automation appears to be a promising solution, it would make sense to focus on aspects of the task that may be automated and the workload associated with each. one caveat is that decisions on how to scope and tailor the methods require some hsi expertise in order to target the aspects of humansystem integration that promise the most risk reduction.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 95as system development progresses, other principles of icm development come into play, including incremental growth of system development and stakeholder commitment. this part of the development lifecycle synthesis leads to construction, invention, or design that is iteratively rened as it is evaluated. hsi activities that would be useful at this point include function allocation and the development of shared representations, such as storyboards and prototypes.based on the previous nding of ˚uctuating workload, it may be decided that human intervention is needed at target areas and during route changes, but that the single operator can handle only one of these peakworkload tasks at a time. it may also be determined that, although automation could handle the routine ˚ight task, an even more important place for automation is in the handoff between the ˚ight tasks and the human planning/replanning operation. the automation would therefore serve a scheduling and handoff function, allocating complex tasks to the human operator as they arise and in order of priority (e.g., priority targets rst). there could also be automation that serves as a decision aid for the targeting task.because only one nonroutine task can be handled at a time under the 1:4 scenario, it may also be decided that operators should be relieved of the ˚ight functions completely but be on call for handoffs from automation. for example, four controllers could handle the prioritized handoffs from the automation, much as air trafc controllers handle multiple planes in a sector. note that this new design and stafng plan are completely different in terms of operator roles and tasks from the former 2:1 operation. it is humansystem integration that guided the allocation of tasks to human and machine; without it there would have been many other possibilities for automation that may not have produced the same endstate.as the icm development continues, the system engineers will go from working prototypes to product development, beta testing, product deployment, product maintenance, and product retirement. but there is continual iteration along the way. the incremental growth in the automation for scheduling, handoffs, and targeting would occur in parallel with the next iteration™s requirements and subsystem denitions (i.e., concurrent engineering). incremental growth will be in˚uenced by stakeholder commitment. the hsi methods in the later stages include interviews and observations in conjunction with the newly designed system and usability testing. some of the same methods used in upfront analysis (e.g., event data analysis, participatory analysis) can be again used and results contrasted with those of the earlier data collection.the goal of humansystem integration at this stage is to verify that the situation for the user has improved and that no new issues have cropped up in the interim. for instance, it may be determined from testing that the targeting decision aid is not trusted by the human operator (a stakeholder) humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.96 humansystem integration in system developmentand as a result is not used (a risk). through iterations, a new design will be tested or the decision aid will be completely eliminated (i.e., stakeholder satiscing).conclusion and lessons learnedin this example, humansystem integration plays a major role throughout the design process and is critical in the early stages before requirements are established. it can be integrated throughout the design life cycle with other engineering methods. it is also clear that the hsi activities serve to reduce human factors risks along the way and make evident the human factors issues that are at stake, so that these issues can be considered as they trade off with other design issues.this example illustrates several lessons regarding humansystem integration and system design:ł the importance and complexity of the ﬁsystemﬂ in humansystem integration compared with ﬁmachineﬂ or ﬁvehicle.ﬂł design concerns are often linked to manpower, personnel, and training concerns.table 51 example of humansystem integration for uass in the context of the riskdriven spirallifecycle phasehsi activityse activitieshypothetical outcomerisks if no hsihsi valueaddedexplorationobserve 2:1 system, interview uas operators, examine literature/data, examine mishap reports, workload analysis and models, event data analysis, communication, work ˚ow analysisdene problem space, concept discovery, concept of operations, synthesisworkload not constant; heavy at target areas and for route changeineffective or errorprone systemrequirements targeted at known system strengths and weaknessesvaluation and architectingfunction allocation, storyboards, prototypessynthesis, construct, invent, design, rene, hard requirements, working prototypesautomation takes over ˚ight and handoffs complex tasks to operatorbased on priorityoperator who is overwhelmed during high workload and bored during low workloaddesign takes into account known machine and human strengths and weaknessesdevelopment and operationinterviews, observations, usability testing, comparisons with previous systemworking prototypes, product development, beta testing, product deployment, maintenance, retirementtargeting decision aid not trusted by human operatorvalidation and verication would not consider the human limitations in relation to the new systemtesting takes into account usability and comparison to prior systemnote: hsi = humansystem integration; se = systems engineering; uas = unmanned aerial system.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 97table 51 example of humansystem integration for uass in the context of the riskdriven spirallifecycle phasehsi activityse activitieshypothetical outcomerisks if no hsihsi valueaddedexplorationobserve 2:1 system, interview uas operators, examine literature/data, examine mishap reports, workload analysis and models, event data analysis, communication, work ˚ow analysisdene problem space, concept discovery, concept of operations, synthesisworkload not constant; heavy at target areas and for route changeineffective or errorprone systemrequirements targeted at known system strengths and weaknessesvaluation and architectingfunction allocation, storyboards, prototypessynthesis, construct, invent, design, rene, hard requirements, working prototypesautomation takes over ˚ight and handoffs complex tasks to operatorbased on priorityoperator who is overwhelmed during high workload and bored during low workloaddesign takes into account known machine and human strengths and weaknessesdevelopment and operationinterviews, observations, usability testing, comparisons with previous systemworking prototypes, product development, beta testing, product deployment, maintenance, retirementtargeting decision aid not trusted by human operatorvalidation and verication would not consider the human limitations in relation to the new systemtesting takes into account usability and comparison to prior systemnote: hsi = humansystem integration; se = systems engineering; uas = unmanned aerial system.ł upfront analysis and hsi input in early exploration activities is critical.ł methods can be tailored to time and money constraints, but hsi expertise is required to do so.ł risks are incurred if humansystem integration is not considered or if it is considered late. in this case the risk would be a system that is not usable and that ultimately leads to catastrophic failure.port securitythe u.s. department of homeland security (dhs) is in the process of implementing a largescale radiation screening program to protect the country from nuclear weapons or dirty bombs that might be smuggled across the border through various ports of entry. this program encompasses all land, air, and maritime ports of entry. our example focuses on radiation screening at seaports, which have a particularly complex operational nature. seaports are structured to facilitate the rapid of˚oading of cargo containers from oceangoing vessels, provide temporary storage of the containers, and provide facilities for trucks and trains to load containers for transport to their nal destination. the operation involves numerous personnel, includhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.98 humansystem integration in system developmenting customs and border protection (cbp) ofcers for customs and security inspection, terminal personnel, such as longshoremen for equipment operation, and transport personnel, such as truck drivers and railroad operators. figure 51 illustrates the steps involved in the radiation screening process.design and deployment of radiation portal monitoring (rpm) systems for seaport operations engages the incremental commitment model for ensuring commitments from the stakeholders and to meet the fundamental technical requirement of screening 100 percent of arriving international cargo containers for illicit radioactive material.this example illustrates aspects of the icm process with specic instances of humansystem integration linked to concurrent technical activities in the rpm program. the development of rpm systems for application in the seaport environment entails an iterative process that re˚ects the overall set of themes developed in this book. we discuss how these themes are re˚ected in the engineering process.humansystem integration in the context of  riskdriven incremental commitmentsthe human factors design issues encountered in this program are very diverse, ranging from fundamental questions of alarm system effectiveness at a basic research level, to very practical and timesensitive issues, such as the most appropriate methods of signage or trafc signaling for controlling 51primary signal threshold processoralarm status allornoneconfirmsecondary scaninspectresolve & dischargeall type replaced on "fixed image" for consistencyfigure 51 rpm security screening at seaports involves multiple tasks, displays, and people.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 99the ˚ow of trucks through an rpm system. hsi methods have been applied on a needsdriven basis, with risk as a driver for the nature of the application. with the issue of alarm system effectiveness, for example, it was recognized early in the program that reducing system nuisance alarms is an important issue, but one that requires a considerable amount of physics research and human factors display system modeling and design. the icm process allowed early implementation of systems with a higher nuisance alarm rate than desirable while pursuing longer term solutions to problems involving ltering, new sensors, and threatbased displays. the nuisance alarm risk was accepted for the early implementations, while concurrent engineering was performed to reduce the alarm rate and improve the threat displays for implementation in later versions.a contrasting example involves trafc signage and signaling. since the ˚ow of cargo trucks through port exits is a critical element of maintaining commercial ˚ow, yet proper speed is necessary for rpm measurement, methods for proper staging of individual vehicles needed to be developed. most ports involve some type of vehicle checkout procedure, but this could not be relied on to produce consistent vehicle speed through the rpm systems. instead, the program engaged the hsi specialty to assist in developing appropriate signage and signaling that would ensure truck driver attention to rpm speed requirements.hsi methods tailored to time and budget constraintssince the rpm program focus is homeland security, there has been schedule urgency from the beginning. the need for rapid deployment of rpm systems to maximize threat detection and minimize commercial impact has been the key program driver, and this has also in˚uenced how the hsi discipline has been applied. the primary effect of program urgency and budgetary limitations has been to focus hsi efforts in work domain analysis, the modeling of humansystem interactions, and theorybased analysis rather than experiment.the work domain analysis has typically focused on gaining a rapid understanding of relatively complicated seaport operations in order to evaluate technology insertion opportunities and to better understand design requirements. in contrast to work domain analysis oriented toward cognitive decision aids, which requires timeintensive collaboration with subject matter experts, the rpm analysis worked at a coarser level to characterize staff functions and interactions, material ˚ow, and operational tempo. similarly, modeling of humansystem interactions (such as responding to a trafc light or an intercom system) was performed at the level of detail necessary to facilitate design, rather than a comprehensive representation of operator cognitive processesšthis was not required to support engineering.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.100 humansystem integration in system developmenttheorybased analysis of alarm system effectiveness has been conducted on a somewhat longer time scale, since the problem of human response to alarms is more complex. this work consisted of adapting traditional observerbased signal detection theory, in which the human is an active component of the detection system, to rpm systems in which the human operator evaluates the output of a sensor system that detects a threat precondition. various threat probability analyses have been conducted in this effort, and they can be used to guide subsequent advanced rpm designs. this work has been guided by empirical studies, but it has not required an independent data collection effort.shared representations used to communicatethe rapidpaced nature of the rpm program places a premium on effective communication between humansystem integration and the engineering disciplines. in this program, fairly simple communication mechanisms that use graphics or presentation methods adapted from engineering have the best chance of successful communication. for example, it is important to evaluate the human error risks associated with new security screening systems so that mitigation approaches can be designed. one approach to describing this to the engineering community might be to simply borrow existing taxonomies from researchers in the eld, such as reason (1990). alternatively, a more graphic and less verbose approach is to represent the approach as a fault tree, shown in figure 52. this type of representation is immediately recognizable to the engineering community and is less subject to interpretation than abstract descriptions of error typologies.failurefailurefailurefailurefailurefailurefailure52initiationprimary screenillicit item approaches screening screening stationitem identified for item  enters primary screening processpositive detection of itemitem identified for secondary screeningend statefailuresuccessfailurefailurefailureyesyesyesyesnonononofigure 52 general model of human error analysis for security screening used as a shared representation to communicate the concept to engineering staff.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 10153primary signalresolve & dischargestatistical processor:templates/spectraalarm status calibrated topotential threatfigure 53 graphical representation of work ˚ow with a threatbased rpm display.humansystem integration has used graphics to convey fairly abstract design ideas to the engineering staff, as shown in figure 53. this display conveys the concept of a threat likelihood display, which informs the rpm operator about the contents of a vehicle based on processing algorithms. the graphic contrasts the eightstep process shown in figure 51, with a fourstep screening process, illustrating the functional utility of the display in a direct way.accommodation to changing conditions and workplace requirementsthe rpm program started with a set of baseline designs for seaports that involved a cargo container passing through an exit gate. as the program expanded to a wider range of port operations, numerous variations in the containerprocessing operations became apparent. in some instances, the trafc volume is so low that the costs of installing a xed installation are too high; alternatively, trenching limits or other physical constraints may preclude a xed portal. operational differences, such as moving containers direct to rail cars, also present challenges for design.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.102 humansystem integration in system development54portrait viewfigure 54 standard truck exit rpm system (left), mobile rpm system (middle), and straddle carrier operation (right).figure 54 illustrates several variants of rpm operational congurations that have hsi implications. the truck exit shown in the gure is a standard design that accommodates the majority of seaport operations as they are currently congured. in order to accommodate reconguration and low volume, a mobile rpm system has been developed, as shown above. for ports at which straddle carriers are used to move containers directly to rail, solutions are currently being evaluated. humansystem integration has been directly responsible for operations studies of straddle carrier operation to discern technology insertion opportunities. the critical issue for seaports is that current operations do not predict future operations; the rapid expansion of imports will fundamentally alter how highvolume ports process their cargo, and hsi studies will be an important element of adapting the security screening technologies to evolving operational models.scalable methodsthe rpm program is large in scalešinvolving geographically distributed installations on a nationwide basis, multiple personnel, government agencies and privatesector stakeholdersšand seaports are an element of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 103the nation™s critical infrastructure. to make an effective contribution in this context, humansystem integration has focused on problems of an aggregate nature that affect multiple installations. the methods generally employed, such as work domain analysis, probabilistic risk modeling, and timeline analysis, are applicable at an individual operator, work group, or portwide level. scalability is inherent in the overall goals of method application (i.e., discerning general operational constraints and potential design solutions); in the process there are requirements for ﬁoneoffﬂ tailored solutions, but the fundamental goal is to provide generic solutions.principles of system developmentthe development of rpm systems for application in the seaport environment has entailed an iterative process that re˚ects the system development principles described in this book. this section discusses how these principles are re˚ected in the engineering process.successcritical stakeholder satiscingas mentioned above, this program involves the private sector (seaport terminal management and labor), local public agencies such as port authorities, local and national transportation companies such as railroads, federal government agencies (dhs), federal contractors, and, from time to time, other federal law enforcement agencies, such as the federal bureau of investigation. the issues and requirements of all need to be addressed in rpm deployments. the dual program goals of maximizing threat detection and minimizing impact on commerce dene the parameters for stakeholder satiscing.incremental growth of system denition and stakeholder commitmentthe objective of minimal disruption to ongoing seaport operations and the need to identify trafc choke points and screening opportunities require considerable upfront analysis, as well as continuing evaluation of impact as individualized deployments are designed. the general activities in this category includeł initial site surveys to identify choke points.ł operational process analysis to identify trafc ˚ow and screening procedures for individual seaport sites.ł adaptation of baseline screening systems to specic seaport site constraints.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.104 humansystem integration in system developmentł continued monitoring and evaluation of impact, including nuisance alarm rates and trafc ˚ow, from design through deployment.ł modication of rpm system elements as required to meet security and operational missions.this process generally involves initial stakeholder meetings to establish the relationships necessary to adapt the technologies to individual operations. based on information gathered in operational studies, conceptual designs (50percent level) are proposed, reviewed, and revised as a more detailed understanding of requirements and impacts is obtained. this leads to more rened denitions of implementation requirements and operational impacts, which in turn lead to commitment at the 90percent design review.risk managementthe multiple operational personnel involved in port security and seaport operations necessarily entails a variety of human factors risks when new technology is introduced. one of the major initial risks involved consideration of stafng, as customs and border protection authorities have not typically placed ofcers on site at seaports. a number of options for operating security equipment were evaluated, and the decision was made that cbp would staff the seaport sites with additional schedule rotations. this reduced the risk of relying on nonlaw enforcement personnel but increased the cost to the government (a tradeoff). other risks include generally low workload associated with processing alarms (a tradeoff of boredom and cost, but physical presence is guaranteed), the gradual erosion of alarm credibility based on the exclusive occurrence of nuisance alarms (a tradeoff of high sensitivity of detection system with potential for reduced effectiveness), risks of labor disputes as more complex technology is introduced that may be seen as infringing on privatesector territory (a tradeoff of the risk of a complex labor situation with the need for security screening), and transfer of training procedure incompatibilities from one location to another (i.e., procedures vary considerably from one site to another, and staff rotate among these locationsša tradeoff of procedural variability with the human ability to adapt).hsi activities tend to be deployed in this program based on continuing assessment of risks associated with individual seaport deployments. for example, hsi operational studies of straddle carrier cargo operations were undertaken midway through seaport deployments, when it was recognized that existing technology solutions could not be adapted to that type of operation. the risk of using existing technology was that seaport operations would need to fundamentally changešthis would lead to an unacceptable humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 105impact on commerce. thus operational studies were undertaken to identify potential technology insertion opportunities that would minimize the risk of commercial impact.concurrent system denition and developmentthe rpm program involves substantial concurrent engineering activity. the initial deployments have utilized relatively lowcost, highsensitivity but lowresolution sensors made of polyvinyl toluene. these sensors are highly sensitive to radioactive material but tend to generate nuisance alarms because of low resolution of the type of radioactive material (naturally occurring versus threat material). while this yields high threat sensitivity, it is also nonspecic and creates a larger impact on commerce due to nuisance alarms and the need for secondary inspections.however, development of advanced spectroscopic portals (asps) that utilize highresolution sensors is taking place concurrently with the installation of lower resolution portals and will be deployed subsequently. these portals will be able to identify specic radioactive isotopes and will help to reduce nuisance alarms that create an adverse impact on commerce. concurrent human factors research concerning threatbased displays will be used for developing appropriate enduser displays for the new systems.ﬁnextgenerationﬂ intravenous infusion pumpthe nextgeneration infusion pump is a generalpurpose intravenous infusion pump (iv pump) designed primarily for hospital use with secondary, limitedfeature use by patients at home. the device is intended to deliver liquid medications, nutrients, blood, and other solutions at programmed ˚ow rates, volumes, and time intervals via intravenous and other routes to a patient. the marketed name is the symbiqž iv pump. the device will offer medication management features, including medication management safety software through a programmable drug library. the infuser will also have sufcient memory to support extensive tracking logs and the ability to communicate and integrate with hospital information systems. the infuser will be available as either a singlechannel pump or a dualchannel pump. the two congurations can be linked together to form a 3 or 4channel pump. the infuser includes a large touchscreen color display and can be powered by either a/c power or rechargeable batteries.to ensure that the infuser has an easytouse user interface, the development of the product was based on a usercentered design approach. as part of the usercentered design approach, the team involved potential users at each phase in the design cycle. during the rst phase, the team conducted interviews with potential users and stakeholders, including nurses, aneshumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.106 humansystem integration in system developmentthesiologists, doctors, managers, hospital administrators, and biomedical technicians to gather user requirements. the team also conducted early research in the form of contextual observations and interviews in different clinical settings in hospitals as a means to understand user work ˚ow involving infusion pumps. the information from these initial activities was used in the conceptual development phase of the nextgeneration infusion pump. iterative design and evaluation took place in the development of each feature. evaluations included interviews, usability testing in a laboratory setting, usability testing in a simulated patient environment, testing with lowdelity paper prototypes, and testing with highdelity computer simulation prototypes. computer simulations of the nal user interface of each feature were used in focus groups to verify features and to obtain additional user feedback on ease of use before the nal software coding began. in the nal phases of development, extensive usability testing in simulated patient environments was conducted to ensure design intent has been implemented and that ease of use and usability objectives were met. throughout the development process, iterative risk analysis, evaluation, and control were conducted in compliance with the federally regulated design control process (see figures 55 and 56).motivation behind the designthe primary motivation was to design a stateoftheart infusion pump that would be a breakthrough in terms of ease of use and improved patient safety. over recent decades, the quality of the user interface in many iv pump designs has fallen under scrutiny due to many human factorsœrelated issues, such as difculty in setting up and managing a pump™s interface through careful control and display interplay. in the past 20 years, the type, shape, and use of pumps have been, from outward appearances, very similar and not highly differentiated among the different medical device manufacturers. in fall 2002, hospira undertook a largescale effort to redesign the iv pump. their mission was to create a pump that was easier to set up, easier to manage, easier to oversee patient care, and easier to use safely to help the caregiver prevent medication delivery errors. there was a clear market need for a newgeneration iv pump. the institute of medicine in 2000 estimated 98,000 deaths a year in the united states due to medical errors (institute of medicine, 2000).the usercentered design process in the  context of the incremental commitment modelthe symbiqž iv pump followed a classic usercentered design process, with multiple iterations and decision gates that are typically part of the inhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 107figure 55 two channel iv pumps with left channel illuminated. photograph courtesy of hospira, inc.figure 56 iv tube management features. photographs courtesy of hospira, inc.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.108 humansystem integration in system developmentcremental commitment model of product development. risk management was a central theme in the development, both in terms of reducing project completion and cost risks and managing the risk of adverse events to patients connected to the device. many of the interim project deliverables, such as fully interactive simulations of graphical user interfaces (gui), were in the form of shared representations of the design, so that all development team members had the same understanding of the product requirements during the development cycle.following a classic human factors approach to device design, the nurse user was the primary in˚uence on the design of the interface and the design of the hardware. physicians and home patient users were also included in the user proles. hospira embarked on a multiphase, usercentered design program that included more than 10 user studies, indepth interviews, eld observations, and numerous design reviews, each aimed at meeting the user™s expectations and improving the intelligence of the pump software aimed at preventing medication errors.preliminary researchmuch preliminary work needed to be done in order to kick off this development. a wellknown management and marketing planning rm was hired to lead concept analysis in which the following areas were researched:ł comparison of the nextgeneration pump and major competitors, using traditional strengths/weaknesses/opportunities methodology, included the following features: œ physical specications œ pump capabilities, e.g., number of channels œ therapies œ programming options œ set features œ pressure capabilities œ management of air in line œ battery œ biomedical indicators œ alarmsł competitive advantages of the nextgeneration pump were identied in the following areas: œ bar code reading capability with ergonomic reading wand œ small size and light weighthumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 109 œ standalone functional channels (easier work ˚ow, ˚exible regarding number of pumping channels) œ extensive drug library (able to set hard and soft limits for the same drug for different proles of use) œ highlevel reliability œ clear mapping of screen and pumping channels œ vertical tubing orientation that is clear and simplean extensive competitive analysis was undertaken, against the ve largest market leaders. task ˚ows and feature lists and capabilities were created. a prioritization of the possible competitive advantage features and their development cost estimates was generated and analyzed.business risks were examined using different business case scenarios and different assumptions about design with input from the outside management consultants. engineering consultants assisted hospira with input on technical development issues and costs, including pump mechanisms, software platforms, and display alternatives.extensive market research was conducted as well to identify market windows, market segment analyses, pricing alternatives, hospital purchasing decision processes, and the in˚uence of outside clinical practice safety groups. key leaders in critical care were assembled in focus groups and individually to assess these marketing parameters. this process was repeated. key outcomes were put into the product concept plan and its marketing product description document. this document also captured current and future user work needs and the related environments.the concept team reached a decision gate with the concurrence of the management steering committee. the project plan and budget were approved and development began. again, business risks were assessed. this step is typical in an icm development approach.design decisionsa fundamental architecture decision was reached to have an integrated design with either one or two delivery channels in a single integrated unit. two or more integrated units could themselves be connected side by side in order to obtain up to four iv channel lines. this alternate was chosen over the competing concept of having modular pumping units that would interconnect and could be stacked onto one master unit to create multiple channels. the integrated master unit approach won out based on problems uncovered from the market research, such as a higher likelihood of lost modular units, inventory problems, and reduced battery life.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.110 humansystem integration in system developmentfeature needs and their rationalebased on the preliminary market research and on an analysis of medical device reports from the food and drug administration (fda) as well as complaints data from the hospira customer service organization, the marketing requirements document was completed and preliminary decisions were made to include the features described in this section. field studies and contextual inquiry were planned as followon research to verify the need for these features and to collect more detail on how they would be designed.types of programmable therapies. decisions were made to offer a set of complex therapies in addition to the traditional simple therapies usually offered by volumetric iv pumps. the traditional simple therapies wereł continuous delivery for a specied period of time (often called ml/hr delivery).ł weightbased dosing, which requires entering the patient™s weight and the ordered drug delivery rate.ł bolus delivery (delivery of a dose of medication over a relatively short period of time).ł piggyback delivery (the delivery type that requires channel a delivery suspension while channel b delivers and then its resumption when channel b completes).the more complex therapies includedł tapered therapy (ramping up and down of a medicine with a programmed timeline. it is sometimes used for delivery of nutritional and hydration ˚uids, called total parenteral nutrition).ł intermittent therapy (delivery of varying rates of medication at programmed time intervals).ł variable time delivery.ł multistep delivery.business risks were examined to understand the sales consequences of including these features of therapy types to address the issue of stakeholder satiscing.medication libraries with hard and soft dosage limits. research uncovered that several outside patient safety advocate agencies, including the emergency care research institute and the institute for safe medical practices were recommending only iv pumps with safety software consisting of upper and lower dosage limits for different drugs as a function of the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 111programmed clinical care area in a hospital. (clinical care areas include emergency room, intensive care unit, oncology, pediatrics, transplants, etc.) it became clear that it would have been imperative to have safety software in the form of medication libraries that were programmed by each hospital to have soft limits (which could be overridden by nurses with permission codes) and hard limits (that could under no circumstances be overridden). it was decided at this time that separate software applications would need to written that would be used by hospital pharmacy and safety committees to enter drugs in a library table with these soft and hard limits, which would vary by clinical care area in the hospital. this is an example of incremental growth and stakeholder commitment in the design process.large color touch screen. a human factors literature review was conducted to create a list of advantages and disadvantages of various input and display technologies. this research was supplemented with engineering data on the costs and reliabilities of these technologies. again, business risks were examined, including reliability of supply of various display vendors. after much research and debate, the list of choices was narrowed to three vendors of touchsensitive color lcd displays.this was a breakthrough, in the sense that no current onmarket iv pumps were using color touchscreen technology. a large 8.4inch diagonal color lcd display with resistive touchscreen input was selected for further testing. a resistive touchscreen was believed to reduce errors due to poor screen response to light nger touch forces.another issue that required some data from use environment analysis was the required angle of view and display brightness under various use scenarios. subsequent contextual inquiry data did verify the need for viewing angles of at least +/ 60 degrees horizontal viewing and +/ 30 degrees vertical viewing angles. the minimum brightness or luminance levels were veried at 35 candelas per square meter. a business risk analysis examined the tradeoffs between a large touchscreen display and the con˚icting customer desire for small footprint iv pumps. the larger display size of 8.4inch diagonal would allow larger onscreen buttons to minimize use errors due to inadvertent selection of adjacent onscreen buttons as well as allowing larger more readable onscreen text. again, human factors research literature and standards on display usability were included in these decisions.special alarms with melodies. fda medical device reports and customer complaint data reinforced the need for more effective visual and auditory alarms to alert iv pump users to pump fault conditions, such as air in line, occlusion in iv tubing, pending battery failure, iv bag nearly empty or unsafe dosage rates for a particular drug in a specic critical care area. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.112 humansystem integration in system developmentthe team also decided to adopt the recommendations of the international electrotechnical commission (iec) for an international standard for medical device auditory alarms to use unique melody patterns for iv pumps to distinguish these devices from other critical care devices, such as ventilators and vital sign patient monitors. these auditory alarms were later subjected to extensive lab and eld studies for effectiveness and acceptability.an early beta test in actual hospital settings with extended use subsequently showed user dissatisfaction with the harshness of some of the alarm melodies. the iec standard had purposely recommended a discordant set of tone melodies for the highest alarm level, but clinicians, patients, and their families complained that they were too harsh and irritating. some clinicians complained that they would not use these iv pumps at all, unless the alarms were modied. or worse, they would permanently disable the alarms, which would create a very risky use environment.this outcome highlights a wellknown dilemma for human factors: lab studies are imperfect predictors of user behavior and attitudes in a realworld, extendeduse setting. the previous lab usability studies were by their very nature shortduration exposures to these tones and showed that they were effective and alerting, but they did not capture longterm subjective preference ratings. a tone design specialist was engaged who redesigned the tones to be more acceptable, while still being alerting, attention grabbing, and still in compliance with the iec alarm standard for melodies. subsequent comparative usability evaluations (group demonstrations and interviews) demonstrated the acceptability of the redesigned melodies. this is a prime example of design iteration and concurrent system denition and development.semiautomatic cassette loading. another early decision involved choosing between a traditional manual loading of the cassette into the iv pump or a semiautomated system, in which a motor draws a compartment into the pumping mechanism, after the clinician initially places the cassette into the loading compartment. the cassette is in line with the iv tubing and iv bag containing the medication. the volumetric pumping action is done through mechanical ngers, which activate diaphragms in the plastic cassette mechanism. customer complaint history suggested the need for the semiautomated system to avoid use error in loading the cassette and to provide a failsafe mechanism to close off ˚ow in the iv line except when it was inserted properly into the iv pump.a major problem with earlier cassettebased volumetric iv pump systems was the problem of ﬁfree ˚ow,ﬂ in which medication could ˚ow uncontrolled into a patient due to gravitational forces, with the possibility of severe adverse events. early risk analysis and evaluation were done from both a business and useerror safety perspective to examine the benet of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 113the semiautomated loading mechanism. later usability testing and mechanical bench testing validated the decision to select the semiautomated loading feature.a related decision was to embed a unique ledbased lighting indication system into the cassette loading compartment that would signal with colored red, yellow, and green lights and steady versus ˚ashing conditions the state of the iv pump in general and specically of the cassette loading mechanism. the lights needed to be visible from at least 9 feet to indicate that the iv pump is running normally, pump is stopped, cassette is improperly loaded, cassette compartment drawer is in the process of activation, etc.special pole mounting hardware. again, data from the fda medical device reports and customer complaints indicated the need for innovative mechanisms for the mounting of the iv pump on poles. later contextual inquiry and eld shadowing exercises validated the need for special features allowing for the rapid connection and dismounting of the iv pump to the pole via quick release/activation mechanisms that employed ratchetlike slip clutches. subsequent ergonomicsfocused usability tests of hardware mechanisms validated the need and usability of these design innovations for mounting on both iv poles and special bedmounted poles, to accommodate iv pumps while a patient™s bed is being moved from one hospital department to another.risk analyses for business and safety risks were updated to include these design decisions. industrial design models were built to prototype these concepts, and these working prototypes were subjected to subsequent labbased usability testing. again, these actions are examples of stakeholder satiscing, incremental growth of system denition, and iterative system design.stacking requirements. given the earlier conceptual design decision to have an integrated iv pump rather than using addon pumping channel modules, decisions were needed on how integrated iv pumps could be stacked together to create additional channels. a concomitant decision was that the integrated iv pump would be offered with either one or two integrated channels. based on risk assessment, it was decided to allow sidebyside stacking to allow the creation of a 4channel system when desired. the 4channel system would be electronically integrated and allow the user interface to operate as one system. again, tradeoff analyses of risks were made against the competing customer need for a smaller device size footprint. a related design decision was to have an industrial design that allowed handles for easy transportation, but would also allow stable vertical stacking, while the units are stored between uses in the biomedihumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.114 humansystem integration in system developmentcal engineering department. market research clearly indicated the need for vertical stacking in crowded storage areas. to facilitate safe storage of the pumps, the special pole clamps were made removable.tubing management. a wellknown useerror problem of tangled and confusing iv tubing lines was addressed in the housing design by including several holders for storing excess tubing. notches were also included to keep tubes organized and straight to reduce linecrossing confusion. these same holders were built as slight protrusions that protected the touchscreen from damage and inadvertent touch activation, if the pump were to be laid on its side or brushed against other medical devices.many other preliminary design decisions were made in these early stages that were based on both business and useerror risk analysis. in all cases, these decisions were veried and validated with subsequent data from usability tests and from eld trials.design process detailsthe development of the symbiqž iv pump followed the acknowledged best practices iterative usercentered design process as described in medical device standards (ansi/aami he 74:2001, iec 6060116:2004, and fda human factors guidance for medical device design controls). the following sections are brief descriptions of what was done. table 52 outlines the use of these human factors techniques and some areas for methodology improvements.contextual inquirycontextual inquiry was done by multiple nurse shadowing visits to the most important clinical care areas in several representative hospitals. several team members spent approximately a halfday shadowing nurses using iv pumps and other medical devices and observing their behaviors and problems. a checklist was used to record behaviors and, as time permitted, ask about problem areas with iv pumps and features that needed attention during the design process. subsequent to the eld visits, oneonone interviews with nurses were conducted to explore in depth the contextual inquiry observations. these observations and interviews were used to generate the following elements:ł task analysesł use environment analysesł user proles analyseshumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 115figure 57 shows an example of one of many task ˚ow diagrams generated during the task analyses phases of the contextual inquiry.setting usability objectivesquantitative usability objectives were set based on data from the contextual inquiry, user interviews, and the previous market research. early useerror risk analysis highlighted tasks that were likely to have high risk, with particular attention to setting usability objectives to ensure that these user interface design mitigations were effective. experience with earlier iv pump designs and user performance in usability tests also in˚uenced the setting of these usability objectives. the objectives were primarily based on successful task performance measures and secondarily on user satisfaction measures. examples of usability objectives wereł 90 percent of experienced nurses would be able to insert the cassette the rst time while receiving minimal training; 99 percent would be able to correct any insertion errors.ł 90 percent of rsttime users with no training would be able to power the pump off when directed.ł 90 percent of experienced nurses would be able to clear an alarm within 1 minute as rsttime users with minimal training.ł 80 percent of patient users would rate the overall ease of use of the iv pump 3 or higher on a 5point scale of satisfaction with 5 being the highest value.early risk managementmany rounds of iterative risk analysis, risk evaluation, and risk control were initiated at the earliest stages of design. the riskmanagement process followed recognized standards in the area of medical device design (e.g., iso 14971:2000, see international organization for standardization, 2000a). the risk analysis process was documented in the form of a failure modes and effects analysis (fmea), which is described in more detail in chapter 8. table 53 presents excerpts from the early symbiqž fmea. business and project completion risks were frequently addressed at phase review and management review meetings.the concept of risk priority number (rpn) was used in the operation risk assessment for the symbiqž infusion system. rpn is the resulting product of multiplying fault probability times risk hazard severity times probability of detecting the fault. a maximum rpn value is typically 125, and decision rules require careful examination of mitigation when the rpn humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.116 humansystem integration in system developmenttable 52 methodology issues and research needshuman factors engineering process stepexplanationmethodology issuesdisadvantagesmethodological research needsuser prolesall major user categories were analyzed.are personas as descriptive of users as regular user proles? can we be sure that we have captured the majority of user proles?studies of design impacts of different ways to capture users and their proles.task analysisall signicant task ˚ows were analyzed.can we be sure that all signicant task ˚ows have been captured and have they been captured at the correct level of detail?studies of advantages and disadvantages of different approaches to task analysis, including cognitive task analysis and task modeling techniques.user environmentall signicant use environments were analyzed.can we be sure that all signicant use environments have been captured and have they been captured at the correct level of detail?studies to develop methods to understand limitations of current ethnographic methods for capturing information about use environments and ways to improve these methods.useerror risk analysisall tasks were analyzed and useerror probabilities were estimated, as were hazard severities and risk priority values. design mitigations were described.when data are not available, then subjective estimates must be made for useerror rate probabilities. group dynamics can bias the consensus ratings of hazard severity, fault likelihood, and mitigation effectiveness.validate estimation methods to reduce bias in consensus ratings, e.g., delphi techniques.research methods to improve error rate modeling.set and meet usability objectivesobjectives were set for all critical tasks using both task completion rate and satisfaction ratings.human performance usability objectives are usually limited to task completion rates and task times, supplemented by subjective measures of satisfaction.research better, more reliable, and valid outcome measurements and methods to make these measurements, e.g., fmri, eeg, or other neuro/physiological measures.prototyping and iterative designdesign was iterated many times over through a series of at least 12 usability test cycles.iteration takes time, even with rapid prototyping tools.develop better, quicker, more efcient methods and tools for rapid prototyping.usability testinga series of formative usability tests were conducted in both usabilitytesting labs and in the patient simulator. a nal summative usability test was completed.usability tests also take a lot of time and resources.it is difcult to select the optimal tasks to include in a usability study.can summative usability tests be done with fewer subjects and still be valid?research more efcient usability evaluation methods.create tools that allow easier selection of the most important and critical tasks to include in a test.investigate the use of alternative statistical analysis methods such as bayesian statistics to conduct summative usability tests.field studiesfield studies are planned for the postmarketing period. a clinical device study was conducted in two hospitals to obtain realworld usability and product effectiveness data.field studies have the advantage of giving realworld validation to labbased usability evaluations, but are time and resource intensive.research techniques that are more efcient in providing the kind of postmarket surveillance data that can be obtained from eld studies.note: eeg = electroencephalogram; fmri = functional magnetic resonance imaging.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 117table 52 methodology issues and research needshuman factors engineering process stepexplanationmethodology issuesdisadvantagesmethodological research needsuser prolesall major user categories were analyzed.are personas as descriptive of users as regular user proles? can we be sure that we have captured the majority of user proles?studies of design impacts of different ways to capture users and their proles.task analysisall signicant task ˚ows were analyzed.can we be sure that all signicant task ˚ows have been captured and have they been captured at the correct level of detail?studies of advantages and disadvantages of different approaches to task analysis, including cognitive task analysis and task modeling techniques.user environmentall signicant use environments were analyzed.can we be sure that all signicant use environments have been captured and have they been captured at the correct level of detail?studies to develop methods to understand limitations of current ethnographic methods for capturing information about use environments and ways to improve these methods.useerror risk analysisall tasks were analyzed and useerror probabilities were estimated, as were hazard severities and risk priority values. design mitigations were described.when data are not available, then subjective estimates must be made for useerror rate probabilities. group dynamics can bias the consensus ratings of hazard severity, fault likelihood, and mitigation effectiveness.validate estimation methods to reduce bias in consensus ratings, e.g., delphi techniques.research methods to improve error rate modeling.set and meet usability objectivesobjectives were set for all critical tasks using both task completion rate and satisfaction ratings.human performance usability objectives are usually limited to task completion rates and task times, supplemented by subjective measures of satisfaction.research better, more reliable, and valid outcome measurements and methods to make these measurements, e.g., fmri, eeg, or other neuro/physiological measures.prototyping and iterative designdesign was iterated many times over through a series of at least 12 usability test cycles.iteration takes time, even with rapid prototyping tools.develop better, quicker, more efcient methods and tools for rapid prototyping.usability testinga series of formative usability tests were conducted in both usabilitytesting labs and in the patient simulator. a nal summative usability test was completed.usability tests also take a lot of time and resources.it is difcult to select the optimal tasks to include in a usability study.can summative usability tests be done with fewer subjects and still be valid?research more efcient usability evaluation methods.create tools that allow easier selection of the most important and critical tasks to include in a test.investigate the use of alternative statistical analysis methods such as bayesian statistics to conduct summative usability tests.field studiesfield studies are planned for the postmarketing period. a clinical device study was conducted in two hospitals to obtain realworld usability and product effectiveness data.field studies have the advantage of giving realworld validation to labbased usability evaluations, but are time and resource intensive.research techniques that are more efcient in providing the kind of postmarket surveillance data that can be obtained from eld studies.note: eeg = electroencephalogram; fmri = functional magnetic resonance imaging.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.118 humansystem integration in system developmentfluid onlyselected orselect fluid onlyrateandvolumeknown?rate andtime knownselect rateselect volumeenter digitsand pressselectenter digitsand pressselectenter digitsand pressselectenter digitsand pressselectenter digitsand pressselectenter digitsand pressselectselect rateselect volumevolumeandtimeknown?select timeselect timepress nextverify programpress startprogram ﬁaﬂ57figure 57 illustrative task ˚ow diagram from the task analysis.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 119values exceed a value of 45. rpn values between 8 and 45 require an explanation or justication of how the risk is controlled.the product requirements document (pdr) was formally created at this point to describe the details of the product design. it was considered a draft for revision as testing and other data became available. it was based on the customer needs expressed in the marketing requirements document. this document recorded the incremental growth of system denitions and stakeholder commitment and served as a shared representation of the design requirements for the development team.prototypesmany prototypes and simulations were created for evaluation:ł hardware models and alternatives considered œ hardware industrial design mockups œ early usability tests of hardware mockups.ł paper prototypes for graphical user interfaces with wireframes consisting of basic shapes, such as boxes and buttons without nished detail graphic elements.ł gui simulations using flashž animations.1ł early usability tests with hardware mockups and embedded software that delivered the flashž animations to a touchscreen interface that was integrated into the hardware case.ł flash animations are excellent examples of shared representations because they were directly used in the product requirements document to specify to software engineering exactly how the gui was to be developed. all team discussions regarding gui design were focused exclusively on the flash animation shared representations of the symbiqž user interface.integrated hardware and software models with integrated usability testsas noted earlier, the usability tests performed later in the development cycle were done with integrated hardware mockups and software simulations. usability test tasks were driven by tasks with highrisk index values in the risk analysis, specically the fmea. tasks were also included that had formal usability objectives associated with them. although the majority of usability test tasks were focused on the interaction with the touchscreen1 flash refers to both a multimedia authoring program and the macromedia flash player, written and distributed by macromedia, which utilizes vector and bitmap graphics, sound and program code, and directional streaming video and audio.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.120 humansystem integration in system developmenttable 53 excerpts from symbiqž failure modes and effects analysis (fmea)taskhazarduse error (fault)fault probabilityrisk hazard severitymethod of controldetect/mitigate riskoutcome (residual risk)referenceenter concentration for those drugs in library with / concentration.patient receives overdelivery of ordered drug.incorrect concentration entered for drug and conrmed.25the completed program screen shows the drug selected. when start is pressed on a program screen, a second screen (conrmation screen) appears with the programmed values on the screen view looking slightly different. a query is displayed and user must select yes or no. if yes selected infusion begins. if no selected, user is returned to program screen and has opportunity to correct the concentration before beginning delivery.after delivery is initiated, the user can view the entered concentration and correct if necessary by returning to the programming screen (by selecting the appropriate line a or b). the user manual provides instructions.trailing zeros have been eliminated for whole numbers, e.g., 50.0 will be 50.110study report for user study protocol #0303 version 3 revealed the experienced users read the conrmation screen and discovered and corrected any mistakes.soft limit override.patient receives underdelivery of ordered drug.soft limit unintentionally overridden and conrmed.24when a value entered is not within specied rule sets, a warning appears and the override soft limits icon appears. the warning indicates the value that is outside the rule sets and the clinician must conrm override, yes or no? if yes is chosen, the conrmation screen appears with the override icon. query is displayed and user must select yes or no. if yes selected, infusion begins and override icon remains on screen during infusion. if no selected, user remains on the program screen and has opportunity to correct. the warning icon remains visible. 18study report for user study protocol #0303 version 3 revealed the experienced users questioned the messages before overriding.based graphical user interface, critical pumphandling tasks were included as well, such as iv pump mounting and dismounting on typical iv poles.tests of alarm criticality and alertingthe initial alarm formative usability studies, described earlier, had the goal of selecting alarms that would be alerting, attention getting, and properly convey alarm priority, as well as communicating appropriate actions. these formative studies evaluated the subject™s abilities to identify and dishumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 121table 53 excerpts from symbiqž failure modes and effects analysis (fmea)taskhazarduse error (fault)fault probabilityrisk hazard severitymethod of controldetect/mitigate riskoutcome (residual risk)referenceenter concentration for those drugs in library with / concentration.patient receives overdelivery of ordered drug.incorrect concentration entered for drug and conrmed.25the completed program screen shows the drug selected. when start is pressed on a program screen, a second screen (conrmation screen) appears with the programmed values on the screen view looking slightly different. a query is displayed and user must select yes or no. if yes selected infusion begins. if no selected, user is returned to program screen and has opportunity to correct the concentration before beginning delivery.after delivery is initiated, the user can view the entered concentration and correct if necessary by returning to the programming screen (by selecting the appropriate line a or b). the user manual provides instructions.trailing zeros have been eliminated for whole numbers, e.g., 50.0 will be 50.110study report for user study protocol #0303 version 3 revealed the experienced users read the conrmation screen and discovered and corrected any mistakes.soft limit override.patient receives underdelivery of ordered drug.soft limit unintentionally overridden and conrmed.24when a value entered is not within specied rule sets, a warning appears and the override soft limits icon appears. the warning indicates the value that is outside the rule sets and the clinician must conrm override, yes or no? if yes is chosen, the conrmation screen appears with the override icon. query is displayed and user must select yes or no. if yes selected, infusion begins and override icon remains on screen during infusion. if no selected, user remains on the program screen and has opportunity to correct. the warning icon remains visible. 18study report for user study protocol #0303 version 3 revealed the experienced users questioned the messages before overriding.criminate among different visual alarm dimensions, including colors, ˚ash rates, and text size and contrast. for auditory alarms, subjects were tested on their ability to discriminate among various tones with and without melodies and among various cadences and tone sequences for priority levels and detectability. subjects were asked to rate the candidate tones relative to a standard tone, which was given a value of 100. the standard was the alternating highlow europeanstyle police siren. subjective measures were also gathered on the tones using the pad rating system, standing for perceived tone pleasure, arousal, and dominance, as well as perceived criticality. data humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.122 humansystem integration in system developmentfrom these studies enabled the team to make further incremental decisions on system denitions for both visual and auditory alarms and alerts.tests of display readabilityanother set of early formative usability tests was conducted to validate the selection of the particular lcd touchscreen for readability and legibility. during the evaluation it was determined that the screen angle (75 degrees) and overall curvature were acceptable. the screen could be read in all tested light conditions at a 15foot viewing distance.iterative usability testsas noted, a series of 10 usability studies were conducted iteratively as the design progressed from early wireframes to the completed user interface with all the major features implemented in a working iv pump. in one of the intermediate formative usability tests, a patient simulator facility was used at a major teaching hospital. users performed a variety of critical tasks in a simulated room in an intensive care unit, in which other medical devices interacted and produced noises and other distractions. the prototype iv pump delivered ˚uid to a mannequin connected to a patient monitor that included all vital signs. as the pump was programmed and subsequently changed (e.g., doses titrated), the softwarecontrolled patient mannequin would respond accordingly. the patient simulator also introduced ringing telephones and other realistic conditions during the usability test. this test environment helped in proving the usability of visual alarms and tones, as well as the understandability and readability of the visual displays. final summative usability tests demonstrated that the usability objectives for the pump were achieved.focus groupsfocus groups of nurses were also used as part of the usability evaluation process. these were used to complement the taskbased usability tests. many of the focus groups had a task performance component. typically the participants would perform some tasks with new and old versions of design changes, such as time entry widgets on the touchscreen, and then convene to discuss and rate their experiences. this allowed a behavioral component and addressed one of the major shortcomings of typical focus groups, that they focus only on opinions and attitudes and not behaviors.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 123field studiesfield studies in the form of medical device studies have also been incorporated in the design process. thoroughly benchtested and working beta versions of the iv pump were deployed in two hospital settings. the hospitals programmed drug libraries for at least two clinical care areas. the devices were used for about 4 weeks. surveys and interviews were conducted with the users to capture their realworld experiences with the pump. data from the pump usage and interaction memory were also analyzed and compared with original doctor™s orders. this study revealed a number of opportunities to make improvements, including the problem with the perceived annoyance of the alarm melodies and the data entry methods for entering units of medication delivery time (e.g., hours or minutes).instructions for use development and testingusability testing was also conducted on one of the sets of abbreviated instructions called tips cards. these cards serve as reminders for how to complete the most critical tasks. these usability studies involved 15 experienced nurses with minimal instructions performing 9 tasks with the requirement that they read and use the tips cards. numerous suggestions for improvement in the tips cards themselves as well as the user interface came from this work, including how to reset the airinline alarm and how to address the alarm and check all onscreen help text for accuracy.validation usability teststwo rounds of summative usability testing were conducted, again with experienced nurses performing critical tasks identied during the task analysis, including those with higher risk values in the risk analysis. the tasks were selected to simulate situations that the nurses may encounter while using the iv pump in a hospital setting. the tasks included selecting a clinical care area, programming simple deliveries, adding more volume at the end of an infusion, setting a ﬁnear end of infusionﬂ alarm, titration, dose calculations, piggyback deliveries, intermittent deliveries, using standby, programming a lock, adjusting the alarm volume, and responding to messages regarding alarms.usability objectives were used as acceptance criteria for the summative validation usability tests. the study objectives were met. the calculated task completion accuracy was 99.66 percent for all tasks for rsttime nurse users with minimal training. the null hypothesis that 80 percent of the participants would rate the usability 3 or higher on a 5point scale in the overall categories was met. there were a few minor usability problems humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.124 humansystem integration in system developmentuncovered that were subsequently xed without major changes to the user interface or that affected critical safetyrelated tasks.federal regulations on product design controls require that a product™s user interface be validated with the nal working product in a simulated work environment. in this instance, the working product was used in a laboratory test, but without having the device connected to an actual patient. bench testing is also a part of validation to ensure that all mechanical and electrical specications and requirements have been met.revised risk analysisas part of the incremental commitment model, the risk analysis was iterated and revised as the product development matured. fmeas were updated for three product areas, which were safetycritical risks associated with the user interface, the mechanical and electrical subsystems, and the product manufacturing process. explicit analysis of the business risks and the costs of continued nancial commitment to the funding of development were also incremented and reviewed at various management and phase reviews.product introductionproduct introduction planning included data collection from initial users to better understand remaining usage issues that can be uncovered only during prolonged usage in realistic clinical conditions. the many cycles of laboratorybased usability testing typically are never detailed enough or long enough to uncover all usability problems. the plan is to use the company complaint handling and resolution process (e.g., corrective action and preventive action) to address use issues if they arise after product introduction.lifecycle planningthe product was developed as a platform for the next generation of infusion pump products. as such, there will be continued business risk assessment during the life cycle of this rst product on the new platform as well as on subsequent products and feature extensions.summary of design issues and methods usedthis infusion pump incorporated the best practices of usercentered design in order to address the serious user interface deciencies of previous infusion pumps. the development process took excellent advantage of the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.case studies 125detailed amount of data that is derived from an integrated hsi approach and used it to improve and optimize the safety and usability of the design. because of these efforts, the symbiqž iv pump won the 2006 human factors and ergonomics society award for best new product design from the product design technical group.this case study also illustrates and incorporates the central themes of this report:1. humansystem integration must be an integral part of systems engineering.2. begin hsi contributions to development early and continue them throughout the development life cycle.3. adopt a riskdriven approach to determining needs for hsi activity (multiple applications of risk management to both business and safety risks).4. tailor methods to time and budget constraints (scalability).5. ensure communication among stakeholders of hsi outputs (shared representations).6. design to accommodate changing conditions and requirements in the workplace (the use of iterative design and the incremental commitment model).this case study also demonstrates the ve key principles that are integral parts of the incremental commitment model of development: (1) stakeholder satiscing, (2) incremental growth of system denition and stakeholder commitment, (3) iterative system development, (4) concurrent system denition and development, and (5) risk managementšriskdriven activity levels.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.part iihumansystem integration methods in system development127humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.the chapters in part ii provide overviews of stateoftheart methods of humansystem integration (hsi) that can be used to inform and guide the design of personmachine systems using the incremental commitment model approach to system development. we have dened three general classes of methods that provide robust representation of multiple hsi concerns and are applicable at varying levels of effort throughout the development life cycle. these broad classes include methods toł dene context of use. methods for analyses that attempt to characterize early opportunities, early requirement and the context of use, including characteristics of users, their tasks, and the broader physical and organizational environment in which they operate, so as to build systems that will effectively meet users™ needs and will function smoothly in the broader physical and organizational context.ł dene requirements and design solutions. methods to identify requirements and design alternatives to meet the requirements revealed by prior upfront analysis.ł evaluate. methods to evaluate the adequacy of proposed design solutions and propel further design innovation.figure ii1 presents a representative sampling of methods that fall into each activity category and the shared representations that are generated by these methods. a number of points are highlighted in the gure:ł the importance of involving domain practitionersšthe individuals who will be using the system to achieve their goals in the target domainšas active partners throughout the design process.ł the importance of involving multidisciplinary design experts and other stakeholders to ensure that multiple perspectives are considered throughout the system design and evaluation process and that stakeholder commitment is achieved at each step.ł the availability of a broad range of methods in each class of activity. appropriate methods can be selected and tailored to meet the specic needs and scope of the system development project.ł the range of shared representations that can be generated as output of each of four hsi activities. these representations provide shared views that can be inspected and evaluated by the system stakeholders, including domain practitioners, who will be the target users of the system. the shared representations serve as evidence that can be used to inform riskdriven decision points in the incremental commitment development process.we realize that the classication of methods for discussion in the three chapters that follow is to some extent arbitrary, as many of the methods humansystem integration methods in system development 129humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.130 humansystem integration in system developmentfigure ii1 hsi activities, participants, methods, and shared representations. organizational and environmental context analysis field observations and ethnography task analysis cognitive task analysis participatory analysis contextual inquiry event data analysisł organization chartsł i/o system diagramsł role networks ł cultural profiles and modelsł futures tablesł opportunity maps ł profiles ł scenariosł mockups and prototypesł task description tablesł hierarchical network representationsł timeline representationsł task flow diagrams ł executable simulations and modelsł concept mapsł goaldecomposition representationsł stories, storyboard, narratives, and use casesł flow models ł sequence diagrams ł physical modelsł the products of multidimensional scaling and pathfinder network scaling usability requirements work domain analysis workload assessment participatory design contextual design physical ergonomics situation awareness methods for analyzing and mitigating fatigue prototyping scenarios personas models and simulation risk analysis usability evaluation methods sample shared representationsproducedrepresentativeset of methodswho™s involved?design experts and other stakeholdersdomain practitionershsi activitiesdefining opportunitiesand context of usedefining requirementsand designevaluationhsi activities, participants, methods, and shared representationsł graphic representations of domain goals, means, and constraintsł network representationsł concept mapsł graphs of workload as a function of time or task progressł pert chartsł gantt chartsł stories, storyboards, narratives, and use casesł theatrical methodsł workshop outcomes ł formal requirements and specificationsł vision statementsł descriptions of current or future enduser work environmentsł physiological test results ł subjective ratingsł checklists and rating scalesł human digital modelingł sa test results ł alertness models ł failure modes and effects analyses (fmea)ł fault tree analyses (fta) and other technique variationsł lists of usability problems in the form of: written reports, presentations, or videosł time and accuracy of user™s performance  user satisfaction ratings surveys/questionnaires experiment design interviews statistics performance measurement111revised 2/30/07are applied at several points in the system design process and thus logically could be presented in more than one chapter. the assignment of methods to classes and chapters is based on how the methods are most frequently used and where in the design process they make the greatest contribution. as already noted, the presentation of methods is not exhaustive. we have selected representative methods in each class, as well as some less well known methods that have been used primarily in the private sector and that we think have applicability to military systems as well. chapter 1 provides other sources of methods.the committee further recognizes that many of the methods described (e.g., event data analysis methods, user evaluation studies) build on foundational methods derived from the behavioral sciences (e.g., experimental design methodology, survey design methods, psychological scaling techniques, statistics, qualitative research methods). these foundational methods are humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.not explicitly covered in this report because they are well understood in the eld, and textbooks that cover the topics are widely available (e.g., charlton and o™brien, 2002; cook and campbell, 1979; coolican, 2004; fowler, 2002; yin, 2003). however, two categories of foundational methods that are not explicitly covered but deserve some discussion are brie˚y described below. both of these method categoriesšfunction allocation and performance measurementšare integral to the application of other methods throughout the design process.function allocation is the assignment of functions to specic software or hardware modules or to human operators or users. in the case of hardware and software, it is a decision about which functions are sufciently similar in software requirements or interfunction communication to collect together for implementation. in the case of assignment to human users versus software/hardware, it is a matter of evaluating the performance capacities and limitations of the users, the constraints imposed by the software and hardware, and the system requirements that imply users because of safety or policy implications. everyone agrees that function allocation is, at the base level, a creative aspect of the overall design process. everyone agrees that it requires hypothesis generation, evaluation and iteration. in our view, it spans the range of activities that are represented by the methodologies we are describing and does not, by itself, have particular methodologies associated with it. there have been attempts to systematize the process of achieving function allocation (price, 1985), but in our view they encompass the several parts of the design process that we are discussing in this section and do not add new substantive information. readers interested in the topic itself are referred to price (1985) and a special issue on collaboration, cooperation, and con˚ict in dialogue systems of the international journal of humancomputer studies (2000).performance measurement supports just about every methodology that is applied to humansystem integration. stakeholders are interested in the quality of performance of the systems under development, and they would like to have predictions of performance before the system is built. while they may be most interested in overall system performancešoutput per unit time, mean time to failure, probability of successful operation or mission, etc.šduring the development itself, there is a need for intermediate measures of the performance of individual elements of the system as well, because diagnosis of the cause of faulty system performance requires more analytic measures at lower functional levels. from a systems engineering point of view, one may consider systemsubsystemmodule as the analysis breakdown; however, when one is concerned with humansystem integration, the focus is on goaltasksubtask as the relevant decomposition of performance, because it is in terms of task performance that measures specically of human performance are most meaningful and relevant.humansystem integration methods in system development 131humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.132 humansystem integration in system developmenttable ii1 types of performance measurestypes of performance measurespotential usesa.  integrated system performance measuresł output per unit timeł mean time to failureł probability of successful operation or missionł is the overall design and implementation successful?b.  system state variablesthe values of parameters re˚ecting the various states of the system as a function of timeł is the system being controlled appropriately, either by automation or by human controllers?ł are safety boundaries being exceeded?c.  human performanceł response timeł percent correct/probability of errorł time to learn/relearnł measures of remembering œ recognition œ free recallł is the system design producing the desired human performance?ł is training effective/efcient?ł is the system requiring unnecessary workload or memory load?d.  industrial engineering measuresł activity analysisšmeasures re˚ecting the allocation of time to different tasksł time and motion studyšmeasures describing in detail the literal time taken for each sequential step in a processł what are the equipment duty cycles?ł how are the users distributing their time?ł what are the most challenging tasks?e.  measures derived from human physiologył electroencephalographic records œ continuous wave analysis œ evoked potentialsł electroocular response œ eye movement tracking œ eye blink response œ pupil sizeł cardiovascular measures œ heart rate/heart rate variabilitył metabolic levelsł how is attention being allocated?ł what information is being sought?ł how attention absorbing is the task?ł how stressful is the task?ł what is the workload?f.  subjective measuresł judges/expert ratingsł questionnaire datał interview/protocol analysisł what are experts™ opinions of user/system performance?ł do the users like the design?ł how hard are the users working?ł do the users have situation awareness?ł are the users stressed?humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.table ii1 contains some examples of the kinds of measures that are likely to be of interest.since each situation is different, the analyst must consider the context of use under which measurement or prediction is to be undertaken, the goals of the measurement, the characteristics of the users who will be tested or about whom performance will be inferred, and the level of detail of analysis required in order to select specic measures to be used.types of performance measurespotential usesg.  team measuresł time to complete team taskł accuracy/quality of team performanceł judges/expert ratings of team effectivenessł team process measures of specic behaviorsł cognitive measures of knowledge sharing and team situation awarenessł are levels of team performance acceptable?ł how do different design decisions affect team performance?ł what aspects of team performance are most critical?table ii1 continuedhumansystem integration methods in system development 133humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.6dening opportunities and context of usein the past when new technologies were introduced, the focus was on what new capabilities the technology might bring to the situation. people then had to nd ways to cope with integrating their actions across often disparate systems. over time, as computational capability has increased and become more ˚exible, one has seen a shift in focus toward understanding what people need in given situations and then nding ways for technology to support their activities. in other words, people no longer need to adapt to the technologyšthe technology can be designed to do what people and the situation demand. the challenge is to understand human needs in dynamic contexts and respond with solutions that leverage the best of what technology has to offer and at the same time resonate with people™s natural abilities. the emphasis and risks have switched from the technology to the users.this chapter introduces a range of methods that can be used to gain an understanding of users, their needs and goals, and the broader context in which they operate. the methods provide a rich tool box to support two of the major classes of humansystem integration (hsi) activities that feed into the incremental commitment model (icm): dening opportunities and requirements and dening context of use. they include methods that focus on the capabilities, tasks, and activities of users (e.g., task analysis methods that characterize the tasks to be performed and their sequential ˚ow, cognitive task analysis methods that dene the knowledge and mental strategies that underlie task performance), as well as methods that examine the broader physical, social, and organizational context in which individu135humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.136 humansystem integration in system developmentals operate (e.g., eld observations and ethnography, contextual inquiry, analysis of organizational and environmental context).the chapter covers a variety of complementary approaches, ranging from participatory analysis methods, which include domain practitioners as active partners, to event data analysis methods, which promise the potential of more automated and less obtrusive ways of uncovering user activities and needs. the chapter also covers methods for capturing and communicating knowledge about users and the context of use in the form of compelling shared representations, including storyboards, scenarios, role networks, and input/output system diagrams. figure 61 provides an overview. each method is discussed in terms of use, shared representations, contribution to the system development process, and strengths and limitations.the extent to which system requirements can be dened at the beginning of a project varies. when requirements are poorly dened, there may be unanticipated opportunities for new features or new applications of the system. typically, there are more opportunities than resources to respond to them. it is therefore prudent to dene the space of opportunities and then to evaluate those opportunities and choose the most promising ones.in order to build systems that can support users and their tasks effectively, it is important to understand the broader context of use. this strategy can be particularly important if the system needs are poorly understood, or if a new system is to be designed and deployed into a domain in which there is no predecessor system. in these cases, it is easy to engage in a rush to judgmentšthat is, to design and deploy a system based on assumptions, rather than on the actual opportunities that old assumptions may not reveal. however, even for systems that will occupy a known niche, it is important to understand the context of use, because eld conditions and work practices change, and old solutions may no longer t the current realities.as illustrated in figure 62, the context of use includes understanding the characteristics of the users, their motivations, goals, and strategies; the activities and tasks they perform and the range and complexity of situations that arise and need to be supported; the patterns of formal and informal communication and collaboration that occur and contribute to effective performance; and the broader physical, technical, organizational, and political environment in which the system will be integrated. understanding the context of use is especially important as one moves toward more complex systems and systems of systems.context of use analysis methods are particularly important during the exploration phase of the incremental commitment model, when the focus is on understanding needs and envisioning opportunities. among the promised benets of leveraging context of use analyses to inform design are systems that are more likely to be successful when deployed because they humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 137 organizational and environmental context analysis field observations and ethnography task analysis cognitive task analysis participatory analysis contextual inquiry event data analysisł organization chartsł i/o system diagramsł role networks ł cultural profiles and modelsł futures tablesł opportunity maps ł profiles ł scenariosł mockups and prototypesł task description tablesł hierarchical network representationsł timeline representationsł task flow diagrams ł executable simulations and modelsł concept mapsł goaldecomposition representationsł stories, storyboard, narratives, and use casesł flow models ł sequence diagrams ł physical modelsł the products of multidimensional scaling and pathfinder network scalingsample shared representationsproducedrepresentativeset of methodswho™s involved?design experts and other stakeholdersdomain practitionershsi activitiesdefining opportunitiesand context of usedefining requirementsand designevaluationhsi activities, participants, methods, and shared representations61figure 61 representative set of methods and sample shared representations for dening opportunities and context of use.address the specic problems facing users and are sensitive to the larger system context. experience has shown that introduction of new technology does not necessarily guarantee improved humanmachine system performance (woods and dekker, 2000; kleiner, drury, and palepu, 1998) or the fulllment of human needs (muller et al., 1997b; nardi, 1996; national research council, 1997; rosson and carroll, 2002; shneiderman, 2002). poor use of technology can result in systems that are difcult to learn or use, can create additional workload for system users, or, in the extreme, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.138 humansystem integration in system developmentusers š goals, knowledge, skills,strategies, and motives.task situation š activities, tasks,range of situations and complexities.social and organizational structure šphysical and technicalenvironment šphysical and technicalcharacteristics andconstraints.formal and informal communication,social/organization/economic/cultural/political goalsand constraints.62figure 62 context of use encompasses consideration of the user, the task situation, the social and organizational structure within which activities take place, as well as the physical and technical environment that collectively provide opportunities and impose constraints on performance.can result in systems that are more likely to lead to catastrophic errors (e.g., confusion that leads to pilot error and fatal aircraft accidents).context of use analysis methods can play an important role in mitigating the risks of these types of design failures by promoting a more complete understanding of needs and design challenges as part of the incremental commitment model. this more complete understanding can help avoid common design pitfalls, such as local optimizations, in which a focus on improving a single aspect of a system in isolation inadvertently results in degradation of the overall system because of unanticipated side effects. it can also help manage ﬁfeature creepﬂ (the proliferation of too many disjointed features in a single release) by integrating new ideas into a few, powerful innovations. thus, an important benet of investing in context of use analysis is a reduction in risk exposure by reducing the risk that the design will fail to meet the user™s needs and thus not be adopted, as well as by reducing the risk that a design will be put in place that contributes to performance problems with costly economic or safety implications. while we have focused on the value of context of use analyses during the early exploratory phases of the incremental commitment model, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 139these methods continue to be relevant throughout the system development process, up to and including when systems are elded. the context of use is constantly evolving, and introduction of new technology can produce operational and organizational changes, not all of which will have been anticipated ahead of time (woods and dekker, 2002; patterson, cook, and render, 2002; roth et al., in press). for example, as part of a recent power plant control room upgrade, computerized procedures were developed that integrated plant parameter information with the procedures so that the lead operator could work through the procedures without having to ask others for plant state information. this had the (anticipated) consequence of improving the lead operator™s situation awareness of plant state and the speed with which the procedures could be executed. however, it decreased the situation awareness of the other crew members (an unanticipated negative consequence) because the lead operator no longer needed to keep them as tightly in the loop. this was discovered during observational studies (o™hara and roth, 2005) conducted as part of the initial system introduction. as a consequence, crew operating philosophy and training were completely redened so as to capitalize on the crew members™ freedup mental resources (they could now provide an independent and diverse check on plant state), resulting in improved shared situation awareness of the entire team.this example highlights the importance of continuing to monitor the context of use up to and beyond system introduction to establish that the intended benets of new technologies are realized and that unintended side effects (e.g., new forms of error, new vulnerabilities to risk) are identied and mitigated. analyses of context of use can be used to guide midcourse design corrections, as well as to lay the groundwork for nextgeneration system development.organizational and environmental contextoverviewa guiding tenet of workcentered design approaches in humansystem integration is that an understanding of the characteristics of the users, including their motivations, goals, and strategies and the context of work, should be central drivers for the specication of the entire system design and not just the user interface. the advantage of a wholesystems approach is the recognition that an organization is, in itself, a system and some organizational designs can better support the organization™s mission and vision (lytle, 1998) than others. some contextoriented questions that drive design in a humancentered systems engineering approach includehumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.140 humansystem integration in system developmentł who are the stakeholders, or interested parties, in the system?ł how can the voices of all of the stakeholders be heard?ł how can con˚icts among stakeholders™ needs be resolved?ł what are the goals and constraints in the application domain?ł what social and interactive patterns occur in the domain of practice?ł what is the broader organizational/sociopolitical context in which the work is placed?the success of humansystem design and integration is to a large extent dependent on the appropriate consideration of organizational, macroergonomic, and sociotechnical factors in a systemofsystems perspective. macroergonomics, a subdiscipline of ergonomics, promotes an analysis of work systems at the level of subsystems or contributing factors (i.e., personnel, technological, organizational, environmental, and cultural and their interactions) before pursuing traditional microergonomics intervention. at the same time, success also depends on a continual focus on the needs of each stakeholder, as well as an openness to balance and rebalance the design and implementation tradeoffs between or among stakeholder needs. in complex designs with many stakeholders, there may in fact be no global optimization, but rather a series of tradeoffs that result in a system that delivers some value to each stakeholder group. it is also important to remember that, whereas requirements may become xed, application domains seldom remain stable. as a result, any optimization scheme may turn out to be shortlived, because the conditions that were considered in crafting the optimization may themselves change.here, we focus on a brief introduction to analyzing the enterprise and the environment as relevant contexts for system development, using the sociotechnical systems perspective and focusing on four general methods with associated sources of data and shared representations (table 61). as adapted from sociotechnical systems theory, a guiding assumption is that to evaluate factors in the environment or organization, variances between what is observed and what is desired can be identied by the analyst and should be minimized (emery and trist, 1978) by those responsible for operational or process improvement. a variance then is an unexpected or unwanted deviation from a standard operating condition, specication, or norm (emery and trist, 1978).key variances potentially signicantly impact system performance criteria, or interact with several other variances, or both. performance is broadly dened to include technical performance (e.g., efciency, productivity) as well as social performance (e.g., safety, satisfaction). typically, 1020 percent of variances are considered key variances. the notion is not dissimilar from the notion of special and common causes of variance in quality ashumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 141table 61 organizational and environmental methods and respective sources of data and shared representationsgeneral methodsource of data (input)shared representation (output)organizational system scanauthority and communication analysismission, vision, principle analysisinput/output analysisorganization chartstable of gaps (variances)input/output system modelrole analysisgapfocused survey, focus groups, and/or interviewsrole networkcultural analysisculture surveycultural prolestakeholder analysisgapfocused survey, focus groups, and/or interviewsfutures tablesurance. special causes are the outliers (in a statistical sense) that should be managed rst, in order to place the system in control. once outliers are managed, common or system causes of variance can be reduced to improve overall system performance.shared representationsthe main purpose of this section is to make and illustrate the point that understanding and to some extent evaluating organizational context are useful endeavors. the shared representations presented have been selected for their potential appreciation by a wide and diverse audience and are the shared representations that map to a sociotechnical systems approach to organizational context.organization charts: a widely known but often incorrectly or underused representation is the organizational chart, which depicts lines of authority and communication in an organization. in theory, formal, informal, and normative depictions of an organization™s lines of authority and communication can be developed. the formal structure is the published chart. the informal chart is a representation of the actual lines of authority and communication in the organization and relates to the informal organization. the normative structure is the theoretical best structure, given a number of considerations.regarding communication processes, various theories have been proposed to explain the emergence, maintenance, and dissolution of communication networks in organizational research (monge and contractor, 1999). although a detailed presentation is beyond the scope of this report, these theories consist of selfinterest (social capital theory and transaction cost economics); mutual selfinterest and collective action; exchange and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.142 humansystem integration in system developmentdependency theories (social exchange, resource dependency, and network organizational forms); contagion theories, (social information processing, social cognitive theory, institutional theory, structural theory of action); cognitive theories (semantic networks, knowledge structures, cognitive social structures, cognitive consistency); theories of homophily (social comparison theory, social identity theory); theories of proximity (physical and electronic propinquity); uncertainty reduction and contingency theories; social support theories; and evolutionary theories. regarding a theoretical ﬁbestﬂ structure, practically, the state of the art is to choose among a set of alternative types, each with its own strengths and weaknesses. these general types and their associated strengths and weaknesses are discussed below.table of organizational variances: mission, vision, and principles represent the identity of an organization. mission is the purpose of the organization, vision is the envisioned future, and principles are the values or underlying virtues that guide organizational behavior. as the contextual environment for a system, the organization portrays the identity it professes through its published mission, vision, and principles statements, and it also has the actual identity represented by the perceptions of organizational members and other stakeholders or observers. thus, there is sometimes a difference between the organizations preferred and actual prole. a table can be constructed that highlights the gaps between the preferred and the actual mission, vision, and principles and can include action items or interventions that are designed to decrease the gaps.input/output system diagram: an alternative to the organization chart is the system diagram or map. a system diagram or map is a representation of the organization as an input output model. such depictions were popularized by deming (2000), starting with the restoration period following world war ii. rather than depicting who reports to whom, this representation illustrates what the organization does from a process perspective. in a focus group or through a survey, opportunities for improvement are identied. also, since systems operate as inputoutput transformers, depicting the organization in such terms provides an opportunity to illustrate where the technical system ts in the organizational context. finally, as described in kleiner (1997), performance criteria and metrics can be mapped to these systems.role network: a role network, based on a role analysis, is also a useful shared representation. a job within an organization is dened by the formal job description that is a contract or agreement between the individual and the organization. this is not the same as a work role within the system, which is comprised of the actual behaviors of a person occupying a position or job in relation to other people. these role behaviors result from actions and expectations of a number of people in a role set. a role set is comprised of people who are sending expectations and reinforcement to humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved. 143ntom b. coughlinproject managermark saundersdiscoveryprogrammanagerdr. andy f.chengproject scientist.  r.w. farquharmissionmanagerbetsy beyerprogram/projectmanager fornearandy santolead systemengineer subsystemlead engineerseros asteroidscientificcommunity omissionoperation leadengineers r.e. goldpayloadmanagerinstrumentationlead engineers apl scienceteam congressnasaaplooooutsidevendors a,i,c,vv,g,av,i,g,a,lv,i,g,a,lv,m,tv,i,g,a,le,l,g,a,i,dkeyv š verticale š equalc š cross departmento š outsiden š nonhumang š goal of variance controla š attend to environmenti š interpersonal longterm developmentt š training supportm š mechanized supportnasa science teamv,i,g,a,lv,i,g,a,lv,i,g,a,lv,g,av,g,alandscape view fig 63l šfigure 63 role network for national aeronautics and space administration (nasa™s) near earth asteroid rendezvous project.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.144 humansystem integration in system developmentthe role occupant. figure 63 is an example of a role network for the near earth asteroid rendezvous (near), a project managed by the applied physics lab for nasa.cultural prole: shared representations related to culture include organizational culture and climate assessment tools. these typically take the form of the results produced by survey instruments. schein (1993) describes culture at three levels: the artifacts (what is visible), espoused values (attributes that guide behavior), and basic underlying assumptions (deeply held beliefs).futures table: an environmental scan is the major representation shared during environmental analysis. during a scan or analysis of the subenvironments, the key stakeholders are identied. their expectations for the system are identied and evaluated and gaps are noted in a futures table. con˚icts and ambiguities are seen as opportunities for system or interface improvement. as with other variance or gap analyses, minimizing the variances is the objective.uses of methodsconsistent with the sociotechnical systems approach, we summarize the general methods associated with the presented shared representations. detailed coverage of nested techniques, such as survey design and analysis or focus group management, is beyond the scope of this report.organizational system scanthe purpose of designing an organizational structure is to create lines of authority and communication in an enterprise in support of a strategy. in the context of system development, these lines of authority and communication establish and dene ownership and management of the system in question. this will ultimately serve as a major determinant of the level of system success. the organizational design is also the manner by which an organization distributes its purpose or mission throughout the enterprise. ideally, a given system supports the mission or purpose of the organization, and the structure facilitates accomplishment of the mission. also, all employees and users ought to understand the overall purpose of the enterprise, the contributing role of the system, and their personal role in achieving the purposes of the system and enterprise. if the organizational design is appropriate and effective, this is more likely to occur.three core dimensions of organizational design underlying all organizational structures can be analyzed: these are referred to as complexity, formalization, and centralization (hendrick and kleiner, 2001). complexity has two componentsšdifferentiation and integration. differentiation refers humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 145to the segmentation of the organizational design. integration refers to the coordinating mechanisms in an organization. coordinating mechanisms serve to tie together the various segments. systems often have an integrative function associated with their purpose. an increase in integration is also believed to increase complexity and therefore cost. formalization refers to the degree to which there are standard operating procedures, detailed job descriptions, and other systematic processes or controls in the organization. centralization refers to the degree to which decision making is concentrated in a relatively few number of personnel.the dimensions noted above manifest themselves in different organizational structures. the functional organizational design classies workers into common technical specialization domains. this type of design works best in small to moderately sized enterprises (up to 250 employees) that have standardized practices and a stable external environment. some advantages of the functional organizational design include professional identity, professional development, and the minimization of redundancy. the major weakness associated with this structure is suboptimization, a condition characterized by competition, coordination, and communication challenges laterally across units at the same level in the hierarchy.the product or divisional organizational design organizes workers by product cluster. in many organizations, divisions characterize the clusters. at the system level, many complex systems are really ﬁproductsﬂ in a divisional organizational design. the product variation of the functional design attempts to minimize suboptimization. instead of focusing on functions, which relate to the mission only indirectly, personnel theoretically identify with a product or system and therefore the product™s customer more readily. another intended advantage with this design is to allow the development and management of prot centers. each division (or system) can be operated as a business within the business. however, within each product cluster or division, functions typically appear. thus, the functional units still exist, although at a lower level. other variations, such as the geographic structure, have comparable strengths and weaknesses.since all of the previously mentioned alternatives are variations of the functional design, all have major shortcomings. specically, some suboptimization will occur. thus, enterprise designers derived a new alternative, mostly inspired from a combination of the functional and product structures. the function x product matrix (or the function x project) attempts to integrate the best of functional and product structures. specically, the benets associated with professionalism and lack of redundancy is retained from the functional design. from the product structure, a focus on the customer reduces the possibility of suboptimization.the major ˚aws associated with the matrix structure are the potentially confused lines of authority and communication. for example, a complex humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.146 humansystem integration in system developmentmilitary or aerospace system that is managed by a matrix structure could have a con˚ict between a safety manager (functional authority) and a project manager (project authority). making a launch deadline at the expense of safety could be a dangerous result. one workaround for such a scenario is to determine a priori which axis has more authority or, based on decision type, identify clearly who has nal authority.figure 64 illustrates a productfocused matrix organization for developing beast, a highdelity aerospace simulation tool (eichensehr, 2006). this organization creates both advantages and challenges for the group that manages the system. the fact that product area leads (software, payloads, special projects, and large programs) all depend on the same matrix of support engineers and programmers means that goals and efforts are more easily aligned. pockets of team members function across projects and transfer results from the latest studies and the latest software techniques. the matrix allows superior communication and effective cohesiveness over the beast product team (eichensehr, 2006).system or organizational scanning involves evaluating the organization™s mission, values, history, current change activities, and business environment (lytle, 1998). it involves dening the workplace in systems terms, including relevant boundaries. the enterprise™s mission is detailed in systems terms (i.e., inputs, outputs, processes, suppliers, customers, internal controls, and feedback mechanisms). the system scan also establishes initial boundaries of the work system. as described by emery and trist (1978), there are throughput, territorial, social, and time boundaries to consider. entities outside the boundaries identied during the system scan are part of the external environment which is discussed below.program managersw leadpayloads leadspecial projects leadlarge program leadboeing engineering aerospace simulation tool (beast) programbeast team:aerospace engineerssw engineersaerospace analystsorganization builds anduses aerospace simulatorto analyze current andfuture satellites and aircraft.beast models all subsystems of spacecraft andaircraft to a high degree offidelity.64figure 64 example of organizational design (used with permission).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 147role analysisrole analysis addresses who interacts with whom, about what, and how effective these relationships are. in a role network, the focal role (i.e., the role responsible for controlling key variances) is rst identied. with the focal role identied at the center, other roles can be identied and placed on the diagram relative to the focal role. based upon the frequency and importance of a given relationship or interaction, line length can be varied, where a shorter line represents more or closer interactions. finally, arrows can be added to indicate the nature of the communication in the interaction. a oneway arrow indicates oneway communication and a twoway arrow indicates twoway interaction. two oneway arrows in opposite directions indicate asynchronous (different time) communication patterns. to show the content of the interactions between the focal role and other roles and the evaluation of the presence or absence of a set of functional relationships for functional requirements, labels are used to indicate the goal of controlling variances. these labels might beł adaptation to shortterm ˚uctuations.ł integration of activities to manage internal con˚icts and promote smooth interactions among people and tasks.ł longterm development of knowledge, skills, and motivation in workers.also the presence or absence of particular relationships is identied as follows:ł vertical hierarchy,ł equal or peer,ł crossboundary,ł outside, andł nonhuman.the relationships in the role network are then evaluated. internal and external customers of roles can be interviewed or surveyed for their perceptions of role effectiveness as well.cultural analysisa cultural context is needed for effective system development. while this section cannot be exhaustive, we intend to convey the importance of this often ignored area of system support. organizational culture is related to the norms, beliefs, unwritten rules, and practices in an organization humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.148 humansystem integration in system development(deal and kennedy, 1982) and is an area of organization that has been signicantly understudied (schein, 1996). according to schein (1993), organizational culture is a pattern of shared basic assumptions that a group learned as it solved its problems of external adaptation and internal integration. this apparently has worked well enough to be considered valid and therefore to be taught to new members as the correct way to perceive, think, and feel in relation to those problems (schein, 1993). the fundamental basis of culture has to do with underlying or foundational values. culture is different from organizational climate. culture is much more permanent and pervasive, whereas climate is the temporary reaction to critical incidents and events.culture can theoretically be changed in several ways. first, major policy changes or launches of new systems can affect the culture of an enterprise, as change can be mandated by management. sometimes however, policy and strategic change are invalid reactions to forces from the environment. second, changing the behaviors of leaders can induce a culture change. leaders need to model expected behavior if they want enterprise members to modify their own behaviors and attitudes. third, selection and training can help to change cultures. finally, when appropriate, a comprehensive work system design change can and often will result in a culture change. most largescale system development launches should be conducted as part of a comprehensive work system design change. a work system design change supported by valid changes in policy and leadership and training is likely to be the best approach to achieving desired culture change and effective performance of a new or improved system.stakeholder analysisin addition to an enterprise context for systems, systems have environments that surround them and the enterprise of which they are a part. the environment is the source of resources (inputs) that are received by systems and enterprises, and it is the stakeholders in the environment that ultimately evaluate the success of the system or enterprise.an external environment can be further divided into relevant subenvironments. subenvironment categories typically encompass economic, cultural, technological, educational, political, and other factors. the system itself can be redesigned to align better with external expectations or, conversely, the system owners can attempt to change the expectations of stakeholders to be more consistent with system needs. according to the sociotechnical systems view, the response to variability in part will be a function of whether the environment is viewed by the system owners as a source of provocation or inspiration (pasmore, 1988). the gaps between system and environmental expectations are often gaps of perception, and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 149communication interfaces need to be developed between subenvironment personnel and the system owners or operators.contributions to system design phasesas part of developing an understanding of the context of use, it is desirable to understand the organizational context, specically in terms of organizational structure, roles, culture, and the environment. thus, analyzing these contexts is most useful at the beginning stages of the system design process. analysis, design, and implementation that fail to include the perspectives of stakeholders can often lead to systems that fail in functional, organizational, or economic terms. workcentered approaches attempt to prevent these types of design failures by explicitly grounding the design in the broad context of the work relationship and work practices to be performed and the sociotechnical system in which it is placed. but attention to the organization and the environment does not stop once the system is designed. as carayon (2006) indicates, the design of sociotechnical systems in collaboration with both the workers and the customers requires increasing attention not only to the design and implementation of systems, but also to the continuous adaptation and improvement of systems in collaboration with customers. thus, an impact can be made during the design phase, implementation, and operation of sociotechnical systems (carayon, 2006). table 62 illustrates how variances can be identied and data established for analysis when evaluating gaps between managers™ and employees™ perceptions.strengths, limitations, and gapsthe enterprise and the environment will have a major impact on whether a system is successful in meeting its intended mission and is well received. hendrick and kleiner (2001) claim that the environment is four times more powerful than other subsystems as a determinant of success. by assessing the enterprise and environmental contexts in the initial design, the likelihood of a successful outcome will be enhanced. there are several frameworks that promote this type of contextual understanding. a challenge is that the entire context cannot be known, and thus it is difcult to decide how much contextual knowledge is enough.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.150 humansystem integration in system developmenttable 62 examples of role varianceskey function from position descriptionperception by employerperception by employeevariancedegreeintensity1ensures that required resources are available for the program(s).will supervise cost engineers providing cost estimating and other services.only one staff in northern va, so doing handson cost engineering services (ces).3œ32manage one or more very complex programs or portions of larger programs having a lifetime value greater than $50 million.will concentrate on business development activities to grow divisional revenue.will do business development as necessary to grow ces staff.1+13maintains relationships with customer to satisfy requirements and develop new or additional business opportunities.will perform as member of proposal teams for work pursued by other divisions and departments.will prepare proposals only for ces department.3œ24serves as primary customer contact for government agency or ofce.will attend available seminars, conferences, and engineering society meetings for networking.will keep networking activities reasonable so as not to interfere with operations.1+15selects, trains, motivates, and disciplines key staff.will assist other program managers with project controls services.will assist and mentor other program managers as well as ces staff.1+2field observations and ethnographyoverviewethnographic principlesethnographic approaches can provide excellent indepth reports on conditions of use in specic case studies or at specic locations or sites. these approaches are typically used to build an overall context of use for such specic, indepth cases. it is therefore crucial to select a broad set of cases, so that the indepth information provides a good range of what is going on in the domain of interest.the practice of ethnography involves both a relatively obvious set of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 151procedures and a subtler set of orientations and disciplines; without the latter, the procedures by themselves are unlikely to lead to goodquality data. nardi (1997) notes that ﬁone of the greatest strengths of ethnography is its ˚exible research design. the study takes shape as the work progressesﬂ (p. 362). however, this ˚exibility may also present risks, if the analyst does not know how to make the numerous choices that are always present in eld research. more broadly, blomberg et al. (2003) state, ﬁthe ethnographic method is not simply a toolbox of techniques, but a way of looking at a problemﬂ (p. 967). note that this stance is almost the exact opposite of participatory analysis and design (see below), which tend to be a resultsoriented set of methods and practices. we therefore begin with a set of principles of the ethnographic way of looking and then describe the practices. these principles are particularly important in dening an opportunity space.the rst principle is that ethnography is holistic (i.e., the assumption that all aspects of the work domain are related to one another, and that no single aspect can be studied in isolation from the others). as nardi (1997) explains, the quality of the relationship may be complex, including not only relationships of similarity and convergence, but also ones of tension, contradiction, and con˚ict. this principle of holism is contrary to many experimental laboratory heuristics, which tend to control as many variables as possible, to isolate a small number of variables of interest, and then to manipulate those variables in a systematic manner. by contrast, ethnography may focus on an aspect of interest, but it remains open to discovering how that aspect of interest is related to other aspects, variables, and in˚uences. from the perspective of dening an opportunity space, this orientation can lead to new understandings and syntheses of diverse concepts that might be considered only in isolation in more traditional analytic approaches.the second principle is that ethnography is descriptive, rather than evaluative. nardi (1997) describes some uses of ethnography for evaluation, occurring relatively late in a product life cycle; however, she agrees with blomberg et al. (2003) that the principal use of ethnography is early in the life cycle, when evaluation would be premature. it is also the case that ethnography is specialized toward nonjudgmental descriptions, and that there are much more powerful evaluative techniques available when those are needed (see chapter 8). the purpose of taking a descriptive stance is strategic: ethnography avoids judgment in order to remain open to possibilities, and in order to integrate diverse aspects and concepts into a rich picture of the domain (see monk and howard, 1998).the third principle is that ethnography focuses onšand privilegesšthe point of view of the people whose work or lifeways are being described (the ﬁmembers,ﬂ as anthropologists term them). most ethnographic reports are intended to take the reader into the mind set of the people who are described. thus, an ethnographic report tends to require a subsequent step humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.152 humansystem integration in system developmentof translation or conversion into a set of engineering requirements. again, this focus on the members™ perspectives is an advantage when the goal is to dene an opportunity space.finally, the fourth principle is that ethnography is usually practiced in the members™ natural setting. in the eld setting, the analyst can see things that have become so commonplace to the members that no one thinks to talk about them. there the analyst can hypothesize new relationships and can use the ˚exibility of ethnography to test those relationships by turning the analysis in a new direction.ethnographic practicesethnography tends to focus on a small number of cases, and to study those cases in depth and detail. it is therefore essential to manage the diversity in those cases, to use that diversity strategically, and exercise caution in generalizing conclusions to other cases that were not studied. there are several strategies and procedures for managing these sampling issues.as discussed by blomberg et al. (2003), bernard (1995) proposed an in˚uential set of disciplined approaches for choosing samples (study sites) for ethnography. in the most controlled quota approach, the team can determine which types of sites are most representative of their application domain, and they have the ability to obtain as many samples (specic sites) of each type to satisfy their sampling requirements. the purposive approach is similar, except that the team cannot control the number of sites of each required type.but sometimes a team cannot exercise even this much control of where or how they will collect their ethnographic data. in the convenience approach, teams improvise with whatever sites become available. one potential enhancement of this improvisational strategy is the snowball approach, in which each site helps to recruit other sites for the study.if the analyst cannot prespecify the sites for the study, then what happens to the discipline and systematic sampling advocated by bernard (1995)? one approach that has gained a strong following is called grounded theory (glazer and strauss, 1967), which makes strategic use of the diversity among sites in an ongoing, hypothesistesting manner. in grounded theory, the analyst begins with a general research question, rather than a specic theory and hypothesis. each site becomes an opportunity for theory creation and theory renement concerning the research question, and part of the discipline of grounded theory is to do the hard work of revising the analyst™s theory after each site. subsequent sites are chosen precisely because they provide a strong test of the current revision of the (evolving) theory.for example, a military ethnographer might study a rst site in a ˚at humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 153desert setting, perhaps drawing some tentative conclusions about how warghters create defensive perimeters based on experiences at that site. however, the terrain is likely to in˚uence those perimeters. more subtly, the terrain might also in˚uence how warghters construct those perimeters and might even in˚uence the organizational dynamics of who orders the perimeter, who constructs it, and who depends on it (recall the principle of holism described above). therefore, the analyst would strategically choose a different terrain for the second eld sitešperhaps a mountainous terrain. observations at the second site would lead to a more rened theory. the more rened theory might lead to questions that contrast natural obstacles with humanmade environments. the analyst might therefore choose a third site that is in a city. and so on.in this way, grounded theory makes strategic use of the variability that is available in the world, and strives to maximize the variance in the factors of interest. note that this subtle discipline is quite different from laboratory studies, in which the goal is usually to minimize and control variability. the maximization of variability naturally leads to more opportunities for insights, and thus can contribute powerfully to dening an opportunity space.within the bounds of the chosen sampling approach (e.g., quota, purpose, convenience, snowball, or grounded theory), ethnographic practices tend to take a small number of forms. the traditional practices are interviews and observations; however, within ethnography, each of these practices has some important details.interviews are typically open, that is, the analyst has a list of topics to ask about, but not a list of specic questions that must be answered before the conclusion of the interview. in contrast to conventional sociological or psychological surveys, ethnographic interviews are not intended to collect a data point on each of a number of preplanned and required dependent measures. instead, the interview follows the principle of ˚exibility, aiming to record a rich and holistic description of the members™ perceptions of their work and world.observations are similarly openended. ethnographers often describe observation practices along a range from observerparticipant to participantobserver. the observerparticipant attempts to be as unobtrusive as possible, merely recording as much data as possible. by contrast, the participantobserver attempts to join into the activities that she or he is observing and to learn about those activities ﬁfrom the inside.ﬂ in some cases, ethnographers supplement the observerparticipant approach with recording technologies, both audio and video (e.g., blomberg et al., 1993). in other cases, ethnographers recruit members (the people being studied) to create their own recordings or diaries (buur et al., 2000; wasson, 2000). most traditional ethnographic observations tend to be broad and holistic. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.154 humansystem integration in system developmentwhen appropriate, however, the analyst may modify this breadth into a focus on a particular person, object, event, or activity.ethnographers emphasize that the practice of ethnography requires both (a) knowledge of specic practices and (b) a perspective and orientation that come from indepth studyšpreferably in the form of an apprenticeship to a practicing ethnographer (blomberg et al., 1993, 2003; glazer and strauss, 1967; nardi, 1997). as noted above, the vital ˚exibility of ethnographic practice becomes strength in the discernment of an expert, but a danger in the improvisations of a novice. the practices are frequently valuable for any analyst; however, we encourage newcomers to these methods to seek advice and if possible working collaborations with more experienced practitioners.two recent trends are beginning to affect the wellestablished set of practices in ethnography. first, the internet itself has become a new in˚uence on culture and cultural practices. unlike conventional facetoface ethnographic practice, new practices are required to study people, work, play, collaboration, and spiritual practices on the internet (e.g., beaulieu, 2004; see also hine, 2000; miller and slater, 2001; olsson, 2000; wittel, 2000). because our report does not focus on internet issues, we note this trend but do not describe it in detail.second, computer technology has allowed more powerful analytic methods through easy ﬁcodingﬂ of eld records or transcripts (annotations in terms of a hierarchy of terms and categories of observations) and easy sharing of coding schemes and coded materials. some of these coding programs may also be used on multimedia eld records (e.g., analog or digital video), thus extending the power and utility of those media for ethnographic recordkeeping and presentation. several commercial tools have become de facto standards in this area; see recommendations from the american anthropology association for details.1contributions to the system design processthere are major claims of the usefulness of ethnographic work to systems engineering and design (e.g., hutchins, 1995). for an accessible survey of early success stories, see hughes et al., (1995). for a more detailed set of accounts, see button (1992), luff et al. (2000), and taylor (2001).nardi (1997) and blomberg et al. (2003) provide detailed discussions of the role of ethnography in system development work. nardi notes the variety of ways that an ethnographer continually brings users™ issues to the 1 for example, http://www.stanford.edu/~davidf/ethnography.html contains an updated list of free and commercial coding products, as a service of the american anthropological association; more generally, see http://www.aaanet.org/resinet.htm.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 155attention of the development team, in both early analysis and even as a proxy for users in early testing.blomberg and colleagues note that the interpretation of ethnographic results is a kind of analysis, carried out according to the principles reviewed above. they describe four types of potential contributions from this type of analysis to system development:1. propose, inform, enhance, and update the working models that developers use as they think about the endusers (see also hughes et al., 1997).2. provide generative concepts to support innovation and creativity in developers™ efforts to dene new solutions.3. provide a critical lens (elsewhere called a framework) with which to evaluate and prioritize feature ideas and solution alternatives.4. serve as a reference for development teams.shared representationsseveral types of intermediary products or shared representations may be used between ethnographers and their clients (e.g., systems engineers or developers):ł experience models are documents or visualizations that help software professionals to understand patterns of human behavior, thought, and communication.ł opportunity maps are analytic summaries of the relationship of multiple dimensions, such as human activities versus evolutionary changes in attitudes.ł proles are similar to personas (discussed later in this chapter).ł scenarios, as discussed later in this chapter and in chapter 7.ł mockups and prototypes, as discussed later in this chapter and in chapter 7.strengths, limitations, and gapsmuch has been written of the difculty of translating ethnographic insights into analytic requirements (e.g., hughes et al., 1992). crabtree and rodden (2002) call this relationship a ﬁperennial problem.ﬂ ethnographic investigations tend to go into great depth in a small number of sites or cases and to restrict their interpretations to these local settings (nardi, 1997); it is difcult to generalize reliably from these small samples to the larger riskreduction questions of what features, functions, or technologies are needed across all relevant users and circumstances (see the powerhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.156 humansystem integration in system developmentful theoretical and practical analysis of ethnographers™ contextualism and engineers™ abstractionism of potts and hsi, 1997; see also hughes et al., 1997). ethnographers often prefer to provide a wealth of detail, whereas systems professionals often desire a more reductionist summary (crabtree and rodden, 2002; somerville et al., 2003).one of the hallmarks of ethnography is its ability to change focus and direction when faced with new insights (nardi, 1997), whereas systems engineering prefers a straightforward process model with known steps, milestones, and completion dates. ethnographic investigations tend to privilege the perspective of the members (the people being described in the analysis) in rich qualitative terms, whereas systems engineering is often a matter of trading off one perspective against another through the use of common or intertranslatable metrics; these metrics are difcult to apply to a description that is couched entirely in the language of the users™ workplace and world (crabtree et al., 2000).much progress has been made more recently in the integration of ethnography into systems engineering. somerville et al. (2003) provide a thematic analysis and review of issues in this evolving interdisciplinary partnership. they, as well as hughes et al. (1997), identied three dimensions of the users™ work in which ethnographers and systems engineers have been shown to make mutually benecial knowledge exchanges: (1) distributed coordination, (2) plans and procedures, and (3) awareness of the work of others. potts and hsi (1997) used a similar strategy of identifying several key dimensions that can serve as conceptual landmarks for both ethnographers and engineers: (1) decomposition into goals, agents, and objects; (2) analysis of the relationships among goals, agents, and objects in terms of actions and responsibilities; and (3) a set of conceptual, literal, or historical test cases for system robustness, phrased in terms of obstacles and defenses. by contrast, millen (2000) recommended that applied industrial ethnography be streamlined (in terms of both process and outcome) into a pragmatic set of practices called ﬁrapid ethnography,ﬂ emphasizing (1) strategically constrained focus and scope, (2) selective work with a small number of key informants, (3) convergence of evidence using multiple eld data techniques, and (4) collaborative analysis of qualitative data (for related approaches to collaborative analysis of eld data, see holtzblatt, 2003; holtzblatt et al., 2004).the wealth of detail that is available through ethnography is undeniable. the translation of that detail into a form that is useful to systems engineers and designers has been a difcult problem, but there are now both guidelines for how to make that translation and convincing success stories of the effectiveness of the translation in a diversity of system and product environments. in the language of potts and hsi (1997), there are now effective ways to bring powerful insights from the contextualism of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 157ethnography into the powerful constructive environment of systems engineering and design.task analysisoverviewsuppose you were trying to design a new control room (e.g., for a process control plant or a ship command center). how would you know what displays and controls are needed and how they should be physically laid out? or suppose you were designing a new web site for an organization (e.g., a corporation, a university, a government agency). how would you know what information to include on the web site and how to organize the information? one of the rst things you would need to know is what tasks people will be performing using the system and how those tasks are performed, so that you could design the system and related supports (e.g., procedures, training manuals, tools).task analysis refers to any process that identies and examines the tasks that are performed by users when they interact with systems. kirwan and ainsworth (1992) provide a comprehensive review of task analysis methods, covering 25 major task analysis techniques.typical task analysis methods are used to understand humanmachine and humanhuman interactions by breaking down tasks or scenarios into component task steps or physical (and sometimes also mental) operations. the result is a detailed description of the sequential and simultaneous activities of a person (or multiple people) as they interact with a device or system to achieve specic objectives. in this section we focus on task analysis methods that are particularly suited for dening tasks and the behavioral sequence of activities necessary to accomplish the task. the next section, on cognitive task analysis, describes specic methods for uncovering and representing the knowledge and mental activities that underlie more cognitive performance (e.g., situation assessment, planning, decision making).the general task analysis process involves identifying tasks to be analyzed, collecting task data, analyzing the results to produce a detailed task description, and then generating an external shared representation of the analyzed tasks. the output is a description that includes specication of the individual task steps required, the technology used in completing the task (controls, displays, etc.) and the sequence of the task steps involved.one of the most commonly used task analysis methods is hierarchical task analysis (hta). hta involves breaking down the task under analysis into a nested hierarchy of goals, subgoals, plans, and specic (mental or physical) operations (annett, 2005).the rst step involves data collection to understand the individual(s) humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.158 humansystem integration in system developmentperforming the task, the equipment or components used to perform the task, and the substeps involved in performing the task, including the stimuli that trigger a task step and the required human response. a variety of methods can be used to collect these data, includingł observation of actual task performance.ł task walkthroughs or talkthroughs.ł verbal protocols.ł tabletop analyses of expected interaction given design descriptions.ł interviews with domain practitioners.ł surveys and questionnaires.ł userkept diaries and activity logs.ł automated records (e.g., computer logs of web searches, keystroke capture).the analysis may be based on examination of video or audio recordings of task performance, detailed notes taken during task performance, or quantitative or qualitative summaries of task performance across individuals.an interesting example is provided by ritter, freed, and haskett (2005), who performed a task analysis to identify the range of tasks that users of a university department web site might want to accomplish. they used multiple converging techniques to identify these tasks, including analysis of existing web sites, review of web search engine logs to determine typical web site search queries, and interviews of a range of different types of users (e.g., current and prospective students, staff, parents, alumni).once the data are collected, it is then analyzed to provide a detailed description of the task steps. in the hta method, the overall goal of the task under analysis is specied at the top of the hierarchy (e.g., startup plant, land aircraft, or withdraw money from an atm machine). once the overall task goal has been specied, the next step is to break down the overall goal into subgoals (usually four or ve) that constitute subelements of the task. for example in the case of withdrawing money from an atm machine, the substeps might be (1) inserting bank card, (2) specifying account to withdraw funds from, (3) specifying amount to be withdrawn, (4) taking money, and (5) taking bank card back. the subgoals are then further broken down into more detailed subgoals, until specic actions/operations are identied at the lowest nodes in the network. for example, in the case of withdrawing money, the lowest nodes may specify (1) type in digits corresponding to desired amount to be withdrawn, (2) press the enter key, (3) read display, (4) conrm that the amount displayed on the screen conrms to desired amount, and (5) press ﬁyesﬂ key.another typical method is a sequential task ˚ow analysis. a ˚ow diagram representation is used to specify the sequence of steps that would be humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 159taken under different conditions. this approach was used in the intravenous infusion pump case study described in chapter 5 (see figure 55).in the symbiqž iv pump case study, task analysis and contextual inquiry were done through multiple nurse shadowing visits to the most important clinical care areas in several representative hospitals. an important outcome of the task analysis was the foundation of the useerror risk analysis, in the form of a failure modes and effects analysis (fmea) (see table 53 for an example). each task statement from the task analysis became a row in the fmea of possible use errors and their consequences.shared representationsa variety of shared representations are used to depict the output of the task analysis. these can take the form of graphical, tabular, or text descriptions (stanton et al., 2005b; kirwan and ainsworth, 1992). examples include task description tables, hierarchical network representations, timeline representations, and task ˚ow diagrams. figure 65 shows an example of a graphic representation of the output of a hierarchical task analysis for the simple example of an atm withdrawal of money. typically the graphic representation would be supplemented with text providing contextual background and details.examples of a task ˚ow diagram and a task description table are provided in the risk analysis section of chapter 8. the outputs of task analyses withdraw moneyfrom atminsert bank cardspecify accountnumberspecify amount tobe withdrawntake moneytake bank cardbacktype in digitscorresponding toamountpress enter keyread displayconfirm amountpress yes key65figure 65 an example of graphic representation of a portion of a hierarchical task analysis of the ﬁwithdraw money from atmﬂ task. the graphic would be accompanied by textual descriptions that provided contextual background and task details.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.160 humansystem integration in system developmentcan also be expressed as executable simulation models (see models and simulation in chapter 7).uses of methodstask analysis methods are widely used to provide a stepbystep description of the activity under analysis. they provide a basis for assessing characteristics of a task, including the number and complexity of task steps, sequential dependencies among task steps, the temporal characteristics of the task (e.g., mean and distribution of time durations for each step and for the task as a whole), the physical and mental task requirements, equipment requirements, mental and physical workload, and potential for error.contributions to system design phasesthe results of a task analysis are relevant to multiple phases in the system design process. the results of task analysis are used to informł function allocation.ł stafng and job organization.ł task and interface design and evaluation.ł procedures development.ł training requirements specication.ł physical and mental workload assessment.ł human reliability assessment (i.e., error prediction and analysis).strengths, limitations, and gapstask analysis is one of the most useful and ˚exible tools available for analyzing and documenting the sequential aspects of task performance. it requires minimal training and is easy to implement. tasks can be analyzed at different levels of detail, and the output feeds numerous human factors analyses throughout the system development process.one of the major strengths of task analyses is that they identify when, how, and with what priority information will be needed to perform expected tasks for which analyses have been performed. as such they provide a powerful tool for creating displays, procedures, and training to support individuals in performing tasks in the range of situations that have been anticipated and analyzed. they help to reduce the risks of device or task mismatches.among the disadvantages that are typically mentioned include that data collection and analysis can be resource intensive to perform thoroughly. detailed task analyses can be particularly timeconsuming to conduct for humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 161large, complex tasks (stanton et al., 2005b). the resource commitment can be amortized if the results of a single task analysis are leveraged to feed into multiple hsi design and analysis activities (e.g., job design, procedure development, training development, human reliability analysis).another limitation of sequential task analysis approaches noted by miller and vicente (1999) is that they are prone to produce ﬁcompiledﬂ procedural knowledge of the steps involved in performing a task, without explicit representation of the deeper rationale for why the task steps work, and how they may need to be adapted to cover situations that were not explicitly analyzed. the results of the task analysis may be narrowly applicable to the specic scenarios analyzed. as a consequence, displays, procedures, and training that exclusively rely on the results of the task analysis may be brittle in the face of unforeseen contingencies (miller and vicente, 1999). work domain analysis, described in chapter 7, provides a complementary analyses technique, intended to compensate for the potential limitations of task analysis methods.cognitive task analysisoverviewtraditional task analysis approaches break tasks down into a series of external, observable behaviors. for tasks that involve few decisionmaking requirements (e.g., assembly line jobs, interacting with a consumer product that are expected to be easy to operate, such as atm machines), traditional task analysis methods work well. however many critical jobs (e.g., air trafc control, military command and control, intelligence analysis, electronics troubleshooting, emergency response) involve complex knowledge and cognitive activities that are not observable and cannot be adequately characterized in terms of sequences of task elements. examples of cognitive activities include monitoring, situation assessment, planning, deciding, anticipating, and prioritizing. cognitive task analysis (cta) methods have emerged that are specically tailored to uncovering the knowledge and cognitive activities that underlie complex performance. cta methods provide a means to explicitly identify the requirements of cognitive work so as to be able to anticipate contributors to performance problems (e.g., sources of high workload, contributors to error) and specify ways to improve individual and team performance (through new forms of training, user interfaces, or decision aids).cta methods provide knowledge acquisition techniques for collecting data on the knowledge and strategies that underlie performance as well as methods for analyzing and representing the results. a variety of  specic techniques for knowledge acquisition have been developed that humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.162 humansystem integration in system developmentdraw on basic principles and methods of cognitive psychology (ericsson and simon, 1993; hoffman, 1987; potter et al., 2000; cooke, 1994; roth and patterson, 2005). these include structured interview techniques, such as applied cognitive task analysis (militello and hutton, 2000) and goaldirected task analysis (endsley, bolte, and jones, 2003); critical incident analysis methods that investigate actual incidents that have occurred in the past (flanagan, 1954; klein, calderwood, and macgregor, 1989; dekker, 2002); cognitive eld observation studies that examine performance in actual environments or in highdelity simulators (woods, 1993; roth and patterson, 2005; woods and hollnagel, 2006, ch. 5); ﬁthinkaloudﬂ protocol analysis methods in which domain practitioners are asked to think aloud as they solve actual or simulated problems (e.g., gray and  kirschenbaum, 2000); and simulated task methods in which domain practitioners are observed as they solve analog problems under controlled conditions (patterson, roth, and woods, 2001).schraagen, chipman, and shalin (2000) provide a broad survey of different cta approaches. crandall, klein, and hoffman (2006) provide an excellent howto handbook with detailed practical guidance on how to perform a cognitive task analysis. comprehensive catalogues of cta methods and additional guidance can also be found on two active web sites: http://www.ctaresource.com maintained by aptima, inc., and http://www.mentalmodels.mitre.org/, maintained by mitre corp.representative methodsone of the most powerful means of uncovering the cognitive demands inherent in a domain and the knowledge and skills that enable experts to cope with its complexities is to study actual incidents that have occurred in the past to understand what made them challenging and why the individuals who confronted the situation succeeded or failed (flanagan, 1954; dekker, 2002). the critical decision method (cdm) is a structured interview technique using that approach (klein, calderwood, and macgregor, 1989; hoffman, crandall, and shadbolt, 1998; klein and armstrong, 2005). it is one of the most widely used cta methods. the cdm approach involves asking domain experts to describe past challenging incidents in which they have participated.a cdm session includes four interview phases or ﬁsweepsﬂ that examine the incident in successively greater detail. the rst sweep identies a complex incident that has the potential to uncover cognitive and collaborative demands of the domain and the basis of domain expertise. in the second sweep, a detailed incident timeline is developed that shows the sequence of events. the third sweep examines key decision points more humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 163deeply using a set of probe questions (e.g., what were you noticing at that point? what was it about the situation that let you know what was going to happen? what were your overriding concerns at that point?). finally the fourth sweep uses whatif queries to elicit potential expertnovice differences (e.g., someone else, perhaps with less experience might have responded differently). the output is a description of the subtle cues, knowledge, goals, expectancies and expert strategies that domain experts use to handle cognitively challenging situations.concept mapping is another interview technique that has been used to uncover and document the knowledge and strategies that underlie expertise (crandall, klein, and hoffman, 2005). in this kind of knowledge elicitation, the cta analyst helps domain practitioners build up a representation of their domain knowledge using concept maps. concept maps are directed graphs made up of concept nodes connected by labeled links. they are used to capture the content and structure of domain knowledge that experts employ in problem solving and decision making. concept mapping are typically conducted in group sessions that include domain experts (e.g., three to ve) and two facilitators. one facilitator provides support in the form of suggestions and probe questions, while the second facilitator creates the concept map based on the participants™ comments for all to review and modify. the output is a graphic representation of expert domain knowledge that can be used as input to the design of training or decision aids. figure 66 is an example of a concept map that depicts the knowledge of cold fronts in gulf coast weather of an expert in meteorology.cognitive task analysis techniques have been developed to explore how changes in technology and training are likely to impact practitioner skills, strategies, and performance vulnerabilities. the introduction of new technologies can often have unanticipated effects. this has been referred to as the ﬁenvisioned worldﬂ problem (woods and dekker, 2000). new, unanticipated complexities can arise that create new sources of workload, problemsolving challenges, and coordination requirements. in turn, individuals in the system will adapt, exploiting the new power provided by the technology in unanticipated ways, and creating clever workarounds to cope with technology limitations, so as to meet the needs of the work and human purposes.cta techniques to explore how people are likely to adapt to the envisioned world include using concrete scenarios or simulations to simulate the cognitive demands that are likely to be confronted. woods and hollnagel (2006) refer to these methods as ﬁstaged worldﬂ techniques. one example is a study that used a highdelity training simulator to explore how new computerized procedures and advanced alarms were likely to affect the strategies used by nuclear power plant crews to coordinate activities and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.164 humansystem integration in system developmentfigure 66 an example of a concept map that represents expert knowledge of the role of cold fronts in the gulf coast. it was created using a software suite called cmaptools. icons below the nodes provide hyperlinks to other resources (e.g., other cmaps, and digital images of radar and satellite pictures; digital videos of experts). cmaptools was developed at the institute for human and machine cognition, and is available for free download at http://ihmc.us. figure courtesy of r.r. hoffman, institute for human and machine cognition.this is a fixed image,i.e., a jpeg(diffi9cult to make alterations66maintain shared situation awareness (roth and patterson, 2005). another example is a study by dekker and woods (1999) that used a future incident technique to explore the potential impact of contemplated future air trafc management architectures on the cognitive demands placed on domain practitioners. controllers, pilots, and dispatchers were presented with a series of future incidents to jointly resolve. examination of their problem solving and decision making revealed dilemmas, tradeoffs, and points of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 165vulnerability in the contemplated architectures, enabling practitioners and developers to think critically about the requirements for effective performance for these envisioned systems.relationship to task analysisthe boundary between task analysis methods and cognitive task analysis methods is not always clearcut. while cognitive task analyses focus on cognitive aspects of performance and task analyses have the objective of describing the sequence of activities required to perform a task, there can be overlap in the types of information covered by each approach (annett, 2000). task analyses can include informationprocessing activities as well as external physical activities. in turn, cognitive task analyses will tend to specify the physical activities required to access and integrate the information needed for cognitive tasks (e.g., if a cognitive task requires integrating information across multiple displays, communicating with others, or traversing physically disparate locations, these will be captured in a cognitive task analysis).a bootstrap processcognitive task analysis is fundamentally an opportunistic bootstrap process (potter et al., 2000). the cta process generally involves the use of multiple converging techniques. in a typical cta approach, the cognitive analyst might start by reading available documents that provide background on the eld of practice (e.g., training manuals, policy and procedure guides). this background knowledge raises new questions and hypotheses that can then be addressed through eld observations or interviews with domain practitioners. these in turn may point to complicating factors in the domain that place heavy cognitive demands on the user and create opportunities for user error. the information can be used to create scenarios that illustrate the complexity in the domain. these scenarios can then be used to observe practitioner performance under simulated conditions, comparing the strategies used by experts with those of less experienced domain practitioners. the scenarios can also be used to evaluate the effectiveness of proposed design concepts for supporting performance under challenging conditions.the particular set of cta techniques selected will generally depend on the goals of the analysis and the pragmatics of the specic local conditions (e.g., access to domain practitioners, practicality of performing observations in the actual work environment). if the goal of the analysis is to identify leverage points at which new technology could have signicant positive impact, then techniques that provide a broad brush overview of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.166 humansystem integration in system developmentcognitive and collaborative requirements and challenges in a domain, such as eld observations and structured interviews, can be very effective. if the goal is to develop training programs or to produce assessment protocols to establish practitioner prociency (e.g., for accreditation purposes) then methods that capture the detailed knowledge and skills (e.g., mental models, declarative and procedural knowledge) that distinguish practitioners at different levels of prociency (e.g., the cdm and process trace approaches) can be particularly useful. if the goal is to develop a computer model that simulates the detailed mental processes involved in performing a task, then techniques such as the thinkaloud verbal protocol methods may be most appropriate.cta in the unmanned aerial systems case studythe hypothetical case study in chapter 5 on unmanned aerial systems illustrates the application of cognitive task analysis to the design of an envisioned system. the focus of the cognitive task analysis was workload, but not physical workload. rather, cognitive or mental workload was examined using a variety of methods, including interviews, observations, accident reports, and event data analysis. the results of the analysis revealed that cognitive workload was not constant but peaked at target areas and when replanning routes. this analysis of the task of operating an unmanned aerial system from a cognitive perspective provided information pertinent to determining the appropriate use of automation for control of multiple unmanned aerial systems. that is, based on these hypothetical results, automation would be most useful at these points of peak cognitive load, as opposed to the en route part of the task.shared representationsthe output of a cognitive task analysis can take multiple forms. in some cases, the output is a prose description of critical incidents and the cognitive demands and strategies they reveal. it can also take the form of structured tables that catalogue the decision points that arise, why they are difcult, the knowledge and skill that enable experts to handle the situation, and the typical errors that less experienced personnel make. other shared representations that are produced from a cognitive task analysis are concept maps that provide graphic depictions of the structure and content of knowledge of domain practitioners (both experts and less experienced individuals) and diagrams that illustrate the problemsolving strategies used by domain practitioners (e.g., contrasting expert versus novice strategies).the hierarchical task analysis formalism described in the task analysis section can also be used to represent the output of a cognitive task analyhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 167sis (annett, 2000). in that case, the goalsubgoal decomposition would include informationprocessing activities as well as overt physical actions. the goms method, which decomposes complex cognitive tasks into goals, operators, methods, and selection rules (card, moran, and newell, 1983) provides another example of a goal decomposition representational approach (see chapter 7). the goaldirected task analysis method developed by mica endsley (endsley, bolte, and jones, 2003) is another example of an approach that produces a goal decomposition representation. in that method, two complementary representations are produced: a goal hierarchy that is similar to a hierarchical task analysis representation and a relational hierarchy that explicitly identies the decisions related to each goal and subgoal, as well as the information needed to support those decisions.the output of a cognitive task analysis can sometimes also take the form of a runnable computational model (e.g., an actr model). the section on models and simulation in chapter 7 provides a number of examples of computational models that have been developed to elucidate cognitive task performance.uses of methodsthe output of a cognitive task analysis is used to dene the knowledge, skills, problemsolving, and decision strategies that are required for effective performance in the domain. the output can be used to specify requirements for training, procedures, displays, and decision aids. it can also be used to guide personnel selection, manning, and function allocation decisions. the results of cognitive task analysis can also be used as input to workload analysis and human reliability modeling.contributions to system design phasescognitive task analyses are particularly useful as part of early context of use analyses in support of understanding needs and envisioning opportunities. they can be used to help focus further analyses and design efforts on aspects of performance that are most cognitively challenging and error prone and identify leverage points at which the introduction of new technology can have the most positive impact on performance. the output of a cognitive task analysis can also be used to dene cognitively demanding scenarios and targets for effective performance that can inform design. the scenarios and performance targets can also be used in later evaluations of the effectiveness of the new design.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.168 humansystem integration in system developmentstrengths, limitations, and gapscta methods are powerful tools for uncovering the complexities in a domain, the knowledge and strategies that underlie expert performance, as well as the contributors to performance difculty and errors.cta methods can be resource intensive. interviews and observations can be timeconsuming to conduct and analyze. they require access to domain experts, which can sometimes be difcult to arrange. finally, they require analysts who have a background in behavioral sciences and training in cta methods to conduct and analyze the cognitive task analyses.while cta methods can be resource intensive, the cta tool kit contains a variety of methods that can be tailored to the needs and constraints of the particular application. for example, if access to the actual work environment is not possible, precluding the possibility of conducting eld observations, then structured interview techniques can be used. if experts cannot discuss actual cases (e.g., because the information is classied or proprietary) then analyses can be conducted using simulated scenarios or analogous problems. if access to domain experts is not possible, it may be possible to conduct a cognitive task analysis based on review of documented descriptions of past critical incidents (e.g., accident reports).one of the current gaps that limits cta productivity is the paucity of computational tools to help in the capture, organization, dissemination, and retrieval of cta results. better software tools could improve the efciency of cta analyses. they could support the development of a corpus of knowledge that could be updated more easily as new information is learned, communicated to stakeholders more effectively, and accessed and reused more readily across the life cycle of a development project (the same cognitive task analysis could be used to inform design, development of procedures, development of training, and development of safetycase submittals). such a resource would be especially valuable in complex design projects whose development can span multiple years across multiple organizations. in the current state of practice, organizations are often not aware of cognitive task analyses (or other analyses of context of use) that have been performed previously by others (especially if they have been conducted by other organizations). in cases in which they are aware of prior relevant analyses, the results may not be available to them, or they may be in a form that is difcult to assimilate. at the same time, it can be costprohibitive for each new group or organization to conduct a cognitive task analysis from scratch. as a consequence, design efforts are forced to shortcircuit the analysis step, even while recognizing its importance because of time and cost constraints. the same difculty arises for all the context of use methods covered in this chapter. all would benet equally humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 169from improved computational methods for capture, dissemination, and reuse of analysis results.participatory analysisoverviewthis section brie˚y reviews methods in participatory analysisša eld that has been intensely developed since the late 1970s and that we think is ready for use in large systems.there is evidence that users can participate as insightful and innovative collaborators during all stages of product life cycles. for collections of examples of notable projects and products, see bjerknes, ehn, and kyng (1987), greenbaum and kyng (1991), muller and kuhn (1993), noro and imada (1991), schuler and namioka (1993), and the proceedings of the participatory design conferences (evennumbered years from 1990 to 2006; available at http://www.cpsr.org/). for booklength treatments of the users™ roles as coanalysts, codesigners, and coevaluators, see beyer and holtzblatt (1998), carroll (2000), checkland (1981), ehn (1988),  mumford and henshall (1983), and rosson and carroll (2002).research in participatory analysis and design has tended to focus on three factors for effective user participation. the rst is the use of welltested group or workshop settings that improve the ability of all the stakeholders to participate on an egalitarian basis. the second factor is the establishment of wellunderstood relationships and project governance structures that include an explicit set of roles and responsibilities for users on the project team (e.g., bjerknes and bratteteig, 1987; bødker et al., 1987; rector et al., 1992). the third factor is the use of specic methods and practices for participatory analysis, design, or evaluation (for catalogues of over 70 such methods, see bødker et al., 2004; ehn and löwgren, 1997; muller, haslwanter, and dayton, 1997a; muller, 2007).the crucial aspect of all of these approaches is the full sharing of diverse expertise and knowledge, as well as an orientation toward mutual learning. bødker et al. (1988) spoke of the ﬁmutual validation of diverse perspectives.ﬂ floyd (1987) wrote of methods as opportunities for learning. muller et al. (1994) described participatory work as depending on three factors: the sharing of diverse expertise, stakeholder commitment, and democratic practices for knowledge sharing, con˚ict clarication, problem solving, and the creation of new solutions.participatory analysis provides methods for understanding the current state of work, including technologies and work practices. participatory design provides methods for improving the state of work in various ways, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.170 humansystem integration in system developmentand it is treated in detail in the next chapter. all methods are assumed to be performed in collaboration with usersšas coreporters of the current state of work, as coanalysts of how the work is proceeding, and as codesigners for improved work practices and technologies. in some interpretations, users have had a cocontributor role and also a codirector role (see, e.g., the collective resource approach of ehn and kyng, 1987). in north america, it is more common to nd users as cocontributors whose work domain knowledge is valued as highly as the more traditional knowledge of technologists, engineers, designers, marketers, trainers, and others (e.g., beyer and holtzblatt, 1998; blomberg et al., 2003; holtzblatt, 2003; holtzblatt and beyer, 1993; muller et al., 1994; noro and imada, 1991; sanders, 2000; wixon and ramey, 1996).methods in participatory analysis assist users to describe their work, their work organizations, their work technologies, and their work contexts. method development in this area has tended to be diverse and creative. we focus on four approaches that have developed a sustained record of experiences and successes.participatory workshopsone strategy for understanding context of use is to leverage directly the knowledge of the workforce (or warghters in the military)šthat is, to work directly with people who are already doing the work that the new system will support, or who are doing related work, or who will be the primary users of the new system. historically, this approach has been termed participatory design; it is described in bjerknes, ehn, and kyng (1987), greenbaum and kyng (1991), muller and kuhn (1993), mumford and henshall (1983), and schuler and namioka (1993). this strategy involves (1) determining crucial knowledge holders and (2) facilitating communication among them so that they can combine their diverse knowledge, expertise, backgrounds, and perspectives to create new and emergent concepts.at rst glance, this appears to be an easy task: get the right people together and ask them to brainstorm. experience has shown that this simple version of the activity can be surprisingly difcult when the participants come from different disciplines, knowledge traditions, social classes, or power positions in the organization (e.g., ofcers and enlisted personnel in the military, management and labor in a commercial enterprise). one of the subtle problems is to create a level playing eld on which people can contribute on an egalitarian basis, despite the fact that they may have very different power relationships outside the contextofuse activity. a second subtle problem is that diverse groups often need to discover their common ground and to cocreate a common language that is synthesized from their diverse backgrounds (muller, 2003). over the years, practitioners humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 171and researchers in the participatory design tradition have developed specic workshop approaches to resolve these subtle problems. three workshop approaches are brie˚y discussed below: future workshops, strategic design workshops, and visual workshops. a comparative review is provided by muller (2003), as well as a more encyclopedic treatment (muller,  haslwanter, and dayton, 1997).future workshops. one of the most effective workshop formats is the future workshop. originally developed for german civic planning (jungk and mullert, 1987), future workshops have been used in diverse software engineering settings and are now included in the emerging participatory information technology methodology of bødker et al. (2004).a future workshop proceeds through three phases:1. critique the present.2. envision the future.3. implement the changes to move from the present to the future.the critique phase allows diverse participants to understand one another™s perspectives and experiences, often fostering a coownership of the problems that are explained from each stakeholder™s point of view. this phase also produces a list of problems to be solved. this list of problems leads to the second phase, in which the group attempts to envision and cocreate future solutions to those problems. those solutions will require implementation, and of course not all solutions can be implemented within existing resource limitations. encountering these kinds of obstacles can send the group back to the phases of envisionment or even critique, before they can develop a proposal for feasible, resourceconstrained solutions. thus, the framework of the future workshop provides minimal structure that has been proven to produce highquality solution proposals that combine diverse knowledge and experiences, with buyin and commitment by diverse stakeholders.strategic design workshops. sanders and colleagues have shown the value of a threeactivity workshop protocol called strategic design workshops (sanders, 2000). these workshops combine methods from market research, ethnography, and participatory design. activities can include both qualitative, imaginative work (e.g., collages), lay formalization (mapping envisioned work processes on paper), and storytelling. the workshops produce a suite of potential opportunities for further investigation and renement.drawing and other visual workshops. several less formal workshop approaches have focused on people™s ability to coanalyze, cocreate, and cohumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.172 humansystem integration in system developmentevaluate ideas using simple graphical communications. monk and howard (1998) described freehand collaborative drawing of a conceptual map of the work domain. dray (1992) provided a more structured approach, in which a group develops a set of related visual concepts through a roundrobin brainstorming technique, in which each person spends a few minutes creating an initial diagram, then gives the diagram to another team member for further elaboration, while simultaneously receiving another diagram that had been begun by another team member. each diagram passes sequentially through the hands of all team members, one at a time. thus, each diagram becomes one version of a solution, but all versions have received contributions from all team members.scenarios in participatory analysissome participatory analysis methods focus on storytelling to create a level playing eld, to put users and technologists on a common footing; in more formal terms, these techniques have been described and analyzed as scenariobased methods (carroll, 1995, 2000; carroll, rosson, and carroll, 2002, 2003). the scenariobased methods tend to ˚ow smoothly from analysis to design; we make a somewhat arbitrary separation into an ﬁanalysisﬂ section in this chapter, and a ﬁdesignﬂ section in the following chapter.lowtechnology representationsone way to document a scenario is through a series of narrative storyboards. work of muller and colleagues pursued the level playing eld approach through partially structured paperandpencil materials to assist users in documenting their own work scenarios in the form of storyboards (lafrenière, 1996; muller, 2001; muller et al., 1995). while these methods were initially conceived as ﬁcard gamesﬂ for participatory analysis, their value emerges more clearly in relation to the scenario methods (described above) and to the generation of engineering requirements (described below).earlier work used ﬁcardboard computersﬂ as a means of both describing current working practices and envisioning future working practices (e.g., ehn and kyng, 1991; henderson and kyng, 1991). users and other coanalysts act out the current and proposed work practices, using lowtech materials as stage props in informal dramas.the work with lowtechnology representations tends to blur the divisions between analysis and design. that is, when people are describing current working practices, they often have profound ideas about how to improve them. good participatory analysis methods provide a means for capturing and elaborating these design insights and innovations as well. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 173this blurring of the line between analysis and design can often be powerful, leading to new insights and also to signicant savings in time and resources (i.e., combining two lifecycle stages that are often treated as different steps in more formal engineering methods).multimedia documentariesother more experimental methods have highlighted documentary materials prepared by usersšspecically photo documentaries (dandavante et al., 2000; hulkko et al., 2004; noble and robinson, 2000) and video documentaries (björgvinsson and hillgren, 2004; mørch et al., 2004). buur™s work (buur et al., 2000; pedersen and buur, 2000; bødker and buur, 2002) includes procedures for creating small video clips as starting points in participatory analysis of the working practices shown in those clips (see ehn and sjögren, 1991, and klær and madsen, 1995, for earlier work using brief textual descriptions as starting points for similar participatory analysis discussions).contributions to the system design processthe common theme is to nd methods that do not require skills or knowledge of technology, but that can instead support users in expressing the knowledge that is uniquely theirs. formal engineering models are included in scenariobased analysis (see above). practices have been developed for the other approaches, to translate between the informal, contextual, concrete, rich world of users and usage, and the more formal, decontextualized, abstract, and somewhat impoverished but powerful representations that are tractable for systems analysis. table 63 provides a synopsis of how each participatory method may be of use in the system development process.shared representationseach category of participatory analysis method produces its own characteristic shared representation.the scenariobased methods produce stories, storyboards, narratives, and (potentially) use cases and ˚ow charts of users™ work. long stories are problematic for systems engineers, but briefer stories, summarized into the components or elements of systems engineering requirements (e.g., use cases), may be very helpful.the lowtechnology representations produce exactly those representations, plus a set of insights, narratives, use cases, and other means of contextualizing those representations in the users™ work. the informality humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.174 humansystem integration in system developmentof the materials may make them appear to be less authoritative, but that informality is also a strength, in that it invites interpretation and further renement. in the more processoriented methods, such as the collaborative analysis of requirements and the collaborative analysis of requirements and design, it is possible to create a set of materials that correspond to a preexisting highlevel, objectoriented analysis of the components of the system, with the result that the outcome is very easy to translate into the language of systems engineering (muller, 2001; lafrenière, 1996).multimedia documentaries produce various personalized or groupauthorized accounts of work. these are somewhat more difcult to integrate directly into the work of systems engineers. these shared representations may thus require a subsequent interpretation or translation into a more consumable information product.the shared representations and issues related to ethnography are also relevant here.strengths, limitations, and gapsparticipatory analysis methods are often very fast to execute. their historic support of democratic work practices may be an advantage in some settings and a disadvantage in others. in any event, they require skilled facilitation. their openness may lead to a lack of rigor, and their strategic table 63 how participatory methods fit into the system development processmethodrole in system  development processshared representation  and useparticipatory workshopunderstanding context of useearly problem analysisvoice of the user/customeropportunity analysisworkshop report (usually informal, except for the following method)future workshopproblem analysisproposed solutionsopportunity analysisstructured report (critique, vision, implementation)participatory scenariosunderstanding context of useproblem analysisproposed solutionspros and cons of solutionsstories, storyboards, narratives, indepth experiences by members of the project teamlowtechnology representationsunderstanding context of useearly designsdesign alternativesexamples of artifacts (current or future)designsinformal requirementsdocumentariesunderstanding context of useopportunity analysisindepth descriptionﬁday in the lifeﬂhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 175informality (to increase enduser participation) may also become a weakness (they do not look like formal engineering methods).addressing the problem of informality, kensing and munkmadsen (1993) described correspondences between a set of concrete, informal enduseraccessible methods and a second set of abstract, formal methods from software engineering. this work was pursued subsequently in a paper to introduce a formal participatory methodology (kensing et al., 1996) and eventually in a booklength treatment of participatory approaches to information technology (bødker et al., 2004).contextual inquiryoverviewunlike the preceding approaches, contextual inquiry is less concerned with egalitarian contributions by users and analysts and more concerned with structuring users™ indepth contributions to the work of the professional analysts (beyer and holtzblatt, 1998; holtzblatt and beyer, 1993; holtzblatt et al., 2004; wixon and ramey, 1996). contextual inquiry is a set of methods for informing analysis with the users™ context and working practices, and for interpreting those analyses into engineering requirements. several systematic booklength treatments of this welldeveloped methodology exist, so we provide only a brief summary here.the analytic work of contextual inquiry ˚ows smoothly into the synthetic work of contextual design (e.g., holtzblatt, 2003). for application to the largesystems work addressed in this report, we separate these two types of endeavor into a section on analysis in this chapter, and a second section on design in the following chapter.contextual inquiry pursues three major activities:1. contextual inquiryšconduct observations and interviews with users (including, in some treatments, a specialized ﬁcontextual interviewﬂ).2. interpretationšwork intensively with members of the development team to understand what was learned in the inquiry step. the interpretation step often focuses on a case study or a single individual at a time, in order to create ve relatively formal models of the work.3. afnity analysisšcombine the individualized interpretations and models into a more consolidated view, nding commonalities where appropriate and preserving individual perspectives.contextual inquiry begins with investigations in the users™ workplace. interviews and observations are conducted there, with an emphasis on partnership between the investigator and each individual user. the interviews humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.176 humansystem integration in system developmentand observations often include a summary statement by the investigator of what was learned, so that the user can correct or elaborate on the investigator™s new knowledge and interpretation.when the investigator returns to her or his team, the entire crossfunctional team is convened to discuss the ndings and to develop a shared interpretation of those ndings. in general, these meetings are strongly participative by team members and produce diverse types of informal and interim representations for team use, largely based on textual notations that are annotated and recongured during interpretative meetings. further such meetings are convened to consolidate data from multiple customers or multiple sites, with the goal of coconstructing afnity diagrams that provide a hierarchical organization of commonalities and differences across sites. more formal models of work and support technologies (see below) begin from these afnity diagrams.shared representationsin the course of these three activities, the contextual inquiry approach creates ve analytic models:1. flow modelša highlevel summary of work processes and communication patterns.2. sequence modelša detailed analysis of the steps required to perform a task.3. physical modelša literal description of the work context and constraints in terms of objects and spaces.4. cultural modelša conceptual description of the policies, working practices, attitudes, organizational contexts, and national or group contextsša second type of ﬁcontext and constraints.ﬂ5. artifact modelša detailed description of the materials and tools involved in the work.these models are created and elaborated through a series of wellunderstood methods, such as specic types of brainstorming, diagramming, and so on. the contextual inquiry approach is thus participatory in its initial phases and then is constructed to move from the informal to the formal and from the concrete to the abstract. for further details, see holtzblatt (2003) and holtzblatt et al. (2004).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 177contributions to the system design processcontextual inquiry produces documents that are strategically designed to be effective inputs to subsequent development stages. the ve models described above are written in the language of systems professionals, to inform their design and implementation work.strengths, limitations, and gapscontextual inquiry has been shown to be a highly effective set of practices for designing system context and requirements, as has been demonstrated in numerous commercial engagements. paradoxically, the thoroughness of its methodology can tend to require more research time and meeting or workshop time than the less formal participatory methods described earlier. the tradeoff is obvious: the participatory methods provide less formal, more open outcomes that emphasize the users™ unique knowledge, but that may require further interpretation and analysis by systems professionals; the contextual inquiry methods produce more formal, more closed outcomes that are more ready for adoption by systems professionals.event data analysisoverviewhuman performance in the context of complex systems is often measured in terms of outcome (number of errors, amount of time to complete task). these measures are important, but in most cases, not at a level of detail needed to provide diagnostic information about how to improve system design and overall humansystem integration. many of the methods used in upfront analysis for humansystem integration, such as those discussed thus far, produce information that is much richer than number of errors or response time, but they also tend to rely on user introspection, verbal reports, or judgments. for instance, some methods require the user or an observer to make judgments about performance in the context of a system. this could be in the form of a questionnaire, a test, or observer ratings. although they are a source of rich data, a downside of these methods is that some require the user to provide retrospective data, which may have become stale or poorly remembered over time. if one attempts to correct the problem of retrospective report by asking the users to reply while they are doing a task, then one is certain to disrupt the task itself; the act of selfreporting on the task changes the task. event data analysis (eda) offers an humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.178 humansystem integration in system developmentalternative that provides output richer than outcome measures, yet it can be less obtrusive and reliant on memory than questionnaires or surveys.event data analysis is largely a descriptive approach to the analysis and summary of data that take the form of observations or events that occur over time. the eda approach incorporates a variety of methods for collecting and reducing data. in the context of humansystem integration, it is particularly useful for observations collected via instrumentation (e.g., keystrokes, communication logs) over time. event data analysis is a bottomup approach, in that the analyst goes from data, to patterns in the data (often sequential patterns), to general descriptions, and ultimately to theory. event data analysis has much in common with data mining, although not all data used in event data analysis need to be ﬁminedﬂ (e.g., verbal reports); not all data that are mined take the form of events (e.g., document corpora); and not all event data that are mined are immediately useful for humansystem integration (e.g., google™s web crawling to update pagerank2 algorithms).the assumption behind event data analysis is that the descriptions of behavior (i.e., patterns of use, collaborative interactions) that result can inform system design or can be used to evaluate the impact of a new tool or system on human performance. the output can be a shared representation, a description (often graphical) of users™ behavior in context, as well as quantitative indices associated with that description. the richness of the event data affords a deeper look at the behavior behind effective or ineffective human performance and thus is valuable in reducing uncertainty and guiding humansystem integration. event data analysis is useful for deriving summaries of behavior (system, user, or both) in the context of the existing system. this information is useful, for example, in identifying interface bottlenecks, unused functionality, and patterns of expert or novice actions.shared representationsa set of instrumentcollected events typically requires data reduction for meaningful interpretation. multivariate statistical techniques or sequential data analyses are often applied to these data sets to reduce them to a presumably more meaningful form. datareduction methods, such as 2 pagerank is a numerical weighting assigned algorithmically to each element of a set of hyperlinked documents as an indication of its relative importance within the set. the pagerank is typically computed using an analysis of links to and from the documents to calculate document centrality.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 179figure 67 example of a pathnder network (r = innite; q = 9) based on conditional transition probabilities between events. bold numbers on nodes indicate event frequencies. numbers on links indicate transition probabilities between the two events. source: cooke, neville, and rowe (1996). used with permission of lawrence erlbaum associates.multidimensional scaling and pathnder network scaling,3 generate shared representations. for example, in figure 67 the pathnder datareduction procedure (schvaneveldt, durso, and dearholt, 1989) resulted in a graphical representation of word processing events (i.e., keystrokes or mouse clicks) with the most commonly occurring pairs of sequential events being directly linked (cooke, neville, and rowe, 1996). the pathnder method takes a set of distance estimates (in this case, probability of transitioning from one function to another in the keystroke sequence) and connects nodes (computer functions in this case) with direct links if they are on the shortest path between two nodes. this kind of description of keystrokes might reveal commonly used functions, unused functions, and common event sequences that should be taken into account in system design.3 pathnder network scaling is a structural modeling technique using algorithms that take estimates of the proximity between pairs of items as input and dene a network representation that preserves the most important links.permission was not granted to post this figure on the web. refer to the source or the printed book.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.180 humansystem integration in system developmenttable 64 examples of uses of event data analysisquestiontype of event datatype of data analysissample outcomeswhat does the operator do from moment to moment? what options are not used? what options precede the request for help? what action sequences occur often enough to be automated or assisted?keystrokes, mouse movements, click streams.frequency analysis.lag sequential analysis.pronet.usability data.frequency of actions and action sequences.specic sequential dependencies.what are the service demands made on a shared resource (like a server or a database)? what are critical dates or times of day? how can server/database trafc be anticipated or smoothed?hits on a web site.database accesses.server trafc.(while conventional server logs provide a very lowlevel view of these demands, instrumentation can provide a workoriented account of server demands.)frequency analysis.timeseries analysis.critical path analysis.highfrequency and lowfrequency service requests.prediction of server load and potential outages.redistribution of functionality.database redesigns.what are the current issues that the organization is grappling with? what is the organization™s current intellectual capital?userinitiated socialsoftware events and data, like tag creation and tag modication, blog entries, wiki entries, and current searches.lexical analysis.cluster analysis.social network analysis.identication of new trends.intelligence analysis.organizational models.what are people thinking and planning as they work? what confuses them?thinkaloud reports.verbal reports.paireduser testing.protocol analysis.descriptions of cognitive processes for that individual.confusing or errorprone aspects of the user experience.what is the communication network in the organization? who communicates with whom?communications events (email, chat, meeting attendance).social network analysis, via pathnder or ucinet.network graphs to show frequent communications patterns. identication of particular communication roles, such as organizer, interorganizational gatekeeper, etc.what is the context of critical events? how often do critical events occur and what events preceded and follow them?stream of video events (e.g., in an emergency room or air trafc control center). one or more recordings of shared radio frequencies among emergency responders.video analysis.exploratory sequential data analysis of video or audio streams.errors and nearmisses and events that are temporally related to them; ethnographic interpretation based on video records.how do people use the work space? what communication patterns or trafc patterns occur? how can the space be used more effectively or efciently?movement in an ofce space.frequencies.link analysis.cooccurrence of individuals in the same space.overused and underused areas, trafc patterns.workspace layout.uses of methodsin the context of cognitive work analysis, event data analysis can be especially useful for strategies analysis and social, organization, and cooperation analysis. in the context of organizational analysis, it has specic application in the descriptions of behavior. overall, event data analysis is a useful approach for systematizing observations and as such, is of value for dening the context of use in the early icm phase of exploration. for humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 181table 64 examples of uses of event data analysisquestiontype of event datatype of data analysissample outcomeswhat does the operator do from moment to moment? what options are not used? what options precede the request for help? what action sequences occur often enough to be automated or assisted?keystrokes, mouse movements, click streams.frequency analysis.lag sequential analysis.pronet.usability data.frequency of actions and action sequences.specic sequential dependencies.what are the service demands made on a shared resource (like a server or a database)? what are critical dates or times of day? how can server/database trafc be anticipated or smoothed?hits on a web site.database accesses.server trafc.(while conventional server logs provide a very lowlevel view of these demands, instrumentation can provide a workoriented account of server demands.)frequency analysis.timeseries analysis.critical path analysis.highfrequency and lowfrequency service requests.prediction of server load and potential outages.redistribution of functionality.database redesigns.what are the current issues that the organization is grappling with? what is the organization™s current intellectual capital?userinitiated socialsoftware events and data, like tag creation and tag modication, blog entries, wiki entries, and current searches.lexical analysis.cluster analysis.social network analysis.identication of new trends.intelligence analysis.organizational models.what are people thinking and planning as they work? what confuses them?thinkaloud reports.verbal reports.paireduser testing.protocol analysis.descriptions of cognitive processes for that individual.confusing or errorprone aspects of the user experience.what is the communication network in the organization? who communicates with whom?communications events (email, chat, meeting attendance).social network analysis, via pathnder or ucinet.network graphs to show frequent communications patterns. identication of particular communication roles, such as organizer, interorganizational gatekeeper, etc.what is the context of critical events? how often do critical events occur and what events preceded and follow them?stream of video events (e.g., in an emergency room or air trafc control center). one or more recordings of shared radio frequencies among emergency responders.video analysis.exploratory sequential data analysis of video or audio streams.errors and nearmisses and events that are temporally related to them; ethnographic interpretation based on video records.how do people use the work space? what communication patterns or trafc patterns occur? how can the space be used more effectively or efciently?movement in an ofce space.frequencies.link analysis.cooccurrence of individuals in the same space.overused and underused areas, trafc patterns.workspace layout.example, event data analysis can contribute to the development of system requirements by describing the current context of use. it also can be used to describe behavior in the context of a new design, thereby pitting old design against new, as might be helpful in the development and operation phases.event data analysis encompasses a family of methods differing on a variety of dimensions. a sample of possible applications of this approach appears in table 64. most salient to differentiating these methodologies is humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.182 humansystem integration in system developmentthe nature of the data or events that are recorded for analysis. events are discrete slices that occur within an ongoing stream of behavior. thus the data have temporal properties that lend themselves to sequential data analysis. some events that are recorded have been used primarily to understand the behavior of a single user interacting within a larger system. other events take a broader look at the collaboration among multiple users and nonhuman agents, which also occurs in the context of a larger system. examples of individually oriented event data analysis include verbal protocol analysis (e.g., ericsson and simon, 1984), video analysis (e.g., bødker, 1996), computer event analysis (e.g., carreira et al., 2004; cooke, neville, and rowe, 1996; vortac, edwards, and manning, 1994), eyehead movement analysis (e.g., salvucci and anderson, 2001), as well as physiological measures (sarter and sarter, 2003). event data analysis applied to collaboration includes communication and interaction analysis (e.g., bowers et al., 1998; kiekel, gorman, and cooke, 2004; olson, herbsleb, and rueter, 1994; paley, linegang, and morley, 2002). the nature of the events collected dictates the intrusiveness of event data analysis (e.g., verbal thinkaloud protocol events are more intrusive than logs of text chat). note, however, that a procedure that is not behaviorally intrusive, such as passive screenrecording, may nonetheless have signicant privacy problems that make it highly invasive of privacy for at least some users (e.g., tang et al., 2006).the application of event data analysis to collaboration is an interesting and fortuitous application for a number of reasons. just as thinking aloud and the verbal protocol that results is assumed to re˚ect cognitive processing at the individual level, event data analysis applied to teams is assumed to re˚ect cognition at the team level (though some assume that it is the teamlevel thinking; gorman, cooke, and winner, in press). indeed, this is the theoretical basis of distributed cognition (hutchins, 1995) and of the concept of the collective subject in activity theory (nardi, 1996). however, the beauty of this general approach applied to groups or teams is that the process that one would like to trace is more readily observed at the group level than at the individual level. that is, one cannot observe individual thought processes and so rely on verbal reports as an indirect measure. but groups communicate, interact, and (some would argue) engage in teamlevel cognitive processing as a matter of course, making communication events, and therefore teamlevel thinking, readily observable.although eda methods such as protocol analysis (ericsson and simon, 1984) and video analysis (bødker, 1996) have been around for some time, advances in computing power have made it possible to automate, speed up, and implement in real time many aspects of event data analysis. with this growth in technology, applications have similarly grown beyond user testing applications to problems in collaborative ltering, adaptive user proles, marketing, communications analysis, and even intelligence analyhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 183sis. for instance, tools like recording user input (kukreja, stevenson, and ritter, in press) create logs of user interface behavior, ideally suited for event data analysis. in addition, web 2.0 and the emerging concept of ﬁattention dataﬂ (i.e., where does the user spend time and effort?) promise to create enumerable possibilities for rich yet unobtrusive data collection.the methods and tools associated with event data analysis can be categorized by the methodological step in which each is used. steps include data collection, data analysis, data representation, and assessment and diagnosis. for some applications it may be sufcient to generate a shared representation, and in others it may be more informative to carry the analysis through to assessment and diagnosis. each of these steps depends on the intended use or application of event data analysis and is discussed in turn.data collectiondata collected as events range from verbal reports during thinking aloud and video or computer events to eye movements and other physiological measures. data can also be collected at the group, team, or organizational level. in the spirit of process tracing, the data are not onetime snapshots of individual or group performance (e.g., response time or accuracy) but are indices of a continuous stream of behavior or interactions. thus, the data recorded for this purpose can include physical interactions among group members (e.g., movement patterns in an ofce space), events that occur of a certain type that are relevant to the research question (e.g., meetings, phone calls, solitary work, breaks), events that occur strictly over the internet (emails, text messaging, chat), discourse (written, oral, or gestural), and other kinds of grouplevel verbal behaviors, such as storytelling and group narratives.the ultimate success of event data analysis is largely determined by the selection of data to record and the parsing of those data into events. meaningfulness of the resulting behavioral and collaborative patterns can depend on how data are parsed. although data collection is relatively straightforward and can be facilitated with tools, decisions about the nature of the data to be collected are not. for example, from whom is data collected? is it an expert user, a manager, a developer, or a novice? decisions like these should hinge on the questions that are asked. in addition, these decisions require experienced human intervention and are not well supported by technology.data analysisalthough the rich data needed for this approach can be gathered relatively easily and unobtrusively, there is a downside: that is, the data are rich humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.184 humansystem integration in system developmentand qualitative and identifying patterns and highlevel descriptions of behavior is a challenge, especially if undertaken manually. data transcription and coding of the type required to get started on communication analysis can take many more hours than the raw data took to collect. once the data are in a coded form, then an analytic method is applied to explore the data and look for patterns. thus, when it comes to event data, one chief goal of the data analysis is to reduce the data in a meaningful way.exploratory sequential data analysis (esda; sanderson and fisher, 1994) is a general approach to this problem that relies heavily on the use of sequential data analysis methods, such as lag sequential analysis or markov modeling. although lag sequential analysis and markov modeling are foundational tools of human factors, custom tools have also been developed (e.g., macshapa; shapa) to facilitate the data analysis process. recognition of statistical patterns in the data has become easier to automate, relieving the human coder of much of the burden. other foundational datareduction methods traditionally applied to similarity or relatedness judgments, rather than event data, have also been applied to help simplify event data analysis. techniques include multidimensional scaling (shepard, 1962a, 1962b), cluster analysis (shepard and arabie, 1979), and pathnder (schvaneveldt, durso, and dearholt, 1989). for example, pathnder has been adapted for use with event data (i.e., cooke, neville, and rowe, 1996) as well as for the analysis of communication ˚ow data (kiekel, gorman, and cooke, 2004). furthermore, event data have also been used to derive social networks, although certainly not the typical approach to social network analysis, which has relied more on human judgments regarding relationships (e.g., tyler, wilkinson, and huberman, 2005). these various analytic methods tend to focus on different aspects of the data and thus serve to reduce the data by highlighting different aspects.data representationthe descriptive analytic techniques, such as multidimensional scaling or pathnderbased communication analysis routines, often return extremely complex, though rich descriptions of behavior. patterns are not always easy to detect in the output by visual inspection. in the data representation step, the output from the analysis is presented to the analyst as a shared representation and in this regard is meant to facilitate interpretation. versions of the pathnder routine, for example, return linked nodes in a graphical format that can be spatially manipulated by the analyst. the application of visualization techniques and tools for these complex behavioral and interaction patterns is an area that is ripe for further research.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 185assessment and diagnosisthe preceding three steps result in a qualitative description of individual or collaborative behavior (sequence of eye movements, frequent chains of mouse clicks, who is talking to whom, how often individuals interact, bottlenecks, isolates, etc.), but up to this point there is no value placed on the description. one could imagine postulating the costs and benets of obvious characteristics of a description, such as an infrequent action, a bottleneck, or an isolate, and indeed these general evaluative interpretations can be made. metrics from social network analysis can also be adopted for the purpose of evaluating a procedural network representation. however, making the jump from description to some deeper and contextually meaningful interpretation of the description is the most challenging aspect of this process and the most difcult to automate.one approach is to map (in a very bottomup way) the descriptions within context onto other criterion measures (e.g., errors, speed, con˚ict, poor situation awareness, shared mental models). automation of this process would involve having a machine learn to discriminate behavioral patterns and attach meaning to them. for instance, a series of mouse clicks might be indicative of a specic erroneous mental model. this mental model could then be targeted for intervention. assessment and diagnosis move event data analysis from its purely descriptive status to serve an additional evaluative function.contributions to system design phasestable 65 describes how eda can be applied across the lifecycle phases. it can be used in exploration to gather information about existing conditions, in advance of engineering a new or enhanced system. for extable 65 lifecycle phases of the icm and edaphasemethodvariationexplorationedamay help scope problem; can base on expert judgment if no existing system.valuationedause to describe existing behavior; highlight obvious weaknesses, strengths.architectingedabegin to focus more on future behavioral repertoire; change to existing behavior patterns.developmentedaecan collect behavioral data with prototype and evaluate success of new design.operationedaegiven other criterion can collect data from users in beta testing to assess success.note: edae (evaluative) includes evaluative steps such as assessment and diagnosis.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.186 humansystem integration in system developmentample, capturing a series of keystrokelevel events can inform the analyst about the order in which operations are actually carried out, the sequence in which systems are accessed, and the communications (people, frequency, media) that are part of current work. this information can be used to nd problems, inefciencies, and opportunities for improvements. these data can also provide early indications of unanticipated usage patterns, which the alert analyst can ﬁharvestﬂ to create best practices or new product or feature proposals. in a more conservative riskmanagement perspective, these data can help analysts and their teams to solve problems that are actually occurring in real work, rather than expending resources on problems that are less important.eda can also be applied at the early development stages of humansystem integration: valuation and architecting. event data can be collected prior to a prototype if expert judgments are used in lieu of events. application in the early stages will reduce risk by providing information about typical user behavior or normative patterns of collaboration. systems developed with the framework of these behavioral patterns will avoid the risk of systems that are incompatible with the user or collaborative behavior, consequently avoiding costly redesign.behavioral patterns provide valuable information about ongoing individual behavior and the collaborative process, including strengths, weaknesses, and possible constraints for future design. by relying on expert judgment about behavior through participatory design, for example, rather than actual behavioral observations, these methods also become useful for descriptions of envisioned systems.application of eda in the later stages of system testing will draw attention to possible problems and provide guidance for selecting between two or more design alternatives (based on compatibility with human or collaborative behavior). this guidance also reduces the risk of the need for changes even later in system development or the even greater risk of failures of system productivity or safety.the more evaluative information, such as which behavioral repertoire is faster or more efcient or best for situation awareness, is useful in later phases of development, in order to test or compare possible designs. the technique in this instance provides a means of assessing individual performance. eda can similarly be used to assess collaborative performancešoften overlooked in favor of more general outcome or system performance. however, it can also provide a deeper, more explanatory level of analysis, regarding the effects of a design on behavior.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining opportunities and context of use 187strengths, limitations, and gapsrelative to some of the other methods for humansystem integration, eda has a number of unique advantages and disadvantages that should be considered along with the risk of not using it. one signicant advantage is that these data can be collected unobtrusively in the eld or operational setting. with more sophisticated tools, much of the processing and analysis of the data can also be done automatically and in real time. this is an advantage because it allows user data to be collected without interrupting users from their routine tasks, consequently avoiding changes in the results due to the interruption and maximizing user time.there are also costs. the denition of data events and the analysis and interpretation of the rich data collected require some expertise and time. this is particularly true for a new task. the costs incurred in these data denition and interpretation activities should decline as analysts gain experience working with a particular domain and task.another cost of this methodology is the associated ethical and privacy concerns when data collection can occur outside an operator™s awareness. the collection of much of the data described in this section raises new issues in security, privacy, and ultimately ethics. some organizations provide guidelines or policies in these areas, but even in those cases, there are many questions for which the researcher/practitioner/engineer must take responsibility. many systems inform the user that her or his data may be used for research purposes. for largescale systems, users often form a reasonable assumption that their small use of the system will be ﬁunder the radarﬂ of any research program. however, contemporary and nearfuture quantitative techniques address very large data sets and can easily nd individual users who match certain search criteria. thus, no one can be condently under the radar any longer, but most users are not aware of this change.finally, there are also risks. one obvious risk is that a focus on recordable, quantiable data may push other phenomena out of focus. for example, measuring the events that occur during a computerized work ˚ow may distract the team from looking at the noncomputerized workarounds and xups that may also be taking place. failing to observe these more qualitative, more difculttorecord events may lead in turn to several types of errors: (1) problems with the work ˚ow may go undetected if all that is measured is the work ˚ow itself and (2) training or education levels may be underestimated if the more demanding workaround activities are not recorded. thus, event data analysis is one tool in the tool box and should be used in a balanced way with other, more qualitative tools.a second risk was alluded to earlier in reference to data collection. these techniques will generate results regardless of the quality of the data. decisions about what data to collect, in what context, for how long, and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.188 humansystem integration in system developmentfrom whom are critical and nontrivial. without experienced decision makers, the analyst is in danger of experiencing the ﬁgarbage inœgarbage outﬂ dilemma and, depending on familiarity with the domain, may never recognize the limits of the data.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.7dening requirements and designdesign is fundamentally an innovative process. the methods discussed in this chapter are intended to support identication and exploration of design alternatives to meet the requirements revealed by analyses of opportunity space and context of use. the methods are not a substitute for creativity or inventiveness. rather they provide a structure and context in which innovation can take place. we begin with a discussion of the need for and the methods used to establish requirements based on the concept of usercentered design. the types of methods included here are work domain analysis, workload assessment, situation awareness assessment, participatory design; contextual design; physical ergonomics; methods for analyzing and mitigating fatigue, and the use of prototyping, scenarios, persona, and models and simulations. as with the descriptions in chapter 6, each type of method is described in terms of uses, shared representations, contributions to the system design phases, and strengths, limitations, and gaps. these methods are grouped under design because their major contributions are made in the design phase; however, it is important to note that they are also used in dening the context of use and in evaluating design outcomes as part of system operation. figure 71 provides an overview.189humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.190 humansystem integration in system development usability requirements work domain analysis workload assessment participatory design contextual design physical ergonomics situation awareness methods for mitigating fatigue prototyping scenarios personas models and simulationsample shared representationsproducedrepresentativeset of methodswho™s involved?design experts and other stakeholdersdomain practitionershsi activitiesdefining opportunitiesand context of usedefining requirementsand designevaluationhsi activities, participants, methods, and shared representationsł graphic representations of domain goals, means, and constraintsł alternative network representationsł prose descriptions of the characteristics of the work domainł concept mapsł graphs of workload as a function of time or task progressł pert chartsł gantt chartsł stories, storyboards, narratives, and use casesł low technology representations ł theatrical methodsł workshop outcomes ł formal requirements and specificationsł vision statementsł descriptions of current or future enduser work environmentsł physiological tests ł subjective instruments such as ratings of perceived exertions ł checklists and rating scalesł a dynamic simulation (human digital modeling) ł data describing the results of sa tests ł alertness models ł list of the opportunities 71figure 71 representative methods and sample shared representations for dening requirements and design.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 191usability requirementsoverviewinadequate user requirements are a major contributor to project failure. the most recent chaos report by the standish group (2006), which analyzes the reasons for technology project failure in the united states, found that only 34 percent of projects were successful; 15 percent completely failed and 51 percent were only partially successful.five of the eight (highlighted below) most frequently cited causes of failure were poor user requirements:1. 13.1 percent, incomplete requirements2. 12.4 percent, lack of user involvement3. 10.6 percent, inadequate resources4. 9.9 percent, unrealistic user expectations5. 9.3 percent, lack of management support6. 8.7 percent, requirements keep changing7. 8.1 percent, inadequate planning8. 7.5 percent, system no longer neededamong the main reasons for poor user requirements are (1) an inadequate understanding of the intended users and the context of use, and (2) vague usability requirements, such as ﬁthe system must be intuitive to use.ﬂfigure 72 shows how usability requirements relate to other system requirements. usability requirements can be seen from two perspectives: characteristics designed into the product and the extent to which the product meets user needs (quality in use requirements).there are two types of usability requirements. usability as a product quality characteristic is primarily concerned with ease of use. iso/iec 91261 (international organization for standardization, 2001) denes usability in terms of understandability, learnability, operability, and attractiveness. there are numerous sources of guidance on designing user interface characteristics that achieve these objectives (see the section on guidelines and style guides under usability evaluation). while designing to conform to guidelines will generally improve an interface, usability guidelines are not sufciently specic to constitute requirements that can be easily veried. style guides are more precise and are valuable in achieving consistency across screen designs produced by different developers. a style guide tailored to project needs should form part of the detailed usability requirements.at a more strategic level, usability is the extent to which the product humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.192 humansystem integration in system developmentsystem requirementshardware and software requirementsother systemrequirementsproductrequirementsdevelopmentrequirementsinherentpropertyrequirementsassignedpropertyrequirementsfunctional requirementsother quality requirementsusability requirementsqualityrequirementsmanagerial requirements including, for example,requirements for price, delivery date, product future, andproduct supplierfor example, requirements for data and business processesdevelopment process requirementsdevelopment organization requirementscontext of use constraintsquality in userequirements72meets user needs. iso 924111 (international organization for standardization, 1998) denes this as the extent to which a product is effective, efcient, and satisfying in a particular context of use. this highlevel requirement is referred to in iso software quality standards as ﬁquality in use.ﬂ it is determined not only by the ease of use, but also by the extent to which the functional properties and other quality characteristics meet user needs in a specic context of use.in these terms, usability requirements are very closely linked to the success of the product.ł effectiveness is a measure of how well users can perform the job accurately and completely.ł efciency is a measure of how quickly a user can perform work and is generally measured as task time, which is critical for productivity.ł satisfaction is the degree to which users like the productša subjective response that includes the perceived ease of use and usefulness. satisfaction is a success factor for any products with discretionary use, and essential to maintain workforce motivation.figure 72 classication of requirements.source: adapted from iso/iec 25030 (international organization for standardization, 2007).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 193uses of methodsmeasures of effectiveness, efciency, and satisfaction provide a basis for specifying concrete usability requirements.measure the usability of an existing systemif in doubt, the gures for an existing comparable system can be used as the minimum requirements for the new system. evaluate the usability of the current system when carrying out key tasks, to obtain a baseline for the current system. the measures to be taken would typically includeł success rate (percentage of tasks in which all business objectives are met).ł mean time taken for each task.ł mean satisfaction score using a questionnaire.specify usability requirements for the new systemdene the requirements for the new system, including the type of users, tasks, and working environment. use the baseline usability results as a basis for establishing usability requirements. a simple requirement would be that when the same types of users carry out the same tasks, the success rate, task time, and user satisfaction should be at least as good as for the current system.it is useful to establish a range of values, such asł the minimum to be achieved,ł a realistic objective, andł the ideal objective (from a business or operational perspective).it may also be appropriate to establish the usability objectives for learnability, for example, the duration of a course (or use of training materials) and the user performance and satisfaction expected both immediately after training and after a designated length of use.it is also important to dene any additional requirements for user performance and satisfaction related to users with disabilities (accessibility), critical business functions (safety), and use in different environments (universality).depending on the development environment, requirements may, for example, either behumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.194 humansystem integration in system developmentł iteratively elaborated as more information is obtained from usability activities, such as paper prototyping during development, orł agreed by all parties before development commences and subsequently modied only by mutual agreement.test whether the usability requirements have been achievedsummative methods for measuring quality in use (see chapter 8) can be used to evaluate whether the usability objectives have been achieved. if any of the measures fall below the minimum acceptable values, the potential risks associated with releasing the system before the usability has been improved should be assessed. the results can be used to prioritize future usability work in subsequent releases.shared representationsthe common industry specication for usability requirements (theofanos, 2006) provides a checklist and a format that can be used initially to support communication between the parties involved to obtain a better understanding of the usability requirements. when the requirements are more completely dened, it can be used as a formal specication of requirements. these requirements can subsequently be tested and veried.the specication is in three parts:1. the context of use: intended users, their goals and tasks, associated equipment, the physical and social environment in which the product will be used, and examples of scenarios of use. an incomplete understanding of the context of use is a frequent reason for partial or complete failure of a system when implemented. the context of use is composed of the characteristics of the users, their task, and the usage environment. there are several methods that can be used to obtain an adequate understanding of this type of information (see chapter 6).2. usability measures: effectiveness, efciency, and satisfaction measures for the main scenarios of use with target values when feasible.3. the test method: the procedure to be used to test whether the usability requirements have been met and the context in which the measurements will be made. this provides a basis for testing and verication.the context of use should always be specied. the importance of specifying criteria for usability measures (and an associated range of acceptable values) will depend on the potential risks and consequences of poor usability.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 195communication among members of the development teamthis information facilitates communication among the members of the development or supplier organization. it is important that all concerned groups in the supplier organization understand the usability requirements before design begins. benets include the following:ł reducing risk of product failure. specifying performance and satisfaction criteria derived from existing or competitor systems greatly reduces the risk of product failure as a result of releasing a product that is inferior to existing or competitor systems.ł reducing the development effort. this information provides a mechanism for the various concerned groups in the customer™s organization to consider all of the requirements before design begins and reduces later redesign, recoding, and retesting. review of the requirements specied can reveal misunderstandings and inconsistencies early in the development cycle, when these issues are easier to correct.ł providing a basis for controlling costs. identifying usability requirements reduces the risk of unplanned rework later in the development process.ł tracking evolving requirements by providing a format to document usability requirements.communication between customers and suppliersa customer organization can specify usability requirements to accurately describe what is needed. in this scenario, the information helps supplier organizations understand what the customer wants and supports the proactive collaboration between a supplier and a customer.specication of requirementswhen the product requirements are a matter for agreement between the supplier and the customer, the customer organization can specify one or more of the following:ł intended context of use,ł user performance and satisfaction criteria, andł test procedure.the common industry specication for usability requirements provides a baseline against which compliance can be measured.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.196 humansystem integration in system developmentcontributions to system design phasesusability requirements should be integrated with other systems engineering activities. for example, the iso/iec 15288 standard (international organization for standardization, 2002) for system lifecycle processes includes the usercentered activities in the stakeholder requirements denition process as shown in box 71.box 71 usercentered activities for stakeholder requirementsł identify the individual stakeholders or stakeholder classes who have a legitimate interest in the system throughout its life cycle.ł elicit stakeholder requirements. stakeholder requirements are expressed in terms of the needs, wants, desires, expectations, and perceived constraints of identied stakeholders.ł scenarios are used to analyze the operation of the system in its intended environment and to identify requirements that may not have been formally specied by any of the stakeholders, for example, legal, regulatory, and social obligations.ł the context of use of the system is identied and analyzed. included in the context analysis are the activities that users perform to achieve system objectives, the relevant characteristics of the endusers of the system (e.g., expected training, degree of fatigue), the physical environment (e.g., available light, temperature) and any equipment to be used (e.g., protective or communication equipment). the social and organizational in˚uences on users that could affect system use or constrain its design are analyzed when applicable.ł identify the interaction between users and the system. usability requirements are determined, establishing, as a minimum, the most effective, efcient, and reliable human performance and humansystem interaction. when possible, applicable standards, for example iso 9241 series, and accepted professional practices are used in order to dene (1) physical, mental, and learned capabilities; (2) workplace, environment, and facilities, including other equipment in the context of use; (3) normal, unusual, and emergency conditions; and (4) operator and user recruitment, training, and culture.ł establish with stakeholders that their requirements are expressed correctly.ł dene each function that the system is required to perform and how well the system, including its operators, is required to perform that function.ł dene technical and quality in use measures that enable the assessment of technical achievement.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 197strengths, limitations, and gapsestablishing highlevel usability requirements that can be tested provides the foundation for a mature approach to managing usability in the development process. but while procedures for establishing these requirements are relatively well established in standards, they are not widely applied or understood, and there is little guidance on how to establish more detailed user interface design requirements.with most emphasis in industry on formative evaluation to improve usability, there is often a reluctance to invest in the summative evaluation in the nal development of the project. formal summative evaluation in terms of established usability criteria is needed to determine valid usability.as much of systems development is carried out on a contractorsupplier basis (even if the supplier is internal to the customer organization), it is for the contractor to judge whether the investment in establishing and validating usability requirements is sufcient to justify the associated risk reduction.usability requirements can also provide signicant benets in clarifying user needs and providing explicit useroriented goals for development, even if they cannot be exhaustively validated. if there are major usability problems, even the results from testing three to ve participants would be likely to provide advance warning of a potential problem (for example, if none of the participants can complete the tasks, or if task times are twice as long as expected).work domain analysisoverviewamong the questions that arise when facing the design of a new system are the following: what functions will need to be accomplished? what will be automated, and what will be performed by people? if people will be involved, how many people will it take, and what will be their role? what information and controls should be made available, and how should they be presented to enhance performance? what training is required?one approach to answering these questions is to start with a list of the tasks to be accomplished and perform task analyses to identify the sequence of actions entailed, the information and controls required to perform those actions, and the implications for number of people and training required. this approach works well when the tasks to be performed and conditions of use can be easily specied a priori (e.g., automated teller machines). however, in the case of highly complex systems (e.g., a process control humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.198 humansystem integration in system developmentplant, a military command and control system) unanticipated situations and tasks inevitably arise.work domain analysis techniques have been developed to support analysis and design of these more complex systems, in which all possible tasks and situations cannot be dened a priori. work domain analysis starts with a functional analysis of the work domain to derive the functions to be performed and the factors that can arise to complicate performance (woods, 2003). the objective is to produce robust systems that enable humans to effectively operate in a variety of situationsšboth ones that have been anticipated by system designers and ones that are unforeseen (e.g., safely shutting down a process control plant with an unanticipated malfunction).work domain analysis methods grew out of an effort to design safer and more reliable nuclear power plants (rasmussen, 1986; rasmussen, pejtersen, and goodstein, 1994). analysis of accidents revealed that operators in many cases were faced with situations that were not adequately supported by training, procedures, and displays because they had not been anticipated by the system designers. in those cases, operators had to compensate for information or resources that were inadequate in order to recover and control the system. this led rasmussen and his colleagues to develop work domain analyses methods to support development of systems that are more resilient in the face of unanticipated situations.a work domain analysis represents the goals, means, and constraints in a domain that dene the boundaries within which people must reason and act. this provides the framework for identifying functions to be performed by humans (or machines) and the cognitive activities those entail. displays can then be created to support those cognitive activities. the objective is to create displays and controls that support ˚exible adaptation by revealing domain goals, constraints, and affordances (i.e., allowing the users to ﬁseeﬂ what needs to be done and what options are available for doing it).a work domain analysis is usually conducted by creating an abstraction hierarchy according to the principles outlined by rasmussen (1986). a multilevel goalmeans representation is generated, with abstract system purposes at the top and concrete physical equipment that provides the specic means for achieving these system goals at the bottom. in many instances, the levels of the model include functional purpose (a description of system purposes); abstract function (a description of rst principles and priorities); generalized function (a description of processes); physical function (a description of equipment capabilities); and physical form (a description of physical characteristics, such as size, shape, color, and location).work domain analyses do not depend on a particular knowledge acquisition method. any of the knowledge acquisition techniques covered in chapter 6 can be used to inform a work domain analysis. in turn, the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 199results of the work domain analysis provide the foundation for further analyses to inform humansystem integration.there are a growing number of hsi approaches that are grounded in a work domain analysis. a prominent example is cognitive work analysis (rasmussen, 1986; rasmussen et al., 1994; vicente, 1999) that uses work domain analysis as the foundation for deriving implications for system design and related aspects of humansystem integration, including function allocation, display design, team and organization design, and knowledge and skill training requirements. burns and hajdukiewicz (2004) provide design principles and examples of creating novel visualizations and support systems based on a work domain analysis.applied cognitive work analysis provides a stepbystep approach for performing and linking the results of a work domain analysis to the development of visualizations and decisionaiding concepts (elm et al., 2003). these includeł using a functional abstraction network to capture domain characteristics that dene the problem space confronting domain practitioners.ł overlaying cognitive work requirements on the functional model as a way of identifying the cognitive demands/tasks/decisions that arise in the domain and require support.ł identifying information/relationship requirements needed to support the cognitive work identied in the previous step.ł specifying representation design requirements that dene how the information/relationships should be represented to practitioner(s) to most effectively support the cognitive work.ł developing presentation design concepts that provide physical embodiments of the representations specied in the previous step (e.g., rapid prototypes that embody the display concepts).each design step produces a design artifact that collectively forms a continuous design thread providing a traceable link from cognitive analysis to design.workcentered design (eggleston, 2003; eggleston et al., 2005) is another example of an hsi approach that relies on a work domain analysis. key elements of workcentered design include (a) analysis and modeling of the demands of work, (b) design of displays/visualizations that reveal domain constraints and affordances, and (c) use of workcentered evaluations that probe the ability of the resultant design to support work across a representative range of work context and complexities.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.200figure 73 selected portions of a work domain representation for a pressurized water reactor nuclear power plant.source: roth et al. (2001). used with permission of lawrence erlbaum associates.permission was not granted to post this figure on the web. refer to the source or the printed book.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 201shared representationsthe shared representation produced as output from a work domain analysis is typically a graphic representation of domain goals, means, and constraints. figure 73 provides an example of a graphic work domain representation that was developed for a nuclear power plant design. the work domain representation species the primary goals of the plant (generate electricity and prevent radiation release), the major plant functions in support of those goals (level 2 functions in the gure) and the plant processes available for performing the plant functions (levels 3 and 4 in the gure). level 4 species the major engineered control functions available for achieving plant goals. this is the level at which manual and automatic control actions can be specied to affect goal achievement.while work domain analyses have often adopted rasmussen™s abstraction hierarchy formalism, the results of a work domain analysis can take multiple forms. these include alternative network representations (e.g., elm et al., 2003), prose descriptions of the characteristics of the work domain, and concept maps.uses of methodswork domain analyses complement more traditional task analysis approaches. traditional task analyses model how tasks in a domain are performed or should be performed. work domain analyses model the problem space in which reasoning and action can take place. the work domain representation provides the basis for deriving the information required to enable domain practitioners to understand and reason about the domain at different levels of abstraction, ranging from domain purposes (e.g., prevent radiation release) all the way down to the particular physical systems (e.g., pumps and valves) available for achieving the domain goals.the output of a work domain analysis is used to inform further analyses that feed different elements of humansystem integration. table 71 provides a summary of the major elements of a cognitive work analysis that provide traceable links between the results of the work domain analysis and implications for system design, including function allocation decisions, team and organization design, design of physical and information systems including displays, personnel selection and training, development of procedures, specication of test cases to drive system evaluation, and conduct of human reliability analyses as part of riskbased analyses.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.202 humansystem integration in system developmenttable 71 analytic tools involved in the cognitive work analysis methodologyphases of cognitive work analysisdescriptionwork domain analysisanalyzes the purposes and physical context in which domain practitioners operate. this includes a description of domain goals, means available for achieving those goals, and constraints (e.g., physical constraints, sociopolitical constraints). control task analysisidenties what needs to be done in a work domain. this includes a description of the work situations that can arise and the work functions that need to be performed, independent of who (person or machine) will perform them or the detailed strategies to be used.strategies analysisanalysis of strategies for making decisions and carrying out tasks, independent of who will carry them out.social organization and cooperation analysisfocuses on who can carry out the work, how it can be distributed or shared, and how it can be coordinated. this includes allocation of work among individuals and/or machines, organization of individuals into teams and larger organizational units, and communication and coordination requirements.worker competencies analysisanalysis of perceptual and cognitive requirements of workers (e.g., skills, knowledge, attitudes) to foster understanding and reduce workload.use of work domain analysis in the port security case studywork domain analysis has been an integral part of the port security hsi work described in chapter 5. one recent application involved determining potential technology insertion points for cargo screening at seaports where containers move directly from ship to rail, without exiting through a truck gate. in order to evaluate this domain comprehensively, interviews were conducted with terminal operations managers, physical site maps were collected, and terminal operations walkthroughs were conducted. the information was synthesized into descriptions of current operations at each of the terminals and rail yards, with a focus on identifying common and contrasting operational practices, speed of operations, overall time requirements for ship servicing, dwell time of containers in storage stacks, labor and equipment requirements, potential radiation portal screening choke points, and issues related to the operational impact of screening at these locations. the ndings were used to dene screening concepts that would maximize threat detection while minimizing impact on commerce.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 203other example applicationsone of the strengths of work domain analysis methods is their ability to drive the design of novel visualizations tailored to the demands of the work (burns and hazdukiewicz, 2004). successful applications range from process control (roth et al., 2001; jamieson and vicente, 2001), to aircraft displays (dinadis and vicente, 1999), to medical device applications (lin, vicent, and doyle, 2001), to military command and control (martinez, bennett, and shattuck, 2001; potter et al., 2002), to network management (duez and vicente, 2005; burns et al., 2000), and to defense against cyber war (gualtieri and elm, 2002). in each case, the approach yielded novel decision support concepts that were netuned to the cognitive work requirements of the domain and markedly different from traditional displays in the domain.one example drawn from a process control application is a large wallmounted group view display intended to enable power plant control room teams to maintain broad situation awareness of the status of the plant. the goal was to increase the ability of operators to quickly assess plant state and effectively control the plant in both normal and abnormal condition.the content and organization of the group view display was based on a work domain analysis (see figure 74). the group view display was organized around the major plant functions that need to be achieved to maintain safety and power generation goals, and the physical processes that support them. the objective was to enable operators to rapidly assess whether the major plant functions are being achieved and the state of active plant processes that are supporting those plant functions. in cases of plant disturbances, in which one or more of the plant goals are violated, a functional representation allows them to assess what alternative means are available for achieving the plant goals.a formal evaluation study demonstrated that the functionally organized overview display was more effective and was preferred by operators over a more conventional overview display that utilized a physical plant mimic as the organizational scheme. teams performed signicantly better with the functionally organized overview display than the more conventional physical mimic display in identifying target events (24percent improvement) and diagnosing plant disturbances (27percent improvement) (roth et al., 2001).the results illustrate the value of work domain analysis in deriving the critical goals, means, and constraints in the domain that impact decision making and in generating novel displays that effectively communicate these factors to support individuals and teams.work domain analyses promote design of novel visualizations that enable practitioners to readily apprehend and assimilate domain information humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.204figure 74 schematic representation of a wallmounted group view display for a compact power plant control room derived from a cognitive work analysis approach. source: roth et al. (2001). used with permission of lawrence erlbaum associates.permission was not granted to post this figure on the web. refer to the source or the printed book.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 205required to support complex decisions (burns and hazdukiewicz, 2004). one recent example is a workcentered support system visualization that was developed to support dynamic mission replanning in a military airlift organization (roth et al., 2006). a work domain analysis identied domain factors that enter into and complicate airlift mission planning decisions, including the need to match loads to currently available aircraft, obtain diplomatic clearance for landings in and ˚ights over foreign nations, balance competing airlift demands, and conform to aireld and aircrew constraints. although existing information systems included all the relevant data, operational personnel had to navigate across multiple tabular displays to extract and mentally collate the necessary information. the work domain analysis provided the basis for design of a novel timeline display that enables operational personnel to graphically ﬁseeﬂ the relationships between mission plan elements and resource constraints (e.g., aireld operating hours, durations of diplomatic clearances, crew rest requirements) to detect and address violations. a formal evaluation comparing performance with the timeline display to performance with the legacy system established signicant improvement in performance with the timeline display (roth et al., 2006).contributions to system design phasesa work domain analysis is usually performed at several levels of detail, depending on the stage of system development and complexity of the system being analyzed. a work domain analysis is performed as a preliminary analysis to identify information needs, critical constraints, and information relationships that are necessary for successful action and problem management within the domain. as the design evolves, the work domain analysis can be deepened and used to inform display design, function identication and allocation decisions, team and organization design, as well as identication of knowledge and skills (e.g., accurate system mental models) that are needed to effectively support performance in the domain.the application of work domain analysis throughout the hsi design cycle has been successfully illustrated by neelam nakar and her colleagues, who have been applying work domain analysis and cognitive work analysis methods to the design of a rstofakind australian awacsstyle air defense platform called the airborne early warning and control (naikar and sanderson, 1999, 2001; naikar et al., 2003; naikar and saunders, 2003; sanderson et al., 1999; sanderson, 2003). their work has demonstrated the usefulness of work domain analysis throughout the system design cycle, including:ł evaluation of alternative platform design proposals offered by different vendors.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.206 humansystem integration in system developmentł determination of the best crew composition for a new platform.ł denition of training and training simulator needs.ł assessment of risks associated with upgrading existing defense platforms.work domain analyses have been similarly successfully employed to provide early input into the hsi issues in a number of largescale rstofakind projects, including the design of a nextgeneration power plant (roth et al., 2001); a nextgeneration u.s. navy battleship (bisantz et al., 2003; burns, bisantz, and roth, 2004), and a nextgeneration canadian frigate (burns, bryant, and chalmers, 2000).strengths, limitations, and gapsa primary strength of work domain analysis is in emphasizing the importance of uncovering and representing domain characteristics and constraints that impact cognitive and collaborative work, as well as in guiding the design of systems that are netuned to supporting the work demands and enabling domain practitioners to respond adaptively to a broad range of situations. it complements traditional sequential task analyses approaches by providing explicit shared representation of domain goals, characteristics, and constraints (miller and vicente, 1999; bisantz et al., 2003).a limitation of work domain analysis methods that is often pointed to is that it can be resourceintensive to exhaustively map the characteristics and constraints of a domain. however, as multiple projects have shown, it is not necessary to perform an exhaustive domain analysis to reap the benets (e.g., bisantz et al., 2003). a work domain analysis can be performed at different levels of detail, depending on the complexity of the system being analyzed and the phase of analysis. a preliminary, highlevel work domain analysis can be performed early in the hsi process to identify information needs, critical constraints, and information relationships that are necessary for successful action and problem management in the domain. as the design evolves, the work domain analysis can be elaborated.a related strength of work domain analysis methods is that it encourages explicit links between analysis and design via intermediate design artifacts. as the design evolves, these artifacts can be expanded and modied to provide a tracable link between domain demands, cognitive and performance requirements, and system features intended to provide the requisite support.one of the current gaps that limit the impact of work domain analysis methods is the paucity of computational tools to facilitate analysis and serve as a core living repository of domain knowledge that could be drawn on throughout the system life cycle. while there has been some progress on humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 207tool development, such as the work domain analysis workbench (skilton, cameron, and sanderson, 1998) and the cognitive systems engineering tool for analysis tool, more comprehensive and robust tools are needed.workload assessmentoverviewone of the most common issues that arise in complex system design is estimating whether the aggregate workload associated with the tasks assigned to system users will result in too much to do in the time available, leading to stress, unreliable performance, or, in some cases, system failure. workload comes in different varieties and may be assessed from many different perspectives.for tasks involving signicant physical effort, physical workload is an ergonomic issue and in sustained task performance is usually measured in terms of oxygen consumption, or heart rate. prediction of physical workload depends on having measurement results from other related activities and conditions and estimating the differences between the known results and the postulated activity. guidelines are available to assess excessive physical workload.structurally, the human limbs and eyes can be directed to only one location at a time, and excessive workload can result from a requirement that they be directed to too many places for the time available or that they need to be in different places at the same time. speech communication is similarly limited. assessing this kind of structural interference requires estimates or measurements of the time required for the various activities required of the limbs, eyes, and voice in each task, laying them out in sequence, subject to temporal constraints, and evaluating the potential con˚icts.the most challenging evaluation is of mental workload. humans can generally direct their attention to only one task or activity at a time. that is not to say that one cannot sometimes process, to some level of completeness, multiple streams of information, especially when they are coordinated or relate to the same task. there is a large literature on attention, attention management, and multitasking that is beyond the scope of this report (see, for example, chafn, anderson, and martin, 1999; wickens and hollands, 1999; and charlton, 2002).the distinctions among these types may become blurred. thinking is often accompanied by visual exploration, and it is difcult to distinguish the structural constraint of where the eyes are looking from the mental load of reasoning about what is seen. demanding physical effort may capture attention that could otherwise be directed to cognitive task performance.predicting mental workload has proved daunting, but there are some humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.208 humansystem integration in system developmentmodeling techniques that have been applied. most depend on having the results of a detailed task analysis, requiring an understanding of the cognitive components of the task and estimates of the time that will be associated with each task element. mccracken and aldrich (1984) dened the visual, auditory, cognitive, and perceptualmotor load associated with a collection of common elemental tasks, such as reading an instrument or operating a control. then, after making corresponding estimates of the time required for each task element in context, they used task analysis results to bring together the elemental components into estimates of the aggregate loads as a function of time on each modality. this basic approach has also been used in a variety of modeling contexts, including network models and more detailed human performance simulations (laughery and corker, 1997).when prediction is not possible or leads to uncertain results, it is necessary to undertake a study to estimate mental workload from actual measurements. there are fundamentally four kinds of measurements and analysis that have been used: (1) varying the task load corresponding to the range of expected task conditions (e.g., pace of input demand, such as air trafc load, or complexity of environment, such as urban versus rural road conditions) and evaluating the functional relation between task performance and task load; (2) introducing independent competing secondary tasks and measuring the quality of performance on the secondary task in the presence of the task under study; (3) asking the user to estimate perceived workload while performing the task or immediately afterward (i.e., subjective assessment, using tools such as the nasa tlx scales; hart and staveland, 1988); and (4) employing physiological measures, such as pupil diameter, eyeblink rate, evoked potential responses, or heart rate. there are numerous summary references that document these methods, such as tsang and wilson (1997) and hancock and desmond (2001).uses of methodwhen individual tasks are time sensitive or when the system users are subjected to the demands of multitasking, excessive workload is one of the paramount issues that can degrade system performance. whenever a new system is designed or revised, it is important to consider the impact of the design on user workload. workload estimates are also needed in job designšthe assembly of tasks into jobs. workload is a key component in preparing estimates of needed manpower or, when there is a mandate to reduce staff, workload estimates are the most important consideration. ultimately, workload is re˚ected in the personnel requirements forecast. it is an important area for coordination across the hsi domains.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 209shared representationsthe primary shared representations are graphs of workload as a function of time or task progress and pert charts (a network diagram in which milestones are linked by tasks) or gantt charts (bar charts that illustrate a project schedule). these shared representations illustrate the timelines of activities, showing where overlaps occur, with highlights showing phases in which the workload exceeds limits. for descriptions of these tools, see modell (1996).however, in most cases the output of studies assessing workload is expressed in an experiment report. whenever possible the estimated workload should be compared with acceptable limits.contributions to system design phasesin a typical system design, consideration of workload begins with the initial task analysis and context of use assessment. in early stages, the estimates will be largely qualitative. the aspects of the design are identied that may be workload sensitive or where overload presents substantial task completion or safety risk. as the design matures, the workload estimates should become more quantitative, and condence in the estimates will improve. when designs have reached the stage of completion in which a simulation of the task or of alternative task designs can be built, modeling studies or humanintheloop evaluations can be undertaken to estimate the workload of critical phases of the operation or critical elements of the system (see the section below on models and simulations). these studies will contribute to the manpower and personnel domains as well and should be coordinated with specialists in those areas. measuring workload is also important during summative test and evaluation stages of a project.strengths, limitations, and gapsthe denition, measurement, and prediction of workload, particularly mental workload, has been on the human factors research agenda for more than 30 years. measurement protocols and modeling approaches are available. it is much harder to dene acceptable limits, because these are dependent on the measures used and there is no standardization of the measures, at least for mental workload. using them requires the expertise of human factors professionals. all of the methods provide only approximate answers until the full system design is complete and the workload of using the real system can be evaluated.objective measures are usually to be preferred, but they require more effort to instrument and apply to simulated or real task performance. subjective methods have been shown to be reliable if standardized questionhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.210 humansystem integration in system developmentnaires are used. users can report only their perceptions and, under stressful conditions, perceived workload may be more important than objective workload requirements.there is a need for more collaboration among the specialists of the manpower, personnel, and human factors domains to ensure that the studies that are undertaken meet the requirements of all these stakeholders. suitable shared representations are not well developed. workload models can produce pert chartœlike representations that are useful for detailed analysis of operational concepts, but the output of most workload studies is simply an experiment report. new visualizations are required that are grounded in data but that present it in a form that allows all stakeholders to understand not only what the recommendations are, but also how they are supported by the data.participatory designoverviewthe preceding sections of this chapter have emphasized design as conducted by professional designers and engineers. this section focuses on design as a hybrid activity (see, e.g., muller, 2003) conducted by professionals and endusers together, as codesigners. much of the background for these concepts was provided in the participatory analysis section of chapter 6. we restrict the discussion here to designrelated concepts within that more general framework.the principal focus of participatory design has been twofold (blomberg et al., 2003; bødker et al., 2004; greenbaum and kyng, 1991; kyng and matthiassen, 1997; muller, haslwanter, and dayton, 1997; muller and kuhn, 1993; schuler and namioka, 1993):1. to present design options clearly and understandably to endusers and2. to provide the means for endusers to make changes in those design options.this overall philosophy means that endusers are more involved in design and development than is the case in conventional treatments, in which endusers tend to be consulted during requirements elicitation, and again during usability or acceptance testing. by contrast, participatory design typically involves iterative engagements with users as rstclass participants at multiple, strategically chosen moments during the specicationdesignevaluation processes. when appropriate, this approach supplements the knowledge of engineers and professional designers with the work domain humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 211knowledge of the endusers themselves, for a better informed, more efcient development process that typically requires fewer iterations to achieve targeted levels of usability, user satisfaction, and user acceptance.participatory design work has focused on issues of theory, context, and practice (for a summary, see levinger, 1998). in this report, we focus on six sets of practices that have been shown to provide sustained value in system development (for encyclopedic reviews of over 70 participatory practices, see bødker et al., 2004; muller, 2003; muller, haslwanter, and dayton, 1997).methods and shared representationsscenariosthe analysis phases of scenariobased methods are noted in the previous chapter (carroll, 1995, 2000; carroll, rosson, and carroll, 2002b, 2003). these activities continue in design. one of the strongest ways to describe a revised or new design is through a story of that design in use. scenariobased design is based around such stories. scenariobased design builds on the problem statement through the following steps:ł a set of activity designs (literally, actionoriented scenarios of future use) are constructed and evaluated with endusers. the claims from the previous step (i.e., assertions of value to the endusers) can be used to structure the evaluation.ł an information design is proposed, based on the approved activity designs. each activity design becomes a reference model for the evaluation of each information design. the information design provides a more detailed perspective on the narrative of the activity design, and is itself a more rened scenario of future use. again, the claims from the participatory analysis can be used to structure the evaluation.ł a more detailed interaction design is developed, based on a rened and stabilized information design. each interaction design is an even more rened and developed scenario of future use. the action designs remain the reference models against which the interaction design is evaluatedšagain with the potential aid of the claims from the participatory analysis.in these ways, scenariobased design produces a structured series of narratives, each focused on resolving particular questions. the scenarios remain intelligible and accessible to the endusers, who are encouraged to critique and modify them as needed.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.212 humansystem integration in system developmentlowtechnology representationsanother powerful way to tell a story about future use is through enactment of that scenario using tangible materials, such as prototypes of the envisioned technology. if the technology has been completed, then this approach becomes a matter of formative or summative usability evaluation (see chapter 8). however, in participatory design, the prototype is often left strategically incomplete to encourage and even to require users to contribute their ideas directly to the evolving concept.one of the most powerful forms of strategic incompleteness is to make a nonfunctional prototype out of lowtechnology materials (bødker et al., 1987; ehn and kyng, 1991; muller, 1992; muller et al., 1995). this approach has several advantages. first, it is easy to produce, and that means that it is easy to revise or abandon (an extreme version of the concept of ﬁthrowaway prototypeﬂ). second, it is easy to modify in placeša form of userinitiated design.1 third, modication of the lowtech representation requires no specialized tools other than domain knowledge. thus, a lowtech representation becomes another means for leveling the playing eld, encouraging endusers to make egalitarian contributions of their knowledge to complement the knowledge of software and design professionals.bødker et al. (1987) provided early demonstrations of the value of lowtech mockups (ﬁcardboard computersﬂ) in critique and redesign of new technologies for newspaper print shops. muller (1992) provided an evolutionary view of paperandpencil materials and associated working practices in the design of user interfaces. lafrenière (1996) showed a more macroscopic approach involving userinitiated construction of storyboard scenarios through the use of strategically incomplete storyboard frames (see also muller, 2001). an integration of several of these approaches became a more formal description of proven ﬁbifocal toolsﬂ for participatory analysis and design (muller et al., 1995).lowtech representations have the additional advantage of being a form of literal requirements document. that is, the constructed form of the representation is a rst approximation of the intended nal design of the user interface. in the course of working with the lowtech representation, users and systems professionals usually enact or review one or more 1 note that the use of lowtech materials for design is quite different from the use of lowtech materials for evaluation, as advocated in contextual inquiry and design (holtzblatt, 2003; holtzblatt et al., 2004) and in snyder™s paper prototyping approach (2003). these latter approaches describe the use of a lowtech prototype as a valuable proxy for a functioning system in usability testing. however, by using the materials for usability testing, these approaches effectively reduce the user™s input into an acceptance test. in participatory design, the goal is for the users to contribute as peer codesigners, not simply as evaluators.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 213scenarios of use. the sequence of events in this scenario (often captured in the form of a video recordingše.g., muller, 1992; muller et al., 1995) is a rst approximation of the user experience and of the userexperienced information design and information architecture that must also be built. in these ways, the simple paperandpencil (or cardboard) materials can become powerful engines for explicating and enhancing designs.theatrical approachesthe strategy of acting out a use scenario has been another tool of participatory design. using the theoretical foundation of boal™s theatre of the oppressed (boal, 1992), participatory designers have staged dramas to elicit discussion of working practices and technology alternatives. the principal method in information technology (e.g., ehn and kyng, 1991; ehn and sjögren, 1991) has been boal™s forum theatre, in which the designers present a skit with an undesirable outcome and challenge the endusers to modify the script, the props (i.e., the technology), or the setting, and then to reenact the drama, until the outcome is better. a secondary method in information technology (e.g., brandt and grunnet, 2000) has been the practice of ﬁfrozen imagesﬂ or tableaux, in which the actors in a drama are asked to stop (ﬁfreezeﬂ) while the audience asks each actor what her or his character was trying to achieve, what obstacles she or he faced, and how the situation or circumstances should be improved.as video technology has become a consumer product, users have also become authors of videos to show current work problems and proposed solutions (björgvinsson and hillgren, 2004; buur et al., 2000; mørch et al., 2004). an explicit tiein to scenariobased methods was made by iacucci and kuutti (2002) in their work on ﬁperforming scenariosﬂ (see also buur and bødker, 2000).ethnographic methodsethnography has gured prominently in the literature on participatory design (e.g., blomberg et al., 1993, 2003; mogensen and trigg, 1992; suchman, 1987, 2002; suchman and trigg, 1991; trigg, 2000). the specic methods used by ethnographers in design activities tend to invoke other methods, previously described in the section on participatory design. for broader discussions of ethnography, see chapter 6.workshop methodspreceding sections have described the use of stories and scenarios, lowtechnology representations, and userproduced documentaries as methods humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.214 humansystem integration in system developmenttable 72 summary of contributions and shared representations in participatory designmethodrole in system  development processshared representation  and useparticipatory scenariosdesign in use (actual use or future use)ongoing opportunity to revisit opportunity analysis and context of uselayered design documents (activity design, information design, interaction design)stories, storyboards, narrativeslowtechnology representationsearly designsdesign alternativesthrowaway prototypesdesignsartifacts created during the design processinformal requirementstheatrical approachesconsequences of designs for work practicesdesign alternativesinformal reportsscripts (rare)workshops, especially generative workshopsopportunity to revisit context of use and opportunity analysisdesignsdesign alternativesconsequences of designs for work practicesdesignsartifacts created during the design processearly marketing insightsand materials for participatory analysis. these and other methods have been integrated in the generative workshops of sanders and colleagues (sanders, 2000). generative workshops consist of methods from market research (e.g., focus groups to elicit users™ comments), ethnography (observation of users engaged in work), and participatory design (construction of anticipated or desired future objects through lowtechnology prototyping). the goal of this conjoint ﬁsaydomakeﬂ approach is to triangulate on important user needs, working practices, and innovations.contributions to the system design processeach participatory design method produces its own characteristic shared representation and contribution; several of these were reviewed in the preceding chapter on analysis. table 72 provides a summary of contributions and shared representations.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 215shared representationsin brief recapitulation, scenariobased methods may produce stories, storyboards, narratives, and use cases; the latter are particularly useful for systems engineering. these materials can become background or reference material for the more detailed work of designers and developers. alternatively, a more detailed scenario can develop into use cases, which directly inform design and development on an eventbyevent (or actionbyaction) basis.lowtechnology representations provide rst drafts of user interface designs and are suitable inputs to the work of professional designers; the information surrounding them is valuable to resolve questions that designers and implementers might have about why certain features are needed and for what purpose. in addition to the rst draft approach, lowtechnology representations can become detailed design documents, ready for implementation into working hardware or software.the theatrical methods are similar to the multimedia documentary methods in the preceding chapter. as with the narratives and explanations surrounding a lowtechnology representation, the additional information in a theatrical method may provide useful contextualization of design recommendations and implementation decisions.the workshop methods are similar in outcome to the theatrical methods, with the difference that the workshop methods were designed by professional designers to be used by professional designers. their outcomes are thus structured to be useful inputs to the next, more formalized design steps.strengths, limitations, and gapsstrengths and weaknesses of participatory design are similar to those for participatory analysis, as discussed in chapter 6. a principal strength of the participatory approaches is the collection and use of detailed, indepth information from the users™ perspective. as discussed above, users have access to a different kind of knowledge from that of systems professionals, and the users™ knowledge can be very valuable for informing design with the realities of how the work gets done, as well as for dening new opportunities and understanding the context of use (chapter 6). a second principal strength is the growing body of practices for combining the users™ knowledge with the knowledge of design and implementation professionals (and other professionals) through wellunderstood methodologies.there are two principal weaknesses of the participatory approaches. the rst is a matter of appearance. participatory approaches involve knowledge holders who have historically been undervalued in systems develophumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.216 humansystem integration in system developmentment, and therefore the participatory design may be required to justify this ﬁunusualﬂ approach to more traditional practitioners and management. similarly, the strategic informality of the participatory approaches may present an appearance problemši.e., the use of lowtechnology, narrative, and expressive media that are so necessary for full and effective communication across disciplinary boundaries.the second principal weakness of the participatory approaches is that it is sometimes difcult to integrate their informal, open, ﬁsoftﬂ outcomes with the kinds of precise knowledge that are typically required as inputs to downstream systems development activities. this problem is rapidly becoming a nonissue, through the integrative methodologies pioneered by kensing and madsen (1993), the integrations with formal methods proposed by muller, haslwanter, and dayton (1997), and the development of a participatory information technology methodology (bødker et al., 2004).contextual designin the participatory analysis section of chapter 6, we summarized the contextual inquiry process, including the three activities of contextual inquiry, interpretation, and afnity analysis, as well as the construction of the ve models characterized, respectively, in ˚ow, sequence, physical, cultural, and artifact terms. contextual inquiry can lead in turn to contextual design (holtzblatt, 2003; holtzblatt et al., 2004), which includes the following activities:ł visioning and storyboarding: develop new concepts and concretize them in the form of stories (ﬁvisionsﬂ). iteratively rene these concepts via storyboards.ł user environment design: develop an abstract version of the structure and function clustering of the system™s components and operations independently of the user interface and implementation (holtzblatt, 2003, p. 943).it is interesting to note that the stories and storyboards are accessible to endusers, whereas the larger components of the visioning and user environment design activities are explicitly stated to avoid issues of user interfaces or user experiences. thus, while contextual inquiry involved a major component of user participation in analysis, much of the work of contextual design focuses more on the product team and its professional staff, returning to the users for a more traditional usability evaluation (see chapter 8).contextual design has been designed to be well integrated into a ˚ow of work beginning with contextual inquiry and proceeding into development. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 217the shared representations of contextual design (see above) are structured and sized for immediate uptake by systems engineers and professional designers.contributions to the system design processcontextual design has been developed for effective transfer of knowledge from designers to other systems professionals. the form of storyboarding used in contextual design is intended for rapid uptake (as in use cases), and the structure and function clustering is one of the principal outcomes of a requirements analysis, to assist other systems professionals in making choices in function allocation.shared representationscontextual design is intended to produce formal requirements and specications. the vision statements and descriptions of current or future enduser work environments are inputs to those more formal documents.strengths, limitations, and gapsas noted in the preceding chapter, the contextual inquiry and design methods involve more research time and more meeting time than some less formal methods, such as participatory design. we proposed in that chapter that there is a straightforward tradeoff between the need for informal and open methods that maximize the contributions of endusers (with their own unique knowledge) versus more formal and closed methods that maximize the subsequent uptake by the development team.physical ergonomicsoverviewphysical ergonomics is concerned with human anatomical, anthropometric, physiological and biomechanical characteristics as they relate to physical activity.2 complex and simple systems often require both cognitive and physical activities of the user or group of users. clearly, it is best to design an ergonomically correct system in the early stages of system design (kroemer, kroemer, and kroemerelbert, 2001), and ideally a formal 2in august 2000, the international ergonomics association council adopted an ofcial denition of ergonomics (see http://www.iea.cc/browse.php?contid=whatisergonomics [accessed april 2007]). humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.218 humansystem integration in system developmentinstitutionalized process for incorporating ergonomics into system design preexists. the steps in the overall ergonomic process are (1) organization of the process, (2) identifying the problem, (3) analyzing the problem, (4) developing a solution, (5) implementing the solution, and (6) evaluating the result (kilbom and petersson, 2006).in ergonomics, the philosophy behind the methods is one of prevention and designing the system to minimize risk factors. without such a proactive, planned approach, the human cost can range from mild discomfort to cumulative trauma or injury and possibly even death. it is therefore a serious matter to consider the human user™s physical limitations and capabilities when designing systems. the major ergonomic considerations for healthy, safe, and efcient workplaces and environments are worker task position (reach, grasp, lines of sight, work heights, etc.), posture (seated and standing), clearances (access, movement space, activity space), machine control (visibility, control dimensions), force application (allowable forces), workstation layout (display and control positions and relationships), and physical environment (lighting, noise, climate, vibration, radiation, chemical, psychosocial, spatial, etc.) (wilson, 1998). anthropometric (and other) data for ergonomic design in new system design can be found in several published military and civilian guidelines and standards. human digital modeling is another excellent way to test design alternatives. in addition, controlled testing and laboratory experimentation (e.g., tting and user testing) can be used to empirically optimize ergonomic design.in physical ergonomics, concern for the user ranges from perceived discomfort to physical injury. assessment methods can be used to identify prospective problems in existing systems or for evaluating alternatives in new systems. using one class of physical ergonomics issues as an example, musculoskeletal injuries often begin with users experiencing discomfort (hedge, 2005). left untreated, these perceptions of discomfort can escalate into pain. untreated pain can then result in musculoskeletal injury (e.g., tendonitis, tenosynovitis, carpal tunnel syndrome) (hedge, 2005).finally, there has been an effort to automate the tools with which physical ergonomics is considered in the design process. digital human models are ergonomic analysis and design tools that are intended to be used early in the product and system development process to improve the physical design of systems and workstations (see section on models and simulation).shared representationsshared representations range from physiological tests, such as the measurement of systolic blood pressure, to subjective instruments, such as ratings of perceived exertions (louhevaara et al., 1998). physical ergonomics methods that focus on assessing discomfort center around selfreport inhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 219struments. such shared representations have the downside of subjectivity. in the assessment of posture, direct observation can be used, with shared representations taking the form of checklists and other dataacquisition and reduction tools. fatigue assessments, while attempting to be quantitative, do rely on subjective ratings, and thus shared representations take the form of the output of ratingbased instruments. finally, methods to assess physical risk also tend to rely on shared representations that are at least partially subjectiveštypically taking the form of checklists and rating scales. with respect to human digital modeling, an avatar or virtual human with specic population attributes is rendered as it dynamically performs tasks in a system. more simply, a dynamic simulation of the humansystem interaction is rendered. more detail on the shared representations, including examples, follows in the context of methods.uses of methodsmethods for assessing discomfortin addition to discomfort serving as an early warning sign for injury, discomfort can in and of itself be costly in terms of affecting the quality or quantity of work performed (hedge, 2005). since discomfort is not directly assessed and must be perceived by the user, methods for assessment involve selfreport instruments. one of the earliest methods to assess a user™s degree of musculoskeletal discomfort is a checklist instrument called plibel (hedge, 2005). this literaturederived instrument allows users to evaluate ergonomics hazards associated with ve body regions (see kemmlert, 1995). the assessment can be applied at the task or system level. in the context of system development within an hsi framework, plibel can help identify specic bodily areas that require attention in design or redesign. for example, if excessive reaches or awkward postures are required by a newly designed jet cockpit ﬁhighway in the skyﬂ display, plibel will identify the physical regions of the body at risk.another group of discomfort instruments to consider in physical ergonomics assessment is that promoted by the national institutes for occupational safety and health (niosh) (hedge, 2005). selfreport measures of discomfort are widely accepted by the agency (see sauter et al., 2005). most of these instruments share the characteristics of combining body maps with questions and, like plibel, attempt to identify particular body regions at risk.additional methods for assessing discomfort include the dutch musculoskeletal survey, the cornell musculoskeletal discomfort survey, and the nordic musculoskeletal questionnaire (hedge, 2005).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.220 humansystem integration in system developmentmethods for assessing postureworkplace posture is a function of the interaction of many factors, including workstation design, equipment design, and methods (keyserling, 1998). as indicated by hedge (2005), there are various reasons why selfreport instruments are less desirable than unobtrusive observations of, for example, posture. posture in a sense is a surrogate for musculoskeletal functioning. in system development, users in mockups or users in existing systems can be evaluated in real time or through recordings to assess postural risk. the quick exposure checklist involves both observer and user assessments. its exposures scores are derived (in percentages), and actions ranging from ﬁacceptableﬂ to ﬁinvestigate and change immediatelyﬂ are recommended (li and buckle, 2005, 1999). the quick exposure checklist can therefore be applied to assessing risks associated with system tasks when evaluating an existing system for redesign or when testing a prototype of a new system.a widely used method, called rapid upper limb assessment, provides a rating of musculoskeletal loads (mcatamney and corlett, 1993, 2005). these ratings relate to the posture, force, and movement required by tasks. after postures are selected, they are scored using scoring forms, body part diagrams, and tables. the scores are converted to actions ranging from ﬁacceptableﬂ to ﬁimmediate changes required.ﬂ for tasks that relate to additional body parts, the rapid entire body assessment method can be used. additional methods include the strain index, the ovako working posture analysis system, and the portable ergonomics observation method (hedge, 2005).methods for assessing fatiguethe previously mentioned methods do not really address the measurement of work effort and fatigue. methods that attempt to quantify effort and fatigue include the borg ratings of perceived exertion scale and the muscle fatigue assessment method (hedge, 2005).the borg ratings increase linearly with oxygen consumption, whereby a range of 620 was established for healthy, middleaged people (borg, 2005). the scale provides a measure of exertion intensity and thus provides quantitative data when evaluating a system or proposed system that requires physical user demands. one limitation is that while quantitative, the scale does rely on perceived exertion.strategies for reducing risk can be pursued after dening the level of effort required. the muscle fatigue assessment method works best when applied to production tasks having less than 1215 repetitions/minute with the same muscle groups and is ideal for team evaluations of a task (rodgers, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 2212005). once tasks are identied, effort intensity levels are determined for each body part. effort durations and frequencies are determined and a rating system is used to prioritize changes. after strategies are developed for reducing the predicted risk, tasks are rerated to determine the impact of the proposed changes (rodgers, 2005). although the technique is partially quantitative, it does rely on subjective input (rodgers, 2005).methods for assessing injury riska predictive method for determining back injury risks was developed by niosh, known as the niosh lifting equation (hedge, 2005). while the lifting equation does not consider the dynamics of lifting, the lumbar motion monitor (lmm) attempts to account for more realistic task situations. the lmm is a patented triaxial electrogoniometer that is attached to the spine via a hip and shoulder harness (marras and allread, 2005). using potentiometers, the lmm measures the position of the spine relative to the pelvis. software provides descriptive information about trunk kinematics and, more importantly, the system determines whether a particular worker is at risk, a task is risky, or whether an entire job comprised of several tasks is risky (marras and allread, 2005).the occupational repetitive action (ocra) methods can be used as the basis for redesign decisions and as an evaluation tool for new designs (hedge, 2005). the ocra index is used for the redesign or analysis of workstations and tasks (occhipinti and colombini, 2005). the ocra checklist is generally used for the screening of workstations with repetitive tasks. both methods assess repetitiveness, force, awkward postures and movements, and lack of adequate recovery periods (occhipinti and  colombini, 2005). the risk index is the result of a ratio between actual technical actions and the recommended actions.human digital modelingdigital human models are ergonomic analysis and design tools that are intended to be used early in the product and system development process to improve the physical design of systems and workstations (chafn, 2004, 2005). software has been developed for human digital modeling (e.g., jack, safeworks, ramsis, sammie, um 3dssp, and santos). digital human models test the capabilities and limitations of humans without the expense and possible risks associated with physical mockups. for example, the particular reach limitations or line of sight capabilities of a vehicular driver could be determined (see the section on models and simulation for further discussion).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.222 humansystem integration in system developmentcontributions to system design phasesas noted earlier, failure to account for the user™s physical limitations and capabilities when designing systems can result in decreased performance and productivity, discomfort, cumulative trauma or injury, even death. physical ergonomics is used to identify the physical regions of the body at risk and can help identify specic bodily areas that require attention in design or redesign. the methods can be applied at the task or system level.to the extent that systems require physical activity, physical ergonomics methods are applicable for dening solutionsšthat is, to support identication and exploration of design alternatives. more specically, semiautomated and automated systems will have human users or supervisory controllers operating in workplaces. design of these workplaces is an iterative process, requiring assessment and support of human user physical needs (chafn, 1997).physical ergonomics methods can also be used in system evaluation and redesign to compare current and redesigned workstations and to justify funding to decision makers (mcatamney and corlett, 2005). physical ergonomics should also be considered in system costbenet analysis, since benets can broadly impact performance (hendrick, 1998).human digital modeling is used early in the product and system development process (construct invent/design) to evaluate proposed new system or workplace designs.strengths, limitations, and gapsattending to the user™s physical ergonomics needs improves the likelihood that the humantechnology t will promote better performance and wellbeing. a limitation of the physical ergonomics approach is that it focuses on ﬁneck downﬂ physiology. complimentary attention should be placed on ﬁneck upﬂ or cognitive ergonomics. as vink, koningsveld, and molenbroek (2006) suggest, not only can physical ergonomics combat negative issues, but it can also positively impact productivity and comfort. this positive impact is maximized when users and management actively participate in the process. another historical limitation is that ergonomics has tended to focus on a single user or operator. some have estimated performance improvement through ergonomics approaches to be in the 1020 percent range (hendrick and kleiner, 2001). with the advent of macroergonomics or systems ergonomics, groups or teams of users can now be considered, as well as broader contextual factors leading to greater performance impact. this broader approach is consistent with the hsi framework. while much research has been conducted and much knowledge humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 223has been generated, there is still much to learn. fundamental issues, such as the actual causes of low back pain, remain. another gap that is slowly being lled is better integration among physical, cognitive, and macroergonomic approaches in order to consider total humansystem integration.in terms of newer methods, such as human digital modeling, current digital human models are generally static or are not fully dynamic, integrated models. human motion databases and models are helping to convert existing, static digital human models to dynamic models. additional research is needed on human motion and biomechanics to help achieve dynamic, complex system modeling.current digital human simulation systems are beginning to allow a user to interact with a digital character with full and accurate biomechanics, a complete muscular system, and subject to the laws of physics (abdelmalek et al., 2006). results have been achieved in the areas of dynamic motion prediction, the modeling of clothing, the modeling of muscle activation and loading, and the modeling of human performance measures.situation awarenessoverviewsituation awareness has become an important ingredient in the analysis of humansystem performance, and therefore hsi specialists should include its measurement in the tool box of methods to bring to each new system development (endsley, bolte, and jones, 2003). tenney and pew (2006) is a recent review of the state of the art.in everyday parlance, the term ﬁsituation awarenessﬂ means the uptotheminute cognizance or awareness required to move about, operate equipment, or maintain a system. the automobile driver requires situation awareness in order to safely operate a vehicle in a rapidly changing environment. the driver needs to understand the position of the vehicle in relation to the road and other trafc, the speed limit under which the vehicle is currently operating, the capabilities of the car itself and any special circumstances, such as weather conditions that may in˚uence driver decision making. the driver uses sensesšeyes and ears and perhaps nose and touch, to take in information and process it to build a conceptual model of the situation. the process of building up situation awareness is called situation assessment. operational people in a variety of disciplines, ranging from military planners to hospital operating room staff, nd the concept useful because for them it expresses an important but separable element of successful performancešbeing aware and current about the circumstances surrounding their current state of affairs.being involved in every aspect of the job leads to good situation humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.224 humansystem integration in system developmentawareness but high workload. introduction of automation reduces routine workload, but also reduces situation awareness, because it takes the user ﬁoutoftheloop.ﬂ then, when a critical event occurs requiring an operator response, workload again becomes high and situation awareness is inadequate.automation also often introduces additional situation awareness requirements to manage the new systems. humansystem integration will be especially important to exploit the information management requirements that will accompany the next generation of automation.achieving situation awareness has therefore become a design criterion in addition to more traditional performance measures. however, measuring situation awareness requires more than an everyday understanding of the term. the most widely quoted denition of situation awareness was contributed by endsley (1988), ﬁsituation awareness is the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning and the projection of their status in the near futureﬂ (p. 97). there is general agreement that the term refers to all the sensory, perceptual, and cognitive activity that prepares the user to make a decision, but it does not include the execution of a course of action once a decision is made.measuring situation awarenessa variety of methods are available that may be used to assess situation awareness. in general they fall into four categories:1. direct experimental measures.2. measures derived from scenario manipulation.3. subjective measures.4. thinkaloud protocols.to apply direct experimental measures, the investigator or designer places a user in the context of the task under study, usually by means of exercising a scenario and simulating the operations under study. then, at various points, the scenario is paused while the user is asked to answer a question about the status of different variables that are relevant to good situation awareness. the measure is the proportion of correct answers to the questions. the most wellknown of these techniques is the situation awareness global assessment technique (endsley, 2000).in order to derive a measure from scenario manipulation, the analyst specically designs a scenario so that, at one or more points, the participants must make a decision that will re˚ect how successfully they have assessed the situation. for example, an aircrew is placed in an approachhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 225tolanding situation on the rightmost of two parallel runways. just as they are preparing to land, a second aircraft that was scheduled to land on the left runway suddenly veers over into the airspace appropriate to the right runway. the time it takes the rightrunway aircrew to make a decision to go around is a measure of their situation awareness (pew, 2000).it is frequently difcult to arrange for collecting these kinds of objective data, and the investigator relies instead on just asking the user to assess their own situation awareness. there are formal scales for doing so, such as the situation awareness rating technique (jones, 2000). again, users are placed in the context of the task under study and then, either during or immediately after completing a trial, they are asked to rate their situation awareness on a predened scale.thinkaloud protocols are just what they sound likešusers are asked to verbalize what they are thinking while they are working on a task. they are useful early in a system development process to obtain from users their interpretation of what aspects of a situation they are thinking about. they could be applied as soon as candidate stories or scenarios have been developed that re˚ect the way the system might work. they can help to dene the information requirements and understanding required to accomplish the task.contributions to system design phasesas indicated, thinkaloud protocols are useful early, during system development, when they can help elaborate the conceptual structure in which the task will take place. the other methods are most useful when prototype userinterface designs are being considered. here the data from testing can support the evaluation of the quality of the designs for achieving situation awareness. evaluation can also be an important part of summative usability testing because situation awareness is such an important part of the success of the application or mission. data describing the results of situation awareness tests provide useful shared representation with other stakeholders, because it is a concept that, in its everyday meaning, can be widely understood as important to good performance.strengths, limitations, and gapsin contrast to overall system performance measures, situation awareness measures provide indices of the way the system is in˚uencing human performance per se, and therefore it is able to provide clues to how to improve the design from the perspective of the user. these measures are more diagnostic, in the sense that they can suggest what is missing from the design or how understanding is inadequate. for some kinds of mishumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.226 humansystem integration in system developmentsions, achieving good situation awareness is the most important aspect of the design.the main weakness is that they require having an experimental or real system to be available for testing, which limits the assessment of situation awareness until later in the development process than would be desirable.a signicant gap is that one would like to be able to predict situation awareness before anything is built, but good predictive models to assess it are not available, although efforts are under way.methods for mitigating fatigueoverviewsystems manned by operators need to accommodate the inherent limitations imposed by human circadian rhythms and endurance capacities. this is evident in the establishment of hoursofservice regulations for various industries, particularly transportation, which limit the number of hours in specic periods of time that workers may stay on the job. the basis for these regulations is the need for sufcient time off to permit rest and recovery and, in particular, sufcient sleep. numerous accident analyses implicate operator fatigue as a proximal cause, and some researchers suggest that certain times during the 24hour period are a higher risk for accidents regardless of fatigue level (folkard et al., 1999).the methods available to the human factors practitioner for dening shift schedule impacts and mitigating them are relatively few and are all based on several factors. these include the basic circadian rhythm, the amount of sleep obtained prior to shift initiation, and the amount of sleep obtained during offwork periods during the shift assignment (e.g., 1 week). it is important to address these issues in the design phase of systems in order to preclude adverse scheduling that may not be covered by hoursofservice regulation and to build in fatigue mitigation elements when schedule impacts cannot be avoided (such as a 24/7 operation or military sustained operations).most of the schedule assessment and fatigue mitigation methods come from the transportation sector (sanquist and mccallum, 2004). the methods with the most general applicability to system design and operation includeł alertness models.ł trip planning.ł strategic napping.ł sleep environment planning and design.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 227each of these methods (sometimes referred to as fatigue countermeasures or alertness management) has been shown to have a benecial impact on reducing or avoiding fatigue in the workplace. given the potentially lethal impact of fatigue on the job, application of these principles and methods during system design is warranted. the principal risk reduction associated with application of these methods is that of operations, which will lead to excessive fatigue and corresponding degradations in human performance. the following sections brie˚y describe each method or countermeasure in terms of applicability in a system requirements and design phase of development.uses of methodsalertness models have been used by researchers for a number of years to predict the likely fatigue level that would result from various shift schedules and the corresponding opportunities for sleep (or lack thereof). most are based on several key parameters, such as a circadian rhythm component, time of day, preceding amounts of sleep, and availability of a recovery sleep period (dawson and fletcher, 2001; folkard et al., 1999). the models are encoded in specialized software packages that generally require some domain expertise to operate. the outputs consist of fatigue levels before, during, and after a shift, and these values can be used as a guide to schedule construction and assignment. for designers without access to the specic modeling tools, which change fairly rapidly since they are principally a research product, simple heuristics for scheduling and rotation are reasonable substitutes. these include such rules of thumb as providing sufcient time off to permit an 8hour sleep period, which in practice means at least 10 hours. similarly, start times prior to 7 am are more likely to be associated with fatigue than later start times.trip planning is a method employed in variable ways by transport workers and is highly dependent on the transportation vector, such as air, road, or rail. both schedulers and individual workers need to plan their trips to provide offduty breaks of sufcient duration to obtain enough sleep. this applies in particular to workers who need to travel long distances to their work location, such as airline pilots commuting crosscountry to start a longdistance ˚ight assignment.strategic napping is a fatigue countermeasure that involves short sleep periods of 2045 minutes duration to provide for recovery during a longduration shift (dinges at al., 1991). a number of studies indicate that strategic napping is associated with better job performance following the nap (e.g., landing an airplane). as a consequence, certain international air carriers have sanctioned napping during longdistance ˚ights by one of the crew members, and airplane manufacturers are beginning to build longhaul humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.228 humansystem integration in system developmentaircraft with sleeping quarters for crew members. similarly, rail carriers are beginning to provide napping rooms in their crew turnaround locations.sleep environment planning and design (zarcone, 2000) have entered into the schedule design process for certain air carriers and have also in˚uenced how the carrierpreferred hotels design their facilities. they are now beginning to reserve certain blocks of rooms and ˚oors for day sleepers and to implement other measures, such as blackout shades and additional soundproong.shared representationsalertness design methods have a common shared representation in specifying the impact on operator sleep. alertness models predict how much sleep an operator will get on a certain shift schedule or the likely fatigue level resulting from lack of sleep. trip planning has a similar outputšgiven a particular duty schedule. what are the opportunities for sleep and how much will be obtained?figure 75 illustrates a shared representation that is common among alertness designers: a graphic plotting time of day against alertness level. this is a common method of dening time periods that are likely to show fatigue effects that might manifest as accidents.75fixed imagefigure 75 time of day and number of alertness level.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 229contributions to system design phasesalertness design methods contribute mainly to the architecting phase of the system development process. in any manned system, the elements of stafng, scheduling, and recovery are addressed during the more specic design phases, involving determining how many people will work, doing what tasks, and the nature of the operations (e.g., 24 hour, sustained, or other). evaluating and designing for alertness management during the architecting phase can prevent unanticipated attrition due to excessive fatigue or more dire consequences, such as accidents.strengths, limitations, and gapsthe strength of alertness design methods is that they address a problem that is reasonably easy to solve if several key parameters are considered: number of staff, duty periods, recovery time necessary, etc. in their simplest implementation, the methods consist of heuristics designed to assess the adequacy of rest periods. more involved methods, such as nap period design or sleep environment planning, can enhance alertness during long assignments or unusual shift rotations.a primary limitation of alertness design methods is that they are relatively unknown outside the fatigue research and transportation community. a cultural tradition of work excess in some industries limits the willingness of system designers to consider the basic needs of sleep. a further limitation is that fatigue mitigation and alertness management/design are not often considered in the traditional suite of human factors methods, but they are an important part of the larger hsi domains. this is beginning to change, but the eld tends to be dominated by the methods with a more traditional taskoriented focus.a large gap in alertness design methods is the availability of robust guidelines or processes for addressing fatigue issues in design. whereas task analysis has many variants and practitioners can learn to apply it rather quickly, alertness design does require some knowledge of biological rhythms and performance effects, and various subtleties of sleep debt accrual and mitigation. the modeling tools developed to date require substantial knowledge in the area for proper application and interpretation, and a simple set of alertness design guidelines, applicable across a wide range of work activities, has yet to be developed.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.230 humansystem integration in system developmentscenariosoverviewscenarios are stories that describe how activities and events unfold over time. they can depict either how the activities currently happen or how the activities might be imagined to happen in the future. scenarios can be produced at a variety of levels of detail, abstraction, and scale. for example, they can tell a story about how a particular culture might change (big and broad scenariobased planning) or suggest how a new technology can in˚uence a particular process (big and focused). scenarios can also be produced to suggest how a particular user might interact at the buttonpush level on a handheld device (small and detailed).scenarios can be used by different system stakeholders in different ways. some design representation methods emphasize the delivery of a formal, integrated concept, embodied in the form of a highly produced and convincing story. by contrast, some participatory analysis methods focus on storytelling to create a level playing eld, so as to put users and technologists on a common footing, making scenarios useful as shared representations. in more formal terms, these techniques have been described and analyzed as scenariobased methods (carroll, 1995, 2000; rosson and carroll, 2002, 2003).uses of methodsin using scenarios, researchers play the character™s (or persona™s) actions forward and are able to share them among themselves and with potential users. the scenarios enable all the participants to critique the assumptions and implications that are made visible. for example, endusers have the potential to see how their work would change in the future. alternatively, systems professionals may be able to see the implications of changed working practices for new technology opportunities. in this way, scenarios offer participants the opportunity to rewrite or coconstruct them until the activities and processes they represent meet all the stakeholders™ needs.designers create a variety of different types of scenarios depending on the design challenge and where they are in the development life cycle. scenarios are created to address the needs of specic stakeholders, their environments, technologies, or according to the specic problem that needs to be addressed.another consideration in using scenarios is what medium should be used to generate and deliver the scenario. scenarios can be represented purely verbally, with text and images (in which the images are similar to storyboards used in lm and animation), or as fully featured video (see the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 231sections on lowtechnology representations and multimedia documentaries below). usually the more informal the medium that is used for the scenarios, the more it invites the viewers to actively participate in modifying or changing them.scenarios are typically elicited through a sequence of steps:ł root concept: beginning with a brief statement of the goal of the project, analysts elaborate a basic rationale for the project, list the crucial stakeholders, and provisionally state some highlevel assumptions.ł ethnographic inquiry: field observations, interviews, and artifact analyses are conducted as needed to understand users™ needs and opportunities.ł interpretation: field observations are then organized and interpreted through a series of afnity analyses (using methods from contextual inquiry).ł problem scenarios and claims: the tentative requirements from the preceding steps are then organized into scenarios of future action that will need to be supported and specic claims (which capture essential or emergent themes and topics) about how the envisioned system will support those scenarios.scenariobased work often involves a preliminary coding scheme for the knowledge that is elicited. for example, rosson and carroll (2002) note that ﬁeach scenario depicts actors, goals, supporting tools and other artifacts, and a sequence of thoughts, actions, and events, through which goals are achieved, transformed, obstructed, and/or abandoned.ﬂ these kinds of scenariobased codings had previously been shown to be useful in creating objectoriented designs (rosson and carroll, 1996). under some circumstances, it is useful to provide materials for scenario construction that embody a particular ﬁvocabularyﬂ of events or actions, so that the resulting design has already been precoded into a target set of system components (muller et al., 1995).shared representationsthere are a variety of shared representations that can result from building scenarios. they are, in a conventional timeordering:individual (episodic, vertical) stories from one informant at a time, describing that informant™s experience.composite stories that are constructed from the individuals™ stories; these stories are usually supposed to be accurate summaries and compilations of the individuals™ stories and are usually supposed to have a similar ﬁepistemic statusﬂ of accuracy and delity.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.232 humansystem integration in system developmentfuturevision stories, which are of necessity ctitious. typically these earlystage thinkingaboutthefuture stories tend to be connotative rather than denotative, evocative rather than denitive, open rather than closed, plural rather than singular, and are often deliberately incomplete.finally, there is the relatively formal requirementsrelated story, which provides a relatively detailed account of future use for designers and developers. these stories tend to be nearly the opposite of the futurevision stories: denotative, denitive, closed, singular (ﬁwe will build thisﬂ), and exhaustively complete.carroll suggests that scenarios are paradoxically concrete, but rough, tangible, and ˚exible, encouraging whatif thinking among all parties and pushing designers beyond the expected solutions (carroll, 2000; see also erickson, 1995, on the strategic use of roughness in representations). as a shared representation, scenarios permit the articulation of possibilities without undermining innovation, enabling the design team to focus on the systems in the given context. scenarios can be simultaneously implicit and explicit.contributions to system design phasesscenarios can be used in the very early stages of the design process to help explain possible system behavior. they are easy to share because they are in natural languagešor in some other conventional representation, such as cartoon framesšand almost anyone can participate in their production (carroll, 2000). later on in the process, scenarios enable the collaborative team to begin to immediately synthesize ndings from research into situated ideas for the future. they can also be used as an evaluative tool with system usersšin other words, the stories and their associated pictures can be shown to end users and other stakeholders before anything is committed to code. according to rosson and carroll (2002), ﬁthe basic argument behind scenariobased methods is that descriptions of people using technology are essential in discussing and analyzing how the technology is (or could be) used to reshape their activities. a secondary advantage is that scenario descriptions can be created before a system is built and its impacts feltﬂ (rosson, maass, and kellogg, 1989; weidenhaupt et al., 1998). finally, later on in the process, scenarios can be translated into use cases or essential use cases and associated with system requirements (preece, 2002). at this stage, they can also provide the specic task details to support humanintheloop simulation experiments and usability evaluation.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 233strengths, limitations, and gapsa primary strength of scenarios is that they are easy to make and revisešthey are fast and cheap. nothing has to be coded, and they can even describe system behavior in words alone. when they include storyboards or pictures of the activity, they can help endusers and other stakeholders envision, react, and help shape possible future systems. the limitation of scenarios is that they can never be exhaustivešnot every story can be toldšso some functionality that could be critical to the design of the system could remain overlooked. although several treatments have begun to analyze the space of stories (e.g., carroll, 2000; muller, 2007; rosson and carroll, 2002, 2003), a more extensive cataloging of scenario types, uses, and limitations could be developed to overcome these limitations.personasthe personas (or ﬁarchetypesﬂ) approach has become a very popular technique in applied design activities. using personas (especially role or segmentationbased archetypes) as actors in scenarios (see following) helps situate the technology in reallife settings. ever since alan cooper described personas in the book the inmates are running the asylum, there has been a great deal of effort spent on understanding why and how personas are useful in the design process and in nding ways to extend the concept beyond their role in bringing scenarios to life (cooper, 1999, 2004; pruitt and grudin, 2003). personas are useful because they build on people™s expectations and natural abilities to anticipate and infer other people™s behavior from what is known about that person. pruitt and grudin suggest that good personas can be generative and help designers ﬁplay forwardﬂ or project what they know about a character into new situations. pruitt, grudin, and others have extended the use of personas throughout the design processšfrom prioritizing features, to usability and market research to qa testing.shared representationswhile scenarios are concise narrative descriptions, personas are descriptions of one or more people who are (or will be) using a product to achieve specic goals. a persona is specically designed to become a shared representation of the users of the target system. they are designed to mediate communication about the potential users of the system. a persona is a model or description of a person, ideally based on observed behavior gathered by the upfront analysis team and dened through an intuitive and systematic synthesis of the analysis data. good personas include descriphumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.234 humansystem integration in system developmenttions of the character™s activities, goals, skills with and without technology, in˚uence on the business, attitudes, and communication strengths and weaknesses (cooper, 1999; pruitt and grudin, 2003; cooper and reimann, 2004; pruitt and adlin, 2006). personas become the actors in the stories of current or future use and interaction. in the commercial world, a variety of user types may be modeled. for example, an online banking design scenario might include both novice and expert users at different life stages (newlywed, college student, empty nester, etc.). in the military it might include representative enlisted personnel who might be assigned the task and an ofcer who would use the application in a supervisory role. although there are signicant differences in practice (adlin et al., 2006), the persona descriptions can also focus more on roles, experience levels, and motivations for the interaction.teams are encouraged to make conceptual tests of their design decisions against the persona who represents the users (e.g., ﬁwhat would kim think about that feature?ﬂ); note, however, that the issue of representativeness is somewhat controversial (muller et al., 2001). task analyses can be based, in part or in whole, on the persona description (redish and wixon, 2003). like a method actor who immerses himself or herself in a character, a persona is usually described in considerable personal detailši.e., with a name, a photograph, a job description, and a variety of personal data that can include pets, favorite foods, make and model of car, and so on in order to support appropriate inferencemaking on the part of the persona user.contributions to the system design processthere is little formal research to support the creation of personas as a part of the systems design process. less formal reports from practitioners are overwhelmingly positive (e.g., cooper, 2004; pruitt and adlin, 2006; adlin et al., 2006). the principal contribution is within the design or development teamšan effective persona can help a team to focus on the experiences and needs of their users, providing a valuable counter balance to the more traditional concerns for systems performance and efciency. these practitioners have successfully extended their use beyond scenarios all the way up to executive product strategy meetings (pruitt and grudin, 2003).strengths, limitations, and gapspersonas can play a powerful role in bringing user concerns to the forefront of the development process. when carefully and systematically constructed, they can be an effective shared representation for the development team. a persona is, ideally, created on the basis of information about the population of real users. however, the basis for selecting the relevant humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 235attributes of a persona is not agreed on (e.g., adlin et al., 2006; grudin and pruitt, 2002; muller et al., 2001). a persona might be based on ethnographic research, but most ethnographic accounts are about individuals rather than about group parameters or generalized characteristics, and thus they are too specic to help with the construction of a representation that faithfully represents the relevant attributes of all users. data from marketing research may be used to select the statistical characteristics of a persona (as suggested by grudin and pruitt, 2002, and as partially done by sinha, 2003), but there remains a wide range of personal characteristics in the persona description whose source is unclear (adlin et al., 2006).in a systematic treatment, pruitt and adlin (2006) advocate the creation of a ﬁpersonaweighted feature matrixﬂ to assist a team in the systematic consideration of multiple personas. these multiple personas might represent users with different responsibilities or even different market segments  (adlin et al., 2006). the feature matrix can then be used to rate the importance (or perhaps market share) of each type of user, and it can be used further for a highlevel quantication of the impact of each feature decision on each class of users and thus on the likely overall success of the product.prototypingoverviewprototyping is a method that can be used at any time during the design process. prototyping helps teams answer questions, shape, and dene the attributes of a desired future state (schrage, 1996) the word ﬁprototypeﬂ refers to a number of different types of things that can be made to express, discuss, critique, or rene a concept or system or product or plan (beaudouinlafon and mackay, 2003; tscheligi et al., 1995). what unites the diverse meanings and types of prototypes is that any prototype is a temporary substitute for the real thing that eventually will be (or might be) implemented or constructed. prototypes are made in different ways, of different materials, by different people, for different purposes (houde and hill, 1997). a pen held to one™s ear as a standin for a cell phone in a design session and the beta release of an application can both be considered prototypes. in the design process, prototypes help teams make the transition from an abstraction of what might be to a concrete notion of what something might be like.prototypes are used to reason and communicatešto persuade and argue what ought to be among collaborators (houde and hill, 1997; rith and dubberly, 2005). prototyping is a process that brings a desired future to life or makes the design tangible (wulff, evenson, and rheinfrank, 1990; humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.236 humansystem integration in system developmentcoughlan and prokopoff, 2004), but the role that a prototype plays in facilitating team activities is equally important. as suchman (2004) notes, a prototype often serves as a means of enactment (i.e., for demonstrating and persuading) as well as the more conventional means of representationša dynamic dance between the invention of needs and the technologies that support them. a prototype is intended to be a standin for the collaborating team™s ideasšnot just as a version of an eventual or target solution (boland and collopy, 2004). schrage warns that organizations may have a specicationdriven culture that may prevent them from innovatively prototyping (1996). in these types of environments, the potential to enact the best possible futures may be sti˚ed. in contrast, in organizations that successfully mediate meaning through prototypes, value is created, communicated, and shared (schrage, 1994).uses of methodsprototypes can represent a number of dimensions in the system design. a horizontal prototype may be a re˚ection or enactment of all activities the system is intended to support at a very high level; a vertical prototype may address a subactivity in the design in complete detail in order to understand the implications of a particular implementation without the cost of prototyping the entire system.some prototypes are intended to be thrown away almost immediately, while others are more evolutionaryšthat is, they are designed to be continually updated throughout the design process. architectural prototypes are produced in order to provide a representation of the performance and feasibility of a particular attribute of the supporting technology; while a requirements prototype may re˚ect what the system needs to do to support the activities of users without any implication of technology that will be used to implement a solution. in some situations, wireframes or purely textual prototypes are used to elicit feedback from potential users of a system, while in other situations the representation may be purely visual and a re˚ection of the nal form of an interface (mannio and nikula, 2001). the level of nish or degree of roughness of a prototype can also be a consideration (erickson, 1995). a prototype can be as simple as a few lines on a napkin or as nished as a beta release.figure 76 shows some examples of different types of prototypes.shared representationsthe shared representations produced as output from prototyping may take a variety of forms (beaudouinlafon and mackay, 2003; houde and hill, 1997). what makes the activity of prototyping and the prototypes that humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 237are produced so powerful as shared representations is that they are tangible and can easily be shared and foster communication among team members, stakeholders, and endusers.prototypes function to make explicit an aspect of form, t, or functionality (boland and collopy, 2004). form is the overall structure of the organization, environment, technology, or process. form can shape interaction and set expectations. fit describes the resonance (or lack) of the current embodiment to the overall endeavor™s objectives. fit is often subjective but deeply meaningful on levels that are often beyond expression (gladwell, 2005). functionality describes whether the design worksšthat is, whether it is effective, appropriate to human use, and emotionally sustainable; has the potential to be taken up by the organization(s) that it responds to; and is situated in its context (boland and collopy, 2004).76figure 76 (a) scribbles on a napkin for prototyping ˚ow across a counter in a service environment. (b) second round prototype for interface to mri device. (c) physical prototype: a foam model of a blood analyzer prototype.(a)(b)(a)(c)humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.238 humansystem integration in system developmentcontributions to system design phasesearly in the life cycle, a prototype may simply be a placeholder for a real object or system: people use the prototype to show the work or actions that would take place around it (e.g., buur et al., 2000). later in the life cycle, a prototype may take the form of a nonfunctional description in concrete materials, such as a physical model of a device (e.g., bødker et al., 1987, 1988) or a paperandpencil mockup of a user interface (e.g., ehn and kyng, 1991; muller, 2001; muller et al., 1995); in some cases, the prototype is designed to be modiable only by experts while in other cases the prototype is designed to be modiable by anyone, including actual or potential users of the eventual product or system (e.g., ehn and kyng, 1991; muller, 2001; muller et al., 1994, 1995; sanders, 2000). still later in the life cycle, a prototype may be a faithful paperandpencil copy of a designed system, used for early user evaluations while the real system is being built (e.g., snyder, 2003). houde and hill (1997) recommend that an integrated prototype be based on the construction of as many as three different types of prototypes (based on the role or function of the target system in people™s work, the look and feel of the system, and the implementation technology).at later phases of the life cycle, prototypes may contain varying levels of functionality. in some cases, the functionality may be complete, but the implementation technology may provide ˚exibility (to try out new or alternative ideas) in preference to performance. in other cases, the functionality may provide surface delity, but with ctitious backend architectures, data, and communications. in the wizard of oz style of prototype, the backend is simulated by a person representing the behavior of the computer. selecting the appropriate form of prototype depends on the development or communication problem to be solved (or both); see beaudouinlafon and mackay (2003) and houde and hill (1997) for details. at this level, prototypes can support experimentation with alternative designs or formative usability evaluation.strengths, limitations, and gapsa primary strength of prototyping and the prototypes that result is the cohesion for the team. according to kelly (2001), ﬁgood prototypes don™t just communicatešthey persuade.ﬂ when discussing ideas or determining direction, having a prototype with which to negotiate makes the process more effective, fosters innovation, and usually reduces development costs (kelley, 2001).the greatest feature of prototyping is also its biggest foible. because humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 239prototypes are so real, they make the experience of the product, application, or service so tangible that they can in˚uence teams to x too quickly on a potential solution. when that happens, people are usually taken in by the level of nish in the prototype and believe that all the qualities and features are setšrather than being open to change. in practice, it is very important to match the level of nish to the stage in the process to avoid early closure on an incomplete solution (erickson, 1995).the most frequent use of prototypes has occurred in hardware and software development. however, prototypes have also been used to explore organizational outcomes, andšsignicantlyšto critique and redesign the technologies that might lead to different organizational outcomes. the bestknown example is the utopia research project, which dealt with new technologies and their implications for changes in working relations and power balances among two groups of skilled workers (e.g., ehn and kyng, 1991; see also bødker et al., 1987, 1988). extensions of these methods could be used to explore the interactions of new technologies and new working practices in a variety of home, commercial, and military settings.aside from the relatively informal demonstrations of ehn and kyng (1991), there is work to be done to understand how physical artifactsšthe nonhuman components of the systemšinteract with the prototypes of the people side of the system. is there a classication scheme to be developed to include verbal or descriptive concepts and theories, to interactive roleplaying, to computational models and simulation? clearly new methods for visualizing interactions and activities must be developed.prototyping organizations (as well as technologies) will help produce and maintain better organizationsšbecause troubling interactions can become visible and renements can be made before the design is rolled out, saving time, effort, and misunderstanding. by having participants (preferably the intended endusers) contribute to designšand by nature some ownershipšthe likelihood of adoption and enactment of the goals of the design will be increased (muller, 1992; muller et al., 1994). once the design is implemented, an organization will be better maintained because the prototyping can facilitate (1) changes to accommodate organizational strategy changes and (2) and an ongoing capability for whatif scenario testing for unanticipated outcomes.prototyping training systems should not only help produce better trainees early on, but also, as noted above, can enable better system designs that make fewer demands for intensive training later on. prototyping training also provides an opportunity for early feedback to the systems as well as organizational designers from the target users, providing insightful opportunities for improvement to the developers, as well as potential for early buyin by the endusers.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.240 humansystem integration in system developmentmodels and simulationsoverviewmodeling and simulation have provided important methods and tools to support the system engineering process since the days of analog computers. models and simulations represent a more formal step in humansystem design. they can reduce the time and data gathering required for functional evaluation by screening alternatives and identifying the critical parameter ranges to test. they can also be used for decision making about specications or the most promising design alternatives. today the capabilities of computers to support virtual environments, multiperson video games, complex systems and their subsystems, and even human thinking processes makes the potential range of application almost limitless.the term ﬁcomputer simulation,ﬂ or often just ﬁsimulation,ﬂ implies using a computer to mimic the behavior of some physical or conceptual system or environment. it can be used to make concrete the eventual real effects of alternative conditions and courses of action, or it can be used to support training. the term ﬁmodelﬂ is widely used for everything from fashion design mannequins and physical mockups to ˚ow charts and block diagram abstractions. because simulations are, by denition, abstractions of the real thing, they make use of models. with respect to humansystem integration, the kinds of simulations and models of interest are quantitative, usually implemented on a computer, and represent one or more aspects of the characteristics, performance, or behavior of a system, a human, or a humanmachine system combination. a simulation of a system also implies a representation of the environment in which it operates. there are many ways to express such models, ranging from closed form mathematical equations to highdelity humansystem computer simulations.types and uses of models and simulationshumanintheloop simulationthe link trainer is perhaps one of the earliest humanintheloop computer simulations. it was an approximate representation of the equations of motion of an airplane and used real aircraft instruments and controls in the cockpit mockup so that a human could practice the skills of instrument ˚ying. later, when simulators began to represent the pilot™s visual eld outside the aircraft, a smallscale physical mockup of a section of terrain was created and a television camera ﬁ˚ewﬂ over this terrain board to project an image of what the pilot would see. today very sophisticated humanintheloop simulation continues to play an important role, both humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 241in operator training, for everything from aircraft operation to physicians practicing medical procedures, and in system development, to evaluate the performance resulting from new technology, concepts of operation, or procedures. the military services, nasa, and the aerospace industry have used humanintheloop or mission simulation in research and during system development very successfully over the past 20 years.for example, nasa has used simulation in its role in research to support the continued improvement and the reduction of human error in the national aerospace system. they have employed everything from single crew member parttask simulations to fullmission representations of the coordinated behavior of commercial aircraft crews and air trafc controllers in air operations. from 1986 to 2005 the rate of major commercial aircraft accidents per million miles ˚own in the united states was reduced from 0.401 to 0.103, or 75 percent, while the volume of trafc has increased nearly 100 percent (national transportation safety board, 2006). similarly, the u.s. air force has demonstrated the training value of fullmission humanintheloop simulation of air operations involving aircrew and forward air controllers (schreiber and bennett, 2006; schreiber, bennett, and gehr, 2006).network models of humansystem performancesimulations are usually associated with the representation of systems or subsystems, but there is now a large body of literature on simulation to represent the performance of a personmachine system. typically, the model is built on the basis of a detailed task analysis, and each subtask is represented as a node in a network of nodes describing the completion of a higher level task. each node represents, as statistical distributions, the time to complete the subtask and the probability that it will be completed successfully. tasks can be aggregated into still higher levels of activities, goals, or missions. one can represent contingent branching structures among nodes, and the resulting models can become quite complex. outcome performance measures are averaged from multiple (often 100300) monte carlo executions of the model, each calculating the aggregate performance time and success probability of the activity or mission. the programming language, microsaint, is an example of a language, specically designed and widely used to support this kind of simulation. the most wellknown examples of this class of models are the imprint series of models used by the u.s. army to predict the performance of military systems (booher and minninger, 2003; archer, headley, and allender, 2003). imprint has been used to create signicant redesigns in many systems, improving performance, saving millions of dollars, and reducing the risk of elding systems not t for their purpose.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.242 humansystem integration in system developmentthere is also a long history of the use of models and simulations in psychology to represent aspects of human behavior or performance (or both). psychologists use them to summarize what they know and to support theories. some of these models have been shown to be useful for system design to estimate and predict performance or to derive performance measures indicative of humansystem performance.signal detection theoryone such mathematical model is signal detection theory, which was originally developed to quantify the detection of signals in noisy radar returns (peterson et al., 1954). it is applicable to a wide range of humansystem decision problems, including medical diagnosis, weather forecasting, prediction of violent behavior, and air trafc control, and it has been shown to be a robust method for modeling these types of problems (swets et al., 2000). signal detection theory has been found to be useful because it provides separate measures of the sensitivity of the humansystem combination to discriminate signal from noise distributions on one hand and the decision criterion (the location of the threshold at which people or machines respond with a signalpresent/signalabsent decision) on the other. the principal value of applying signal detection theory is to develop metrics for humansystem performance and to evaluate design tradeoffs between detector sensitivity, base rates of the signals of interest, and overall predictive value of the system output. the method is best employed to model effectiveness of discrete decision processes supported by automated systems. it serves to reduce the risk of picking the wrong operating point for a decision process, resulting in too many false alarms or a nonoptimal number of successful detections.models derived from human cognitive operationsa second, quite different approach is goms (card, moran, and  newell, 1983). goms models represent, for a given task, the user™s goals, operators (a keystroke, memory retrieval, or mouse move), methods (to reach a goal, such as using keystrokes or a menu to open a le), and selection rules (to choose which method to use). these models can be applied as soon as there is an explicit design for a user interface, and they have been used to predict response times, learning times, workload, and to provide a measure of interface consistency and complexity (i.e., similar tasks should use similar methods and operators). these models are now being more widely applied, and there are tools available to support their use (kieras, 1998; nichols and ritter, 1995; williams, 2000). they provide a sharable representation of the tasks, how they are performed, and how long each humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 243will take. goms models can support user interface hardware and software design in several ways. they can be used to conrm consistency in the interface, that a method is available for each user goal, that there are ways to recover from errors, and that there are fast methods for frequently occurring goals (chipman and kieras, 2004).the goms series of models had their most notable, documented application to predicting the performance of a new design for a telephone information operator™s workstation in project ernestine (gray, john, and atwood, 1993). in this case, a variant of goms predicted that performance with a new telephone operator workstation design would be so much slower than that of the existing workstation, which would result in an increased operation cost of about $2.5 million per year. the new workstation was actually built and soon abandoned because the predictions were correct. as another example, preliminary studies suggest that a modeling approach could make cell phone menu use more efcient by reducing interaction time by 30 percent (st. amant, horton, and ritter, 2004). if applied across all cell phones, this would save 28 years of user time per day. gong and kieras (1994) describe a goms analysis that suggested a redesign of a commercial computeraided design system would lead to a 40percent reduction in performance time and a 46percent reduction in learning time. these time savings were later validated with actual users. thus, simple goms models can reduce the risk of subsequent operational inefciencies quite early in the system development process.models can also provide quantitative evidence for changešthey can be used to reject a design that does not perform well enough. glen osga (noted in chipman and kieras, 2004, pp. 910) did a goms analysis of a new launch system for the tomahawk cruise missile system. the analysis predicted that the launch process with the new system would take too long. this was ignored and the system was built as designed. indeed, the system failed its acceptance test and had to be redesigned. as chipman and kieras note, it was costly to ignore this analysis, which could have led to a better design.despite their usefulness, goms models have not been as widely used by human factors specialists or systems engineers in systems development, particularly in large systems. although relatively straightforward, they are perceived to be too difcult and timeconsuming to apply.digital human physical simulationsa third class of models is anthropometric representations of the size, shape, range of motion, and biomechanics of the human body (see also the section on physical ergonomics). digital human models have been created to predict how humans will t into physical workspaces, as in ground, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.244 humansystem integration in system developmentaircraft, or space vehicles or to assess operations under the constraints of encumbering protective clothing. representative of these models are commercial offerings, such as jack (http://www.ugs.com/products/tecnomatix/humanperformance/jack/) (badler, erignac, and liu, 2002), safeworks, (http://www.motionanalysis.com/applications/industrial/virtualdesign/safeworks.html), and ramsis (http://www.humansolutions.com/automotiveindustry/ramsiscommunity/indexen.php). they are available as computer programs that represent the static physical dimensions of human bodies, and they are increasingly able to represent the dynamics and static stresses for ergonomic analyses (chafn, 2004). they are primarily used for checking that the range of motion and accessibility are feasible, consistent with safe ergonomic standards, and efcient. they typically contain an anthropometric database that enables them to perform these evaluations for a range of types and sizes of users.dynamic anthropometric models are thus routinely used to reduce the risks of creating unusable or unsafe systems. the resulting models and analyses can be shared between designers and across design phases. having a concrete computer mannequin that conrms the success or failure of accommodation at a workplace is a very useful shared representation. there is beginning to be interest in integrating these models with human behavior representations to integrate the physical and cognitive performance of tasks. midas provided an early demonstration of this concept, and new developments are being introduced regularly (e.g., carruth and duffy, 2005).models that mimic human cognitive and perceptualmotor behaviora fourth class, human performance and information processing models, simulates the sensory, perceptual, cognitive, and motor behavior of a human operator. they are referred to by some as integrated models of cognitive systems and by the military as human behavior representations. they interact with a system or a simulation and represent human behavior in enough detail to execute the required tasks in the simulation as a human would, mimicking the results of a humanintheloop simulation without the human.some of these models are based on ad hoc theories of human performance, such as the semiautonomous forces in simulations, such as the military modsaf and jsaf. others are built on cognitive architectures that represent theories of human performance. examples of cognitive architectures include cognet/igen (zachary, 2000), created specically for engineering applications; soar (laird, newell, and rosenbloom, 1987), an articial intelligenceœbased architecture used for modeling learning, interruptability, and problem solving; actr (anderson et al., 2004), used to model learning, memory effects, and accurate reaction time performance; humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 245epic (kieras, wood, and meyer, 1997), used to model the interaction between thinking, perception, and action; and domar (deutsch, 1998), used to model teamwork. available reviews note further examples that have been developed for specic purposes (morrison, 2003; national research council, 1998; ritter et al., 2003).these human behavior representations are more detailed because they actually mimic the information processing activities that generate behavior. they require a substantial initial investment, and each new application requires additional effort to characterize the task content to be performed. however, once developed, they can be used, modied, and reused throughout the system development life cycle, including to support conceptual design, to evaluate early design prototypes, to exercise system interfaces, and to support the development of operational procedures. they offer the ability to make strong predictions about human behavior. because they provide not only what the descriptive models provide, but also the details of the information processing, they can be used to support applications in which it is useful to have models stand in for users for such things as systems analyses, or in training games and synthetic environments as colleagues and opponents. models in this class have been used extensively in research and demonstration, but they have not, as yet, been widely used in system design (gluck and pew, 2005).in some cases, models of human performance are represented only implicitly in a design tool that takes account of human performance capacities and limitations in making design recommendations. automatic web site testing software is an example of this. guidelines and style guides that suggest good practice in interface design are increasingly being implemented in design tools and guideline testing tools. a review of these types of testing tools shows their ease of use and increasing range (ivory and hearst, 2001). for example, ﬁbobbyﬂ (http://www.watchre.com/products/webxm/bobby.aspx) is one of many tools to test web sites. bobby notes what parts of a web site are barriers to accessibility by people with disabilities and checks for compliance with existing accessibility guidelines (e.g., from section 508 of the u.s. rehabilitation act). bobby does this by checking objects on a web page in a recursive manner against these guidelines (e.g., that captions for pictures are also provided to support blind users, that fonts are large enough).while the developers of these systems may not have thought specically about developing a model of the user, the guidelines and tools make assumptions about users. for example, bobby makes assumptions about the texttospeech software used by blind users, as well as about the range of visual acuity of sighted users. the implementation often hides the details of these models, creating human performance models that are implicit with the shared representation being only the results of the test, not the assumptions humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.246 humansystem integration in system developmentsupporting the test. on one hand, to their credit, these tools represent methods of incorporating consideration of human characteristics into designs that are very easy to use. on the other hand, just as with using statistics programs without understanding the computations they implement, using these tools without understanding the limitations of their implicit user models and performance specications creates risks of inappropriate application or overreliance on the results.contributions to system design phaseshumansystem simulation can play an important role in system design across the development life cycle to reduce the development risk. humanintheloop simulation is widely accepted and has been applied successfully in all of the lifecycle phases discussed below. in this section, we focus on applications of humansystem modeling because this kind of modeling has been less widely applied and has the potential to make signicant contributions. in research labs routinely and increasingly in applied settings, the use of explicit computer models representing human performance has been demonstrated for a variety of uses, including testing prototypes of systems and their interfaces; testing full interfaces to predict usage time and errors; providing surrogate users to act as colleagues in teamwork situations; and validating interfaces as meeting a standard for operator performance time, workload, and error probability. they can also be used to evaluate the ability to meet user requirements and the interface consistency in a common system or a system of systems. further reviews on models in system design are available (e.g., beevis, 1999; howes, 1995; national research council, 1998; vicente, 1999).exploration and valuationhumansystem models can be useful in exploratory design, because they can range from backoftheenvelope calculations to formal models that re˚ect, at a detailed level, the costs and benets of alternative approaches to a new or revised system. if one is working in air trafc control, for example, models of trafc ˚ow in the u.s. airspace could be modied to postulate the impact of introducing alternative forms of automation. analysis and network models will be particularly helpful in this stage because they are more ˚exible and can be performed earlier in the design process. in many cases, the model™s impact in the elaboration phase may be derived from design lessons learned from previous designsšthey will help the designer choose better designs in what can be a very volatile design period.an important contribution of a model, especially in the early development stages, is that the model™s development forces the analyst to think very deeply and concretely about the human performance requirements, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 247about the usersystem interactions, and about the assumptions that must be made for a particular design to be successful. for example, a network model can help make explicit the tasks that must be supported, providing a way for development teams to see the breadth of applicability and potential requirements of a system.architecting and designduring the system™s construction period, models help describe and show the critical features of human performance in the system. a humansystem performance model can serve as a shared representation that supports envisioning the hsi implications of a design. as such, they can help guide design, suggesting and documenting potential improvements. most model types can be used to predict a variety of user performance measures with a proposed system. these measures, including the time to use, time to learn, potential error types, and predicted error frequency, can provide predicted usability measures before the system is built. the models do not themselves tell how to change the system, but they enable alternative designs to be compared. as designers incorporate the implications of a representation in their own thinking, the models also suggest ways to improve the design. in addition, experience with models re˚ecting multiple design alternative provides a powerful way to help designers understand how the capacities and limitations of their users constrain system performance. booher and minninger (2003) provide numerous examples in which redesign was performed, sometimes with initial reluctance but with longterm payoff based on modelbased evaluations at this and later stages of design.in a previous section, the usefulness of prototypes was highlighted. prototypes can be represented at many different levels of specicity. when the design has progressed to the point at which concrete prototype simulations can be developed, it can be very useful to exercise the simulation with a human behavior representation. the development of the human behavior representation itself will be illuminating because it will make the tasks and human performance concrete, but it will also be useful for exploring alternative operational concepts, rening the procedures of use, and identifying the user interface requirements. again, the humansystem simulation can serve as a very useful shared representation that brings the development team together.evaluationmodels can be very helpful in evaluating prototype system and userinterface designs. that is, using a model of the user to evaluate how the interface presents information or provides functionality.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.248 humansystem integration in system developmentrening and testing offer perhaps the canonical application of user models in system design. the same or rened versions of models applied earlier in the design process can be reused to support system evaluation. a human model can exercise the interface and compute a variety of usability and system performance measures. while the system is still evolving, evaluation is formativešthat is, supporting renement and improvement. in the later stages of test and evaluation, the evaluation is summative, providing estimates of how the system will perform in the eld. many examples of rening systems using models are now are available (booher and minninger, 2003; kieras, 2003; st. amant, freed, and ritter, 2005).also, all types of models have been used to help create system documentation or for developing training materials. as the model species what knowledge is required to perform a task, the model™s knowledge can also serve as a set of information to include in training and operations documentation, either as a manual or within a help system.operationthe designs of a complex system are never complete because they continually evolve. humansystem simulations can continue to be applied to guide the evolution as experience is gained from the system in the eld. potential changes can be tried out in the simulated world and compared with the existing performance. this has frequently been done in the space program, in which engineers on the ground try out solutions with simulation to nd the best one to communicate to the actual ˚ight crew. it should be noted that simulations are less successful as complexity grows and for dealing with conditions such as boundary conditions and anomalies.strengths, limitations, and gapsstrengthssimulations, particularly humanintheloop simulations, and humansystem models are especially valuable because they make concrete, explicit, and quantitative the role of users in task execution and their impact on the characteristics of the systems to be controlled. they provide concrete examples of how a system will operate, not only how the equipment will operate, but also what humansystem performance will result. another aspect of the use of models and simulations in design is the cumulative learning that occurs in the designer as a result of a simulationbased design and evaluation process. when using a model or simulation to design an interface, the designer receives feedback about users, their behavior, and how they interact with systems. in their next design task, if the feedback was explicit humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 249and heeded, designers have a richer model of the user and of the system, their joint behavior, and the roles users play. having the knowledge in the designer™s head supports the creative process and makes the knowledge easier to apply than through an external tool.limitationsease of use. if the models are more challenging and costly in time and effort than practitioners are willing to use, then one cannot expect them to be used to reduce risk during development. fullmission humanintheloop simulation is costly and timeconsuming to apply and should be used only when the potential risks and opportunities justify it. parttask simulation is a less costly alternative in which only the elements that bear critically on the questions to be answered are simulated. humansystem models range widely in their scope and the effort required to apply them. while the keystrokelevel model version of goms can be taught fairly quickly, other modeling approaches all appear to be more difcult to use than they should be and more difcult than practitioners currently are willing to use routinely. even imprint, a welldeveloped and popular collection of models, is considered too difcult for the average practitioner to use. this may be inherent in the tools; it may be due to inadequate instructional materials or to inadequacies in the quality of the tools and environments to support model development and use. it may also result from the lack of education or experience about how valuable the investment in models can bešthat the investment is worth the cost in time and effort. few people now note how expensive it is to design and test a computer chip, a bridge, or a ship or bemoan the knowledge required to perform these tasks. and yet humans and their interactions are even more complex; designing for and with them requires expertise, time, and support. further work is needed to improve the usability of the model development process and the ease of use of the resulting models.in order for humansystem models to be credible as shared representations, they must make their characteristics and predictions explicit in a way that can be understood by the range of stakeholders for whom they are relevant. there is a range of questions that people ask about models including what their structure is, how they ﬁwork,ﬂ and why they did or did not take a particular action (councill, haynes, and ritter, 2003). this problem is more acute for the more complex models, particularly the informationprocessing models. unclear or obtuse models risk not being used or being ignored if they are not understood. promoting the understanding of models will increase trust in understanding where the system risks are. future models will need to support explanations of their structure, predictions, and the source of the predictions.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.250 humansystem integration in system developmenthow models are developed will be important to how models will be used in system design. using models across the design process from initial conception to test and evaluation will require adapting the level of depth and completeness to each task. right now, model developers are at times still struggling with building user models once, let alone for reuse and across designers and across design tasks.there have been several efforts to make models more easily used. for human behavior representations, these include amadeus (e.g., young, green, and simon, 1989), apex (freed et al., 2003), cogtool (john et al., 2004), herbal (cohen, ritter, and haynes, 2005), and g2a (st. amant, freed, and ritter, 2005). at their best, these tools have offered, in limited cases, a 3 to 100 times reduction in development time, demonstrating that progress can be made in ease of use.while promising, these tools are not yet complete enough to support a wide range of design or a wide range of interfaces, tasks, and analyses. for example, cogtool is useful and supports a full cycle of model, test, revise interface. it cannot model problem solving or realtime interactive behavior, but it starts to illustrate what such an easytouse system would look like. research programs have been sponsored by the u.k. ministry of defence (ﬁreducing the cost of acquiring behavioursﬂ) and by the u.s. ofce of naval research (ﬁaffordable human behavior modelingﬂ) to make models more affordable and are sources of further examples and systems in this area.integration. there are gaps in integrating user models within and across design phases as well as connecting them to the systems themselves. as models get used in more steps in the design process, they will serve as boundary objects, representing shared understanding about users™ performance in the systems under evaluationštheir goals, their capabilities to execute tasks, and their behavior. imprint has often been used this way. once widely used, there will be a need to integrate models to ensure that designers and workers at each stage are talking about the same usersystem characteristics. the models might usefully be elaborated together, for example, starting with a goms model and moving to a human behavior representation model to exercise an interface. this kind of graceful elaboration has been started by several groups (lebiere et al., 2002; ritter et al., 2005, 2006; urbas and leuchter, 2005) but is certainly not yet routine.the models will also have to be more mutable so that multiple views of their performance can be used by participants in different stages of the design process. some designers will need highlevel views and summaries of behavior and the knowledge required by users to perform the task, and other designers may need detailed time predictions and how these can be improved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.defining requirements and design 251it is especially valuable for models of users to interact with systems and their interfaces. models that interact with systems are easiest for designers to apply, most general, and easiest to validate. eventually it could allow models™ performance to serve as acceptance tests, and it may lead to new approaches, such as visual inspection of operational mockups rather than extensive testing. currently, connecting models to system or interface simulations is not routine. the military has shown that the highlevel architecture connection approach can be successful when the software supporting the models and systems to be connected is open and available for inspection and modication. however, much commercial software is proprietary and not available for modication to support model interaction (ritter et al., 2000). in the long term, we think that the approach of having models of human behavior representations interacting directly with an unmodied or instrumented interface software will become the dominant design approach, which can also include automatic testing with explicit models. models that use segman represent steps toward this approach of automatic testing of unmodied interfaces (ritter et al., 2006; st. amant, horton, and ritter, 2004).highlevel languages. currently, many models, particularly human behavior representation models, require detailed specications. creating these models for realistic tasks can be daunting. for example, there are at least 95 tasks to include in a university department web site design (ritter, freed, and haskett, 2005). one way to reduce the risk that human behavior models will be unused is to provide a highlevel language that is similar to that used in network models. interface designers will need a textual or graphical language to create models that are higher level than most of the current human behavior representation languages, and analysts will need libraries of tasks (or the ability to read models as if they were libraries), and they will need to be able to make it easy to program new and modied tasks. more complete lists of requirements for this approach are available (e.g., kieras et al., 1995; ritter, van rooy, and st. amant, 2002).cultural, team, and emotional models. models of individual task performance have rarely included social knowledge about working in groups or cultural differences. users are increasingly affected by social processes, including culture and emotion. as one better understands the role of these effects on systems, models will need to be extended to include what is known about these characteristics as a further element of risk reduction. for a mundane but sometimes catastrophic example, consider the interpretation of switches in different cultures. some cultures ˚ip switches up to be on, and some switch them down. the design, and implementation, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.252 humansystem integration in system developmentof safetycritical switches, such as aircraft circuit breakers or power plant controls, needs to take account of these cultural differences.social knowledge, cultural knowledge, theories of emotions, and task knowledge have been developed by different communities: models of social processes will need to be adapted if they are to be incorporated in models of task execution (like human behavior representation models, hudlicka, 2002). understanding and applying this knowledge to design is of increasing interest as a result of a desire to improve the quality of models performance and an acknowledgment that cultural, team, and emotional effects in˚uence each other and task performance. for example, there is a forthcoming national academies study on organizational models (national research council, 2007) and there is also recent work on including social knowledge in models of human behavior representation (e.g., sun, 2006).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.8methods for evaluationthis chapter presents two classes of methods for evaluating human performance and the interaction between humans and systems. the rst class of methods, risk analysis, discusses the approaches to identifying and addressing business risks and safety and survivability risks. the second class of methods, usability evaluation, describes the range of experimental and observational approaches used to determine the usability of system features in all stages of the system development life cycle. figure 81 provides an overview. this gure lists the foundational methods (e.g., surveys, interviews, experiment design) noted in the introduction to part ii because they play a central role in evaluation.risk analysisoverviewthis section describes some commonly used tools for risk management, including failure modes and effects analysis (fmea) and fault tree analysis (fta). these tools are ˚exible and can be used to assess, manage, and mitigateł business risk due to faults in the development process, including failed steps to consider humansystem integration (hsi).ł failed usability outcomes (e.g., failure to meet customer usability objectives, which results in product failure in the marketplace).253humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.254 humansystem integration in system development risk analysis  usability evaluation methods sample shared representationsproducedrepresentativeset of methodswho™s involved?design experts and other stakeholdersdomain practitionershsi activitiesdefining opportunitiesand context of usedefining requirements and designevaluationhsi activities, participants, methods, and shared representationsł failure modes and effects analyses (fmea)ł fault tree analyses (fta) and other technique variationsł lists of usability problems in the form of: written reports, presentations, or videosł time and accuracy of user™s performance ł user satisfaction ratings  surveys/questionnaires experiment design interviews statistics performance measurement81revised 3/30/07figure 81 representative methods and sample shared representations for evaluation.ł useerror faults that result in harm to product users (e.g., medical devices, failed mission objectives, such as failure to destroy enemy targets in a military system).the emphasis is on use of these tools to evaluate and control negative outcomes related to use error or errors resulting from defects in the user interface element of humansystem integration. by simple extensions, they can also be used to evaluate and control business risk related to the development cycle. most of the following text is focused on use errors, but we make the case for the relative ease of using the philosophy behind these tools for many other purposes, including assessing and controlling business risk. in the military, the analysis of use error is especially relevant to the hsi domains of human factors, safety and occupational health, and survivability.as noted, these tools and related methods are frequently applied to understanding use errors made with medical and other commercial devices. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 255use errors are dened as predictable patterns of human errors that can be attributable to inadequate or improper design. use errors can be predicted through analytical task walkthrough techniques and via empirically based usability testing. here we explain and discuss the special methodology of useerror focused risk analysis and some of its history. examples are presented that illustrate the methods of useerror risk analysis such as fta and fmea and some pitfalls to be avoided. these methods are widely used in safety engineering. the concepts are illustrated with a medical device case study using an automatic external debrillator and a business risk example.riskmanagement techniquesrisk analysis in the context of use errors in products and processes has received increasing attention in recent years, particularly for medical devices. these techniques have been used for decades to assess the effect of human behavior on critical systems, such as in aerospace, defense systems, and nuclear power applications. use errors are dened as a pattern of predictable human errors that can be attributable to inadequate or improper design. use error can also produce faults that create failures for many types of systems and products, includingł ecommerce web sitesšthe user fails to complete the checkout process and revenue from orders is lost.ł weapons systemsšthe user fails to arm and deploy the weapons system and a critical enemy target survives and goes on to destroy combat systems and personnel.ł energy systemsšthe operator fails to detect and isolate a component failure and the entire energy plant fails.ł transportation systemšthe driver fails to avoid another approaching vehicle and all occupants of both vehicles are killed in the subsequent collision.dening use erroruse error is characterized by a repetitive pattern of failure that indicates that a failure mode is likely to occur with use and thus has a reasonable possibility of predictability of occurrence. use error can be addressed and minimized by the device designer and proactively identied through the use of such techniques as usability testing and hazard analysis. an important point is that, in the area of medical products, regulator and standards bodies make a clear distinction between the common terms ﬁhuman errorﬂ and ﬁuser errorﬂ in comparison to ﬁuse error.ﬂ the term ﬁuse errorﬂ attempts humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.256 humansystem integration in system developmentto remove the blame from the user and open up the analyst to consider other causes, including the followingł poor user interface design (e.g., poor usability).ł organizational elements (e.g., inadequate training or support structure).ł use environment not properly anticipated in the design.ł not understanding the user™s tasks and task ˚ow.ł not understanding the user prole in terms of individual differences in training, experience, task performance, incentives, and motivation.analysis of human errorthe analysis of human error has played a central role in risk analysis since the 1950s. initially in nuclear weapons assembly, then in the nuclear power industry and in industry more generally, particularly after the three mile island accident in 1979. although in this chapter, risk analysis focuses on safety critical systems, the risk of human error is relevant to humansystem integration more generally because errors can also result in inefciencies, excessive cost of operations, and wasted resources.  reason (1990) provides a comprehensive classication of errors as shown in figure 82. this classication makes clear that even though every error is identied by an action, the source of the error can be a much wider set of alternative failures. the category of knowledgebased mistakes can be expanded to include the many additional psychological sources of mistakes, including the following:ł situation awareness.ł decision making.ł estimation.ł computation.embry (1987) summarizes approaches to human reliability assessmentšthat is, assessment of the risk of human error. the oldest and most wellknown technique is the technique for human error rate prediction (therp) (swain, 1963; swain and guttman, 1983). this approach is based on probabilistic risk analysis and fault tree task decomposition methods, and it has been applied extensively in nuclear power plant design and procedure assessment. the techniques described in this chapter are the basic building blocks of quantitative methods, such as therp; the degree to which complex models involving estimates of error probability are necessary depends largely on the application and extent to which quanticahumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 257unsafe  actsunintended  actionintended  actionsliplapsemistakeviolationattentional failures  intrusion  omission  reversal misordering  mistimingmemory failures  omitting planned items  placelosing  forgetting intentionsrulebased mistakes  misapplication of good rule  application of bad rule knowledgebased mistakes  many variable formsroutine violations exceptional violations acts of sabotagebasic error  types82figure 82 reason™s error classication. source: reason (1990). reprinted with the permission of cambridge university press.tion is necessary. however, basic error risk analysis as described in this chapter is relatively straightforward and is warranted in virtually all hsi applications.identication of hazards and when risk management is conductedan important rst step in risk management is to understand and catalogue the hazards and possible resulting harms that might be caused by a product or system. sometimes this is called hazard analysis. others use the term in a more general way as a synonym for riskmanagement. hazard analysis is often accomplished as an iterative process, with a rst draft being updated and expanded as additional risk management methods (e.g., fmea, fta) are used. medical experts and those in quality control and product development, among other commercial product disciplines, can brainstorm on harms and hazards. technically, hazards are the potential for harms. harms are dened as physical injury or damage to the health of people or damage to property or the environment. box 81 shows examples humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.258 humansystem integration in system developmentbox 81 possible harms and hazards from the use of medical equipmentuse of an automatic needle injection device ł bleeding, bruising, or tearing of skin, leading to a possible infection ł incomplete injection that may lead to giving another injection, leading to overmedication ł undermedication ł delay in therapy ł failed therapy due to unsuccessful injection ł pain on injection ł increased bleeding, due to the presence of alcohol ł nondelivery, wasted dose ł delivery intramuscularly instead of subcutaneously ł possible infection from microorganisms present on skinuse of an automatic external debrillator ł nondelivery of debrillating shock ł delay in delivery of debrillating shock ł administration of shock when not needed ł bystander shocked when touching patient during delivery ł set victim on re ł delivery of weak noneffective shock ł ignoring subsequent second episode of cardiac brillation ł burns caused by delivery of electrodes touching each otherof harms from hazards for a penlike automatic needle injector device and shows similar harms and hazards from an automatic external debrillator. box 82 extends the notion of harm to negative business outcomes resulting from hsi faults.below we describe the most commonly used tools involved in user error risk analysis, fmea, and fta. these tools can also be used to assess and control business risk. the shared representations typically resulting from these methods are reports containing graphical portrayals of the fault trees or tabular descriptions of the failure modes. the fta representations show cumulative probabilities of logically combined fault events demonstrating the overall risk levels. the tabular shared representations documented with fmea tables show calculated risk levels associated with different business or operational hazard outcomes.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 259box 82 negative business outcomes resulting from hsi faultsł product cannot be developed. all development costs are sunk costs with no return on investment (roi).ł product introduction is delayed and market window is missed. reduced net present value (npv) of product revenue stream.ł substandard product is introduced and support costs become very high.ł manufacturing costs of the product exceed estimates in business case and margins are drastically reduced.ł not all desired features can be delivered and product fails to meet revenue plan in business case.ł product is faulty and needs to be recalled. recall costs are enormous.ł product is unsafe and subsequent liability claims become very large and threaten the nancial viability of the development organization.ł product fails to meet the target market needs (not developed for the most important user proles) and misses revenue plans.shared representationsfmeathe recommended steps for conducting a useerror risk analysis are the same as for traditional risk analysis with one signicant addition, namely the need to perform a task analysis. possible use errors are then deduced from the tasks (israelski and muto, 2006). each of the use errors or faults is rated in terms of the severity of its effects and the probability of its occurrence. a risk index is calculated by combining these two elements and can then be used for risk prioritization. for each of the highpriority items, modes (or methods) of control are assumed for the system or subsystem and reassessed in terms of risk. the process is iterated until all higher level risks are eliminated and any residual risk is as low as reasonably practicable (sometimes referred to as alarp).among the most widely used of the risk analysis tools is fmea and its close relative, failure modes, effects, and criticality analysis (fmeca).1 1 fmeca is an extension of fmea that starts with fmea elements and further considers ratings of criticality and probability of occurrence. because of their common basis, fmea and fmeca are commonly referred to as fmea. likewise, in this section fmea and fmeca will be referred to as fmea.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.260 humansystem integration in system developmentfmea is a design evaluation technique used to dene, identify, and eliminate known or potential failures, problems, and errors from the system. the basic approach of fmea from an engineering perspective is to answer the question: if a system component fails, what is the effect on system performance or safety? similarly, from a human factors perspective, fmea addresses the question, ﬁif a user commits an error, what is the effect on system performance from a safety or nancial perspective?ﬂ a human factors risk analysis has several components that help dene and prioritize such faults: (1) the identied fault or use error, (2) occurrence (frequency of failure), (3) severity (seriousness of the hazard and harm resulting from the failure), (4) selection of controls to mitigate the failure before it has an adverse effect, and (5) an assessment of the risk after controls are applied.a useerror risk analysis is not substantially different from a conventional design fmea. the main difference is that, rather than focusing on component or systemlevel faults, it focuses on user actions that deviate from expected or ideal user performance. for business risk, the development faults would include the items shown in box 82. table 81 summarizes the steps in performing fmea.fta and other technique variationsother commonly used tools for analyzing and predicting failure and consequences are fault tree and event tree analysis. fta is a topdown deductive method used to determine overall system reliability and safety (stamatis, 1995). a fault tree, depicted graphically, starts with a single undesired event (failure) at the top of an inverted tree, and the branches show the faults that can lead to the undesired eventšthe root causes are shown at the bottom of the tree. for human factors and safety applications, fta can be a useful tool for visualizing the effects of human error combined with device faults or normal conditions on the overall system. furthermore, by assigning probability estimates to the faults, combinatorial probabilistic rules can be used to calculate an estimated probability of the toplevel event or hazard.an event tree is a visual representation of all the events that can occur in a system. as the number of events increases, the picture fans out like the branches of a tree. event trees can be used to analyze systems that involve sequential operational logic and switching. whereas fault trees trace the precursors or root causes of events, event trees trace the alternative consequences of events. the starting point (referred to as the initiating event) disrupts normal system operation. the event tree displays the sequences of events involving success and/or failure of the system components. in human factors analysis the events that are traced are the contingent sequences of human operator actions (swain and guttman, 1983).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 261table 81 steps in performing fmeastepsdescription 1.  form a teamthe most effective risk analyses are performed by a team of stakeholders. 2.  perform a task analysisa task analysis is a detailed sequential description (in graphic, tabular, or narrative form) of tasks performed while operating a devise or system. the analysis should cover the major task ˚ows performed by users. 3.  start a worksheetthere are a variety of fmea worksheets for documenting use errors. computer spreadsheets can be useful. 4.  brainstorm potential use errors (failure modes)brainstorming involves identifying possible operator errors and actions that deviate from the expected or optimal behavior for each task identied in the task analysis (step 2 above). 5.  list potential effects of each failure mode/operator errorthe team identies potential harms associated with each failure mode. this step is important for subsequent determination of risk ratings. 6.  assign severity ratings to the harm or negative outcomesa severity rating determines the seriousness of the effects of a given fault if it occurs. severity can be assigned a numeric value or a qualitative descriptive rating. 7.  assign occurrence ratingsoccurrence ratings are estimates of the predicted frequency or likelihood of the occurrence of a fault. these ratings should be based on existing data such as customer complaints or usability test results. 8.  derive risk indexa numeric risk index is calculated by multiplying the severity rating by the occurrence rating. a qualitative risk rating requires the development of criteria establishing risk levels based on combinations of severity and occurrence ratings. 9.  prioritize risksrisks are prioritized to determine how, when, and whether identied failure modes should be addressed.10.  take actions to eliminate or reduce highpriority failure modesorganized problemsolving approaches are used by the team to select modes of control for each highpriority failure. the most desirable mode of control is design; training and warnings may also be considered.11.  assign effectiveness ratingseffectiveness ratings are assigned to each mode of control selected/identied in step 10 above. depending on the stage in the development life cycle, these ratings may be based on either formative or summative evaluation data.12.  revise risk prioritieswhen modes of control are in place, numerical or qualitative risk indices are revised or recomputed.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.262 humansystem integration in system developmentas with fmeas, fault trees and event trees can be developed by teams or by individuals with team review. for more information, refer to the literature in reliability engineering or systems safety engineering (e.g., nuclear regulatory commission, 1981).in recent years, graphical software programs have been made available for personal computers that enable users to rapidly assemble fault trees by ﬁdragging and droppingﬂ standard logic symbols onto a drawing area and connections are made (and maintained) automatically. these tools automatically calculate branch and toplevel probabilities based on the estimated event probabilities entered. such tools make ftas much more accessible and much less labor intensive. figure 83 is an example of a fault tree diagram for an automatic external debrillator. table 82 shows a summary of the steps in creating an fta.contributions to system design phasesuseerrorfocused risk analyses including fmea and fta are particular methods in the usercentered or human factors design process. it is the analytical complement to empirical usability assessment, commonly called usability testing. risk analysis, evaluation, and control starts early in any development process (e.g., the incremental commitment model development process) and is iterated and reassessed as the development process progresses and the system design matures. for humansystem integration, risk is assessed for usability, systems safety, and survivability issues. there are opportunities to develop single analyses that would serve all of these purposes, with the proper coordination across these development teams.strengths, limitations, and gapsthese riskmanagement techniques can be powerful analytic tools. tables 83 and 84 list advantages and disadvantages of both fmeas and ftas.the limitations for ftas and fmeas are similar:ł achieving group consensus is difcult. research is needed on more effective and reliable techniques, such as modications of the delphi group decisionmaking technique. groups can be dominated by individuals based on their rank, power, or personality, and the nal ratings may not really re˚ect the group opinion.ł estimating likelihood of occurrence is very unreliable. better probability modeling is needed.ł better tools are needed to integrate ftas and fmeas to make them easier to modify and apply.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved. 263figure 83 example fta for a hypothetical automatic external debrillator.source: israelski and muto (2006). used with permission of lawrence erlbaum associates.permission was not granted to post this figure on the web. refer to the source or the printed book.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.264 humansystem integration in system developmenttable 82 steps in performing an ftastepsdescription1.  identify the toplevel hazards. the team will brainstorm to identify the toplevel hazards (undesired events) to be addressed. a fault tree will be developed for each of these hazards.2.  identify fault tree events.identify faults and other events (including normal events) that could result in the toplevel undesired event. these can be documented in a list or on notes posted on a wall.3.  identify the conditions under which the events can lead to failure. these include events that may lead directly to harm (singlepoint failure) or cause another fault without other events occurring; events that must happen in conjunction with other events to cause failure; and events that must happen in sequence to cause a failure.4.  combine the above events into a fault tree. a fault tree is constructed using symbols that represent individual events and the most signicant logic symbols, the ﬁor gateﬂ and the ﬁand gate.ﬂ5.  assign probabilities to each event. if the fault tree does not sufciently characterize the system and human interactions, the team will assign probabilities to each of the events based on quantitative data or estimates based on expert judgment.6.  calculate the probability of each of the branches leading to the toplevel hazard. fault tree probabilities propagate upward from the individual events. the probability of the individual gates and the overall fault tree probability are computed by using numerical combinatorial rules for various logic gates. table 83 advantages and disadvantages of fmeaadvantagesdisadvantagesrisk index /rpn enable prioritization of faults.difcult to assess combination of events complex interactions (unless explicitly documented).explicitly documents modes of control/mitigation.large documents can be difcult to manage: minimize inconsistencies and redundant items.format useful for tracking action items.severity and occurrence ratings are often difcult for individuals or teams to estimate. much time can be spent in discussions.easily constructed using hand written spreadsheets or computerbased software tools: spreadsheets/word processing tables specialized fmea tools.sometimes can be overly conservative. with each fault isolated, failure to consider combinatorial events (as do fault trees) may lead to the false conclusion that every item requires explicit mitigation.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 265table 84 advantages and disadvantages of ftaadvantagesdisadvantagesgraphical format enables visualization of combination of events.drawings can become large and unwieldy in complex systems.enables estimation of overall probability of failure based on estimates of root causes.modes of control are not always explicit.small fault trees can be developed using common ˚owchart drawing tools.requires more training than fmea.special software required for rapid development of fault trees.usability evaluation methodsoverviewthis section explains how usability evaluation methods can contribute to systems development by providing feedback on usability problems and validating the usability of a system. these methods not only help improve the user interface, but also often provide insight into the extent to which the product will meet user requirements.there are four broad approaches to ensuring the usability of a product or system:1. evaluation of the user™s performance and satisfaction when using the product or system in a real or simulated working environment. also called evaluation of ﬁquality in useﬂ or ﬁhuman in the loop.ﬂ2. evaluation of the characteristics of the interactive system, tasks, users, and the working environment to identify any obstacles to usability.3. evaluation of the process used for systems development to assess whether appropriate hsi methods and techniques were used.4. evaluation of the capability of an organization to routinely employ appropriate hsi methods and techniques.thus, an organization needs the capability to apply humansystem integration in the development process in order to be able to design a product or interactive system with characteristics that will enable adequate user performance and satisfaction in the intended contexts of use (figure 84).evaluation of the usability of a product provides feedback on the extent to which a design meets user needs, and thus it is central to a usercentered design process. feedback from usability evaluation is particularly important because developers seldom have an intimate understanding of the user™s perhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.266 humansystem integration in system developmentfigure 84 approaches to ensuring usability. the quality in use is determined by the quality of the product, which is determined by the quality of the development process, which is determined by the organizational capability.developmentprocessproductcharacteristics processquality productqualityquality in useorganizationprocessesorganizationalcapability userperformanceandsatisfaction84spective and work practices. in the collective experience of the committee, initial designs therefore very rarely fully meet user requirements. the cost of rectifying any divergence between the design and user needs increases rapidly as development proceeds, which means that user feedback should be obtained as early as possible.without proper usability evaluation, a project runs a high risk of expensive rework to adapt a system to actual user needs or of potential rejection of the product or system. usability evaluation can be used to assess the magnitude of these. for more information on evaluating the development process and organizational capability, see earthy, sherwood jones, and bevan (2001).uses and types of methodsusability is determined not only by the characteristics of the interactive product or system, but also by the whole context of use, including the nature of the users, tasks, and operational environment (see chapter 6). in the broadest context, usability is concerned with optimizing all the factors that determine effective interaction between users and systems in a working environment. but in some cases, the scope of the evaluation is more limited, for example to support the design of a particular interactive component in an otherwise predetermined system. the word ﬁproductﬂ is used below to refer to the component or system being evaluated.evaluations of user behavior and product characteristics are complementary. although a userbased evaluation is the ultimate test of usability, it is not usually practical to evaluate all permutations of user type, task, and operational conditions. evaluation of the characteristics of the product or interactive system can anticipate and explain potential usability problems, and it can be carried out before there is a working system. however, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 267evaluation of detailed characteristics alone can never be sufcient, as this does not provide enough information to accurately predict the eventual user behavior.uses of methods: formative and summative evaluationthe most common type of usability evaluation is formative: to improve a product by identifying and xing usability problems. formative evaluation of early mockups can also be used to obtain a better understanding of user needs and to rene requirements. an iterative process of repeated formative evaluation of prototypes can be used to monitor how closely the prototype designs match user needs. the feedback can be used to improve the design for further testing. early formative evaluation reduces the risk of expensive rework. formative evaluation is most effective when it involves a combination of expert and userbased methods.some examples of prototypes that can be evaluated areł paperbased, lowdelity simulations for exploratory testing.ł computer simulations (typically screenbased, e.g., flashž, macromedia directorž, visual basicž, java, html). this can simulate the user interface while sacricing full delity.ł working early prototypes of the actual product.prototypes are discussed in more detail in chapter 7.in a more mature design process, formative evaluation should be complemented by establishing usability requirements (see chapter 7) and testing whether these have been achieved by using a more formal summative evaluation process. summative testing reduces the risk of delivering a product that fails as a result of poor user performance. usability has also been incorporated into six sigma quality methods (sauro and kindlund, 2005).summative usability testing of an existing system can be used to provide baseline measures that can form the basis for usability requirements (i.e., objectives for human performance and user satisfaction ratings) for the next modication or release. a common industry specication for usability requirements (theofanos, 2006) has been developed to support iterative development and the sharing of such requirements.summative tests at the end of development should have formal acceptance criteria derived from the usability requirements. summative methods can also be elaborated to identify usability problems, but if prior iterative rounds of formative usability testing are performed, then typically there will be few usability surprises uncovered during this latestage testing (theofanos, 2006).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.268 humansystem integration in system developmenttypes of methodsthe remainder of this section describes methods in the following categories:user behavior evaluation methodsł methods based on observing users of a real or simulated system.ł methods that collect data from usage of an existing system.ł methods based on models and simulation.product usability characteristics evaluation methodsł methods based on expert assessment of the characteristics of a system.ł automated methods based on rules and guidelines.all the methods can provide formative information about usability problems. the rst two types of user behavior methods can also provide summative data. other more informal techniques (such as a focus group) often do not provide reliable information for evaluation.methods based on observing users of a real or simulated system. methods in this category are usedł at all stages of development if possible.ł to provide evidence for management.ł in observing user trials, as a good way of providing incontrovertible evidence to developers.in these userbased methods, users step through the design attempting to complete a task with the minimum of assistance. there are different types of userbased methods adapted specically for formative testing or to also provide summative data (see table 85).ł formative methods focus on understanding the user™s behavior, intentions, and expectations and typically employ a thinkaloud protocol.ł summative methods measure the quality in use of a product and can be used to establish and test usability requirements. summative usability testing, normally based on the principles of iso 924111 (international organization for standardization, 1998), obtains quality in use measures forhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 269table 85 types of userbased evaluation methodtypedescriptionwhen in design cycletypical sample size (per group)considerationsformative usability testingexploratoryhighlevel test of users performing tasksconceptual design58simulate early concepts, for example, with very low delity paper prototypes or foam core models. diagnosticgive representative users real tasks to perform iterative throughout the design cycle58early designs or computer simulations. used to identify usability problems.comparisonidentify strengths and weaknesses of an existing designearly in design58can be combined with benchmarking.summative usability testingbenchmarkingcompetitivereal users and real tasks are tested with existing designprior to design830to provide a basis for setting usability criteria. can be combined with competitive comparison.validationreal users and real tasks are tested with nal designend of design cycle830to validate the design by having usability objectives as acceptance criteria and should include any training and documentation. œ effectiveness šﬁthe accuracy and completeness.ﬂ errorfree completion of tasks is important in both business and military applications. œ efciencyšﬁthe resources expended.ﬂ how quickly a user can perform work is critical for productivity. œ satisfactionšﬁpositive attitudes toward the use of the product.ﬂ satisfaction is a success factor for any products with discretionary use and essential to maintain workforce motivation.each type of measure is usually regarded as an independent factor with humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.270 humansystem integration in system developmenta relative importance that depends on the context of use (e.g., efciency may be paramount for employers, while satisfaction is essential for public users of a web site).these measures can also be used to assess accessibility (the performance and satisfaction of users with disabilities), and learnability (e.g., the duration of a course or use of training materials), and the user performance and satisfaction expected immediately after training and after a designated length of use. in summative testing, the system to be evaluated may be a functioning prototype (e.g., in alpha or beta testing) or controlled trials of an existing system.methods that collect data from usage of an existing system. this category of methods is used when planning to improve an existing system. they includeł satisfaction surveys: satisfaction questionnaires distributed to a sample of existing users can provide an economical way of obtaining feedback on the usability of an existing product or system.ł web metrics: a web site can be instrumented to provide information on entrance and exit pages, frequency of particular paths through the site, and the extent to which search is successful. if combined with popup questions, the results can be related to particular user groups and tasks.ł application instrumentation: data points can be built into code that ﬁcountﬂ when an event occurs (e.g., in microsoft ofcešharris, 2005). this could be the frequency with which commands are used or the number of times a sequence results in a particular type of error. the data are sent anonymously to the development organization. this realworld data from large populations can help guide future design decisions.for more information, see the section on event data analysis in chapter 6.methods based on models and simulation. this category of methods is used when models can be constructed economically, particularly if user testing is not practical. modelbased evaluation methods can predict such measures as the time to complete a task or the difculty of learning to use an interface. some models have the potential advantage that they can be used without the need for any prototype. however, setting up a model usually requires a detailed task analysis, so modelbased methods are most costeffective in situations in which other methods are impracticable, or the information provided by the model is a costeffective means of managing particular risks. see chapter 7 for more information on modeling.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 271methods based on expert assessment of the characteristics of a system. these methods are used for the following purposes:ł to provide breadth that complements the depth of userbased testing.ł when there are too many tasks to include all of them in a usability test.ł before userbased testing.ł when it is not possible to obtain users.ł when there is little time.ł to train developers.the several approaches to expertbased evaluation are discussed brie˚y in the paragraphs below:guidelines and style guides. conformance to detailed user interface guidelines or style guides is an important prerequisite for usability, as it can impose consistency and conformance with good practice. but as published sources typically contain several hundred guidelines (e.g., iso 9241 series), they are difcult to apply or assess unless simplied and customized to project needs.interfaces can be assessed for conformance with general guidelines, such as the usability heuristics recommended by nielsen (nielsen and mack, 1994) and the iso924110 dialogue principles (international organization for standardization, 1996). checking conformance with iso 924110 forms part of the usability test procedure approved by datech in germany (dzida, geis, and freitag, 2001).parts 1217 of the iso 9241 series of standards contain very detailed user interface guidelines. although these are an excellent source of reference, they are very timeconsuming to employ in testing. further information on standards can be found in bevan (2005).detailed guidelines for web design have proved more useful to both usability specialists and web designers. the most comprehensive, wellresearched, and easytouse set has been produced by the u.s. department of health and human services (2006).following guidelines usually improves an interface, but they are only generalizations so there may be particular circumstances in which guidelines con˚ict or do not applyšfor example, because of the use of new features not anticipated by the guideline.heuristic evaluation. heuristic evaluation assesses whether each dialogue element follows established heuristics. although heuristic evaluation (nielsen and mack, 1994) is a popular technique and research has shown humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.272 humansystem integration in system developmentthat heuristics are a useful training aid (cockton et al., 2003), using heuristics in the context of a taskbased walkthrough is usually more effective.usability walkthrough. usability walkthrough identies usability problems while attempting to achieve tasks in the same way as a user, making use of the expert™s knowledge and experience with relevant usability research. a variation is pluralistic walkthrough, in which a group of users, developers, and human factors people step through a scenario, discussing each dialogue element.cognitive walkthrough. this originally referred to a detailed process of analyzing the cognitive processes of a user carrying out a task, although it is now also sometimes used to refer to a usability walkthrough. the distinctions are summarized in table 86.methods such as a usability walkthrough that employ task scenarios are generally the most costeffective and can be combined with using heuristic principles or checking conformance to guidelines.expert evaluation is simpler and quicker to carry out than userbased evaluation and can, in principle, take account of a wider range of users and tasks than userbased evaluation, but it tends to emphasize more supercial problems (jeffries and desurvire, 1992) and may not scale well for complex interfaces (slavkovic and cross, 1999). to obtain results comparable to userbased evaluation, the assessment of several experts must be combined. the greater the difference between the knowledge and experience of the experts and the real users, the less reliable are the results.automated methods based on rules and guidelines. this category of methods is used primarily for basic screening. there are some automated tools (such as websat, lift, and bobby) that automatically test for conformance with some basic usability and accessibility rules. although these are useful for screening for basic problems, they only test a very limited scope of issues (ivory and hearst, 2001).table 86 types of expertbased evaluation methodsguidelinestask scenariosnoyesnoneexpert reviewusability walkthroughpluralistic walkthroughgeneral guidelinesheuristic inspectionheuristic walkthroughdetailed usability guidelinesguidelines inspectionguidelines walkthroughinformation processing viewn/acognitive walkthroughsource: adapted from gray and salzman (1998).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.methods for evaluation 273shared representationsall evaluations result in a list of usability problems, and these may be reported to the stakeholders in a written report, a presentation, or a video. while the people responsible for sponsoring the usability work may be quite receptive, those who have to act on the results may be less sympathetic. so it is good practice to praise the strengths of the system from a user perspective before listing the problems.the list of problems can be categorized (typically by task or screen) and prioritized, either from a user perspective or by the estimated costs and benets of xing the problem. it may make sense to ignore very lowpriority issues, although they are worth reporting if they are easy to x.for maximum impact, stakeholders should be invited to view userbased evaluations. if this is not practical, edited videos of major issues have a much higher impact than other types of report or presentation.if the evaluation results are being used to validate requirements, they will probably be incorporated into an existing quality control process.contributions to system design phasesevaluation from a user perspective should be an integral part of systems development. in a riskdriven development process, the question is not whether to evaluate, but how to evaluate and how often. early expert or userbased evaluation of mockups of new designs is essential to clarify requirements and to assess the viability of design concepts.evaluation of working prototypes can assess both their ease of use and whether they support the needs and tasks of real users. late evaluation can validate whether a system has met the usability requirements.strengths, limitations, and gapsthere is a long history of research into the usefulness of different types of usability evaluation, resulting in broad agreement on the value and importance of including it in any system development for humanintensive systems.while the costs and benets of usability evaluation are well established (bias and mayhew, 2005), there is no way to be sure that all the important problems have been found. with some complex applications like an ecommerce web site, 15 or more users may be required to identify all the serious problems (spool and schroeder, 2001). in some situations, this number or more test participants will be costeffective.there have been several reports of different teams identifying different usability issues for the same system (molich et al., 2004; molich and humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.274 humansystem integration in system developmentdumas, 2006). optimizing the evaluation procedures to obtain maximum value and consistency is still a research issue.there may also be a temptation to apply the same evaluation procedure to every project, although the most effective approach will depend on a wide range of issues, including the availability and diversity of users, the range of tasks, and the potential risks of poor usability (see chapter 4 and the rst section of this chapter). an experienced usability practitioner will tailor the evaluation to the needs of the situation. appropriate tools could be developed to support this process and would be of particular assistance to the less experienced practitioner.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.part iiithe future: scenarios, conclusions, and recommendations275humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.9scenarios for the futurein this report, we have outlined a systems engineering view of the life cycle of development activities, a humansystem integration (hsi) view, and an overview of how the two should be t together seamlessly. we have emphasized that these development processes should be riskdriven, iterative, incrementally growing, and providing a basis for agreement among all stakeholders. there are a variety of tools and methodologies that the systems analyst can apply to meet these challenges; and new and revised tools are constantly under development. we have summarized the kinds of methods, tools, and shared representations that are available to support the hsi development process. although our summary is not exhaustive, we think it is representative of the state of the art. we have indicated where there are gaps in the currently available methodologies and some needed new tools and methodologies.there are tools and methods for investigating and documenting the task requirements and the context of use. contemporary forms of simulation and virtual environments can support rapid prototyping, visualization, and humanintheloop testing. human performance models and related analytic tools are often used, sometimes in conjunction with engineering models, to evaluate alternative designs early, eliminate impractical alternatives, and to narrow the choices and set parameter bounds on alternatives to be tested. product and usability evaluation methodologies are widely used.in this chapter we advance the clock 5 to 10 years into the future to envision new directions for how, with the addition of new supporting technology, the hsi discipline, including this collection of hsi system development tools and processes, could play out. in the following sections we present 277humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.278 humansystem integration in system developmentscenarios for the future. the rst describes the bases for an integrated methodology. the second focuses on hsiled system development and the need for the development of a formal hsi discipline. the third scenario suggests a set of knowledgebased planning aids that would support hsi activities in the larger systems engineering context. the fourth scenario features a new perspective on active user participation in system design.an integrated methodologywe think that there are many advantages to streamlining and supporting the hsi process with advanced technology in the ways proposed here. it can reduce the development risk, cycle time, and cost by ensuring that products developed early can be expanded and reused throughout the development cycle. it can support the visualization of how the system will function and be used before it is fully committed to hardware and software, leading to fewer unforeseen difculties and required retrots. finally, it should contribute to the creation of systems that can continue to evolve as experience with their operation is accumulated.we think that such an integrative methodology is becoming feasible because of continued advances in semantic web technology (shadbolt, bernerslee, and hall, 2006), virtual environment technology, simulation, modeling and gaming technology, multimedia technology, and collaboration technology.here we provide an overview of such a methodology in terms of four of the main hsi activity categories in figure 23 and table 21:1. dening opportunities and requirements.2. dening the context of use.3. designing solutions.4. evaluating.as figure 23 illustrates, these activity categories are not to be confused with lifecycle phases. they comprise the steps that are taken repeatedly, in some cases concurrently, and iteratively as the lifecycle phases and milestones are met. however, when dening an integrative methodology, it is these activities that provide the basis for integration that can result in cost savings and more efcient development as a design is formalized, extended in depth, implemented, and tested throughout the life cycle.generating a baselinemost system developments are undertaken to replace and improve an existing system or set of procedures. it is important to begin the process humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 279by ensuring that there is documentation supporting the understanding and performance of the prior implementation. such baselines often do not exist and have to be produced. the more quantitative these baselines can be the better. they are important in order to understand the basis for improvement and to develop a quantitative business case for undertaking the new development.dening opportunities and requirements and dening the context of usewe take these two categories together because they are the most openended of the hsi development activities and are similar in terms of the methods used and representations that result. it is here that exploration and evaluation of highlevel opportunities take place. these activities require information collection and representation. as we project these processes into the future, we would not propose to change the methods of information collection from those described in part ii, with the caveat of incorporating the new developments and improvements suggested there and in our recommendations.the integration emphasis in these activities focuses on incorporating the documentation of the baseline, when it is relevant, and improved representation of the results. their goal in the future should be to produce shared representations or artifacts that are linked associatively to each other. it is to be expected that, early in the process, these representations will be incomplete. as the initial steps in designing solutions are undertaken, there will be much iteration of the initial representations. also, it should be noted that the choice, scope, and completeness of these representations will be in scale with the size and complexity of the enterprise. below are some examples intended to survey the alternatives applicable to the most complex project:ł personas representative of the potential individual users of the system.ł goal/task decompositions re˚ecting the activities required.ł a catalog of information required to accomplish these activities.ł a description of the anticipated work environment that ultimately can be populated with product or workstation descriptions.ł scenarios representative of the domain and activities to be performed.ł situations in which the current system does not fully meet user requirements.ł time lines or gantt charts visualizing the potential sequences of overlapping activities implied by the scenarios.ł a risk analysis identifying potential development risks.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.280 humansystem integration in system developmentł a risk analysis identifying hsi risks, including safety risks and potential for human error.ł stakeholder success criteria.ł the business case for undertaking the development.ł system requirements specications (at varying levels of detail) derived from the information gathering and representation activities.there may be other intermediate representations that are produced prior to these, such as storyboards, artifacts from the eld, workshop reports, etc., but ultimately those artifacts will be used to produce the representation on which integration will be based.in the early phases, these will be static descriptions represented in a set of associative databases. they must be interlinked because an important feature of the representations should be that a stakeholder could ask questions and trace audit trails through them. for example, the information requirements should be linked to the goal decomposition, the gantt chart, or to a scenario so that one could ask where and when that information is needed, or a requirement could be traced to the source that generated it. having these representations in interactive form makes it possible for stakeholders to study, explore, and review the state of the development in more depth so that they do not have to rely solely on the presentations at the milestone reviews.this early phase of investigation and analysis provides a crucial moment of ˚exibility, in which new ideas can be explored and compared at low cost to the project and its stakeholders. project teams can engage in various types of whatif analyses, assuming for example the consequences of using certain types of new technologies or exploring the consequences of potential new threats. the interlinkage of descriptions should include the ability for any stakeholder to make annotations and recommendations, which can then be analyzed by the team when it is time to move from exploration to stakeholder commitment.design solutionsas design is initiated and alternative function allocations between human and system considered, the representations described above will continue to be enriched and, in some cases transformed into more quantitative representations. priorities for which activities to consider rst should be based on the risk analyses suggesting where the greatest uncertainties and hsi risks lie. system components will be enumerated and prototypes of the user interfaces will be sketched out as facades, with the functionality only implied. implications of the tentative design solutions may be explored by highlevel simulation before committing resources to a particular solution.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 281at this point, the beginnings of a formal system simulation that will embody the growing richness of the system representation should be kicked off. the previously static descriptive scenarios will become executable in the context of the simulation so that the operational concepts can be envisioned as a part of the system representation. the gantt charts can become timebased and synchronized with the scenarios guided by goms (goalsoperatorsmethodsselection rules) analysis. the personas may be implemented as human performance models of those roles. the simple facades will become working prototypes, but much of the system backing it up may still be scripted. at this stage, it becomes possible to postulate alternative system designs that can be quantitatively evaluated, either in a modeling framework or as humanintheloop simulations. gradually, as the design is committed, the scripted modules will be ˚eshed out in hardware and software and those modules substituted for the scripted versions. in the prototyping languages of today and tomorrow, it should be possible to move seamlessly from early prototypes to productionquality software. the goal is that at each stage there will artifacts that represent the current state of development that may be examined and used by relevant stakeholders. these artifacts become the basis for visualization of the operational concepts and how they might play out.evaluationevaluation is ongoing throughout the development life cycle, with peaks at the incremental commitment milestones, as illustrated in figure 23. as the modeling and humanintheloop simulation efforts progress, a measurement module is added that makes it possible to generate performance measures appropriate to the current state of system development. at different stages in development, the measurement may consist of video recording of simulated or real interactions, keystrokelevel monitoring of model users or real users™ activity, eyemovement recording, and higher level derivation of human and system performance measures. as mentioned in part ii, the ability to coordinate, interleave, and annotate these data records will also be important. early in the development, the formative evaluations may be nothing more than written critiques produced by various stakeholdersšor userinformed critiques from the participatory design or contextual design traditionsšbut when simulations become available, then more systematic and quantitative evaluation becomes possible. model results must be validated with humanintheloop simulations. as detailed design and implementation are completed, the simulation transitions to actual system hardware and software, and evaluation of actual system components in use is undertaken. the evaluation culminates in a formal, summative evaluationšeld test and evaluation in the case of the military; early deployment humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.282 humansystem integration in system developmentto a restricted number of eld sites in the case of commercial software. evaluation reports become shared representations that are useful at each lifecycle milestone and are linked with the congurations tested.the meaning of integrationthere are several senses in which this postulated development process is integrated. first, it is integrated in the sense that the products of each activity are manifest in representations that may be shared across the development community. second, it is integrated in the sense that each product builds on the reusable components of previous ones. common threads are provided by storyboards, use cases, scenarios, timelines, models, and system simulations. documents, such as the business case, are elaborated, not reinitiated from scratch. third, it is integrated in the sense that achieving the goals described requires, even demands, the cooperation of many stakeholders serving as an integrated team. finally, the successful resulting design will accomplish much of system integration before implementation begins, and the result will represent a system that is truly responsive to the needs of its users, the ultimate goal of humansystem integration.hsiled system developmentcurrently humansystem integration is viewed as a support discipline, when it is engaged at all. this scenario for the future envisions it as the lead discipline in the system development life cycle. current development practice tends to be dominated by the technical disciplines that are most salient for the particular system being built: software for information processingintensive systems, and various electrical, mechanical, and physical sciences for systems heavily dominated by electronics, structures, or sensors, respectively. in these instances, it is often the case that technical performance overrides human factors and operational considerations, these being considered secondary to, for example, sensor system optimization. indeed, the system development process can become dominated by technical functionality that is later unused or, worse, gets in the way of the task at handšthat is, generates risk.the ultimate goal of our vision for hsiled systems is that an hsi professional with a system engineering background and training will be responsible for overall program management for new, complex systems, especially systems in which people play a signicant role. the program manager with an hsi background and experience will speak the language of developers and understands their constraints, while also being properly attuned to business case issues, such as schedule and resources. at the same time, the specialist will ensure that humansystem integration is appropriately adhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 283dressed by the hsi specialty team. this assignment will lead to the proper balance for ensuring that systems meet (satisce) stakeholder requirements, especially operational stakeholders, while delivering a product within the schedule and budget constraints.we have emphasized the ways in which the hierarchical decomposition of the work domain should take precedence over the engineering decomposition of functional modules, because work domain factors are the ultimate contributors to operational system effectiveness and success. it is the hsi professional who has the broadest perspective on these factors. such a person, when also endowed with systems engineering training and expertise, becomes the strongest candidate for program manager.the hsi specialistœprogram manager will provide a leadership and management culture that understands, embraces, and promotes the importance of humansystem integration in system development. there is no need for education or salesmanship on the part of humansystem integration, because, with an hsiknowledgeable program manager, the culture sees it as integral to good design as well as costeffective. humansystem integration becomes the glue that pulls all the system components together in a way that emphasizes human use. this leads to a supportive environment and appropriate levels of resources to carry out the hsi functions. humansystem integration is viewed as an important component of overall risk reduction in complex development, and the specialty is always an integral element of system development from the earliest stages.as the program manager for complex systems involving people, the hsi specialistsystems engineer would lead the program management team. crossfunctional and multidisciplinary interaction is critical to the success of large programs and can be accomplished through use of integrated product teams (ipts), as advocated by rouse (2005). the program manager™s assignment of resources will be based on riskopportunity analyses, but separate ipts would be established to coordinate the most critical risks. one such team, if warranted, would be an hsi ipt. some large projects are already using an hsi ipt. this team is responsible for the aspects of system concept denition involving endusers, further dening requirements associated with the concept, communicating those requirements in appropriate shared representations to afliated ipts, such as software development or structural design, and working with those teams to develop specications for aspects of the system affecting endusers, such as displays, operational processes, and communications. the hsi ipt would also have representation from individuals representing planning for operations support, such as manpower and personnel domains and training developers. a typical ipt structure is shown in figure 91.a key element of the implementation of the hsi ipt process is the application of the various methods described in this book. during the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.284 humansystem integration in system developmentintegratedproductteamhumansystem integrationsensors,electronics,hardwaresoftware engineeringoperations/support91figure 91 ipt structure for hsiled system development.early phases of development, methods for dening context of use and requirements are applied. design methods are used to develop solutions, and evaluation approaches are applied to characterize performance. during each phase, the hsi ipt produces appropriate shared representations, such as display concepts and behavior specications, facility drawings, and process descriptions, to communicate designrelevant information to other specialties.developing humansystem integration as a disciplinethe committee envisions a new educational perspective on the specialties associated with hsi design and implementation, perhaps eventually leading to a new engineering discipline. as described in chapter 2, the committee uses the following denition of humansystem integration:a comprehensive management and technical program that focuses on the integration of human considerations into the system acquisition and development process to enhance humansystem design, reduce lifecycle ownership cost, and optimize total system performance.furthermore, a key element of the hsi approach is the coordination and integration of the hsi domains at each system lifecycle phase.the vision of humansystem integration as a discipline will require new educational programs that cover the hsi disciplines but also include training in systems engineering. it will also provide linking interfaces to such disciplines as computer science, software engineering, and acquisition management, rather than create additional wedges with these functions. many humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 285current academic programs have certain components of humansystem integration. the naval postgraduate school is in the process of initiating such a curriculum, but no other known programs have all the necessary components and focus on their integration. the traditional recruiting ground for hsi personnel has been the academic discipline of experimental psychology, re˚ecting the origins of the eld. industrial engineering programs often have an ergonomics and human factors specialty. more recently, usability professionals have been developed from the academic tradition of information sciences and technical writing. although these types of background serve important functions in humansystem integration as a support discipline, they are to be too narrowly focused to integrate effectively with other engineering personnel or program management constraints. similarly, traditional systems engineering without hsi perspectives does not, by itself, meet the needs of this new discipline.this perspective asserts that humansystem integration is fundamentally an engineering discipline. it can emerge as a recognized discipline in its own right, within an engineering program supported by the appropriate academic curricula and programs.we think that a market study would demonstrate that there is demand for this kind of hsi professional. this demand would presumably be derived from an increasing recognition among acquisition, program, and project managers of the important role of humans in systems and that effective humansystem integration can signicantly reduce risk.we envision meeting these increased demands through hsi courses and curricula. at the undergraduate level, this content would be likely to be covered to track with a chapter in a text. at the graduate level, assuming that demand can be demonstrated, masters and ph.d. programs will emerge. the domain lends itself particularly well to satellite campus or distancelearning technologies to support the parttime student working professionally in industry or government. similar integrative academic programs have begun to emerge to meet integration demands for cognitive science and social science, in the new ﬁschools for information,ﬂ and more broadly in programs that grant a combination degree in humancomputer interaction and business.it is expected that these educational programs will convince prospective students that successful careers can be pursued through the study of humansystem integration. career ladders in both industry and government will be created to legitimize humansystem integration and to emphasize hsi knowledgeability in promotion criteria. workshops and continuing education programs for working professionals will emerge, including programs for making nonhsi people hsi knowledgeable. the denition of the domain and the currency of methods and tools will need to be maintained to have longterm success and impact as well. kleiner and booher (2003) humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.286 humansystem integration in system developmentprovide some initial thinking on levels of hsi competency for different functional assignments ranging from entry level to hsi manager. they discuss both the core competencies needed at all career levels and the specic knowledge, skills, and aptitudes needed for each specic level.since humansystem integration is a projectoriented discipline, it would be benecial in the future to create a ﬁpracticumﬂ environment out of existing, complex projects in which undergraduate students who are on a workstudy program or graduate students could have available applied experiences. in addition to developing processes by which hsi projects can make use of graduate and undergraduate interns and assistants, it is envisioned that there would be opportunities for which federal hsi specialists could be involved in interagency or industry projects. such assignments would be rewarded and recognized and should not be perceived as detrimental to career development.finally, our vision includes hsi tracks at professional conferences and special editions of relevant journals.knowledgebased planning for  humansystem integrationmany complex system development efforts begin with a core team of managers and systems engineers who may know that getting the hsi aspects right is important, but who have little knowledge of which hsi techniques work best in different situations, or of when such hsi techniques are no longer costeffective.in helping such managers and systems engineers, another scenario for what may be achievable in the next 10 years with sustained investment in hsi support technology is the development, usage, and growth of a family of domainspecic tools for helping projects to assess their risks and to suggest what hsi skills, methods, and tools they would need to identify, analyze, prioritize, and mitigate hsi risks.here is an example future scenario of the use of such a capability in the domains of command and control (c2) for defense or emergency services. an ipt consisting of operational stakeholders representing the major c2 functions of observation, orientation, decision, and action management, as well as development stakeholders representing humansystem integration, hardware engineering, software engineering, and c2 system acquisition management functions is convened for the purpose of a scoping and planning project to develop a new c2 system. as part of their team building, scoping, and planning activity, they interact with a c2domain, knowledgebased planning aid for an hsi tool.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 287the tool input requires the ipt to provide a set of project descriptors addressing the project and system as a whole and its c2 functions. the system or project specications would include such descriptors as:ł size in terms of the number of people, information sources, and assets in need of c2.ł organizational complexity in terms of the number of independently managed organizations involved in providing the services being commanded and controlled, as well as the degree of interorganizational coupling involved in providing the services.ł precedents for this team in terms of the past history of developing similar systems, of having the organizations work together, of c2 development experience of the organizations, and the need for new c2 doctrine, organization, training, material, logistics, personnel, and facilities.ł criticality in terms of the risk to human life and the value of the assets at stake.ł technical and human factors complexity of the functions involved in providing the c2 services and of the need for such additional system functions as security, instant response, rapid adaptation to change, and degraded mode operation.ł available expertise among organizations for system engineering, developing, and acquiring similar c2 systems.drawing on its knowledge base of related successful and unsuccessful c2 development projects, the c2 knowledgebased tool provides the ipt with the following:ł a summary of the most signicant acquisition and operational risks needing to be managed.ł recommended development timelines and stafng proles.ł necessary levels of system acquisition, humansystem integration, hardware engineering, software engineering, and c2 subject matter expert stafng required during the system lifecycle phases.ł the likely most relevant methods and tools to be used during the various phases, along the lines of appendix table 3a1.these tool capabilities would enable the ipt to perform sensitivity analyses of differences in tool inputs in order to better identify, avoid, and manage risks; to avoid the late rework and project overruns; and to deliver more costeffective c2 system performance.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.288 humansystem integration in system developmentuser participationour stateoftheart review has emphasized the importance of grounding design in a deep understanding of work domain activities and the context of use. we have also argued for the importance of including domain practitioners who are the intended users of the system as active partners in the design endeavor. while we have argued for the importance of these activities to successful design, we acknowledge that many of the current approaches for analysis of context of use can be time and labor intensive, require expertise to employ, and produce results that are not always packaged in a way that can readily be assimilated in the system development process. these factors combine to slow their adoption and limit their effectiveness. a related consideration is that user activities and context of use are not xed elements that can be captured once and for all. the activities that people engage in and the physical, social, and organizational environment in which they take place are constantly evolving. it is important to develop efcient techniques that can dynamically capture changes in work context and requirements and to create systems that can be readily adapted to meet changing demands (e.g., woods and dekker, 2000; hoffman and elm, 2006; roth et al., 2006).these points highlight the importance of developing new approaches to capturing user activities and context of use in ways that are less obtrusive, less resource intensive, more continuous, and more readily assimilated into the system development (and update) process.approaches to capturing user inputin chapter 6 we pointed to some promising directions for streamlining the capture and analysis of context of use knowledge, such as event data analysis methods that are intended to collect information on context of use unobtrusively. in this section we point to an emerging con˚uence of activities and technologies that promise to help endusers learn more about their activities, re˚ect on their actions, and provide useful contributions to the system development and evolution processes.in the past, system designers often assumed that users received their technologies in a nished state then went on to use those technologies as intended by the designers. numerous studies have now shown that users often have to modify the technology or its usage extensively (see, e.g., bikson and eveland, 1996; dourish, 2001, 2003; muller et al., 2003; pipek, 2005; more broadly, see darrah, 1995; eglash et al., 2004). in military terms, the practice of ﬁeld modicationﬂ is another example of users™ needs to change and reinvent the technologies that they receive.developments in web 2.0 have accelerated this process (o™reilly, 2005). humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 289in the new networks, it is common to interface one application or service with another, to create new functionalities and new value propositions. each application provides a standardized interface (typically xml) to other applications, and new services can be created through simple interfaces among these existing applications (making a ﬁcallﬂ between applications, similar to a subroutine call in a conventional program architecture). the standardization of data formats among these services allows very rapid prototyping and testing of new service concepts, and these integrations can lead to user experiences that appear to be entirely new concepts and functionalities. each such web site or module uses these standardized formats to offer ﬁservicesﬂ that can be called from other web sites or modulesšhence the more formal description as ﬁserviceoriented architecturesﬂ or soas (erl, 2005; soa technical committee, 2006). we describe ve classes of new services here.the rst class of such services are the examples of combining listbased advertising entries from one system with mapbased visualizations from a second system, using standardized address data representations as the common servicecalling protocol, to provide interactive geographic summaries of opportunities that change dynamically with new textual entries to the original list.1 these quickly assembled services have been called ﬁmashupsﬂ to emphasize that they have been constructed by bringing together two different data sets.these technologycentric developments have enabled new forms of shared usage and collaborationatadistance, often on a massive scale, and often involving users who have no knowledge of one another other than through these new systems and forms of collaboration. these developments have been generally described as ﬁsocial softwareﬂ (allen, 2004; ibm, n.d.; teton and allen, 2007; see also chi et al., 2007). the remaining four classes of new services fall into this general area.a second class of such services provides awareness services in the form of ﬁfeedsﬂ of information via the rss protocol.2 each feed is provided in the form of updates on a specied page at a web siteša ﬁweblogﬂ or ﬁblog.ﬂ these blogs can be read and aggregated by a user via one of many ﬁfeedreaders,ﬂ leading to increasingly integrated lists of updates from selected web sites. commercial uses range from nancial awareness to competitive intelligence. military uses could include situational awareness.a third class of such services involves the collection within a web site of shared references (e.g., ﬁbookmarksﬂ) to entities at other web sites, in which each reference includes keyword descriptors called ﬁtagsﬂ (golder 1 see http://www.craigslist.org.2 see http://www.rssprotocol.com, http://www.rssboard.org/rssspecication.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.290 humansystem integration in system developmentand huberman, 2006). these references may refer to documents,3 pictures,4 recorded music, and many other types of data and are created independently by thousands of users, and each such reference is generally shared with all other users of the original web site. searches can thus be conducted by tag or by user, resulting in a powerful and lowmaintenance alternative to complex directories or organizational taxonomies (classication schemes). signicantly, people have begun to aggregate these emergent ﬁfolksonomiesﬂ (i.e., bottomup, usercoconstructed alternatives to taxonomies) across web sites and services, and there is a trend toward linking selected types of references to commercial sites (e.g., userconstructed references to books at librarything are often linked to book product descriptions at amazon.com).a fourth class of such services is much more personoriented and involves the posting of information by a user about herself or himself.5 some of the information may be relatively static, while some of the information may be frequently updated, including in the form of a blog (see above). in addition, information about each person may be aggregated from other web sites through mashup or soabased technologies.a fth class of such services involves the cocreation of knowledge resources by many users, with the expectation that the knowledge will be accessed by many more usersša groupconstructed encyclopedia, of which wikipedia6 is the most well known of many instances.the pace of development using these new technologies is so swift that there are web sites dedicated to providing daily updates about the status of various web 2.0 experiments, beta tests, and business propositions.7 key characteristics of these developments are the reuse of technologies and services for new offerings, the diffuse and bottomup nature of both the development effort, and the data accumulation through the contributions and negotiations of thousands of users. users are rapidly becoming designers and data providers in these new web services.in a related trend, networked technologies have empowered people to ﬁcacheﬂ their lives. usersšespecially young usersšare integrating text, video, photos, and audio to produce momentbymoment descriptions of their daily activities, using commonly available enduser web technologies. these young users are beginning to enter the civilian and military workforce and are bringing their familiarity and expectations of these technologies 3 see http://del.icio.us/.4 see http://www.˚ickr.com/.5 see http://www.facebook.com.6 see http://www.wikipedia.org.7 see http://www.momb.sociokybernetics.net/, the museum of modern betas.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 291into work cultures. these technologies are likely to be transformed for selfre˚ection in most any situation.the tools enable things such as autouploading, tagging by association, dynamic views of tag clouds andšcruciallyšthe ﬁmashupﬂ technologies of web 2.0 to integrate these diverse media into coherent new services. in the future, additional information will be gathered from sensors in objects in the world and digital tagging of locations in the environment.we see these tools as a means to enduser empowerment in much the same way that desktop publishing on personal computers transformed business communication in the workplace. recently, bradley horwitz, vice president of yahoo!™s product strategy group, explained that only a small number of people needs to leverage the tools in order for the resulting information to become useful for the masses (see also discussions of the ﬁlong tail,ﬂša statistical analysis of the in˚uence of a small number of highfrequency contributors on a much larger community of lowfrequency contributors and readersšanderson, 2006).8 we suspect that the same will be true in this context. not all users will have to be actively re˚ecting on their activities and environment, but those who do will help positively transform the environment for everyone. mckinsey describes this as a new model of knowledge production, access, and distribution. he goes on to suggest that communities, not individuals, become the sources of innovation in a world of opensource approaches to knowledge development (davis and stephenson, 2006). in this vein, the following vision of the future is presented.systems engineering for user participationin 5 to 10 years, hsi professionals are still focused on identifying hsi needs, translating their ndings into opportunities, developing prototypes, requirements, and ultimately designing solutions that respond to those needs. but the world has fundamentally changed and systems engineering and hsi professionals have anticipated these changes and are working in new ways.some activities look the same, but others look radically different. hsi professionals are gathering their information with some of the methods they used in the past (such as cognitive task analysis or through observation) but they also have new ways to uncover opportunities, understand users and their contexts, and dene solutionsšthey are constantly sensing and responding and have the skills to create not only solutionsšbut also wholly new ways of doing things from the data they are collecting and through the collaborative efforts of the real endusers.8 see also http://www.thelongtail.com.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.292 humansystem integration in system developmentso what is different? data about the users, the environment, and objects in the environment are being continuously collected in real time and then represented for users to comment and learn from. nearly every object in the user™s system has been ﬁspimeﬂenabled. a spime is a currently theoretical object with embedded sensing and responding capabilities that enable tracking through space and time (sterling, 2004). the geospatial web has enabled the environment to constantly update people with locationbased services and locationaware applications. information will be integrated with the historical, cultural, and other relevant information of the specic place or setting or from smart dust distributed among places (liebhold, 2004). this technological development is a logical maturation of some of the technologies reviewed in sections about event data analysis in previous chapters.at the same time, endusers are becoming increasingly sophisticated producers and distributors of interlinked media. collections of users have the ability to form reporting communities. best practices in one community can easily be shared across the network. events produce dynamic blogs, too, in which participants can see the activity of people, objects, and the interaction with the environment as it happens. the histories are then mined to look for patterns that can be used to build models, and then the models are trained to make better predictions about future events. users are monitoring and contributing to their own ﬁmoblogsﬂ that compile information about their activities into views that are meaningful to them. people post to these blogs through mobile cellular or other input devices. the algorithms are constantly updated and made better through the analysis of the behavior of real people in real settings and the commentary users provide through their blogging activities.why are the users participating? there are several reasons. it is easy to comment and represent information. wearable technologies have made ﬁin the actionﬂ collection automatic or nearly so. another reason is that there are widgets embedded in the interfaces that enable users to build and create their own ways to track data based on what they think they really need. as individuals become recognized by their community for their contributionsšwe can anticipate more and more participation in much the same way bloggers today do. eventually the ﬁbest of the bestﬂ contribute to design efforts and trainersšof the systems, the other users, and the developers.in the meantime, hsi professionals have also been able to study what has happened even without users™ annotations. they have studied how different people have appropriated the technologies in the moment. they have watched, in realtime, how people have built new applications out of old technology, what used to be a workaround is now a ﬁwork as.ﬂhsi staffs for their part are now building the tools that others formerly built for themselves. for a system to remain workcentered over time, it humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 293must not only support the elements of work identied at the design stage, but it must also be able to accommodate elements that the initial design did not appropriately capture and be adaptable to meet the changing nature of the work (roth et al., 2006). systems need to explicitly incorporate mechanisms to enable users to adapt the system to evolving requirements. the development of these modular systems place even greater demands on hsi professionals.similar calls have been made in the computerhuman interaction community to move toward enduser development systems (fischer et al., 2004). the goal of enduser development is to develop tools to enable endusers to adapt and further develop applications to meet evolving requirements. it has its roots in early calls to enable users to create customizations, extensions, and applications so as to address unanticipated requirements (mackay, 1990; nardi, 1993). fischer and his colleagues (2004) have argued for the importance of developing metadesign approaches that create open systems that can be modied by their users and evolve over time. enduser development systems range from systems that provide for modest user modiability to systems that have enduser programming features (e.g., open source code).these new evolvable, workcentered systems are consistent with a growing recognition in the sociotechnical literature that software system requirements should not be viewed as xed but rather as emergent over time as changes arise in the context of work (floyd, 1987; truex, baskerville, and klein, 1999; scacchi, 2004). as truex et al. (1999) have argued, this implies a need for ongoing analysis, negotiated requirements among system stakeholders, and an ongoing investment in software maintenance activities.another change that can be anticipated is that hsi personnel become the experts in issue tracking and resolution as systems are now never nishedšbut more dynamically evolvingšand in continuous beta mode. their experience in requirements gathering and documentation has been successfully leveraged in this new role of keeper of the desired future state of the systems.together, these trends have sharply reduced a number of system integration risks. the greater participation by endusers in the design of systems has led to technologies that are nally ready for use as delivered to end users. from a military perspective, ready for use translates into reduced training and user assistance requirements, faster learning, more effective use, and fewer accidents. from a consumer products perspective, ready for use translates into reductions in use errors or other problems with unanticipated uses. from a businesstobusiness perspective, ready for use translates into immediate return on investment and reduced total cost of ownership.a second area of risk reduction occurs because of the richer, more humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.294 humansystem integration in system developmentimmediate, and more broadly based sources of data. spimes promise to provide nearly instantaneous awareness of changing conditions, and the dataparticipative trends of web 2.0 bring many users™ knowledge to bear on collaborative problems (e.g., the ﬁwisdom of crowdsﬂ).the third area of risk reduction occurs in the rarer cases in which a system is delivered that does not meet the users™ requirementsšor in cases in which the users™ environment has changed so quickly (due to changing threats or new business challenges) that the original design has been made obsolete by changing conditions. in these cases, the abilities of users to modify and enhance the technologies (e.g., through the mashup capabilities in web 2.0 technologies) allow users to make rapid changes that can provide new functionality to an obsolete technology so that it remains a worthwhile investment or a valuable part of defensive or offensive capability.in this chapter we have envisioned a future in which knowledge acquisition will no longer be a laborious manual process but will instead leverage the collective knowledge that naturally emerges as domain practitioners act in the world, re˚ecting on their own practices and on the ability of their tools to support their work, engage in collaborative knowledge sharing, and appropriate and adapt their software tools to accommodate dynamically changing needs. already today we see evidence of users embracing new technologies to share experiences and lessons learned and build shared knowledge bases (e.g., specialized blogs, discussion groups, and tagbased sharing cites have emerged in multiple domains, including military groups). we also see evidence in virtually every domain of users creatively extending and adapting software tools (e.g., creating new visualizations, local databases, and homegrown software support systems) to meet the constantly changing demands of work. we think this is an important positive trend that needs to be fostered and facilitated through design methods that acknowledge and accommodate evolving requirements, as well as software systems that are designed with expectation of user appropriation and adaptation. as hoffman and elm (2006) have pointed out, there is a need to rethink the assumption that system requirements can be xed in a world that is not xed (see also floyd, 1987). to them, ﬁ‚requirements creep™ is not a nasty thing to eradicate, but an empirical inevitability to accommodate and understand empiricallyﬂ (hoffman and elm, 2006, p. 76).having sketched out the broad vision, we want to acknowledge that there are technical challenges to be overcome and to diffuse some potential misconceptions. first, we want to make clear that, while we envision that knowledge of user practices and use contexts will naturally emerge and that software systems will be appropriated and adapted, we do not intend to suggest that explicit analysis of users and context of use will no longer be needed. nor do we mean to suggest that users will evolve their own software so that explicit systems analysis and software design will no lonhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.scenarios for the future 295ger be required. human factors analysts will still be needed to synthesize and interpret the domain knowledge gleaned; they will simply be able to do their job more efciently and comprehensively than has been possible in the past. similarly, systems, software, and hardware engineers will still need to analyze requirements and architect solutions, but with more explicit awareness of the need to develop solutions that accommodate change. this is especially true in safetycritical domains, such as the military and the transportation and health care industries and systems of systems more generally, in which explicit consideration of unanticipated side effects and risk consequences of design decisions are critical.finally, we want to make clear that our vision of a more automated means of collecting information on user goals, needs, and activities is not intended as a substitute for including users as explicit stakeholders and equal partners in the design endeavor. effective design will continue to require active dialogue and discovery among a variety of stakeholders, including users, human factors specialists, systems engineers, and software developers.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.10conclusions and recommendationsin this chapter, we report our broad conclusions related to each of the themes we introduced at the start of the report. these conclusions re˚ect detailed consideration of (1) our research into current views of systems engineering, (2) what the committee learned is needed to meet the requirements for adequate support for the role of humans in systems, (3) our survey of the methods and tools available to support what is needed, and (4) our assessment of the state of the art in humansystem integration (hsi).our most fundamental conclusion is that human performance and humansystem integration will never be most effective in system design unless it is seen by all stakeholders as an integral part of the entire systems engineering process, from initial exploration and concept evaluation through operational use, reengineering, and retirement. many systems have failed because the role of humans was considered only after design problems were identiedšwhen it was too late to make the kind of changes that were required to produce systems responsive to users™ needs. we conclude that the denition of user requirements should begin when the system is rst being conceived, and those requirements should continue to provide important evaluation criteria right up to the time the system is placed in use.the military services are recognizing the need for more emphasis on human considerations in design through the introduction of manprint, seaprint, and, most recently, airprint requirements. more and more commercial software, hardware, and service industries are beginning to realize that commercial success requires attention to the customer™s needs and that achieving that success has implications for the product engineering 296humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 297team, not just the marketing and sales teams. it begins with product conceptualization and continues throughout the product development cycle.as a process for integrating human considerations into the systems engineering process, the committee has built on the strengths of existing systems engineering process models (waterfall, vmodel, concurrent, incremental, spiral, evolutionary, agile) to synthesize an incremental commitment model (icm) that helps to situate hsi activities within a system™s life cycle. as described in the introduction, this model is based on ve critical success factor principles: (1) negotiation to ﬁsatisceﬂ system stakeholders™ (e.g., users, acquirers, developers) requirements; (2) incremental growth of system denition and stakeholder commitment; (3) concurrent system denition and development; (4) iterative system denition and development; and (5) risk management. incremental commitment model is consistent with current approaches to systems engineering, including the u.s. department of defense (dod) 5000 series of system acquisition policies and guidelines, and provides the kind of emphasis that the committee considers important to achieving humansystem integration. although it is not the only model that could be used on future humanintensive systems, it has served as a reasonably robust framework for explaining the study™s hsi concepts, and for evaluating these via the case studies in chapter 5. however, there are ways to extend or reinterpret existing process models to accommodate the ve critical success factor principles and hsi activities.in the paragraphs below we build on the six themes rst mentioned in the introduction, and highlight features based on them that require special attention from the perspective of humansystem integration.begin hsi contributions to development early and continue them throughout the development life cycle. if there were a single message to communicate to program managers and developers, it would be to understand that hsi expertise is important from the very beginning of the life cycle, when systems are rst being conceived. hsi specialists are trained to explore and understand the environment in which a system will be used. in order to develop an operational concept, full understanding of the context of use is required. these factors need to be assessed even before a conceptual design is put forward. human factors specialists have a collection of methods and tools for efciently understanding the system environment and context of use. consideration of these factors early can have ordersofmagnitude impacts on system performance. if human factors and other hsi input are left until the test and evaluation stage, only smallpercentage improvements can be realized under the best of circumstances, and there is a risk that the system will not satisfy the original goals. we have also emphasized that system development needs to be an iterative process, and that there are humansystem design considerations that evolve and need to be iterated along with every other aspect of system development.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.298 humansystem integration in system developmentintegrate across humansystem domains as well as across the system life cycle. the domains identied in the manprint methodologyšhuman factors, manpower, personnel, training, system safety and health, habitability, and survivability, the rst ve of which are potentially as relevant to commercial products as to military systemsšare not independent, and consideration of them must not be treated separately (i.e., ﬁstovepipedﬂ). while each has its own methods, there are many areas in which the methodologies we describe in part ii can serve multiple purposes across the domains and do not have to be analyzed for each. for example, task analysis, risk analyses, and workload analysis can support human factors, manpower, training, and safety. ergonomic analysis can support human factors, training safety, and health hazards. for it to do so requires that the individual specialists in each area cooperate up front to ensure that the resulting shared representations meet the requirements of all the domains. this is a critical aspect of negotiation to ﬁsatisceﬂ system stakeholders™ requirements.adopt a risk and opportunitydriven approach to determining needs for hsi activity. at each of the system development milestones, the systems engineering team undertakes an analysis of the development risk and opportunities before proceeding to the next milestone. it is essential that the hsi team contribute an evaluation of hsi risks and opportunities to be considered in collaboration with the rest of the system engineering team. it is through the risk analysis that the argument may be made for assigning resources to evaluate particular risks further or to nd ways to mitigate the risks that the system will fail, for example, because of safety risk, risk that it will be too costly to train the personnel in its use, or risk that it will be maladapted to the people who must use it. in addition, considering opportunities may allow the hsi team to improve program execution and system capabilities.there is often a tendency for the hsi team to insist on a complete hsi analysis. the purpose of the risk and opportunity analysis is to focus attention on the risks whose likelihood and seriousness are both appreciable, as well as the opportunities with the greatest payoffs. it will also serve to identify the areas of development in which the risks are minimal and do not need further attention. hsi risk and opportunity analysis becomes a component of the overall system development risk analyses and is given equal importance to other system risk factors. the use of humansensitive mission effectiveness models, simulations, and exercises can be highly effective in this regard.if there are integrated product teams (ipt) for which hsi issues are relevant, there should be at least one hsi representative on each such team, and that person should be responsible for ensuring that the hsi risks and opportunities are considered.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 299tailor methods to time and budget constraints. every system development takes place under time and budget constraints. it is not possible to undertake fullscale hsi evaluation of every aspect of a system development. early in the life cycle, as a part of the iterative system denition and development, it is important to evolve the humansystem requirements, prepare the hsi part of the business case for designing and elding the system, and undertake the risk and opportunity analysis. the business case should include quantitative performance objectives based on human capacities and limitations. from that point on, it is important that the hsi team, driven by its risk, opportunity, and requirements analyses, focus further attention on the critical issues and requirements identied in the risk/opportunity analysis only. with respect to each identied issue, they should evaluate the analysis requirements carefully, consider alternative approaches to achieving them, and select the methods and tools that are most costeffective for answering the questions at hand. the proposed budget should be based on a careful but realistic analysis of what needs to be done to satisfy the critical and most risky requirements. doing so will gain the respect and condence of the program manager and will improve the chances that adequate budget will be provided.ensure communication among stakeholders of hsi outputs. many of the contributions of the hsi teamšespecially those that are developed early in the development processštend to be based on observation, interview, and questionnaire methods. the individuals who collect the data become the most knowledgeable about the characteristics of the system environment and context of use. similarly, the knowledge acquisition associated with developing task and process analysis results in very rich information in the heads of the analysts. however, much of this information is needed by all the system stakeholders, from the funders and program managers to the detail designers and developers. in following the principle of negotiating to satisce all stakeholders™ requirements, it is very important that the hsi team provide outputs and deliverables that capture the information and its interpretation in forms that are understandable and usable by these stakeholdersšwe have called them shared representations. we have discussed the kinds of methods to be used for generating the needed information and, for each method, suggested that the kinds of shared representations we recommend should be developed as the outputs. effort should be made to create these shared representations in a form that is readily assimilated into the engineering process, that is, expressed in terms that are compatible with other engineering outputs. this might be accomplished through the generation of scenarios of use, models and/or simulations based on the task analysis output, or analyses of the context of use. effective shared representations can be very helpful in smoothing the ˚ow of information among team members and in ensuring that the hsi team output is in˚uential.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.300 humansystem integration in system developmentdesign to accommodate changing conditions and requirement in the workplace. there have been and are continuing to be signicant changes in many factors that in˚uence the way that work gets accomplished and the nature and complexity of the systems that are developed. personnel costs are a signicant percentage of the operational cost of systems, and everywhere there is pressure to reduce the numbers of personnel. technology is often seen as the panacea to reduce personnel costs, increase efciency, and improve safety. technological evolution has become much more rapid, and the systems developed last year may be already out of date.it is impossible to capture all the requirements up front, so it is valuable to develop systems that can be more easily adapted or modied in order to continue to provide support as the work context changes. the ultimate ideal is to create evolvable systems that can be ﬁappropriatedﬂ (or reinvented) by the users and tailored to meet the inevitable changes that will arise. this argument is consistent with the principles of incremental growth of system denition and concurrent system denition and developmentšthe idea that requirements should not be assumed to be xed but instead expected to evolve over the life cycle of the system.the design of systems of systems involves a level of complexity and challenge much greater than the design of individual complex systems themselves. for example, the military is designing command and control systems that span the activities of many logistics, battleeld operations, manned and unmanned aerial systems, and multinational forces. telephone companies are now faced with integrating digital phone systems with cell phones, internet access, and television delivery systems. hospital information systems must be integrated with the accounting, nursing unit, pharmacy, and individual physician™s workstations, not to mention supply systems and inventory control, and they must do it in a way that promotes patient safety.complex systems of systems demand new approaches to uncover the multiple points of interdependency across systems and anticipate their impacts on the people operating in those environments. new envisioning methods and modeling tools are needed to predict the kinds of challenging situations that are likely to arise, the kinds of adaptations that will be required of people to cope with new complexities, and the kinds of errors and failures that may emerge in the future (woods and dekker, 2000; woods, 2002; winograd and flores, 1987; feltovich et al., 2004). the ability to anticipate likely reverberations of technology insertions early in the design process can contribute substantively to the design of complex systems and systems of systems that are resilient in the face of a wide range of operational perturbations (hollnagel, woods, and leveson, 2006).the emergence of systems of systems further emphasizes the importance of considering humansystem integration as an integral part of the humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 301development process. we have highlighted the value of iterative design and the role that shared representations and especially models and simulations can play in ensuring that all stakeholders remain informed about the current state of development. in this kind of very dynamic development environment, it is important to keep in mind the potential for changes after the system is implemented. information currency is likely to be a very important consideration, since design requirements can change with each new iteration. in chapter 2, we described a procedure for accommodating rapid change and high assurance through incremental development. design for evolvable systems requires anticipating the scope of changes that might take place, making the design modular, leaving appropriate entry points for the changes, providing thorough software documentation, and providing scalable serviceoriented architectures.research and policy recommendationsthese recommendations identify further critical steps to facilitate the kind of integration into systems engineering that we consider of paramount importance. our intent is to provide sufcient detail to guide the development of a research plan and the formulation of policy initiatives for the dod and other government and private organizations. the recommendations are organized into four areas: (1) realizing the full integration of human systems and systems engineering; (2) methods for dening opportunities and the context of use; (3) methods for dening requirements and design; (4) and methods for evaluation. accomplishing these steps will provide needed support to realize the future scenarios outlined in chapter 9. the committee was not able to prioritize these research recommendations as they cover diverse areas of equal importance. we believe work in these areas should proceed concurrently.realizing the full integration of human systems and systems engineeringthis report presents the incremental commitment model as an example framework for system development activities and discusses how humansystem integration ts within this framework. here we present our policy and research recommendations regarding the principal areas of research, development, and policy initiatives needed to facilitate integration throughout the development life cycle and across hsi disciplines. these areas includeł institutionalizing the success factors associated with the incremental commitment model.ł accommodating the emergence of hsi requirements.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.302 humansystem integration in system developmentł ensuring that hsi operational requirements are included in the initial system development contract and acquisition documents.ł managing integrated system development.ł providing traceability of hsi objectives, decision points, and the rationale for decisions across lifecycle design phases.ł developing approaches to humansystem integration and systems of systems research.ł sizing the hsi effort.ł designing shared representations to facilitate communication across disciplines and lifecycle phases.ł creating knowledgebased planning aids for providing hsi information.ł developing humansystem integration as a discipline and as a lead for the ipt.ł fostering more synergy between research and practice.institutionalizing a system development process based on the success factorsthrough our analyses of more and less successful hsi projects, our evaluation of alternative hsi process models, and our case studies, the committee makes the case that a model like the incremental commitment model better enables the kind of humansystem integration that will be needed for the complex, humanintensive systems of the future. it embodies the success factor principles of stakeholder satiscing, incremental growth of system denition and stakeholder commitment, iterative system development and denition, concurrent system denition and development, and riskdriven activity levels, product levels of detail, and anchor point milestones. however, it does this in clearer ways than the spiral model, particularly for hsi considerations, and it does so in a manner compatible with the dod acquisition milestones and the commercial ibm/rational unied process and the eclipse process framework openup milestones. it provides a process framework for the toplevel recommendation of realizing the full integration of human engineering and systems engineering.recommendation: the u.s. department of defense and other government and private organizations should rene and coordinate the denition and adoption of a system development process that incorporates the principles embodied in the incremental commitment model. it should be adopted as the recommended approach for realizing the full integration of humanrelated design considerations with systems engineering in organizational policies and process standards, such as the dod 5000 series and the iso systems engineering standards.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 303accommodating the emergence of hsi requirementsparticularly for complex systems of systems and for collaborationintensive systems, humansystem interface states, modes, and functional requirements are not known at the time of program initiation. many current system acquisition policies and standards require these human considerations to be fully dened before proceeding into development.although it is risky to leave hsi requirements completely undened, it is equally risky to insist on dening them before they are fully understood or allowed to emerge through experience. a reasonable middle approach is to use incremental and evolutionary development processes and to dene hsi requirements in terms of capabilities, with more detail provided for later increments, but sufcient detail provided for earlier increments to ensure proper preparation for the later increments. this approach is consistent with the principle of riskdriven levels of product detail.recommendation: the u.s. department of defense and other government and private organizations should revise current system acquisition policies and standards to enable incremental, evolutionary, capabilitiesbased system acquisition that includes hsi requirements and uses riskdriven levels of requirements detail, particularly for complex systems of systems and for collaborationintensive systems.hsi operational requirements in contracts and acquisition documentsin discussing risk management, we have alluded to the importance of considering hsi aspects when negotiating baseline metrics for program execution. this negotiation is a critical phase in product development, when estimates and assumptions are formulated and agreed on by all stakeholders. customer requirements and value propositions, technical performance measures that measure compliance with technical requirements, schedule milestones, and requisite resources all contribute to that negotiation. involving hsi practitioners in the negotiation process ensures that their perspective and knowledge are accounted for, increasing the likelihood that hsi risks and issues will not arise during program execution. this recommendation focuses on policy, rather than research, and addresses the need to have humansystem integration considered in establishing program execution baselines. key to successful contract execution, resulting in an end product that lls a specied role and meets operational needs, are crisp requirements that have been properly vetted.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.304 humansystem integration in system developmentrecommendation: the u.s. department of defense and other government and private organizations should put the operational requirements of humansystem integration on a par with traditional engineering requirements at the beginning of initial requirements analyses to determine which requirements have priority and provide an opportunity for negotiation.recommendation: when developing system acquisition programs, the u.s. department of defense and other government and private organizations should dene potential means for verifying and validating hsi requirements to enable supplier program managers to establish clearly speciable hsi technical performance measures for contracts.the procuring agency has the ability to drive contractor hsi efforts by seeding the extent to which hsi considerations are accounted for contractually and their degree of importance. without the inclusion of hsi considerations throughout program denition efforts, contractors have limited basis for addressing hsi considerations in their business offer.recommendation: the u.s. department of defense and other government and private organizations should account for hsi considerations in developing the technical, cost, and schedule parameters in the business offer. in particular, contracts need to re˚ect an understanding of how humansystem integration affects the ability to reuse existing technical solutions or the feasibility of inserting new technologies, as well as an appreciation of how anticipated hsi risks may affect meeting program award fee criteria. it is also important that the contractor understand how hsi elements in their product offering contribute to achieving market capture goals and subsequently the viability of their business case.overall, the procuring agencies are able to directly in˚uence the extent to which hsi elements are addressed in contracts by establishing wellarticulated hsi requirements re˚ective of enduser needs and working with the contractor to establish verication and validation methods that overcome program management concerns about the typically subjective nature of hsi elements. the contractors or suppliers should take the time to involve hsi practitioners in their business development efforts to account for hsi elements in the business offer, thereby mitigating a portion of potential hsi risks and issues that may arise during program execution.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 305managing integrated system development so that all representations are kept in synchronizationin our vision for an integrated system development methodology, a serious concern is conguration control of the various entities that are being developed in order to support it. it is likely that new developments in web technology will be able to support some of these requirements.recommendation: explore the usefulness of the technologies associated with web 2.0 and related web developments for providing support for conguration control and synchronization of the component representations in a large system development project as they evolve and become more quantitatively dened.recommendation: support a research program to explore how to provide ˚exible and open systems with appropriate security protections. the apparent con˚ict between openness and protection is not a matter of balance or tradeoff, but rather of providing strong forms of both attributes.traceability and requirementsthe committee has argued for the importance of capturing the context of use in a form that can inform later phases of design. this is important to ensure that operational objectives and constraints and their design implications are taken into account in the system design process, so that the nal ﬁasbuiltﬂ system meets the support objectives and constraints identied in earlier phases. this goal can be met only if methods and tools facilitate capture and traceability of hsi design objectives, decision points (together with the rationale for those decisions) and constraints across design phases.our vision is to adapt existing tools or to develop new software tools to facilitate the traceability of hsi design objective implications and how they are being met to ensure that they are preserved across design phases. this includes traceability across multiple intermediate humansystem integration shared representations, starting with (1) outputs of context of use analyses that specify domain demands, stakeholder objectives, human performance needs, and design implications; through (2) the products of intermediate design phases, such as scenarios, personas, models, and prototypes; through (3) the decision rationale and system hardware and software design specications intended to re˚ect the support objectives embodied in the design concepts; through (4) the nal asbuilt system. traceability across design phases is important to ensure that hsi objectives and constraints are preserved across design phases or when modication or redesign is unhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.306 humansystem integration in system developmentdertaken. it also makes it easier to assess whether the asbuilt system meets the operational and support objectives and design implications uncovered by earlier design phases.recommendation: adapt existing or develop new methods and tools that facilitate capture and traceability of hsi design objectives, design rationale, and constraints across design phases. specically:1. develop shared representations that effectively communicate how the output of one design activity meets the objectives, design rationale, constraints, and design implications uncovered in the prior design phase.2. develop shared representations that effectively communicate essential design characteristics and their rationale that can be interpreted and used by multiple system development stakeholdersšincluding individuals that did not participate in earlier design activities (see wampler et al., 2006, for an example of an effort toward this goal).3. adapt existing and develop new software tools to support traceability and update as changes arise in later design phases that require updates to outputs of earlier design phases.4. adapt existing and develop new tools and techniques for explicitly connecting hsi objectives and design implications to higher level system requirements tracked in formal system requirements tracking systems. this is important to ensure explicit links between hsi design objectives and systemlevel requirements that re˚ect contractual commitments.5. adapt existing and develop new methods for generating scenarios that re˚ect the range of complexities uncovered by context of use analyses. this corpus of scenarios can be used to support development and evaluation of designs, procedures, and training, including human reliability and safety analyses. they could also be used to exercise models and simulations as part of the system development process. the goal would be to ensure that the systems have been explicitly designed and tested to support performance across a comprehensive range of representative situations, as identied by context of use analyses. context of use scenarios are also essential to the meaningful denition of such key performance parameters as response time, reliability, and accuracy.6. develop methods to identify meaningful human (and joint personcomputer system) performance metrics that can provide the basis for objective system acceptance criteria. this is important to encourage incorporating hsi objectives as part of formal contractual humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 307requirements that are established early in the systems acquisition process. steps includea. developing methods for identifying individual, team, organization, and joint personcomputer system (as well as systems of systems) performance metrics that provide objective measures of factors that are key to successful performance of tasks, of system design, and of accepted systems.b. developing methods for establishing objective acceptance criteria that accurately re˚ect humansystem integration and context of use goals while being straightforward to evaluate.shared representationsthe committee has argued for the importance of shared representations, sometimes referred to as boundary objects. they can serve an important role in fostering communication across the various systems engineering disciplines. focusing explicitly on representations that communicate across discipline boundaries is novel. although we have provided many examples of artifacts that could serve as shared representations, research is needed to understand just what this means and how best to achieve it. we identied a specic issue concerning shared representations for task analysis among the specialists supporting the various manprint domains, especially the domains of human factors, stafng requirements, training, and safety. each tends to undertake its own task analysis, resulting in substantial duplication of effort.recommendation: conduct research to identify characteristics of shared representations that communicate effectively across hsi domains and engineering disciplines. we recommend the following steps:1. identify characteristics of a useful shared representation:a. dene what it means to share an understanding.b. characterize the mental models and representations associated with design used by various stakeholders, such as ˚ow charts, blueprints, wiring charts, or gantt charts, as well as more workoriented representations, such as prototypes and mockups.c. dene the areas of overlap between those who are practitioners in hsi domains and other stakeholders that represent fruitful areas in which to develop shared representations.2. consider a specic area, such as cognitive task analysis or risk analysis:a. review and evaluate existing and proposed representations.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.308 humansystem integration in system developmentb. identify common aspects and differences.c. synthesize representations that have the potential for improving communication across stakeholders.3. assemble an ipt representing the manprint domains with the assignment to reach agreement on a single set of generic specications for what needs to be included in shared representations for task analysis.4. design a multimedia database format and tool, including coordinated video, as a shared representation derived from hsi evaluations. build on multimedia software and tools used for documenting usability evaluations.systems of systemsthere is a gap in the arsenal of hsi methodologies in that many of them (perhaps most of them) fail to scale up to the systems of systems level. for example, usability methods are typically suited to the single userœsingle interface scenario: how can these methods be adapted to complex systems of systems, and how can organizational modeling approaches (national research council, 1998) be applied to humansystem integration? similarly, how can other hsi methods, such as cognitive task analysis and participatory design, be adapted for this complexity? is cognitive work analysis as suited for networkcentric command and control environments as it is for process control systems (cummings, 2006)? other methodological issues, such as envisioned worlds (i.e., systems that do not yet exist in any form and may even be revolutionary, resulting in the need for methods that are not anchored in existing systems) and tailorability to the situation, are exacerbated by the complexity of systems.recommendation: conduct research and development on hsi methods for systems of systems in the following manner:1. develop a testbed that provides a research environment simulating systems of systems in the context of a domain by working closely with domain users, experts, and developers to design the testbed, and to ensure transition of work in the testbed to the real world.2. select methods and identify potential ways to adapt them for complex systems. include stateofthe art methods and technologies, such as data mining, wikis, social software applications such as blogs and tagging systems, and virtual collaboration and envisioned worlds.3. apply the methods in the context of the testbed to test reliability and validity, compare methods with each other, and identify methhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 309ods that scale up and aspects of methods that seem to scale better than others.4. feed back scalable methods and methods for envisioning new systems to system developers.in addition to a gap in metrics applicable to systems of systems, there are other problems that arise in regard to humansystem integration and systems of systems. for example, the human capability for understanding or developing a mental model of a system of system stretches the limits, raising issues for training, operations, and maintenance of these systems, as well as for determining risks or degree of system resilience (feltovich et al., 2004; hollnagel, woods, and leveson, 2006). furthermore, systems of systems inherit potentially incompatible humansystem interfaces from the best suppliers and legacy systems. systems of systems also bring together stakeholders with different linguistic, cultural, and technical backgrounds who must effectively collaborate but have a wider range of linguistic, cultural, and technical backgrounds than those involved in smaller systems. finally, systems of systems must support multiple missions with different objectives, constraints, and successcritical stakeholders.recommendation: conduct research and development studies to1. develop mental models and system transparency as applied to large and complex systems of systems.2. undertake efforts toward envisioning methods and models to uncover the sources of complexity and points of interdependency across systems and anticipate their impacts on the people operating in those environments.3. undertake studies to develop methods and tools for identifying and reconciling incompatibilities inherited from the best suppliers and legacy systems.4. undertake studies to develop methods and tools for analyzing and synthesizing candidate multimission solutions and supporting stakeholders™ convergence on a mutually satisfactory solution.5. undertake studies to develop methods and tools for analysis and design of resilient systems that foster adaptability to cope with unanticipated disturbances and change (hollnagel, woods, and leveson, 2006).sizing the hsi effortsystems engineering maturity models, such as the capability maturity model integration, require organizations to have objective and experiencehumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.310 humansystem integration in system developmentbased methods for estimating systems engineering effort, but in practice the methods for estimating hsi effort are largely ad hoc. in general, the estimation community has a number of methods for estimating effort, but their relative applicability to hsi effort estimation is not well understood.major relevant classes of effort estimation include (1) bottomup or activitybased methods in which individual performers estimate their needed amount of effort and the results are summed up; (2) topdown or systembased methods that involve various forms of analogybased estimation (using comparisons with the effort expended on similar previous systems); (3) unitcost methods that involve counting the number of work units (operational threads or scenarios, transaction types, etc.), perhaps weighted by complexity, volatility, and reuse, and multiplying the number of work units of each type by the average effort for each type; (4) expert consensus methods that involve ipts or consensusdetermination techniques such as delphi to converge on an effort estimate; (5) parametric models that attempt to characterize and parameterize the factors that cause variations in effort per work unit and to develop parametric models that account for the variations; and (6) riskbased ﬁhow much is enoughﬂ models that involve balancing the risk of expending too little hsi effort (operational shortfalls, expensive rework, project overruns) with the risk of doing too much hsi effort (critical path delays in making project progress; nonvalueadding effort). each of these approaches has strengths and weaknesses.recommendation: conduct research to develop, experimentally apply, evaluate, and rene versions of these methods for hsi effort estimation.knowledgebased planning aids for humansystem integrationas described in our vision for knowledgebased planning, currently humansystem integration most often takes place as standalone activities that are not well integrated with the mainstream system development processes. research is needed to develop a framework for integrating and adapting hsi methods and techniques into complex system development environments, supported by a tool implementing the framework that can be used to select the most costeffective methods and techniques based on operational, business, organizational, and project needs. humansystem integration and systems engineering activities rely on different methods, techniques, languages, and tools.the basis for integration exists in iso/iec 15288 (systems engineeringšsystem lifecycle processes), iso/tr 18529 (humancentered lifecycle humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 311process descriptions), and iso/pas 18152 (specication of the process assessment of humansystem issues), as well as in approaches to humansystem integration. see international organization for standardization (2000b, 2002, 2003). schaffer (2004) has published an example of how to institutionalize usability.some example planning tools that could be leveraged to support this kind of development areł logistics planning tools, such as dart and cougaar in the defense advanced research projects agency.ł hardware, software, and systems engineering resource estimation tools, such as the price systems, galorath, seer/sem, and usc  cocomo/cosysmo tool suites.ł risk assessment tools, such as active risk management, @risk, the software technology risk advisor (toth, 1995), and expert cocomo/cocots (madachy, 1995; yang et al., 2006).ł experience base management systems, such as those at the nasaœuniversity of maryland™s software engineering lab and the mitre corporation™s risk repository.recommendation: develop a framework for integrating and adapting hsi methods and techniques into complex system development environments.recommendation: establish a topdown framework for integrating humansystem integration with contrasting development environments to provide the common ground to leverage the integration of hsi methods, languages, and techniques into systems development.recommendation: develop a tool for selecting the most costeffective methods and techniques for humansystem integration based on business, organizational, and project needs and for integrating them with system engineering processes. there is currently little agreement in textbooks or the literature on appropriate methods and techniques, with con˚icting advice from different sources.recommendation: based on the framework outlined above, develop a set of criteria for selecting methods and techniques derived topdown from specic organizational, project, and lifecycle needs. the criteria will promote effective integration with mainstream system development processes.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.312 humansystem integration in system development1. provide estimates of the relative costs and benets that would be obtained by using different combinations of hsi methods and techniques.2. develop support tools incorporating the criteria.developing humansystem integration as a disciplinethis report makes the case that improved system performance and reduced development and operational risk would result from proper attention to the human user™s capacities and limitations and from better integration among user requirements and technical specications, especially concerning the introduction of computer support and automation. the committee has established a vision for humansystem integration to emerge as a distinct discipline. such a discipline would be made up from components of systems engineering, occupational health and safety, human factors and ergonomics, manpower, personnel and training, as well as business economics. it would provide specialists who could serve as the lead on hsi ipts, as the hsi representative on multidisciplinary ipts and, with the appropriate experience, could be selected as system development program managers. as systems and systems of systems become increasingly complex, the kind of expertise associated with this discipline will be a requirement.recommendation: humansystem integration should be developed as a distinct discipline. several questions and actions are posed in reaching this goal:1. what is hsi expertise?a. building on the work of booher (2003a, 2003b), develop a consensusbased taxonomy of skills, knowledge, and abilities by surveying leading hsi subject matter experts in both commercial and military domains. use the denitions and assumptions from booher (2003a, 2003b) and from this report to dene humansystem integration and to design the survey instrument.b. perform a market study that quanties the benets and costs associated with formalizing hsi curricula and continuing education programs in current or emergent academic departments. kleiner and booher (2003) provide a template and details for such a curriculum. experience gained thus far with the naval postgraduate school hsi program can be benchmarked for additional education programs. there is a need to serve both the military and nonmilitary communities.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 3132. what does it mean to be procient at humansystem integration?a. benchmark current best practices and requirements derived from this report; create a standardized hsi program management job description (knowledgeskillsabilities expectations).b. assuming the results of the market study are suggestive of further development, fund a number of pilot hsi graduate programs. the details of curricula and prociency requirements will be established by the academicians in these departments, with input from hsi subject matter experts.3. what is the rationale for selecting alternative hsi methods for different purposes?a. research is needed to establish the reliability, validity, and scalability of hsi methods, as well as the knowledge, skills, and abilities required to carry them out. these results are needed so that contractors can justify their selection of methods and procuring organizations can evaluate their selections.4. how can the discipline grow internationally?a. establish a source of hsi research funding that requires crosscultural or international teams. this can be funded by a single agency (e.g., the national science foundation or dod) or can be multiagency (e.g., department of commerce/european union).b. establish international hsi symposia within recognized professional conferences (e.g., international ergonomics association, north atlantic treaty organization).c. establish dedicated international hsi meetings and conferences.d. establish or reinforce hsi technical groups in relevant professional organizations, such as the human factors and ergonomics society that has a systems development technical group, and the international council on systems engineering, which has an hsi working group that can help promote the recommendations in this report.e. establish an international journal of human system integration to disseminate applied research and appropriately evaluated case studies related to humansystem integration. ideally, a relevant government agency or university with appropriate funding would host such a journal. the objective of the journal would be to serve as a repository of applied research, including appropriately designed and evaluated case studies that will expand the depth and breadth of knowledge, skills, and abilities associated with humansystem integration worldwide, across application domains and sectors.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.314 humansystem integration in system developmentfostering more synergy between research and practiceone factor that has hampered the advancement of humansystem integration as a discipline is the chasm that exists between research and practice. practitioners are not sufciently aware of relevant research, and research is not sufciently informed by the insights and body of knowledge gained from practice (norman, 1995; woods and christoffersen, 2002). there is a need to develop more effective ways to abstract knowledge and models from individual application contexts in a form that can be readily transferred to new application domains. while there are many examples of excellent hsi designs, their successes rely heavily on local knowledge and expertise. there is a need to develop methods and tools to more effectively leverage the knowledge and insights gained from practice and improve the crossdialogue between research and practice.recommendation: develop methods and tools to facilitate knowledge generalization and transfer across application domains and improve crossfertilization between research and practice.ł develop methods and tools for extracting abstract descriptions of behavioral patterns and the conditions that shape them that can be generalized across specic application domains (e.g., conditions that lead to specic error forms or foster specic types of expertise).ł develop abstract reusable design patterns that embody specic aiding principles and can be transferred across application domains;ł create publication vehicles for presenting eld studies and design case studies that offer generalizable insights (the new journal of cognitive engineering and decisionmaking is one such example).ł encourage practitioneroriented publications that synthesize research results in a form that can be readily assimilated and applied by hsi practitioners.methods for dening opportunities and context of usewe make research and development recommendations in two major areas. first, we recommend the development of software tools to capture and disseminate the results of context of use analyses so that they can more easily by applied in various phases of system lifecycle development. second, we make a series of recommendations concerning the active participation of users in engineering design, the future of unobtrusive, passive data collection, and the ethical considerations of both.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 315tools to support capture and dissemination of results of context of use analysesthe committee has argued for the importance of capturing the context of use in a form that can be more readily communicated and used throughout the hsi design life cycle. improved software tools are needed to support capture, organization, dissemination, update, and retrieval of results of context of use analyses. this includes capture of the results of task and cognitive task analyses, eld observations, participatory analysis and design activities, contextual inquiry, and work domain analyses. the research objective is to provide a suite of software tools to enable analysts to build and maintain a core corpus of work domain and context of use knowledge that can be updated easily as new information is learned, communicated to stakeholders effectively, and accessed and reused more readily across the life cycle of a development project. this core corpus of knowledge would then be available to inform design, the development of procedures, the development of training, the development of safety case submittals, etc. such a resource would be especially valuable in complex design projects whose development can span multiple years and multiple organizations. some promising research efforts toward developing core multimedia knowledge repositories include the work domain analysis workbench developed by sanderson and her colleagues (skilton, cameron, and sanderson, 1998) and the cmaptools software suite created at the institute for human and machine cognition. more research is needed to produce more robust systems with broader applicability.recommendation: conduct research to provide a suite of software tools to enable analysts to build and maintain a core corpus of work domain and context of use knowledge. specic steps include1. identify characteristics of a core corpus of work domain and context of use knowledge required to support a variety of stakeholders across the system life cycle. this would include hsi system designers, individuals responsible for system verication and validation, individuals responsible for development of risk analyses and safety case submittals, and individuals responsible for personnel selection, personnel training, and procedure and document development for system operation and maintenance.2. explore multimedia databases and software architectures to support development and retrieval of a variety of shared representations derived from context of use analyses. this would include graphic representations of domain and context of use knowledge, such as concept maps and abstraction hierarchies, and multimedia humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.316 humansystem integration in system developmentcapture of elements of the work context and proposed design concepts (e.g., videos illustrating expert strategies, still images of work environments illustrating usergenerated artifacts and workarounds compensating for poor system designs, sketches of design concepts generated during participant design sessions).3. identify and develop a demonstration project that would exercise and evaluate the approach in a particular complex applicationšideally one that involves system of systems design challenges.user participation in systems engineering and event data analysis and their ethical implicationsin the vision for systems engineering for user participation scenarios, we have argued for new ways to understand conditions in the eld, as well as the work practices of the endusers that involve unobtrusive, passive logging and interpretation of these activities. we have also argued that the new technologies of web 2.0 and related web development will allow endusers to modify, create, and revise systems that are already in use, thus providing a signicantly greater role for endusers in designing the systems that they will use. finally, we have argued for greater use of what we called event data analysis, to collect users™ actions and other occurrences in the eld and to nd emergent patterns from the data. these trends converge into three related sets of recommendations.recommendation: conduct a research program with the goal of revolutionizing the role of endusers in designing the system they will use.1. conduct lab and eld studies to understand current practices in serverlog data extraction and analysis and develop tools to efciently generate logs whose format is more useful to analysis than server logs.2. develop tools to facilitate rerepresenting automatically generated data, such as server logs, re˚ecting users™ perspectives on their work, their tools, and their experiences. we note that some of these issues may also involve issues of credit or payment or digital rights management of the users™ ideas (intellectual property). specic research and development activities includea. conduct research (lab and eld studies) and develop designs and technology to support user control or in˚uence over the online display of the user™s identity, i.e., impression management (goffman, 1956) and reputation management (beard, 1996).b. conduct research (lab and eld studies) and develop designs humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 317and technology to support user control or in˚uence over descriptions and representations of the user™s experience (individually or collectively with other users).c. conduct research (lab and eld studies) and develop designs and technology to support users in developing shared representations that effectively communicate the users™ needs, goals, intentions, strategies, and usergenerated solutions to problems (individually or collectively with other users).d. conduct research (lab and eld studies) exploring the usefulness of collaborative communication technologies for accomplishing the goals of improved user participation in system development.3. conduct research (lab and eld studies) and develop designs and technology to support users in transforming existing technologies and systems into modied or new systems that meet their needs. this process has variously been described as ﬁreinvention,ﬂ ﬁevolution,ﬂ and ﬁevolvability,ﬂ ﬁappropriation,ﬂ and ﬁeldmodication.ﬂ specically:a. identify, develop, or rene (as necessary) new software architectures that make it easier for users to modify systems or tailor congurations to support new uses, for subsequent use by other users or for subsequent ﬁharvestingﬂ by organizations.b. develop tools to support users in maintaining credit or ownership for their innovations.4. conduct research on the interactions of the new technologiesšsuch as the introduction of sensors in objects (spimes) and locations (geospatial web), in the targeted contexts. specically:a. determine what the introduction of spontaneously communicating ubiquitous devices will do to the work. develop methods for users to reform or reshape those technologies to change those interactions, as needed.b. determine how users will understand the functionality and security or privacy challenges of the new sensing and data integration technologies. determine effective ways of presenting these new technologies and new challenges to endusers.c. identify the users™ mental models of the technologies. determine how the technologies should be changed or packaged to match these mental models. determine what education or training will be needed on the part of endusers.d. determine how these new technologies can be made useful and usable by endusers in ofces, homes, and military theatres through reinvention or eld modication and other practices.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.318 humansystem integration in system developmentthe rst set of recommendations in this section explored the use of these data and technologies for endusers™ recording of data and experiences, harvesting of insights, communication of lessons learned, and expression of needs and recommendations. by contrast, the second set of recommendations in this section explores the analyst™s role in the use of such data for somewhat different purposes. in these recommendations, we focus on a more analytic approach to realtime data collection, with an emphasis on data collection that does not intrude on the users™ consciousness and therefore may provide a more traditional view on time and motion and other quantitative measures of how users do their work. data such as keystrokes, communications, emails, and web sites visited can be logged unobtrusively over the course of a day, weeks, or years as the user performs the task and potentially serve as a rich source of ethnographic and usability data for humansystem integration. in addition, web 2.0 and the emerging concept of ﬁattention dataﬂ (i.e., where does the user spend time and effort?) promise to create enumerable possibilities for rich yet unobtrusive data collection.recommendation: rene event data analysis methods and develop new methods in line with the following series of interrelated activities:1. explore the data sources described above for types of data that can be collected without interfering with the users™ ongoing work (e.g., keystroke analysis, observational cameras, and transportation data).2. instrument a setting (real or testbed) for collection of event data of a targeted variety to understand the practical implications for obtaining these kinds of data.3. collect other indices of performance/usability/cognition as well to serve as criterion measures.4. request users to provide their own perspective on their work (e.g., according to selected methods in the rst set of recommendations in this section).5. apply, adapt, and develop datamining or pattern recognition algorithms to identify regularities, anomalies, and changes in the data.6. map the patterns onto meaningful outcomes by associating them with other criteria.7. derive a small number of data structure standards for the records of such a behavioral instrumentation log, to facilitate quick analysis, searchable storage, and (when appropriate) data exchange of behavioral instrumentation logs in a (secured) group of collaborators or analysts.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 319the collection of these kinds of data raises new issues in security, privacy, and (ultimately) ethics. some organizations provide guidelines or policies in these areas, but even in those cases, there are many questions for which the researcher/practitioner/engineer must take responsibility. many systems inform the user that her or his data may be used for research purposes. for largescale systems, users often form a reasonable assumption that their limited use of the system will be under the radar of any research program. however, contemporary and nearfuture quantitative techniques address very large data sets and can easily nd individual users who match certain search criteria. indeed, many of the commercial applications of attention data operate on just such a basis. thus, no one can be condently under the radar any longer, but most users are not aware of this change.convergently, there have been major advances in data mining and data extraction by several communities whose interests are not necessarily aligned with the interests of the users, such as advertisers, fraud artists, and intelligence agencies (e.g., legitimate agencies as well as competitive agencies in the commercial space and enemy agencies in the military intelligence space). various lowvisibility industries exist for the purpose of understanding users™ interests and habits from the perspective of manipulating or taking advantage of them. when researchers or engineers compile large data sets, they are producing targets of high value for this shadowy industry.a third set of issues arises in different national policies. in the united states, most users consider their data privacy to be their own responsibility. by contrast, countries in the european union are more likely to have rules that govern the privacy of personal data, in which personal data can in some cases include not only private records created by an individual, but also private and public records that make reference to that individual.recommendation: conduct research on technologies to protect privacy and security and on the broader ethical and legal issues surrounding privacy and security.1. develop a graduated scale of data privacy. some data about users should be generally available; other data should have greater protection. what models of data protection are technically feasible? what options for user privacy and permission should be provided, beyond the current two approaches that have been summarized as humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.320 humansystem integration in system developmentﬁoptinﬂ and ﬁoptoutﬂ?1 how can the available privacy options be effectively presented and explained to the users? what technology and user experience are required to allow users to dene and implement their own data protection and security policies?2. examine the programs of nonprot organizations that have proposed to store users™ data in a protected repository, so that users can negotiate for some benet in exchange for allowing other organizations to access and use their data.2 how can these options be implemented technically on a largescale (market) basis? how can these options be effectively presented and explained to the users? what commercial models of benet for personal data access transactions should be available? what fraud protections are possible? what are effective mechanisms through which users can (a) make their personal data available to third parties and then, upon need, (b) withdraw both their permission and their data from those third parties?3. explore ways in which large data sets of user information could be made available to authorized users and yet be protected from unauthorized users. determine ways to (a) detect unauthorized access, (b) record the extent of unauthorized access to data stores, and (c) automatically notify affected users, so they can know what kinds of selfprotection to invoke following such unauthorized access.methods for dening requirements and designthe committee makes recommendations concerning the research and development needs related to humansystem development and to developing prototypes of organizations and training programs.humansystem model developmenthumansystem models have been shown already to be useful in the system acquisition and development process as a means to reduce uncertainty and development risk; however, they are not employed to the extent that even the current state of development would justify. there is a perception that models that re˚ect human performance characteristics are too hard to 1 in an optin approach, the user™s permission (e.g., to store or share data) is explicitly requested, and no action is taken unless the user takes an action to permit storage or sharing of data. in an optout approach, the user is informed that storage and/or sharing will be done unless the user takes action to prevent it or to revoke permission. in this latter case, the burden is on the user to prevent the storage or sharing of her or his data. in general, users prefer optin approaches, whereas merchants prefer optout approaches.2 see http://www.attentiontrust.org.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 321use or understand. potential users focus on the limitations and not on the advantages. in fact, models exist at all levels of complexity from simple mathematical expressions to complex computer programs. that said, it is true that the more sophisticated models, particularly those derived from discrete event simulators and cognitive architectures, are often brittle, costly, and timeconsuming to develop and are not yet well validated for all uses in design. there is a wide variety of both research developments and policy changes that have the potential to impact the usefulness and usability of humansystem models.recommendation: conduct an indepth study of how humansystem models are created, used, and shared, together with their strengths and limitations. the study should consider not only the various structures and architectures in which to build models, but also how data are acquired and represented in these models. what makes a model easy or difcult to use? to what extent are models reusable? why aren™t they reused more often? such a study would support improved education about how to develop models as well as provide recommendations for improving the quality, robustness, usefulness, and usability of the models that are developed. the study should include a retrospective review of a range of models, such as fitts™s law, signal detection theory, goms, microsaintbased models, to complex cognitive architectures, such as actr and epic.recommendation: pick, as a case study, a class of models at an intermediate level of complexity and invent a highlevel humansystem model development language, having as its goal to make building such models as simple as customizing an excel spreadsheet to a specic application.recommendation: explore the applicability of computer learning and adaptation algorithms for growing more robust models.currently, in models such as imprint, the user models included in the systems are useful, but the theories from which they are derived often lead to a basically linear, single thread model of human attention to tasks. increasingly, multiple task management, the impact of interruptions, and the role of situation awareness for decision making and planning are important in complex system analysis.recommendation: expand the delity of the user representations to include these aspects of behavior and how these aspects change with time on task, workload, heat, stress, and other behavior moderators.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.322 humansystem integration in system developmentrecommendation: expand models, particularly human behavior representation and cognitive models, to include the effects of culture, social processes, and emotion. this will also require gathering additional data, as many studies in these areas are not performed with the application to models in mind.there is much research on validating models, and it is recognized as a very complex and difcult problem. the consensus is that face validity is inadequate, but that achieving ﬁapplication validityﬂ is realistic and should be required. application validity is dened as the degree to which a model or simulation is a faithful representation of the real world from the perspective of the intended users. models are developed for specic purposes, and it is validation with respect to those purposes that is important.policy recommendation: require all humansystem performance models that are to be used in system acquisition risk reduction to meet the standards of application validity.recommendation: at a research level, better validation criteria need to be created. how good is good enough? better model validation criteria are needed for specic model types and for models in general. currently, when models are applicable, how much risk they reduce, or how valid they need to be to reduce risk is not well dened or even well explored.models and simulations have the potential to serve as effective shared representations for communicating the state of system development across the range of stakeholders. their major uses will be to support coordination and integration of multiple viewpoints, to provide shared envisioning of operational concepts and predicted performance characteristics, and for system integration. current examples fall short of achieving required goals and require further development.recommendation: conduct research on how to make the design rationale and the relationships among model and simulation assumptions, execution, and derived performance measures more transparent and understandable.prototyping training and organizational designthe committee has explained the role of prototyping in the systems development process. one of the challenges in developing integrated systems is that of the balance of prototyping elements of the proposed system humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 323in isolation (in order to support parallel development and validation of the elements) and prototyping the collection of subsystems (in order to evaluate the overall behavior of the linked subsystems and tradeoffs among them). in conventional systems engineering practice, both are done. the real challenge comes when the human operator, team, or organization must be considered in a more inclusive hsi design effort. it is clear from increasingly complex system development efforts that the earlier hsi issues can be addressed, the better.one way of addressing the challenge early is to createšlike the early machine system prototypesšearly prototypes of the people organization that will be interacting with the mediating technology or system hardware and software components. organizational prototypes could take many forms. they could be simply verbal or descriptive concepts and theories, involving walkthroughs or talkthroughs with hypothetical organizational structures. or the rules dening the relationships between organizational elements could be dened and individuals could stand in for each organizational element, a kind of interactive roleplaying, and carry out prototypical interorganizational operations (i.e., follow predened scenarios), while observing these rules and constraints (for summaries of successful applications of these types of approaches, see bjerknes, ehn, and kyng, 1987; bødker et al., 2004; muller, 2007; muller et al., 1997). alternatively, organizational elements could be represented by computational models and simulations, including the rules and constraints for interacting with each other (national research council, 1998). for example, a synthetic teammate based on a computational model could serve as a training or operational aid, as well as a component prototype for system design (gluck et al., 2006). it will mean that one has to know not only about all the interrelationships or links involved (human to human, human to machine, and machine to machine interactions) but also the nonmachine elements or nodes. like any prototyping problem, the appropriate level of resolution (person, team, organization) will become even more critical as personmachine coproduction denes the success or failure of the teams, organization, and system involved.similarly, it is important to consider prototyping the training program of potential team members as early in the design process as possible. this involves postulating alternative ways the training could be accomplished and testing their usefulness at varying levels of specicity as the design matures. success in this approach will mean that the system design, organization, and training program all coin˚uence each other. this kind of work is at such an early stage of development that there are many unanswered questions:1. what does it mean to prototype an organizationšwhat is the curhumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.324 humansystem integration in system developmentrent state of the art? are there differences with prototyping formal versus informal organizations? what are the implications for prototyping static versus dynamic teams and organizations? and how are artifactsšthe nonhuman components of the systemšaccounted for?2. are the prototyping issues different for individual, team, and organizational prototypes? what disciplines should be involved in supporting prototyping at an individual (cognitive psychology), team (social psychology), and organizational level (sociology, economics, anthropology, political science)?recommendation: undertake a review of the current state of the art in prototyping organizations. dene a set of requirements that effective prototyping methods should meet. select a candidate relatively complex domain, perhaps a system of systems domain, and dene alternative organizational structures that might be effective in this domain. dene alternative prototyping methods designed to span the range from very abstract to very specic. apply the different methods to evaluate the different possible organizations for this domain and revise the methods until they meet the requirements proposed.recommendation: undertake a review of the current state of the art in prototyping training systems. dene a set of operational domains and compare training requirements. examine use of synthetic agents in the development of training prototypes.methods for evaluationwe have discussed two classes of evaluation methods: risk usability evaluation and risk analysis. here the committee provides research and development objectives in both areas.improve the use of usability objectivesthe quantication of usability goals through the use of usability objectives is a recognized human factors and hsi best practice for many kinds of systems. but their use is not employed very often or consistently. the main goal of specifying usability objectives (also known as usability requirements, usability goals, performance goals, human factors requirements) is to create a metric that can be applied during usability testing as a way of having quantitative acceptance criteria for the test. usability objectives are one way to create a quantitative qualityrelated goal and avoid qualitative conclusions that are sometimes claimed about devices (e.g., ﬁthis device is userfriendlyﬂ). typically, quantied usability objectives includehumansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 325ł human performance goals (objective goals), such as task completion time, success rate or error rate and type, learning time, and accuracy.ł efciency (number of total steps and missteps), such as number of references to instructions or online help.ł user satisfaction (subjective goals) using such approaches as rating scales (likert, e.g., agree or disagree or comparative ratings) and semantic differential (pick rating between two opposite adjectives).in systems in which usability objectives are relevant, they should be validated as part of customer requirements (using common market research techniques, such as interviews, surveys, and focus groups) and compared with competitive benchmarks (usually obtained from published studies or from comparative usability testing of bestinclass competitor™s products). only a few critical taskrelated usability objectives typically are necessary. examples of quantitative usability objectives or goals areł 90 percent of experienced nurses will be able to insert the infusion pump tubing set on the rst try with no instructions. and 100 percent will be able to correct any insertion errors.ł 90 percent of experienced anesthesiologists will be able to calibrate the cardiac monitor within 2 minutes with no errors.ł experienced operators working in port security will be able to detect potential dangerous substances with a sensitivity of d™ = 3 or greater.ł unmanned aerial vehicle operators will be able to ˚y 3 planes at the same time in level ˚ight and be able to land the 3 planes within 15 minutes, with no more than a 5percent failure rate.ł 80 percent of experienced maintenance technicians will rate their satisfaction with the usability of device x as 7 or higher on a 10point satisfaction scale.ł after reading the quick reference card, 90 percent of experienced clinicians will be able to properly congure the display on the rst try to show the two ecg lead traces.ł 80 percent of experienced intensive care unit nurses will prefer the readability of the display for the latest generation ventilator monitor compared with the existing monitors.ł 95 percent of technicians with no prior experience with this type of network management system will achieve the target mastery level in 2 or fewer hours of use.recommendation: for cases in which usability objectives have been shown to be useful, conduct research to develop better ways to investigate, set, and use them as acceptance criteria. this research would humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.326 humansystem integration in system developmentspecically show the value and limitations of usability objectives in achieving overall project goals. specically:1. improve methods for demonstrating when usability objectives are valuable by surveying dod and commercial projects on their successes and failures in using usability objectives and collecting examples of usability objectives from surveys and literature reviews; create a taxonomy of usability objectives.2. improve methods for creating and setting usability objectives by surveying methods that have been used and their strengths and weaknesses; conducting experimental research on the relationship of using riskmanagement techniques, like failure mode and effects analysis and fault tree analysis, to set utility objectives and whether these projects are successful and meet project/mission goals; and searching the literature in other domains, such as software, electrical engineering, and the like and how they have used quantiable performance objectives and how they set and validate them.3. improve methods for validating usability objectives by surveying validation methods that have been used and their strengths and weaknesses and conducting literature reviews of techniques in other domains, such as marketing research, used to validate their objectives.4. improve methods for using usability objectives as a subset of project acceptance criteria by surveying techniques (including their strengths and weaknesses) for using usability objectives as acceptance criteria, including hypothesis testing and appropriate statistical techniques that have been used.maximize the costeffectiveness of usability evaluationalthough usability evaluation methods are widely used, no systematic and generalizable research has been carried out on the study size, scope, or protocols that costeffectively identify the most important usability problems. nielsen et al. (1994) analyzed the results of usability studies in the early 1990s to produce a formula to relate the number of test participants to the proportion of usability problems identied. this has been criticized as being applicable to only a limited class of products. molich and nielsen (1990) have shown that different usability evaluation procedures identify different subsets of problems; however, there is not good matching of problems with evaluation procedures. furthermore, it is rarely costeffective to evaluate every permutation of user type and task.there is little applied research evidence and few practices to assist a practitioner in deciding what number of studies to reduce the risk of humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 327human system mismatches are costeffective in a particular development environment, or to determine which groups or strata of users to include. market researchers have developed efcient methods from sociology for dening and using segmented or stratied samples, and there has been a small amount of research in humancomputer interaction (principally by siegel and dray, 2001) to integrate these marketoriented methods with traditional methods.recommendation: conduct research to generalize the sample size formula developed by nielson so that it can be applied to a wider range of products and systems, including such factors as system complexity, job function diversity, enduser demographics, and other relevant factors.recommendation: conduct research to understand which evaluation procedures are most appropriate for different types of products and systems, and how the evaluation procedure can be rened to maximize the number of problems identied most costeffectively while producing valid and reliable results.recommendation: conduct research to understand how to choose culturally appropriate evaluation methods, how to treat each method as a lens on a potentially larger set of usability problems, and how to translate from the constraints of a particular evaluation method into a more general or canonical description of the usability problems that were discovered and claried by that particular method.recommendation: there is often a shortage of skilled personnel to carry out usability evaluations. conduct research to establish whether members of a development team without a formal human factors background could be trained to carry out simple usability evaluations that produce valid and reliable results or, failing that, to understand the tradeoffs in data collection and quality when hsi methods are carried out by untrained practitioners.recommendation: conduct research to establish how precisely the evaluation procedure needs to be specied to ensure that two organizations will produce acceptably similar usability measures for summative evaluation.identify and assess hsi risksit is often stated in the hsi discipline that usability or human factors risks that are not addressed in the engineering design process are the basis humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.328 humansystem integration in system developmentfor catastrophic errors. the profession tends to fall back on the history of wellknown events, such as three mile island, bhopal, and the vincennes downing, to illustrate the perils of failing to address humansystem issues in design. while these examples can be compelling, they do not provide a rigorous basis for understanding risks in developing systems or for analyzing potentially catastrophic error conditions that may result from human operation. there are many human error classication schemes, but they tend to be locally focused and do not scale up to systemwide implications.we envision the initial research activity resulting from this recommendation to be developing a comprehensive database of hsi risks that are described at multiple levels and from multiple perspectives, from the initiating activity (e.g., cognitive error) to a system or societywide result (e.g., melting the core of a power plant). this is both a theoretical and a practical research activity, requiring the integration and extension of various error classication schemes, with larger scale systems impacts, such as costs, malfunctions, rework, among others, and multiple theoretical and even political frameworks. we see this research activity as going well beyond the typical cost justication exercise for human factors engineering and resulting in a systems model of hsi risks.recommendation: conduct research to develop a robust hsi risk taxonomy and a set of methodologies for analyzing and comparing relevant risk representations and con˚icting values.the general nature of the problem is to dene the con˚uence of human and system factors that may align to create operational problems that exceed the design basis of the system or result in operations that were totally unanticipated (reason, 1990, 1997). such features have been referred to as ﬁemergentﬂ in discussions of systems of systems, and that is really the principal focus of this researchšlinking the human and hardware and software systems with analytic techniques that can better identify extreme situations. incorporating the concepts of the relatively new domain called resilience engineering (hollnagel, woods, and leveson, 2006) will help to move this approach forward.recommendation: extend traditional fault tree and risk analysis techniques to better identify the ﬁboundary casesﬂ that may lead to extreme operational consequences.the benet to the hsi eld of conducting this research will be to establish a more robust basis for risk analysis and design than currently exists today. the error taxonomies are a start, but they tend to leave off where theoreticians stopšwell before examining the linkages in complex systems humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.conclusions and recommendations 329during the design process. the overall vision of this research recommendation is that the results will place hsi risk analysis on a more even footing with wellaccepted risk methods, such as the probabilistic risk analysis work performed in designing complex process plants, and they will extend the traditional fault analysis techniques to identifying and addressing situations that are beyond the typical design basis faults.improve the communication of riskthe analysis of risk must be done systematically, with great attention to use error or operational risk, business risk and mission risk, and (when appropriate) societal risk. in this report, the theme of risk reduction is mentioned quite often. techniques such as failure modes effect criticality analysis and fault tree analysis are recommended to analyze and control risk. these methods have been in use for many years, but they suffer from methodological problems, mostly involving how to make reliable estimates of risk parameters such as fault likelihood and severity of the consequences. another major issue concerns the weaknesses in the ways these project and user risks are communicated to decision makers and other stakeholders, as well as the political processes that may required to reconcile and integrate views of risks across multiple constituencies that may have different perspectives on systems and their implications (e.g., to achieve a satisced solution).recommendation: conduct research studies to show the value of improved assessment and shared representations that quantify the risk level for improved communication of business and operational risks to management and development team stakeholders. specically:1. survey communication techniques in other domains, such as advertising, sales, and news, and categorize success factors that could apply to business and operational risk communications.2. conduct literature searches and analysis of successful communication techniques used in other domains that might be applicable to riskmanagement communication stakeholders.3. conduct experiments comparing different risk communication techniques, for example, do risk estimation calibration exercises to improve risk communication as measured by changes in operator or decisionmaker behavior.recommendation: support applied interdisciplinary investigations into the communication, representation, and negotiation of risks and related humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.330 humansystem integration in system developmentissues, with the goal of assisting con˚icting parties in mutual understanding and satisced decision making.identify and assess hsi contributors to system adaptability and resiliencewhile humans are often viewed as the ﬁweaklinksﬂ in systems that contribute to errors and risk, there is a growing body of literature that has shown that people in fact play a critical role in system resiliencešthe ability of systems to operative effectively in the face of unanticipated disturbances. individuals, teams and organizations contribute to system resilience by planning for, recognizing and adapting to perturbations and surprisesšespecially ones that fall outside of the range of situations that the system was designed to handle (e.g., carthey, deleval and reason, 2001; weick and sutcliffe, 2001). alternatively, the individuals and management policies can be the detriments to resilience. this has led to a newly emerging area called resilience engineering that attempts to advance the study and design of systems that exhibit resilience (hollnagel, woods, and leveson, 2006; woods and hollnagel, 2006). more research is needed to understand the role people play in contributing to or inhibiting system resilience, and how new tools and technologies can be deployed to enhance people in the former role.recommendation: conduct research to understand the factors that contribute to system resilience, the role of people in resilient systems and how to design more resilient systems. some of the key questions that need to be addressed include the following:what kinds of knowledge and strategies enable people (particularly experts) to catch and recover from error and adapt to unanticipated situations?what methods can be used to analyze, measure, and monitor the resilience of organizations, systems and systems of systems?what traits and metrics enable systems to be developed and evaluated according to their adaptability and resilience?what methods can be used to model and predict the short and longterm effects of change on adaptability and resilience?humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.referencesabdelmalek, k., arora, j., yang, j., marler, t., beck, s., swan, c., freylaw, l., mathai, a., murphy, c., rahmatalla, s., and patrick, a. (2006). santos: a physicsbased digital human simulation environment. presentation and demonstration at the 50th annual meeting of the human factors and ergonomics society, october 1620, san francisco, ca.adlin, t., hynes, c., pruitt, j., mcgrane, k., goodwin, k., rosenstein, a., and muller, m.j. (2006). putting personas to work. panel discussion at the conference on human factors in computing systems (chi 2006), april 2227, quebec, canada.allen, c. (2004). life with alacrity: tracing the evolution of social software. available: http://www.lifewithalacrity.com/2004/10/tracingtheevo.html [accessed march 2007].allender, l. (2000). modeling human performance: impacting system design, performance, and cost. in m. chini (ed.), proceedings of the military, government, and aerospace simulation symposium, advanced simulation technologies conference (pp. 139144). san diego, ca: the society for computer simulation international. amram, m., and kulatilaka, n. (1999). real options: managing strategic investment in an uncertain world. boston: harvard business school press.anderson, c. (2006). the long tail: why the future of business is selling less of more. new york: hyperion.anderson, j.r., bothell, d., byrne, m.d., douglass, s., lebiere, c., and qin, y. (2004). an integrated theory of the mind. psychological review, 111, 10361060.annett, j. (2000). theoretical and pragmatic in˚uences on task analysis methods. in j.m. schraagen, s.f. chipman, and v.l. shalin (eds.), cognitive task analysis (pp. 2540). mahwah, nj: erlbaum.annett, j. (2005). hierarchical task analysis (hta). in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 331œ337). boca raton, fl: crc press.archer, s., headley, d., and allender, l. (2003). manpower, personnel, and training integration methods and tools. chapter 11 in h.r. booher (ed.), handbook of human systems integration (pp. 379432). hoboken, nj: wiley. 331humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.332 humansystem integration in system developmentbadler, n.i., erignac, c.a., and liu, y. (2002). virtual humans for validating maintenance procedures. communications of the acm, 45(7), 5663.beard, j.w. (ed.). (1996). impression management and information technology. greenwood, ct: quorum.beaudouinlafon, m., and mackay, w. (2003). prototyping tools and techniques. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 10061031). mahwah, nj: erlbaum.beaulieu, a. (2004). mediating ethnography: objectivity and the making of ethnographies of the internet. social epistemology, 18(23), 139163. available: http://www.virtualknowledgestudio.nl/staff/annebeaulieu/documents/mediatingethnography.pdf [accessed feb. 2007].beck, k. (1999). extreme programming explained: embrace change. boston: addisonwesley.beevis, d. (ed.). (1999). analysis techniques for humanmachine systems design: a report produced under the auspices of nato defense research group panel 8. wrightpatterson air force base, oh: crew systems ergonomics/human systems technology information analysis center.bernard, h.r. (1995). research methods in anthropology: qualitative and quantitative approaches (2nd ed.). thousand oaks, ca: sage.bevan, n. (2005). international standards for hci. in c. ghaoui (ed.), encyclopedia of human computer interaction (pp. 362372). hershey, pa: idea group.beyer, h., and holtzblatt, k. (1998). contextual design: dening customercentered systems. san francisco: morgan kaufmann.bias, r.g., and mayhew, d.j. (eds.). (2005). costjustifying usability: an update for the internet age. san francisco: morgan kaufmann.bikson, t.k., and eveland, j.d. (1996). groupware implementation: reinvention in the sociotechnical frame. in proceedings of the conference on computer supported cooperative work (cscs 96) (pp. 428437), nov. 1620, boston, ma. new york: association for computing machinery press.bisantz, a.m., roth, e.m., brickman, b., gosbee, l., hettinger, l. and mckinney, j. (2003). integrating cognitive analyses in a largescale system design process. international journal of human computer studies, 58, 177206.bjerknes, g., and bratteteig, t. (1987). florence in wonderland: system development with nurses. in g. bjerknes, p. ehn, and m. kyng (eds.), computers and democracy: a scandinavian challenge (pp. 279295). brookeld, vt: gower.bjerknes, g., ehn, p., and kyng, m. (eds.). (1987). computers and democracy: a scandinavian challenge. brookeld, vt: gower.björgvinsson, e., and hillgren, p.a. (2004). on the spot experiments within healthcare. in proceedings of the participatory design conference (pdc 2004), vol. 1, track 2, methodological considerations. available: http://trout.cpsr.org/conferences/pdc2004/proceedings/vol1/p93bjorgvinsson.pdf [accessed march 2007].black, f., and scholes, m. (1973). the pricing of options and corporate liabilities. journal of political economy, 81, 637659.blomberg, j., burrell, m., and guest, g. (2003). an ethnographic approach to design. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 964986). mahwah, nj: erlbaum.blomberg, j., giacomi, j., mosher, a., and swentonwall, p. (1993). ethnographic eld methods and their relation to design. in d. schuler, and a. namioka (eds.), participatory design: principles and practices (pp. 123155). hillsdale, nj: erlbaum.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 333boal, a. (1992). games for actors and nonactors (a. jackson, trans.). london, england: routledge.bødker, k., kensing, f., and simonsen, j. (2004). participatory it design: designing for business and workplace realities. cambridge, ma: mit press.bødker, s. (1996). applying activity theory to video analysis: how to make sense of video data in hci. in b. nardi (ed.), context and consciousness: activity theory and humancomputer interaction (pp. 147174). cambridge, ma: mit press.bødker, s., and buur, j. (2002). the design collaboratoriumša place for usability design. transactions on computerhuman interaction, 9(2), 152169.bødker, s., ehn, p., kammersgaard, j., kyng, m., and sundblad, y. (1987). a utopian experience: on design of powerful computerbased tools for skilled graphical workers. in g. bjerknes, p. ehn, and m. kyng (eds.), computers and democracy: a scandinavian challenge (pp. 251278). brookeld, vt: gower.bødker, s., knudsen, j.l., kyng, m., ehn, p., and madsen, k.h. (1988). computer support for cooperative design. in i. grief, and l. suchman (eds.), proceedings of the conference on computersupported cooperative work (cscw 88), sept. 2628, portland, or. new york: association for computing machinery press.boehm, b. (1991). software risk management: principles and practices. ieee software, 8(1), 3241.boehm, b. (1996). anchoring the software process. software, july, 7382.boehm, b. (2000). unifying software engineering and systems engineering. computer, march, 114116.boehm, b. (2006). some future trends and implications for systems and software engineering processes. systems engineering, spring, 119.boehm, b., brown, a.w., basili, v., and turner, r. (2004). spiral acquisition of software intensive systems of systems. crosstalk, may. available: http://www.stsc.hill.af.mil/crosstalk/2004/05/index.html [accessed march 2007].boehm, b., egyed, a., kwan, j., port, d., shah, a., and madachy, r. (1998). using the winwin spiral model: a case study. computer, july, 3344.boehm, b., and hansen, w. (2001). the spiral model as a tool for evolutionary acquisition. crosstalk, may, 411.boehm, b., and jain, a. (2005). an initial theory of valuebased software engineering. in s. bif˚, a. aurum, b. boehm, h. erdogmus, and p. grünbacher (eds.), valuebased software engineering (pp. 1537). berlin, germany: springerverlag.boehm, b., and lane, j. (2006). 21st century processes for acquiring 21st century systems of systems. crosstalk, may. available: http://www.stsc.hill.af.mil/crosstalk/2006/05/index.html [accessed march 2007].boland, r.j., and collopy, f. (2004). toward a design vocabulary for management. in r.j. boland and f. collopy (eds.), managing as designing (pp. 265276). palo alto, ca: stanford university press.booher, h.r. (2003a). introduction: human systems integration. in h.r. booher (ed.), handbook of human systems integration (pp. 130). hoboken, nj: wiley.booher, h.r. (ed.). (2003b). handbook of human systems integration. hoboken, nj: wiley.booher, h.r., and minninger, j. (2003). human systems integration in army systems acquisition. in h.r. booher (ed.), handbook of human systems integration (pp. 663698). hoboken, nj: wiley.borg, g. (2005). scaling experiences during work: perceived exertion and difculty. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 111œ117). boca raton, fl: crc press.bowers, c.a., jentsch, f., salas, e., and baun, c.c. (1998). analyzing communication sequences for team training needs assessment. human factors, 40, 672679.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.334 humansystem integration in system developmentbrandt, e., and grunnet, c. (2000). evoking the future: drama and props in user centered design. in proceedings of the participatory design conference (pdc 2000). available: http://intranet.dkds.dk/postnukephoenix/images/imageupload/305/les/pdc00evokingthefuturefinal.pdf [accessed march 2007].bucciarelli, l.l. (1988). an ethnographic perspective on engineering design. design studies, 9(3), 159168.burns, c.m., barsalou, e., handler, c., kuo, j., and harrigan, k. (2000). a work domain analysis for network management. in proceedings of the international ergonomics association/ human factors and ergonomics society (iea 2000/hfes 2000 congress) (vol. 1, pp. 469471). santa monica, ca: human factors and ergonomics society.burns, c.m., bisantz, a.m., and roth, e.m. (2004). lessons from a comparison of work domain models: representational choices and their implications. human factors, 46(4), 711727.burns, c.m., bryant, d., and chalmers, b. (2000). a work domain model to support shipboard command and control. in proceedings of the 2000 ieee international conference on systems, man and cybernetics (vol. 3, pp. 22282233). piscataway, nj: ieee.burns, c.m., and hajdukiewicz, j.r. (2004). ecological interface design. boca raton, fl: crc press.button, g. (ed.). (1992). technology in working order: studies of work, interaction, and technology. london, england: routledge.buur, j., binder, t., and brandt, e. (2000). taking video beyond ﬁhard dataﬂ in user centered design. in proceedings of the participatory design conference (pdc 2000). available: http://www.sdu.dk/nat/mci/m/research/publications/ucd/videobeyondharddata.pdf [accessed march 2007].buur, j., and bødker, s. (2000). from usability lab to ﬁdesign collaboratoriumﬂ: reframing usability practice. in proceedings of the conference on designing interactive systems: processes, practices, methods, and techniques (dis 2000), pp. 297307, aug. 1719, new york city.carayon, p. (2006). human factors of complex sociotechnical systems. applied ergonomics, 37, 525535.card, s.k., moran, t.p., and newell, a. (1983). the psychology of humancomputer interaction. hillsdale, nj: erlbaum.carlile, p.r. (2002). a pragmatic view of knowledge and boundaries. organization science, 13(4), 442455.carreira, r., crato, j.m., goncalves, d., and jorge, j.a. (2004). evaluating adaptive user proles for news classication. in proceedings of the 9th international conference on intelligent user interface (iui 04), jan. 1316, funchal, madeira, portugal (pp. 206212). new york: association for computing machinery press.carroll, j.m. (ed.). (1995). scenariobased design: envisioning work and technology in system development. new york: wiley.carroll, j.m. (2000). making use: scenariobased design of humancomputer interactions. cambridge, ma: mit press.carroll, j.m. (2002). dimensions of participation: elaborating herbert h. simon™s ﬁscience of design.ﬂ in j. perrin (ed.), les sciences de la conception [science of design]. presented at the international conference in honour of herbert simon, march 1516, insa de lyon. carruth, d., and duffy, v.g. (2005). towards integrating cognitive models and digital human models. in proceedings of the 11th international conference on humancomputer interaction, july 2227, las vegas, nv. mahwah, nj: erlbaum.chafn, d.b. (1997). biomechanical aspects of workplace design. in g. salvendy (ed.), handbook of human factors and ergonomics (2nd ed., pp. 772789). new york: wiley.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 335chafn, d.b. (2004). human motion simulation for vehicle and workplace design. in proceedings of 10th international conference on human aspects of advanced manufacturing: agility and hybrid automation, aug. 2427, galway, ireland.chafn, d.b. (2005). improving digital human modeling for proactive ergonomics in design. ergonomics, 48(5), 478491.chafn, d.b., anderson, g.b., and martin, b.j. (1999). occupational biomechanics (3rd ed.). new york: wiley.charlton, s.g. (2002). mental workload test and evaluation. in s.g. charlton and t.g. o™brien (eds.), handbook of human factors testing and evaluation (2nd ed.). mahwah nj: erlbaum.charlton, s.g., and o™brien, t.g. (eds.). (2002). handbook of human factors testing and evaluation (2nd ed.). mahwah, nj: erlbaum.checkland, p. (1981). systems thinking, systems practice. new york: wiley.chi, e., kittur, a., mytkowicz, t., pendleton, b., and suh, b. (2007). augmented social cognition: understanding social foraging and social sensemaking. plenary presentation at human computer interaction consortium, feb., winter park, co.chipman, s.f., and kieras, d.e. (2004). operator centered design of ship systems. in american society of naval engineers, engineering the total ship symposium 2004. alexandria, va: american society of naval engineers.cockton, g., woolrych, a., hall, l. and hindmarch, m. (2003). changing analysts™ tunes: the surprising impact of a new instrument for usability inspection method assessment. in p. palanque, p. johnson, and e. o™neill (eds.), people and computers xvii: designing for society (proceedings of hci 2003, pp. 145162). berlin, germany: springerverlag.cohen, m.a., ritter, f.e., and haynes, s.r. (2005). herbal: a highlevel language and development environment for developing cognitive models in soar. in l. allender and t. kelley (eds.), proceedings of the 14th conference on behavior representation in modeling and simulation (pp. 133140). orlando: university of central florida.conrow, e.h. (1995). the use of ordinal risk scales in defense systems engineering. in proceedings of the acquisition research symposium (16th)šacquisition reform: a mandate for changešreengineering the acquisition process. fort belvoir, va: defense systems management college.cook, j., and brown, j.s. (1999). bridging epistemologies: the generative dance between organizational knowledge and organizational knowing. organization science, 10(4).cook, t.d., and campbell, d.t. (1979). quasiexperimentation: design and analysis issues for eld settings. chicago, il: rand mcnally.cooke, n.j. (1994). varieties of knowledge elicitation techniques. international journal of humancomputer studies, 41(6), 801849.cooke, n.j., neville, k.j., and rowe, a.l. (1996). procedural network representations of sequential data. humancomputer interaction, 11, 2968.coolican, h. (2004). research methods and statistics in psychology (4th ed.). london, england: hodder and stoughton.cooper, a. (1999). the inmates are running the asylum: why high tech products drive us crazy and how to restore the sanity (1st ed.). indianapolis, in: sams.cooper, a. (2004). the inmates are running the asylum: why high tech products drive us crazy and how to restore the sanity (2nd ed.). indianapolis, in: sams.cooper, a., and reimann, r. (2003). about face 2.0: the essentials of interaction design. new york: wiley.coughlan, p., and prokopoff, i. (2004). managing change, by design. in r.j. boland and f. collopy (eds.), managing as designing (pp. 188192). palo alto, ca: stanford university press.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.336 humansystem integration in system developmentcouncill, i.g., haynes, s.r., and ritter, f.e. (2003). explaining soar: analysis of existing tools and user information requirements. in f. detje, d. dörner, and h. schaub (eds.), proceedings of the fifth international conference on cognitive modeling (pp. 6368). bamberg, germany: universitätsverlag bamberg.crabtree, a., o™brien, j., nichols, d., rounceeld, m., and twidale, m. (2000). ethnomethodologically informed ethnography and information systems design. journal of the american society for information science and technology, 51(7), 666682.crabtree, a., and rodden, t. (2002). ethnography and design? in proceedings of the international workshop on ‚interpretive™ approaches to information systems and computing research (pp. 7074). west london, england: brunel university.crandall, b., klein, g., and hoffman, r.r. (2006). working minds: a practitioner™s guide to cognitive task analysis. cambridge ma: mit press.crisp, h. (2006). systems engineering vision 2020, version 2.0. presentation to the washington metropolitan area chapter international council on systems engineering (incose), may 9.cummings, m.l. (2006). can cwa inform the design of networked intelligent systems? paper presented at the moving autonomy forward conference, june 2123, grantham, england.curtis, b., krasner, h., and iscoe, n.a. (1988). field study of the software design process for large systems. communications of the acm, 31, 12681287.dandavante, u., steiner, d., and william, c. (2000). working anywhere: codesign through participation. in proceedings of codesigning 2000. london, england: springer.darrah, c.n. (1995). technoguanxi: connecting relationships and icons through technology. paper presented at the american anthropological association annual meeting, washington, dc.d™astous, p., détienne, f., visser, w., and robillard, p.n. (2004). changing our view on design evaluation meetings methodology: a study of software technical review meetings. design studies, 25, 625655.davis, i., and stephenson, e. (2006). ten trends to watch in 2006. mckinsey quarterly. available: http://www.mckinseyquarterly.com/articleabstractvisitor.aspx?ar=1734&l2=21&l3=33&srid=17&gp=0#registernow [accessed march 2007].dawson, d., and fletcher, a. (2001). a quantitative model of workrelated fatigue: background and denition. ergonomics, 44, 144163.deal, t.e., and kennedy, a.a. (1982). corporate cultures: the rites and rituals of corporate life. harmondsworth, england: penguin.dekker, s. (2002). the eld guide to human error investigations. burlington, vt: ashgate.dekker, s., and woods, d.d. (1999). extracting data from the future: assessment and certiciation of envisionsed systems. in s. dekker and e. hollnagel (eds.), coping with computers in the cockpit (pp. 727). burlington, vt: ashgate.deming, w.e. (2000). out of the crisis. cambridge, ma: mit press.détienne, f. (2006). collaborative design: managing task interdependencies and multiple perspectives. interacting with computers, 18(1), 120.deutsch, s.e. (1998). interdisciplinary foundations for multipletask human performance modeling in omar. in proceedings of the twentieth annual meeting of the cognitive science society, madison, wi. mahwah, nj: erlbaum. also available: http://omar.bbn.com/ [accessed march 2007].dinadis, n., and vicente, k.j. (1999). designing functional visualizations for aircraft system status displays. international journal of aviation psychology, 9, 241269.dinges, d.f., connell, l.j., rosekind, m.r., gillen, k.a., kribbs, n.b., and graeber, r.c. (1991). effects of cockpit naps and 24hour layovers on sleep debt in longhaul transmeridian ˚ight crews. sleep research, 20, 406.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 337dourish, p. (2001). process descriptions as organizational accounting devices: the dual use of work˚ow technologies. available: http://www.informatik.unitrier.de/%7eley/db/conf/group/group2001.html#dourish01. [accessed march 2007].dray, s.m. (1992). understanding and supporting successful group work in software design: lessons from ids. in proceedings of the computer supported cooperative work (cscw ™92) conference. new york: association for computing machinery press.duez, p., and vicente, k.j. (2005). ecological interface design and computer network management: the effects of network size and fault frequency. international journal of humancomputer studies, 63, 565586.dzida, w., geis, t., and freitag, r. (2001). the datech usabilityengineering and testing process based on iso 13407. in proceedings of the 6th congress on software quality management, cologne, germany.earthy j., sherwood jones b., and bevan n. (2001). the improvement of humancentred processesšfacing the challenge and reaping the benet of iso 13407. international journal of humancomputer studies, 55(4), 553585.eggleston, r.g. (2003). workcentered design: a cognitive engineering approach to system design. in proceedings of the human factors and ergonomics society 47th annual meeting (pp. 263267). santa monica, ca: human factors and ergonomics society.eggleston, r.g., roth, e., whitaker, r., and scott, r. (2005). conveying workcentered design specications to the software designer: a retrospective case analysis. in proceedings of the human factors and ergonomics society 49th annual meeting (pp. 332336). santa monica, ca: human factors and ergonomics society.eglash, r., crossiant, j., di chiro, g., and fouché, r. (2004). appropriating technology: vernacular science and social power. minneapolis: university of minnesota press.ehn, p. (1988). workoriented design of computer artifacts. falköping, sweden: almqvist and wiksell international.ehn, p., and kyng, m. (1987). the collective resource approach to systems design. in g. bjerknes, p. ehn, and m. kyng (eds.), computers and democracy: a scandinavian challenge (pp. 1757). brookeld, vt: gower.ehn, p., and kyng, m. (1991). cardboard computers: mockingitup or handson the future. in j. greenbaum and m. kyng (eds.), design at work: cooperative design of computer systems (pp. 169195). hillsdale, nj: erlbaum.ehn, p., and löwgren, j. (1997). design for qualityinuse: humancomputer interaction meets information systems development. in m. helander, t.k. landauer, and p.v. prabhu (eds.), handbook of humancomputer interaction (2nd ed., pp. 299313). amsterdam, netherlands: elsevier.ehn, p., and sjögren, d. (1991). from system descriptions to scripts for action. in j. greenbaum and m. kyng (eds.), design at work: cooperative design of computer systems (pp. 241268). hillsdale, nj: erlbaum.eichensehr, p. (2006). knowledge application module. macroergonomics. virginia tech.elm, w.c., potter, s.s., gualtieri, j.w., easter, j.r., and roth, e.m. (2003). applied cognitive work analysis: a pragmatic methodology for designing revolutionary cognitive affordances. in e. hollnagel (ed.), handbook for cognitive task design (pp. 357382). mahwah, nj: erlbaum.embry, d.e. (1987). human reliability. in r. anthony (ed.) human reliability in nuclear power. london, england: ibc technical services.emery, f.e., and trist, e.l. (1978). analytical model for sociotechnical systems. in w.a. pasmore and j.j. sherwood (eds.), sociotechnical systems: a sourcebook (pp. 120133). lajolla, ca: university associates.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.338 humansystem integration in system developmentendsley, m.r. (1988). design and evaluation for situation awareness enhancement. in proceedings of the human factors society 32nd annual meeting (vol. 1). santa monica, ca: human factors society.endsley, m.r. (2000). direct measurement of situation awareness: validity and use of sagat. in m.r. endsley and d.j. garland (eds.), situation awareness analysis and measurement (pp. 147174). mahwah, nj: erlbaum.endsley, m.r., bolté, b., and jones, d.g. (2003). designing for situation awareness: an approach to usercentered design. london, england: taylor and francis.erickson, t. (1995). notes on design practice: stories and prototypes as catalysts for communication. in j.m. carroll (ed.), scenariobased design: envisioning work and technology in system development (pp. 3758). new york: wiley.erickson, t. (1996). design as storytelling. interactions, 3(4), 3035.ericsson, k.a., and simon, h.a. (1984). protocol analysis: verbal reports as data. cambridge, ma: mit press. ericsson, k.a., and simon, h.a. (1993). protocol analysis: verbal reports as data (rev. ed.). cambridge, ma: mit press.erl, t. (2005). serviceoriented architecture: concepts, technology, and design. upper saddle river, nj: prentice hall.evenson, s. (2005). designing design: establishing a new common ground for collaboration. presented at the 11th international conference on humancomputer interaction: interaction design education and research: current and future trends, july 2227, las vegas, nv.federal republic of germany. (2004). vmodell xt. available: http://www.vmodellxt.de [accessed march 2007].feltovich, p.j., hoffman, r.r., woods, d.d., and roesler, a. (2004). keeping it too simple: how the reductive tendency affects cognitive engineering. ieee intelligent systems, 19(3), may/june, 9094.fischer, g., giaccardi, e., ye, y., sutcliffe, a.g., and mehandjiev, n. (2004). metadesign: a manifesto for enduser development. communications of the acm, 47(9), 3337.fisher, r., and ury, w. (1981). getting to yes: negotiating agreement without giving in. boston: houghtonmif˚in.flanagan, j.c. (1954). the critical incident technique. psychological bulletin, 51, 327358.floyd, c. (1987). outline of a paradigm change in software engineering. in g. bjerknes, p. ehn, and m. kyng (eds.), computers and democracy: a scandinavian challenge (pp. 191210). brookeld, vt: gower.folkard, s., akerstedt, t., macdonald, i., tucker, p., and spencer, m.b. (1999). beyond the threeprocess model of alertness: estimating phase, time on shift and successive night effects. journal of biological rhythms, 14, 579587.fowler, f.j., jr. (2002). survey research methods (3rd ed.). thousand oaks, ca: sage.freed, m., matessa, m., remington, r., and vera, a. (2003). how apex automates cpmgoms. in f. detje, d. dörner, and h. schaub (eds.), proceedings of the fifth international conference on cognitive modeling (pp. 9398). bamberg, germany: universitätsverlag bamberg.garvey, p.r., and lansdowne, z.f. (1998). risk matrix: an approach for identifying, assessing, and ranking program risks. air force journal of logistics, 25(1), 1619.gasson, s. (2005). the dynamics of sensemaking, knowledge and expertise in collaborative boundaryspanning design. journal of computermediated communication, 10(4), 14.gladwell, m. (2005). blink: the power of thinking without thinking. new york: little, brown and company.glaser, b.g., and strauss, a.l. (1967). the discovery of grounded theory: strategies for qualitative research. new york: aldine.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 339gluck, k.a., ball, j.t., gunzelmann, g., krusmark, m.a., lyon, d.r., and cooke, n.j. (2006). a synthetic teammate for uav applications: a prospective look: final report. mesa, az: air force research laboratory. available: http://handle.dtic.mil/100.2/ada452642 [accessed march 2007].gluck, k.a., and pew, r.w. (eds.). (2005). modeling human behavior with integrated cognitive architectures. mahwah, nj: erlbaum.goffman, e. (1956). presentation of self in everyday life. garden city, ny: doubleday.golder, s.a., and huberman, b.a. (2006). structure of collaborative tagging systems. available: http://www.hpl.hp.com/research/idl/papers/tags/tags.pdf [accessed march 2007].gong, r., and kieras, d.e. (1994). a validation of the goms model methodology in the development of a specialized, commercial software application. in proceedings of the conference on human factors in computing systems (chi 1994) (pp. 351357). new york: association for computing machinery press.gorman, j.c., cooke, n.j., and winner, j.l. (in press). measuring team situation awareness in decentralised command and control systems. submitted to ergonomics for special issue on command and control.gray, w.d., john, b.e., and atwood, m.e. (1993). project ernestine: validating a goms analysis for predicting and explaining realworld task performance. humancomputer interaction, 8(3), 237309.gray, w.d., and kirschenbaum, s.s. (2000). analyzing a novel expertise: an unmarked road. in j.m. schraagen, s.f. chipman, and v.l. shalin (eds.), cognitive task analysis (pp. 275290). mahwah, nj: erlbaum.gray, w.d., and salzman, m.c. (1998). damaged merchandise? a review of experiments that compare usability evaluation methods. humancomputer interaction, 13(3), 203261.greenbaum, j., and kyng, m. (1991). design at work: cooperative design of computer systems. hillsdale, nj: erlbaum.grudin, j., and pruitt, j. (2002). personas, participatory design, and product development: an infrastructure for engagement. in proceedings of the participatory design conference participation and design: inquiring into the politics, contexts and practices of collaborative design work (pp. 144161). palo alto, ca: computer professionals for social responsibility.gualtieri, j.w., and elm, w.c. (2002). power tool for countering cyberwar: visualizations for information assurance and computer network defense. in proceedings of the human factors and ergonomics society 46th annual meeting (pp. 463467). santa monica, ca: human factors and ergonomics society.hall, e.m. (1998). managing risk: methods for software systems development. reading, ma: addisonwesley.hancock, p.a., and desmond, p.a. (2001). stress, workload, and fatigue. mahwah, nj: erlbaum.harris, j. (2005) an ofce user interface blog. available: http://blogs.msdn.com/jensenh/archive/2005/10/31/487247.aspx. [accessed july 2006].hart, s.g., and staveland, l.e. (1988). development of nasatlx (task load index): results of empirical and theoretical research. in p.a. hancock and n. meshkati (eds.) human mental workload (pp. 139183). amsterdam, netherlands: elsevier.hedge, a. (2005). physical methods. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 21œ24). boca raton, fl: crc press.henderson, a., and kyng, m. (1991). there™s no place like home: continuing design in use. in j. greenbaum and m. kyng (eds.), design at work: cooperative design of computer systems (pp. 219240). hillsdale, nj: erlbaum.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.340 humansystem integration in system developmenthendrick, h.a., and kleiner, b.m. (2001). macroergonomics: an introduction to work system design. santa monica, ca: human factors and ergonomics society.hendrick, h.w. (1998). lowering costs through ergonomics. in w. karwowski, and g.  salvendy (eds.). ergonomics in manufacturing: raising productivity through workplace improvement (pp. 2942). dearborn, mi: society of manufacturing engineers.highsmith, j. (2000). adaptive software development: a collaborative approach to managing complex systems. new york: dorset house.hine, c.m. (2000). virtual ethnography. thousand oaks, ca: sage.hoffman, r. (1987). the problem of extracting the knowledge of experts from the perspective of experimental psychology. ai magazine, 8(summer), 5367.hoffman, r., coffey, j.w., ford, k.m., and novak, j.d. (2006). a method for eliciting, preserving, and sharing the knowledge of forecasters. weather and forecasting, 21, 416428.hoffman, r., crandall, b.w., and shadbolt, n.r. (1998). use of the critical decision method to elicit expert knowledge: a case study in cognitive task analysis methodology. human factors, 40, 254276.hoffman, r., and elm, w.c. (2006). hcc implications for the procurement process. ieee intelligent systems, 21(1), 7481.hollnagel, e., woods, d.d., and leveson, n. (2006). resilience engineering: concepts and precepts. burlington, vt: ashgate.holtzblatt, k. (2003). contextual design. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 941963). mahwah, nj: erlbaum.holtzblatt, k., and beyer, h. (1993). making customercentered design work for teams. communications of the acm, 36(10), 92103.holtzblatt, k., wendell, j.b., and wood, s. (2004). rapid contextual design: a howto guide to key technologies for usercentered design. san francisco, ca: morgan kaufmann.houde, s., and hill, c. (1997) what do prototypes prototype? in m. helander, t.k. landauer, and p.v. prabhu (eds.), handbook of humancomputer interaction (2nd ed., pp. 367381). amsterdam, netherlands: elsevier.howes, a. (1995). cognitive modelling in hci. in a. monk and n. gilbert (eds.), perspectives on hci: diverse approaches (pp. 97119). london, england: academic press.hudlicka, e. (2002). increasing sociallyintelligent architecture realism by modeling and adapting to affect and personality. in k. dautenhahn, a.h. bond, l. canamero, and b. edmonds (eds.), multiagent systems, articial societies, and simulated organizations. dordrecht, netherlands: kluwer academic.hughes, j., king, v., rodden, t., and anderson, h. (1995). the role of ethnography in interactive systems design. interactions, 5665.hughes, j.a., o™brien, j., rodden, t., rounceeld, j., and blythin, s. (1997). designing with ethnography: a presentation framework for design. in proceedings of designing interactive systems: processes, practices, methods, and techniques (dis 97). new york: association for computing machinery press.hughes, j.a., randall, d., and shapiro, d. (1992). faltering from ethnography to design. in proceedings of the computer supported cooperative work (cscw ™92) conference. new york: association for computing machinery press.hulkko, s., mattelmäki, t., virtanen, k., and keinonen, t. (2004). mobile probes. presented at the nordic conference on computerhuman interaction (nordichi 2004), oct. 2327, tampere, finland.hutchins, e. (1995). cognition in the wild. cambridge, ma: mit press.iacucci, g., and kuutti, k. (2002). everyday life as a stage in creating and performing scenarios for wireless devices. personal and ubiquitous computing, 6, 299306.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 341ibm (n.d.). social software for business. available: http://www142.ibm.com/software/swlotus/products/product3.nsf/wdocs/connections [accessed feb. 2007].institute of medicine. (2000). to err is human. building a safer health system. l.t. kohn, j. m. corrigan, and m.s. donaldson, eds. committee on quality of health care in america. washington, dc: national academy press.international organization for standardization. (1996). iso 924110. ergonomic requirements for ofce work with visual display terminals (vdts)ópart 10: dialogue principles. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=16882 [accessed april 2007].international organization for standardization. (1998). iso 924111. ergonomic requirements for ofce work with visual display terminals (vdts)špart 11: guidance on usability. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=16883&ics1=13&ics2=180&ics3= [accessed april 2007].international organization for standardization. (2000a). iso 14971. medical devicesšapplication of risk management to medical devices. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=31550 [accessed april 2007].international organization for standardization. (2000b). iso/tr 18529. ergonomics of humansystem interactionšhumancentered lifecycle process descriptions. available: http://www.iso.ch/iso/en/cataloguedetailpage.cataloguedetail?csnumber=33499&scopelist= [accessed april 2007].international organization for standardization. (2001). iso/iec 91261. software engineeringproduct qualityšpart 1: quality model. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=22749&ics1=35&ics2=80&ics3= [accessed april 2007].international organization for standardization. (2002). iso/iec 15288. systems engineeringšsystem life cycle processes. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=27166&ics1=35&ics2=80&ics3= [accessed march 2007].international organization for standardization. (2003). iso/pas 18152. ergonomics of humansystem interactionšspecication for the process assessment of humansystem issues. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=38596 [accessed april 2007].international organization for standardization. (2006). iso/iec 25062. software engineeringšsoftware product quality requirements and evaluation (square)common industry format (cif) for usability test reports. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=43046&ics1=35&ics2=80&ics3= [accessed march 2007].international organization for standardization. (2007). is0/iec 25030. software engineeringšsoftware product quality requirements and evaluation (square)quality requirements. available: http://www.iso.org/iso/en/cataloguedetailpage.cataloguedetail?csnumber=35755&scopelist=programme [accessed april 2007].israelski, e.w., and muto, w.h. (2006). human factors engineering and the design risk management in medical devices. in p. carayon (ed.), handbook of human factors and ergonomics in healthcare and patient safety (part v, technology). mahwah, nj: erlbaum.ivory, m.y., and hearst, m.a. (2001). the state of the art in automating usability evaluation of user interfaces. acm computing surveys, 33(4), 470516.147. available: http://webtango.berkeley.edu/papers/uesurvey/p470ivory.pdf. [accessed april 2007].jamieson, g.a., and vicente, k.j. (2001). ecological interface design for petrochemical applications: supporting operator adaptation, continuous learning, and distributed, collaborative work. computers and chemical engineering, 25, 10551074.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.342 humansystem integration in system developmentjamshidi, m. (2005). systemofsystems engineeringša denition. ieee transactions. system, man, cybernetics, (oct.).jeffries, r., and desurvire, h. (1992). usability testing vs. heuristic evaluation: was there a contest? sigchi bulletin, 24(4), 3941.john, b.e., prevas, k., salvucci, d.d., and koedinger, k. (2004). predictive human performance modeling made easy. in proceedings of the conference on human factors in computing systems (chi 2004) (pp. 455462), april, vienna, austria. new york: association for computing machinery press.jones, d.g. (2000). subjective measures of situation awareness. in m.r. endsley and d.j. garland (eds.), situation awareness analysis and measurement (pp. 113128). mahwah, nj: erlbaum.jungk, r., and müllert, n. (1987). future workshops: how to create desirable futures. london, england: institute for social inventions.kelley, t. (2001). prototyping is the shorthand of innovation. design management journal, 12(3), 3542.kemmlert, k. (1995). a method assigned for the identication of ergonomic hazardsœplibel. applied ergonomics, 126, 199211.kensing, f., and madsen, a. (1993). pd: structure in the toolbox. communications of the acm 36(6), 7885.kensing, f., and munkmadsen, k.h. (1991). generating visions: future workshops and metaphorical design. in j. greenbaum and m. kyng (eds.), design at work: cooperative design of computer systems (pp. 155168). hillsdale, nj: erlbaum.kensing, f., simonsen, j., and bødker, k. (1996). mustša method for participatory design. in proceedings of the participatory design conference (pdc 1996), nov. 1315, cambridge, ma. san francisco: computer professionals for social responsibility.keyserling, w.m. (1998). methods for evaluating postural workload. in w. karwowski and g. salvendy (eds). ergonomics in manufacturing (pp. 167188). dearborn, mi: society of manufacturing engineers.kiekel, p.a., gorman, j.c., and cooke, n.j. (2004). measuring speech ˚ow of colocated and distributed command and control teams during a communication channel glitch. in proceedings of the human factors and ergonomics society 48th annual meeting, sept. 2024, new orleans, la. santa monica, ca: human factors and ergonomics society.kieras, d.e. (1998). a guide to goms model usability evaluation using ngomsl. in m. helander (ed.), handbook of humancomputer interaction (vol. 12, pp. 391438). amsterdam, netherlands: elsevier.kieras, d.e. (2003). modelbased evaluation. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 11391151). mahwah, nj: erlbaum.kieras, d.e., wood, s.d., abotel, k., and hornof, a. (1995). glean: a computerbased tool for rapid goms model usability evaluation of user interface designs. paper presented at the acm symposium on user interface software and technology (uist™95), new york.kieras, d.e., wood, s.d., and meyer, d.e. (1997). predictive engineering models based on the epic architecture for a multimodal highperformance humancomputer interaction task. transactions on computerhuman interaction, 4(3), 230275.kilbom, å., and petersson, n.f. (2006). elements of the ergonomic process. in w.s. marras and w. karwowski (eds.), occupational ergonomics handbook: interventions, controls, and applications in occupational ergonomics (2nd ed., pp. 11œ16). boca raton, fl: crc press.kirwan, b., and ainsworth, l.k. (eds.). (1992). a guide to task analysis. london, england: taylor and francis.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 343klær, a., and madsen, k.h. (1995). participatory analysis of ˚exibility. communications of the acm, 38(5), 5360.klein, g., and armstrong, a.a. (2005). critical decision method. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 351œ358). boca raton, fl: crc press.klein, g., calderwood, r., and macgregor, d. (1989). critical decision method for eliciting knowledge. ieee transactions. system, man, cybernetics, 19, 462472.kleiner, b.m. (1997). an integrative framework for measuring and evaluating information management performance. international journal of computers and industrial engineering, 32(3), 545555.kleiner, b.m., and h.r. booher (2003). human systems integration education and training. in h.r. booher (ed.), handbook of human systems integration (pp. 121163). hoboken, nj: wiley.kleiner, b.m., drury, c.g., and palepu, p. (1998). a computerbased productivity and quality management system for cellular manufacturing. computers and industrial engineering, 34(1), 207217.kroemer, k.h.e., kroemer, h.b., and kroemerelbert, k.e. (2001). ergonomics: how to design for ease and efciency (2nd ed.). upper saddle river, nj: prentice hall.kruchten, p. (1999). the rational unied process: an introduction. boston: addison wesley.kukreja, u., stenson, w.e., and ritter, f.e. (in press). ruišrecoding user input from interfaces under windows and mac os x. submitted to behavior research methods, instruments, and computers, 2.kyng, m., and matthiassen, l. (eds.). (1997). computers in design and context. cambridge ma: mit press.lafrenière, d. (1996). cuta: a simple, practical, lowcost approach to task analysis. interactions, 3(5), 3539.laird, j.e., newell, a., and rosenbloom, p.s. (1987). soar: an architecture for general intelligence. articial intelligence, 33(1), 164.lane, j., and valerdi, r. (2005). synthesizing systemsofsystems concepts for use in cost estimation. in proceedings of the 2005 ieee international conference on systems, man, and cybernetics (smc 2005), oct. 1012, waikoloa, hi. piscataway, nj: ieee.laughery, k.r., jr., and corker, k.m. (1997). computer modeling and simulation of human/system performance. in g. salvendy (ed.), handbook of human factors (2nd ed., pp. 13751408). new york: wiley.lebiere, c., biefeld, e., archer, r., archer, s., allender, l., and kelley, t.d. (2002). imprint/actr: integration of a task network modeling architecture with a cognitive architecture and its application to human error modeling. in proceedings of the advanced technologies simulation conference. san diego, ca.levinger, d. (1998). participatory design history. available: http://www.cpsr.org/prevsite/conferences/pdc98/history.html [accessed july 2006].levis, a. (2006). private presentation to the committee.li, g., and buckle, p. (1999). current techniques for assessing physical exposure to workrelated musculoskeletal risks, with emphasis on posturebased methods. ergonomics, 42, 674695.li, g., and buckle, p. (2005). quick exposure checklist (qec) for the assessment of workplace risks for workrelated musculoskeletal disorders (wmsds). in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 61œ610). boca raton, fl: crc press.liebhold, m. (2004). infrastructure for the new geography. menlo park, ca: institute for the future.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.344 humansystem integration in system developmentlin, l., vicente, k.j., and doyle, d.j. (2001) patient safety, potential adverse drug events, and medical device design: a human factors engineering approach. journal of biomedical informatics, 34, 274284.louhevaara, v., smolander, j., aminoff, t., and ilmarinen, j. (1998). assessing physical work load. in w. karwowski, and g. salvendy (eds.). ergonomics in manufacturing: raising productivity through workplace improvement (pp. 121134). dearborn, mi: society of manufacturing engineers.luff, p., hindmarsh, j., and heath, c. (eds.). (2000). workplace studies: recovering work practice and informing system design. cambridge, england: cambridge university press.lytle, w.o. (1998). designing a high performance organization: a guide to the wholesystems approach. clark, nj: block petrella weisbord.mackay, w.e. (1990). users and customizable software: a coadaptive phenomenon. doctoral dissertation. cambridge, ma: sloan school for management, massachusetts institute of technology.madachy, r. (1995). knowledgebased risk assessment and cost estimation. automated software engineering, 2(3), 219230.maier, m. (1998). architecting principles for systemsofsystems. systems engineering, 1(4), 267284.mannio, m., and nikula, u. (2001). requirements elicitation using a combination of prototypes and scenarios. lappeenranta, finland: lappeenranta university of technology.marenzano, j.f., rozsypal, s.a., zimmerman, g.h., warnken, g.w., wirth, p.e., and weiss, d.m. (2005). architecture reviews: practice and experience. ieee software, march/april, 3443.marras, w.s., and allread, w.g. (2005). lumbar motion monitor. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 141œ147). boca raton, fl: crc press.martinez, s.g., bennett, k.b., and shattuck, l., 2001. cognitive systems engineering analyses for army tactical operations. in proceedings of the human factors and ergonomics society 44th annual meeting (pp. 523526). santa monica, ca: human factors and ergonomics society.mayer, d. (2005). falconer aoc weapon system achieves ioc. the integrator, 1(27). available: http://integrator.hanscom.af.mil./2005/june/06232005/06232005.htm [accessed april 2007].mcatamney, l., and corlett, n. (1993). rula: a survey method for the investigation of workrelated upper limb disorders. applied ergonomics, 24, 9199.mcatamney, l., and corlett, n. (2005). rapid upper limb assessment (rula). in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 71œ711). boca raton, fl: crc press.mccracken j.h., and aldrich, t.b. (1984). analyses of selected lhs mission functions: implications for operator workload and system automation goals. [technical note asi 497024084(b)]. fort rucker, al: anacapa sciences.militello, l.g., and hutton, r.j.b. (2000). applied cognitive task analysis (acta): a practitioner™s toolkit for understanding cognitive task demands. in j. annett and n.a. stanton (eds.), task analysis (pp. 90113). london, england: taylor and francis.millen, d.r., (2000). rapid ethnography: time deepening strategies for hci eld research.in proceedings of the conference on designing interactive systems: processes, practices, methods, and techniques (dis 2000), pp. 280286, august 1719, new york city.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 345miller, c.a., and vicente, k.j. (1999). task ‚versus™ work domain analysis techniques: a comparative analysis. in proceedings of the human factors and ergonomics society 43rd annual meeting (pp. 328332). santa monica, ca: human factors and ergonomics society.miller, d., and slater, d. (2001). the internet: an ethnographic approach. oxford, england: berg.miller, r.b. (1953). a method for manmachine task analysis. (report #53137). dayton, oh: wright air development center, wrightpatterson air force base.modell, s. (1996). management accounting and control in services: structural and behavioural perspectives. international journal of service industry management, 7(2), 5780.mogensen, p., and trigg, r. (1992). artifacts as triggers for participatory analysis. in proceedings of the participatory design conference (pdc™92), nov. 67, cambridge, ma. san francisco: computer professionals for social responsibility.molich, r., and dumas, j.s. (2006). comparative usability evaluation (cue4). behaviour and information technology, 25.molich, r., ede, m.r., kaasgaard, k., and karyukin, b. (2004) comparative usability evaluation. behaviour and information technology, 23(1), 6574.molich, r., and nielsen, j. (1990). improving a humancomputer dialogue. communications of the acm, 33, 338348.monge, p.r., and contractor, n.s. (1999). emergence of communication networks. in f.m. jablin and l.l. putnam (eds.), handbook of organizational communication (2nd ed.). thousand oaks, ca: sage.monk, a., and howard, s. (1998). the rich picture: a tool for reasoning about work context. interactions, 2, 2130.mørch, a.i., engen, b.k., and åsand, h.r.h. (2004). the workplace as a learning laboratory: the winding road to elearning in a norwegian service company. in proceedings of the participatory design conference (pdc 2004) (pp. 142151). new york: association for computing machinery press.morrison, j.e. (2003). a review of computerbased human behavior representations and their relation to military simulations. (ida paper #p3845). alexandria, va: institute for defense analyses.muller, m.j. (1992). retrospective on a year of participatory design using the pictive technique. in proceedings of the conference on human factors in computing systems (chi ™92) (pp. 455462). new york: association for computing machinery press.muller, m.j. (2001). layered participatory analysis: new developments in the card technique. in proceedings of the conference on human factors in computing systems (chi 2001), (pp. 9097), march 31april 5, seattle, wa. new york: association for computing machinery press.muller, m.j. (2003). participatory design: the third space in hci. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 10511068). mahwah, nj: erlbaum.muller, m.j. (2007). participatory design: the third space in hci (revised). in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook (2nd ed.). mahwah, nj: erlbaum.muller, m.j., haslwanter, j.h., and dayton, t. (1997). participatory practices in the software lifecycle. in m. helander, t.k. landauer, and p.v. prabhu (eds.), handbook of humancomputer interaction (2nd ed., pp. 255297). amsterdam, netherlands: elsevier.muller, m.j., and kuhn, s. (eds.). (1993). special issue on participatory design. communications of the acm, 36(6).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.346 humansystem integration in system developmentmuller, m.j., millen, d.r., and strohecker, c. (2001). what makes a representative user representative? a participatory poster. in proceedings of the conference on human factors in computing systems (chi 2001), extended abstracts, march 31april 5, seattle, wa. new york: association for computing machinery press.muller, m.j., raven, m.e., kogan, s., millen, d.r., and carey, k. (2003). introducing chat into business organizations: toward an instant messaging maturity model. in proceedings of group 2003 international conference on supporting group work, nov. 912, sanibel island, fl. new york: association for computing machinery press.muller, m.j., tudor, l.g., wildman, d.m., white, e.a., root, r.w., dayton, t., carr, r., diekmann, b., and dykstraerickson, e. (1995). bifocal tools for scenarios and representations in participatory activities with users. in j.m. carroll (ed.), scenariobased design: envisioning work and technology in system development (pp. 135163). new york: wiley.muller, m.j., wharton, c., laux, l., and mciver, w., jr. (1997). toward an hci research and practice agenda based on human needs and social responsibility. in proceedings of the conference on human factors in computing systems (chi ™97), april 1823, atlanta ga. new york: association for computing machinery press.muller, m.j., wildman, d.m., and white, e.a. (1994). participatory design through games and other group exercises. in proceedings of the conference on human factors in computing systems (chi ™94), april, boston, ma. new york: association for computing machinery press.mumford, e., and henshall, d. (1983). designing participatively: a participative approach to computer systems design: a case study of the introduction of a new computer system. manchester, england: manchester business school. (original work published in 1979).naikar, n., pearce, b., drumm, d. and sanderson, p.m. (2003). designing teams for rstofakind, complex systems using the initial phases of cognitive work analysis: case study.human factors, 45(2), 202217.naikar, n., and sanderson, p.m. (1999). work domain analysis for trainingsystem denition and acquisition, international journal of aviation psychology, 9(3), 271290.naikar, n., and sanderson, p.m. (2001). evaluating design proposals for complex systems with work domain analysis, human factors, 43(4), 529542.naikar, n., and saunders, a. (2003). crossing the boundaries of safe operation: an approach for training technical skills in error management, cognition, technology and work, 5, 171180.nardi, b. (1993). a small matter of programming: perspectives on end user computing. cambridge, ma: mit press.nardi, b. (ed.). (1996). context and consciousness: activity theory and humancomputer interaction. cambridge, ma: mit press.nardi, b. (1997). the use of ethnographic methods in design and evaluation. in m. helander, t.k. landauer, and p.v. prabhu (eds.), handbook of humancomputer interaction (2nd ed., pp. 361366). amsterdam, netherlands: elsevier.national research council. (1997). more than screen deep: toward an everycitizen interface to the nation™s information infrastructure. toward an everycitizen interface to the nation™s information infrastructure steering committee. computer science and telecommunications board. commission on physical sciences, mathematics, and applications. washington, dc: national academy press.national research council. (1998). modeling human and organizational behavior: application to military simulations. r.w. pew and a.s. mavor (eds.). panel on modeling human behavior and command decision making: representations for military simulations, commission on behavioral and social sciences and education. washington, dc: national academy press. also available: http://www.nap.edu/catalog.php?recordid=6173 [accessed march 2007].humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 347national transportation safety board. (2006). aviation accident statistics, table 2. accidents and accident rates by ntsb classication, 1986 through 2005, for u.s. air carriers operating under 14 cfr 121. available: http://www.ntsb.gov/aviation/stats.htm [accessed march 2007].nemeth, c.p. (2004). human factors methods for design: making systems humancentered. boca raton, fl: crc press.nichols, s., and ritter, f.e. (1995). a theoretically motivated tool for automatically generating command aliases. in proceedings of the conference on human factors in computer systems (chi ™95), (pp. 393400), may 711, denver, co. new york: association for computing machinery press.nielsen, j., and mack, r.l. (eds.). (1994). usability inspection methods. new york: wiley.nightingale, d.j., and rhodes, d.h. (2004). enterprise systems architecting: emerging art and science within engineering systems. paper presented at the mit engineering systems symposium, session vi, march 31, cambridge, ma. available: http://esd.mit.edu/symposium/pdfs/papers/nightingale.pdf [accessed march 2007].noble, a., and robinson, c. (2000). for the love of the people: participatory design in a community context. in proceedings of codesigning 2000 (pp. 8191). london, england: springer.norman, d. (1993). things that make us smart: defending human attributes in the age of the machine. cambridge, ma: perseus.norman, d. (1995). on the difference between research and practice: ergonomics in design. santa monica, ca: human factors and ergonomics society.noro, k., and imada, a.s. (eds.). (1991). participatory ergonomics. london, england: taylor and francis.nuclear regulatory commission. (1981). fault tree handbook. w.e. vesely, f.f goldberg, n.h. roberts, and d.f. haasl, eds. washington, dc: author.occhipinti, e., and colombini, d. (2005). the occupational repetitive action (ocra) methods: ocra index and ocra checklist. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 151œ1514). boca raton, fl: crc press.o™hara, j.m. and roth, e.m. (2005). operational concepts, teamwork, and technology in commercial nuclear power stations. in c.a. bowers, e. salas, and f. jentsch (eds.), creating hightech teams: practical guidance on work performance and technology (pp. 139159).washington, dc: american psychological association.olson, j.s., olson, g.m., storrøsten, m., and carter, m. (1992). how a group editor changes the character of a design meeting as well as its outcome. in proceedings of the conference on computersupported cooperative work (cscw ™92) (pp. 9198), nov. 14, toronto, ontario, canada. new york: association for computing machinery press.olson, g.m., herbsleb, j., and rueter, h. (1994). characterizing the sequential structure of interactive behaviors through statistical and grammatical techniques. humancomputer interaction, 9, 427472.olsson, s. (2000). ethnography and internet: differences in doing ethnography in real and virtual environments. paper presented at the conference on information research seminar in scandinavia (iris 23) doing it together, aug. 1215, uddevalla, sweden. available: http://citeseer.ist.psu.edu/cache/papers/cs/20350/http:zszzsziris23.htu.sezszproceedingszszpdfzsz102nal.pdf/olsson00ethnography.pdf [accessed feb. 2007].o™reilly, t. (2005). what is web 2.0?  design patterns and business models for the next generation of software. available: http://www.oreillynet.com/pub/a/oreilly/tim/news/2005/09/30/whatisweb20.html [accessed march 2007].humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.348 humansystem integration in system developmentpaley, m.j., linegang, m.p., and morley, r.m. (2002). using communication data to assess organizational and system effectiveness in future combat systems. in proceedings of the human factors and ergonomics society 46th annual meeting, baltimore, md. santa monica, ca: human factors and ergonomics society.pasmore, w.a. (1988). designing effective organizations: the sociotechnical systems perspective. new york: wiley.pasztory, e. (2005). thinking with things: toward a new vision of art. austin: university of texas press.patterson, f. (1999). system engineering life cycles: life cycles for research, development, test, and evaluation; acquisition; and planning and marketing. in a. sage and w. rouse (ed.), handbook of systems engineering and management (pp. 59111). new york: wiley.patterson, e.s., cook, r.i., and render, m.l. (2002). improving patient safety by identifying side effects from introducing bar coding in medication administration. journal of the american medical informatics association, 9(5), 540553.patterson, e.s., roth, e.m., and woods, d.d. (2001). predicting vulnerabilities in computersupported inferential analysis under data overload. cognition, technology and work, 3, 224237.pedersen, j., and buur, j. (2000). games and moves: towards innovative codesign with users. in proceedings of codesigning 2000. london, england: springer.peterson, w.w., birdsall, t.g., and fox, w.c. (1954). the theory of signal detectability. ire professional group on information theory, 4, 171212.pew, r.w. (2000). the state of situation awareness measurement: heading toward the next century. in m.r. endsley and d.j. garland (eds.), situation awareness analysis and measurement (pp. 3350). mahwah, nj: erlbaum.pipek, v. (2005). from tailoring to appropriation support: negotiating groupware usage. phd thesis, oulu university, finland. available: http://herkules.oulu./isbn9514276302/ [accessed june 2005].potter, s.s., elm, w.c., roth, e.m., gualtieri, and easter, j. (2002). bridging the gap between cognitive analysis and effective decision aiding. in m.d. mcneese and m.a. vidulich (eds), state of the art report (soar): cognitive systems engineering in military aviation environments: avoiding cogminutia fragmentosa! (pp. 137168). dayton, oh: human systems information analysis center, wrightpatterson air force base. available: http://iac.dtic.mil/hsiac/.potter, s.s., roth, e.m., woods, d.d. and elm, w.c. (2000). bootstrapping multiple converging cognitive task analysis techniques for system design. in j.m. schraagen, s.f. chipman, and v.l. shalin (eds.), cognitive task analysis (pp. 317340). mahwah, nj: erlbaum.potts, c., and hsi, i. (1997). abstraction and context in requirements engineering: a synthesis of goal renement and ethnography. annals of software engineering, 3, 2361.preece, j. (2002). supporting community and building social capitalšintroduction. communications of the acm, 45(4), 3739.price, h.e. (1985). the allocation of functions in systems. human factors, 27(1), 3345.pruitt, j., and adlin, t. (2006). the persona lifecycle: keeping people in mind throughout product design. san francisco, ca: morgan kaufmann.pruitt, j., and grudin, j. (2003). personas: theory and practice. presented at the conference on designing for user experience (dux2003), june 57, san francisco, ca.raiffa, h. (1982). the art and science of negotiation. cambridge, ma: harvard university press.rasmussen, j. (1986). information processing and humanmachine interaction: an approach to cognitive engineering. new york: northholland.rasmussen, j., pejtersen, a.m., and goodstein, l.p. (1994). cognitive systems engineering. new york: wiley.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 349reason, j.t. (1990). human error. cambridge, england: cambridge university press.reason, j.t. (1997). managing the risks of organizational accidents. brookeld, vt: ashgate.rector, a. l., horan, b., fitter, m., kay, s., newton, p.d., nowlan, w.a., robinson, d., and wilson, a. (1992). user centered development of a general practice medical workstation: the pen&pad experience. in proceedings of the conference on human factors in computing systems (chi 1992). new york: association for computing machinery press.redish, j., and wixon, d. (2003). task analysis. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 922940). mahwah, nj: erlbaum.rheinfrank, j., and welker, k. (1994). working from the border. humancomputer interaction, 9(1), 111114.rith, c., and dubberly, h. (2005). horst rittel: a denitive bibliography. san francisco, ca: dubberly design. ritter, f.e., baxter, g.d., jones, g., and young, r.m. (2000). supporting cognitive models as users. acm transactions on computerhuman interaction, 7(2), 141173.ritter, f.e., freed, a.r., and haskett, o.l. (2005). user information needs: the case of university department web sites. acm interactions, 12(5), 1927.ritter, f. e., haynes, s. r., cohen, m., howes, a., john, b., and best, b. (2006). highlevel behavior representation languages revisited. in d. fum, f. del missier, and a. stocco (eds.), proceedings of iccm2006 seventh international conference on cognitive modeling (pp. 404407). trieste, italy: edizioni goliardiche.ritter, f.e., van rooy, d., and st. amant, r. (2002). a user modeling design tool based on a cognitive architecture for comparing interfaces. in c. kolski and j. vanderdonckt (eds.), computeraided design of user interfaces iii, proceedings of the 4th international conference on computeraided design of user interfaces (cadui 2002) (pp. 111118). dordrecht, netherlands: kluwer academic.ritter, f.e., shadbolt, n.r., elliman, d., young, r.m., gobet, f., and baxter, g.d. (2003). techniques for modeling human performance in synthetic environments: a supplementary review. dayton, oh: human systems information analysis center, wrightpatterson air force base.rodgers, s. (2005). muscle fatigue assessment: functional job analysis technique. in n.  stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 121œ1210). boca raton, fl: crc press.rosson, m., and carroll, j.m. (1996). objectoriented design from user scenarios. available: http://sigchi.org/chi96/proceedings/tutorial/rosson/mbrtxt.htm [accessed july 2006].rosson, m., and carroll, j.m. (2002). usability engineering: scenariobased development of humancomputer interaction. san francisco, ca: morgan kaufmann.rosson, m. and carroll, j.m. (2003). scenariobased design. in j.a. jacko and a. sears (eds.), the humancomputer interaction handbook: fundamentals, evolving technologies, and emerging applications (pp. 10321050). mahwah, nj: erlbaum.rosson, m., maass, s., and kellogg, w. (1989). the designer as user: building requirements for design tools from design practice. communications of the acm, 31(11), 12881297.roth, e.m., lin, l., kerch, s., kenney, s.j., and sugibayashi, n. (2001). designing a rstofakind group view display for team decision making: a case study. in e. salas and g. klein (eds.), linking expertise and naturalistic decision making (pp. 113135). mahwah, nj: erlbaum.roth, e.m., and patterson, e.s. (2005). using observational study as a tool for discovery: uncovering cognitive and collaborative demands and adaptive strategies. in h. montgomery, r. lipshitz, and b. brehmer (eds.), how professionals make decisions (pp. 379393). mahwah, nj: erlbaum.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.350 humansystem integration in system developmentroth, e.m., scott, r., deutsch, s., kuper, s., schmidt, v., stilson, m. and wampler j. (in press). evolvable workcentered support systems for command and control: creating systems users can adapt to meet changing demands. submitted to ergonomics.roth, e.m., stilson, m., scott, r., whitaker, r., kazmierczak, t., thomasmeyers, g., and wampler, j. (2006). workcentered design and evaluation of a c2 visualization aid. in proceedings of the human factors and ergonomics society 49th annual meeting (pp. 332336). santa monica, ca: human factors and ergonomics society.rouse, w.b. (2003). human systems integration and new product development. in h.r. booher (ed.), handbook of human systems integration (pp. 877903). hoboken, nj: wiley.royce, w.e. (1998). software project management. boston: addison wesley.royce, w.w. (1970). managing the development of large software systems: concepts and techniques. proceedings of ieee wescon, 26(august), 19. available: http://www.cs.umd.edu/class/spring2003/cmsc838p/process/waterfall.pdf [accessed march 2007].sage, a., and cuppan, c. (2001). on the systems engineering and management of systems of systems and federations of systems. information, knowledge, and systems management, 2, 325345.sage, a., and rouse, w. (eds.) (in press). handbook of systems engineering and management (revised edition). new york: wiley.sage, a., and rouse, w. (1999a). an introduction to systems engineering and systems management. in a. sage and w. rouse (ed.), handbook of systems engineering and management (pp. 158). new york: wiley.sage, a., and rouse, w. (eds.) (1999b). handbook of systems engineering and management. new york: wiley.sager, l., and grier, r.a. (2005). identifying and measuring the value of human factors to an acquisition project. presented at the human systems integration symposium. available: http://www.aptima.com/publications/2005sagergrier.pdf [accessed march 2007].salvendy, g. (2006). handbook of human factors and ergonomics (3rd ed.). hoboken, nj: wiley.salvucci, d.d., and anderson, j.r. (2001). automated eyemovement protocol analysis. humancomputer interaction, 16, 3986.sanders, e.b.n. (2000). generative tools for codesigning. in proceedings of codesigning 2000. london, england: springer.sanderson, p. (2003). cognitive work analysis. in j.m. carroll (ed.), hci models, theories, and frameworks: toward a multidisciplinary science (pp. 225264). san francisco: morgan kaufmann.sanderson, p., and fisher, c. (1994). exploratory sequential data analysis: foundations. humancomputer interaction, 9, 251317.sanderson, p., naikar, n., lintern, g., and goss, s. (1999). use of cognitive work analysis across the system life cycle: requirements to decommissioning. in proceedings of the 43rd annual meeting of the human factors and ergonomics society (pp. 318322). santa monica, ca: human factors and ergonomics society.sanquist, t.f., and mccallum, m.c. (2004). a comprehensive evaluation and classication of fatigue countermeasures for transportation operators. in proceedings of the human factors society annual meeting. santa monica, ca: human and ergonomics society.sarter, n., and sarter, m. (2003). neuroergonomics: opportunities and challenges of merging cognitive neuroscience with cognitive ergonomics. theoretical issues in ergonomics science, 4, 142150.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 351sauro, j., and kindlund, e. (2005). making sense of usability metrics: usability and six sigma. presented at the usability professionals™ association meeting (upa 2005), june 27july 1, montreal, quebec, canada. available: http://www.measuringusability.com/ [accessed march 2007].sauter, s.l., swanson, n.g., waters, t.r., hales, t.r. and dunkinchadwick, r. (2005). musculoskeletal discomfort surveys used at niosh. in n. stanton, a. hedge, k. brookhuis, e. salas, and h. hendrick (eds.), handbook of human factors and ergonomics methods (pp. 4œ1œ10). boca raton, fl: crc press.scacchi, w. (2004). sociotechnical design. in w.s. bainbridge (ed.), the encyclopedia of humancomputer interaction (pp. 656659). great barrington, ma: berkshire.schaffer, e. (2004). institutionalization of usability: a stepbystep guide. boston: addisonwesley.schein, e. (1996). culture: the missing concept in organizational studies. administrative science quarterly, 41, 229240.schraagen, j.m., chipman, s.f., and shalin, v.l. (eds.). (2000). cognitive task analysis. mahwah, nj: erlbaum.schrage, m. (1994). peeking from the periphery: does the document metaphor inspire (re)designs? humancomputer interaction, 9(1), 115118.schrage, m. (1996). cultures of prototyping. in t. winograd (ed.), bringing design to software (pp. 191205). new york: association for computing machinery press.schreiber, b.t., and bennett, w., jr. (2006). distributed mission operations withinsimulator training effectiveness baseline study. volume i: summary report (afrlheaztr20060015). mesa, az: warghter training research division, air force research laboratory. schreiber, b.t., bennett, w., jr., and gehr, s.e. (2006). fidelity tradeoffs for deployable training and rehearsal. in proceedings of the interservice/industry training, simulation and education conference (i/itsec). orlando, fl: national security industrial association.schuler, d., and namioka, a. (eds.). (1993). participatory design: principles and practices. hillsdale, nj: erlbaum.schvaneveldt, r.w., durso, f.t., and dearholt, d.w. (1989). network structures in proximity data. in g.h. bower (ed.), the psychology of learning and motivation: advances in research and theory (vol. 24, pp. 249284). new york: academic press.shadbolt, n., bernerslee, t., and hall, w. (2006). the semantic web revisited. ieee intelligent systems, 21(3), 96101.shepard, r.n. (1962a). analysis of proximities: multidimensional scaling with an unknown distance function. i psychometrika, 27, 125140.shepard, r.n. (1962b). analysis of proximities: multidimensional scaling with an unknown distance function. ii psychometrika, 27, 219246.shepard, r.n., and arabie, p. (1979). additive clustering: representation of similarities as combinations of discrete overlapping properties. psychological review, 86, 87123.shneiderman, b. (2002). leonardo™s laptop: human needs and the new computing technologies. cambridge, ma: mit press.siegel, d., and dray, s. (2001). new kid on the block: marketing organizations and interaction design. interactions, 8(2), 1924.sinha, r. (2003). persona development for informationrich domains. in proceedings of the conference on human factors in computing systems (chi 2003), extended abstracts, (pp. 830831), april 510, ft. lauderdale, fl. new york: association for computing machinery press.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.352 humansystem integration in system developmentskilton, w., cameron, s., and sanderson (1998). supporting cognitive work analysis with the work domain analysis workbench (wdaw). in proceedings of the computer human interaction conference (pp. 260267), nov. 30dec. 4. piscataway, nj: ieee.slavkovic, a., and cross, k. (1999). novice heuristic evaluations of a complex interface. in proceedings of the conference on human factors in computing systems: the chi is the limit (chi ™99), extended abstracts, may 1520, pittsburgh, pa. new york: association for computing machinery press.snyder, c. (2003). paper prototyping: the fast and easy way to design and rene user interfaces. san francisco: morgan kaufmann.somerville, i., martin, d., and rounceeld, m. (2003). informing the requirements engineering process with patterns of cooperative interaction. international arab journal of information technology, 1(1).special issue on collaboration, cooperation, and con˚ict in dialogue systems. (2000). international journal of humancomputer studies 53(6). spool, j., and schroeder, w. (2001) testing web sites: five users is nowhere near enough. in proceedings of the conference on human factors in computing systems (chi ™01) (pp. 285286), extended abstracts, march 31april 5, seattle, wa. new york: association for computing machinery press.st. amant, r., freed, a.r., and ritter, f.e. (2005). specifying actr models of user interaction with a goms language. cognitive systems research, 6(1), 7188.st. amant, r., horton, t.e., and ritter, f.e. (2004). modelbased evaluation of cell phone menu interaction. in proceedings of the conference on human factors in computing systems (chi ™04), (pp. 343350), april 2429, vienna, austria. new york: association for computing machinery press.stamatis, d.h. (1995). failure mode and effect analysis: fmea from theory to execution. milwaukee, wi: asqc quality press.standish group. (2006). the standish store. available: https://secure.standishgroup.com/reports/reports.php [accessed march 2007].stanton, n.a., hedge, a., brookhuis, k., salas, e., and hendrick, h. (eds.) (2005a). handbook of human factors and ergonomics methods. boca raton, fl: crc press.stanton, n.a., salmon, p.m., walker, g.h., baber, c., and jenkins, d.p. (200b5). human factors methods: a practical guide for engineering and design. burlington, vt: ashgate.star, s.l. (1989). the structure of illstructured solutions: boundary objects and heterogeneous distributed problems solving. in l. gasser and m.n. huhns (eds.), distributed articial intelligence (vol. ii, pp. 3754). san francisco: morgan kaufmann.sterling, b. (2004). when blobjects rule the earth. keynote address presented at the 31st international conference on computer graphics and interactive techniques (siggraph 2004), aug., los angeles. available: http://www.boingboing.net/images/blobjects.htm [accessed march 2007].suchman, l.a. (1987). plans and situated actions: the problem of humanmachine communication. cambridge, england: cambridge university press.suchman, l.a. (2002). located accountabilities in technology production. scandinavian journal of information systems, 14(2), 91105.suchman, la. (2004). decentering the manager/designer. in r.j. boland and f. collopy (eds.), managing as designing (pp. 169173). palo alto, ca: stanford university press.suchman, l., and trigg, r. (1991). understanding practice: video as a medium for re˚ection and design. in j. greenbaum and m. kyng (eds.), design at work: cooperative design of computer systems (pp. 6590). hillsdale, nj: erlbaum.sun, r. (ed.). (2006). cognition and multiagent interaction: from cognitive modeling to social simulation. cambridge, england: cambridge university press.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 353suthers, d.d. (2005). collaborative knowledge construction through shared representations. in proceedings of the 38th annual hawaii international conference on system sciences (hicss ‚05). washington, dc: ieee computer society.suwa, m., and tversky b. (2002). external representations contribute to the dynamic construction of ideas. in proceedings of the diagrammatic representation and inference: second international conference, diagrams 2002, callaway gardens, ga, april 1820 (p. 341). berlin, germany: springerverlag.swain, a.d. (1963). a method for performing a human factors reliability analysis. (monograph #scr685). albuquerque, nm: sandia national laboratories.swain, a.d., and guttmann, h.e. (1983). handbook of human reliability analysis with emphasis on nuclear power plant applications. (nureg/cr 1278). albuquerque, nm: sandia national laboratories.swets, j.a., dawes, r.m., and monahan, j. (2000). psychological science can improve diagnostic decisions. psychological science in the public interest, 1, 126.tang, j.c., liu, s.b., muller, m.j., drews, c., and lin, j. (2006). unobtrusive but invasive: using screen recording to collect eld data on computermediated interaction. in proceedings of the 20th anniversary conference on computer supported cooperative work (cscw 2006) (pp. 479482), nov. 48, alberta, canada. new york: association for computing machinery press.taylor, s. (ed.). (2001). ethnographic research: a reader. london, england: sage.tenney, y.j., and pew, r.w. (2006). situation awareness catches on: what? so what? now what? in r.c. williges (ed), reviews of human factors and ergonomics. santa monica, ca: human factors and ergonomics society.teton, d., and allen, s. (2007). the growth of social software. available: http://www.fastcompany.com/resources/networking/tetenallen/120606.html [accessed feb. 2007].theofanos, m. (2006). a practical guide to the cif: usability measurements. interactions, 13(6), 3437.thorp, j. (1998). the information paradox: realizing the business benets of information technology. toronto, canada: mcgraw hill.toth, g. (1995). automated method for identifying and prioritizing project risk factors. automated software engineering, 2(3), 231248.trigg, r.h. (2000). from sandbox to ﬁfundboxﬂ: weaving participatory design into the fabric of a busy nonprot. in proceedings of the participatory design conference (pdc 2000) (pp. 174182). new york: computer professionals for social responsibility.truex, d., baskerville, r., and klein, h. (1999). growing systems in an emergent organization. communications of the acm, 42(8), 117123.tsang, p.s., and wilson, g.f. (1997). mental workload. in g. salvendy (ed.), handbook of human factors and ergonomics (2nd ed., pp. 417449). new york: wiley.tscheligi, m., houde, s., marcus, a., mullet, k., muller, m.j., and kolli, r. (1995). creative prototyping tools: what interaction designers really need to produce advanced user interface concepts. in proceedings of the conference on human factors in computer systems (chi ™95), (pp. 170171), may 711, denver, co. new york: association for computing machinery press.tversky, b, morrison, j.b., and betrancourt, m. (2002). animation: can it facilitate? international journal of humancomputer studies, 57(4), 247262.tyler, j.r, wilkinson, d.m., and huberman, b.a. (2005). email as spectroscopy: automated discovery of community structure within organizations. the information society, 21, 14431453.urbas, l., and leuchter, s. (2005). modelbased analysis and design of humanmachine dialogues through displays. kiœzeitschrift für künstliche intelligenz [aijournal for ai], 4551.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.354 humansystem integration in system developmentunited states army. (2000). manprint history. available: http://www.manprint.army.mil/manprint/mphistory.asp. [accessed march 2007].united states department of defense. (1999). department of defense handbook: human engineering program process and procedures. (milhdbk46855a). available: http://hfetag.dtic.mil/docshfs/milhdbk46855a.pdf. [accessed march 2007].united states department of defense. (2003a). department of defense instruction 5000.2: operation of the defense acquisition system. available: http://akss.dau.mil/dag/dod5000.asp?view=document [accessed april 2007].united states department of defense. (2003b). risk management guide for dod acquisition. fort belvoir, va: defense acquisition university press.united states department of health and human services. (2006). researchbased web design and usability guidelines. available: http://www.usability.gov/pdfs/guidelines.html. [accessed march 2007].united states navy. (2005). human performance center, seaprint. available: https://www.spider.hpc.navy.mil/index.cfm?rid=webot1001399 [accessed march 2007].vicente, k.j. (1999). cognitive work analysis: toward safe, productive, and healthy computerbased work. mahwah, nj: erlbaum.vink, p., koningsveld, e.a.p., and molenbroek, j.f. (2006). positive outcomes of participatory ergonomics in terms of greater comfort and higher productivity. applied ergonomics, 37(4), 537546.wampler, j., roth, e., whitaker, r., conrad, k., stilson, m., thomasmeyers, g., and scott, r. (2006). dening a workcentered specication: an approach to integrate cognitive requirements into the software development of complex work systems. presented at the human factors and ergonomics society (hfes) 50th annual meeting, oct. 1620, san francisco, ca.wasson, c. (2000). ethnography in the eld of design. human organization, 59(4), 377388.weick, k.e., and sutcliffe, k.m. (2001). managing the unexpected: assuring high performance in an age of complexity. san francisco: jossey bass.weidenhaupt, k., pohl, k., jarke, m., and haumer, p. (1998). scenarios in system development: current practice. ieee software, 15(2), 3445.white, b.e. (2005). a complementary approach to enterprise systems engineering. presented at the national defense industrial association 8th annual systems engineering conference focusing on mission areas, netcentric operations and supportability of defense systems, oct. 2427, san diego, ca.wickens, c.d., and hollands, j.g. (1999). engineering psychology and human performance (3rd ed.) new york: harpercollins.williams, k.e. (2000). an automated aid for modeling humancomputer interaction. in j.m. schraagen, s.f. chipman, and v.l. shalin (eds.), cognitive task analysis (pp. 165180). mahwah, nj: erlbaum.wilson, j.r., and corlett, e.n. (1998). evaluation of human work: a practical ergonomics methodology. london, england: taylor and francis.winograd, t., and flores, f. (1987). understanding computers and cognition: a new foundation for design. boston: addisonwesley.wittel, a. (2000). ethnography on the move: from eld to internet. forum: qualitative social research, 1(1). available: http://www.qualitativeresearch.net/fqstexte/100/100wittele.pdf [accessed feb. 2007].wixon, d., and ramey, j. (eds.). (1996). field methods casebook for software design. new york: wiley.womack, j.p., and jones, d.t. (1996). lean thinking: banish waste and create wealth in your corporation. new york: simon and schuster.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.references 355woods, d.d. (1993). processtracing methods for the study of cognition outside of the experimental psychology laboratory. in g. klein, j. orasanu, r. calderwood, and c.e. zsambok (eds), decision making in action: models and methods. norwood, nj: ablex.woods, d.d. (2002). steering the reverberations of technology change on elds of practice: laws that govern cognitive work. plenary address in proceedings of the 24th annual meeting of the cognitive science society aug, 1012, fairfax, va. austin, tx: cognitive science society.woods, d.d. (2003). discovering how distributed cognitive systems work. in e. hollnagel (ed.), handbook of cognitive task design (pp. 3753). mahwah, nj: erlbaum.woods, d.d. (2006). resilience engineering: redening the culture of safety and risk management. hfes bulletin, 49(12), 13.woods, d.d., and christoffersen, k. (2002). balancing practicecentered research and design. in m.d. mcneese and m.a. vidulich (eds.), cognitive systems engineering in military aviation environments: avoiding cogminutia fragmentosa. state of the art report (pp. 121134). dayton, oh: human systems information analysis center, wrightpatterson air force base.woods, d.d., and dekker, s. (2000). anticipating the effects of technological change: a new era of dynamics for human factors. theoretical issues in ergonomics science, 1(3), 272282.woods, d.d., and hollnagel, e. (2006). joint cognitive systems: patterns in cognitive systems engineering. boca raton, fl: crc press.wulff, w., evenson, s., and rheinfrank, j. (1990). animating interfaces. in proceedings of the conference on computersupported cooperative work (cscw ™90), oct. 710, los angeles. new york: association for computing machinery press.yang, y., boehm, b., and clark, b. (2006). assessing cots integration risk using cost estimation inputs. in proceedings of the acm/ieee 28th international conference on software engineering (pp. 431438), may 2028, shanghai, china.yin, r.k. (2003). case study research: design and methods (3rd ed.). thousand oaks, ca: sage.young, r.m., green, t.r.g., and simon, t. (1989). programmable user models for predictive evaluation of interface designs. in proceedings of the conference on human factors in computing systems (chi™89) (pp. 1519). new york: association for computing machinery press.zachary, w. (2000). cognet tutorial and overheads. presentation at the third international conference on cognitive modeling (iccm2000), march 2325, groningen, netherlands.zarcone, v.p. (2000). sleep hygiene. in m.h. kryger, t. roth, and w.c. dement (eds.), principles and practices of sleep medicine (3rd ed., pp. 657662). new york: w.b. saunders. humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.appendix asponsors and contributorssponsorsjohn lockett, army research laboratoryed martin, air force research laboratorymaris vikmanis, air force research laboratorycontributorsbritt bray, dynamics research corporationnancy dolan, hsi ofce, u.s. navyrick drawbaugh, u.s. air forcemichael drillings, director of manprint, u.s. armyjonathan earthy, lloyd™s registerjohn hawley, u.s. army research laboratory, human resources and engineering directoraterandall hill, institute for creative technologiesandrew jones, institute for creative technologiestaylor jones, manprint acquisition liaison, u.s. armyalex levis, george mason universityjohn owen, u.s. navybill swartout, institute for creative technologiesharvey weintraub, abbott laboratoriesgreg zacharias, committee on human factors357humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.appendix bbiographical sketches of  committee members and staffrichard w. pew (chair) has been a principal scientist at bbn technologies in cambridge, massachusetts, since 1974 and is currently working parttime there. he has 35 years of experience in human factors, human performance, and experimental psychology as they relate to systems design and development. throughout his career, he has been involved in the development and use of human performance models and in the conduct of experimental and eld studies of human performance in applied settings. before bbn, he spent 11 years on the faculty of the psychology department at the university of michigan, where he was involved in human performance teaching, research, and consulting. the university has recently created a collegiate chair in his name. he was the rst chair of the national research council™s committee on human factors. he has been president of the human factors society and of division 21 of the american psychological association. he has a bachelor™s degree in electrical engineering from cornell university (1956), a master of arts degree in psychology from harvard university (1960), and a ph.d. in psychology with a specialization in engineering psychology from the university of michigan (1963).nigel bevan is an independent usability consultant with wide industrial and research experience. he provides consultancy and training in usability and usercentered design. he was technical coordinator of the eu music (measurement of usability in context), a project that produced methods for usability measurement, which have since been widely applied commercially. he was manager of the inuse and respect projects, which set up a network of usability support centers around europe; the trump project, 358humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.appendix b 359which incorporated usercentered design into the development processes of two large organizations; the prue project, which trialed use of the common industry format for usability test reports; and the usabilitynet project, which established a web site of usability resources. he participates in several international standards groups in which he has introduced the concept of quality in use. he contributed to iso 13407 and the common industry format and edited iso 924111 (guidance on usability), iso/iec 145981 (evaluation of software qualityšgeneral guide), iso/iec 91261 (software product quality model), and iso/iec 91264 (quality in use metrics). he currently edits iso/iec 25030 (quality requirements), iso 202822 (usability of everyday products), and the new common industry format for usability requirements. he has a b.sc. in physics and in psychology from london university, and a ph.d. in manmachine interaction from the council for national academic awards (cnaa).barry w. boehm is trw professor of software engineering and director of the center for software engineering at the university of southern california. between 1989 and 1992, he served in the u.s. department of defense as director of the darpa information science and technology ofce and as director of the ddr&e software and computer technology ofce. his current research interests focus on valuebased software engineering, including a method for integrating a software system™s process models, product models, property models, and success models, called modelbased (system) architecting and software engineering (mbase). his contributions to the eld include the constructive cost model (cocomo), the spiral model of the software process, the theory w (winwin) approach to software management and requirements determination, the foundations for the areas of software risk management and software quality factor analysis, and two advanced software engineering environments: the trw software productivity system and quantum leap environment. he is a member of the national academy of engineering. he has a b.a. from harvard university (1957) and an m.s. (1961) and a ph.d. (1964) from the university of california, los angeles, all in mathematics. he also received an honorary sc.d. in computer science from the university of massachusetts in 2000.kristen a. butler (research assistant) joined the national academies in 2005. she is currently the research assistant for the committee on humansystem design support for changing technology, the committee on human factors, and the committee on organizational modeling from individuals to societies. prior to working at the national research council, she worked as a student coop in the human factors division of the volpe national transportation systems center of the u.s. department of transportation. she has a b.s. in engineering psychology and biomedical engineering from the tufts university school of engineering.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.360 humansystem integration in system developmentnancy j. cooke is professor in the applied psychology unit at arizona state university and is science director and on the board of directors of the cognitive engineering research institute in mesa, arizona. currently, she supervises graduate and undergraduate research in the laboratory for cognitive engineering research on team tasks. her research interests include the study of knowledge and its application to the development of cognitive and knowledge engineering methodologies, as well as to expertise, intelligent tutors, humancomputer interfaces, and team performance. in particular, she specializes in the development, application, and evaluation of methodologies to elicit and assess individual and team cognition. her most recent work includes the development and validation of methods to measure shared knowledge and team situation awareness and research on the impact of cross training, distributed mission environments, and workload on team knowledge, process, and performance. she is editorinchief of human factors. she has a b.a. in psychology from george mason university and m.a. (1983) and ph.d. (1987) degrees in cognitive psychology from new mexico state university.shelley evenson is currently associate professor in the area of interaction design in the school of design at carnegie mellon university. she has worked for more than 25 years in multidisciplinary consulting practices, working closely with users to develop products that are aesthetically pleasing and usable to them. her clients include apple computer, the bank of montreal, diamond technologies, kodak, texas instruments, the williamsburg institute, and xerox. she uses rapid prototyping to iteratively reshape solutions and present them to users for interactive evaluation. these prototypes incorporate business strategy and new technologies and are used to transform the users™ experiences of the product and increase product adoption and loyalty. evenson was cofounder of seespace and chief experience strategist for scient. she served as a board member for the american center for design. her current interests include design languages and strategies, organizational interfaces, design, and the study of what lies beyond usercentered design. she has a b.s. in industrial design from the ohio state university.dave graeber is a human factors engineer at boeing phantom works in seattle. he has a background that has afforded application of human factors skills, techniques, and concepts to a diverse array of projects spanning complex systems design, business development, project management, and bringing technologies to new markets. working within a mix of systems engineering and business development environments, his focus centers on the trade space of system design to support endusers and the pragmatic realities of program management. he has a ph.d. in industrial engineering from the university of central florida.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.appendix b 361edmond w. israelski is a human factors program manager at abbott laboratories in abbott park, illinois. he has worked as a systems engineer, product manager, market researcher, and industrial/organizational psychologist as well as a human factors engineer. he was technical manager of the human factors systems group at lucent technologiesšbell labs, formerly at&t. later he was director of human factors for sbc/ameritech, where his organization supported the design and evaluation of user interfaces for telecommunications products and services. in 2000, he became chief technology ofcer at human factors international, a user interface design and consulting rm. he joined abbott laboratories, a medical device and pharmaceutical company, as program manager of human factors in 2001, where he leads a crossdivision team to embed bestpractice human factors design methods into all of abbott™s products to ensure safety and usability. he is a fellow of the human factors and ergonomics society and cochair of the human factors engineering standards development committee for the association for the advancement of medical instrumentation. he has a b.s. in electrical engineering from the new jersey institute of technology, an m.s. in operations research from columbia university, and a ph.d. in industrial and engineering psychology from the stevens institute of technology.brian m. kleiner is a professor of industrial and systems engineering at virginia polytechnic institute and state university. he also directs the center for innovation in construction safety and health. his research interests focus on sociotechnical systems, health and safety and on the analysis and design of work systems and work system interfaces (macroergonomics). this includes function allocation in automation and system design, training/communication/information system, support system design, design of collaborative and distributed work environments, safety and health, and human reliability and decision making in quality control. he has an m.s. (1983) in human factors concentration and a ph.d. (1990) in industrial engineering (human factors concentration) from the state university of new york at buffalo.anne s. mavor (study director) is the staff director for the committee on human factors and the committee on humansystem design support for changing technology. her previous national research council work has included studies on occupational analysis and the enhancement of human performance, modeling human behavior and command decision making, human factors in air trafc control automation, human factors considerations in tactical display for soldiers, scientic and technological challenges of virtual reality, emerging needs and opportunities for human factors research, and modeling cost and performance for purposes of military enlistment. for the past 35 years, her work has concentrated on human factors, humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.362 humansystem integration in system developmentcognitive psychology, and information system design. she has an m.s. in experimental psychology from purdue university.michael muller is a research scientist in the collaborative user experience group at ibm research in cambridge, massachusetts. his expertise is in participatory design, having codeveloped participatory practices, such as pictive, card, and participatory heuristic evaluation. his current work analyzes knowledge sharing and knowledge management through social software applications in organizations. he has worked in research and practice in usability, usercentered design, and work analysis at microsoft, u.s. west advanced technologies, and bellcore, and serves on ibm™s collaboration invention development team. he has a ph.d. in cognitive psychology from rutgers university.frank e. ritter is associate professor of information sciences and technology, of psychology, and of computer science and engineering at the pennsylvania state university. he has received study fellowships from the air force ofce of scientic research, the european science foundation™s program on learning in humans and machines, and the fulbright commission. he has developed software, tutorials, and methodology for cognitive modeling, particularly with soar and actr, creating models that have tested humanrobot interfaces, sample and real telephones, and complex interfaces. he has published widely in the area of cognitive modeling, articial intelligence, and psychology. he is on the editorial board of human factors, aisb journal, and aisb quarterly, and is the editor for oxford university press™ series on cognitive models and architectures. he has a b.s.e.e. (with honors) from the university of illinois at urbanachampaign as well as an m.s. in psychology and a ph.d. in articial intelligence and psychology from carnegie mellon university.emilie roth is president of roth cognitive engineering. her work has involved analysis of human problem solving and decision making in realworld environments (e.g., military command and control, intelligence analysis, monitoring and control of internet networks, nuclear power plant operations, railroad operations, surgery), and the impact of support systems (e.g., computerized procedures, alarm systems, advanced graphical displays, new forms of automation) on performance. she has conducted empirical studies of naturalistic decision making, developed and applied cognitive task analysis and cognitive work analysis techniques for understanding the cognitive demands imposed by work environments, and developed principles for effective decision support for individuals and teams. she has served as part of multidisciplinary design teams developing rstofakind systems, including design and manning of the command center for a nextgeneration humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.appendix b 363navy ship, design of a nextgeneration nuclear power plant control room, and design of workcentered support systems for ˚ight planning and monitoring for an air force organization. she is currently serving as editor of the design of complex and joint cognitive systems track of the journal of cognitive engineering and decision making. she has a ph.d. in cognitive psychology from the university of illinois at urbanachampaign.thomas f. sanquist is a research scientist with the pacic northwest laboratory in seattle. his research focuses on the use of analytic and eld research methods for designing and evaluating user interfaces for complex systems. application areas include intelligence analysis, security systems, transportation, imaging devices, satellite control systems, nuclear power plants, and military command and control. he has experience in both the research and practice of human factors engineering, having designed and implemented signicant largescale systems such as the air force satellite control network user interface and seaport radiation portal monitoring for customs and border protection. he has a b.a. from the university of michigan (1974) and a ph.d. in cognitive and physiological psychology from the university of california, los angeles (1980).humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.indexaabstraction hierarchies, 198accidents bhopal, 328 chernobyl, 1 in largescale systems, 1 at power plants, 198 three mile island, 1, 256, 328 by vincennes, 328acr. see architecture commitment reviewactr model, 167, 244, 321active risk management, 311activity view, concurrent levels of, 41œ44acwa. see applied cognitive work analysis methodadaptability, 6, 26adjustable methods, 24advanced spectroscopic portals (asps), 105advocacy. see also nonadvocate technical experts for consideration of hsi, 15afnity analysis, 175afghanistan, current needs in, 93afqt. see armed forces qualication testaggregation, of features, 26agile methods, 35, 37air force falconer air operations center, 16air force research laboratory, 2air trafc control systems, 13, 21airprint, 296alarms, with melodies, 111œ112alarp. see as low as reasonably practicablealertness level, 227œ228ambiguity, 63american anthropology association,  154n. 1anchor point milestone reviews, 23, 25, 37, 44 development commitment, 44œ46anthropometric models, 244applied cognitive work analysis (acwa) method, 62applied physics lab, 144applied psychology research unit, 10aptima, inc., 162archetypes, composite user, 65architecting phase, 3 and design, 247 pointsolution, 33architectural prototypes, 236architecture commitment review (acr), 44 procedures, 46architectures, backend, 238armed forces aptitude test battery (asvab), 19œ20365humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.366 humansystem integration in system developmentarmed forces qualication test (afqt), 19army comanche helicopter program, 13army human engineering directorate, 19army research laboratory, 2artifact models, 50, 176, 280as low as reasonably practicable (alarp), 259asps. see advanced spectroscopic portalsassessment of hsi of contributors to system adaptability and resilience, 330 of risks, 327œ329asvab. see armed forces aptitude test batteryasynchronous communication patterns, 147atm machine withdrawals, 197 hierarchical task analysis of, 158œ159, 161at&t architecture review board procedures, 46attention management, 207, 318automated methods, based on rules and guidelines, 272automatic external debrillator, example fta for a hypothetical, 263automation, 11bbackend architectures, 238baselines, generating, 278œ279bduf. see big design up front activitiesbeast. see boeing engineering aerospace simulation tool programbehavioral patterns, 186bell laboratories, 10besteffort denitions, 49best practices for hsi, 57 for risk mitigation, 67œ74 tables of, 44bhopal accident, 328ﬁbifocal tools,ﬂ 212big design up front (bduf) activities, 39ﬁblogs,ﬂ 22, 289œ290, 292ﬁbobbyﬂ tool, 245, 272boeing engineering aerospace simulation tool (beast) program, 146bootstrap process, 165œ166borg ratings of perceived exertion, 220budget constraints, 23 tailoring methods to, 24business case, 77 viability of, 4business week, 1ccaiv. see cost as an independent variablecameras, reconceptualizing, 65ﬁcardboard computers,ﬂ 172, 212œ213case studies, 91œ125 ﬁnextgenerationﬂ intravenous infusion pump, 105œ125 port security, 97œ105 unmanned aerial systems, 92œ97cassette loading, semiautomatic, 112œ113causeeffect relationships, 50cbp. see customs and border protectioncdm. see critical decision methodcentralization, 145change. see also rapid change in conditions and requirements in the workplace, designing to accommodate, 26, 300œ301chaos report, 191chernobyl accident, 1child safety, concerns about, 10choke points, identifying, 103, 202circadian rhythm, 227cmap tools software suite, 315cognet/igen model, 244cognitive task analysis (cta), 161œ169 a bootstrap process, 165œ166 contributions to system design phases, 167 overview, 161œ166 relationship to task analysis, 165 representative methods, 162œ165 shared representations, 166œ167 strengths, limitations, and gaps, 168œ169 in the unmanned aerial systems case study, 166 uses of methods, 167cognitive walkthroughs, 272cognitive work analysis methodology, 199 analytic tools involved in, 202humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 367collaborationatadistance, 289collaboration failures, 5collaborationintensive systems, 4, 25color touch screens, large, 111colors, stoplight, 83command and control (c2), 286œ287, 300command and control vehicles, 12committee on human factors, 2committee on humansystem design support for changing technology, 2 charge and scope of, 16œ17 report organization, 27œ28common ground, 61common industry specication for usability requirements, 194œ195, 267communication. see also shared representations for communication among members of the development team, 195 creating shared representations for, 25 between customers and suppliers, 195 of risk, improving, 329œ330compatibility, evidence of, 45complexity of systems, 1, 144œ145, 308composite stories, 231composite user archetypes, 65computational tools, paucity of, 206computer simulations, 25, 106, 240, 267concept mapping, 163 of the role of cold fronts in the gulf coast, 164concurrent engineering process models, 34, 37, 48, 51concurrent systems, denition and development, 32, 105conditions, accommodation to changing, 101œ102consensus building, 2n. 1consequence levels, assessing, 82œ83consumer product safety commission, 10context of use analysis methods, 136œ138 cognitive task analysis, 161œ169 contextual inquiry, 175œ177 dening opportunities and, 55, 129, 135œ188, 279œ280 event data analysis, 177œ188 eld observations and ethnography, 150œ157 organizational and environmental context, 139œ150 participatory analysis, 169œ175 task analysis, 157œ161contexts, 18œ22 military sector, 18œ20 private sector, 20œ22 of use, 138contextual design, 216œ217 contributions to the system design process, 217 shared representations, 217 strengths, limitations, and gaps, 217contextual inquiries, 114œ115, 149, 175œ177 afnity analysis, 175 contributions to the system design process, 139, 177 interpretation, 175 overview, 175œ176 shared representations, 176 strengths, limitations, and gaps, 177control, of information, 22control rooms, 157 for power plants, 139cornell musculoskeletal discomfort survey, 219cost as an independent variable (caiv), 76costcompetitive contracts, 33costeffective systems, 23costs, providing a basis for controlling, 195cougaar, 311crisis response systems, 15critical decision method (cdm), 162critical success factor (csf) aspects of top ve software projects, 52cta. see cognitive task analysiscultural analysis, 147œ148cultural models, 144, 176, 251œ252currentpointintime shapshot requirements, 33customer observations, negative, 13œ14, 112œ113customs and border protection (cbp), 98, 104ddomar model, 245dart, 311humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.368 humansystem integration in system developmentdata analysis, 183œ184 collection, 6, 183, 187, 319 mining, 178, 318œ319 privacy of, 319 rate of change of, 22 representation, 184datareduction methods, 178datech, 271dcr. see development commitment reviewdecentralization, of information, 22decompositions goal/task, 279œ280 hierarchical, 283defense advanced research projects agency, 311defense systems, 24debrillators, automatic external, 263dening requirements and design, 56, 129, 189œ252 contextual design, 216œ217 methods for mitigating fatigue, 226œ229 models and simulations, 240œ252 participatory design, 210œ216 personas, 233œ235 physical ergonomics, 217œ223 prototyping, 235œ239 scenarios, 230œ233 situation awareness, 223œ226 usability requirements, 191œ197 work domain analysis, 197œ207 workload assessment, 207œ210delphi group decisionmaking technique, 262descriptive methods, in ethnography, 151design as an innovative process, 189 as a socially constructed process, 61design cycle time, pressure to reduce, 12design issues decisions, 109 meaning, 63 and methods used, 124œ125 opportunities and constraints, 5 solutions, 56, 280œ281design team members, 11development commitment review (dcr), 44, 47, 49 procedures, 46development phase, 3 risk of destabilizing, 50dhs. see u.s. department of homeland securitydiagrams, 25differentiation, 144œ145digital human physical simulations, 243œ244disuse, operational stage risk of, 59diversity, managing, 152documentaries, multimedia, 173dod. see u.s. department of defensedomain knowledge, repository of, 206drawing workshops, 171œ172dutch musculoskeletal survey, 219eecommerce web sites, 255ease of use, 249œ250eclipse process framework openup, 302ecr. see exploration commitment revieweda. see event data analysiseducation of hsi specialists.  see also humansystem integration, developing as a discipline opportunities for, 14electronic models, 25electronic systems center, 16emergency care research institute, 110emergency medical missions, 15emergent behavior, 15, 53emergent requirements, 33emotional models, 251œ252encyclopedias. see also wikipedia online, userconstructed, 22endstate operational system risks, 57energy systems, 255engineering development risk, management of, 59enterprise resource planning (erp) package, 39environmental context, 5, 17, 139œ150 contributions to system design phases, 149 methods and respective sources of data, 141 overview, 139œ141 shared representations, 141œ144 strengths, limitations, and gaps, 149 uses of methods, 144œ149humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 369ﬁenvisioned worldﬂ problem, 163œ164epic model, 245, 321ﬁepistemic status,ﬂ 231erp. see enterprise resource planning packageerrors operational stage risk of, 59 taxonomies of, 328esda. see exploratory sequential data analysisethical considerations, 6, 316œ320ethnographic inquiry, 231 contributions to the system design process, 154œ156 interviews, 153 methods, 213 observations, 153œ154 practices, 152œ154 principles, 150œ152 shared representations, 155 strengths, limitations, and gaps, 155œ157european union, 319evaluation, 56, 247œ248, 281œ282 heuristic, 271œ272 of remaining plan activities, 90 of success accomplishments, 90 systemlevel, 14event data analysis (eda), 5, 95, 177œ188 contributions to system design phases, 185œ186 ethical implications, 316œ320 examples of uses of, 180œ181 overview, 177œ178 shared representations, 178œ179 uses of methods, 180œ185event trees, 260evolutionary system growth, 51evolvability, designing for, 26excel spreadsheets, 321expert cocomo/cocots, 311exploration commitment review (ecr), 46œ47exploration phase, 3, 246œ247exploratory sequential data analysis (esda), 184ffailure modes, effects, and criticality analysis (fmeca), 259n.1failure modes and effects analyses (fmea), 115, 124, 159, 253, 259n. 1, 260 advantages and disadvantages of, 264 of symbiqž iv pump, 119œ121failures. see collaboration failures; humansystem failures; product failures; system failuresfallback plans, identication of, 89fault tree analysis (fta), 253 advantages and disadvantages of, 265 and other technique variations, 260œ262 steps in performing, 264fda. see food and drug administrationfeasibility evidence of, 45 rationale for, 50feature needs large color touch screens, 111 medication libraries with hard and soft dosage limits, 110œ111 semiautomatic cassette loading, 112œ113 special alarms with melodies, 111œ112 special pole mounting hardware, 113 stacking requirements, 113œ114 and their rationales, 110œ114 tubing management, 114ﬁfeedreaders,ﬂ 289ﬁfield modication,ﬂ 28field observations, 5, 123, 150œ157 ethnographic practices, 152œ154 ethnographic principles, 150œ152fitts™s law, 321flashž animations, 119, 119n.1flow models, 176fmea. see failure modes and effects analyses steps in performing, 261fmeca. see failure modes, effects, and criticality analysisfocus groups, 122ﬁfolksonomies,ﬂ 22, 290food and drug administration (fda), 110, 113formalization, 145formative evaluation, uses of methods in, 267œ268fta. see fault tree analysisfullscale warfare, 15function allocation, 131humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.370 humansystem integration in system developmentfunders of research, lack of commitment to hsi by, 2, 5the future, 7, 275œ330 conclusions and recommendations, 296œ330 scenarios for, 277œ295futurevision stories, 232future workshops, 171futures table, 144ggantt charts, 209, 279œ281global context, 16goal/task decompositions, 279œ280goms (goals, operators, methods, and selection rules) method, 167, 242œ243, 249œ250, 281, 321google, 178government organizations, 4œ5graphic user interface (gui) simulations, 119 interactive builder, 32œ33grounded theory, 152œ153group narratives, 183 ﬁthinking with,ﬂ 63groupware support systems, 38guidelines, 271hhabitability, in the military sector, 1handoff functions, 94handbook of systems engineering and management, 34hardware models, with integrated usability tests, 119œ120harms, dening, 257health hazards. see also safety and health considerations in the military sector, 18heuristic evaluation, 271œ272hierarchical task analysis (hta), 157œ158 formalism of, 166 graphic representation of, 159hierarchies abstraction, 198 decomposing, 283 deep supplier, 50high assurance, incremental development for accommodating, 49œ51highlevel languages, 251holistic methods, 16 in ethnography, 151 of measuring risk, 83home media systems, 13hospira customer service organization, 110hospital systems, 12hsi. see humansystem integrationhta. see hierarchical task analysishuman capabilities and needs, considering early, 1human cognitive characteristics, 2humancomputer interaction, 10human digital modeling, 221, 223human error analysis, 255œ265 contributions to system design phases, 262 general model of, for security screening, 100 identication of hazards, 257œ259 shared representations, 259œ262 strengths, limitations, and gaps, 262œ265human factors analysis of, 295 events in the growth of, 10 introducing early enough, 14 professionals in, 59human factors and ergonomics society, 10, 125, 313human factors engineering, 1, 11 in the military sector, 18humanintheloop evaluations/simulations, 87, 209, 232, 240œ241, 265humanintensive systems, future of, 3humansystem domain experts, 2humansystem engineering, 2humansystem failures, 13humansystem integration (hsi), 2, 4, 9, 31 accommodating the emergence of requirements, 303 activities, participants, methods, and shared representation, 130 beginning early and continuing throughout the development life cycle, 297humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 371 developing as a discipline, 7, 284œ286, 312œ313 modeling, 99 operational requirements in contracts and acquisition documents, 303œ304 risks, 57 sizing the effort, 309œ310 system development led by, 282œ284 for uass in the context of the riskdriven spiral, 96œ97humansystem integration (hsi) in the context of riskdriven incremental commitments, 98œ103 accommodation to changing conditions and workplace requirements, 101œ102 hsi methods tailored to time and budget constraints, 99œ100 scalable methods, 102œ103 shared representations used to communicate, 100œ101humansystem integration (hsi) in the incremental commitment model, 57œ60, 94œ96humansystem integration (hsi) in the system development process, 55œ74, 127œ274 best practices for risk mitigation, 67œ74 case studies, 91œ125 conclusion, 66 dening opportunities and context of use, 55, 129, 135œ188 dening requirements and design, 56, 129, 189œ252 evaluating, 56 function allocation, 131 managing risks, 75œ90 methods for evaluation, 129, 253œ274 performance measurement, 131œ133 shared representations, 61œ66 the system development process, 31œ54humansystem integration methods tailored to time and budget constraints, 99œ100humansystem model development, 320œ322iibm/rational unied process, 302icm. see incremental commitment modelidentication of fallback plans, 89 of hazards and when risk management is conducted, 257œ259 of hsi contributors to system adaptability and resilience, 330 of risks, 78œ84, 327œ329iec. see international electrotechnical commissionimprint (improved performance research and integration tool), 19, 241, 249œ250, 321incremental commitment model (icm), 9, 23, 31, 36œ51 for accommodating rapid change and high assurance, 49œ51 activity categories and level of effort, 41 anchor point milestone feasibility rationale, 46 concurrent levels of activity view, 41œ44 development commitment anchor point milestone review, 44œ46 different risks creating different processes, 40 lifecycle process elaboration, 36, 45 milestone reviews, 37, 46œ47 phases of, 44 principles, 33 process model generator view, 39œ40 project experience with, 50œ53 spiral view of, 47œ49 top5 projects explicitly using, 51, 51n. 1incremental growth, of system denition and stakeholder commitment, 32, 103œ104individual stories, 231information, sharing across domains, 7input/output system diagrams, 142institute for human and machine cognition, 315institute for safe medical practices, 110institutionalization, of a system development process based on the success factors, 302insurgency suppression missions, 15integrated product team (ipt), 80œ81, 283, 286œ287, 298 structuring hsiled system development, 284humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.372 humansystem integration in system developmentintegrated usability tests, integrated hardware and software models with, 119œ120integration of human systems and systems engineering, 27, 145, 250œ251, 278œ286, 298, 301œ314 accommodating the emergence of hsi requirements, 303 dening opportunities and requirements and dening the context of use, 279œ280 design solutions, 280œ281 developing hsi as a discipline, 284œ286, 312œ313 evaluation, 281œ282 fostering more synergy between research and practice, 314 generating a baseline, 278œ279 hsiled system development, 282œ284 humans in the design process, 1 institutionalizing a system development process based on the success factors, 302 knowledgebased planning aids for hsi, 310œ312 managing system development, 6, 305 meaning of, 282 operational requirements in contracts and acquisition documents, 303œ304 shared representations, 307œ308 sizing the hsi effort, 309œ310 systems of systems, 308œ309 traceability and requirements, 305œ307interconnectedness and interdependency, 26international council on systems engineering, 313international electrotechnical commission (iec), 112international ergonomics association, 217n. 2, 313international journal of humancomputer studies, 131international journal of human system integration, 313international organization for standardization. see iso standardsinternet, the. see also web 2.0 in˚uence on culture, 154interpretation, 175, 231interviews, 153ipt. see integrated product teamiraq, current needs in, 93iso standards, 4, 115, 302 iso 924111, 192, 268, 271 iso/iec 15288, 196, 310 iso/iec 91261, 191 iso/pas 18152, 44, 57, 311 iso/tr 18529, 310iteration, 48, 60 system denition and development, 32 system growth, 51 usability tests, 122iv pumps tube management features, 107 two channel, 107jjsaf model, 244kkeystrokelevel analysis, 13, 186, 249knowledge acquisition techniques, 161knowledgebased planning for hsi, 286œ287, 310œ312 tools for, 7llabor savings, 14laboratory studies, 153lag sequential analysis, 184largescale systems. see systems of systemslca. see lifecycle architecture packagelead systems integrator (lsi), 15lean development process, 51lean methods, 37libraries. see medication librarieslibrarything, 290lifecycle architecture (lca) development phases, 3 of the icm and eda, 185 operational stage risk of high costs, 59 package, 44, 50 planning, 124lift tool, 272likelihood levels, assessing, 82œ83limitations, 249œ252 of cultural, team, and emotional models, 251œ252 ease of use, 249œ250humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 373 of highlevel languages, 251 of integration, 250œ251limited warfare, 15link trainer, 240linkage of system engineering principles to hsi activities that reduce risks, 58lmm. see lumbar motion monitorlogistics planning tools, 311loselose situation, 38lowtechnology representations, 172œ173, 212, 212n. 1, 213lsi. see lead systems integratorlumbar motion monitor (lmm), 221mmacromedia flash player, 119n. 1manpower, personnel, and training (mpt) domains, 18manpower considerations, 1, 5, 11 in the military sector, 18œ19manprint (manpower personnel integration) program, 10, 17, 24, 296, 298, 307œ308manufacturing sector, 17, 21maps, territory, 64market capture goals, 4marketing requirement document, 110markov modeling, 184ﬁmashupﬂ technologies, 26, 289, 291matrix organization, 146maximizing the costeffectiveness of usability evaluation, 326œ327medical equipment possible harms and hazards from the use of, 258 standards for, 114 use of an automatic external debrillator, 258 use of an automatic needle injection device, 258medical research council laboratory, 10medication libraries, with hard and soft dosage limits, 110œ111mental workload, 207œ208metadesign approaches, 293method acting, 234methods. see also types of methods; uses of methods application instrumentation, 270 for assessing discomfort, 219 for assessing injury risk, 221 for assessing posture, 220 based on models and simulation, 270 collecting data from usage of an existing system, 270 issues and research needs, 116œ117 satisfaction surveys, 270 tailoring to time and budget constraints, 24, 299 types of, 6, 268œ272 uses of, 266œ272 web metrics, 270methods and shared representations, 211œ214 ethnographic methods, 213 lowtechnology representations, 212œ213 scenarios, 211 theatrical approaches, 213 workshop methods, 213œ214methods based on expert assessment of the characteristics of a system, 271œ272 cognitive walkthrough, 272 guidelines and style guides, 271 heuristic evaluation, 271œ272 usability walkthrough, 272methods based on observing users of a real or simulated system, 268œ270 formative methods, 268 summative methods, 268œ269methods for dening opportunities and context of use, 314œ320 tools to support capture and dissemination of results of context of use analyses, 315œ316 user participation in systems engineering and event data analysis and their ethical implications, 316œ320methods for dening requirements and design, 320œ324 humansystem model development, 320œ322 prototyping training and organizational design, 322œ324methods for evaluation, 129, 253œ274, 324œ330 analysis of human error, 256œ265 identifying and assessing hsi contributors to system adaptability and resilience, 330humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.374 humansystem integration in system development identifying and assessing hsi risks, 327œ329 improving the communication of risk, 329œ330 improving the use of usability objectives, 324œ326 maximizing the costeffectiveness of usability evaluation, 326œ327 risk analysis, 253œ256 usability methods, 265œ274methods for mitigating fatigue, 226œ229 assessment, 220œ221 contributions to system design phases, 229 overview, 226œ227 shared representations, 228 strengths, limitations, and gaps, 229 uses of, 227œ228microsaintbased models, 321microergonomics interventions, 140microsoft ofce, 270milestone b commitment, 39military sector context, 10, 12, 18œ20. see also command and control habitability and survivability in, 1 manpower, 19 personnel, 19œ20 training, 20missioncritical subsystems, 34mitigation efforts, ﬁoff the books,ﬂ 89mitre corp., 162, 311models, 3, 5, 7, 25, 240œ252. see also artifact models; cultural models; emotional models; flow models; hardware models; human digital modeling; humansystem model development; incremental commitment model; network models; physical models; sequence models; software models; team models contributions to system design phases, 246œ248 derived from human cognitive operations, 242œ243 overview, 240 strengths, limitations, and gaps, 248œ252 that mimic human cognitive and perceptualmotor behavior, 244œ246 types and uses of, 240œ246modsaf model, 244motivation behind the design, 106mpt. see manpower, personnel, and training domainsmultidimensional scaling, 184multimedia documentaries, 173multiple systems. see systems of systemsmultitasking, 207muscle fatigue assessment method, 220nnapping, strategic, 227nasa. see national aeronautics and space administrationnational academies committee on human factors, 2 study on organizational models, 252national aeronautics and space administration (nasa), 60n. 1 near earth asteroid rendezvous project, 144 tlx scales, 208national aerospace system, 241national institutes for occupational safety and health (niosh), 219œ220national science foundation, 313national transportation safety administration, 10naval postgraduate school, 285, 312navy tactical decision support systems, 13near earth asteroid rendezvous (near) project, 144negative business outcomes. see also customer observations resulting from hsi faults, 259negotiation facilitating, 64 terms oriented to, 34nested techniques, 144network management, 21network models, of humansystem performance, 241œ242new technologies, 26 feasibility of inserting, 4 governmental and commercial uses of, 22ﬁnextgenerationﬂ intravenous infusion pump, 105œ125 motivation behind the design, 106humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 375 summary of design issues and methods used, 124œ125 usercentered design process in the icm context, 106œ124niosh. see national institutes for occupational safety and healthnonadvocate technical experts, 79nordic musculoskeletal questionnaire, 219norman, don, 62œ63north atlantic treaty organization, 313nuclear power plants, 21 work domain representation for a pressurized water reactor, 200nuclear regulatory commission, 262nynex science and technology organization, 13oobservations, 153œ154. see also customer observationsobserverparticipant approach, 153occupational safety and health administration (osha), 10occupational repetitive action (ocra) methods, 221ocr. see operations commitment reviewocra. see occupational repetitive action methodsoperation of the defense acquisition system, 2, 4œ5, 14operational requirements, of hsi, 4operational return on investment, 31operational stage, 3, 248operational stage risks, 59 useerrorinduced, 92operations commitment review (ocr), 47operator fatigue, 226opportunitydriven approach, to determining needs for hsi activity, adopting, 298ﬁoptinﬂ and ﬁoptoutﬂ approaches, 320, 320n. 1optimization schemes, 140options assessment assuming the risk, 87 avoiding the risk, 85œ86 handling, 85 mitigating the risks, 87œ88 transferring the risk, 86ordinal values, 82organization charts, 141œ142organizational context, 5, 139œ150 contributions to system design phases, 149 methods and respective sources of data, 141 overview, 139œ141 shared representations, 141œ144 strengths, limitations, and gaps, 149 uses of methods, 144œ149organizational design example of, 146 modeling approaches, 308organizational system scan, 144œ147organizational variances, table of, 142osha. see occupational safety and health administrationovako working posture analysis, 220ﬁovercondenceﬂ bias, 12ppagerank algorithms, 178n. 2paper prototypes, 119parameter estimation, 13parttask simulations, 249participatory analysis, 5, 95, 169œ175, 210œ216, 230 contributions to the system design process, 173, 214 tting into the system development process, 174 methods, 211œ214 overview, 169œ173, 210œ211 scenarios in, 172 shared representations, 173œ174, 211œ215 strengths, limitations, and gaps, 174œ175, 215œ216 workshops in, 170œ172participatory workshops, 170œ172 drawing and other visual workshops, 171œ172 future workshops, 171 lowtechnology representations, 172œ173 multimedia documentaries, 173 strategic design workshops, 171pass/fail reviews, 14humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.376 humansystem integration in system developmentpathnder network scaling, 179, 179n. 3, 184pattern recognition, 318pdr. see product requirements documentperformance measurement, 131œ133personas, 233œ235, 279 contributions to the system design process, 234 shared representations, 233œ234 strengths, limitations, and gaps, 234œ235personnel considerations, 1, 5, 11 backup, 12 in the military sector, 18œ20ﬁpersonnel subsystems,ﬂ 10pert charts, 209œ210photo documentaries, 172physical ergonomics, 5, 217, 217n. 2, 218œ223 assessing, 207 contributions to system design phases, 222 overview, 217œ218 shared representations, 218œ219 strengths, limitations, and gaps, 222œ223 uses of methods, 219œ221physical models, 25, 176physical performance characteristics, 2physical prototypes, foam model of a blood analyzer prototype, 237physical simulations, digital human, 243œ244plibel, 219pointsolution architecture, 33pole mounting hardware, 113policy recommendations, 4, 301œ330 methods for dening opportunities and context of use, 314œ320 methods for dening requirements and design, 320œ324 methods for evaluation, 324œ330 realizing the full integration of human systems and systems engineering, 301œ314polyvinyl toluene sensors, 105port security, 97œ105. see also radiation portal monitoring (rpm) systems hsi in the context of riskdriven incremental commitments, 98œ103 principles of system development in, 103œ105 use of work domain analysis in, 202power plants. see also nuclear power plants accidents at, 198 control rooms, 139, 204ﬁpracticumﬂ environment, 286preventive action, 124price systems, 311principlesbased comparison, of alternative process models, 34œ36prioritized capabilities, specifying, 34prioritized risks, 84privacy of data, 319 options in, 320private sector context, 4œ5, 12, 20œ22process control, 17, 21process model generator view, 39œ40process tracing, 183product design methodologies, 2product failures, reducing risk of, 195product introduction, 124product requirements document (pdr), 119, 121product usability characteristics evaluation methods, 271œ272 automated methods based on rules and guidelines, 272 methods based on expert assessment of the characteristics of a system, 271œ272product variation, 145program award fee criteria, 4program impacts, assessing, 83œ84program management risks, 57program managers, lack of commitment to hsi by, 2program schedules, 89œ90progress monitoring, 14project ernestine, 243protocols analysis of, 182 rss, 289 thinkaloud, 225prototypes, 3, 5œ6, 25, 119, 235œ239, 267, 324 architectural, 236 contributions to system design phases, 238humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 377 overview, 235œ236 paper, 119 rapid, 22 shared representations, 236œ237 strengths, limitations, and gaps, 238œ239 ﬁthrowaway,ﬂ 212 training and organizational design, 322œ324 uses of methods, 236qﬁqualitative and quantitative personnel requirements inventory,ﬂ 10ﬁquality in use,ﬂ evaluation of, 265quick exposure checklist, 220quick look reports, 60, 60n. 1rradiation portal monitoring (rpm) systems, 98œ99, 202 largescale, 97rapid change, 33 incremental development for accommodating, 49œ51ratio values, 82rational unied process (rup), 37, 41, 51r&d. see research and developmentreal options theory, 38reason™s error classication, 257rebaselining, 32recommendations, 2, 4, 296œ330 adopting a risk and opportunitydriven approach to determining needs for hsi activity, 298 beginning hsi contributions to development early and continuing them throughout the development life cycle, 297 designing to accommodate changing conditions and requirements in the workplace, 300œ301 ensuring communication among stakeholders of hsi outputs, 299 integrating across humansystem domains as well as across the system life cycle, 298 tailoring methods to time and budget constraints, 299recording language, standard, 64recording technologies, 153reductions assessing achievement of, 90 in the development effort, 195relationships, causeeffect, 50reliability, 12remotely piloted vehicles (rpvs), 92reports, 25representations. see diagrams; lowtechnology representations; models; prototypes; reports; shared representations; simulations; spreadsheets; stories; storyboards; time linesrepresentative methods, 162œ165 for dening opportunities and context of use, 137 for dening requirements and design, 190 for evaluation, 254requirements analysis of, 4, 304 classication of, 192 ﬁcreepﬂ of, 294 specication of, 195 specication of inappropriate, 3research agenda, 3, 5œ7 full integration of human systems and systems engineering, 6œ7 methods and tools, 5œ6 preliminary, 108œ109 shared representations, 5research and development (r&d), 86 support for, 13research recommendations, 301œ330 methods for dening opportunities and context of use, 314œ320 methods for dening requirements and design, 320œ324 methods for evaluation, 324œ330 realizing the full integration of human systems and systems engineering, 301œ314residual risk, 259resilience, 6, 14, 309, 328, 330resources failure to assign, 14, 24 suboptimal, 84, 145reusable components, 7, 33risk assuming, 87humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.378 humansystem integration in system development avoiding, 85œ86 identication of, 78œ81 prioritizing, 84 residual, 259 transferring, 86@risk, 311risk analysis, 5, 78œ84, 253œ256 assess likelihood and consequence levels, 82œ83 assessing program impacts, 83œ84 dening use error, 255œ256 determining level of, 83 determining method of, 82 overview, 253œ256 revised, 124 steps in, 82riskdriven icm approach, 51 for accommodating rapid change and high assurance, 49 adopting, 23œ24 to determine needs for hsi activity, adopting, 298riskhandling options, decision ˚ow of, 85risk management, 48, 75œ90, 104œ105 ecommerce web sites, 255 early, 115œ119 energy systems, 255 executing risk mitigation, 88œ90 handling options assessment, 85 identication of hazards when conducting, 257œ259 riskdriven activity levels and anchor point milestones, 32œ33 techniques for, 255 transportation systems, 255 weapons systems, 255risk mitigation, 87œ88 best practices for, 67œ74 developing a plan, 88œ89 evaluating plan activities, 90 evaluating success accomplishments, 90 executing, 88œ90 identifying fallback plans, 89 incorporating into program schedules, 89œ90 progressive, 23 steps in, 88risk of product failure, reducing, 195risk priority number (rpn) values, 115, 119robust systems, 198role networks, 142œ144 for nasa™s near earth asteroid rendezvous project, 144role variances, examples of, 150root concept, 231rpm. see radiation portal monitoring systemsrpn. see risk priority number valuesrpvs. see remotely piloted vehiclesrss protocol, 289rules and guidelines, automated methods based on, 272rup. see rational unied processssafety and health considerations, 1, 11safetycase submittals, 168safetycritical systems, 24, 34, 252sample size formula, 327satisfaction surveys, 270satiscing, 283. see also stakeholders dening, 2n. 1ﬁsaydomakeﬂ approach, 214scalable methods, 24, 102œ103 multidimensional, 184scenarios, 7, 211, 230œ233, 280 contributions to system design phases, 232 overview, 230 in participatory analysis, 172 shared representations, 231œ232 strengths, limitations, and gaps, 233 uses of methods, 230œ231scenarios for the future, 277œ295 integrated methodology, 278œ286 knowledgebased planning for hsi, 286œ287 user participation, 288œ295schematic representations, for a compact power plant control room, 204screening. see security screeningseaports. see radiation portal monitoring (rpm) systemsseaprint (systems engineering, acquisition, and personnel integration), 18, 296search and rescue missions, 15second round prototypes, for interface to mri device, 237humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 379security screening in complex labor situations, 104 general model of human error analysis for, 100 likely tightening of, 22seer/sem, 311selfreport instruments, 218œ219sensors, polyvinyl toluene, 105sequence models, 157œ159, 176service industries, 17serviceoriented architectures (soas), 22, 289œ290shared language, 63shared representations, 141œ144, 155, 159œ160, 166œ167, 173œ179, 194œ195, 201, 209, 215œ219, 228, 231œ237, 259œ262, 273, 307œ308 artifact model, 176 attributes of good, 63œ64 composite stories, 231 cultural model, 176 cultural prole, 144 for dening requirements and design, 190 in the design process, 64œ66 for evaluation, 254 ˚ow model, 176 and fmea, 259œ260 and fta, 260œ262 futurevision stories, 232 futures table, 144 individual stories, 231 input/output system diagram, 142 organization charts, 141œ142 physical model, 176 providing a basis for controlling costs, 195 reducing risk of product failure, 195 reducing the development effort, 195 and role networks, 142œ144 sequence model, 176 for specication of requirements, 195 table of organizational variances, 142 tracking evolving requirements by providing a format to document usability requirements, 195 usefulness of, 62œ63shared representations for communication, 5, 100œ101 among members of the development team, 195 of concepts to engineering staff, 100 creating, 25 between customers and suppliers, 195 of hsi issues and opportunities, 61œ66signal detection theory, 242, 321simulations, 3, 5, 7, 25, 240œ252 contributions to system design phases, 246œ248 overview, 240 parttask, 249 strengths, limitations, and gaps, 248œ252 types and uses of, 240œ246singleuser systems, 21situation awareness, 11, 139, 223œ226 contributions to system design phases, 225 measuring, 224œ225 overview, 223œ224 strengths, limitations, and gaps, 225œ226situation awareness global assessment technique, 224situation awareness rating technique, 225soas. see serviceoriented architecturessocial network analysis, 185ﬁsocial softwareﬂ services, 22, 289ﬁsocial tagging,ﬂ 22socially constructed processes, design as, 61, 63sociotechnical systems approach, 141, 148œ149software models, with integrated usability tests, 119œ120software technology risk advisor, 311ﬁsourcing,ﬂ of information, 22space program, 248. see also national aeronautics and space administrationspecial causes, 141spimes, 294spiral models, 34, 37, 39, 47œ49 development of, 35 simplied view of the icm, 48 winwin, 51spreadsheets, 5, 25stacking requirements, 113œ114ﬁstaged worldﬂ techniques, 163œ164stakeholders, 2, 5, 11 analyzing, 148œ149 concurrence of, 40 con˚icting requirements of, 15humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.380 humansystem integration in system development of hsi outputs, ensuring communication among, 299 satiscing, 31œ32, 48, 283 successcritical, 38, 103 usercentered activities for, 196standard recording language, 64standardized interface, 22standish group, 191stories, 5, 25, 183storyboards, 7, 280straddle carriers, 102strategic design workshops, 171style guides, 271subjectivity issues, 219suboptimal resources. see resourcessuccesscritical stakeholder satiscing, 103successful system development concurrent system denition and development, 32 incremental growth of system denition and stakeholder commitment, 32 iterative system denition and development, 32 principles for, 2œ3, 32œ33 riskdriven activity levels and anchor point milestones, 32œ33 stakeholder satiscing, 32summative methods, 267œ270supplier hierarchies, deep, 50survivability, 11 in the military sector, 1, 18ﬁsweeps,ﬂ 162symbiqž iv pump, 105œ107, 114œ115, 125, 159 excerpts from failure modes and effects analyses (fmea), 120œ121synergy between research and practice fostering more, 7, 314 lack of, 14system design phases, 11 architecting and design, 247 contributions to, 149, 160, 167, 185œ186, 196, 205œ206, 209, 222, 225, 229, 232, 238, 246œ248, 262, 273 evaluation, 247œ248 exploration and valuation, 246œ247 operation, 248system design process, contributions to, 154œ155, 173, 177, 214, 217, 234system developers, 14system development principles, 103œ105 concurrent system denition and development, 105 incremental growth of system denition and stakeholder commitment, 103œ104 risk management, 104œ105 successcritical stakeholder satiscing, 103system development process, 31œ54 conclusion, 53œ54 evolving nature of system requirements, 33œ34 incremental commitment model, 36œ39 institutionalizing based on success factors, 302 participatory methods tting into, 174 principlesbased comparison of alternative process models, 34œ36 principles for successful system development, 32œ33 project experience with icm principles, 51œ53 views of the incremental commitment model, 39œ51system diagrams, inputs and outputs, 142system engineers, 2system failures, catastrophic, 9systemlevel evaluation, 14system lifecycle processes, 196 activity level of hsi methods across phases of, 56 issues involved in, 2system performance, compromises in, 24system requirements emergent, 33 evolving nature of, 33œ34 rapid change, 33 reusable components, 33system resilience. see resiliencesystem safety, in the military sector, 18system scoping, 3system simulations. see simulationssystems engineering for user participation, 291œ295systems of systems, 6, 14, 36, 300, 308œ309 complexity of, 1, 4, 308 dening, 15 very large, 50humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 381ttadmus (tactical decision making under stress) program, 13task analysis, 5, 157œ161 contributions to system design phases, 160 overview, 157œ159 relationship to, 165 shared representations, 159œ160 strengths, limitations, and gaps, 160œ161 traditional, 201 uses of methods, 160task ˚ow diagrams, 115, 118taxonomies, of error, 328team models, 12, 251œ252technique for human error rate prediction (therp), 256technologies. see also new technologies ﬁmashup,ﬂ 26, 289, 291 potential insertion opportunities for, 105 recording, 153 wearable, 292territory maps, 64testing of alarm criticality and alerting, 120œ122 of display readability, 122 rapid, 22 of usability requirements, 194theater response package, 16theatrical approaches, 213, 215themes, 23œ27 adopting a riskdriven approach, 23œ24 creating shared representations for communication, 25 designing to accommodate changing conditions and requirements in the workplace, 26 integrating hsi contributions across lifecycle phases and humansystem domains, 27 tailoring methods to time and budget constraints, 24theorybased analysis, 99theory w approach, 38therp. see technique for human error rate predictionthinkaloud protocols, 225threatbased rpm display, graphical representation of work ˚ow with, 101threat detection, 99three mile island accident, 1, 256, 328ﬁthrowawayﬂ prototypes, 212time constraints, 23 tailoring methods to, 24time of day, and alertness level, 228time lines, 7, 279tips cards, 123tlx scales, 208tools. see also individual tools for product design, 2 to support capture and dissemination of results of context of use analyses, 315œ316top5 projects, explicitly using icm principles, 51, 51n. 1touch screens, large color, 111traceability, 6 and requirements, 305œ307tracking evolving requirements, by providing a format to document usability requirements, 195tradeoffs, 3, 19, 34, 140training considerations, 1, 5, 11 deciencies in, 20 in the military sector, 18, 20transportation systems, 255trustworthiness, 12tubing management, 114types of methods, 268œ272. see also methods; uses of methods expertbased evaluation, 272 product usability characteristics evaluation, 271œ272 user behavior evaluation, 268œ270types of models and simulations, 240œ246 digital human physical simulations, 243œ244 humanintheloop simulation, 240œ241 models derived from human cognitive operations, 242œ243 models that mimic human cognitive and perceptualmotor behavior, 244œ246 network models of humansystem performance, 241œ242 signal detection theory, 242humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.382 humansystem integration in system developmentuuass. see unmanned aerial systemsunintended relations and features, detection of, 62unmanned aerial systems (uass), 92œ97 conclusion and lessons learned, 96œ97 hypothetical case, 93œ94 in the icm context, 94œ96u.s. army, 10, 18œ19, 241u.s. department of defense (dod), 2, 4œ5, 10, 14, 18œ19, 241, 250, 297, 301œ304, 313 development milestone reviews, 23, 37 dod instruction 5000.2, 2, 4œ5, 14, 302 milestone b commitment, 39u.s. department of health and human services, 271u.s. department of homeland security (dhs), 97u.s. navy, 18œ19, 250u.s. rehabilitation act, 245us west, 13usability approaches to ensuring, 266 contributions to system design phases, 196, 273 evaluation methods, 5, 232, 265œ274 of an existing system, measuring, 193 improving the use of objectives, 324œ326 overview, 191œ192, 265œ266 practitioners of, 274 quantifying, 325 setting objectives, 115 shared representations, 194œ195, 273 strengths, limitations, and gaps, 197, 273œ274 tools to support capture and dissemination of results, 315œ316 uses and types of methods, 193œ194, 266œ272 walkthrough, 272usability requirements, 191œ197 specifying for new systems, 193œ194usc cocomo/cosysmo, 311useerror faults, 254 dening, 255œ256 risk analysis, 159, 255useerrorinduced operational risks, 92use of methods, 193œ194, 208. see also methods; types of methods instructions for development and testing, 123 measuring usability of an existing system, 193 shared representations, 62œ63 specifying usability requirements for the new system, 193œ194 testing whether usability requirements have been achieved, 194userbased evaluation methods, types of, 269user behavior evaluation methods, 268œ270 methods based on models and simulations, 270 methods based on observing users of a real or simulated system, 268œ270 methods that collect data from usage of an existing system, 270usercentered design process in the icm context, 106œ124 activities for stakeholder requirements, 196 contextual inquiry, 114œ115 design decisions, 109 early risk management, 115œ119 feature needs and their rationales, 110œ114 eld studies, 123 focus groups, 122 instructions for use development and testing, 123 integrated hardware and software models, 119œ120 iterative usability tests, 122 lifecycle planning, 124 preliminary research, 108œ109 product introduction, 124 prototypes, 119 revised risk analysis, 124 setting usability objectives, 115 tests of alarm criticality and alerting, 120œ122 tests of display readability, 122 validation usability tests, 123œ124usercreated dynamic pages, 22humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.index 383user participation in systems engineering, 288œ295 approaches to capturing user input, 288œ291 ethical implications, 316œ320uses of methods, 144œ149, 160, 167, 180œ185, 201œ205, 219œ221, 227œ231, 236 assignment and diagnosis, 185 cultural analysis, 147œ148 data analysis, 183œ184 data collection, 183 data representation, 184 ethnographic inquiry, 231 in formative and summative evaluation, 267 human digital modeling, 221 interpretation, 231 methods for assessing discomfort, 219 methods for assessing fatigue, 220œ221 methods for assessing injury risk, 221 methods for assessing posture, 220 organizational system scan, 144œ147 other example applications, 203œ205 problem scenarios and claims, 231 root concept, 231 stakeholder analysis, 148œ149 strengths, limitations, and gaps, 187œ188 use of work domain analysis in the port security case study, 202uses of models and simulations, 240œ246 digital human physical simulations, 243œ244 humanintheloop simulation, 240œ241 models derived from human cognitive operations, 242œ243 models that mimic human cognitive and perceptualmotor behavior, 244œ246 network models of humansystem performance, 241œ242 signal detection theory, 242uss vincennes, iranian air bus downed by, 13, 328utopia project, 65, 239vvmodel, 37, 39 updates, 34validation usability tests, 123œ124valuation commitment review (vcr), 46œ47valuation phase, 3, 246œ247valuebased systems and software engineering, 38variability, maximization of, 153vcr. see valuation commitment reviewvincennes. see uss vincennesvisual workshops, 171œ172visualizations, novel, 203voice recognition applications, 13wwalkthroughs. see cognitive walkthroughswarfare, limited or fullscale, 15waterfall models, 34 sequential, 34, 39ﬁweak links,ﬂ 330weapons systems, 255wearable technologies, 292web 2.0, 22, 26, 288, 290œ291, 294, 305, 316, 318web metrics, 270web sites, designing, 157ﬁweblogs,ﬂ 22, 289. see also ﬁblogsﬂwebsat, 272wholesystems approach, 139wikipedia, 290winlose situations, 38winwin spiral process, 51wireframes, 119workarounds, 26workcentered design approaches, 139work domain analysis, 197œ207 contributions to system design phases, 205œ206 overview, 197œ200 representation for a pressurized water reactor nuclear power plant, 200 shared representations, 201 strengths, limitations, and gaps, 206œ207 use in the port security case study, 202 uses of methods, 201œ205work ˚ow graphical representation of, 101 problems with, 187workload, managing, 19humansystem integration in the system development process: a new lookcopyright national academy of sciences. all rights reserved.384 humansystem integration in system developmentworkload assessment, 207œ210 contributions to system design phases, 209 overview, 207œ208 shared representations, 209 strengths, limitations, and gaps, 209œ210 use of method, 208workplace investigations, 175workplace requirements, accommodation to, 101œ102workshop methods, 213œ214, 280. see also drawing workshops; future workshops; participatory workshops; strategic design workshops; visual workshopsworkstations, 12world war ii, 10xxml interface, 22, 289yyahoo!, 291