detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/12998toward better usability, security, and privacy ofinformation technology: report of a workshop70 pages | 6 x 9 | hardbackisbn 9780309383448 | doi 10.17226/12998steering committee on the usability, security, and privacy of computer systems;computer science and telecommunications board; division on engineering andphysical sciences; national research counciltoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.steering committee on the usability, security, and  privacy of computer systemscomputer science and telecommunications boarddivision on engineering and physical sciencestoward better information technologyreport of a workshopusability, security, and privacy of toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, n.w. washington, dc 20001notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn from the councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsible for the report were chosen for their special competences and with regard for appropriate balance.this project was supported by the national science foundation under grant no. cns0841126 and the national institute of standards and technology under grant no. 70nanb8h8126. any opinions, ndings, conclusions, or recommendations expressed in this publication are those of the author(s) and do not necessarily re˚ect the view of the organizations or agencies that provided support for this project.international standard book number13: 9780309160902international standard book number10: 0309160901copies of this report are available from:the national academies press500 fifth street, n.w., lockbox 285washington, dc 20055(800) 6246242(202) 3343313 (in the washington metropolitan area)internet: http://www.nap.educopyright 2010 by the national academy of sciences. all rights reserved.printed in the united states of americatoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprot, selfperpetuating society of distinguished scholars engaged in scientic and engineering research, dedicated to the furtherance of science and technology and to their use for the general welfare. upon the authority of the charter granted to it by the congress in 1863, the academy has a mandate that requires it to advise the federal government on scientic and technical matters. dr. ralph j. cicerone is president of the national academy of sciences.the national academy of engineering was established in 1964, under the charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programs aimed at meeting national needs, encourages education and research, and recognizes the superior achievements of engineers. dr. charles m. vest is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to the health of the public. the institute acts under the responsibility given to the national academy of sciences by its congressional charter to be an adviser to the federal government and, upon its own initiative, to identify issues of medical care, research, and education. dr. harvey v. fineberg is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology with the academy™s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientic and engineering communities. the council is administered jointly by both academies and the institute of medicine. dr. ralph j. cicerone and dr. charles m. vest are chair and vice chair, respectively, of the national research council.www.nationalacademies.orgtoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.vsteering committee on the usability, security, and privacy of computer systemsnicholas economides, new york university, chairlorrie faith cranor, carnegie mellon universityjames d. foley, georgia institute of technologysimson l. garfinkel, naval postgraduate schoolbutler w. lampson, microsoft corporationsusan landau, radcliffe institute for advanced study donald a. norman, northwestern universitycharles p. pfleeger, p˚eeger consulting groupstaffjon eisenberg, director, computer science and telecommunications board nancy gillis, program ofcer (through january 2010)shenae bradley, senior program assistanttoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.vicomputer science and telecommunications boardrobert f. sproull, oracle corporation, chair prithviraj banerjee, hewlettpackard company steven m. bellovin, columbia university seymour e. goodman, georgia institute of technology john e. kelly iii, ibmjon m. kleinberg, cornell university robert kraut, carnegie mellon university susan landau, radcliffe institute for advanced study david e. liddle, us venture partners william h. press, university of texas, austin prabhakar raghavan, yahoo! labs david e. shaw, d.e. shaw research alfred z. spector, google, inc. john a. swainson, silver lakepeter szolovits, massachusetts institute of technology peter j. weinberger, google, inc. ernest j. wilson, university of southern californiastaffjon eisenberg, director virginia bacon talati, associate program ofcershenae bradley, senior program assistantrenee hawkins, financial and administrative manager herbert s. lin, chief scientistemily ann meyer, program ofcer lynette i. millett, senior program ofcer eric whitaker, senior program assistantenita a. williams, associate program ofcerfor more information on cstb, see its website at  http://www.cstb.org, write to cstb, national research council, 500 fifth street, n.w., washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.viiprefaceusability has emerged as a signicant issue in ensuring the security and privacy of computer systems. moreusable security can help avoid the inadvertent (or even deliberate) undermining of security by users. indeed, without sufcient usability to accomplish tasks efciently and with less effort, users will often tend to bypass security features. a small but growing community of researchers, with roots in such elds as humancomputer interaction, psychology, and computer security, has been conducting research in this area.with sponsorship from the national science foundation and the national institute of standards and technology, the national research council™s computer science and telecommunications board conducted a 2day workshop in july 2009 to identify promising research directions that would help advance usability, security, and privacy. it was also intended that the workshop would build awarenessšin the research community as well as in federal agencies and the broader technical community responsible for the design, development, and deployment of information  systemsšof the challenges at the nexus of usability and security/privacy, the tradeoffs that exist today, and the opportunities for making advances. a single workshop of this sort cannot be comprehensive; indeed, important topics such as the special usability considerations faced by those with impairments were not covered.the steering committee on the usability, security, and privacy of computer systems was convened to plan the workshop (biosketches of the steering committee members can be found in appendix c). the worktoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.viii prefaceshop was designed to identify research opportunities and potential roles for the federal government, academia, and industry and ways to embed usability considerations in research, design, and development related to security and privacy, and vice versa (the formal statement of task appears in box p.1). this report summarizes the workshop. as a workshop report, it does not necessarily re˚ect the consensus views of the committee or the workshop participants, and the committee was not asked to provide ndings or recommendations. the workshop was structured to gather suggestions from experts on computer security, privacy, and usability, as well as from economists and sociologists on new research topics within the intersection of usability, security, and privacy. it also involved a number of federal government representatives interested in usability, security, and privacy research. a detailed agenda can be found in appendix a, and a list of workshop participants can be found in appendix b.the workshop featured two overview presentations, the rst addressing computer security and the second addressing usability (summarized in chapter 2). it also included six presentations intended to provide an overview of current and prospective research topics (summarized in chapter 3). following these talks, workshop participants split into smaller groups that discussed research needs and opportunities, addressing the topics listed in appendix a. they were provided in advance with a set of potential research questions developed by the steering committee. the committee™s summary of results from the breakout sessions is presented box p.1  statement of taskan ad hoc committee will plan and conduct a public workshop on ways to advance the usability, security, and privacy of computer systems. the workshop will feature invited presentations and discussions on the stateoftheart in  usability, security, and privacy and how usability contributes to security and privacy. the agenda should include topics on ways to mutually advance objectives in usability and security/privacy especially in cases that replace tradeoffs (e.g., between usability and security) with winwin scenarios. it should also include topics on research opportunities and potential roles for the federal government, academia, and industry and ways to embed usability considerations in research, design, and development related to security, privacy and vice versa. a report of the workshop will be issued. toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.preface ixin chapter 4. chapter 5 discusses overarching questions in advancing research in usability, security, and privacy.the committee thanks the workshop participants for their thoughtful presentations and discussion. it also acknowledges the nancial support provided by the project™s sponsors, the national science foundation (nsf) and the national institute of standards and technology (nist), and it appreciates the encouragement and support of mary f. theofanos (nist) and karl n. levitt and c. suzanne iacono (nsf). nicholas economides, chair steering committee on the usability, security, and  privacy of computer systemstoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.xiacknowledgment of reviewersthis report has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise, in accordance with procedures approved by the national research council™s (nrc™s) report review committee. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published report as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the study charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this report:steven m. bellovin, columbia university,bob blakley, gartner, inc.,tadayoshi kohno, university of washington,eric sachs, google, inc., andstuart e. schechter, microsoft research.  although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the views expressed, nor did they see the nal draft of the report before its release. the review of this report was overseen by joseph f. traub, columbia university. appointed by the nrc, he was responsible for making certain that an independent examination of this report was carried out in accortoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.xii acknowledgment of reviewersdance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this report rests entirely with the authoring committee and the institution.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.xiiicontents1  overview of security, privacy, and usability 1 security, 1 privacy, 3 usability, 3 usability, security, and privacy, 4 usability, security, and privacy: an emerging discipline, 62 framing the security and usability challenges 7 an overview of the state of computer security  (butler lampson), 7 usable security and privacy: it™s a matter of design  (donald norman), 9 3 current research at the intersection of usability, security, and privacy 11 usable privacy (lorrie faith cranor), 11 economic issues of usable security and privacy  (nicholas economides), 14 what would usercentered security look like?  (angela sasse), 17 security in virtual worlds (frank greitzer), 18 feeding practice back into research (mary ellen zurko), 19 cybersecurity insider threat (deanna caputo), 21toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.xiv contents4 some potential research directions for furthering the usability, security, and privacy of computer systems 24 dimensions of usability, security, and privacy, 24 metrics, evaluation criteria, and standards, 26 understanding users, 27 incentives for better security and privacy, 30 approaches to constructing systems with ﬁusable security,ﬂ 325  overarching challenges to advancing research in usability, security, and privacy 37 inconsistent terminology and denitions, 37 limited access to data, 38 scarceness of expertise and unfamiliarity with each  other™s work at the intersection of usability, security,  and privacy, 38appendixes a workshop agenda 43b workshop participants 46c biosketches of steering committee members and staff 50toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.11overview of security, privacy, and usabilitythis overview brie˚y discusses computer system security and privacy, their relationship to usability, and research at their intersection. the chapter is drawn from remarks made at the national research council™s (nrc™s) july 2009 workshop on usability, security, and privacy of computer systems as well as recent reports from the nrc™s computer science and telecommunications board (cstb) on security and privacy.1securitysociety™s reliance on information technology (it) has been increasing simultaneously with the ability of individuals, organizations, and state actors to conduct attacks on computer systems and networks. it has become essential to the daytoday operations of companies, organizations, and government. people™s personal lives also involve computing in areas ranging from communication with family and friends to online banking and other household and nancial management activities. companies large and small are ever more reliant on information systems to support diverse business processes, including payroll and accounting, the tracking of inventory, the operation of sales, manufacturing, and research 1  national research council, toward a safer and more secure cyberspace, seymour e. goodman and herbert s. lin, eds., the national academies press, washington, d.c., 2007; and national research council, engaging privacy and information technology in a digital age, james waldo, herbert s. lin, and lynette i. millett, eds., the national academies press, washington, d.c., 2007.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.2 toward better usability, securiy, and privacy of itand developmentšthat is, computer systems are increasingly needed for organizations to be able to operate at all. critical national infrastructuresšsuch as those associated with energy, banking and nance, defense, law enforcement, transportation, water systems, and government and private emergency servicesšalso depend on information systems and networks. the telecommunications system itself and the internet running on top of it are critical infrastructure for the nation. information systems play a critical role in many governmental functions, including national security and homeland and border security. the conventional denition of computer security relates to the following attributes of a computer system: condentiality (the system prevents unauthorized access to information), integrity (information in the system cannot be altered without authorization), and availability (the system is available for authorized use). authenticationšthe verication of identity using some combination of something that one knows (such as a password), something that one has (such as a hardware token), and something that one is (such as a ngerprint)šis often thought of as an additional essential security capability. reliability is a closely related conceptša reliable system performs and maintains its functions even in hostile circumstances, including but not limited to threats from adversaries.nearly all indications of the severity of the security threat to computer systems, whether associated with losses or damage, type of attack, or presence of vulnerability, indicate a continuously worsening problem.2 the potential consequences fall into three broad categories:ł economic dragšto counter security problems, organizations are forced to spend in order to defend and strengthen insecure it systems.ł avoidancešbecause of the perceived security risks of computing, individuals or organizations avoid using it systems, thereby missing the potential benet of their use.ł catastrophešfailure of an it system causes major economic loss and perhaps even loss of life. a catastrophe could be the result of a cyberattack, a serious software design or implementation ˚aw, or system misuse.despite advances that have been made in both practice and technology, cybersecurity will be a concern into the foreseeable future. more and more sensitive information will be stored in systems whose security does not necessarily increase in proportion to the value of the assets they contain. the threats will continue to evolve both on their own and as defenses against them are discovered and implemented. new vulnerabilities will emerge as previously unknown weaknesses are uncovered and as innova2  nrc, toward a safer and more secure cyberspace, 2007, p. 2.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.overview of security, privacy, and usability 3tion leads to the use of it in new applications and the deployment of new technologies. the growing complexity of it systems and the fastgrowing importance of network access and networkintermediated computing are likely to increase the emergence of new vulnerabilities.privacyinformation privacy concerns the protection of information about individuals and other entities. the environment for privacy is dynamic, re˚ecting societal shifts (e.g., increases in electronic communication), varying and evolving attitudes (e.g., across generations or cultures), and discontinuities (e.g., events and emerging conditions that rapidly transform the national debate, such as the september 11, 2001, attacks and the global response to them) as well as technological change. the decreasing cost of storage combined with the increase in communications devices, including, and especially, mobile ones, has led to remarkable impacts on personal privacy within a very short period of time. private information can be compromised by attacking networks and computers directly or by tricking users into revealing the information or the credentials required to access it.3 protecting privacy often occurs in the face of competing interests in the collection or use of particular information, and addressing privacy issues thus involves understanding and balancing these interests.usabilityusability may be thought of narrowly in terms of the quality of a system™s interfaces, but the concept applies more broadly to how well a system supports user needs and expectations. the international organization for standardization (iso) 924111 standard denes usability as ﬁthe extent to which a product can be used by specied users to achieve specied goals with effectiveness, efciency and satisfaction in a specied context of use.ﬂ4 a framework attributed to both nielsen5 and shneiderman6 describes usability in terms of learnability, efciency of use, memorability, few and noncatastrophic errors, and subjective satisfaction. usability relates not only to understanding what taking a particular action means in 3  one example of the latter is phishing, which refers to attempts to acquire sensitive information such as passwords by pretending in an email or other communication to be a trustworthy entity.4 international organization for standardization (iso), ergonomics of human system interactions: guidance on usability (part 11), iso, geneva, 1998.5  jakob nielsen, usability engineering, academic press, san diego, calif., 1993, p. 26.6 ben shneiderman, designing the user interface: strategies for effective humancomputerinteraction, addisonwesley, reading, mass., 1992.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.4 toward better usability, securiy, and privacy of itthe context of a particular interaction, but also to whether the user understands the implications of his or her choices in a broader context. information system design and development inevitably embed assumptions and values, both implicit and explicit, that have impacts on a system™s users; these considerations may be thought of as another aspect of usability. usability, security, and privacydespite many advances, security and privacy often remain too complex for individuals or enterprises to manage effectively or to use conveniently. security is hard for users, administrators, and developers to understand, making it all too easy to use, congure, or operate systems in ways that are inadvertently insecure. moreover, security and privacy technologies originally were developed in a context in which system administrators had primary responsibility for security and privacy protections and in which the users tended to be sophisticated. today, the user base is much wideršincluding the vast majority of employees in many organizations and a large fraction of householdsšbut the basic models for security and privacy are essentially unchanged. security features can be clumsy and awkward to use and can present signicant obstacles to getting work done. as a result, cybersecurity measures are all too often disabled or bypassed by the users they are intended to protect.7 similarly, when security gets in the way of functionality, designers and administrators deemphasize it. workshop participant don norman quipped, ﬁthe more secure a system, the less secure the systemﬂšthat is, when users nd that security gets in their way, they gure out ways to bypass it.8 indeed, some participants suggested, it may be the dedicated workers who are most highly motivated to defeat security measures.the result is that end users often engage in actions, knowingly or unknowingly, that compromise the security of computer systems or contribute to the unwanted release of personal or other condential information. for example, industry reports, such as the one issued in 2008 by the 7 a recent paper by herley explains that ﬁsecurity advice is a daily burden, applied to the whole population, while an upper bound on the benet is the harm suffered by the fraction that become victims annually.ﬂ c. herley, ﬁso long, and no thanks for the externalities: the rational rejection of security advice by users,ﬂ new security paradigms workshop 2009, oxford.8 this observation was published following the workshop in d.a. norman, ﬁwhen security gets in the way,ﬂ interactions 16(6): 6063, 2009; a similar observation (ﬁmore onerous security requirements can lead to less secure situationsﬂ) appears in d.a. norman, living with complexity, mit press, cambridge, mass., 2010, chapter 3, in press.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.overview of security, privacy, and usability 5verizon business risk team, have highlighted the impact that end users have on system security. as the verizon report observed: [l]oosely dened, error is a contributing factor in nearly all data breaches. poor decisions, miscongurations, omissions, noncompliance, process breakdowns, and the like undoubtedly occur somewhere in the chain of events leading to the incident.9usability and security are thus attributes that can trade off against each other. for example, requiring users to change their passwords periodically may improve security but places a greater burden on users. (poor usability may also reduce security by driving users to workarounds, such as when users tape hardtoremember passwords to their workstations.) or, a password may be replaced by a hardware token; this relieves the user of having to remember a password but imposes a new burden on the user to carry the token wherever that access is required. poor usability is also an impediment to privacy protection. for example, a privacy policy or privacy settings that are difcult to understand or navigate make it difcult for users to know what privacy choices they have made or to change the settings to best re˚ect their preferences.usability, security, and privacy are all especially challenging aspects of system design. for example, although wellestablished techniques exist for testing the usability of a system, at least in the narrow sense of the quality of the system™s interface, much less is known about how to effectively embed usability considerations in a specication. better user models might help in the identication of usability requirements and more generally speed development. more sophisticated models might make it easier to strike the right balance between usability and risk mitigation. moreover, usability, security, and privacy have all come to be understood as attributes that must be addressed throughout a system™s development life cycle. early decisions about architecture, data structures, and so forth can have a large impact on what sorts of usability aspects are even feasible. finally, both usability and security/privacy considerations are not nished once a product or system is released, but need to be kept in mind through the life cycle of usešassumptions, norms, and expectations may change over time. data about these factors can be gathered and taken into account during system updates and revisions.9 verizon business risk team, 2009 data breach investigations report, verizon business. available at http://www.verizonbusiness.com/products/security/risk/databreach; accessed february 16, 2010.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.6 toward better usability, securiy, and privacy of itusability, security, and privacy: an emerging disciplinea small but growing research community has been working at the intersection of usability, security, and privacyšone that draws on expertise from multiple disciplines including computer security, humancomputer interaction, and psychology. participants noted that as an emerging and multidisciplinary discipline, it is sometimes viewed as too ﬁsoftﬂ by some engineers and scientists and that it does not always have buyin from those responsible for managing the development and operation of computer systems. there has, however, been growing interest in the eld from the more traditional disciplines. papers at the intersection have appeared occasionally at traditional security conferences for many years, but until recently there have been few sustained research efforts in this area. exploratory workshops held in 2003 and 2004 led to the organization in 2005 of the rst formal conference on this topic, the symposium on usable privacy and security (soups), which has been held annually since then. increasingly, usable security and privacy papers are also appearing at traditional security conferences and humancomputer interaction conferences, more academic and industry researchers are focusing their research in this area, several universities now offer courses in this area,10 and the national science foundation™s trustworthy computing program highlights usability as an important research area.10 for example, courses have been offered by carnegie mellon university (ﬁusable privacy and securityﬂ; see http://cups.cs.cmu.edu/courses/ups.html), and harvard university (ﬁsecurity and privacy usabilityﬂ; see http://www.seas.harvard.edu/courses/cs279/syllabus.html).toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.72framing the security and usability challengestalks by butler lampson and donald norman provided workshop participants with an overview of key challenges related to security and usability. lampson™s presentation discussed the current state of computer security and its relationship to usability considerations. norman™s remarks centered on the issue of design as it relates to usability, security, and privacy. the following sections summarize these remarks.an overview of the state of computer security (butler lampson)computer security today is in bad shape: people worry about it a lot and spend a good deal of money on it, but most systems are insecure. the primary reason for this poor state of computer security, lampson argued, is that users do not have a model of security that they can understand. lampson suggested that research is needed to decide whether appropriate models can be elicited from what users already know, or whether there is a need to invent and promote new models. metrics play an important role in addressing the state of computer security. security is about risk management: balancing the loss from breaches against the costs of security. unfortunately, both are difcult to measure. cost is partly in dollars budgeted for rewalls, software, and help desks but mostly in the time that users spend typing and resetting passwords, responding to warnings, nding workarounds so that toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.8 toward better usability, securiy, and privacy of itthey can do their jobs, and so forth. frequently the costs and risks are unknown, and there are no easy ways to estimate them.a proper allocation of economic incentives is essential to improving computer security. users, administrators, organizations, and vendors respond to the incentives that they perceive. users just want to get their work done. without an appropriate understanding of the risks involved and how proper security may help avoid those risks, they view security as a burden, causing them to ignore it or to attempt to work around it. organizations do not measure the cost of the time that users spend on security and therefore do not demand usable security. vendors thus have minimal incentive to supply it.many people think that security in the real world is based on locks. in fact, realworld security depends mainly on deterrence and hence on the possibility and severity of punishment. the reason that one™s house is not burgled is not that the burglar cannot get through the lock on the front door; rather, it is that the chance of getting caught, while small, together with a signicant punishment, makes burglary uneconomic. it is difcult to deter attacks on a computer connected to the internet because it is difcult to nd ﬁthe bad guys.ﬂ one way to x this is to communicate only with parties that are accountable, that one can punish. there are many different punishments: money nes, ostracism from some community, ring, jail, and other options. some punishments require identifying the responsible party in the physical world, but others do not. for example, to deter spam, one might reject email unless it is signed by someone known to the receiver or unless it comes with ﬁoptional postageﬂ in the form of a link certied by a trusted third party, such as amazon or the u.s. postal service; if one clicks the link, the sender contributes a dollar to a charity.the choice of safe inputs and the choice of accountable sources are both made by one™s own system, not by any centralized authority. these choices will often depend on information from third parties about identity, reputation, and so forth, but which parties to trust is also one™s own choice. all trust is local.to be practical, accountability needs an ecosystem that makes it easy for senders to become accountable and for receivers to demand it. if there are just two parties, they can get to know each other in person and exchange signing keys. because this approach does not scale, there is also a need for third parties that can certify identities or attributes, as they do today for cryptographic keys. this need not hurt anonymity unduly, since the third parties can preserve anonymity except when there is trouble, or accept bonds posted in anonymous cash.this scheme is a form of access control: you accept input from me only if i am accountable. there is a big practical difference, though, because toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.framing the security and usability challenges 9accountability allows for punishment or the possibility to undo things that should not have been allowed to occur. auditing is crucial, to establish a chain of evidence, but very permissive access control is acceptable because one can deal with misbehavior after the fact rather than preventing it up front.one obvious problem with accountability is that one often wants to communicate with parties about whom one does not know much, such as unknown vendors or gambling sites. to reconcile accountability with the freedom to go anywhere on the internet, one should, lampson suggests, use two (or more) separate machines: a green machine that demands accountability and a red one that does not.on the green machine one keeps important things, such as personal, family, and work data, backup les, and so forth. it needs automated management to handle the details of accountability for software and web sites, but one chooses the manager and decides how high to set the bar: like one™s house or like a bank vault. of course the green machine is not perfectly securešno practical machine can bešbut it is far more secure than what is generally available today.on the red machine one lives wild and free, not putting anything there that one really cares about keeping secret or not losing. if anything goes wrong, the red machine is reset to some known state.things are so bad for usable security, lampson concluded, that it will be necessary to give up on perfection and focus on essentials. the primary cause of the problem is metrics and incentives: the costs either of getting security or of not having it are not known, so users do not care much about it. therefore, vendors have no incentive to make security usable.to x this, it is necessary to measure the cost of security, and especially the time that users spend on it. simple models of security that users can understand are needed. to make systems trustworthy, accountability is needed, and to preserve freedom, separate green and red machines are needed, to protect things that one really cares about from the wild things that can happen on the internet.usable security and privacy: it™s a matter of design (donald norman)among the recurring questions at the workshop were these: does added security make things more difcult to use? will people always resent the extra steps? the answer to both questions is the same: not necessarily. consider the physical world of doors and locks mentioned earlier: one can see that they can get in the way of easy access but are tolerated because they seem necessary and because the amount of effort required to open them usually seems reasonable. this example highlights toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.10 toward better usability, securiy, and privacy of ittwo key design issues: (1) the importance of users (and vendors) understanding the necessity for protection and (2) the reasonableness of the effort required. different groups are involved in ensuring the security of a computer system, each group requiring a different form of design assistance. system developers provide the underlying mechanisms, but the information technology (it) administrators at the various sites determine just how those policies are to be enforced. the it staff is under considerable pressure from its own administration to reduce security and privacy concerns, but to do so it must be well versed in technology, in the law, in the needs of the user community, and in the psychology of both the legitimate and the illegitimate users. what the community needs, norman suggested, is a set of standardized scripts, templates, and system tools that allows them to implement best practices in ways that are both effective and efcient, standardizing interactions across systems in order to simplify the life of users but still tailoring the requirements to any special needs of the organization. these tools do not exist today.in the absence of standard guidelines and adequate tools, different systems implement the same policies with very different philosophies and requirements, complicating life for people who must use multiple systems. developers who lack an understanding of real human behavior tend to impose logical rules and requirements on a bewildered, overwhelmed audience. the users, either not understanding the rationale or simply disagreeing with the necessity for the procedures imposed on them, see these as impediments to accomplishing their jobs. moreover, the system developers may lack understanding of the clever ruses and social engineering skills of the illegitimate users, who break into systems the easy way: by lying, stealing, and deceiving. the strongest locks in the world do not deter the clever social engineer. security and privacy are difcult problems. norman suggested that a way to improve security is to design systems that are easy to use for their intended purposes or by the intended people, but difcult for nonauthorized people or uses. for these purposes, norman added, one needs to consider components not normally considered in simple product design: means of authenticating identities or authority, needs, and permissions. it also means undertaking research to ensure that systems are accompanied by a clear and understandable conceptual model, norman concluded. individuals do appear willing to adapt to the inconvenience of locks that seem reasonable for protection, but not to those that just get in the way. if people understand why they are required to implement security protocols, they might be more willing to pay a reasonable penalty of inconvenience. toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.113current research at the intersection of usability, security, and privacy six workshop speakers who work at the forefront of usability, security, and privacy and associated elds were asked to discuss the challenges, applicable research, and potential research needs associated with usability, security, and privacy. their remarks are summarized below. usable privacy (lorrie faith cranor)privacy has been described as an ﬁadjustment processﬂ in which humans continuously adjust the views of themselves that they present to others. in the online world, humans often rely on software tools to help them manage this process. however, many currently available privacy tools are difcult to use. lorrie faith cranor™s presentation addressed areas in which usability research is needed in order to provide more effective privacy protection and explored areas in which some privacy goals may appear to con˚ict with other privacy goals, usability goals, or security goals.cranor began her talk by observing that privacy is hard to dene, and quoted from a paper by robert c. post in the georgetown law journal: ﬁprivacy is a value so complex, so entangled in competing and contradictory dimensions, so engorged with various and distinct meanings, that i sometimes despair whether it can be usefully addressed at all.ﬂ1 she went on to provide a variety of denitions of privacy that have been offered 1 robert c. post, ﬁthree concepts of privacy,ﬂ georgetown law journal 89: 2087, 2001. toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.12 toward better usability, securiy, and privacy of itby public gures and in legal and other academic literature. the myriad denitions have at their core the basic notions limiting access to and providing control over personal information or contact with individuals.2 access and control can be provided through either technical or legal and regulatory measures. access can be limited using either laws that prohibit or limit the collection and disclosure of information or technology that facilitates anonymous transactions or otherwise minimizes disclosure. one way to provide control over personal information is through laws and regulations that mandate choice, the choice either to opt in or to opt out. another is the use of technology that facilitates informed consent, such as tools to keep track of and enforce privacy preferences.although work in the past has often focused on information collected by web sites, a wide array of current and emerging technologies will have signicant impacts on privacy, including behavioral advertising, social networks, deep packet inspection, server log les, and location sharing. all of these technologies raise questions about how to communicate meaningfully about the effects that these technologies will have on privacy and about how to help people understand privacy risks that may seem distant or not relevant to them today. related to this, different rates and patterns of use and the acceptance of these technologies suggest that different types of communication may be necessary to reach people in different age groups, of different genders, or in different cultures. cranor drew the connection between privacy and usability, observing that the privacy concerns that people often express seem inconsistent with their actual behavioršthat is, people say that they want privacy but do not always take the steps necessary to protect it. there are many possible explanationsšfor example, people may not actually care all that much about privacy, or they may favor shortterm benets that may come at the cost of privacy over the longterm consequences for their privacy. but there are other possible explanations for the gap between expressed concerns and behavior: people may not understand the privacy implications of their behavior; the cost of privacy protection may be too high (including the cost of guring out what steps should be taken to protect their privacy); or users might think that they have taken steps to protect their privacy but misunderstood those steps and actually did not. all three possibilities directly implicate usability.one case where usability issues impede privacy protection is the use of privacy policies, which are intended to inform consumers about pri2 two recent cstb reports explored these denitional issues: see national research council, who goes there: authentication through the lens of privacy, the national academies press, washington, d.c., 2003; and national research council, engaging privacy and information technology in a digital age, the national academies press, washington, d.c., 2007.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.current research 13vacy practices and to help them decide whether those practices are acceptable or whether to opt out. however, cranor observed that most policies are difcult to read, long, and subject to frequent change, with the result that few people read privacy policies; this suggests that privacy policies of the sort common today do not really enable consumers to exercise effective control over their personal information. meaningful control is only possible if individuals can understand what their options are and what the implications of these options are, if they have the means to exercise the options, and if the costs (in terms of money, time, convenience, and cost versus benet) are reasonable. cranor described a research effort in which she is involved that aims to address these issues through the development of standardized, easytoread labels akin to nutritional labeling on food. another case is privacy conguration management. how can the creation of privacy rules be simplied even though the context may be very complex? how can people be allowed to establish privacy preferences easily up front for a range of applications? how can people be helped to realize when adjustments to these settings are needed and to adjust them easily or automatically? cranor described a research effort studying some of these privacy conguration issues: the locationnding service, locaccino, developed at carnegie mellon university. the application includes capabilities for dening with whom, when, and where location information is shared. it also provides information about who has asked to view a user™s location and who can view that information currently, and it is instrumented to collect feedback on how comfortable users are with this information.the compelling functionality as well as the signicant privacy impacts of locationnding services is illustrative of the con˚icts that can arise. how can the need to store information be balanced with the need to discard information to provide privacy? examples of such con˚icts involve not only information used to improve application functionality but also information used to automate privacy congurations. similar tensions arise between privacy and other interests, such as the need to store access data for auditing purposes versus the need to protect employee privacy, or the needs of law enforcement versus the need to discard information to protect privacy. are there technical solutions that can preserve privacy while enabling these functions?anonymity tools can enhance privacy in certain situations. these tools typically hide users in cover trafc or send trafc by way of a  circuitous route that is difcult to trace back. users typically give up speed, convenience, or functionality in exchange for this anonymity. the tools must also be turned on and off, which is cumbersome and requires explicit user action. are there ways of providing anonymity without degrading the user experience?toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.14 toward better usability, securiy, and privacy of itcranor ended her talk by presenting a series of slides listing a number of the research questions discussed above. she closed by posing three questions with broad implications for privacy and usability as well as future research on these topics: ł as today™s youth grow up with their lives online, will they come to expect less privacy?ł as we increasingly trade off privacy for convenience and functionality, are we doomed to a slow erosion of privacy that eventually leaves us with minimal expectations of privacy?ł can ﬁusable privacyﬂ be designed into technology to provide convenience and functionality without sacricing privacy?economic issues of usable security and privacy (nicholas economides)the talk by nicholas economides addressed how the incentives of both users and companies with respect to usable security and privacy are not currently structured to maximize social benet.3 most users do not have sufcient incentives to secure their computers to prevent networkwide catastrophic events, and they might nd it very difcult to implement sufcient security even if they had sufcient incentives. what economic and legal policies can be implemented to change the incentives of users, software and hardware companies, rms conducting electronic commerce, and companies providing online services such as search so that they are closer to maximizing social benet? what are some possible economic motivators for usable security and privacy from the perspective of the end user, private companies, and society? how do economic incentives change when viewed domestically versus globally?economides began by noting the signicant security deciencies of computing devices and software today, the complexity of the interfaces that dene security functionality, and the poor knowledge that users typically have about the level of privacy present in the software and services that they use. the internet is widely understood to have both multiplied the security problems of connected devices and highly increased the global impact that results from a local lack of security. indeed, typical users have a very limited understanding of the network capabilities of their computers and the possibilities of abuse in a network setting.3 a similar phenomenon was noted in don davis, ﬁcompliance defects in publickey cryptography,ﬂ proceedings of the 6th usenix security symposium, san jose, calif., 1996, pp. 171178, available at http://world.std.com/~dtd/#compliance.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.current research 15the question of incentives can be approached from a number of perspectives, such as those of the individual or residential user; private companies (which have different perspectives depending on the nature of their business); the overall network or societal interests; vendors of hardware, software, and services; and internet service providers.even individual users face a myriad of choices with respect to their activities that depend on computing, communications, and storage capabilities. it is not clear that users došor even can reasonably be expected tošunderstand the nancial or other consequences to themselves or others from poor security in any of these choices. do users have sufcient economic incentives (either rewards or penalties) to use sufcient security? improved usability of security would make it possible for at least those users who aim for higher security to achieve it at reasonable cost. private rms™ views on security and privacy vary widely. some rms, such as banks, investment brokers, and electronic commerce rms, generally desire higher levels of security and have found various private solutions to make their transactions more secure. (the level of security achieved and the investment that they make re˚ect such rms™ view of the costs and benets and will not necessarily provide a level of security demanded by broader societal interests.) other rms, such as online advertisers, tend to favor more retention or disclosure of private information so that they can use this information to identify products and services that better match consumer preferences. economides observed that, as a result, a very secure online world in which users are made fully aware of the impact of disclosures of their private information would cut into the prots of these rms. other rms that produce operating systems and other software have not fully adjusted to today™s world in which the exploitation of even small security ˚aws can have global consequences. operating systems™ producers do not face full liability for the damage that may be caused by security ˚aws. once sold, many systems will persist for years; security issues and questions about incentives apply not only at the time of purchase but also throughout the useful life of the product. internet service providers (isps) have an interest in furthering the security of end users, given that breaches can affect their own networks; isps may also view security as an attractive valueadded business. given these diverse perspectives, economides observed that a consensus among companies on security and privacy is unlikely.from a societal point of view, the value of security is much higher for the network than it is for an individual user. that is, users, left on their own, will generally tend to achieve lower security than what society desires. low security at the nodes can lead to catastrophic network events that are much more damaging to society than to the individual node. the owner of the node does not face the networkwide nancial and other toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.16 toward better usability, securiy, and privacy of itliability that low security at the node causes. the lack of security at a node is, therefore, a negative externality to the network. similar considerations apply to the vendors of hardware, software, and services.economides posed related questions about the incentives for security:ł what legal and economic policy changes would help improve the usability of the security of operating systems, web sites and services, or internet service providers? ł how can the usability of security be improved (and thus its cost reduced) so that users who aim for higher security are better able to achieve it?ł when usable security is available, how can economic incentives be created so that users will aim for sufcient security?a variety of potential incentives might be considered. these include positive monetary incentives, awards and other nonmonetary positive incentives, and punishments. negative incentives would include enduser liability for damage caused by insecure nodes, liability for vendors, or regulation. for example, regulations could prohibit computers that fail a basic security test from being connected to the internet, or they could prohibit systems from being shipped with known insecure default settings. there are also thorny policy issues that apply in individual sectors. for example, blocking access on the basis of a security test limits to some extent the rights of computer owners. also, there may be a tension between asking isps to play a greater role in limiting or preventing some attacks and ensuring that carriers comply with network neutrality principles such as not prioritizing content.economides closed by posing the following key questions regarding incentives for security and privacy:ł how can society best deal with the negative externality for the network and society that is created by the lack of usable security of individual network nodes?ł how can positive and negative, monetary, and nonmonetary incentives be provided to both users and privatesector rms to reduce or eliminate the negative externality?ł how can the usability of security be improved so that the costs are lowered for users who aim to achieve higher security?toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.current research 17what would usercentered security look like? (angela sasse)angela sasse started with the observation that usercentered approaches to designing technology start with understanding user requirements. to do that, researchers and developers try to establish the following:ł the needs of the target users, plus specic capabilities or limitations that they have;ł the tasks and business processes that the users have to perform; andł the physical, cultural, and situational context in which the interaction takes place.however, since security is not a primary goal of users (protecting data, transactions, and systems is secondary to ﬁgetting the job doneﬂ), users often experience security as something that gets in the way of their activities as opposed to being something that is valuable. how can security be made less of a ﬁbarrierﬂ that gets in the way of user goals? how can the user effort required be reduced? when is it reasonable to expect users to expend extra effort on security? what are existing user needs and values that could be connected to security?sasse then turned to the reasons that usability is important for security. she observed that the results of failure to make security usable are much more widespread than is generally realized. for users, this failure manifests itself as errors, frustration, annoyance, and individual loss of productivity. for organizations, there are the risks of system failure, the alienation of customers, and damage to organizations™ reputations and impacts on their business processes and performance. for society, security ends up being seen as an annoyance or obstacle rather than as something that should be valued. poor security makes possible attacks that undermine trust and condence.sasse offered a framework for thinking about usability that includes the following elements: the users and actors (including individuals and organizations), the activity (the goals of the interaction [the ﬁwhatﬂ] and the tasks and processes to be carried out to achieve those goals [the ﬁhowﬂ]), and the context (including physical, situational, and cultural aspects). in addition, one must consider the system or technology platform in question.in terms of users, one must understand their requirements and capabilities, which include not only such factors as human memory, propensity to make errors, fatigue, biases, and the like, but also what the users are trying to achieve. another consideration is the specic capabilities of users; because it is often essential to use security capabilities in order to toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.18 toward better usability, securiy, and privacy of itgain access to services, accommodations should be made for user groups that have particular requirements.in terms of activity, it is important realize that security is a secondary or enabling activity. from a user™s perspective, security at best slows down the completion of a task, and at worst it can prevent the user from achieving a goal. from an organization™s perspective, security consumes resources and slows down business processes; at worst it may stop business processes altogether. as a result, the needs of business processes and user tasks impose performance requirements on security tasks.a number of contextual factors have a bearing on usability and privacy. these include the physical environment, situational factors such as the impact of interactions and failures, and cultural factors. cultural factors include behavioral norms such as the acceptability of touching equipment, or reactions to the prohibitions on smiling associated with some facerecognition systems.security has both costs and benets. individual costs include the physical workload (e.g., additional keystrokes or mouse clicks) and mental workload (e.g., remembering passwords). both actual and perceived costs are relevant. organizational costs include the cost of operating security capabilities (including training and maintenance) and the cost when these capabilities fail. the impacts of security extend beyond business efciency to employee behavior, trust, and goodwill. these costs and benets are weighed in each decision about whether or not to comply with security measures. such decisions are affected by the design of the security system, the organizational culture, and the extent of monitoring and the possibility of sanctions for noncompliance.sasse closed by listing the following as key research challenges:ł identifying and understanding tradeoffs,ł developing ways to quantify and compare costs for different usability and security criteria and for different stakeholders,ł identifying and reconciling individual and collective goals with respect to security, andł developing a better understanding of the short and longterm impact of security measures on individuals, businesses, and society.security in virtual worlds (frank greitzer)social media such as blogs, microblogs (e.g., twitter), social networking sites (e.g., facebook), and virtual worlds provide new tools for individuals to communicate, play, and work. because these virtual communities are being used for many of the same things that people do in real life, they are becoming plagued by many problems and crimes of toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.current research 19the real worldšincluding theft of identities and virtual assets. identity and access management is a particular challenge in virtual environments because it is difcult to establish that an online identity is in fact the reallife person that it claims to be. moreover, online tools do not necessarily provide protection that is strong enough to protect condential discussions (and it may be appropriate today to shift such activities to a private environment). this suggests the need for a better understanding of the security issues that threaten trust and privacy in these environments and for a better understanding of the role played by usability. frank greitzer noted several conventional cybersecurity challenges that may play out in different ways in virtual environments. these include what sorts of authentication and credentials are most appropriate in virtual worlds, who should be responsible for managing credentials and verication, and how authentication and identication can best be manifested in a virtual environment. one of the most important research questions concerns the human factors and usability implications of proposed solutions. how can someone trust that the person (avatar) with whom he or she is interacting is accountable? for any particular solution, how can the solution be made usable and trustworthy for individuals who participate in virtual worlds? finally, greitzer underscored that validationšhow to evaluate the effectiveness of proposed solutionsšis essential.feeding practice back into research (mary ellen zurko)mary ellen zurko discussed how to integrate lessons learned from practice into research thinking, noting that not only should research results inform practice, but practice and realworld experience with development, deployment, and use also should inform research. issues that can only be understood in this context include scaling; performance; usability, accessibility, and user experience; and the total cost of ownership and return on investment. for example, the security weaknesses of text passwords have been revealed by understanding their use and changes in their use. in the early days, passwords were used primarily by a handful of professionals to access a single computer. today, people make use of passwords for a wide array of services, each of which has different strength requirements and management policies. the result is that almost all forms of deployed security using passwords are weak in terms of both usability and the security that results. researchers are exploring alternatives to passwords for authentication, but these have many barriers to deployment, such as those toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.20 toward better usability, securiy, and privacy of itassociated with the scale of enrollment and the need to retrot complex infrastructures that only support passwords.another connection between practice and research is the realworld constraints that affect the deployment of research results. for example, a researcher might come up with a better way of presenting a user with information about how much trust to place in the claimed sender of an email message. in the real world, the space available for presenting this information may be signicantly constrained by an email client™s user interface. products routinely have a number of features competing for space in the user interface, with designers making decisions based on factors such as primary use cases, sales criteria, organizational politics, esthetics, technical difculty, and maintenance. such tradeoffs, commonplace in practice, need to inform research so that researchers can successfully transfer their results into practice and products. such technology transfer depends on the development of tools and best practices that allow practitioners to incorporate research results on usercentered security into the systems that they design, build, and operate. it also depends on the development of criteria and approaches for evaluating how usably secure a system or approach is likely to be. the transfer into practice can be facilitated through standards groups such as the web security context working group of the world wide web consortium. intellectual property concerns can also be a barrier to uptake. zurko proposed a number of ideas that would encourage a greater emphasis on technology transfer concerns within the context of the research environment. most obviously, funding specically targeted at usable security research addressing uptake issues would drive progress in that area. venues for publishing the results of such research are critical, as one of the main activities of researchers is to publish. framing devices such as use cases, frameworks, and challenges can inspire and structure potential research and its results. zurko suggested several opportunities for research to be informed by experiences with deployed systems, including the following:ł conducting user studies of deployed technology, including contextual analysis;ł measuring changes in user behavior in response to changes in services;ł using opensource and freeproduct betas as a source of information on user behavior; andł studying the characteristics of deployed security, through such techniques as tigerteaming.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.current research 21the presentation closed with the observation that although there is no substitute for the ground truth of realworld experiments, there are also constraints on what can be done in these settings. one should not be able to make changes that deliberately impair materially the security of an operational system. as a result, experiments with security in realworld settings require controls and oversight, much as efcacy and safety considerations govern the conduct of drug trials.cybersecurity insider threat (deanna caputo)deanna caputo began her presentation by discussing the problem posed by trusted insiders. espionage, intellectual property theft, and sabotage involving computer networks are among the most pressing cybersecurity challenges that threaten government and the private sector. surveys reveal that current or former employees and contractors are the secondgreatest cybersecurity threat, exceeded only by hackers. the insider threat is manifested when human behavior departs from compliance with established policies, regardless of whether it results from malice (malicious insiders) or a disregard for security policies. because insiders can make use of the privileges that they have been granted, they do not need to engage in behaviors that break explicit rules, making it difcult to detect these actions. what are the possible signatures of lawful but suspicious activities? how can these detection mechanisms be made usable by security analysts? how can the interests in detecting suspicious behavior be balanced with the privacy interests of employees?caputo went on to describe work being done at the mitre corporation to address these questions. this work includes the development, testing, and piloting of a prototype detection system known as exploit latent information to counter insider threats (elicit). it uses sensors to collect information used to detect and prioritize potential threats. it is based on a characterization of how trusted insiders use information, and it uses information about both the user and the information context to differentiate malicious and legitimate activities. caputo commented that the resulting information allows timeconsuming and costly threat validation and forensic investigation to be concentrated on a small number of prioritized cases. work on elicit prompted a team of social scientists and engineers to explore experimentally how malicious insiders use information differently from how a benign baseline group uses information.4 caputo 4 deanna d. caputo, marcus maloof, and gregory stephens, ﬁdetecting insider theft of trade secrets,ﬂ ieee security and privacy 7(6): 1421, november/december 2009.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.22 toward better usability, securiy, and privacy of itdiscussed preliminary results from the doubleblind study of malicious insiders, which revealed some counterintuitive results. one surprise was that malicious insiders tend to grab and gošfavoring quantity over  qualityšcontrary to expectations that insiders would be ﬁlow and slow,ﬂ working meticulously to avoid raising suspicions. caputo also offered some essential aspects gleaned from these efforts of approaches for detecting insider threats. the work has also involved the development of test data to represent both malicious and benign users. the work has also informed practical guidance developed by mitre for handing these threats.5 the following measures can be used by organizations to defend against the insider threat:ł make employees the rst line of defense. educate them about spotting suspicious behavior. understand that satised workers are less likely to be disgruntled insiders.ł pay attention to employee behavior. look for signs of vulnerability, unexplained wealth, and so on.ł prioritize assets. concentrate monitoring resources where it matters most.ł know what baseline behaviors on the network look like so that anomalies can be recognized. enumerate trust relationships with other organizations because their insiders can become your insiders.ł divide responsibilities. separate duties for key functions to reduce exposure.ł grant least privileges, and audit for privilege overentitlement.ł prepare for recovery through continuity of operations and data backup plans.caputo also described work on the insider threat by several other research groups. shari lawrence p˚eeger and joel predd at rand have developed a framework for understanding the insider threat and a taxonomy for describing insider actions, and they are developing a framework for response to the insider threat. frank greitzer at the pacic northwest national laboratory is looking at behavioral data to support predictive modeling and analysis in order to improve situational awareness for the security analyst, facilitate response coordination, and help the analyst focus on the highestrisk activities. a prototype system is under development that provides enhanced visual analytics and a multilayered user 5 mark maybury, how to protect digital assets from malicious insiders, the mitre corporation and institute for information infrastructure protection. available at http://www.thei3p.org/research/mitremi.html; accessed february 25, 2010.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.overview of security, privacy, and usability 23interface encompassing displays for highlevel status as well as detailed monitoring.in terms of areas for further research, caputo posed the following questions:ł what tradeoffs associated with insider threat monitoring are there between the individual™s right to privacy and the organization™s need to protect its assets?ł what are the implications of preinterventional activities such as monitoring and the collection of data and predictive modeling? how might they affect morale or violate employee trust or legal guidelines? what is the potential for false accusations or misuse?ł what is the impact of user proling, and what are the ethical and legal issues surrounding this approach?finally, caputo noted that research on the insider threat would be aided by good operational data samples.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.244some potential research directions for furthering the usability, security, and privacy of computer systemsa principal goal for the workshop was to identify research questions and areas within the emerging eld of usability, security, and privacy that would assist in increasing the security of computer systems used by individuals and organizations. limiting the discussion to research questions was, perhaps not surprisingly, a challenge. participants approached the problem from a multitude of perspectives, re˚ecting the many disciplines represented at the workshop and the involvement of academic, industry, and government researchers as practitioners. and because many participants were very engaged with the usabilitysecurityprivacy challenge, there was a natural temptation to explore possible solutions as well as fruitful research areas. the following sections summarize research directions that emerged from the questions posed to workshop participants and from breakout sessions, reports back from the breakout sessions, and plenary presentations and discussion. dimensions of usability, security, and privacydenitionsbreakout session participants spent a considerable amount of time grappling with how to dene usable security, working under the belief that one cannot improve something that cannot be measured and that one cannot measure something without a good denition for what one seeks to measure. indeed, denitions were discussed in every breakout toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 25session in some form, leading the committee to identify the need for better agreement on terminology and denitions as one of the four overarching research challenges at the intersection of usability, security, and privacy (see chapter 5).usability for whom?although usability is often equated with the experience of end users of it systemsšand this was indeed the focus of many presentations and discussions at the workshopšusability concerns for other groups were also discussed. notably, administrators of it systems also contend with systems that are difcult to understand and congure. the security or privacy consequences of a misconguration or other error by a system administrator can, of course, be much more serious and wider in scope than the consequences of an error of a single user. however, the line between administrator and end user is somewhat blurry because every home user is in effect the administrator of his or her own home network and the computers and other devices attached to it, which suggests that both system administrators and home users stand to benet from improvements aimed at either group. usability also matters for system developers. more usable tools would make it easier for them to avoid or detect design and coding errors that affect security and privacy. moreover, there is an opportunity to improve the usability and security of systems by introducing better usable security and privacy features to development environments and libraries. to what extent do demographic and cultural differences affect usability, security, and privacy? one particular question that came up repeatedly during the workshop was whether it was true that younger generations are more securitysavvy and less privacysensitive. a related question, assuming that younger users are less privacysensitive, was whether they would retain that perspective as they grew older.finally, participants cautioned that academic studies of usability are not necessarily representative of the user population. they typically employ small groups of college students, which re˚ects poor experimental design for two reasons: the group sizes are too small, and they are not drawn from a group that is representative of the broader population. companies can also make the same mistake with respect to usability studies used to test new services. is usability for security and privacy special?how might usability for security and privacy be distinct from the broader topic of usability of information technology? one difference of toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.26 toward better usability, securiy, and privacy of itpossible signicance is that security inherently involves an actor other than the useršthe active adversary who will try to take advantage of usability ˚aws and may also attempt to mislead the user through ﬁsocial engineering.ﬂ another is that security involves focusing the user™s attention not only on the task at hand but also on the future consequences and aftereffects of the task. yet another is that security is generally not the end user™s primary concern. further investigation of the similarities and differences might yield insights as to what lessons can be transferred directly from other usability work and where the issues are in fact different. metrics, evaluation criteria, and standardsmetricsšthat is, measures of how usable or secure a system isšare important to assessing progress (e.g., how much better is this system than another one?) and making rational decisions about investment (e.g., is this system ﬁgood enoughﬂ or is further investment in improvements warranted?). workshop participants observed that security has long resisted precise measurementšlet alone in combination with usability. that is, there are few good ways to determine the effectiveness or utility of any given security measure, and the development of metrics remains an open area of research.1 with respect to usability, participants noted a multitude of potentially relevant measures for usability (which might be measured in terms of user errors, time required to congure or modify a system, time to master a system, or user satisfaction ratings) and system effectiveness or utility. further research would help identify which of these measures, or what others, are most useful.related to metrics is the question of what criteria should be used in evaluating and accepting the usability and security of an it system and how one might go about certifying a system as aligning security, privacy, and usability. how might such criteria be instantiated as future guidelines? are there exemplar software applications that could be identied as benchmarks for security and usability and therefore serve as a source for creating a set of criteria for usable, yet secure, systems? several discussions considered how such criteria might vary accordingly to application, context, or perspective. for example, how might one divide applications into categories in which similar weights would be given to security and usability? despite the likely differences among the categories, might it be possible to develop a common checklist that contains a core set of usability and security criteria that would cover 80 percent of all applications? 1 for a detailed discussion of the challenges associated with cybersecurity metrics and possible research directions, see nrc, toward a safer and more secure cyberspace, 2007, pp. 133142.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 27workshop participants also grappled with the question of perspective. how might criteria for a usable and secure system differ for people in different roles, including system administrators, security professionals, system owners, end users, security designers, and developers?another question raised was whether compliance with usability and security standards might become a condition of connecting to enterprise or public networks. finally, with respect to the development of standards, it was observed that such efforts would be challenging today given the limited understanding of what constitutes a system that is usable and secure and that appropriately protects personal information. what would be required to develop useful standards? what organizations and institutions are best positioned to develop them?understanding userscentral to the topic of usability is a better understanding of users. an approach known as usercentered design addresses the needs, desires, and limitations of users. the related eld known as humancentered computing concerns information technology artifacts and their relationship to people. both approaches are informed by and depend on observation of human behavior. workshop presentations and discussions approached this topic from several perspectives: user mental models, risk perception and communication, and user incentives. (incentives, another important topic with respect to understanding users and their motivations, are considered separately below, because they also apply to other actors.)user mental modelsﬁmental modelsﬂ describe people™s thought processes and understanding. (a related term used by some speakers was ﬁuser metaphors.ﬂ) workshop participants suggested that work to understand and enhance models of security and privacy would be valuable.a rst research topic and logical starting point is to gain a better understanding of the mental models that people apply to security and privacy today. what are the best ways to elicit these current mental models? what do they tell us that could be used to make improvements in today™s systems and in the design of future systems? what specically do system designers and developers need to know about user mental models to design systems and applications that are usable yet secure?a second research topic is the development of better models that could be adopted in system design. for example, are there models for security or privacy that have the concreteness and usefulness of the nowfamiliar desktop and folder scheme? this nearly ubiquitous metaphor toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.28 toward better usability, securiy, and privacy of ithas been enormously successful in making computing accessible to a broad population. what abstractions might make security and privacy more usable?a third topic is how to deploy better modelsšthat is, how best to introduce new models to users and incorporate these new models in future system design. (this issue also relates to the topic of user education, discussed below.) one specic suggestion was that it might be useful to develop ﬁuser storiesﬂ describing appropriate use of it that highlights the importance of security and privacy. such user stories could be created after the development of a better understanding of how users make use of security indicators and interfaces. taking an epidemiological perspective, it would be useful to understand how many individual users™ mental models would have to be changed to make a noticeable impact in improving computer security ﬁfor the masses.ﬂa fourth topic is to study how well users understand their own user model. can they assess their technical prociency well enough to understand whether or not they are capable of making informed security decisions? one suggestion for how to assess this understanding is to compare the results of selfreporting with testing, to determine the prociency of different user types to make informed security decisions. risk perception and communicationdo people understand how secure (or insecure) their computers are? do they understand the concept of riskšthat is, the probabilities and consequencesšand the risks associated with particular actions? do people understand the implications for themselves and others of a lack of attention to security? do they understand the risks associated with system failure, disclosure of condential information, or the release of their private information? do people care less about damage to others if they themselves do not pay or incur damages for security breaches caused to others? what role does the information source play in getting users to change their behavior? what impact do disclosures about the use of personal information have on the use of security functionality? how might the literature on risk communication developed largely in other domains be applied and extended to enhancing security and privacy? how can what is known about how people understand and react to risk be used to induce them to do things that are good for them and for society?a closely related set of issues involve what languages and processes can best be used to communicate with users, including those within particular organizations as well as the general public. how can best practices be transferred to those who compose training materials, documentation, and user messages?toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 29learning about and from mistakesa number of comments at the workshop related to the importance of understanding users™ mistakes that play a role in security incidentsš mistakes that are often a direct result of usability problems. a better understanding of these mistakes could be fed back into better designs and better user education. one suggestion was to develop a taxonomy of human security errors and mistakes, which would help with identifying general classes of problems and thus a set of general solutions that would in˚uence behavior. a rst step would be to conduct a literature review and metaanalysis of past studies. participants noted that it is not easy to gather information on user mistakes. how does one get users to gure out that they have made mistakes? how can users be convinced to report mistakes (and how are the associated privacy issues to be dealt with)? how does one create an environment in which users are motivated to report errors (so that design and user education can be improved), yet maintain a culture of user accountability? what can be learned from the records that organizations (e.g., enterprises or internet service providers) keep about security incidents? it was also noted that individual users may have quite different denitions of what constitutes an error; there may be many security incidents in which the end user would not view something as an error even though others might. what are useful denitions for developers, managers, and users to adopt? user educationusers who better understand how to use systems and appreciate the security and privacy implications of their actions are better positioned to protect security and privacy. better education can help overcome usability challenges; however, workshop participants cautioned that an emphasis on education not be used as an excuse for not improving usability. one suggested area for research is to achieve a better understanding of the knowledge that users currently have and how they attained that knowledge. user education was also suggested as a way of in˚uencing values associated with security and privacy. how can one in˚uence norms for acceptable and/or appropriate behavior with respect to security and  privacy? how is a ﬁculture of securityﬂ to be created among different user groups? what can be learned from such elds as social psychology or social marketing? participants also suggested examining the limits of user education as a way of improving security and privacy. for example, to what extent is it valid to assert that ﬁif they understood why they are being inconvetoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.30 toward better usability, securiy, and privacy of itnienced, users would follow the directionsﬂ? the discussion of incentives, below, suggests that there are signicant limits. another limiting factor may be that security is generally not the end user™s primary concern.a nal set of questions relates to curriculum and institutionalizing education. what are core concepts that one should teach? how could user education best be incorporated into specic settings such as kindergarten through grade 12 education or employee training programs? how might user education be introduced into informal learning settings such as libraries? how might other informal learning techniques be usedštechniques such as videos that play while software is loading or online games that teach about security and privacy? under what circumstances should user education be mandated, and by whom?incentives for better security and privacymany workshop participants observed that incentives are an important force in shaping the behavior related to security and privacy. incentives can be applied to different actors. (for example, should the onus for security be placed on a home internet user or on that user™s isp or on both?) one might even consider how incentives apply to adversaries. (for example, if the cost of massscale attacks is increased, will adversaries instead conduct targeted attacks?) incentives can take both positive and negative forms. for example, employees can be given positive incentives through the use of awards for maintaining good security, or they can be given negative incentives through reprimands or poorer evaluations for security failures. in the marketplace, positive incentives might include favorable reviews of products with better security, whereas negative incentives would include liability for inadequate security or negative reports in the press. importantly, incentives for usability, security, and privacy are not necessarily aligned. to take a simple example, an employee who faces pressure to accomplish a task to meet a deadline may choose to sidestep security measures that slow his or her work. however, if a system administrator fears being sanctioned for a possible security breach, he or she may impose on user activity onerous restrictions that reduce usability. externalities play an important role in considering incentives. individuals can easily take steps that have little consequence for themselves but negatively affect many others. for example, household computer users do not face the cost of damage that poorly secured computers may have across the internet when those household users fail to take simple steps to prevent their computers from being infected. nor does an employee incur the total cost of allowing a virus to infect a corporate network. the result is that individual users will tend to pay less attention toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 31to security than is desirable from an organizational or societal perspective. how can the right incentives be created so that users choose a level of security that better protects everyone else? what fraction of such failures can be attributed to inadequate incentives, a lack of information, or the poor usability of today™s security tools?more generally, participants noted a misalignment of individual, corporate, and societal incentives. modern computer systems, especially in a network setting such as the internet, exhibit very signicant differences between the effects of an insecure computing environment on an individual and the effects on society. in particular, often each individual faces small negative consequences from a lack of security for his or her computer system, but when such a lack of security is widespread, the consequences are exponentially large negative effects, even catastrophic ones. the divergence between private and public incentives with respect to exerting effort to secure computing systems leads with mathematical certainty to a less secure it environment as computing systems become more interconnected and more complex, making better alignment of private and public incentives on security an important challenge for policy makers. with respect to incentives for businesses, participants asked where the money is in usable security. how might business models be adjusted to make usable security protable? how might regulatory models be adjusted to make unusable security less protable? they also pointed to a particular problem of users who continue to use systems even though their subscriptions to security updates have expired. are there viable business models in which security subscriptions never expire?behavioral aspects surfaced repeatedly in the workshop discussions, notably in the observation that sometimes individuals seem not to act in a fully rational way in protecting security. such seemingly irrational behavior can have multiple explanationsšactors not being well informed, actors considering a wider range of outcomes than have been anticipated by the system designer, or such ideas as ﬁbounded rationalityﬂ that have been developed in behavioral economics. finally, participants observed that it is hard to develop appropriate incentives when little is known about costs or impacts. for example, relatively little is known about the cost of identity theft or cybersecurity breaches. this is due in part to the inherent difculty in obtaining access to the relevant data. neither private rms nor the government is incentivized to share such data (see chapter 5). the ironic result is that it may be necessary to address the issue of incentives to share data in order to acquire a better understanding of how to increase incentives to enhance security and privacy. toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.32 toward better usability, securiy, and privacy of itapproaches to constructing systems with ﬁusable securityﬂautomationone specic approach to improving the usability of systems is to reduce the burden on the end user through automation. people may be more satised with systems when they have more control; but in the context of security, it may be that the more control allowed the user, the greater the opportunities for introducing vulnerabilities or security breaches. to what extent and when should usable security aim to automate security decision making and remove the human from the loop entirely, versus providing a more usable interface for the human to interact with? despite the appeal of taking the human out of the loop, participants cautioned that there are limits, because automation cannot handle unexpected, novel eventsšand the one thing that is known about such events is that they are certain to occur at some point.several specic ideas were proposed. one was to use machine learning from context to come up with an acceptable security policy for a user without the user™s directly having to adjust security or privacy parameters. another idea was to have a user establish policy by specifying desired outcomes and having the system express those outcomes as a set of security rules. the system would then verify that the rules derived from those outcomes are consistent and complete, and only ask the user for additional instructions in the event that they are not. research could help shed light on the feasibility of such approaches. authentication beyond passwordsmany participants noted the wellknown shortcomings of passwords with respect to security and usability. simply, the effort spent entering passwords and recovering or resetting them when they are forgotten was noted to be a signicant waste of time. passwords that are easy to remember are also easy to guess, but passwords that are hard to remember are more easily forgotten or subject to compromise if they are written. systems often require users to change passwords periodically, which may also lead to users™ writing them down or using guessable mnemonic schemes for generating their passwords. systems typically require their own passwords, often with con˚icting rules about acceptable user names and passwords, meaning that users must keep track of a wide array of credentials.alternatives that address these shortcomings have been developed. they are used for certain applications but have not enjoyed widespread support and use. these alternatives include hardware token authenticatoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 33tion, which provides stronger authentication than do passwords, and (primarily within enterprises) federationbased authentication schemes that free users from keeping track of multiple passwords. several barriers to these alternatives were mentioned, including a lack of awareness about alternatives, the cost of implementing a new approach, and the lack of offtheshelf ﬁdropinﬂ replacement technology. another barrier is the potential impact on privacy arising from the potential for the use of alternatives to link activities across multiple systems. several techniques have been proposed to reduce the likelihood of such linkage, but they may nonetheless be susceptible to determined attack.2 participants offered a number of open questions that research could address:ł what obstacles have been encountered to the deployment of alternatives to passwords? what can be learned from data and research collected by industry groups such as the openid foundation?ł what have been the barriers to the adoption of federationbased authentication schemes? would standardizing the rigor of systems used for authenticating help?ł suppose that authentication schemes were to be considered as they related to the needs of sets of users: how would one even begin to classify what the different sets of users are?ł there are populations of users that have already been issued strong authenticators (e.g., the federal government™s personal identity verication card and its predecessor, the common access card). what has prevented their use outside the workplace?ł suppose that users had a single authenticator that could be used universally. would they prefer to have that supplied by the government or by private industry? how aware and concerned are people about the potential for the linkage of activities across multiple systems? what approaches are best suited for preventing linkage across multiple systems, and what would it take for them to be widely deployed?processes and toolsparticipants suggested a number of development and management processes and tools that would help advance usable security and privacyšas well as associated research challenges:2 one commercial example of a technology for preventing the linking of visits across multiple parties that rely on a common identier is ﬁuprove,ﬂ offered by credentica, a rm recently purchased by microsoft. it relies on a zeroknowledge scheme developed by stefan brands and colleagues.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.34 toward better usability, securiy, and privacy of itł creating better developer support tools. guidelines, principles, and design patterns can all help support developers in building systems that provide usable security and privacy. research questions include how well usable security can be built into such elements as integrated development environments or libraries and how one would evaluate the effectiveness of support tools. ł dealing with dynamic threats that develop between design iterations. security threats involve adversaries who seek to exploit weaknessesšoften more rapidly than the typical designcycle time. how are threats to be dealt with that arise between typical design iterations? can the design process be sped up? ł making recovery more usable. recovery from security breaches, where the extent of the damage done may be difcult to determine, is a major challenge. how can recovery processes be made more secure and usable?ł simplifying user decisions. complexity impedes usability. how can one make the best use of such approaches as establishing useful bundles of security settings or secure default settings in order to reduce the burden on users?ł redesigning infrastructure. are there ways that key infrastructure such as the internet or operating systems (which can be difcult to change in major ways given their enormous installed base) might be redesigned to provide more usable security and privacy? how might barriers to making such changes be overcome?usability through the ﬁstackﬂcomputer systems are often thought of in terms of layersšfor example, the commonly used open system interconnection model for communications networks consists of the physical, data link, network, transport, session, and presentation layers. similarly, software runs on top of operating systems that provide abstractions for accessing computing, storage, and display resources. such layering hides details below each layer from the layers above. much of the work in usable security has focused on advances at the presentation layeršin user interfaces. but it was suggested at the workshop that one should consider whether changes to this conventional model might enhance usable security and privacy. participants suggested several questions regarding how these conventional abstractions might be reconsidered in order to enhance usable security and privacy. how ﬁfar down the stackﬂšthat is, how far down into the design of the underlying systemšis it necessary to go to provide usable security? toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.some potential research directions 35can one enhance usable security by tweaking the abstractions that are used today? what are possible improvements that might result from rethinking the abstractions? how might lower layers be redesigned to support metaphors that would improve usable security? what ambitious new usable security goals could be achieved by redesigning the stack?what information is needed from lower levels to interact with the user about security errors? how can the application developers at upper levels be helped to understand and use the security information from lower levels?what if the abstractions were to be changed, say from hosts in the network to user data? how would one express protocols in those terms? would this help with users™ control of their information? does moving the security abstractions to the data make them safer? how can a lifecycle view of user data be incorporatedšthat is, who can it be sent to, who can store it, how is it protected, and how is it controlled?other opportunities for improving systemspresentations and discussions advanced a number of specic opportunities for improving the usability, security, and privacy of it systems:ł distinguishing green and red machines. butler lampson™s talk (chapter 2) suggests enhancing security and privacy by using separate ﬁgreenﬂ and ﬁredﬂ machines for conducting activities that are safe and not safe. the green machine, used for important things, would demand accountability, whereas the red one would not. this approach immediately raises a usability question: how does a user readily identify green and red machines and understand their distinct purposes? more generally, what are the potential advantages of morespecialized machines, and what are the usability challenges associated with using multiple machines?ł ﬁscarlet letterﬂ option. is it helpful to inform users that they are interacting with a system or service that is following unsafe practices? what can be learned about the effectiveness of such capabilities that have been included in browsers and search engine result pages? how does one deal with the risk of spoong? how does one address the privacy issues introduced because the service identifying unsafe activities knows what systems or services the user is interacting with?ł building systems that assume worstcase scenarios. no matter how usable computer systems are, no matter how well users are trained and motivated, and no matter what precautions are taken, errors will occur and systems will be compromised. how should systems be built to cope with these inevitable problems?toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.36 toward better usability, securiy, and privacy of itł whitelisting versus blacklisting. whitelists (lists of approved entities) and blacklists (lists of prohibited entities) can both be used to authorize access or to grant privileges. in which cases does each approach provide better security and usability? toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.375overarching challenges to advancing research in usability, security, and privacyfour overarching challenges facing researchers working in the eld of usability, security, and privacy were apparent in the presentations and discussions at the workshop. although these challenges apply to many emerging research areas, they are particularly relevant to research on usability, security, and privacy.inconsistent terminology and definitions participants in the breakout sessions devoted considerable time and attention to terminology and denitions. ﬁusable securityﬂ was the term frequently used to capture the notion of security measures developed with attention to usability considerations. another commonly used term was ﬁhcisecﬂ (humancomputer interactionœsecurity). whatever the specic term used to describe the intersection of usability, security, and privacy, each participant tended to dene the area in relation to his or her own background. interestingly, usability practitioners tended to stress security issues, and security practitioners tended to stress usability issues. adding ﬁprivacyﬂ to the mix complicated matters still further, as denitions of privacy were frequently based on personal philosophies and experience, perhaps re˚ecting the deeply personal way in which many individuals approach privacy issues. moreover, some workshop participants noted that although some activities, such as the annual symposium on usable privacy and security mentioned above, explicitly call out both terms, neither ﬁusable securityﬂ nor ﬁhcisecﬂ explicitly invokes issues toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.38 toward better usability, securiy, and privacy of itrelated to privacy, despite the technical and policy links between the two concerns. some may immediately associate privacy issues with the term ﬁsecurity,ﬂ but this is not universally true. agreeing to a common denition or term that was inclusive of the concept of privacy proved challenging throughout the workshop. limited access to dataseveral workshop participants cited the need for more and better empirical data and commented on the difculties that they faced in gaining access to such data. for example, data on industry or government computer system security breaches are generally unavailablešcorporations are hesitant to disclose this information owing to the potential threat to reputation, stock price, and ongoing business; and information about breaches to government computer systems is frequently treated as sensitive or classied. even data on matters less touchy than security breaches cannot be readily obtained. participants noted, for example, the difculty in obtaining data on the productivity impacts of security measures. even when researchers are able to obtain data, nondisclosure agreements may restrict their ability to publish their results. if researchers do gain the ability to work with corporate data, an additional challenge is that of conducting research in a way that enables repeatability.scarceness of expertise and unfamiliarity with each other™s work at the intersection of usability, security, and privacymany of the workshop participants commented that working in the area of usability, security, and privacy is especially challenging because of the need for researchers who are familiar with both computer security and humancomputer interaction. these were, at least until recently, considered distinct disciplinesšmost security researchers have traditionally ignored usability issues, and vice versa (and likewise for usability and privacy). one consequence is unfamiliarity with each other™s work. throughout the workshop, there were frequent instances in which either a computer security or a usability expert would identify a research question outside his or her area of expertise, only to receive immediate feedback from relevant experts that this particular question had already been addressed. ﬁi did not know that that research existedﬂ was a common lament heard at the workshop. although this immediate feedback was useful to the workshop participants, it also suggests there may be a signicant lack of knowledge about usabilityrelated work among security researchers and toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.overarching challenges 39about securityrelated work among usability researchers (with a similar situation existing with respect to usability and privacy). another consequence pointed out by workshop participants is that valuable resources may be spent reresearching questions that are already well understood.still another consequence is that although a few interdisciplinary research collaborations have emerged, there remain few individuals in either area with sufcient expertise to identify their counterparts on the other sidešand fewer still with expertise in both areas. research funding at the intersection would foster the development of such expertise by training graduate students and attracting young faculty. toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendixestoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.43aworkshop agendausability, security, privacy of computer systems: a workshopjuly 21œ22, 2009 national academy of sciences, 2100 c st., n.w., washington, dcjuly 21, 20099:00 a.m. welcome nicholas economides ł introduction of committee members and provocateurs ł purpose and goals of workshop ł review workshop agenda ł logistical items9:30 framing the usability, security, and privacy research challenge butler lampson10:00 perspectives on current and prospective research security in virtual worlds frank l. greitzertoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.44 toward better usability, securiy, and privacy of it usable privacy lorrie faith cranor feeding practice back into research mary ellen zurko cybersecurity and insider threat deanna d. caputo creating a hierarchy of categories of user interactions  angela sasse framework of economic issues on usable security nicholas economides12:15 p.m. working lunch1:30  breakout sessions i how do we measure usable security? frank l. greitzer and charles p. p˚eeger, session leads approaches to usable security  lorrie faith cranor and don norman, session leads developing a ﬁusable securityﬂ standard butler lampson, session lead economic issues for usable security and policy changes nicholas economides and susan landau, session leads beyond phishing 1: improving systems james foley and simson garnkel, session leads3:00 break3:30  breakout sessions ii approaches to usable security lorrie faith cranor and don norman, session leads developing a ﬁusable securityﬂ standard butler lampson, session leadtoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix a 45 beyond phishing 2: alternatives to passwords simson garnkel and susan landau, session leads human factors and security incidents deanna d. caputo and charles p˚eeger, session leads usable security through the stack, its life cycle, and all its users angela sasse and mary ellen zurko, session leads report back from session leadsjuly 22, 20099:00 a.m. welcoming remarks nicholas economides9:30 moving from usability to understandability don norman, cofounder, nielsen norman group10:00 breakout sessions: identifying short and longterm research projects related to usability, security, and privacy of computer systems11:30 lunch1:00 p.m. session leads report back2:00 closing remarkstoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.46b workshop participantsalessandro acquisti, carnegie mellon universitygailjoon ahn, arizona state universitylujo bauer, carnegie mellon universityamy baylor, national science foundationrichard beckwith, intel corporationrichard beigel, national science foundationgenevieve bell, intel corporationsteven bellovin, columbia universitykonstantin beznosov, university of british columbiasameer bhalotra, senate select committee on intelligenceduane blackburn, ofce of science and technology policy, executive ofce of the president, the white housebob blakley, the burton groupmatt blaze, university of pennsylvaniarobert bohn, national coordination ofce for networking and information research and developmentroy boivin ii, it mastermindstanya brewer, national institute of standards and technologydesiree campbell, cigital federaldeanna caputo, mitre corporationbill cheswick, at&tyee yin choong, national institute of standards and technologydouglas e. comer, purdue universitygreg conti, ruminttoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix b 47alissa cooper, center for democracy and technologyearl crane, department of homeland securitylorrie faith cranor, carnegie mellon universityrenee crews, department of justiceanita d™amico, applied visionspatrick dempster, cscrachna dhamija, harvard universityroger dingledine, tor projectdonna dodson, national institute of standards and technologycathy dunaway, department of educationstephen duncan, general services administrationnicholas economides, new york universitykeith edwards, georgia institute of technologysherri eillis, department of transportationcarl ellison, microsoft corporationjeremy epstein, sri internationalnicholas feamster, georgia institute of technologyjames fisher, noblisheather foley, peace corpsjames foley, georgia institute of technologymyisha fraziermcelveen, citigroupjeffrey friedberg, microsoft corporationsimson garnkel, naval postgraduate schoolcarrie gates, computer associates international, inc.nathaniel good, palo alto research centerchris greer, national coordination ofce for networking and information research and developmentfrank greitzer, pacic northwest national laboratorywendy grossman, independent consultantlawrence hale, general services administrationgillian hayes, university of california, irvinemarty herman, national institute of standards and technologyhaym hirsh, national science foundationjason hong, carnegie mellon universitydarren kall, kall consultingjason kerben, department of statejoseph kielman, department of homeland securitylarry koved, ibmmike lake, ibmbutler lampson, microsoft corporationsusan landau, privacylink.orgcarl landwehr, ofce of the director of national intelligenceji sun lee, department of homeland securitytoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.48 toward better usability, securiy, and privacy of itrichard lempert, department of homeland securitybill lewis, united states navysusan lightman, executive ofce of the presidentpatrick lincoln, sri internationalroy maxion, carnegie mellon universityernest mcdufe, national coordination ofce for networking and information research and developmentgary mcgraw, cigital federalross micheals, national institute of standards and technologyrichard morris, national institutes of healthpat muoio, ofce of the director of national intelligence/science and technologyelaine newton, national institute of standards and technologybrand niemann, environmental protection agencydonald norman, nielsen norman grouplucy nowell, department of energyjennifer o™connor, department of homeland securityandrew patrick, carleton universityhetel petel, peace corpscharles p˚eeger, p˚eeger consultingshari lawrence p˚eeger, rand corporationgary phillips, symantecwalt polansky, department of energyjules polonestky, future of privacy forumrob reeder, microsoft corporationholly rensvold, department of homeland securitytom rhodes, national institute of standards and technologymarc rogers, purdue universitycharles romine, national institute of standards and technologymarc rotenberg, electronic privacy information centernorman sadeh, carnegie mellon universityangela sasse, university college londonstuart schechter, microsoft corporationdiane smetters, palo alto research centerdarren smith, national oceanic and atmospheric administrationjim sorace, department of health and human servicessylvia spengler, national science foundationbrian stanton, national institute of standards and technologytim stanton, naval postgraduate schooljoe steele, adobe systemsbrock stevenson, department of justicemichael sulak, department of statedenise tayloe, privotoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix b 49mary theofanos, national institute of standards and technologyjoseph trella, truestonev.n. venkatakrishnan, university of illinois at chicagodaniel weitzner, massachusetts institute of technologygeoff willcher, bellevue collegejeannette wing, national science foundationirene wu, federal communications commissionlenore zuck, national science foundationmary ellen zurko, ibmtoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.50cbiosketches of steering committee members and staffnicholas economides, chair, is a professor of economics at the stern school of business at new york university. he is an internationally recognized academic authority on network economics, electronic commerce, and public policy. his elds of specialization and research include the economics of networks, especially of telecommunications, computers, and information; the economics of technical compatibility and standardization; industrial organization; the structure and organization of nancial markets and payment systems; antitrust; application of public policy to network industries; strategic analysis of markets; and law and economics. professor economides has published more than 100 articles in top academic journals in the areas of networks, telecommunications, oligopoly, antitrust, and product positioning, and on the liquidity and the organization of nancial markets and exchanges. he is editor of information economics and policy, netnomics, quarterly journal of electronic commerce, journal of financial transformation, and journal of network industries; he is on the advisory board of the social science research network, editor of economics of networks abstracts by ssrn, and former editor of the international journal of industrial organization. his web site on the economics of networks has been ranked as one of the top four economics sites worldwide by the economist magazine. professor economides is the executive director of the net institute, http://www.netinst.org, a worldwide focal point for research on the economics of network and hightechnology industries. he is an adviser to the u.s. federal trade commission; the governments of greece, ireland, new zealand, and portugal; the attorney toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix c 51general of new york state; major telecommunications corporations; a number of the federal reserve banks; the bank of greece; and major financial exchanges. he serves on the advisory board of the economist intelligence unit. he has commented extensively in broadcast and in print on hightechnology, antitrust, and public policy issues. previously, he taught at columbia university (19811988) and at stanford university (19881990). he holds a phd and ma in economics from the university of california at berkeley, as well as a bsc (first class honors) in mathematical economics from the london school of economics.lorrie faith cranor is an associate professor of computer science and of engineering and public policy at carnegie mellon university, where she is the director of the cylab usable privacy and security laboratory (cups). she is also chief scientist of wombat security technologies, inc. she has authored more than 80 research papers on online privacy, phishing and semantic attacks, spam, electronic voting, anonymous publishing, usable access control, and other topics. she has played a key role in building the usable privacy and security research community, having coedited the seminal book security and usability (o™reilly, 2005) and founded the symposium on usable privacy and security (soups). she also chaired the platform for privacy preferences project (p3p) specication working group at the w3c and authored the book web privacy with p3p (o™reilly, 2002). she has served on a number of boards, including the electronic frontier foundation board of directors, and on the editorial boards of several journals. in 2003, she was named one of the top 100 innovators 35 or younger by technology review magazine. she was previously a researcher at at&tlabs research and taught in the stern school of business at new york university. dr. cranor received her doctorate degree in engineering and policy from washington university in st. louis in 1996.james d. foley is a professor in the college of computing, and a professor in the school of electrical and computer engineering at the georgia institute of technology (georgia tech). a leading international gure in two major disciplines of computer science (graphics and humancomputer interaction), dr. foley has received lifetime achievement awards in both elds from the association for computer machinery™s special interest groups (siggraph in 1997 and sigchi in 2007). dr. foley was one of the computer graphics pioneers who went on to help establish hci as a discipline. the coauthor of three books, he is the rst author of what many consider the denitive text in computer graphics, fundamentals of interactive computer graphics, which has sold 400,000 copies in 10 translations. dr. foley arrived at the college of computing in 1991 and founded the gvu center. four years later, u.s. news and world report ranked the toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.52 toward better usability, securiy, and privacy of itcenter no. 1 for graduate computer science work in graphics and user interaction. active in industry, dr. foley became the director of merl (mitsubishi electric research laboratory) in 1996 and then ceo and chair of mitsubishi electric information technology center america in 1998. he returned to georgia in late 1999 to head up the state™s yamacraw economic development initiative in the design of broadband systems, devices, and chips. for 4 years (20012005), dr. foley chaired the computing research association (cra), which represents more than 200 research universities, corporate research laboratories, and professional societies. in february 2008, he was elected to the national academy of engineering. a few months later, he received the 2008 class of 1934 distinguished professor award, the highest honor that georgia tech bestows on faculty. of all his awards, dr. foley says that he most treasures the one given him by computing graduate students who named him ﬁmost likely to make students want to grow up to be professors.ﬂ simson l. garnkel is an associate professor at the naval postgraduate school in monterey, california, and an associate of the school of engineering and applied sciences at harvard university. his research interests include computer forensics, the emerging eld of usability and security, personal information management, privacy, information policy, and terrorism. dr. garnkel is the author or coauthor of 14 books on computing. he is perhaps best known for his book database nation: the death of privacy in the 21st century. his most successful book, practical unix and internet security (coauthored with gene spafford), has sold more than 250,000 copies and has been translated into more than a dozen languages since the rst edition was published in 1991. dr. garnkel received three bachelor of science degrees from the massachusetts institute of technology (mit) in 1987, a master of science in journalism from columbia university in 1988, and a phd in computer science from mit in 2005. butler w. lampson is a technical fellow at microsoft corporation and an adjunct professor of computer science and electrical engineering at mit. he was on the faculty at the university of california, berkeley, and then at the computer science laboratory at xerox parc and at digital systems research center. he has worked on computer architecture, local area networks, raster printers, page description languages, operating systems, remote procedure call, programming languages and their semantics, programming in the large, faulttolerant computing, transaction processing, computer security, wysiwyg editors, and tablet computers. he was one of the designers of the sds 940 timesharing system, the alto personal distributed computing system, the xerox 9700 laser printer, twophase comtoward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix c 53mit protocols, the autonet local area network, the sdsi/spki system for network security, the microsoft tablet personal computer (pc) software, the microsoft palladium highassurance stack, and several programming languages. he holds a number of patents on networks, security, raster printing, and transaction processing. at microsoft he has worked on antipiracy, security, faulttolerance, and user interfaces. he was one of the designers of palladium and spent 2 years as an architect in the tablet pc group. currently he is in microsoft research, working on security, privacy, and faulttolerance, and kibitzing in systems, networking, and other areas. he is a member of the national academy of sciences and the national academy of engineering and a fellow of the association for computing machinery and the american academy of arts and sciences. he also served on the computer science and telecommunications board of the national research council. he received an ab from harvard university, a phd in eecs from the university of california at berkeley, and honorary scd™s from the eidgenössische technische hochschule, zurich, and the university of bologna.  susan landau is a fellow at the radcliffe institute for advanced study during the academic year 20102011. she recently completed a book on security risks of building surveillance into communications infrastructures (to be published by mit press in the spring of 2011). from 1999 to 2010 dr. landau was a distinguished engineer at sun microsystems; there she concentrated on the interplay between security and public policy. she has briefed government ofcials both in washington, d.c., and in europe on such disparate issues as security risks in surveillance mechanisms, digital rights management, and cryptographic export control; she has written numerous articles and oped pieces on these issues. most recently she testied for the house science committee on cybersecurity activities at the national institute of standards and technology™s (nist™s) information technology laboratory. she and whiteld dife wrote privacy on the line: the politics of wiretapping and encryption. dr. landau is a member of the commission on cyber security for the 44th presidency, established by the center for strategic and international studies, and serves on the computer science and telecommunications board of the national research council and on the advisory committee for the national science foundation™s directorate for computer and information science and engineering. before joining sun, dr. landau was a faculty member at the university of massachusetts and at wesleyan university. she is the recipient of the 2008 women of vision social impact award, a fellow of the american association for the advancement of science, and an acm distinguished engineer.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.54 toward better usability, securiy, and privacy of itdonald a. norman is the breed professor of design at northwestern university where he codirects mmm, the dualdegree mba and engineering program offered jointly by northwestern™s schools of management and engineering that focuses on managing products and services from design to execution. he is also codirector of the segal design institute. he is distinguished visiting professor at kaist, the korea advanced institute of science and technology, in the department of industrial design. he is cofounder of the nielsen norman group and has been vice president of apple computer and an executive at hewlett packard. he serves on many advisory boards, such as the editorial advisory board of  encyclopedia britannica and kaist. he has received honorary degrees from the university of padova (italy) and the technical university of delft (the  netherlands), the ﬁlifetime achievement awardﬂ from sigchi, the professional organization for computerhuman interaction, and the benjamin franklin medal in computer and cognitive science from the franklin institute (philadelphia). he is well known for his books the design of everyday things and emotional design. his most recent book, the design of future things, discusses the role that automation plays in such everyday places as the home and the automobile. he is currently working on a new book called sociable design that combines the lessons of his previous works, extending them to cover social networks and social interaction. he earned a phd in psychology from the university of pennsylvania.charles p. p˚eeger is an independent consultant for p˚eeger consulting group specializing in computer and information system security. among his responsibilities are threat and vulnerability analysis, system design review, certication preparation, training, expert witness testimony, and general security advice. his customers include government and commercial clients throughout the world. dr. p˚eeger was previously a master security architect on the staff of the chief security ofcer of cable and wireless, and exodus communications, and before that he was a senior computer scientist and director of research for arca systems, director of european operations for trusted information systems, inc. (tis), and a professor in the computer science department of the university of tennessee. dr. p˚eeger was chair of the ieee computer society technical committee on security and privacy from 1997 to 1999 and has been a member of the executive council of that committee since 1995. he is on the board of reviewers for computers and security, is a book review editor for ieee security and privacy, and is on the board of advisers for owasp, the open web application security project. dr. p˚eeger has lectured throughout the world and published numerous papers and books. his book security in computing (of which the fourth editionšcoauthored with dr. shari lawrence p˚eegeršwas published in october 2006) is the toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.appendix c 55standard college textbook in computer security. he is the author of other books and articles on technical computer security and computer science topics. he holds a phd degree in computer science from pennsylvania state university and a ba with honors in mathematics from ohio wesleyan university. he is a certied information systems security professional (cissp). cstb staffjon eisenberg is director of the computer science and telecommunications board of the national research council. he has also been study director for a diverse body of work, including a series of studies exploring internet and broadband policy and networking and communications technologies. in 19951997 he was a aaas (american association for the advancement of science) science, engineering, and diplomacy fellow at the u.s. agency for international development, where he worked on technology transfer and information and telecommunications policy issues. dr. eisenberg received his phd in physics from the university of washington in 1996 and a bs in physics with honors from the university of massachusetts at amherst in 1988.shenae bradley is a senior program assistant at the computer science and telecommunications board of the national research council. she currently provides support for the committee on sustaining growth in computing performance, the committee on wireless technology prospects and policy options, and the computational thinking for everyone: a workshop series planning committee, to name a few. prior to this, she served as an administrative assistant for the ironworker management progressive action cooperative trust and managed a number of apartment rental communities for edgewood management corporation in the maryland/dc/delaware metropolitan areas. ms. bradley is in the process of earning her bs in family studies from the university of maryland at college park.toward better usability, security, and privacy of information technology: report of a workshopcopyright national academy of sciences. all rights reserved.