detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/5780more than screen deep: toward everycitizen interfaces tothe nation's information infrastructure448 pages | 6 x 9 | paperbackisbn 9780309063579 | doi 10.17226/5780toward an everycitizen interface to the nii steering committee, nationalresearch councilmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.prefaceitoward everycitizen interfaces to thenationõs information infrastructuretoward an everycitizen interface to the nationõs informationinfrastructure steering committeecomputer science and telecommunications boardcommission on physical sciences, mathematics, and applicationsnational research councilnational academy presswashington, d.c. 1997more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.notice: the project that is the subject of this report was approved by the governing boardof the national research council, whose members are drawn from the councils of thenational academy of sciences, the national academy of engineering, and the institute ofmedicine. the members of the committee responsible for the report were chosen for theirspecial competences and with regard for appropriate balance.this report has been reviewed by a group other than the authors according to procedures approved by a report review committee consisting of members of the nationalacademy of sciences, the national academy of engineering, and the institute of medicine.support for this project was provided by the national science foundation under grantno. iri9529473. any opinions, findings, conclusions, or recommendations expressed inthis material are those of the authors and do not necessarily reflect the views of the nationalscience foundation.library of congress cataloginginpublication datamore than screen deep : toward everycitizen interfaces to thenationõs information infrastructure / toward an everycitizeninterface to the nationõs information infrastructure steeringcommittee, computer science and telecommunications board, commissionon physical sciences, mathematics, and applications, nationalresearch council.p. cm.summary report from a workshop held in august 1996.includes bibliographical references.isbn 0309063574 (pbk. : acidfree paper)1. user interfaces (computer systems)ñcongresses. 2. humancomputer interactionñcongresses. 3. information superhighwayñunited statesñcongresses. i. national research council (u.s.).toward an everycitizen interface to the nationõs informationinfrastructure steering committee.qa76.9.u83m67 1997303.483ñdc219721211additional copies of this report are available from national academy press, 2101 constitution avenue, n.w., lockbox 285, washington, d.c. 20055; (800)6246242 or (202)3343313(in the washington metropolitan area); internet, http://www.nap.educopyright 1997 by the national academy of sciences. all rights reserved.printed in the united states of americamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.iiitoward an everycitizen interface to the nationõsinformation infrastructure steering committeealan w. biermann, duke university, chairtora bikson, rand corporationthomas defanti, university of illinois at chicagogerhard fischer, university of coloradobarbara j. grosz, harvard universitythomas landauer, university of coloradojohn makhoul, bbn corporationbruce tognazzini, healtheon corporationgregg vanderheiden, university of wisconsinstephen weinstein, nec america inc.staffmarjory s. blumenthal, directorjohn m. godfrey, research associate (until january 31, 1997)gail e. pritchard, project assistant (until december 13, 1996)synod boyd, project assistant (from may 21, 1997)more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.ivprefaceivcomputer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chairfrances e. allen, ibm t.j. watson research centerjeff dozier, university of california at santa barbarasusan l. graham, university of california at berkeleyjames gray, microsoft corporationbarbara j. grosz, harvard universitypatrick hanrahan, stanford universityjudith hempel, university of california at san franciscodeborah a. joseph, university of wisconsinbutler w. lampson, microsoft corporationedward d. lazowska, university of washingtonbarbara h. liskov, massachusetts institute of technologyjohn major, qualcomm inc.robert l. martin, at&t network systemsdavid g. messerschmitt, university of california at berkeleycharles l. seitz, myricom inc.donald simborg, knowmed systems inc.leslie l. vadasz, intel corporationmarjory s. blumenthal, directorherbert s. lin, senior staff officerjerry r. sheehan, staff officerjulie lee, administrative assistantsynod boyd, project assistantlisa l. shum, project assistantmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.prefacevvcommission on physical sciences, mathematics,and applicationsrobert j. hermann, united technologies corporation, cochairw. carl lineberger, university of colorado, cochairpeter m. banks, environmental research institute of michiganlawrence d. brown, university of pennsylvaniaronald g. douglas, texas a&m universityjohn e. estes, university of california at santa barbaral. louis hegedus, elf atochem north america inc.john e. hopcroft, cornell universityrhonda j. hughes, bryn mawr collegeshirley a. jackson, u.s. nuclear regulatory commissionkenneth h. keller, university of minnesotakenneth i. kellermann, national radio astronomy observatorymargaret g. kivelson, university of california at los angelesdaniel kleppner, massachusetts institute of technologyjohn kreick, sanders, a lockheed martin companymarsha i. lester, university of pennsylvaniathomas a. prince, california institute of technologynicholas p. samios, brookhaven national laboratoryl.e. scriven, university of minnesotashmuel winograd, ibm t.j. watson research centercharles a. zraket, mitre corporation (retired)norman metzger, executive directormore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technologyand to their use for the general welfare. upon the authority of the chartergranted to it by the congress in 1863, the academy has a mandate thatrequires it to advise the federal government on scientific and technicalmatters. dr. bruce alberts is president of the national academy of sciences.the national academy of engineering was established in 1964, underthe charter of the national academy of sciences, as a parallel organization of outstanding engineers. it is autonomous in its administration andin the selection of its members, sharing with the national academy ofsciences the responsibility for advising the federal government. the national academy of engineering also sponsors engineering programsaimed at meeting national needs, encourages education and research, andrecognizes the superior achievements of engineers. dr. william a. wulfis president of the national academy of engineering.the institute of medicine was established in 1970 by the nationalacademy of sciences to secure the services of eminent members of appropriate professions in the examination of policy matters pertaining to thehealth of the public. the institute acts under the responsibility given tothe national academy of sciences by its congressional charter to be anadviser to the federal government and, upon its own initiative, to identifyissues of medical care, research, and education. dr. kenneth i. shine ispresident of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science andtechnology with the academyõs purposes of furthering knowledge andadvising the federal government. functioning in accordance with generalpolicies determined by the academy, the council has become the principal operating agency of both the national academy of sciences and thenational academy of engineering in providing services to the government, the public, and the scientific and engineering communities. thecouncil is administered jointly by both academies and the institute ofmedicine. dr. bruce alberts and dr. william a. wulf are chairman andvice chairman, respectively, of the national research council.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.viithe spread of information systems and, in particular, informationinfrastructure throughout the economy and social fabric raises questionsabout the technologyõs ease of use by different people, from those withlimited technical knowhow to those with various disabilities to the socalled power users who push for higher performance on many dimensions. in response to a request from the national science foundation, thecomputer science and telecommunications board (cstb) of the nationalresearch council convened a steering committee to evaluate and suggestfruitful directions for progress in user interfaces to computing and communications systems. the charge to the steering committee is best presented by quoting from the project prospectus, which called for a workshop to òdetermine the stateoftheart of research in cs [computerscience] and other disciplines, identify the questions most important toinvestigate next . . . , identify what is known from research on the longerterm problems that will aid in nearterm humancomputer communications design, and identify important longterm research issues.ó the steering committee met in march 1996 to plan a twoday workshop that washeld in august 1996 (the agenda and participants are listed in appendixa) and then met again in september 1996 to plan the structure and formatof this summary report. it relied primarily on electronic mail for itssubsequent interactions, including electronic mail with the larger set ofworkshop participants.the workshop participants, like the steering committee, included experts from multiple disciplinesñcomputing and communications softprefacemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.viiiprefaceware and hardware, psychology, sociology, human factors, design, andeconomicsñand experts experienced with applications in specific domains (e.g., health and education) and with the needs and experiences ofa wide range of subpopulations (e.g., people with physical disabilities;those with lowincome and/or limited education). whether from a computer science, social science, or applicationdomain perspective, all hadexperience working with a variety of computing and communicationssystem users, and all were asked to draw on their practical experience. itwas anticipated that viewing earlier, more technically focused treatmentsof user interfaces through the lens of a familiar life domain would revealneglected issues, unidentified challenges, unexpected convergences, ornew directions for research or action. the participants pooled their skillsto make suggestions concerning how to build interfaces that will enablethe broadestpossible spectrum of citizenry to interact easily and effectively with the nationõs information infrastructure to obtain as many services as is reasonable.the workshop demonstrated the value of assembling a very diversegroup of experts embodying many complementary perspectives; it alsodemonstrated how differently people in different disciplinesñor peoplewith different subspecialties within a given disciplineñperceive, analyze,and discuss the experiences and needs of users of computing and communications systems. that recognition implies that the workshop should beseen as part of a process of interdisciplinary convening and exchange thatshould continue. that process may require special effort and encouragement through activities like the one responsible for this report.the role of the steering committee was not only to organize the workshop but also to sift through the many inputs to distill key themes, ideas,and recommendations. the results compose part i of the present report,which is a synthesis and distillation primarily of workshoprelated inputsand which focuses on research opportunities. its contribution lies in itsintegration of a very diverse set of perspectives to illuminate directionsfor research, with emphasis on directions that blend multiple disciplines.part i does not purport to be a comprehensive treatise on either userinterfaces or the entire set of problems inherent in the challenge of broadening public access to the national information infrastructure (nii), nordoes it focus on the important subset of problems associated with niiapplications in support of the rights and responsibilities of citizenship.for those seeking more detail and a mapping of ideas to sources, positionpapers contributed by workshop participants (several containing bibliographies) are included in part ii. additional position papers can be foundon the world wide web at http://www2.nas.edu/cstbweb).the steering committee is grateful to the many people who contributed to its deliberations and to this report. the workshop participantsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.prefaceixgenerated a lively set of discussions and commented on early drafts derived from panel discussions. the steering committee is particularlygrateful to those who also contributed position statements (see part ii),brief outlines of the state of the art in specific areas (distributed with theworkshop program to participants), and comments on a draft of this report. h. rex hartson (virginia polytechnic institute), who was unable toattend the workshop, generously supplied a special overview of the userinterface landscape, which is the lead segment of part ii. terry winograd(stanford university), ben shneiderman (university of maryland), andnathan shedroff (vivid studios), who were also unable to attend, provided position papers.several workshop participants and a few individuals with no formalparticipation in the project provided extraordinary inputs to this report.austin henderson (apple computer) made significant contributions tothe committeeõs thinking about collaboration and information dimensions.johanna moore (university of pittsburgh) assisted in the revision of thediscussion on agent technology by collecting input from other participants and integrating it with her own suggestions. candace sidner (lotus development corporation) and c. raymond perrault (sri international) contributed additional insights, references, and text describingnatural language understanding and processing. blake hannaford (university of washington) contributed text describing commercial and research trends relating to haptic and tactile interfaces, and david warner(syracuse university) provided input on medical applications for suchtechnology. julia hirschberg (at&t research laboratories) and pierreisabelle (center for information technology innovation) provided stateoftheart reviews for texttospeech synthesis and machine translation,respectively. jason leigh (university of illinois at chicago) supplied asubstantial part of the graphics and virtual reality reference list.commercenet (http://www.commerce.net) and nielsen media research(http://www. nielsenmedia.com/commercenet) generously provided results of their internet demographics survey. michael north (north communications) and marc regberg (venture development corporation) supplied reference materials on kiosks and their uses. david crocker(brandenburg consulting) created an electronic mail discussion list thatsupported postworkshop exchanges by the workshop participants andthe steering committee.the anonymous reviewers of this report provided an invaluable, ifsometimes confounding, sanity check on the steering committeeõs earlyefforts to synthesize its impressions and conclusions. the range of comments, criticisms, and suggestions was as broad as the other inputs to theproject, but collectively they guided the steering committee in tighteningand reinforcing its presentation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.xprefacejohn godfrey, a cstb research associate until february 1997, putconsiderable effort into organizing the workshop and working with thesteering committee as it developed this report. rob cheng, a graduatestudent at the massachussetts institute of technology, prepared background research and other materials for the workshop as a summer internwith cstb. finally, the committee thanks gary strong, of the nationalscience foundation, for both making this project possible and providingongoing encouragement.alan w. biermann, chairtoward an everycitizen interface to thenationõs information infrastructuresteering committeemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.prefacexixicontentsexecutive summary1part i1introduction92requirements for effective everycitizen interfaces213input/output technologies: current status andresearch needs714design and evaluation1215communication and collaboration1546agents and systems intelligence1807conclusions and recommendations192bibliography198part iibackground papertrends in humancomputer interaction researchand development221h. rex hartson, virginia polytechnic institutemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.xiicontentsposition paperson interface specificsan embedded, invisible everycitizen interface243mark weiser, xerox palo alto research centerintelligent multimedia interfaces for òeachó citizen246mark t. maybury, mitre corporationinterfaces for understanding252nathan shedroff, vivid studiosinterspace and an everycitizen interface to the nationalinformation infrastructure260terry winograd, stanford universitymobile access to the nationõs information infrastructure265daniel p. siewiorek, carnegie mellon universityordinary citizens and the national informationinfrastructure271bruce tognazzini, healtheon corporationspokenlanguage technology279ronald a. cole, oregon graduate institute of science andtechnologytoward an everycitizen interface284steven k. feiner, columbia universitynomadicity, disability access, and the everycitizeninterface297gregg c. vanderheiden, university of wisconsinmadisonon functionscomputermediated collaboration307loren terveen, at&t researchcreating interfaces founded on principles of discoursecommunication and collaboration315candace sidner, lotus development corporationdigital maps322lance mckee and louis hecht, open gis consortium inc.gathering and integrating information in the nationalinformation infrastructure330craig a. knoblock, university of southern californiamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.integrating audiences and users334john richards, turner le@rning inc.intelligent agents for information341katia p. sycara, carnegie mellon universityintelligent information agents345johanna d. moore, university of pittsburghresource discovery and resource delivery354kent wittenburg, bellcoresearch and publishing359robert a. virzi, gte laboratories incorporatedsecurity363stephen kent, bbn corporationresearch to support widespread access to digitallibraries and government information and services372ben shneiderman, university of marylandon application areascommunity computing projects375aki helen namioka, computer professionals forsocial responsibilitylifelong learning382gerhard fischer, university of colorado, bouldersupporting learning in communities of practice389charles cleary, northwestern universityon selected population groupsextending knowledge access to underserved citizens395wallace feurzeig, bbn systems and technologieselectronic access to services for lowincome populations403adam porter, university of marylandaccess for people with disabilities407larry goldberg, wgbh educational foundationcontentsxiiimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.xivprefaceon key processescrossdisciplinary, socialcontext research411john leslie king, university of california, irvineaudio access to the national information infrastructure417john c. thomas, nynex science and technologyappendixesaworkshop agenda and participants425bsteering committee membersõ biographies429xivcontentsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary11interfaces for everyonecomputing, communications technologies, and associated enterprisesadvanced enough in the early 1990s for the national information infrastructure (nii) to be accepted as public infrastructure. as a result, concern is growing about what will be required to enable most if not all of thepublic to use nii resources. the opportunity for broad public access anduse reflects many factors, among them the technologies used directly bypeople as part of their interactions with the information and communications systems that make up the nii. this report outlines issues and directions for progress in developing interface technologies that will enable increasing numbers of people to use the nii effectively. drawing from a late1996 workshop hosted by the computer science and telecommunicationsboard, the steering committee responsible for this project derived ideas forresearch in computing, communications, and social science to advance theunderlying sciences and enable development of innovative, implementableconcepts for interfaces that are more usable and capable than todayõs technologies and are accessible by as many people as possible.the nii is dominated by computing and communications systems,and the humanmachine or user interface represents the means by whichpeople communicate with a particular system and the machines andpeople connected to it. in this report such technologies are referred to aseverycitizen interfaces (ecis), reflecting the projectõs mission to examinewhat might be required for every citizen to be able to use the resourcesposition papersexecutive summarymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.2more than screen deepavailable through the nii. ecis are defined broadly as including inputand output hardware and software as well as design and performancecharacteristics of applicationsñsuch as ease and speed of communicationñthat influence the overall experience of a person or group of peopleworking in a system. the concern of the study is that, even though theusability of systems has improved substantially over many years, currentinterfaces still exclude many people from effective nii access. most obvious are individuals with physical and other disabilities, but as articles ineven the national and business press attest, people without such distinguishing characteristics, even expert users of nii systems, experience difficulties that constrain or even preclude their full use of nii resources.the steering committee emphasizes that effective technological research on and development of ecis must be grounded in a wellconsidered understanding of the needs and behavior of people. achieving ecisis thus an interdisciplinary endeavor involving computingrelated science and engineering disciplines as well as social science disciplines.progress toward developing improved ecis will require basic research intheory, modeling, and conceptualization; experimental research involving building, evaluating, and testing of artifacts; and empirical social science research assessing segments of the population and how people actually work with different systems. in all cases, data, methodology, andtools are themselves targets for research or research support.certainly, however, the needed ecirelated research discussed in thisreport accounts for only part of the challenge of making nii resourcesbroadly accessible. policies aimed at promoting universal access to thenii must be developed that address economic factors, such as a personõsability to pay for communication and information services and accessdevices, as well as social and psychological factors, such as organizational, family, and peer group support, and personal preferences. although the importance of such factors is clear, examination of them isbeyond the scope of this report, which focuses primarily on issues relatedto computing, information, and communications technologies.technologies for humanmachine communicationby every citizenat this time and for the foreseeable future, enlarging the set of options for humanmachine communication, not replacing older technologies with new per se, is a broad goal for eci research. making a full rangeof options available involves continued improvements in mainstream interface technologies, such as graphical direct manipulation interfaces andtyped and menuselected command line interfaces, as well as research onmodes that are currently not widely available. recent advances in themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary3performance and the commercial deployment of speech recognition andnatural language processing technologies, for example, indicate theirpromise for future interfaces. in the last several years, progress in research and in the development of commercial products points to credibleprospects for software agents as aids to ordinary citizens. major progressin virtual reality technologies and threedimensional user interfaces generally suggests their nearterm availability. a variety of ideas are beinggenerated for collaboration and communications technologies. other options such as gesture recognition, pointing devices, and haptic devices arebeing proposed and in some cases developed and installed. together,these technologies provide a rich set of opportunities to create new humanmachine interface paradigms for the coming years.just as the nii is more than a single entity, so also will ecis be diverseand varied. no single interface can be used by absolutely everyone,because people differ in ways relevant to the design of the technologiesthey use and because for a given person the activities and conditions ofuse for technologies vary: graphical user interfaces are problematic forblind people and also for people driving cars, for example. experts whohave concentrated on meeting the needs of users with specific limitationshave discovered not only that it is possible to achieve adaptations ofconventional interfaces to suit those users (giving rise to prototypes andcommercial systems), but also that such adaptations often prove attractive and useful to many others. such experiences underscore the value ofmedium and modality independence for future ecis. research and experience with real systems show that crossdisability access is compatiblewith diversity in the look and feel of an interface and that providing for itdoes not imply compromising capabilities that are useful to people without disabilities. in the language of this project, aiming for use by everycitizen can enhance use by ordinary citizens. even the seemingly ordinary are heterogeneous: the general population varies greatly in computer skills (e.g., from novice to expert); in the ability to speak, read, andwrite english; in personal cognitive styles (e.g., from linguistic/verbal tospatial/visual); and in personal propensity for using complex technological gadgets.other motivations for ensuring the versatility and adaptability of userinterface technologies in the nii context include the desirability of achieving nomadicity, the ability of people to use the nii effectively regardless oftheir location, and the quality of available computing or communicationsequipment and services, which may vary depending on whether users areon the road, in the office, or en route between locations. another morecommercial motivation for emphasizing versatile and adaptable interfacing is the drive by relevant businesses to produce massmarket technologies. although in the early 1990s popular discussions of the nii focusedmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.4more than screen deepon the use of personal computers (pcs) and the internet as an nii component, more recent experiences with commercialization and public acceptance are leading to a broader view in the late 1990s of an nii accessed bypcs, telephones, televisions, and a myriad of consumer electronics andother devices. some of these devices have primary purposes other thancomputing and communications but incorporate embedded systems thatallow for connection with networked infrastructure and therefore integration with other computing and communications systems. this diversification further broadens the range of people, activities, and environments thatcan be supported by the nii and thus represents one of the requirementsfor effective ecis; it underscores the value of certain kinds of research, suchas research and development to lower costs or foster compatibility. takentogether, the evolving set of motivations for facilitating humanmachinecommunication gives rise to a range of eci desiderata: flexibility, adaptability, ease of learning, compatibility, affordability, and so on.synthesizing a research agendaan important starting point in building a research agenda is to askwhat peopleõs computing, communication, and information needs arewith respect to the nii and how these needs can be met. this approachinvolves studying people doing ordinary tasks with and without technological aids and asking how new technologies might improve the process.it can also include gathering data from existing applications as input toguide new designs. proposed systems can then be simulated or built inprototype for testing, refinement, and evaluation. work of this kind canin turn guide decisions in technical areas concerning specific perceivedneeds and new research goals. a complementary approach is to studytechnical areas to discover fundamental mechanisms that can serve inproviding support when they are needed. the pursuit of the two pathstogether can lead to an eventual synthesis of truly usable and importantnew aids for future communities.generally with this view in mind, the steering committee crystallizedthree recommendations that are summarized here and are presented indetail in chapter 7. the first is that a major new effort be launched to seeknew paradigms for humanmachine interaction. the research community recognizes the success achieved by technologies developed two ormore decades ago but also sees many indications that better alternativesare needed and are possible. among the drawbacks of or problems withcurrent technologies are that they are too finely tuned to the peculiaritiesof the technologically elite, too inflexible for the variety of applicationsand environments that the nii will offer, and too inaccessible to ordinaryusers or to individuals with disabilities. new, better interfaces are neededmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary5that utilize a variety of technologies that are now becoming available, thatare usable by a broader cross section of people, that take advantage of theopportunities afforded by the nii, and that emphasize the new role oftechnology in society as a mediator among individuals, groups of individuals, and networked machines. elaborating on this recommendation,the steering committee in chapter 7 specifies a series of properties andcharacteristics that it thinks new and improved interfaces should have,including learnability, modality and medium independence, and a strongcapability for supporting group activities.the steering committeeõs second recommendation encourages investment in research on the component subsystems needed for ecis and emphasizes the importance of studies of human and organizational behaviors and ways that technology can support them. it encourages researchon a variety of potentially useful technologies, including input technologies (such as speech recognition, natural language processing, computervision, gesture sensing, and multimodal input languages) and outputtechnologies (such as flexible, portable, and compact displays, highresolution displays, virtual reality, haptic devices, mechanical actuators, voiceand artificial sound, and multimodal generation of output) that can helpto maximize humanmachine communication by more closely matchingmachine audio, visual, and mechanical capabilities to those of humans.this second recommendation also emphasizes the importance of developing modality and medium independence so that individual systemscan be used by a variety of people in a variety of situations, and it recognizes the importance of agent technologies that can aid in interpretingand responding appropriately to usersõ needs.the steering committeeõs third recommendation encourages researchat the systems level that assembles the many subsystem components referred to in its second recommendation. it encourages the developmentof theories and architectures for collaboration and problem solving; emphasizes continued studies in humancentered design methodologies andsocial science research into how well the public is being served by newand proposed technologies; and underscores the importance of buildingexperimental humanmachine systems to test, refine, and measure theeffectiveness of various proposed systems.because they have not been emphasized in other research or mayhave unusual payoffs in achieving improved ecis, the steering committee chose to designate some areas for highestpriority consideration andaccordingly emphasizes the following:1.undertake psychological, sociological, and historical studies to determine the needs of every citizen in the context of the nii and thus tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.6more than screen deepprovide guidance to technologists concerning what needs to be createdand what will not work for real users.2.encourage additional research on speech recognition and the associated natural language processing so that speech can become a viableoption for input in a variety of niirelated applications. speech recognition and natural language processing are each important; speech as anoutput option calls for research related to speech synthesis. the steeringcommittee was impressed regarding both the broad need for such capabilities and the recent progress in the field supporting the hypothesis thatspeech will soon become usable for at least some interface applications.3.develop technologies that enable modality and medium independence for as many applications as possible, in order to support the goalsof nomadicity, compatibility of interfaces with a variety of hardwaretypes, and usability by people with disabilities.4.develop theories and architectures that support collaborationamong networked people. the new opportunities offered by the nii willcome to fruition only if technologies are developed that enable collaboration.5.build experimental humanmachine systems, for individual usersand groups, using proposed technologies or simulations of them. testthem, refine them, install them in applications environments, and measure their effectiveness.the steering committee emphasizes the importance of there being astrong experimental component in upcoming studies.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary7part imore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction99information infrastructureñlocal, national, and globalñholds thepromise of connecting people of all ages and descriptions to other people;to business, government, and other organizations; and more generally tosources of information, art, entertainment, and more. we can only beginto imagine the transformations that might unfold. obvious trends areillustrated by activities on the world wide web and innovations in telephony and cable television networks, with improvements in network anddevice support for finding, viewing, or exchanging text and growth inaudio and video exchange over alternative media. although the mostcommon examples relate to whitecollar activities, the same technologiesare beginning to reshape service and goods production jobs as well. morespeculative are the possibilities arising from greater and more explicitnetworking of computing and communications systems embedded in allmanner of consumer and producer devicesñincluding systems in automobiles and home appliances as well as systems associated with manufacturing and service process automation.within this context, the question arises as to whether the many proposed benefits of the new technologies will be available to ordinary citizens. specifically, will these technologies have interfaces that are usableby the broad spectrum of people who may wish to use national information infrastructure (nii) resources? in cases where they will not, whatnew research is needed to make such interfaces available? this reportexamines these questions and their solutions as analyzed by the authoringsteering committee.11introductionmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.10more than screen deepas a start for the study, the steering committee notes that good interface design can help the spread of technologies. for example, one canpoint to the movement of personal computers from offices to homes andthe growth of electronic game systems (e.g., nintendo and sega) that runon special or generalpurpose computers. in the last several years, wehave also witnessed the explosive growth of the world wide web and itsuse by individuals, schools and universities, companies, governmentalunits, and nonprofit organizations. another area of growth involves the800 and 900number telephone services and experiments in electronicbanking, meter reading, and other specialized data services to the home,as well as the rise of òfreenetsó and other local public network services.yet problems with many interfaces have also been observed. interfaces often frustrate or are of limited use to many users, restricting accessand use.2 problems begin with those who do use these technologies despite some apparent difficulties. they suffer from repetitive stress syndrome and from the effects of low input/output bandwidths, overly restrictive computational formats, information overload, and many otherproblems. market research also shows that todayõs costs of owning apersonal computer, in the home or office, are very high once the varioussupport costs are factored in.3 other problems relate to those who do notor cannot use the information infrastructure. current interfaces areamong a variety of factors that limit use today by those who have physical, sensory, cognitive, language, and learning difficulties and by thosewhose activities or environments impose constraints on what they can doand how. despite an enormous number of smart people working toimprove interfaces, this is an area characterized by tough problems, manyof which are getting tougher as the user population and its demandsgrow. as bruce tognazzini observed at the august 1996 workshop,òwhile critical roadwork needs to be done in building the nationõs information superhighway, we cannot afford any longer to ignore the cars.our 1960s rattletrap hardware and 1970s rattletrap interfaces and software are not up to the task of everycitizen access to this nationõs information infrastructure.óbased on its study of such problems, the steering committee recommends an aggressive research program, funded by government and private sources, that examines both the human performance side of interfaces and the interface technologies, current and potential. certainly suchfunding has played a major role historically in breaking new ground ininterface design, and even greater reasons exist now for its continuance.one need only look at the roots of current graphical interfaces, notablythe apple computer macintosh operating system, which built on theearlier xerox parc smalltalk and alto systems and yet earlier work atsri and rand.4 another example is the internet, which can be traced tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction11box 1.1constraints imposed by commercial conditionsserving every citizen implies not just technical feasibility, but also that there areproducts available on the market and, in particular, that many information infrastructure products take on the character of massmarket goods and services, which is notthe case today for most computerbased products. if they prove relatively expensive,are virtual reality and many other of the newest technologies likely to find their wayinto everyday life? economists and people in industry note that high prices arecommon early in technology markets; consumer advocates caution against the inherent exclusion implied by high prices.the observed rate of progress is a function of the marketplace: vendors offertechnology that sells, using their best guess about what people will buy in sufficientvolumes and rushing to fill narrow market windows. market pressures affect whatkinds of interfaces are available in several ways. rapid product life cycles, for example, militate against longterm evaluation and testing (implicitly relying on marketresponse testing) and emphasize incremental changes that allow vendors to continueto sell what sells, in part to facilitate transfer of skills among successful products. anexample is the evolution and growth in market dominance over more than a decadeof graphical user interfaces that involve windows, icons, menus, and pointers. evenin a marketplace characterized by rapid change, facilitating the adoption of newtechnology by the existing base of users is as important to industry as assimilatinguninitiated or previously unserved users. in computing, as in telephony and television, the existing base represents a known market that vendors do not want to abandon or alienate; this base provides vendors the incentive to moderate the pace ofchange.1 market pacing also reflects perceptions about what people will buy, otherthings being equal. early videotext and recent cable television and online servicemarket trials foundered because they failed to appeal to consumers.1controlled rate of change is reinforced by regulation in television contexts, andsome speculate that the growing user base of the internet will also prove to be aconservative force.federally funded network research and deployment (cstb, 1994a, 1995).these developments show that major progress can be made in spreadingthe use of technologies. they also illustrate a fruitful combination ofpublic and private investment in research and development. box 1.1outlines the influence of commercial conditions on interface availability.a significant research opportunity (and challenge!) is presented bythe need to narrow the gap between the capabilities provided in todayõsinterface products and the capabilities that computer science and interface design researchers believe are possible.5 research that can contributeto advancing innovative concepts and that can promote better understanding of what technology works well to make interfaces more usable,useful, and accessible is the focus of this report.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.12more than screen deepdefinitions, key concepts, and parametersthe steering committee established definitions for the major termsthat appear in the subtitle of this report: toward everycitizen interfaces tothe nationõs information infrastructure. the term òevery citizenó representsthe steering committeeõs desire to consider the needs of people of all agesand physical abilities, races and ethnicities, education and ability levels,economic backgrounds, cognitive styles, and personal inclinations. itovercomes the homogenization suggested by a term used early in theproject, òordinary citizen,ó but also includes people who are ordinary inthe sense that they are not distinguished by special needs, such as accommodation of disabilities. the term opens up consideration not only ofconventional office and household equipment and services but also ofsystems in production manufacturing and service environments, systemsembedded in equipment designed for purposes other than computingand communications, and public access systems such as public kiosks.associated with this definition are several principles:6¥promoting broader (everycitizen) access does not necessarily imply making all systems accessible to literally all users; rather, the goal canbe expressed quite usefully in terms of enabling many more people to usethe information infrastructure well than do at present. (see chapter 2 fordata concerning the current demographic patterns of nii use and thedistribution in the u.s. population of special characteristics such as sensory disabilities and illiteracy.)¥ease of use does not necessarily imply no personal effort in learning or mastery.¥improvements aimed at meeting special needs, for example, thoseof partially disabled persons, may benefit other (even all) users.the steering committee defines the òinterfaceó to a system as encompassing the various means by which people communicate and interactwith the system to engage and guide what it does, the nature of thedialogue, and the means by which the system communicates its responses.the interface includes input/output hardware and softwareñthe actuators, keyboard, speech recognition, and so forthñthat people may employ for input and the visual, audio, and other representations that thesystem returns as its output. it also includes application characteristicssuch as information management and presentation, collaborative andother group interaction dimensions, and sharing of labor and responsibility between people and systems (e.g., by means of autonomous agents).the technical facilities (e.g., communications, computation) supportingpeopleõs interaction with systems are also part of the interface becausemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction13their performance directly influences the experiences people have using asystemñthe interface in its broadest sense. for example, an importantdimension of an interface is the amount of time delay encountered whenusing a particular system; this depends on the available communicationsbandwidth, processor speed, and memory capacity as well as the designand function of the input/output components. an interface may connecta person to a machine, an application program of some kind, other people,or a combination of such entities. the definition used in this report ismore comprehensive than may be traditional; the steering committeeõsgoal is to avoid the slippage that comes when the interface and application are narrowly defined and important issues are lost in an unfortunategap that falls between them.because the nii and the population are inherently diverse and heterogeneous, it is unreasonable to expect to have a single everycitizen interface to the nii. the variety of users, applications, and vendors mandatesa corresponding variety of interfaces. these will include presentdaytelephones and computers (including both portable and fullfeatureddesktop or room systems), inexpensive network computers and variousportable computing and communications systems, a variety of devicesthat can be worn on oneõs body or installed in a vehicle, and systemsembedded in equipment and services with other primary purposes.7the term ònational information infrastructureó as used here meansthe collection of communications systems in the united states and the setof computers and information stores and services that may be accessiblethrough them. it includes the telephone system, the radio and televisionnetworks, all of the libraries and computers in the country, and a long listof other communications and storage facilities and services (cstb, 1996).of course, elements of the information infrastructure have always existed, but the term òniió was coined recently because of the possibility oftying together a great many (if not all) of these elements into an integratednetwork complex that will be accessible (with some limitations) to essentially everyone. the internet is a significant part of the nii, but it isimportant not to equate it with the much richer and more complex nii asa whole. the nii concept implies that the paradigm for the coming century is one of networked machines, collaborative computing, ubiquitousand possibly continuous access, and group interactions over networks ofall kinds.8of course, interface improvement is not sufficient for maximizing theutility of the information infrastructure. other factors outside the scopeof this report include the appeal of the content and activities made available (do people want to use the information infrastructure more, or areadvocates projecting their own tastes?), regulatory and legal conditionsthat affect the nature and pricing of communications products that commore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.14more than screen deeppose and depend on the infrastructure, free speech protections and intellectual property controls that shape what information is available throughdifferent components of the infrastructure, and political processes basedon value judgments about how technology can be leveraged to meet societal objectives (themselves subjective) and decisions about the allocationof public resources to technology relative to other uses. all of thesefactors combine to shape who uses the information infrastructure andhow, when, where, why, and how well. they indicate why public policyis an important element of context. in this context, the americans withdisabilities act and the telecommunications reform act are recent examples of public policy interventions to promote more and easier use ofthe information infrastructure (and other facilities) by every citizen; thetelecommunications reform act, for example, contains language requiring that product design incorporate features enabling access by peoplewith disabilities.9additional commentsthere is a vital interaction between the shape of the technology andthe public and private objectives for its use, drawing implicitly on ideasassociated with universal service in telecommunications or equitable access more broadly viewed. for example, the expression òeverycitizeninterfaceó led some contributors to this report to suggest framing researchrelative to objectives concerning how much of the population can undertake certain activities associated with exercising the rights and responsibilities of citizenship (e.g., sending and receiving email, querying a government agency, or participating via the network in a multiweekorganized educational experience). others pointed to problems in framing such objectivesñhow much of the population constitutes critical massor social equity? what activities are most essential to enable? how cantheir achievement be paid for if they are not likely to emerge from themarketplace?10 contributors to this project noted, therefore, that givenwhat people can and do do with todayõs information infrastructure (including activities that substitute for use of other technologies), prematurely promoting broader access and use might result in either underusedresources or a diversion of personal and institutional resources from lessto more expensive technologies currently used in somewhat similar ways.overall, the difficulty of getting many things right, at the same time,suggests that serving every citizen will take timeñand that research canhelp accelerate the progress.questions of timing and the incidence of costs and benefits are familiar ones in the evolution and diffusion of new technologies. what standsout in the context of the information infrastructure, however, is the strongmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction15belief by many that the associated technologies, including their interfaces,have publicinterest ramifications that should be considered in decisionmaking about associated computer and social science research agendas.11the steering committee shares that belief but reports that this projectprovides evidence of divergent views about specific opportunities andneeds: consensus on social objectives and how tradeoffs should be madeis difficult to attain or define. discussions and disagreements amongworkshop participants point to the value of developing applications andaccess technologies, including interfaces, concurrently. they also explainwhy some issues are identifiable only through actual use of an interface.synthesizing a research agendathe starting point for user interface improvement comes in multipleformsñthere is no single approach to recommend. the visual approachis epitomized in commercial graphical user interfaces. commercial speechsynthesis and recognition systems exist, but they are restricted in applicability and bandwidth compared to visual interfaces. menus are commonin many kinds of systems, yet todayõs systems point to limitations in howthey are implemented. but their success suggests that, for the near, medium, and even longer terms, progress will come through introducingmore options that meet more needs rather than in eliminating the incumbents.the next milestone depends on oneõs vision of the future. from almost any angleñtechnical, social, business, or policyñdisagreements exist. overall, the future may be reached incrementally, by extrapolatingfrom and building directly on earlier successes. a large variety of newtechnologies are being pioneered that could potentially address peopleõsneeds. they include speech recognition and generation, virtual realityand advanced graphics systems, haptic devices, advanced database querymechanisms, and intelligent agents, all aided by much faster processingand greater memory than were available before. in most cases, substantial research is needed before the functionality, reliability, and appropriateness of new technologies for use by different people will be understood to the point that such technologies can be widely used.incremental improvements will take place; they should be consideredpart of the (moving) baseline. for example, more conservative membersof the community point to the successes of direct manipulation interfacesand suggest that development efforts should build on them. the futuremay also be radically different as a result of technical breakthroughs ortransformations arising from cumulative incremental developments.some of the more visionary objectives come out of the (sub)discipline ofartificial intelligence and involve credible and useful realization of natumore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.16more than screen deepral language and intelligent systems. but to experts from other subdisciplines, those visions will not work or may be undesirable because of whatthey imply for complexity, control, and time investment to develop. othertensions relate to emphasis on support for realworld communities andinteractions versus support for artificial worlds and virtual environments.these are not inconsistent, but reflect different preferences and assumptions regarding people, activities, and allocation of resources. some ofthe difference in perspective reflects differing views of the desirability ofautomating different functions or of different approaches to simplifyingtechnology (e.g., whether functions should be hidden). what is simple,easy to use or learn, or even helpful is a matter of opinion. some reflectattention to different segments of society: attention to information components of work and other activity tends to emphasize whitecollar activities, raising questions about support for other kinds of activities, including those that may have little connection to information finding andmanipulation (such as the purely recreational). yet other differences arisein contemplating the larger architecture of the evolving information infrastructure: what is likely or preferable as the locus of intelligence, processing, various input/output functions, and so on? what capabilities belongin what kind of user device, and what capabilities belong in the network?will one approach dominate, or will multiple solutions be sustainable technically and economically? how these issues are sorted out bears on enduser device and service options (technical features and costs), the cost structure of information and communications service providers, and the featuresand qualities desired in interfaces. the range of issues and their interactions underscore the value of joining social and computer science perspectives because technical capability is only a piece of the puzzle.this project has shown that experts differ strongly in their viewsabout what visions should shape the agenda for future user interfaceresearch. those differences reflect the inherent biases of personal concentration and investment in a given subdiscipline, as well as differentialunderstanding and evaluation of what has and has not worked in thepast, varying orientations to medium and longterm time horizons, relative openness to new or synthetic ideas/approaches, diverging valuesand frameworks, and myriad other factors. the increasing scale anddiversity of the research effort make it harder for people to know aboutand understand progress outside their own niche; uneven understandingcan be constraining in an inherently multifaceted arena. this report triesto be catholic in its approach, accepting the value of incremental andradical, as well as foreseeable and speculative, approaches and embracingthe promise offered by multiple technologies and the interaction of technical and social science perspectives.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction17interface research must proceed along many dimensions to accommodate every citizen and to sustain the marketplace of ideas and experimentation that composes a healthy research enterprise. it is already proceedingalong multiple paths because of the fragmentation and multidisciplinarynature of the research community. many different and often disagreeingcommunities exist: those oriented toward speech and those toward visualsystems, those oriented toward artificial intelligence and those toward direct manipulation, those oriented toward meeting the needs of people whohave disabilities or are disadvantaged, and those oriented toward the highend, fully enabled, resourcerich users (these are characteristics often foundamong the early adopters of any new technology). these and other differences characterize the technical community; they are complemented bydiffering approaches among a variety of social sciencesñpsychology (e.g.,cognitive, perception, social, industrial), sociology, anthropology, and economicsñthat offer valuable insights into how and why people use theinformation infrastructure and how those uses can be better in one or moreways. diversity in research does not imply that all ideas are equivalent inmerit or priority, but rather that there are risks in focusing too soon and toonarrowly and that there is value in reassessing the prospects of certaintechnologies as conditions change. the diversity in research outlooks evidenced in this project underscores both the value of fostering interdisciplinary research and the challenge of undertaking such collaborations.progress toward achieving ecis will involve basic research in theory,modeling, and conceptualization; experimental research involving evaluating, testing, and implementing artifacts; and empirical social scienceresearch assessing segments of the population and how people actuallywork with different systems. in all cases, data, methodology, and toolsare themselves targets for research or research support.organization of this reportpart i of this report represents the steering committeeõs synthesis ofthe factors shaping goals for eci design (chapter 2) and issues and directions for research in relevant and promising areas (chapters 3 through 6).the crosscutting issue of design and evaluation is covered in chapter 4.chapter 7 presents overarching conclusions and recommendations developed by the steering committee. part ii includes selected position papersprepared for the projectõs august 1996 workshop. these papers containadditional details on overall and specific eci issues and the authorsõ personal recommendations for further research. additional position papersare posted on the world wide web at http://www2.nas.edu/cstbweb.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.18more than screen deepnotes1.use of the nii is, of course, a matter of individual choice. although many factorsaffect who chooses to use what technology, when, where, how, and how well, contemporary experience shows that many people seem to want to use infrastructure technologies.further, economists have shown that individuals benefit from widespread use of networktechnologies, suggesting that enabling use by more of the population will benefit more thanjust those newly accommodated. broader deployment, if not ubiquity, and broader useallow for the economic and social benefits of what economists call network externalitiesñindividuals gain value and appreciate networked systems more as more people becomeconnected users. even if advocacy based on the social or societal value of enhanced information infrastructures is premature, as some skeptics argue, the evidence for the promise ofthe technologies is great enough to make continued efforts to improve interfaces a wisenational investment.2.some of the difficulty reflects the explosion in numbers of features and capabilities in the software and information infrastructure, a result of which is to make the olderwimp (windows, icons, menus, and pointers) interfaces more clumsy to use. whereas anearly1980s desktopstyle interface might be used with perhaps 50 documents, ordersofmagnitude more documents might be used in late1990s applications.3.many of these support costs reflect limitations of todayõs interfaces, inasmuch asthey involve ongoing training, consultation, and thirdparty adaptation of how a system isconfigured to meet the userõs needs; these costs can be compounded by significant operating costs for telephone and cable television service. note that even mouse pointing devicesconfound people initially, as recognized by microsoftõs inclusion of a solitaire game withwindows software packages.4.others building on that research legacy include motif, the evolution of themicrosoft windows line through windows 95, and mosaic and other web browsers.5.context and motivation are provided by changing needs, an example of which isthe contrast between searching a single document and searching vast repositories of documents (with the library of congress providing the canonical example). research can enable a competitive marketplace to produce a wider variety of interfaces and applications,supporting citizen choice based on individual perceptions of needs and wants.6.other principles or goals can be framed as a function of value judgments aboutwhat people should be able to do and under what circumstances. goals related to specificapplications such as health care, education, or other domains can be very helpful in suggesting attributes for interfaces, and these are the focus of separate literatures, references towhich are scattered throughout this report. for example, as sproull and faraj (1995) pointout, policy discussions of the internet and other electronic networks tend to assume thatthese media are mainly informational in nature and that users chiefly want better ways tobrowse and find the information they desire or to send information to others. empiricalsocial science studies suggest a contrasting view of users as complex social beings whoseinformation needs are inextricably bound up with a collection of other ends that are communicative, participatory, and social in nature.7.the expectation that computer and communications systems will take manyforms and be used in many contexts underscores a caution voiced by some project contributors against òpersonal computer centrismó: many devices and systems present many interface needs. the proliferation of technology promises ubiquityñeventuallyñand calls attention to the context of use: there is an evolution of what mark weiser, a workshopparticipant from xerox parc, has called òpersonal information infrastructures,ó and systems can be differentiated or used in common among personal, household, organizational,and public facility or public space environments.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.introduction198.taking advantage of improvements in the cost, performance, and capabilities ofthe underlying hardware technologies, as well as the basic and applied interface researchthat has made possible todayõs successful commercial implementations, todayõs successfulinfrastructure products (epitomized by internet services now extending to audio and videodelivery) are often creatures of software. user interfaces are also driven increasingly bysoftware, which can increase (or decrease) the accessibility of computerbased products tomeet varying needs. hardware improvements have enabled faster computing speed, oneof the key sources of advances found in commercial graphical and, to a lesser degree,speech recognition and synthesis user interfaces.as gregg vanderheiden (1996) explained in testimony to the federal communications commission:software determines the user interface more than hardware: in todayõs computers and most telecommunication and enhanced telecommunication devices,the user interface is almost entirely defined by the software rather than thehardware. although the hardware provides some limits on what the softwarecan do, the bulk of the user interface is determined by the software. work withapple computer, ibm, microsoft, and others in computer operating systemshas shown how much disability access can be achieved without making anyhardware changes. software can be used to make mouse functions operablefrom the keyboard for those who cannot operate a mouse. software can allowscreen displays to be made accessible to individuals with low vision or blindness, and information emitted by speakers to be displayed visually for individuals who are blindñall without any changes in the hardware. in fact, theaccessibility of almost any product can be tremendously enhanced by modifying nothing more than the instructions (the software) which govern its behavior. on the other hand, relatively little can be done to make a product morecrossdisability accessibility without addressing the software issue.9.section 255: access by individuals with disabilities.(a)definitionsñas used in this sectionñ1.disabilityñthe term òdisabilityó has the meaning given to itby section 3(2)(a) of the americans with disabilities act of 1990 (42u.s.c. 12102(2)(a)).2.readily achievableñthe term òreadily achievableó has themeaning given to it by section 301 (9) of that act (42 u.s.c. 12181(9)).(b)manufacturingña manufacturer of telecommunications equipment or customer premises equipment shall ensure that the equipmentis designed, developed, and fabricated to be accessible to and usableby individuals with disabilities, if readily achievable.(c)telecommunications servicesña provider of telecommunications services shall ensure that the service is accessible to and usableby individuals with disabilities, if readily achievable.(d)compatibilityñwhenever the requirements of subsections (b) and(c) are not readily achievable, such a manufacturer or provider shallensure that the equipment or service is compatible with existing peripheral devices or specialized customer premises equipment commonly used by individuals with disabilities to achieve access, if readilyachievable.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.20more than screen deep(e)guidelinesñwithin 18 months after the date of enactment of thetelecommunications act of 1996, the architectural and transportationbarriers compliance board shall develop guidelines for accessibility oftelecommunications equipment and customer premises equipment inconjunction with the commission. the board shall review and updatethe guidelines periodically.10.lee sproull, boston university, personal communication.11.this is central to the linkage with universal telecommunications service, a concept many seek to expand from telephony, and to the discussion of public access points,from network access computers in libraries to kiosks in shopping malls.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces2121in addition to giving us new tools or techniques for carrying out theactivities we are already doing, communications and information technologies will provide new opportunities for doing things we cannot currently do: viewing the invisible; hearing the unhearable; shrinking theworld or ourselves in real time in order to better explore, learn, or interactwith the real or virtual worlds; enhancing our sensory, physical, or cognitive skills; and tackling tasks we would otherwise never attempt becauseof the physical demands. not only will what we do and how we do itaffect the way interfaces should be designed, but the way we design theinterfaces will also have profound effects on the way we do things. at thesame time, substantial growth in information quantity and diversity isaffecting both activities and the nature of the information infrastructurefrom the inside out, suggesting alternative perspectives for interface designers to consider. the steering committee expected that viewing existing interfaces through the lens of a familiar life domain would revealneglected issues, unidentified challenges, unexpected convergences, ornew directions for research or action. accordingly, the workshop convened by the steering committee generated examples of trends, needs,and anticipated developments in education and lifelong learning, selectedwork environments, and home life, civic life, and social life.this chapter begins with a highlevel overview of the almost kaleidoscopic interplay of task, environment, information, and user attributes towhich effective ecis must be responsive. the overview of tasks, environments, and users provides the basis for an enumeration in the rest of the2requirements for effectiveeverycitizen interfacesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.22more than screen deepchapter of the qualities desired from everycitizen interfaces (ecis). thesteering committee emphasizes that this overview, synthesized fromworkshop discussions and supporting materials, is impressionistic ratherthan complete. more completeness is both beyond the scope of this reportand problematic: the ease of extrapolating from what we see and do todaymay be misleading about the future, although contemporary experiencesdo illuminate what does and does not work well.1 in particular, contemporary examples emphasize the characteristics of contemporary personalcomputers and, to a lesser extent, telephones and televisions; tomorrowõsinformation infrastructure will draw more on embedded systems anddifferent kinds of devices, too (verity and judge, 1996).diversity of demands to be met byeverycitizen interfacesthe interdisciplinary nature of the workshop discussions providedevidence for the contributions to technical development of better interfaces from better understanding of the social context and òdomesticationóof system use. for example, how does the new technology change orbecome integrated into household and community routines? how is thedefinition of home computing evolving? as explained by social scientists, that understanding should be informed by a history of social changeassociated with computing and communications systems, leveraging descriptive data and analysis to anticipate the amount and style of use. forexample, what are the roles of service features, early experiences, andsocial influences in the adoption and use of networked infrastructure bymainstream users? longitudinal, multimethodological field research maybe especially important for systems intended for public access (e.g., library resident and kiosk systems2). it may also help in understandinghow public knowledge, understanding, and educational needs about security and trustworthiness should be factored into technical decision making. for example, how far can one go in providing anonymity and/orprivacy protection to citizens without huge increases in cost or effortassociated with use of the national information infrastructure (nii)? istechnology that is aimed mainly at protecting institutional (governmentor corporate/proprietary) information generalizable, or do individualspresent specific additional requirements?todayõs diverse uses of information andcommunications technologiesreliable, comprehensive, and uptodate data about everyday uses towhich people currently put information technology are in short supply,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces23but what is available provides important insights. table 2.1 summarizesdata from the u.s. bureau of the census about computer use by adultsand children who have access to a computer at home (22.8 percent of u.s.households at the time of the survey). the census bureau data werecollected in 1993 in the current population survey, which uses a statistically valid sample of the u.s. population (unlike online surveys andmost market research reports). the 1993 data are the most recent available from the census bureau concerning the countryõs home computeruse; unfortunately, the 1993 survey predated the widespread growth inpopularity of the world wide web and did not ask about web use. morerecent private surveys (e.g., hoffman et al., 1996) provide only snapshots,since the combination of broadening use of personal computers and frequent introductions of new software and services leads to relatively frequent changes in who is doing what.table 2.1computer use at homepercentage of users by age groupa0141539405960adults age 15applicationyearsyearsyearsyearsyearsemail125353829bulletin boards28888communicationsna18242420databasesna18252121spreadsheets 118242020word processing2658645760games8520191919graphics1514141014household recordsand financena15201717work at homena22332126connect to workfrom homena8948homebasedbusinessna4665school assignments403314224educational programs3913181415learning computer use2521201520programming38979na, not applicable.a percentages are the proportion of people who had a computer at home (not thepercentage of total u.s. population) and used it for the indicated purpose.sources:u.s. bureau of the census, current population survey, october 1993;rand (1995, p. 185).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.24more than screen deeptable 2.1 suggests that work, learning, entertainment, household chores(e.g., bookkeeping), and social/collegial contact (e.g., bulletin boards) haveall become part of everyday household computer use. for example, learningñincluding formal educationñis not restricted to household membersin the kindergarten through high school age range. rather, a sizable proportion of adults who have home computers have been doing school assignments on them (24 percent), using educational programs (15 percent),and investing time in learning about computer use (21 percent). wordprocessing seems to have been the dominant application for adults (60percent reported its use), probably because it figures into so many otheractivities (e.g., bulletin boards, email, homebased business, remote work,school assignments).excluding word processing, email has the highest incidence of homeuse among adults (29 percent) in the census bureau data. more recent dataadd support to the conclusion that communication is a dominant reason forcomputers (sandberg, 1996). a representative example is provided byforrester research, which estimated that about 15 percent of all americans(not just those with home computers and thus a different measure than thecensus bureau data cited above) communicate by email at work and/or athome, up from 2 percent in 1992 (investorõs business daily, 1997). typical ofmarket research optimism, forrester predicts that growth in the use ofpersonal computers in homes and corporate internet access will drive email use up to 50 percent of the u.s. population within 5 years.use of home computers for workrelated purposes appears to be increasing. according to an international data corporation (idc) study,the number of households with full or parttime selfemployed homeworkers reached 20 million in 1996. idc found that these householdslead u.s. households overall in their rates of personal computer (pc)ownership (56.5 percent compared to 35 percent), online service use (27.5percent compared to 21.1 percent), and internet use (23.1 percent compared to 15.9 percent), and they are more likely to use online and internetservices than households with home computers but no home workers.idc segments home offices according to whether they are used by selfemployed home workers or by people with òcorporate home officesó (i.e.,those who work elsewhere and telecommute or bring work home afterhours). perhaps because of financial and training support from theiremployers, the latter group have even higher rates of pc ownership andnetwork use than selfemployed home workers. although these datacannot be compared directly to the census bureau data in table 2.1,3idcõs finding of 10 percent growth in home offices in 19951996, combined with the high rates of computer and network use observed amongsuch offices, suggests that doing paid work at home is a more commonuse of computers and networks now than in 1993.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces25recent research on internet use in the united states draws on the 1995commercenet/nielsen internet demographic survey (cnids), a telephone survey conducted in august 1995 (see table 2.2).4 unlike the 1993census bureau survey, this survey examined web use, which is a subsetof internet use since one must use the internet to reach the web, but notvice versa. researchers for project 2000 at vanderbilt university foundtable 2.2internet use in the past three months (all data representpercentages of the u.s. population)people in computerpeople usingcategoryhouseholds (%)networks (%)income quartile115223483431046821education level< hs265hs or more326b.a. or more5923gendermale4112female526age< 205014203941124059439> 59152note: getting an accurate picture of the distribution of computer and network use amongu.s. citizens is not straightforward. numerous samples are used to generate publicizedsurvey data, but close examination shows that despite care in the planning of sample design, the actual data must be adjusted statistically (through the use of weights) to achievemeaningful and accurate inferences about the u.s. population. in addition, what is beingmeasured is often neither clear nor consistent. survey researchers have observed, for example, that people often do not understand enough about their equipment or services toanswer questions reliably; questions about activities and uses tend to yield more accurateand consistent results. another factor inspiring caution about reported data is that there issignificant òchurnó in the pc application and services markets: people start and stop activity relatively often, but it is too soon to describe either longterm attrition rates or consistentpatterns in how use varies over time and among different categories of people.source: òcommercenet/nielsen media research internet demographics study for fall1995 and spring 1996 recontact,ó nielsen interactive services, dunedin, fl, august 1996.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.26more than screen deepthat 28.8 million people in the united states who are 16 or older hadaccess to the internet at home, work, and/or school; 16.4 million actuallyused the internet at some time in the previous 3 months; 11.5 million hadused the web; and 1.5 million had used the web to buy something. table2.3 presents detailed findings about a subset of the populationñthe 12.9million people identified as frequent internet users (once per week ormore), segmented by gender and amount of web use. among the interesting findings from this table are that women are much more likely thanmen to use the internet for communication (e.g., email, noninteractivediscussions on news groups and bulletin boards, and interactive chatdiscussions) and that men are more likely than women to download software, use a computer remotely over the internet, make purchases basedon information gathered on the web, or use the web for business.project 2000õs (hoffman et al., 1996) finding of 11.5 million web usersin 1995 suggests rapid growth in the use of this relatively new applicationtable 2.3internet and web use by frequent internet usershigh web usealow web useano web useamalefemalemalefemalemalefemalegender (%)782272285644activities performed on internet (%)bcommunication374130282242interactive discussion (chat)96121229noninteractive discussion1924971510download software15108614use another computer1657647activities performed on web (%)bsearch for product/service72564933informationsearch for company/organization72675645informationsearch for other information86836666browse/explore95918782make purchase based on web2918178 informationever used web for business57464430total in segment4.9 million4.6 million3.4 millionaall three segments are frequent internet users (once per week or more often). frequencyof web use is defined on a 4point scale.bpercentage of segment that named the activity as frequently performed.source: project 2000 (hoffman et al., 1996).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces27in the nii. informationgathering activity predominates on the web, witha much smaller share of people using it to plan or make purchases. webuse is constantly evolving, however, and this august 1995 snapshot tookplace before tools for publishing oneõs own web page became widelyavailable.5because access to the internet from work and school as well as fromhome is included, the project 2000/cnids data are not directly comparable to the 1993 census bureau data in table 2.1. nevertheless, it issignificant that both surveys found communication to be the most common use of the internet. this finding squares with detailed field observations gathered in carnegie mellon universityõs homenet project (krautet al., 1996), described at the workshop by sara kiesler and robert kraut.the homenet project gave 48 families of varied demographic backgrounds computers, internet connections, and technical support for a year.in pretrial questionnaires, participants did not expect that computerswould be useful for interpersonal communications. however, communicating with friends and family via email proved to be the dominantreason for use of the internet, especially among teenagers, and email useturned out to be a strong predictor of web useñbut not vice versa. teenagers also were likely to become the household experts and most frequentusers of networked information and communications media.similarly, civic networks report that communication is the incentivethat draws most of their participants online (anderson et al., 1995), andother anecdotal and case study evidence also points to growth in networked activity among children, especially at home rather than at school.while large income and educationbased differences exist in the access ofprimary and secondary school students to these media, a 1994 times mirror survey of technology in american households found òvirtually nosocioeconomic differences in how often and for what purposes childrenuse computers if present in the home.ópublic, civic, and social activities are hardest to represent with robustdata (kraut et al., 1996). every study of civic networks has reported thataccess increases community attachment and political involvement (e.g.,anderson et al., 1995). yet such findings reflect selection biasñrespondents are those who have opted for civic network membership. moreobjective data are available in the nationally representative 1994 timesmirror household technology survey. the survey established that individuals with network access from home were significantly more likely toknow the anwers to questions about their current political environmentthan their computerowning peers without network access. these resultsare mirrored in enterpriselevel research: those who use an organizationõsnetwork have more knowledge about it and feel more positive about itthan those who do not (huff et al., 1989; kraut et al., 1992).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.28more than screen deeplifelong learningevolution of the nationõs information infrastructure makes clear thatit presents opportunities and challenges to people of all ages, who mustlearn how to assimilate it into their lives. continuous changes in technology (and in the mix of activities that make up our lives) imply that peoplewill confront the need to learn new systems or activities at multiple pointsduring their lives, notwithstanding peopleõs changing willingness and ability to learn over time. todayõs teenagers, for example, emerge from variousstudies as leadingedge users and innovators, but those qualities will notnecessarily endure over time since a number of circumstances differentiateteenagers from other age groups. making learning a part of life and theimplications this has on how, under the influence of new media, humanbeings will think, create, work, learn, and collaborate in the future constitute a major consideration for the design of everycitizen interfaces to thenii; recognition of these concerns contributes to the rise of programmaticsupport for lifelong learning in a variety of contexts. the lifelong learningchallenge illustrates the need for interfaces and other elements of technology that transcend todayõs ògiftwrappingó approach to education, training, and learning in which the tradition of rote learning is òwrappedó in themantle of new technologies such as multimedia or the world wide web(rubin, 1996; wasser, 1996).6 see gerhard fischerõs and wallace feurzeigõsposition papers in this volume for a fuller discussion.lifelong learning is grounded in a variety of descriptive and prescriptive goals, such as the following:¥learning should take place in the context of authentic, complexproblems (because learning is more effective when people understand itsimpact).¥learning should be embedded in the pursuit of intrinsically rewarding activities. motivation is an enduring concern.¥learning on demand needs to be supported because change isinevitable, complete coverage of relevant information and knowledge isimpossible, and obsolescence of acquired skills and knowledge is unavoidable.7¥organizational and collaborative learning must be supported toleverage limited individual human minds and to meet collective organizational needs.¥skills and processes that support learning as a lifetime habit, thatreflect a realistic view of what should be considered basic skills in a societythat assumes broader use of information technology, and that transcendthe schooltowork transition must be developed.8more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces29research is needed to enable successful pursuit of all of these goals.the organizational emphasis that is emerging in a variety of workenvironments is as a growing and recurrent theme, in part because the niiconcept emphasizes the interconnection of groups of people (see chapter5). at the workshop, john thomas, of nynex, explained that more frequent and less regular changes in work environments imply that òassimilative learning,ó which is incremental and oriented to information acquisition, will be supplemented increasingly by òaccommodative learning,ówhich relates to more substantial change in perspective and activities. in avariety of contexts, communities of practice exist that may provide vehiclesand contexts for learning that may generate requirements for new interfaces (see the position paper by charles cleary in this volume).growing use in home, civic, and social activitiesthe growing penetration of computing and communications intohome settings and social activities is increasing their commonality withwhitecollar work. it is possible, as mark weiser, of xerox, mused at theworkshop, to begin to talk about personal information infrastructuresñwhich are elements of or complements to the larger nii. the personal andsocial impacts are changing with the technologies and their uses. forexample, as a tool for social interaction, the typewritingtelegraphy nature of todayõs applications seem to trade off isolation in the immediateenvironment for dispersed community on the net.9 with progress innetworking technology and access, evolving interfaces are expected toenable tomorrowõs electronic communities to see, hear, and touch eachother, meeting face to face, safely and anonymously, in cyberspace (seebox 2.1). already, people are using even typed text interfaces in multiuserdomains (muds) and multiuser domains/objectoriented (moos) to experiment with alternative identities and other behaviors that relate to selfimage; two and threedimensional avatars are also providing vehicles forplay, expression, and experimentation that underscore the potential forsocial impact that is only beginning to be recognized.the challenge of making interfaces appealing and easy to learn isgreater in home and social contexts, inasmuch as people at work have nochoice but to learn and make the best of systems available to them,whereas the success of home applications depends more on individualdiscretion and desire, which are in large part a response to the interfacealong with the associated content and specifics of the application. theselessons are repeated regularly in market trials of new services and consumer electronics. home settings also reflect the dynamics of families,which are different from other kinds of groups or institutions. at themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.30more than screen deepworkshop, patricia brennan, for example, noted that apparently sharedtasks are often defined very differently by different people. this condition suggests added value for tools that allow different people to assigndifferent interpretations to tasks and arrive at a common endpoint.another clear difference between home and institutional settings(work, school, and public access points such as libraries) is that equipment and networks at home are paid for by individual users. the relabox 2.1evolution of social interactionamerica is staying home. in the 1980s, futurist faith popcorn labeled the phenomenon òcocooning.ó now she is suggesting that we have entered into an evenmore isolated phaseñòburrowingóñas we go beyond physical withdrawal into emotional withdrawal as well: òsome of us are too overwhelmed or exhausted by thestress of life to bother to return . . . even the phone calls of friends we really want totalk to.ó the next stage she predicts is òclanning,ó where we will cluster like birds ofa feather into clans of 20 to 20,000 members. that trend is upon us today, andcyberspace is facilitating its growth. in the early part of this century, on a warmsummer evening, you could find people sitting on their front porches, calling out tofriends and neighbors passing in the street. people lived in communities, knowingwho their neighbors were and what they were up to. radio brought little alteration,except that people might leave their front door open, so that the sounds of òonemanõs familyó or òthe shadowó might brighten their evening. then television cameand everything changed. today, you can walk down those same streets and neversee a soul. the only signs of life are the telltale bluish glow of the tv sets within.the resulting social isolation has brought about a new form of instant intimacy.television shows have devolved from formal stage presentations and movies downto a peek into that interesting neighborõs window down the street (an augmentationof the same peek we used to take in person). you can now watch people just likeyourselves losing their pants at a wedding, revealing graphic details of their maritalinfidelities, or being shot or arrested, all in living color right on your tv.today, we are engaging in the myth of a settop box that will connect to thefamily tv set, around which everyone will cluster, watching in rapture as dadtraverses a labyrinth of baseball statistics or mom pays the bills. interactive servicesdo not invite partnership. in the coming decade the single blue glow of the livingroom tv will be replaced with a separate glow for every member of the family. thishas already happened at my house, where we have moved our computers into theliving room, so that we can be together while we work and play on our own. withthe advent of continuous speech recognition and vocal conversation on the internet,we may finally be driven into separate rooms, spending time with each other throughour viewports and offering greetings as we pass through the hall.source: adapted from a background paper prepared for the august 1996 workshop by bruce tognazzini, healtheon corporation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces31tively greater cost burden of network use by selfowned and very smallbusinesses is reflected in the finding of the 1996 idc and 1993 censusbureau surveys that selfemployed individuals lagged the general population in access to network services (including access from home, work, orschool), despite leading the general population in personal computerownership. in work settings, the institution provides both equipmentand support (training, help, and other resources), which are important forthe assimilation of information technology. in contrast, home users presumably must invest discretionary income in acquiring computing andcommunications systems and associated help, consulting, and training.less demanding designs for which less help is needed and systems withbetter builtin help support than is typical at present could reduce theseburdens. this premium on usability in home settings is one reason theterm appliance has been used with greater frequency to describe an easeofuse objective for future access devices. the problem of meeting usersupport needs is compounded, of course, in the case of people with inferior devices or systems (e.g., for reasons of affordability), except inasmuch as their designs require less support. also, systems that are moreselfcontained or sealed as a process of being more appliance like mayimply a need for disability access features to be built in, on the assumption that modifications will become more difficult. building in such access may also become a requirement for the shared systems that may bemore typical of institutional (e.g., employers or schools) or public contexts (e.g., kiosks) than homes (government information technology systems (gits), 1995).civic activities may involve use of the nii from home or other settings, including public facilities, such as libraries. examples of civic usesinclude motor vehicle registrations and renewals of driver licenses; finding and filing income tax forms, getting refunds or paying owed amounts;commenting on a proposed rezoning or a national forest land management plan during a public comment period; and monitoring the agendasand actions of government units at all levels (gits, 1995). as a class,governmentsupported efforts (e.g., under the digital library initiativeand various nii access initiatives) should be of particular interest to interface researchers because they are inherently more amenable to data gathering and analysis that can be discussed publicly than proprietary efforts,yet this potential is not exploited for the most part. many experiments areunder way at local, state, and federal levels of government and socialservice organizations, and many workshop participants urged the use ofthese nascent efforts for study about what works, what does not, what ismissing, and so on. where possible, comparisons to corresponding research in other countries is desirable.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.32more than screen deepinformation as a common currencycontemporary experimentation with the world wide web, theinternet, and even telephony and television provide what are expected tobe only hints of future information exchange. in the work world alone, itfeeds expectations that employees will need to connect to the open worldof cyberspace to access their colleagues around the world, vast onlinelibraries, and video, audio, and data feeds from news services offeringeverything from this minuteõs news to archived video and print history.along with technical access, people must have the skills and tools to find,comprehend, and work with information; current technologies show bothprogress and limitations in all three areas. these skills and tools presentan alternative, crosscutting perspective to interface contexts from thatpresented by applications, tasks, or activities.todayõs technology, built to meet obsolete constraints of the 1960s and1970s, focuses usersõ attention and work patterns on the tool instead of theinformation: they must first decide what tool set they wish to use and thenopen a document inside that tool set before they can proceed with theirwork. if people want to gather information, they must use their browser. ifthey want to include that information in their own work, they must transport it from the browser into their productivity tool. when they want towrite a memo, they do so in their word processor, where spell checking isonly a click away (but typically absent from email editors).there are interactions between the nature of information and its presentation that are sensitive to interface design. recent experiments withhypermedia and multimedia show the potential for new forms of presenting and representing information, both of which involve technical challenges; they may also enable new forms of information, per se, illustratedtoday by emerging uses in the creative arts and attempts by authors towrite specifically for the electronic medium. at the workshop, louis hecht,of the open geographic information systems consortium, for example,referred to the power of nontextual electronic representations, such as digital maps and virtual reality, for moving òour individual minds and collective culture away from textinduced linear, sequential thinking towardnonlinear thinking. . . . virtual reality applications will employ spatial representations of real spatial phenomena, but they will also employ spatialrepresentations of nonspatial phenomena, simply because our brains arehardwired for solving problems in threedimensional space.ódrawing from her experiences working with humanities scholars,susan hockey (then with the center for electronic texts in the humanities) described, at the workshop, how documents can be viewed as complex data structures; digital annotations and hypertext representations oftextual documents can include nonlinear links and can show layers ofmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces33value and meaning that paper cannot. box 2.2 provides examples fromhumanities scholarship of how the standard generalized markup language can be used to encode logical structure, change over time, andother aspects, enabling powerful new ways of understanding and analyzing information.10 hockeyõs illustrations emphasize that interfaces shouldbe seen as part of a system that not only presents or represents but alsocan influence interpretation of and options for working with information.interfaces inherently constrain the userõs view because their designers must make compromises between burgeoning choices of informationand limitations on display space and bandwidth for communication orreception. those choices might be made for many reasons and in manyways; technology is not neutral. it is important to recognize that there arechoices and that, by shaping the presentation of information, interfacedesign may affect use. most obviously, for example, for those with sensory disabilities, information that is presented in only one modality maynot be accessible. the overtly political debate of the mid1990s aboutwhether and how to control obscenity in networked infrastructure is aharbinger of other debates; technical tools (e.g., information filters, labels,blocking systems) developed in that context and the associated publicpolicy frameworks will influence demand for interface features and maybe transferable to other contexts.11 public and private decision makingabout whether and how to label and block information will, of course,reflect a combination of perceptions of technological options and a varietyof nontechnical factors.reflecting on the workshop and a draft of this report, workshop participant susan brummel, of the general services administration, characterized the challenge of providing support for multiple views:in order for citizens to construct personal, community, and actionoriented views, they need multiple technology òviewersó to see their viewsrelative to others, to conduct the discourse that keeps views òeasedóñpliant and flexible relative to achieving the overall agreedupon purposeñand òeaseledóñangled and standing in the best possible light tocapture the current and proposed view as it emerges. they also need tobe able to be accountable to themselves and others for what they haveagreed to do. we havenõt graduated to the availability of devices thataccommodate greater relativity beyond viewpoint, to reflect for example òviewplaneó (multiple views with their respective coherence/interference patterns), òviewsphereó (multiple views over a complete cycleor course of action), òviewtorusó (multiple long views as dynamic cultural influences as a whole, swell, crest, crash/transform, reform, and soon). how do we see the flow patterns that enable us to be eased upabove the noiseñand hold a balanced, steady course?more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.34more than screen deepbox 2.2representing humanities textsinformation in the arts and humanities can take many forms, and it can be studiedfor many different purposes. humanities primary source texts may take the form ofliterary works, historical documents, manuscripts, papyri, inscriptions, coins, transcriptions of spoken texts, or dictionaries, and they can be written in any naturallanguage. this information is characterized more than anything by its complexity. itmay include variant readings, variant spellings, marginal notes, annotations of various kinds, cancellations, and interlineations, as well as nonstandard characters. literary texts rarely conform to the simple document structure required by most currenttext retrieval systems. plays consist of acts, scenes, speeches, stage directions, castlists, and so forth. there are very many different types of verse. systems for processing literary texts must also be able to handle different languages and alphabets, bothin terms of analyzing the structure of words and displaying the text in the correctscript.most textual information in electronic form is intended to be used in a documentretrieval system where a typical user wants to find all the documents about a certaintopic. for primary source material in textual form, this is less likely to be the majorapplication. a user may want to locate a quotation, compare the vocabulary of thecharacters in a novel, examine the rhyme and sound patterns in verse, or even findout whether a particular word is used at all. these types of searches require anaccurate text and one that is encoded to make certain features explicit.ever since father busa began to create the first humanities electronic text in 1949,effort has concentrated on finding ways to represent the characteristics of texts suchthat they can be manipulated easily. most early projects attempted to transcribeelectronic texts by maintaining as accurate reproduction of the original as possible.typographic features were faithfully encoded, and many texts were prepared beforeit was fully realized how ambiguous typography can be. for example, italic can beused to represent titles, foreign words, or emphasized words, making it impossible toretrieve only foreign words.in late 1987 the humanities computing community became one of the earliestgroups to adopt the standard generalized markup language (sgml) when it begana major project called the text encoding initiative (tei). the tei has developed ansgml application that can handle many different types of humanities electronictexts. it includes tags not only for the structural features of the text, but also foranalysis and interpretation. the tei includes sgml tag sets for prose, verse, drama,transcriptions of speech, dictionaries, and terminological data, as well as analyticalfeatures, transcription of manuscripts, names and dates, language corpora, and asophisticated method for hypertext linking both within and outside the current document. the tei consists of about 400 possible tags, but very few are mandatory. thephilosophy is that one person can encode a text for the features he or she is interestedin. another person can then take that text and add encoding for other features. thetei makes it possible to encode multiple and possibly conflicting views in the samedocument, thus allowing for differences of opinion in interpretations of the material.source: excerpted from position paper by susan hockey available online at http://www2.nas.edu/cstbweb.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces35constraints on views will reflect the differing incentives and possibilitiesin both private and public quarters of cyberspace. emerging debatesabout privacy of personal data illustrate that even private uses (e.g., healthdata, which may be used by patients, physicians, health care organizations, health insurers, employers, government benefits providers, medical researchers) are not without policy constraints. in private domains,various restrictions may be both legal and either sought after or a concomitant of use (e.g., restrictions on use of companyowned resources byemployers). in public access systems, other constraints may be embodiedin system design. in general, nonpersonal systems and interfaces maylimit what every citizen can do with them, at least in the near to mediumterms.range of environments in which access is neededñrequirementfor nomadicityin a period of rapid technical and social change, not much can orshould be taken for granted. two things, however, seem evident from thecourse of development of the nii, to date:¥a personõs physical location at any time during the day will makeless and less difference to his or her ability to carry out most any activityassociated with information processing, communication, and electronictransactions.¥since electronic interaction is likely to become integral to education,employment, and daily living, not having access to these emerging technologies will have increasingly negative ramifications for individuals whoare unable to access them for various reasonsñnot being able to understand them, not being able physically to use them, not being able to afforddevices and other end systems (or the communications, capacity and service to use them to access the nii).the range of environments where people can access networked infrastructures is growing. with miniaturization and advances in wirelesscommunications, and architectures for distributed computing that mayplace fewer demands on at least some classes of devices, people will nolonger need to be tied to a workstation or carry a large device for access tocomputing, communications, and information services and functions. atthe same time, growth in the variety of networkattachable devices inhomes (not only computers, but also televisions, stereos, systems for managing energy consumption, and many others) implies networking withinthe home and additional hardware or software that supports both intermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.36more than screen deepconnections and management of homebased devices and systems. thequality of communications capacity to homes and other remote locationsdepends on the evolution of associated services (people differ as to theiroptimism about what will be deployed to homes and when; see the section titled òthe communications infrastructureó in chapter 3); the prospect of greater networking within homes raises questions about household economics that compound those presented by pc ownership.nevertheless, interface research should contemplate possible changes innetworking capacity and services and alternative architectures, whichembody alternative expectations for what functionality will be in terminating devices, hosts or servers, and the network itself.a number of conceptual frameworksñuntethered computing andcommunications or nomadicity,12 ubiquity, and universalityñhave incommon the vision of systems and, therefore, interfaces that can be usedanywhere, anytime: while a person is sitting at a desk, driving a car,sitting in an easy chair, participating in a meeting, sitting in a library,walking down the street, sitting on the beach, walking through a noisyshopping mall, taking a shower, or relaxing in a bathtub. the challenge ofoperability across environments is being pursued in the context of specific kinds of jobs, such as maintenance work, which involves problemsolving, distributed corporate knowledge, and people who move amonglocations and need to communicate both in transit and from afar (see, forexample, the position paper by daniel siewiorek in this volume). at leastsome systems and interfaces will also need to be operable in hostile environmentsñwhen camping or hiking, in factories, or on a battlefield.ubiquitous computing and communications implies that many peoplewill need to access their device (or devices) in very different environments even on the same day. different environments will put constraintson what type of physical and sensory input techniques will work underwhat circumstances and conditions (e.g., it is difficult to use a keyboardwhen walking, difficult and dangerous to use an input method that requires vision when driving a car; keyboard use is fine when sitting at adesk, but speech input may not be acceptable in a shared environment),as well as the types of display or other output techniques that will beaccessible and usable or not (in a noisy mall, in the midst of a meeting,while at the library, while driving a car).some devices and systems will be personally purchased and owned,while others will be public in nature. for personal systems an individualcan do a certain amount of selecting among systems to meet personalneeds or preferences and can even make modifications if necessary. public systems, on the other hand, must be operable without modification byall individuals who may come upon them, implying suitability for peoplewho have any of a wide range or combination of disabilities and alsomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces37systems that are very easily learned. institutional systems (e.g., providedby employers or schools) may provide an intermediate level ofcustomization. the contexts of public use may imply greater needs fordurability (e.g., because of highervolume or more intensive use) andruggedization (e.g., because of public space or outdoor installations).these elements, of course, affect cost. for example, touchscreens are themost common kiosk input device; thinner liquidcrystal display panelswith touch membrane overlays are increasingly used to allow shallowerkiosk enclosures. assessments of public kiosks already recognize thatthere are tradeoffs in a variety of cost elements (including deploying morekiosks to raise proximity to more of the population versus raising theamount of use per kiosk with fewer of them; see gits, 1995). expectations for greater use of public access systems, evidenced by experimentation with a variety of kiosk applications, suggests a need to assess theirperformance and technical requirements more systematically; insightsmight be gained from contemporary phone booths, automated teller machines, and kiosk systems (gits, 1995; venture development corporation, 1996ac).13range of userspeople who have disabilities or who are older represent a particularlyimportant target community for ecis, because for people who lack suchabilities as walking, seeing, speaking, or hearing, the nii is a medium ofcommunication that allows participation in the nationõs civic, social, andeconomic life on an even footing with fully abled people (see box 2.3).the goal of developing ecis does not mean accommodating literally allpeople in all situations and applications. some tasks are incompatiblewith particular disabilities; for example, blind people are not likely to befilm editors, even if an interface could be built that somehow enabledthem to operate a film editing system.it should not, however, be too readily assumed that any given task isinherently inaccessible to some people, since trying to figure out how tomake the inaccessible accessible can lead to insights that make the taskmore accessible to and usable by all people. for example, modificationsto enlarge fonts on screen to make them more usable by people withvisual impairments have been found to be very useful for individualswithout visual impairments when using highresolution screens onlaptops. strategies developed on kiosks to allow them to be used byindividuals with low vision or blindness have facilitated use by individuals with literacy problems. closed captioning on televisions, which wasimplemented for people who are deaf, is now being used by an evenlarger number of children and adults who are learning english as a secmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.38more than screen deepond language. nevertheless, efforts to extend accessibility to the nii to asmany people as possible must account for the fact that a large number ofpeople have some condition that constrains their ability to use some formsof interfaces.altogether, people with physical, sensory, and cognitive disabilitiesaccount for 15 to 20 percent of the u.s. population. the census bureauregularly measures the number and characteristics of people with specificdisabilities.14 some 49 million americans (about 1 in 5) have a disability,defined as a limitation on performing one or more of a range of functionaland social activities, such as seeing words in newsprint, engaging in spoken conversation, climbing stairs, shopping, or performing light housework. of these, 24 million have a severe disabilityñan inability to perform one or more of these activities.although the data do not directly address the use of informationtechnologies, they support some conclusions about interface usability.among persons 15 and older, 5 percent (9.7 million) report difficultybox 2.3importance of access to information technology for theblind and visually impairedaccess to information technology is particularly important and valuable for blindand lowvision citizens. the ability to use computers and network services booststhe employment prospects of such people and enables them to participate in onlinecommunications. the following comments were recently submitted by the american foundation for the blind to the federal communications commission:according to research conducted by the american foundation for theblind for the department of education, blind and visually impaired people areas likely as the general population to have consumer electronics in theirhomes, to use personal computers, and to use internet and online services.this, despite the fact that blind persons tend to be poorer, on average, thanthe general population, and tend to be employed much less often. . . . sincestudies have shown that computer users and internet users tend to have higherincome than the general population and that people tend to use computersand the internet at work, it is particularly noteworthy, given these differencesin income and employment, that usage rates for blind and visually impairedpersons are similar to the general population, suggesting the increased importance of this access to them. . . . a study completed just before the passage ofthe americans with disabilities act (ada) estimates that 43 percent of employed persons who are blind or visually impaired use computers to write(kirchner, corinne, and harkins, don, issues and strategies toward improving employment of blind or visually impaired persons in illinois, americanfoundation for the blind, 1991, table vi5 (a)).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces39seeing words and letters in ordinary newsprint, including 1.6 million whoare blind; 5.6 percent (10.9 million) have trouble hearing what is said in aconversation with another person (including 0.9 million who are deaf);and 8.3 percent (16.2 million) have difficulty lifting and carrying a full bagof groceries. difficulty with these tasks implies that certain interfacescould be difficult or impossible to use, such as those requiring readingprint on a screen, hearing synthesized speech output, or manipulating atouch screen or mouse.according to the census bureau, the chances of having a disabilityincrease with age, and more than half of persons aged 65 or older have adisability (u.s. bureau of the census, 1995). some degradation of sensesand abilities is normal with age. people over 65 account for 12 percent ofthe u.s. population, but they make up 34 percent of persons with disabilities and 43 percent of persons with severe disabilities (u.s. bureau of thecensus, 1994). as sara czaja notes in her position paper (available online at http://www2.nas.edu/cstbweb), research on older personsñanincreasing share of the populationñhas found that advanced age is associated with decreased performance working with computers. the precisecause of the decline is not known. physical disabilities such as decreasedvision, decreased hearing, and arthritis probably are involved. czajanotes that factors other than physical disability may also impair performance for some older people, such as declines in cognitive skills and (fortodayõs older cohorts) less familiarity with information technologies thanyounger people have. further research will be required to identify themost significant factors and to find accommodations for the interface limitations of older persons.illiteracy is another impediment to effective use of information technology. the 1992 national adult literacy survey by the u.s. department ofeducation estimated that about 21 percent of americans over age 16 (morethan 40 million people) lack more than rudimentary reading and writingskills, including about 4 percent (8 million) who are unable to performeven the simplest literacy tasks.15 for many of these people, spokenlanguage may be a more accessible form of interaction with informationtechnology than reading output and writing or typing input.16 the distinction between speaking ability and literacy also applies to youngerchildren, who are expected to be a growing segment of novice nii users.it is also relevant to people whose primary language is not english. forexample, at the workshop, adam porter drew on his experiences withlatino groups to note the importance of simple predictable interfaceswith audio support and culturally appropriate presentations (which mayinclude the ability to shift among languages). it will be important thatsystems (particularly public systems) allow for crosscultural flexibility inmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.40more than screen deeporder to better match peopleõs language, conventions, culture, and soforth.people also vary in their level of computer expertise and style of interaction with computer systems. research that quantifies these variationsand their implications for interface design, however, is sparse. overcoming an apparent emphasis in the design of todayõs information technologieson advanced users at the expense of ordinary people was identified at theworkshop as a central part of the everycitizen interface challenge. brucetognazzini (this volume) describes a pervasive tendency in the informationtechnology industry to design òtoys for boysóñsystems that, by virtue oftheir complexity, superabundance of features and options, and interactionstyles that stress unusual logical and spatial cognitive skills, are much moreappealing to and usable by power users than ordinary people.it is vital to understand that the recognition that people have a rangeof abilities and styles does not mean that system capabilities valued byadvanced users should be eliminated. it would be undesirable to do so;advanced users hold special interest for interface designers because, as inother aspects of information technology, these are the people who pushthe technology and promote innovation, a good part of which later entersmainstream use. however, even advanced users as a group exhibit arange of abilities that should be accommodated; many individuals whohave disabilities (such as blindness) turn out to be some of the best powerusers, as long as the interfaces stay within their sensory capabilities. moreover, the economic factors that militate against developing unique interfaces for target groups of people with limited interface abilitiesñeconomies of scale, transferability of training and skills, and economies ofinteroperability with mainstream users)ñalso constrain or inhibit the development of unique interfaces for the most skilled users.with multiple input/output modes and graceful progression fromnovice to expert use, interfaces can be made operable by and efficient forexperienced and power users along with everyone else. what was characterized at the workshop as universal design aims to produce interfacesthat accommodate a range of user skills and abilities and do not excludepeople unnecessarily. for example, a text menu that can be read aloud bya speech synthesizer can be used by blind and lowvision people as analternative to icons and other graphical displays. conversely, the graphical alternative, if it uses symbols that are comprehensible without words,can be used better than text by people with poor literacy skills. peoplewho are illiterate in english but can read another language could gainaccess to english text if machine translation between human languages isavailable; as chapter 3 notes, this capability is not out of reach for simplemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces41systems with limited vocabularies. in addition, any of these can incorporate shortcuts for advanced users.the nature of the devices and software applications used for nii access influences how readily they might be made universally accessible.some devices will be general in nature, such as todayõs pcs, and used fora wide variety of activities. as larry goldberg observes in his positionpaper in this volume, pcs can run specialized texttospeech synthesizersand thus make applications accessible to blind or illiterate users. goldbergexpressed concern that lowcost òinformation appliancesó with less generalpurpose capability than pcs could preclude addons such as speechsynthesis and largeprint displays. nevertheless, it is apparent that bothgeneral and specialpurpose devices will be components of the evolvingmix of devices and systems that people carry around with them or thatreside in specific environments. that mix presents a software challengefor systems integration. the interaction among multiple technical choicesand constraints will provide part of the context for interface development, for example, by increasing the potential for customization.user ability independence and environment independence are synergistic. providing better access across the range of environments discussedabove (many of which have impacts tantamount to transitory situationaldisabilities) will end up addressing most of the issues faced by peoplewith disabilities. for example:¥when interfaces are created that will work well in noisy environments, such as small airplanes, construction sites, busy shopping malls, orfor people who must be listening to something else while using theirdevice, we will have created interfaces that work well for people whocannot hear well or at all.¥when interfaces are created that will work well for people drivinga car or doing something else where it is not safe to look at the device theyare operating, we will have created interfaces that can be used by peoplewho cannot see.¥when very small pocket and wearable devices for which it is hardto use a fullsized keyboard or even a large number of keys are developed, we will have developed techniques that can be used by individualswith certain types of physical disabilities.¥when interfaces are created that can be used by people who aredoing something that occupies their hands, we will have systems that canbe used by people who cannot use their hands.¥when interfaces are created for individuals who are very tired,under a lot of stress, under the influence of drugs (legal or illegal), orsimply in the midst of a traumatic event or emergency (and who mayhave little ability to concentrate or deal with complexity), we will havemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.42more than screen deepdeveloped interfaces that can be used by people who naturally have reduced abilities to concentrate or deal with complexity.required elements for effectiveeci input/output systemseffectively addressing the diversity of activities, environments foruse, and users requires an entirely new look at interface design. almostexhausted is the approach that expects the user to come to the interfaceand adapt to it, an approach that leaves a large portion of society unableto learn or use existing systems effectively or at all. even those who areusing systems today often interact with the interface using what wouldbest be termed superstitious behaviors, and they often use only a smallportion of the functionality of their systems.input optionseven though input techniques may be quite different in different environments, they should share operating principles. an improvementover todayõs techniques would be for users not to have to master three orfour completely different interface paradigms in order to be able to operate their devices in different environments. this implies continuity in themetaphor and interface òlook and feeló even though operating entirelyvisually at one point (e.g., in a meeting) or entirely aurally at another (e.g.,while driving a car). users should also be able to transition from oneenvironment to another and from one device to another (e.g., workstationto handheld), and from one mode to another (e.g., visual to voice) in themidst of a task. the challenge relates not only to conventional communications and information devices, such as personal computers and variouskinds of telephones, but also other systems, some embedded in very different kinds of equipment, to which the conventional devices may beinterconnected or which may supplant those devices for at least somepurposes. new types of input, including passive input, gestures, andincreased use of speech and natural language, will not replace existinginput techniques but rather complement them, providing the user with awealth of alternate input strategies to select from depending on the task,environment, and personal abilities or preferences. what is natural, interactive, and supportive is subjective, suggesting the expectation for multiple interfaces.there is a wide range of input options an interface device can offer.these may be built in, or a device may provide a connection point (suchmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces43as an infrared port) that would allow an individual to easily use alternative input systems with the device. some of the input options include:¥typing on a keyboard (still a viable and important interface)ñstandard, chordic, braille;¥alternative keyboardsñoperable with eyegaze, sip and puff,single switch, etc.;¥codes (morse, abbreviationexpansion);¥handwriting;¥keypads;¥speech;¥gesture;¥video inputñpassive, gesture recognition, image interpretation;¥optical character recognition (ocr)ñincluding recognition ofmath script;¥numerous pointing devices;¥touchscreens;¥virtual realityñincluding direct manipulation; and¥via data linkñinfrared, radio frequency, cable.control strategiesthe strategies used to control a system are similar to the input techniques. these include:¥verbal techniques (keyboard, speech recognition, alternatekeyboards, sign language recognition),¥gesture,¥pointing devices,¥direct manipulation (of the object itself or of virtual objects), and¥direct thought control.the specific approaches and technologies chosen for control will varydepending on the size, format, and function of the device. ideally, ofcourse, the system would incorporate a sufficiently flexible combinationof interface techniques to allow it to be used in different environments byindividuals with a variety of (dis)abilities to carry out the different tasksspecific to the device. as noted above (particularly with portable devices), by the time interfaces are designed to function in the differentenvironments and situations most of the variations for different users willalready be accounted for.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.44more than screen deepoutput optionssimilarly, there is a wide range of display options that a device mayoffer, including:¥alphanumeric displays;¥graphic displays (high and low resolution, large and small);¥auditory output (monophonic, stereophonic, threedimensional)ñspeech and sound, including both artificial and natural sounds;¥tactile (two and threedimensional representations as well asbraille presentation of text);¥olfactory (very low bandwidth);¥immersive and virtual reality environments (visual, auditory,tactile); and¥visualizationñusually video (two or threedimensional) but couldalso be done verbally.in looking at the ability to display information in alternative formats,it is useful to differentiate between information that is medium independent and information that is medium specific (and where parallel presentation would be required to provide user choice). examples of mediumindependent information would be information that could be representedpurely by ascii text. such information can be presented very easilyusing any number of different modalities, including visually (as printedor displayed text), aurally (as spoken text), or tactilely (as raised letters orbraille). mediumspecific information might be such things as picassoõsguernica or a symphony. with very mediumspecific information (suchas guernica), it is difficult to convey very much of the information in anyother medium. between these extremes lie a number of other types ofinformation, such as the floor plan of a house, a weather map, a companyõslogo, or even a movie, which may be primarily or optimally presented inone medium (in this case, visual), but which could also be presented (withvarying degrees of success) in a second medium (in this case, auditorythrough description). making mediumspecific information accessiblegenerally involves creating an information package that includes both theoriginal format (picture, movie, etc.) and alternate presentations that areeither in complementary modalities or in mediumindependent form. inthe case of the photograph or diagram, this might take the form of anaudio description (complementary medium) or an ascii text description(mediumindependent). for a movie it might include verbal descriptionsof the visual information and visual presentation of the auditory information (e.g., captions).again, it is important to note that the same techniques that makemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces45mediumspecific information accessible to people with different disabilities also makes the information accessible to computers and softwareagents (which tend to be both deaf and blind). for example, puttingcaptions in movies allows text search engines to find the movies based ondialogue in the movie. it also allows users to jump directly to any point inthe movie, speech, documentary, etc., that contains a particular word orphrase. if a photograph or movie is also described and the description isstored in electronic text form, search engines can also locate graphic information based on its description. at the same time, consideration of communicationrelated disabilities is helpful in understanding how, when,where, and why peopleõs needs differ: speech synthesis can help the visually impaired people, whereas visualization can help hearingimpairedpeople, and so on.characteristics desired for effective interfacesin exploring possible directions for developing more effective interfaces, workshop participants identified the following characteristics, eachof which is discussed in more detail below along with approaches forachieving these goals. it was thought that ecis would need to be:¥easy to understand;¥easy to learn;¥error tolerant;¥flexible and adaptable;¥appropriate and effective for the task;¥powerful and efficient;¥inexpensive;¥portable;¥compatible;¥intelligent;¥supportive of social and group interactions;¥trustworthyñsecure, private, safe, and reliable;¥information centered; and¥pleasant to use.easy to understandmaking the interfaces on nextgeneration devices easier to understand is often equated with making them simpler, but that is not alwayspossible for a given level of reduction in functionality. one place wherethings can be made simpler is in the removal of unnecessary complexitythat does not have anything to do with the task at hand. an analogy canmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.46more than screen deepbe found in the standard television. when tvs first came out, it wasusually necessary for people to understand how to both tune and finetune the stations. they also needed to master the vertical and horizontalholds. with advancing electronics, it was possible to eliminate all of thesecontrols and leave the user with only those controls that were reallyneeded in order to accomplish any given task: channel selector, volumecontrol, and perhaps a closedcaption button. the analogy for computerswould be to remove all of the work necessary to set up, connect, or makedevices work together. the òplug and playó capability commercialized inthe macintosh, which is the trend today, is an example. there are alsocomputers and printers that need only be brought into proximity witheach other, at which time they automatically find each other and connectvia infrared beam, configuring themselves and requiring only that theuser issue a print command in order to print documents. having systemsthat are always on and do not need to be started or configured can eliminate a control and leave the system always up and able to provide assistance.a second strategy that can be used is to create interfaces that providea better match with the userõs abilities, knowledge base, and expectations.creating interfaces that are more natural and more intuitive can allowindividuals to deal with much greater levels of complexity; doing so presupposes an ability to define and measure naturalness and intuitivenessconsistently. rather than òdumbing downó the interface, it can be madeto present the situation to the user in a context with which they are already familiar. the ability to communicate with the computer usingnatural language (either spoken or typed) is a powerful technique here.the use of natural metaphors and virtual environments (either two orthreedimensional) can also be helpful here, particularly for some types oftasks. better ability to handle natural gestures, such as pointing, alsocould play a role here.cueing is another technique for making systems easier to understand,particularly where sequences of input are required that would otherwiseneed to be remembered. with cueing, a userõs progress through a sequence is tracked, and the user is given verbal and/or visual promptsleading through the process or offering help.layering can be used to create interfaces that are easier to understandyet still allow for the full functionality that may be desired by powerusers. layering basically involves the covering up of more advancedfeatures to present a less complex initial interface to the individual. withmastery of a system, an individual can peel back the layers to exposeadditional functionality. a simple example of layering can be found onsome video cassette recorders (vcrs), which present only a basic set ofcontrols on their face and hide additional controls behind a door. layermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces47ing is important in order to provide a mechanism for users to slide gracefully from novice to intermediate to power users. it can also be used toallow advanced systems to function as both an appliance and a tool,depending on the needs and skills of the user.one goal is to create systems that can function like appliances (i.e., weget good results even if we are not particularly adept) when a person isfirst learning to use them, but that provide the freedom to use them inmore powerful and individual ways as the userõs skills increase (i.e., theycan become more toollike). as frequent complaints about vcrs andmicrowave ovens illustrate, some appliances can be both big sellers and asource of frustration to buyersñpresumably because virtually everyonecan learn how to do at least the basic functions with them. designers ofother appliances, including more generalpurpose computing and communications systems, might learn from the problems and attempted solutions for such products even if it is reasonable to assume some minimumcommitment to learning on the part of users (and that assumption issubject to considerable disagreement).the ability to slide seamlessly from passive to active/interactive modecan also be used to make systems more accessible and engaging to noviceusers. for example, systems might be designed to be more like televisionor videotape in nature, where information or activity sequences occurwithout much input at all from the user. the systems would be designed,however, such that at any point in time that a user took an interest in aparticular portion of the information, he or she would be able to begininteracting with the system. one can think of this in terms of watchingtelevision but being able to explore topics as they are presented. however, the basic premise can be taken much further than this analogy andbe applied to most any type of education or learning, as well as to activities such as communication, information searches, and even creative activities where the system starts creating something that the user either canmake minor modifications to (as it is happening) or step in and take fullcontrol of. multiuser domains (muds) are another example of environments where an individual can take the role of passive observer until suchtime as he or she feels more confident and wants to step forward andparticipate more actively.easy to learnhand in hand with easy to understand is the need to make systemseasy to learn, but there are differences of opinion as to what that shouldmean, illustrated in comments made at the workshop. many designers ofcomputer systems observe that success in areas of life involving depthand complexity comes from problemsolving skill (which helps people tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.48more than screen deepovercome minor technical problems on their own) and a willingness to trycomplex tasks repeatedly until successful. the alternative may involvemaking the space of possible activities so trivial that there are no potentialproblems (e.g., presettop box changing of television channels). someexpectation for skill and learning may be realistic, although it should notbe an excuse for avoiding improvement.some strategies discussed above, such as cueing and the passive/active strategy, can help an individual learn about the capabilities of asystem on the fly as it is being used. especially with layered systems,such cueing and builtin assistance can allow individuals to naturallyevolve an understanding of the additional functions of a device in a morenatural manner as they are using the more basic functions of the device.in addition, overt training functions could be built directly into thedevices that would introduce the user to the various functions. instead ofbeing òtutorialó in nature (like an electronic videotape), these trainingfunctions might take the form of mentoring systems, as well as the òfollowthenleadó approaches suggested by the passivetoactive strategyabove. (see also discussion under òsupportive of social and group interactionsó below and chapter 5.)mechanisms to allow users to learn new techniques and strategieswill be important for a couple of reasons. first, there simply may not beany good metaphors or experience base from daily life that matches withall of the functions of a device. individuals will need to learn new concepts when this happens. second, the model or reallife metaphor maynot be a particularly efficient or effective way of carrying out a task. itmay be useful in the beginning, enabling initial useñto write letters,make phone calls, write checks. but over time the same metaphor thatworked so well to introduce users to a system may hamper their abilityeither to understand or to use advanced features. in this case, eitherspecific training modules or onthefly training techniques might be usedto slide users gracefully forward into higher levels of understanding andadditional capabilities.social scientists at the workshop noted the appeal of interfaces designed to provide simple but conceptual models (e.g., electronic diagrams)of how things work, what is going on in the application, so that òhelpócan be better understood or so that people will be able to understand ontheir own where they are in an interaction. doing this implies understanding what makes a good model as well as how such models can bedesigned to convey complex information accurately to nontechnical usersat an appropriately general but still useful level of abstraction.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces49flexible and adaptableone thing that is clear from the above discussion of environments,people, and tasks is that no single interface approach will be sufficient fora device (e.g., only speech or only keyboard). this is true even if one isonly trying to address the different environments in which it may beused. for example, speech is one very powerful technique. however, asdiscussed above, speech is not usable in a noisy environment (e.g., ashopping mall at christmas), or in a quiet environment (a meeting orlibrary). similarly, the keyboard, another powerful technique, is not usable when walking or driving a car.ideally, therefore systems should exhibit:¥environment/situation independenceñthat is, systems should beportable and usable wherever the user happens to be and whatever happens to be going on around the user.¥equipment independenceñthat is, systems should work whenonly low bandwidth is available, when the user switches to a device witha poor display size or resolution (because a highbandwidth, highresolution device is unaffordable or because the user is simply in a lowbandwidth access location or is using a very small device).¥user (ability) independenceñthat is, systems should be usable byall individuals regardless of their visual, hearing, cognitive, or manualabilities.¥modality independenceñthat is, systems should not require thatusers view the information in any particular format or via any particularsense.¥task appropriatenessñthat is, systems should allow users to varythe way that information is input or presented to match the particulartask a user is engaged in and to match the abilities the user has left givenany other tasks being carried out in parallel (not using the particularsystem).it is clear that a òleast common denominatoró strategy will not work(e.g., only using capabilities that everyone has or that could be used inany environment). that approach would require development of an interface with no visual display, no auditory output, no speech input, andno manual controls and that could be used while the individual is distracted or unable to think or concentrate well. this leaves little exceptdirect mind control, which is being explored but seems very speculativeat this time.the alternative is to create flexible modalityindependent interfaces:interfaces that allow the user to select the input, control, and displaymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.50more than screen deepmodalities that best meet the userõs current environment, current abilities,and current task. box 2.4 defines and discusses the relationship betweenmodality and medium; implicit in the distinction is the relationship between inputlevel (e.g., vision) and higherlevel processing (e.g., languageor image). this distinction is important in thinking about the appropriateselection of mode and medium for ecis to use in different circumstances,including strategies that combine multiple modalities and media in asingle interaction.because an individual will probably need to access information appliances and tools in a wide variety of environments even in a single day, itwill be important that modality independence be built into the base product and that it be easy, seamless, and natural to move between modes. asdiscussed above, it is important that these interfaces accommodate thefull range of users, from novice through expert power users. this dailyswitching among modes also implies the value of a common òlook andbox 2.4multimedia and multimodal interfacesmode or modality refers primarily to the human senses used to process incominginformation (e.g., vision, audition, taction, olfaction), not mode in the sense of purpose (e.g., word processing mode versus spread sheet mode). additionally, in itsconventional definition, medium refers to both the material object (e.g., paper, video) and the means by which information is conveyed (e.g., a sheet of paper with texton it). these definitions could include the possibility of layering, so that a naturallanguage mode might use written text or speech as media even though those mediathemselves rely on other modes.media and mode are related nontrivially. first, a single medium may supportseveral modalities. for example, a piece of paper may support both language andgraphics, just as a visual display may support text, images, and video. likewise, asingle modality may be supported by many media. for example, the language modality can be supported visually (i.e., written language) and aurally (i.e., spokenlanguage). in fact, spoken language can have a visual component (e.g., lip reading).just as a single medium may support several modalities and a single modality may besupported by many media, many media may support many modalities, and likewise.for example, a multimedia document that includes text, graphics, speech, and videoaffects several modalities (e.g., visual and auditory perception of natural language,visual perception of images (still and moving), and auditory perception of sounds).finally, this multimedia and multimodal interaction occurs over time. therefore, it isnecessary to account for the processing of discourse, context shifts, and changes inagent states over time.source: maybury (1994).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces51feeló or underlying metaphor or behavior across the different devices ordisplay formats (e.g., visual versus auditory); see òsupportive of socialand group interactionsó below for observations on standards. whenswitching from keyboard and display screen access to the information ina meeting to voice input/output access to information while driving between meetings, the user will want to have the system feel and behave assimilarly as possible.required versus optional flexibility.although it is important thatusers be allowed to tailor their products, they should not be required todo so. allowing users to adapt the interface to meet their constraints andpreferences is important, but setting a system up so that an individualuser must tailor it before using it quickly adds complexity to the system.today, in many cases, to configure a system is much more complex andforeign to users than actually using the product once it is configured.one powerful concept is a mechanism that would allow the device torecognize the userõs needs and adapt to them. this might come eitherfrom monitoring the userõs behavior or by the user carrying a small cardor device (such as a wireless smart card) that contains his or her preferences and that could be automatically read by the device. issues of privacy arise here, but the card need not identify the person. the card couldsimply indicate the userõs preferred mode for interacting with devices.it will be important to define and explore the full option space forincreasing customizability in access appliances. the ramifications andappropriateness of having an nii identity for every device and system, assome expect to accompany/enable ubiquity, are incompletely understood.related questions pertain to sustaining greater portability of device identifiers/identities and to enabling grouping of different devices into a newappliance (e.g., via shared object systems).appropriate and effective for the tasknot all interface techniques are appropriate for all tasks. the flexibility provided needs to allow for the user to select interfaces that best matchthe particular task. in the attempt to make all services available to allpeople, it is also important to allow individuals with more advancedskills and full use of all their senses the opportunity to use whateverinterface is most effective for them and the task. it will almost always betrue that an individual with a reduction in one or more of his or her sensesor physical abilities will have a lower bandwidth available for either input or output. this does not necessarily result in lower effectiveness orproductivity, but it does imply a narrowerbandwidth input/output channel. a challenge will be to develop interface techniques and flexiblemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.52more than screen deepinformation systems that can maximize the efficiency of individuals operating either in constrained environments or with personal constraints witha goal of matching the efficiency of users with highbandwidth interfaces.this challenge, however, should not be equated with reducing the bandwidth or the interface efficiency for those who do not have physical orsensory disabilities.again, it is interesting to note that in looking at collaborative systems,we will be looking at trying to collaborate with a computerña systemthat has distinctly impaired vision, hearing, and cognitive abilities. theresearch aimed at developing interface strategies that work for peoplewith physical and sensory limitations should provide interesting insightsfor those working on intelligent collaborative machines (and vice versa).powerful and efficientexpert or òpoweró users tend to complain about the limitations ofcontemporary interfaces for meeting some of their needs, although someof those complaints may be shared by novices, too. upon scrutiny, thecomplaint may relate at least as much to the applicationñwhich mayhave a limited òunderstandingó of the userõs intentionsñas to the interface; judging from the workship, that differentiation confounds much ofthe discussion of interface needs.in making an interface easy to understand and flexible, it is importantthat the system not be òdumbed downó or made less efficient. throughlayering, as well as alternate access methods, it is possible to have systemsthat are both easy to understand and still efficient for individuals who aremore experienced or have advanced abilities. multisensory presentation,shortcuts, and memorybased acceleration techniques are all examples ofstrategies that can be used to provide higherbandwidth interfaces forindividuals who are able to handle them.inexpensivethe vision of interfaces for every citizen implies the availability ofsystems to much of the population, and that implies affordability.affordability reflects both the cost to purchase and the cost to own and usea system. the muchhyped rapid change in the information technologymarketplace begs questions about the prospects for an access system thatdoes not have to be replaced every 2 years because its functionality hasobsolescedñfor example, by assuring that when a new interface is neededit can be delivered and installed over a network without a huge user investment in cost and effort or in getting old data to work with new applications.(the same issue applies to hardware.) tools that facilitate the transfer andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces53implementation of appropriate techniques in commercial products and better testing strategies for evaluating the ability of new devices and interfacesto meet the needs of lowincome people (and segments of the mass market)could support affordability and broader access objectives.both device and service characteristics will be shaped by the largercontext of computer, communications, and consumer electronics trends.crts (cathoderay tubes), for example, have dominated computer displays because the television marketplace drove down the cost of thattechnology over many years. communications bandwidth into and outof the home comes at a price, which affects what people choose to do fromhome and what features they seek or can afford in access devices (today,for example, isdn service is available at a premium over òplain old telephone service,ó although emerging data service from cable operators willresult in price competition). meanwhile, debates over the design andcommercial viability of socalled network computers raise questions aboutthe architecture of the evolving information infrastructureñwhat can ormust be done in the userõs device, what can or must be done in the network, what is centralized and what is distributed, and so on. there aremany technical, economic, regulatory, and business factors interacting inthe environment within which interface design decisions must be made.comments at the workshop and on the review draft of this report underscore the wide range of appreciation for the larger environment and forthe interactions that shape demand and supply for the technologies forwhich interfaces are needed.the needs of lowerincome people raise questions about how to lowerthe historically relatively high cost of access devices (notably pcs), how togain more functionality from inherently lowcost access devices (such astelephones, televisions, and newer variants of ònetwork computersó), andhow to leverage information services at minimal cost. there is no agreement yet on how far one can go with ògreen screens,ó how much functionality of the desired/needed type can be achieved without the level ofsophistication implied by contemporary graphical user interfaces. flexibility and options with regard to display can be important. at the workshop, adam porter, for example, noted the need in lowincome populations for support for presentations on lowbandwidth devices or deviceswithout fixed internet addresses (e.g., locator systems, services that canbe suspended and resumed). systems that can be used with variableresolution displays and different bandwidth connections lend themselvesto use by individuals with less expensive interface devices. networkservices, such as video or auditory communication, which allow the userto degrade the video or audio quality in exchange for lowercost connections (since fewer packets are being exchanged) can lower usage costs.also, if information is available in visual, auditory, or ascii text format,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.54more than screen deepusers can select formats that both match their abilities and/or preferencesand their pocketbooks. another important feature might be some advance indication of the resources needed to accomplish a task (and, therefore, the associated costs) prior to its being initiated. this will be particularly important when agentoriented and other more automated systemsare more common.the expectation for a range of device types raises questions abouthow to devise criteria for, and enable, applications design that supportthe required functionality for lowend interfaces at a usable level whileproviding highend interfaces the options to exploit their special affordances. this range of support may be especially important for publicinterest applications (e.g., delivery of government information and services). for example, are there ways to facilitate support for both informationcreating/sending and retrieval/reception in even lowend/lowcost accessdevices? what does it take to achieve flexible data structures/presentations that serve different populations without duplicating content? thiskind of exploration of the hows and whys of publicinterest applicationsraises questions about the tradeoffs between multiple interface options andequity attained by efforts to provide the same interface for all users that areoutside the scope of this report but that, to the extent they are addressed bypolitical processes, will affect the environment in which interface designdecisions are made.the cost challenge may be particularly great for subpopulations withlimitations for which a significant market is not recognized or likely. atthe workshop, candace sidner, of lotus development corporation, notedthe lagging support for blind users associated with recent advances ingraphical user interfaces and suggested that similar market dynamicsmilitate against industrial support for research on the use of speech interfaces by users with visual, motor, or linguistic limitations.portablethe vision of being able to have a system that will work and beavailable to the user at any time in any place is dependent on the systembeing portable. research on device, network, application, and middleware aspects is proceeding under the nomadic computing aegis; also,with miniaturization continuing at the pace it is, it will be only a matter oftime before very powerful systems can be made that are quite small andeasily worn. creating displays and input systems for these very smallportable systems, however, will continue to be a challenge. this is especially true if they are to be used in noisy or silent environments wherespeech cannot be readily used.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces55compatiblethe new and evolving systems will have to be compatible with legacysystems to at least some extent. this issue is explicit in telephony andtelevision and more de facto in computing; where common, it is associated with slowing the process of change. the convenience of user accessto the nii and the impression of high performance in the user interfaceare greatly enhanced by interoperability (between equipments, networks,applications), consistency (the same or very similar interface is used everywhere), and easy adaptability of a component to an environment(òplug and play,ó òdiscoveryó of other system entities, quick and easystartup of a new service). all of these requirements suggest the importance of norms and standards.much of the òease of learningó that users will experience with newdevices will be a function of the similarity of the new devices to ones theyused in the past. interconnectivity and interoperability are also highlydependent on standards. thus, standardization can have a profoundeffect on the familiarity of new devices that individuals may encounter intheir environments. that said, experiences such as disagreement overproposed transitions from on/off to 0/1 on power control switches donot promise rapid agreement on interfacerelated standards. in the marketplace, product differentiation is an important source of profit.a more important compatibility issue, however, deals with the abilityof devices to work with each other. at the present time, interoperabilityof systems is limited, and even getting a computer to work with printersor other peripherals designed to work with it can be a complicated process.17 for individuals who require special adaptive interfaces, it is oftena nightmare. it should be as easy as bringing a computer and any peripherals near each other or attaching them to get them to work together.however, integration of key features or functions across platforms andservices is an issue in the marketplace; it constrains the commercial support for interface commonalities.òplug and playó is an urgent necessity for what a user perceives as ahopelessly complex environment of multiple service providers and facilities. the need ranges from carrying a settop box from one residence toanother and having it work when it is plugged in, with minimal humanparticipation through the remote control, to adapting devices to new services and protocols through automatic refreshing of software. it impliessystem adaptation and convergence, with devices and applications òdiscoveringó one another. systems research in this area would be very helpful.beyond media, universal and secure commercial protocols (for transmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.56more than screen deepactions such as credit card and electronic cash purchases) are essential forindividual and organizational trust in the nii; they require industry resolution. advances in encryption technology are becoming widely disseminated, and there are candidate security systems (such as secure socketslayer) for the internet that use them. some observers of the evolution ofelectronic commerce believe that a widely accepted endtoend paradigmfor secure transactions will be in place within 2 years, encouraging expanded commercial use of web browsers. this suggests the value offurther research on user interfaces for commercial transactions, includinghandshaking palmtop devices, communicating pocketbooks and wallets,and other innovative interfaces.although much of the standardsrelated work is more in the nature ofapplied research or development than basic research, and although leaders in the academic technical community often disparage standardsrelated work, the question of whether basic research could facilitate or support standards setting is especially important for systems intended for thebroadest possible use. for example, research that could contribute tostandards could illuminate options for maintaining a univerally understood paradigm across heterogeneous people, devices, access networks,and locations, using whatever media and media quality are possible in agiven situation. in the eci area, as in others, standards raise concernsabout limiting commercial offerings to lowest common denominators,which some maintain is the flip side of highestpossible access.intelligentto achieve much of the friendly, supportive, collaborative, andmentoring characteristics discussed above, it is necessary for the systemsto be intelligent. òintelligenceó is an elusive quality, the definition ofwhich differs with the speaker. although global intelligence would beideal, even systems that are intelligent only for a limited range of topics oractivities could be very useful. any ability on the part of agents to provide feedback to an individual as to its state or understanding would behelpful, particularly when operating in an anticipatory mode and tryingto predict or take semiautonomous action based on its predictions of theuserõs needs.there is also much room for progress around elicitation techniques.often, users are unaware of which questions to ask or what options areavailable to them. developing systems that can help users determinewhat they should do and how they might accomplish their desired goalscould be very powerful in helping novices or individuals with less technical skill to master and effectively use the new technologies.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces57finally, in considering agent technologies, it is important to realizethat agents may be architecturally external to the device or systems wewant them to control. this introduces the need for an òexternal agentóinterface to the software system as well: an agent that is probably onlygoing to be able to deal with ascii text or òmediumindependentó interfaces. (for a more extensive discussion of intelligent agents, see chapter 6.)supportive of social and group interactionsspeculation about very large numbers of individuals engaged in various social or interpersonal interactions (e.g., group discussions, visits topublic places such as online museums or exhibits, doing routine taskssuch as checking on the status of a filed medicare or other insuranceclaim) raises questions about what can be learned about how to makethese kinds of interactions work. (see chapter 5 for detailed discussions.)for example, what social mechanisms can be evolved or developed orexperimentally introduced that will preserve freedom of speech but prevent, reduce, or mitigate destructive individual behaviors so that largescale networkbased interactions can proceed? (this is new territory insocial theory.) will there be a need for significant numbers of humanfacilitators to give help and support; if so, what tools, interfaces, and othersupport will they need to enact their roles? what are the critical psychosocial features or dimensions of interactions with people or informationthat are likely to influence the effectiveness of publicinterest activitiescarried out via networked infrastructure? what differences are introduced by the nii media in these activities? how can nii interface designboost positive effects or damp negative ones? (in discussing some ofthese questions, workshop participants suggested that clinical communications could provide a test case.) for example, when does a communityuse setting feel okay? under what conditions or for what purposes dosuch settings not feel sufficiently private? (note that this research question concerns privacy as a psychosocial experience, not as a property ofsystems per se.) also, what are electronic analogs of emotional or otherreaction that are expressed nonverbally in inperson interactions? dosigns such as :), sometimes referred to as òemoticons,ó really work foreveryday citizens as nonverbal cues?more generally, how are the pragmatic dimensions of niibased interactions to be accommodated? for applications expected to serve largecrosssections of the public, interface design may affect experiences withand perceptions of classbased functionality in interactions between citizens and government agencies or citizens engaged in publicinterest activities based on interfaces and hardware platforms. minimizing classmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.58more than screen deepbased distinctions in those interactions can make participation more egalitarian, which may be particularly important in at least some applications,and it should be a consideration in interface and system design. in whatways might the interface representations of participants in a publicinterest interchange give status signals or otherwise produce information onsocioeconomic status (e.g., because of differences in lowcost or subsidized interfaces and highend interfaces to publicinterest functions)?how can systems for public participation be designed to obliterate statusinsignia (e.g., based on types of access that indicate very lowend machines, publicaccess community settings, subsidized users)?trustworthyñsecure, private, safe, and reliablealthough information security has often been viewed (and thereforetoo often dismissed) as specialized, the extension of information infrastructure to more citizens is driving an expansion of security to thebroader concept of trustworthiness, linking it to complementary considerations for privacy, safety, and reliability. protections are needed againstboth inadvertence and malice in a world of what mark weiser has calledubiquitous computing, where personal information infrastructures relateto more general information infrastructure, and where dependence oninformation infrastructure implies systems to assure trustworthiness ofpeople and systems with which one communicates. security mechanismsfor identification and authentication are likely to become more commonelements of interfaces; the question of how much information one shouldreveal about oneself (and in exchange for what) in that context is openand itself sensitive to technological options as well as broader publicpolicy parameters. for example, a number of technical options for automatically capturing, recording, and even analyzing data about users andtheir patterns of use (their behavior) are becoming more common but notnecessarily apparent to users.the interface aspects of information security are associated with thechallenge of making security solutions more convenient, inexpensive, andmore readily accepted and used by people. at the workshop, stephenkent, of bbn, noted three research areas, each with long roots: managingconfinement (to limit the use of information systems and resources tothose authorized), certification (for presumed public key infrastructuresas complements to assumed growth in the use of encryption for a varietyof protectionsñof privacy, security, or intellectual property and otherrights), and personal tokens for identification and authentication purposes (reflecting the shortcomings of more familiar passwordbased access control technology). separation of an identity token from a basicaccess device may take on growing importance with broader civic use ofmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces59the nii. for example, identification is required in many dealings with thegovernment; services beyond the simple supply of information requireidentification and authentication for privacy and security, and so realizing the nii promise involves joint improvement of interfaces and applications to incorporate these functions.18 depending on how the interface isdesigned, it is possible to either enhance or compromise the individualõsprivacy in carrying out transactions with the systems. this is particularlyimportant around public information systems and systems that can monitor user activity. overall, enhanced reliability of infrastructure servicesmay be supported by more attention to and integration of studies of physical device reliability, software protocols, and operator errors.the broadening base of users and applications implies a concern formany dimensions of reliability, which relates to basic system design aswell as interfaces. for individuals who are novice or less expert, as wellas those with lesser ability (physical, sensory, or cognitive), this includesthe ability to help avoid serious and nonreversible errors (although theeci concept implies this ability is valuable to all). options relate to strategies to allow more types of actions to be reversed, strategies for requiring confirmation (that do not become so automatic that they are instantlyoverridden), strategies for identifying and predicting potential mistakesor suspected mistakes, and better cueing techniques for error recovery.for heavier users potentially subject to repetitive strain injuries, the interfaces may be designed in such a way as to help detect potential injury andprovide guidance.information centeredthe growing pervasiveness of information suggests that interface designers consider a perspective that is information centered, rather than orin addition to one that is application or tool centered. at the workshop,johanna moore, of the university of pittsburgh, described this replacement as a change in the òbasic currencyó of the nii from applications toinformation. a fully informationcentered approach would allow peopleto use whatever application they wished and to extract pieces of information from documentsñsuch as lines from a table displayed in a webpage.19 in a modefree, informationcentered design, people would haveone spell checker that could be brought to bear against any text anywhere.the concept of an informationcentered perspective poses hard problems that begin with developing a better understanding of what information is. as the forms of information have diversified and intermixed inthe nii, our fundamental concept of informationñwhat we know, howwe know it, how we relate to itñhas become unstable and must be upmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.60more than screen deepdated (see box 2.5). otherwise, conflicting assumptions will confoundpeopleõs interactions with information.an informationcentered perspective implies better understanding ofthe dimensions of information that determine how well people can create,publish, search, browse, retrieve, study, integrate, validate, and use information. how good is the information? can it be trusted? is it easilyaccessible or remote and untouchable? does it form a part of a largerwhole, leading to deep understanding, or does it stand in isolation? is ituseful when found, or does it require an inordinate amount of effort onthe part of the finder to comprehend it and concentrate it? can information from different sources be integrated in meaningful ways? thesebox 2.5what is information?in addressing the question of how to provide every citizen access to the nii, weinevitably cast our questions, at least in part, in terms of information. we assume thatcitizens will use the nii to get to information, whether from relatively static information sources such as web pages, databases, email, newsgroup items, and files, orfrom more dynamic sources such as people, services, and computations. the interfaces we build for every citizen, and the research supporting their designs, will dependupon and be framed in terms of providing every citizen with access to information.the centrality of the notion of information to the development of research programs raises the question of whether the concept of information is well understood.if our understanding of this concept rested on foundations held in common andagreed upon by the joint community of researchers, funders, suppliersñof hardware,software, functionality, and contentñand the users of interfaces, then one huge areaof potential misunderstanding and difficulties could be regarded as safely under control. however, not only is there no such agreement, but many working in the fieldsthat affect interface design and development do not even recognize that there is anissue here. different communities use the term òinformationó presuming a certainmeaning, without recognition of the alternatives or of the consequences of adoptinga particular stance. different conceptions of information lead to different questions,different approaches, and different ways of evaluating solutions. given the scaleand diversity of the nii, research agendas may have to be reexamined in light of thefoundational assumptions they are making about information.in everyday conversation, òinformationó refers to facts or knowledge that may beacquired either directly by observation or indirectly by reading or hearing from another. although there is allowance for error (e.g., òhe gave me incorrect information,ómisinformation), there is usually some presumed authoritative source; the authoritymight derive from direct observation (and trusted senses) or from the reputation of thesource.there are two predominant formal technical treatments of the concept, one fromthe mathematical theory of information, the other from philosophical work in semantics. these two treatments differ from the naive conception and from one another.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces611. the mathematical theory of information is concerned with the amount ofinformation and the accuracy with which it is transmitted. it does not considermeaning; neither what the information is òaboutó nor its truth (or falsity) are factorsthat play roles in the questions that information theory asks nor the techniques itdevelops. it is thus clear why the major impact of information theory is on issues ofbandwidth, channel, and the like.2. philosophicalsemantic treatments deal instead with content and meaning;their focus is on how to treat formally the concept that some entity (the sign ormessage) òcarries the information that . . . . ó * these theories are newer and less welldeveloped than the theory of information. although they deal explicitly with theòcontentó aspect of information, which is central to everyday use of the term and theways in which òevery citizenó will conceive of information for the nii, they do notaddress issues of how information is represented, encoded, or displayed, all of whichare also of importance for ecis. furthermore, because they are grounded in òtruth,óthey are unable to deal adequately with misinformation or with questions of authoritativeness.a major issue for the nii, and certainly for ecis for the nii, is understanding howthese three different perspectivesñeveryday, mathematical, and philosophicalsemanticñrelate. integration of these perspectives will be important for economicissues (which view information as a commodity to be paid for), legal issues (e.g.,intellectual property rights), and control (e.g., personal view: ownership, conjointthe right to make change). thus, the nii must ultimately deal with a conception ofòinformationó that encompasses all facets of everyday use of the term. both themathematical and semantical theories can contribute to this understanding, but thereare facets important to the nii that neither cover.*a simple example of the concept, òx carries the information that y,ó is òsmokecarries the information that fire [is present].ó technically, the issue is that x counterfactually supports y (i.e., if one has x, then one has y and, furthermore, if y werenõtaround, one wouldnõt have x).source: austin henderson, apple computer corporation.questions go well beyond requirements for interfaces, but interfaces cansupport the user seeking to answer such questions. the central concern isdealing with large volumes of information of varying and uncertain quality, recognizing that òqualityó can be both subjective and dependent oncontext.20research to support better finding and use of information will becomplicated by the absence of standard ways to convey the quality ofinformation to people and the dependence of quality on the context ofpublication or use, suggesting value in a flexible way of representingqualityñgrounded in a sound sociological understanding of how peopleuse informationñso that people can differentiate the quality of informamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.62more than screen deeption for their own context. interface approaches should take into accountnot only the needs of end users but also the larger evolution of the information infrastructure per se: the proliferation of information and changesin its cost structure affect the demand for editing, publishing, and libraryservices as well as the demand for information per se.support for searching and retrieving, including catalogs, abstracts,and other tools, are among the challenges. ben shneiderman, of the university of maryland, argues that searching should not be invisibleñpeopleshould be informed about and have input into choices about the scope,attributes, results, and opportunities for refinement of their queries(shneiderman et al., 1997). kept informed, people can learn and growfrom novice to expert searchers. in addition, interdisciplinary assessmentcan illuminate subtle aspects relating to how information and options fortools are presented. for example, according to recent research by nassand reeves (1996), interactive media generate fundamental psychosocialcues even where not intended, and other research points to the impact ofwording in commands, messages, presentation of images, and so on.other challenges relate to the fact that publishing is not a neutralactivity, as noted above. reflecting classical concerns about control overcontent by those with control over conduits, appleõs austin hendersoncautioned, at the workshop, thatfailure of the nii [would] be that a small collection of sources broad ornarrowcast their creations to the waiting masses. as the printing presslet everybody be a reader, the copier let everybody be a publisher, thepersonal computer let everybody be a writer, so the real promise of thenii is that it will allow everybody to be an author (create and publish).the nii can give everybody a voice. a deep concern is whether suchplurality of voices will be discouraged or encouraged.concerns about control over content have shaped past public policy relating to content and equal access in broadcasting (radio and television),antitrust legal inquiries relating to screen displays in computerized reservation systems provided by airlines to travel agents, and recent publicstatements of information service providers and consumer advocatesabout screen displays associated with web browsers and other internetrelated services. public policy may impose requirements on interfacedesign; technologists should become prepared by recognizing the issueand considering the technical options for representation, display, finding,filtering, and so on. research on tools for publishing should consider theconflict between the goals of information providers and those of consumers. for example, commercial providers may want to prevent peoplefrom mixing and matching parts of services and/or missing the advertismore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces63ing. already, computer systems vendors have been contending over control and content of the initial displays associated with operating systemsand browsers. more generally, susan hockey noted, at the workshop,that even apart from explicit digital annotations or hypertext representations, the processes of transcribing a text (including encoding of accentedcharacters) or digitizing an image (including possible enhancements) involves decisions about the intellectual content of the object.one approach that may affect interface design is to more consistentlyadd metadata to information that could help peopleñor machines actingon their behalfñto interpret and integrate information. metadata describe the attributes of information such as format, quality, intended purpose, version, origin, and underlying assumptions. because everyoneviews the world differently, integrating information requires a shareddescription of semantic content. for example, at the workshop, louishecht explained that the open geographic information systems consortium inc. is working on standards for semantic translation because different geodata producers and users give the same geographic feature different names, sets of descriptive parameters, and metadata. similarly, kentwittenburg of bellcore suggested that research on standardized distributed objectlike protocols holds promise for integrating across services,noting that, although commercial services will continue to improve interfaces for searching and browsing, customizing searches across multipleservices is a longerterm problem.21according to craig knoblock, of the information sciences institute,the most natural way to model the semantic content of informationsources is in reference to ontologiesñknowledge representations that canbe constructed for a given subject area (e.g., stock market data); machinelearning technology is needed to automate model generation because thebody of information is so large.22 because the metadata also will becomesemantically drifted, knoblock argued against central standardization:òthere is going to have to be some kind of distributed solution, where ifyou have these information providers that are actually buying this information, they are going to have to change their model and update things.there has to be enough information in the underlying structure that it iseasy to make those changes. but there is no way that you can anticipateall those changes.ómoshe zloof, also at the workshop, cautioned against reinventinglessons from decades of experience with database management. newapproaches such as using agents to model the semantics of unstructureddata now flooding the web may be less effective than structuring the datato begin with (e.g., by using a relational database model). as austinhenderson observed, however, fixed structuresñwhether embodied in adatabase or modeled from diverse sources on the webñinevitably bemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.64more than screen deepcome out of date: òsuddenly my database shifts, not because anything init shifts, but because the world shifted. this is the wellknown problem ofsemantic drift. . . . [we are] never going to get everyone to agree [on astructure. we are] always going to be in the position of negotiating.ópleasant to usean important factor in attracting new users and helping them overcome their fear of technology is creating interfaces that are naturally attractive and fun to use. a key historic differentiator between home andwork, underscored by social scientists at the workshop, is the element ofòdesirabilityó: home uses of technology have tended to be discretionary,and interfaces or other aspects of technology that do not appeal to consumers are often not used in the home. the homenet study, for example,focuses much more on what people want to do than what they need to do,as would be the case at work. at the workshop, robert kraut, of carnegiemellon university, explained that there is no direct connection amongutility, usability, and desirability and that much is not understood abouthow those qualities do or can relate to each other. making systems lessthreatening, less technical looking, more familiar, and more interestingand fun will be important components in creating interfaces that willactually be approachable and used by many individuals. as mentionedabove, these systems, however, must gracefully lead to more efficientinterface strategies whenever the interesting/fun interfaces are, themselves, not efficient for longterm or general use.the pleasure, fun, or desirability of use is part of a broader pattern ofinteraction with behavior that should be considered in designing interfaces. for example, the ability, in a communications context, to see peopleon screen, especially in real time, can affect how involved an individual isbut also tends to result in payment of more attention to physical appearance, associated symbols and cues that can be removed with other communication modes, and increase in cognitive load, which affects attributions toothers and persuasiveness. regardless of context, as sara kiesler observedat the workshop, every change in an interface implies changes in socialpsychology, organizational processes, and other side effects for organizations and individualsñeffects that can be studied and anticipated.telepresence, in the form of casual video conferencing and collaboration, is the subject of much speculation about how technology can eliminate barriers to intimacy. although many technologists and businessanalysts tout video teleconferencing as a possible òkiller appó for the nii,robert kraut and sara kiesler noted that research over 25 years suggestslimited payoff to itñconversations accompanied by video are not clearer,information exchange is not betterñbut some do like it better than simplemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces65audioconferencing. similarly, different attitudes have been recorded forparticipation in text email versus systems with image transmission. moreoptimistic technologists hold out the promise that within a year or twosome people will be able to glance into the officesñhome or businessbasedñof perhaps 60 people with whom they normally interact, in contrast to most video conferencing used for remote meetings with manypeople in attendance. with the advent of wideband digital networks,ease of use, and better quality, the telecommunications center is movinginto personal computers or workstations. as the technology becomesmore widespread, most meetings could consist of two people collaborating under casual circumstances; as experimentation on the internetõsmbone multicast system suggests, extremely large (e.g., in the thousandsor more participants) or variablesize meetings also will become easierand may become more common. as discussed in chapters 4 and 5, largegroup interactions appear to be an area where more understanding ofsocial dynamics is needed.pulling it all together:eci interfaces in the year 20xxto describe the future is to risk being wrong, but it is a useful technique for showing how it may be possible to integrate the key concepts ofan eci to work seamlessly together to create a whole new paradigm forinteraction between information infrastructure and people. a simple scenario, focusing primarily on the input/output aspects, is provided below.along with demonstration or prototype projects, scenarios, per se,were suggested by workshop participants as useful elements of an interdisciplinary research program because of their amenability to computerand social science explorations that begin with their design and continuethrough assessment of the resulting roles/relationships/outcomes underdifferent rules and starting assumptions. as illustrated at the workshopby michael traynorõs telemedicine scenario, research could develop andexplore scenarios that involve multiple stakeholders and diverse intereststhat converge on cases of nii use. scenarios might also provide a training/teaching paradigm related to how new media affect extant procedures, expectations, and so on; similarly, simulation games aimed atpolicy analysis have already shown that scenarios hold promise for providing a framework or vehicle for collaborative policy deliberation amongdiverse stakeholders and for arriving at negotiated agreements on policyinputs to the nii decisionmaking process, but the methodology calls forsystematic evaluation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.66more than screen deepin the year 20xxñone scenarioit is the year 20xx. systems with ecis abound and take a wide variety offorms. some appear on workstations; others are on accessories carried aroundas a notepad or cellular phone was carried in the 1990s. these accessories,however, are multifunctional in nature and can be used to access almost anytype of information or service available. many of the ecis are simply integrated into the environment as part of rooms, vehicles, appliances, and even clothing that people wear. the generalized information systems themselves are integrated so that people can begin a task (e.g., sending a message) in their office onthe system built into a desk or wall there and continue the activity seamlessly asthey walk out the door to get into their vehicle and leave on a trip.the systems are modality independent with regard to both input and output. in the office, they may be primarily visual display based (especially if oneworks in a shared office space). however, as the user gets up and leaves, theyare able to seamlessly move from interacting in a visual fashion to interactingin a verbal fashion, completing the òemailó as they walk down the hall, get intotheir vehicle, and head for the airport. while en route, the voice interface can beused to access any of the information transaction or communications systems,in a purely verbal fashion. this might include checking weather òmaps,ó buying a gift for oneõs spouse, touching base with other colleagues, etc. since thesystems can all work either visually or verbally (words), these same systemswork equally well for colleagues who have low vision or blindness or are hard ofhearing or deaf. because the verbal information can be rendered as braille orspeech, the systems could also be used by individuals who are deaf or blind orwho are unable to read at all because of specific learning disabilities that prevent them from learning to read or read well visually.individuals who have difficulty learning the new systems or new functionson the systems find that there are builtin agents that will help them throughwhatever task they are interested in and that will interact with them in a friendly, natural language format (or that can interact with the userõs own personalagents). they can either speak to the systems aloud, type on the builtin keypad, or use any other technique or device to input information. as users become more expert, they can begin using shorthand phrases, codes, gestures, andother more efficient but less obvious strategies. the user and the systems thatthe user interacts with develop these strategies naturally over time. theseconventions are also passed from one device to another so that usersõ familiaritywith them is interchangeable as they move between physical systems. in addition to using verbal input, many of the systems will have the ability to monitorboth the environment around the individual and the individuals themselves forcontextual information.in addition, they can use global positioning systems to determine physically where the individual is and environmental databases to help understand thecontext or surroundings the individual is in at any point in time. this mayinclude a knowledge of which other people are in the immediate vicinity (inasmuch as they allow this information to be known). with information about theenvironment, the context, and the individual, the device can much more easilymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces67interpret the interactions and requests it receives from the user and may be ableto anticipate or facilitate the activities of the user as well.when an individual does not understand information that is being presented or how to achieve some objective, intelligent agents in the system are available to assist the individual in representing the information in a simpler formator to assist with instructions or with carrying out the activity. some agentsmight be autonomous and carry out tasks automatically for the user. mostagents, however, are collaborative and interactive and act more like an intelligent colleague or assistant. they are able to interact with the individual atwhatever level and in whatever modality (visual, aural, tactile) is most appropriate and most effective given the environment (noisy, etc.), situation (personõs eyes or hands are occupied, or a situation requires silent operation as in ameeting), task, and user abilities or preferences.although many situations and environments may require the use of only oneor another of the available interface modalities (e.g., visual only, verbal only),there will also be times when the full abilities of the user are available, includingsimultaneous use of whatever visual, auditory, and tactile manipulative abilitiesthe user may have. in these cases the individual can take advantage of this byusing a full immersive environment. for example, the user may use an immersive environment to simulate transport to another virtual environment. insteadof traveling to meet colleagues, the user can sit at a desk and move into a modewhere he or she visually, aurally, and manipulatively (and, eventually, tactilelyand olfactorially?) joins with other colleagues from around the country in a virtual meeting room where they communicate and exchange virtual documents orexhibits and carry out their meeting. the colleagues around the table who aredeaf can have the system invoke a speech recognizer and present its output on thescreen. (in the next decade or so, the speech recognition technology will probablystill make errors. but for clear speakers and narrow domains of discourse, recognition may be sufficient for understandability.) the text may appear to float inspace in front of the speaker, or the user can drag the text displays for differentpeople closer together in the space in front so that it is easier to monitor themsimultaneously. people who do not have a hearing impairment also find thisfeature useful, particularly if they can read faster than they can listen and find iteasier to focus attention on a particular verbal stream or to check over what wassaid when everybodyõs speech is presented visually. it also allows them to checkback over what was said. this is particularly valuable if they are trying to listento multiple overlapping discourses. colleagues who are blind or who have difficulty reading any of the printed materials can have the materials presented tothem aurally or translated into a form that is easier to understand. sightedindividuals also take advantage of this feature in order to allow them to continuemonitoring the situation or demonstration with their eyes while the textual information is being fed to them aurally. even an individual who is deaf or blind canhave the information translated and presented on a special dynamic braille andtactile display that can be attached to the system.immersive environments can be used for a wide range of functions beyondallowing an individual to travel to and visit most any real or simulated spot onearth. they also allow the individual to scale themselves larger or smaller inmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.68more than screen deeporder to explore or better learn about objects or environments (e.g., the ability tozoom in and out to learn about geography, biology, etc.). they are also used toallow individuals to explore things with their senses that are not available totheir senses. this includes seeing the invisible, hearing the inaudible, andtranslating concepts that have no physical form (such as information) into visual or auditory formats in order to gain new insights. again, users with all oftheir senses intact can choose to have the information presented in simultaneous multisensory form. individuals for whom some senses are weaker orabsent have the information presented in forms that best meet their individualabilities and learning styles.notes1.in addition, early experiences are often limited indicators of new technologyõsbenefits: the 1980s and early 1990s discussions of the òproductivity paradoxó suggest thatdisappointing financial returns from early computing investments reflect relatively simpleminded automation of existing work processes rather than the fundamental restructuringof those processes that has proved necessary to realize the full benefits of computing. seecstbõs information technology in the service society (cstb, 1994b).2.an interagency assessment of issues and opportunities for kiosks in governmentapplications proposed a staged pilot and market test program that would support datagathering and incorporation of feedback into future design and deployment steps (seegovernment information technology service (gits), 1995).3.the idc data are at the household level and thus likely to produce higher percentages than the individuallevel data from the census bureau survey. however even ifboth data sets were at the individual level, it would still be impossible to draw meaningfulcomparisons, because they used different sample weightings in order to factor their resultsto the scale of the whole population. this is one example of the difficulty of identifyingtrends and making comparisons from survey data in this field.4.project 2000 researchers statistically corrected the cnids data to weight thesample in proportion to the u.s. population for gender, age, and educationñvariablesknown to affect the likelihood of internet use. income was not included because of a highnonresponse relate for income in the cnids survey; education, however, is a reasonableproxy for income. the researchers also adjusted the data to omit logically inconsistentresponses that the cnids had included, such as those from people who initially reportedhaving used the internet but later in the survey reported the opposite. see hoffman et al.(1996).5.whether new webpage publishing tools are readily usable by nonspecialistsremains an open question. for an anecdotal account that illustrates the difficulties noviceshave with such applications (among others), see rigdon (1996).6.of course, a number of innovative applications of multimedia technology havebeen introduced for education, but several education experts believe the promise of suchtechnology is only beginning to be tapped.7.a further challenge results from the level of exposure to a given environment,situation, or task; for example, there is a difference between a mobile phone one rarelylooks at, a phone one never looks at, and a phone one uses frequently.8.a related concern is whether there are general skills that people can learn for usein a variety of settings. does learning in a specific context ever limit the usefulness of theresulting knowledge?9.for example, internet bridge clubs type in bids without idle chitchat; they sitmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.requirements for effective everycitizen interfaces69locked in their houses, staring at text, punching at keyboards.10.by contrast, the encoding features of the hypertext markup language are mainlyused to control the appearance of text (e.g., bold type, fonts, blinking text). htmlõs descriptive codes are mostly for lowlevel constructs such as emphasis or indented lists. it hasno standard mechanism for indicating common document parts such as author, abstract,keywords, or references. new html codes (tags) for such elements could have the sidebenefit of being interpretable by software agents for automatic indexing and searching.new tags are continually being proposed and implemented; however, the resulting lack ofstandardization hinders content producers, because a conscientious web author must testpages to ensure that they appear properly when viewed with a variety of web browsersthat support different overlapping sets of tags (schulzrinne, 1996).11.note that capabilities for filtering and blocking stand out as features specificallycontemplated for children as a subpopulation.12.according to the crossindustry working team (1995), nomadicity refers to theability of people to easily access a rich set of services, other people, and content while theyare on the move, at intermediate stops and at arbitrary destinations; ubiquitous refers tosystems that access communications and computing services via the nii and that will be atleast as common as todayõs telephone. moreover, the nii will facilitate connectivity througha wide range of electronic devices, including portable, mobile, and wireless computing andcommunications.13.u.s. sales of interactive kiosk hardware were $449 million in 1994 and estimatedat $610 million for 1995. the retail sector accounts for 84 percent of kiosks installed in 1995,but venture development corporation (vdc, 1996c) expects faster growth in financial,government, and corporate use. informationdispensing kiosks are about 60 percent of1995 installations; the remainder are pointofsale manufacturing kiosks (e.g., greeting cardand business card printing) and transactional (e.g., product ordering, driverõs license renewal). vdc expects faster growth in transactional kiosks than in information deliverykiosks, partly because return on investment is easier to justify for a kiosk that sells something than for one that gives free information.14.the most detailed recent survey of disabilities by the census bureau is the 1993survey of income and program participation. although the data are now several years old,it is unlikely that the percentages of people with various disabilities have changed significantly. see http://www.census.gov/hhes/www/disable.html.15.the survey involved interviews with over 26,000 adults. it measured skills likelyto be required in work, home, and community contexts, such as locating and integratinginformation in a prose passage; writing new text; interpreting lists, charts, and graphs; andreading and using numerical information (u.s. department of education, 1992).16.in addition, as wallace feurzeig observes in his paper in this volume, spokenlanguage interfaces allowing literacy training systems to integrate spoken and written communications could enhance training by enabling learners to build on their spoken languageabilities.17.interoperability is being advanced through standards such as mpeg for videocoding and h.323 for multimedia conferencing. there appears to be a trend for weboriented multimedia products (telephony, conferencing) to conform to these standards,which, in the immediate future, will make it much easier to communicate without elaborateprearrangements. interoperability is also advanced, as described earlier, through the use oftransportable software (in a standardized language and virtual machine), which removesthe necessity of every party to a session needing to have all of the application software inadvance, and distributed object systems, which allow existing applications on diverse computing platforms to interact with one another. standards are taking on new meaning as ameans for facilitating interaction between applications or customizing equipment withmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.70more than screen deeptransportable software, rather than being rigid constraints on the equipment. networks, aswell as applications, can be customized with transportable software, and programmablenetworks are a significant nearfuture research topic.18.how and when these developments take place depends in part on relevant public policy parameters (e.g., the evolution of cryptography policy).19.a documentcentered approach represents a midpoint, in which people coulduse various applications, but would still have to access whole documents rather than datafrom within documents.20.at the workshop, robert kraut, of carnegie mellon university, noted that because information is not a passive, inactive thing, it can have different values for consumersand producers. for example, a babysitter who wants to advertise to parents in the neighborhood probably values that information more than the parent who feels bombarded withadvertisements from many sources.21.see http://wwwdb.stanford.edu/~gravano/standards.22.knoblock refers to information in the web, but the observation applies moregenerally to all forms of information in the nii.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies7171meeting the everycitizen interface (eci) criteria described in chapter2 will require advances in a number of technology areas. some involveadvances in basic underlying display and interface technologies (higherresolution visual displays, threedimensional displays, better voice recognition, better tactile displays, and so on). others involve advances in ourunderstanding of how to best match these input/output technologies tothe sensory, motor, and cognitive capabilties of different users in differentand changing environments carrying out a wide variety of tasks. but thenew interfaces will need to do more than just physically couple the user tothe devices. to meet these visions, the interfaces must have the ability toassist, facilitate, and collaborate with the user in accomplishing tasks.subsequent chapters address interface designñthe creation of interfaces that make the bestpossible use of these humanmachine communications technologiesñand system attributes that lie beneath the veneer ofthe interface, such as system intelligence and software support for collaborative activities. this chapter examines the current state and prospective advances in technology areas related directly to communication between a person and a systemñhardware and software for input (to thesystem) and output (to a human). the emphasis is on technical advancesthat, if implemented in welldesigned systems (as stressed in chapter 4),hold the potential to expand accessibility and usability to many morepeople than at present. the discussion includes a cluster of speech input/output technologies; natural language understanding (including restrictedlanguages with limited vocabularies); keyboard input; gesture recogni3input/output technologies:current status and researchneedsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.72more than screen deeption and machine vision; auditory and touchbased output; interfaces thatcombine multiple modes of input and output; and visual displays, including immersive or virtual reality systems. because the eci challenge involves connecting to the information infrastructure, rather than just tostandalone systems, this chapter reviews the current status of and research challenges for interfaces for systems in largescale national networks. the chapter ends with the steering committeeõs conclusions, basedon workshop discussions and other inputs, about the research prioritiesto advance these technologies and our understanding of how to use themto support every citizen.framing the input/output discussionñlayersof communicationthe interface is the means by which a user communicates with a system, whether to get it to perform some function or computation directly(e.g., compute a trajectory, change a word in a text file, display a video); tofind and deliver information (e.g., getting a paper from the web or information from a database); or to provide ways of interacting with otherpeople (e.g., participate in a chat group, send email, jointly edit a document). as a communications vehicle, interfaces can be assessed and compared in terms of three key dimensions: (1) the language(s) they use, (2) theways in which they allow users to say things in the language(s), and (3) thesurface(s) or device(s) used to produce output (or register input) expressions of the language. the design and implementation of an interface entailchoosing (or designing) the language for communication, specifying theways in which users may express òstatementsó of that language (e.g., bytyping words or by pointing at icons), and selecting device(s) that allowcommunication to be realizedñthe input/output devices.box 3.1 gives some examples of choices at each of these levels. although the selection and integration of input/output devices will generally involve hardware concerns (e.g., choices among keyboard, mouse,drawing surfaces, sensorequipped apparel), decisions about the languagedefinition and means of expression affect interpretation processes that arelargely treated in software. the rest of this section briefly describes eachof the dimensions and then examines how they can be used to characterize some currently standard interface choices; the remainder of the chapter provides an examination of the state of the art.language contrasts and continuumthere are two language classes of interest in the design of interfaces:natural languages (e.g., english, spanish, japanese) and artificial lanmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies73box 3.1layers of communications1.language layer¥natural language: complex syntax, complex semantics (whatever a humancan say)¥restricted verbal language (e.g., operating systems command language, airtraffic control language): limited syntax, constrained semantics¥direct manipulation languages: objects are ònounlike,ó get òverb equivalentsó from manipulations (e.g., drag file x to trash means òerase xó; drag message onto outgoing mailbox means òsend messageó; draw circle around object yand click means òiõm referring to y, so i can say something about it.ó)2. expression layermost of these types of realization can be used to express statements in most of theabove types of languages. for instance, one can speak or write natural language;one can say or write a restricted language, such as a commandline interface; andone can say or write/draw a direct manipulation language.¥speaking: continuous speech recognition, isolatedword speech recognition¥writing: typing on a keyboard, handwriting¥drawing¥gesturing (american sign language provides an example of gesture as therealization (expression layer choice) for a fullscale natural language.)¥pickfromset: various forms of menus¥pointing, clicking, dragging¥various threedimensional manipulationsñstretching, rotating, etc.¥manipulations within a virtual reality environmentñsame range of speech,gesture, point, click, drag, etc., as above, but with three dimensions and broaderfield of view¥manipulation unique to virtual reality environmentñlocomotion (flyingthrough/over things as a means of manipulating them or at least looking at them)3. deviceshardware mechanisms (and associated devicespecific software) that provide away to express a statement. again, more than one technology at this layer can beused to implement items at the layer above.¥keyboards (many different kinds of typing)¥microphones¥light pen/drawing pads, touchsensitive screens, whiteboards¥video display screen and mouse¥video display screen and keypad (e.g., automated teller machine)¥touchsensitive screen (touch with pen; touch with finger)¥telephone (audible menu with keypad and/or speech input)¥pushbutton interface, with different button for each choice (like big buttonson an appliance)¥joystick¥virtual reality input gearñglove, helmet, suit, etc.; also body position detectorsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.74more than screen deepguages (e.g., programming languages, such as c, java, prolog; databasequery languages, such as sql; mathematical languages, such as logic;command languages, such as cshell provides). natural languages arederived evolutionarily; they typically have unrestricted and complex syntax and semantics (assignment of meaning to symbols and to the structures built from those symbols). artificial languages are created by computer scientists or mathematicians to meet certain design and functionalcriteria; the syntax is typically tightly constrained and designed to minimize semantic complexity and ambiguity.because an artificial language has a language definition, constructionof an interpreter for the language is a more straightforward task thanconstruction of a system for interpreting sentences in a natural language.the grammar of a programming language is given; defining a grammarfor english (or any other natural language) remains a challenging task(though there are now several extensive grammars used in computationalsystems). furthermore, the interactions between syntax and semanticscan be tightly controlled in an artificial language (because people designthem) but can be quite complex in a natural language.1,2natural languages are thus more difficult to process. however, theyallow for a wider range of expression and as a result are more powerful(and more ònaturaló). it is likely that the expressivity of natural languages and the ways it allows for incompleteness and indirectness maymatter more to their being easy to use than the fact that people alreadyòknow them.ó for example, the phrase, òthe letter to aunt jenny i wrotelast march,ó may be a more natural way to identify a letter in oneõs filesthan trying to recall the file name, identify a particular icon, or grep (aunix search command) for a certain string that must be in the letter. thecomplex requests that may arise in seeking information from online databases provide another example of the advantages of complex languagesnear the natural language end of this dimension. constraint specifications that are natural to users (e.g., òdisplay the protein structures havingmore than 40 percent alpha helixó) are both diverse and rich in structure,whereas menu or formbased paradigms cannot readily cover the spaceof possible queries. although natural language processing remains achallenging longrange problem in artificial intelligence (as discussedunder ònatural language processingó below in this chapter), progresscontinues to be made, and better understanding of the ways in which itmakes communication easier may be used to inform the design of morerestricted languages.however, the fact that restricted languages have limitations is not,per se, a shortcoming for their use in ecis. limiting the range of language in using a system can (if done right) promote correct interpretationby the system by limiting ambiguity and allowing more effective commumore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies75nication. for instance, the use of domain and taskspecific restrictedlanguages for certain applications of speech recognition systems has produced results, allowing people to use speech to communicate when theycannot see (either because they are limited by the communication devicebeing used, such as the telephone, or because of physical impairment).radiologistsõ workstations, for example, allow the use of speech as theprimary means of inputting reports on xrays or other radiographic tests.direct manipulation languages may be ideal if there is a close match towhat the user wants to do (and hence is able to òsayó), that is, if the userõsneeds are anticipated and the user will not need to program or alter whatthe system does; they can be a robust means of control that limits the riskof system crashes from misdirected user actions.in short, the design of an interface along the language dimensionentails choices of syntax (which may be simple or complex) and semantics(which can be simple or complex either in itself or in how it relates tosyntax). more complex languages typically allow the user to say morebut make it harder for the system to figure out what a person means.expression contrastsa natural language sentence can be spoken, written, typed, gestured,or selected from a menu. an artificial language statement also can bespoken, written, typed, gestured, or selected from a menu.language expression can take many forms, generally differentiatedas being more or less continuous or involving selection from a set ofoptions (e.g., a menu). speaking can involve isolated words or continuous speech recognition. writing can involve handwriting or typing; drawing can be free form or can use prespecified options. gesturingñindependently or to manipulate objectsñcan be free form, can involve afullscale natural language (e.g., american sign language), or can involve a more restricted set of prespecified options (e.g., pointing, dragging, stretching, rotating). virtual reality and other visualization techniques represent a multimedia form of expression that may involvespeech, gesture, direct manipulation, and haptic and other elements.thus, the different ways of saying things in a language may also bedivided into two structural categoriesñfree form and structuredñandseveral different realization categories: typing, speaking, pointing. freeform expression is usually more difficult to process than structured expression. for example, a sentence in natural language can be spokenòfree formó (this is what we usually think of with natural language), or itmight be specified by picking one word at a time out of a structuredmenu.3 in the structured form the system can control what the user getsto choose to òsayó next, and so it is much easier for a system to interpretmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.76more than screen deepand handle. within a given form, some means of realization may beeasier to handle than others (e.g., correctly typed words are easier tointerpret than handwritten words; freehand drawings are more difficultthan structured cad/cam (computeraided design/computeraidedmanufacturing) diagrams). it is also important to note that more structured systems may be preferable for certain applications, such as thoseinvolving completion of forms (oviatt et al., 1994).menu/icon systems thus provide an alternative way of expressingcommandlike languages. they have underlying languages, typicallyvery much like command languages. the commands (natural languageverb equivalents) are often menu items (e.g., òselect,ó òeditó); the parameters (natural language noun equivalents) are icons (or open files); andthe statements (natural language sentence equivalents) are sequences ofselect ònounsó and òverbs.ó the menus and icons provide the structurewithin which a user can say something in the language.devicesthe hardware realization of communication can take many forms;common ones include microphones and speakers, keyboards and mice,drawing pads, touchsensitive screens, light pens, and push buttons. thechoice of device interacts with the choice of medium: display, film/videotape, speaker/audiotape, and so on. there may also be interactions between expression and device (an obvious example is the connection between pointing device (mouse, trackball, joystick) and pulldown menusor icons). on the other hand, it is also possible to relax some of theseassociations to allow for alternative surfaces (e.g., keyboard alternativesto pointers, aural alternatives to visual outputs). producing interfaces forevery citizen will entail providing for alternative input/output devicesfor a given languageexpression combination; it might also call for alternative approaches to expression.comparisons among graphical user interfaces,natural language, and speechthe languageexpressiondevice framework can be used to gain perspective on current standard interface types and on the research opportunities and challenges presented by ecis. for example, it makes clear thatnatural language processing and speech recognition (and other technologies that may be associated colloquially) introduce different issues anddifferent tradeoffs. a speechbased interface such as at&tõs longdistance voice recognition system, which can recognize phrases such as òcollect calló and òcalling card,ó4 can combine a restricted language withmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies77speech as a means of expression. as this example illustrates, neitherspeech recognition with unlimited vocabulary nor complete/comprehensive language understanding is necessary to provide natural languagelike input to a system within a restricted domain and task. similarly, it ispossible to improve restricted language interfaces by applying principlesfrom natural language communication.current graphical user interface/menu/icon systems tightly constrainwhat one can say, both by starting with a very constrained language and byhaving a structured way in which one can express things in that language.they are at the opposite end of both the language and the expression spectrum from natural languages. it is thus clear why they are easier to process,but also why they are more constraining (cohen and oviatt, 1994).ongoing efforts to develop speech interfaces for web browsers provide a concrete example of the importance of understanding the differenttradeoffs of each of these dimensions. choosing speech on the expressionlayer rather than pointing and clicking would lead to being able to òspeakóthe icons and hyperlinks that are designed for keyboard and mouse. although this may suffice in certain settingsñreplacing one modality foranother can be useful in handsfree contexts and for those with physicallimitationsñit does not necessarily expand a systemõs capabilities or leadto new paradigms for interactions. an alternative approach would be toexplore how spoken language technology can expand the userõs ability toobtain the desired information easily and quickly from the web, leadingto a different, probably more expressive, language. from this perspective, speech would augment rather than replace the mouse and keyboard,and a user would be able to choose among many interface languageexpression options to achieve a task in the most natural and efficientmanner.natural language interaction is particularly appropriate when the information space is broad and diverse or when the userõs request containscomplex constraints. both of these situations occur frequently on theweb. for example, finding a specific home page or document now requires remembering a universal resource locator, searching through theweb for a pointer to the desired document, or using one of the keywordsearch engines available. current interfaces present the user with a fixedset of choices at any point, of which one is to be selected. only by stepping through the offered choices and conforming to the prescribed organization of the web can users reach the documents they desire. themultitude of indexes and metaindexes on the web is testimony to thereality and magnitude of the problem. the power of a human/naturallanguage in this situation is that it allows the user to specify what information or document is desired (e.g., òshow me the white house homepage,ó òwill it rain tomorrow in seattle?ó or òwhat is the zip code formore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.78more than screen deeporlando, florida?ó) without having to know where and how the information is stored. a natural language, regardless of whether it is expressedusing speech, typing, or handwriting, offers a user significantly morepower in expressing constraints, thereby freeing the user from having toadhere to a rigid, preconceived indexing and command hierarchy.in examining the state of the art of various input/output technologies, it is important to recognize that no single choice is right for allinterfaces. in fact, one of the major challenges of interface design may bedesigning a language that is powerful enough for a user to say whatneeds to be said, but in as constrained a manner as possible, while stillhaving the power to make processing easier and the possibility of misinterpretation less likely. in looking at input/output options, it will beuseful to keep in mind where various options fall on one or another ofthese scales and the tradeoffs implicit in choosing a given option.technologies for communicating with systemshumans modulate energy in many ways. recognizing that fact allows for exploration of a rich set of alternatives and complementsñat anytime, a userchosen subset of controls and displaysñthat a focus on simplicity of interface design as the primary goal can obscure. current directmanipulation interfaces with twodimensional display and mouse inputmake use, minimally, of one arm with two fingers and a thumb and oneeyeñabout what is used to control a television remote. it was considereda stroke of genius, of course, to reduce all computer interactions to thissimple set as a transition mechanism to enable people to learn to usecomputers without much training. there are no longer any reasons (including cost) to remain stuck in this transition mode. we need to developa fuller coupling of human and computer, with attention to flexibility ofinput and output.in some interactive situations, for example, all a computer or information appliance needs for input is a modulated signal that it can use todirect rendered data to the userõs eyes, ears, and skin. over 200 differenttransducers have been used to date with people having disabilities. inwork with severely disabled children, david warner, of syracuse university, has developed a suite of sensors to let kids control computer displayswith muscle twitches, eye movement, facial expressions, voice, or whatever signal they can manage to modulate. the results evoke profoundemotion in patients, doctors, and observers and demonstrate the value ofresearch on human capabilities to modulate energy in real time, the sensors that can transduce those energies, and effective ways to render theinformation affected by such interactions.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies79the state of the art in a range of technologies for communicating withsystems is reviewed below. also addressed are the device and expressionlayers of the model described in the previous section and summarized inbox 3.1. the choice of languageñnatural, restricted, or direct manipulationñinfluences but does not dictate the technologies discussed here.the exception is the subsection, ònatural language processing,ó whichalso encompasses the language layer of the model and discusses howchoices along a spectrum from fully natural languages to relatively restricted languages influence the performance of various expressionmodes, particularly speech input.speech synthesistexttospeech systems, or speech synthesizers, take unrestricted textas input and produce a synthetic spoken version of that text as output.most current commercial synthesizers exhibit a high degree of intelligibility, but none sound truly natural. the major barriers to naturalness aredeficiencies of text normalization, intonational assignment, and synthesized voice quality. female speech and childrenõs speech are generallyless acceptable than adult male synthetic speech, probably because theyhave been studied less (roe and wilpon, 1994).in the course of transforming text into speech, all texttospeech systems must do the following:¥identify words and determine their pronunciations;¥decide how such items as abbreviations and numbers should bepronounced (text normalization);¥determine which words should be made prominent in the output,where pauses should be inserted, and what the overall shape of the intonational contour should be (intonation assignment);¥compute appropriate durations and amplitudes for each of thewords that will be synthesized;¥determine how the overall intonational contour will be realizedfor the text to be synthesized;¥identify which acoustic elements will be used to produce the spoken text (for concatenative synthesizers) or to retrieve the sequences ofappropriate parameters to generate synthetic elements (for format synthesizers);5 and¥synthesize the utterance from the specifications and/or acousticelements identified.while most systems permit some form of user control over various parameters at many of these stages, to finetune system defaults, documenmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.80more than screen deeptation and tools for such control are usually lacking, and most users lackthe requisite background to produce satisfying results.particularly for concatenative synthesizers, it is difficult and time consuming to produce new voices, since each voice requires that a new set ofconcatenative units be recorded and segmented. while most researchgroups are developing tools in an attempt to automate this process (oftenby using automatic speech recognition systems to produce a firstpasssegmentation), none have succeeded in eliminating the need for laborioushand correction of the database. there have also been efforts in recentyears to automate the production of other components of synthesis, tofacilitate the production of synthesizers in many languages from a singlearchitecture.we know that synthetic speech should sound better. it is not clear,exactly, how to decide what is better: more natural and more humanlike? more intelligible? more intelligible at normal talking speeds or athigh speeds? speech is usually used for conversational modes of interaction. when speech is being used for presenting a web page, for example,there is additional information that needs to be provided: which wordsform links? which words are italicized? how is this information presented most effectively? how should words be dealt with that havemultiple different pronunciations in different parts of the country or todifferent individuals?speech input/recognitionthe full integration of voice as an input medium, if achievable, couldalleviate many of the known limitations of existing humanmachine interfaces. people with poor or no literacy skills, people whose hands arebusy, people suffering from cumulative trauma disorders associated withtyping and pointing (or seeking to avoid them)ñcould all benefit fromspoken communication with systems. while the capabilities envisionedin such a system are well beyond the state of the art in both speech recognition and language understanding at present, the technology has advanced sufficiently to allow very simple voicebased applications toemerge (see below).speech recognition research has made significant progress in the past15 years (roe and wilpon, 1994; cole and hirschman, 1995; cole et al.,1996). the gains have come from the convergence of several technologies:higheraccuracy continuous speech recognition based on better speechmodeling techniques, better recognition search strategies that reduce thetime needed for highaccuracy recognition, and increased power of audiocapable, offtheshelf workstations. as a result of these advances,realtime, speakerindependent, continuous speech recognition, with vomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies81cabularies of a few thousand words, is now possible in software on regular workstations.in terms of recognition performance, word error rates have droppedby more than an order of magnitude in the past decade and are expectedto continue to fall with further research. these improvements have comeabout as a result of technical as well as programmatic innovations. technically, there have been advances in two areas. first, a paradigm shiftfrom rulebased to modelbased methods has taken place. in particular,probabilistic hidden markov models (hmm) have proven to be an excellent method of modeling phonemes in various contexts. this modelbased paradigm, with its ability to estimate model parameters automatically from training data, has shown its power and versatility by applyingthe technology to various languages, using the same software. second,the use of statistical grammars, which estimate the probability of twoand threeword sequences, have been instrumental in improving recognition accuracy, especially for largevocabulary tasks. these simple statistical grammars have, so far, proven to be superior to traditional rulebasedgrammars for speech recognition purposes.programmatically, the collection and dissemination of standard, common training and test corpora worldwide, the sponsorship of commonevaluations, and the dissemination at workshops of information aboutcompeting methods have all ensured very rapid progress in the technology. this programmatic approach was pioneered by the defense advanced research projects agency (darpa), which continues to sponsorcommon evaluations and initiated the establishment of the linguistic dataconsortium, which has been in charge of the collection and disseminationof common corpora. a similar approach is now being taken in europe.word error rates for speakerindependent continuous speech recognition vary a great deal, depending on the difficulty of the task: from lessthan 0.3 percent for connected digits, to 3 percent for a 2,500word travelinformation task, to 10 percent for articles read from the wall street journal, to 27 percent for transcription of broadcast news programs, to 40percent for conversational speech over the telephone. although worderror rates in the laboratory can be quite small for some tasks, error ratescan increase by a factor of four or more when the same systems are usedin the field. this increase has various causes: heavy accents, ambientnoise, different microphones, hesitations and restarts, and straying fromthe systemõs vocabulary.speech recognition has begun to enter the mainstream of everydaylife, chiefly through telephonebased applications (margulies, 1995). themost visible of these applications involve directory assistance services,such as the recognition of a few words (e.g., the digits and words such asòoperator,ó òyes/no,ó òcollectó) or recognition of the names of cities in amore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.82more than screen deepparticular area code. speakerindependent recognition of overthephonedigit strings (more difficult than singledigit recognition) has been deployed since 1990.6 other applications include voiceactivated dialing(especially useful for cellular phones), personal assistant services (to manage oneõs telephone at work), and call router applications (where thecaller says the personõs full name instead of dialing). other less prevalentapplications include obtaining stock and mutual fund quotes by voice,simple banking services, and bill payment by telephone.7other operational applications of speech recognition include air traffic control training, dictation, and internet access. largevocabulary dictation systems capable of recognizing discrete speech are available on themarket and have been used for years. for continuous speech there aresystems that are capable of recognizing a few thousand words in realtime; at least one of these systems is now being marketed for the dictationof radiology reports. systems for using voice for internet access haverecently been announced.simply making speech recognition available with machines, however,does not necessarily make it immediately useful; it will have to be interfaced properly with the other modalities so that it appears seamless to theuser (martin et al., 1996). (several vendors have been shipping speechrecognition capabilities with personal computers, but there is little evidence of wide usage.) optimism for general use of speech technologiescomes from the facts that performance levels are continuing to improveand that many applications do not require large vocabulary sizes. however, applications must be designed to take into account the fact thatrecognition errors will occur, either by allowing the user to correct errorsor by designing additional error correction mechanisms, such as properinclusion of humanmachine dialogue capabilities. these include the ability to deal with issues such as how to phrase a system prompt, how todetermine if a recognition error has occurred, and how to engage in conversational repair if such a determination is made. other speech integration issues include habitability (the ability of a user to stay within thesystemõs vocabulary most of the time), portability (the ease with which aspeech recognition system can be ported to a new domain), and userexperience (different users, depending on their experience, may requiredifferent types of interaction).looking into the future of the national information infrastructure(nii), speech recognition could have many applications, such as command and control, information access and retrieval, training and education, email and memo dictation, and voice mail transcription. the current state of the art in speech recognition can support these applications atvarious levels of performance, some quite well (e.g., command and control) and others not well at all (e.g., voice mail transcription). functionsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies83that perform information access, such as making an airline reservation,may require the use of a certain level of language understanding technology. the state of the art in that field only allows for the simplest of suchapplications at this time (see ònatural language processingó below).despite significant progress in speech recognition technology in thepast decade, the fact remains that machine performance may still not begood enough for many applications. as a barometer of how muchprogress we may need for certain advanced applications, experimentshave shown that human speech recognition performance is still at least anorder of magnitude better than that of machines. one optimistic note,however, is that commercialization of the technology is proceeding veryvigorously and is lagging the corresponding research capabilities by onlya few years, so that any advances in the laboratory can be expected toappear on the market with a delay of only a few years.speaker verificationa related but quite different technology is speaker verification. therehas been much concern about private and secure communications overthe internet, especially for business information and financial transactions. although encryption methods will be used more and more toprotect digital data, it will still be necessary to make a more positiveidentification of customers for certain types of transactions. speaker verification technology can be used to help provide additional security.in an initial enrollment phase, each user is enrolled in a system byproviding samples of his or her voice. system performance improvesover time as the user supplies more voice samples. using those voicesamples, the system creates a model for the voice of each user. then,when in operation, the system prompts the user to say a (random) phraseand, using the stored model of the user with the claimed identity, computes the likelihood that the speech came from that person. the user isthen either accepted or rejected.the performance of a speaker verification system is often measuredby the equal error rate (eer), which is the operating point in a systemwhere the false rejection rate is equal to the false acceptance rate. in thelaboratory, an eer of less than 0.5 percent can be achieved. performancetypically degrades to an eer of 2 to 4 percent in the field.while the current state of the art may be sufficient for lowsecurityapplications, it would not, by itself, be adequate for highsecurity applications. however, if combined with other security measures, such as use ofa pin (personal identification number), speaker verification can providethe added desired security for many applications of interest.for users with physical disabilities who would like to have voiceonlymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.84more than screen deepaccess to devices and systems, speaker verification could be of great benefit. it should be noted, however, that there are a significant number ofpeople who are unable to speak clearly or reliably. for those people,alternate means of verification will be necessary if they are to use systemsthat rely on voice verification.alternate keying/typing approaches: strategies and acceleratorsas speech recognition becomes accurate and reliable, it will play amuch larger role in future interface systems than it does today. it will not,however, ever completely replace or obsolete keyboard or keypad inputto systems. keying information into systems will continue to be a quiet,accurate, noiseimmune (and, for some applications, faster) means of inputting data or commands. furthermore, even as the performance ofnatural language understanding improves, freeform typing of naturallanguage will remain a viable alternative to spoken input to such systems.today, keypads and keyboards range from systems that are as smallas a wristwatch and are operated with a pen tip, to large, wallsizedkeyboards operated with a light pen. common keyboards are operatedby using all 10 fingers, which push keys one at a time. other keyboardshave been developed that are chordic in nature and involve the pressingof multiple keys simultaneously. many of these do not require the user toever remove his or her hand.in addition to pressing discrete keys, data can also be input usinggestures. finger spelling is one technique. today, there are gloves thatallow the wearer to spell out the desired characters using fingerspellinggestures. techniques are also being explored that use cameras to takedata via both finger spelling and sign language.handwriting is another common method for entering alphanumericdata. there are techniques for recognizing letters formed in the standardway, as well as techniques (such as ògraffitió) that increase the accuracy ofhandwritten characters by having the user write with letters that are similarto, but different from, the standard characters people are familiar with.to increase the rate of data entry, a number of abbreviation and prediction techniques have been developed. abbreviation techniques allowan individual to use a smaller set of letters (which can resemble the targetword, such as òabvó for òabbreviation,ó or be completely arbitrary suchas òt1ó for òplease call homeó). prediction techniques look at what aperson has typed and try to guess what the next word or words would be.prediction techniques are less useful for people who can enter data quicklysince the time spent looking at the systemõs guesses may slow one downto the point where it is faster to just enter the data. however, for individuals who have to enter data very slowly or for those who have diffimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies85culty spelling (e.g., because of a learning disability, cognitive impairment,second language), systems that can guess words correctly can significantly increase their rate of communication. if a system always guessesconsistently (e.g., when òtó is typed, it guesses òtheó; when òthó is typed,it guesses òthereó), the user can begin using it for prediction techniques,but very quickly switch over to using it as abbreviation expansion (e.g.,the user types òtó and then the confirm button because the user knowsthat the system will have guessed òtheó). ironically, systems that monitorthe context and change their guesses to better match the context preventan individual from getting into the faster abbreviation expansion mode.if systems can predict whole sentences or phrases, however, their utilitywould increase. this is usually possible only, however, for stereotypiccommunication (vanderheiden et al., 1986).in some aspects this area is one of the more thoroughly researchedones. however, it is not clear what the best techniques are for combiningthese input techniques for using keyboard input in connection with speechand other virtual reality and gestural input systems. what is the best wayto use a minimalist keyboard with a voice response system either in a keyin/voiceout paradigm or to help handle error correction in voice recognition systems? also, currently there are no good mechanisms for providing keyboardbased input when people are walking or moving aboutin virtual realitylike environments.natural language processing8natural languageñspoken, written, or even signedñis at the heart ofhuman communication. it is key to interaction between humans and themedium for much of the vast amount of information stored in books,newspapers, scientific journals, audio and video tapes, and now webpages. as a means of interaction with computers, it requires no specialtraining on the part of users, but it remains uncommon because of thedifficulties in supporting it technically. to date, there have been a number of successful commercial applications of natural language processing,including grammar and stylechecking programs; text indexing and retrieval systems, particularly for the namedentity task9 database queryproducts that utilize natural language as input, which are being marketedfor targeted applications; abstracting software (for summarizing blocks oftext), which has been introduced commercially; and machineaided translation programs. access to the nii could be made easier and more productive if people could interact with a computer using natural languageand if the computer could better retrieve, summarize, and understand thewealth of linguistic information at its disposal.10over the years, natural language processing (nlp) has focused primore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.86more than screen deepmarily on three tasks: (1) database access, from typed or spoken queries;(2) information extraction, or the generation of formatted summaries fromtexts such as newspaper stories, military messages, and web pages; and(3) machine translation of typed or spoken utterances from one languageto another. the challenge of nlp is to build systems that can distinguishin the input language as many significantly different meanings as arerelevant to the applications of interest; to interpret correctly as large avariety of linguistic expressions of these meanings as would naturallyoccur; and to do so in as many task settings as possible, with the computational resources available.until recently, most nlp systems shared the same gross architecture,roughly analogous to that of programming language compilers: a syntactic analyzer, or parser, to identify the lexical category of the words of theinput sentence11 and their hierarchical organization into phrases andclauses; a semantic analyzer, to construct a representation of the meaningof the input sentence, generally independent of the specific task or application domain; and, finally, a domain and taskspecific mapping fromthe semantic interpretation to a representation suitable to the task at hand,such as a database query for query systems, a filled template for information extraction systems, or an input into a language generation modulefor a machine translation system.12 in the current practice, several hundred rules may need to be handcoded for a new application, even in alimited domain.13in the early 1990s, nlp took several new directions, largely at theinstigation of a succession of darpa program managers. first, afteryears of working in parallel, researchers in speech recognition and nlpwere encouraged to construct integrated speech understanding systems,for which the chosen task was to answer spoken queries to databases (e.g.,of air travel information). second, information extraction was made amajor task of interest. finally, the performance of nlp and speech understanding systems was to be systematically evaluated.it was thus necessary to reject the thenprevailing assumption that thenlp system needed to understand only syntactically and semantically wellformed utterances or that the entire content of an utterance or text neededto be understood. spoken language systems had to deal with the inevitablerecognition errors of even the best speech recognition systems as well asqueries such as òboston san francisco after 8 a.m.ó and òiõd like to go toboston, ah, to atlanta, tomorrow.ó systems were designed that toleratednot understanding some parts of the utterance, combining partial analysesof other parts, and explicitly correcting certain forms of disfluencies. evenwith such difficult input, it now became possible to actually improve theaccuracy of even the best speech recognition programs by applying syntactic and semantic constraints, at least in limited domains.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies87systematic evaluation of nlp systems is not possible without thecollection of large corpora of linguistic data, both raw and annotated,such as with correct transcriptions and correct answers to spoken queries.14 although the rulebased paradigm that has dominated computational linguistics so far has produced only a few largescale systems thathave been reused over several different projects (e.g., the core language engine at sri), it has been difficult to share large grammars, lexicons, and semantic rules across sites, making it difficult to build on previous results.the domain specificity of rulebased nlp systems suggests that itwould be attractive to be able to automatically train an nlp system, as isdone with the hidden markov models used in speech recognition. significant effort is being devoted to this direction. the results are promisingbut still not comparable to what is routinely achievable with rulebasedsystems. some of the problems are the amount of training data required,the difficulty of obtaining such data in a wide range of domains, and thecost of annotating the input data with the correct taskspecific semanticrepresentation. the annotation problem is exacerbated by the fact that itis much more difficult to get human annotators to agree on correct semantic annotations than on transcriptions of spoken utterances.many researchers believe that for some time yet the most effectivestrategy for the development of nlp systems in new domains will behybrid systems, based on a core of handcoded rules but tuned to a domain by automatic training methods. domainspecific corpora can beused, for example, to assign probabilities to the rules, providing a mechanism by which probabilities can be assigned to rulebased interpretations.this approach, used by most of the currently bestperforming systems,can be seen as a way of adapting a set of general rules to a particulardomain. farther down the road are ways of circumventing the data andannotation requirements of fully automatic training methods by dynamically adapting to one domain a system developed in another.nlp systems vary widely, from those that perform full and deepunderstanding of an utterance in narrowly construed domains to thosethat perform partial and shallow understanding of very wide domains.query systems tend to be at the full and deep understanding end, andinformation extraction systems at the partial and shallow end.several systems have been implemented to answer queries in thedarpasponsored airline travel information service task (darpa,1995b), where the user asks information about flights and schedules usingspeech. the utterance error rate, measured as the percentage of queriesfor which the system gives the wrong answer, is currently about 6 percentfor spoken input and 4 percent for the corresponding text input.the standards for evaluation of information extraction systems aremore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.88more than screen deepset by the darpasponsored message understanding conferences(mucs). for the ònamed entityó application, where the system must findall named organizations, locations, persons, dates, times, monetaryamounts, and percentages, the error rates are below 5 percent. for theòscenario templateó application, where the system extracts complex relationships in welldefined domains (such as joint ventures) in an opensource (such as the wall street journal), the error rate for finding the correct elements of the templates is about 45 percent.in the area of machine translation, the most significant advances continue to occur in europe. recent work in the united states using textswritten with an eye toward translation also show promise (carbonell,1992). several speechtospeech translation systems in limited domains,combining speech understanding, machine translation, and speech generation, have been demonstrated.still in their infancy are systems with which a human can conduct acoherent dialogue in service of a complex and extended task. early examples include the trains system (in use at the university of rochester), which allows a human to control a system that plans the transport ofmaterials, and the commandtalk system, which provides a spoken interface to a large military simulator. the approach of sadek and coworkers,at france telecom (bretier and sadek, 1996; bretier et al., 1995), offerscompelling evidence that spoken language systems can have sophisticated models of dialogue and can benefit from them. future systems willneed to allow for a variety of speech acts (e.g., requests, assertions, questions, rejections) and contain dialogue models that enable the establishment of correlations between occurrence of phrases used to refer to thesame entities and events in the discourse. coreference resolution hasbeen the subject of much research, and systems using it are being evaluated in the muc benchmarks. also, there is compelling evidence thatspoken language systems can have sophisticated models of dialogue andcan benefit from them.gesture recognitiongesture input can come in many forms from a variety of devices (e.g.,mouse, pen, data glove). its role is to convey information (e.g., identify,make reference to, explain, shift focus) in a manner similar to the othermore studied forms of language. gesture replaces the click of the mouseñthe mouseõs only wordñwith a wide range of commands. it eliminatesthe myriad objects on the screen intended to let the user communicate hisor her desires. rather than having to find the word, duplicate, and clickon it, the user can make simpler movements involving only the hand. forexample, at the workshop, bruce tognazziniõs òstarfireó video showed amore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies89user separating her fingers to indicate a desire to duplicate an objectñleave it here and move it. gesture can relieve problems of repetitivestresss by varying the userõs movements, thereby lowering the repetitionof any particular action.rim” and schiaratura (1991) characterize several classes of gesture.symbolic gestures are conventional, contextindependent, and typicallyunambiguous expressions (e.g., òokó or peace sign). in contrast, deicticgestures are pointers to entities, analogous to natural language deixis(e.g., òthis not tható). iconic gestures are used to display objects, spatialrelations, and actions (e.g., illustrating the orientation of two cars at anaccident). finally, pantomimic gestures display an invisible object or tool(e.g., making a fist and moving to indicate a hammer). gestural languages exist as well. these include sign languages and signing systemsfor use in environments where alternative communication is difficult.early experience with glove interfaces indicates that some users havedifficulty remembering the gesture equivalents to commands (herndonet al., 1994).gesture recognition plays a role in immersive environments such asthe virtual reality or simulation environments. it also should find widespread application in helping to give directions to computers or computerized agents. pointing and gesturing with the hand or with other objectsare natural communication behaviors and will likely form an importantcomponent in a natural intuitive interface. in addition, for individualswho are deaf and who communicate primarily through gestural languages(such as american sign language), machine recognition of american signlanguage gestures is the equivalent of speech recognition for those of uswho can speak.machine vision and passive inputmachine vision is likely to play a number of roles in future interfacesystems. primary roles are likely to be:¥data input (including text, graphics, movement)¥context recognition (as discussed above)¥gesture recognition (particularly in graphic and virtual realityenvironments)¥artificial sight for people with visual impairmentsexperience with text and image recognition provides a number of insights relevant to future interface development, especially in the contextof aiding individuals with physical disabilities. in particular, systemsthat are difficult to use by blind people would pose the same problems tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.90more than screen deeppeople who can see but who are trying to access information aurallybecause their vision is otherwise occupied. similar problems may arise aswell for intelligent agents.text recognitiontoday, there are powerful tools for turning images of text into electronic text (such as ascii). optical character recognition (ocr) is quitegood and is improving daily. driven by a desire to turn warehouses ofprinted documents into electronic searchable form, companies have beenand are making steady advances. some ocr programs will convert programs into electronic text that is compatible with particular word processing packages, preserving the text layout, emphasis, font, and so on. theproblem with ocr is that it is not 100 percent accurate. when it makes amistake, however, it is not usually a character anymore (since word lookup is used to improve accuracy). as a result, when an error is made, it isoften a legal (but wrong) word. thus, it is often impossible to look at adocument and figure out exactly what it did sayñsome sentences maynot be accurate (or even make sense). one company gets around this bypasting a picture of any words the system is not sure about into the textwhere the unknown word would go. this works well for sighted persons, allows human editors to easily fix the mistakes, and preserves theimage for later processing by a more powerful image recognizer. it doesnot help blind users much except that they are not misled by a wrongword and can ask a sighted person for help if they cannot figure something out. (most helpful would be to have an ocr system include itsguess as to the letters of a word in question as hidden text, which a personwho is blind could call up to assist in guessing the word.) highly stylizedor embellished characters or words are not recognizable. text that iswrapped around, tied in knots, or arranged on the page or laid out in anunusual way may be difficult to interpret even if available in electronictext. this is a separate problem from image recognition, though.image recognitiondespite great strides by the military, weather, intelligence, and othercommunities, image interpretation remains quite specialized and focusedon looking for particular features. the ability to identify and describearbitrary images is still beyond us. however, advances in artificial intelligence, neural networks, and image processing in combination with largedata banks of image information may make it possible in the future toprovide verbal interpretation or description for many types of information. a major impetus comes from the desire to make image informationmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies91searchable by computers. the combination of a tactile representationwith feature or texture information presented aurally may provide thebest early access to graphic information by users who are blind or cannotuse their sight.some images, such as pie charts and line graphs, can be recognizedeasily and turned into raw data or a text description. standard softwarehas been available for some time that will take a scanned image of a chartand provide a spreadsheet of the data represented in the chart. otherimages, such as electronic schematic diagrams, could be recognized butare difficult to describe. a house plan illustrates the kind of diagram thatmay be describable in general terms and would benefit from combining averbal description with a tactile representation for those who cannot seeto deal with this type of information.visual displaysvisual display progress begins with the screen design (graphics, layouts, icons, metaphors, widget sets, animation, color, fisheye views, overviews, zooming) and other aspects of how information is visualized. thehuman eye can see far more than current computer displays can show.the bandwidth of our visual channel is many orders of magnitude greaterthan other senses: ~1 gigabit/second. it has a dynamic range of 1013 to 1(10 trillion to 1). no humanmade sensor or graphics display has thisdynamic range. the eye/brain can detect very small displacements atvery low rates of motion and sees change up to a rate of about 50 times asecond. the eye has a very focused view that is optimized for perceivingmovement. humans cannot see clearly outside an ~5degree cone offoveal vision and cannot see behind them.stateoftheart visualization systems (as of 1996) can create images ofapproximately 4,000 polygons complexity at 50 hz per eye. moderngraphics engines also filter the image to remove sampling artifacts onpolygon edges and, more importantly, textures. partial transparency isalso possible, which allows fog and atmospheric contrast attenuation in anaturallooking way. occlusion (called òhidden surface removaló ingraphics) is provided, as is perspective transformation of vertices. smoothshading in hardware is also common now.thus, the images look rather good in real time, although the scenecomplexity is limited to several thousand polygons and the resolution to1,280 1,024. typical computeraided design constructions or animatedgraphics for television commercials involve scenes with millions of polygons; these are not rendered in real time. magazine illustrations arerendered at resolutions in excess of 4,000 3,000. thus, the imagery usedin realtime systems is portrayed at rather less than optimal resolution,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.92more than screen deepoften much less actually than the effective visual acuity required to drivea car. in addition, there are better ways of rendering scenes, as when thephysics of light is more accurately simulated, but these techniques are notcurrently achievable in real time. a sixorderofmagnitude increase incomputer speed and graphics generation would be easy to absorb; ateraflop personal computer would be rather desirable, therefore, but isprobably 10 years off.visual input/output hardwarethe computer industry provides a range of display devices, from smallembedded liquidcrystal displays (lcds) in personal digital assistants(pdas) and navigational devices to large cathoderay tubes (crts) andprojectors. clearly, desirable goals are lower cost, power consumption,latency, weight, and both much larger and much smaller screens. currentcommercial crts achieve up to 2,048 2,048 pixels at great cost. projectorscan do ~1,900 1,200 displays. it is possible to tesselate projectors at will toachieve arbitrarily higher resolution (woodward, 1993) and/or brightness(e.g., video walls shown at trade shows and conventions). screens with>5,000pixel resolution are desirable. durability could be improved, especially for portable units.15 some increase in the capability of television setsto handle computer output, which may be furthered by recent industrybased standards negotiations for advanced television (sometimes referredto as highdefinition television), is expected to help lower costs.16 how,when, and where to trade off the generality of personal computers againstother qualities that may inhere in more specialized or cheaper devices is anissue for which there may be no one answer.hollywood and science fiction have described most of the conceivable, highly futuristic display devicesñdirect retinal projection, directcerebral input, holodecks, and so on. less futuristic displays still have along way to go to enable naturalappearing virtual reality (vr). liquidcrystal displays do not have the resolution and low weight needed foracceptable headmounted displays to be built; users of currently availableheadmounted displays are effectively legally blind given the lack of acuity offered. projected vr displays are usable, although they are large andare not portable.the acceptance of vr is also hindered by the extreme cost of the highend graphics engines required to render realistic scenes in real time, theenormous computing power needed to simulate meaningful situations,and the nonlinearity and/or short range of tracking devices. given thatthe powerful graphics hardware in the $200 nintendo 64 game is justincremental steps from supporting the stereo graphics needed for vr, it isclear that the barriers are now in building consumerlevel tracking gearmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies93and some kind of rugged stereo glasses, at least in the home game context.once these barriers are overcome, vr will be open for wider application.highresolution visual input devices are becoming available to nonprofessionals, allowing them to produce their own visual content. digitalsnapshot cameras and scanners, for example, have become available athighend consumer levels. these devices, while costly, are reasonable inquality and are a great aid to people creating visual materials for the nii.17compositing and nonlinear editing software assist greatly as well. similarly, twodimensional illustration and threedimensional animation software make extraordinary graphics achievable by the motivated and talented citizen. the cost of such software will continue to come down as themarket widens, and the availability of more memory, processing, graphicspower, and disk space will make results more achievable and usable.as a future goal that defines a conceptual outer limit for input andoutput, one might choose the holodeck from the movie star trek, a devicethat apparently stores and replays the molecular reconstruction information from the transporter that beams people up and down. in the physicsof star trek, physicist lawrence krauss (1995, pp. 7677) works out theinformation needed to store the molecular dynamics of a single humanbody: 1031 bytes, some 1016 times the storage needed for all the books everwritten. krauss points out the other difficulties in transporter/holodeckreconstruction as well.auditory displaysthe ear collects sound waves and encodes the spatial characteristicsof the sound source into temporal and spectral attributes. intensity difference and temporal/phase difference in sound reaching the two ears provide mechanisms for horizontal (left to right) sound localization. the eargets information from the whole space via movement in time.hearing individual components of sound requires frequency identification. the ear acts such as a series of narrowly tuned filters. sound cuescan be used to catch attention with localization, indicate near or far positions with reverberation, indicate collisions and other events, and evenportray abstract events such as change over time. lowfrequency soundcan vibrate the userõs body to somewhat simulate physical displacement.speakers and headphones as output devices for synthesized soundmatch the ears well, unlike the case with visual displays. however, understanding which sounds to create as part of the humancomputer interface is much less well understood than for the visual case.about 50 million instructions per second are required for each synthesized sound source. computing reverberation off six surfaces for foursound sources might easily require a billioninstructionpersecond commore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.94more than screen deepputer, one that is within todayõs range but is rarely dedicated to audiosynthesis in practice. audio sampling and playback are far simpler andare most often used for primitive cues such as beacons and alarms.thus, the barriers to good matching to human hearing have to do withcomputing the right sound and getting it to each ear in a properly weightedway. although in many ways producing sound by computer is simplerthan displaying imagery, many orders of magnitude more research anddevelopment have been devoted to graphics than sound synthesis.haptic and tactile displays18human touch is achieved by the parallel operation of many sensorsystems in the body (kandel and schwartz, 1981). the hand alone has 19bones, 19 joints, and 20 muscles with 22 degrees of freedom and manyclasses of receptors and nerve endings in the joints, skin, tendons, andmuscles. the hand can squeeze, stroke, grasp, and press; it can also feeltexture, shape, softness, and temperature.the fingerpad has hairless ridged skin enclosing soft tissues made offat in a semiliquid state. fingers can glide over a surface without losingcontact or grab an object to manipulate it. computed output and input ofhuman touch (called òhapticsó) is currently very primitive compared tographics and sound. haptic tasks are of two types: exploration andmanipulation. exploration involves the extraction of object propertiessuch as shape and surface texture, mass, and solidity. manipulation concerns modification of the environment, from watch repair to using a sledgehammer.kinesthetic information (e.g., limb posture, finger position), conveyedby receptors in the tendons, and muscles and neural signals from motorcommands communicate a sense of position. joint rotations of a fractionof a degree can be perceived. other nerve endings signal skin temperature, mechanical and thermal pain, chemical pain, and itch.responses range from fast spinal reflex to slow deliberate consciousaction. experiments on lifting objects show that slipping is counteractedin 70 milliseconds. humans can perceive a 2micrometerhigh single doton a glass plate, a 6micrometerhigh grating, using different types ofreceptors (kalawsky, 1993). tactile and kinesthetic perception extendsinto the kilohertz range (shimoga, 1993). tactile interfaces aim to reproduce sensations arising from contact with textures and edges but do notsupport the ability to modify the underlying model.haptic interfaces are highperformance mechanical devices that support bidirectional input and output of displacement and forces. theymeasure positions, contact forces, and time derivatives and output newforces and positions (burdea, 1996). output to the skin can be point,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies95multipoint, patterned, and timevarying. consider david warner, whomakes his rounds in a òcyberwearó buzz suit that captures informationfrom his patientsõ monitors, communicating it with bar charts tingling hisarms, pulse rates sent down to his fingertips, and test results whispered inhis ears, yet allowing him to maintain critical eye contact with his patients(http://www.pulsar.org).there are many parallels and differences between haptics and visual(computer graphics) interfaces. the history of computing technologyover the past 30 to 40 years is dominated by the exponential growth incomputing power enabled by semiconductor technology. most of thisnew computing power has supported enriched highbandwidth user interfaces. haptics is a sensory/motor interaction modality that is just nowbeing exploited in the quest for seamless interaction with computers.haptics can be qualitatively different from graphics and audio input/output because it is bidirectional. the computer model both deliversinformation to the human and is modified by the human during the haptic interaction. another way to look at this difference is to note that,unlike graphics or audio output, physical energy flows in both directionsbetween the user and the computer through a haptic display device.in 1996 three distinct market segments emerged for haptic technology: lowend (2 degrees of freedom (dof), entertainment); midrange (3dof, visualization and training); and highend (6 dof, advanced computeraided engineering). the lesson of video games has been to optimize for realtime feedback and feel. the joysticks or other interfaces forvideo games are very carefully handled so that they feel continuous. theobviously cheap joystick on the nintendo 64 game is very smooth, suchthat a 2 year old has no problem with it. such smoothness is necessary tobe a good extension of a personõs hand motion, since halting responsechanges the dynamics, causing one to overcompensate, slow down, etc.a video game joystick with haptic feedback, the òforce fx,ó is nowon the market from ch products (vista, calif.) using technology licensedfrom immersion corp. it is currently supported by about 10 video gamesoftware vendors. other joystick vendors are readying haptic feedbackjoysticks for this lowpriced, highvolume market. in april 1996,microsoft bought exos, inc. (cambridge, mass.) to acquire its haptic interaction software interface.haptic interaction will play a major role in all simulationbased training involving manual skill (buttolo et al., 1995). for example, force feedback devices for surgical training are already in the initial stages ofcommercialization by such companies as boston dynamics (cambridge,mass.), immersion corp. (palo alto, calif.), sensable devices (cambridge,mass.), and ht medical (rockville, md.).advanced cad users at major industrial corporations such as boeingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.96more than screen deep(mcneely, 1993) and ford (buttolo et al., 1995) are actively funding internal and external research and development in haptic technologies to solvecritical bottlenecks they have identified in their computeraided productdevelopment processes.these are the first signs of a new and broadbased hightechnologyindustry with great potential for u.s. leadership. research (as discussedbelow) is necessary to foster and accelerate the development of these andother emerging areas into fullfledged industries.a number of science and technology issues arise in the haptics andtactile display arena. haptics is attracting the attention of a growingnumber of researchers because of the many fascinating problems thatmust be solved to realize the vision of a rich set of hapticenabled applications. because haptic interaction intimately involves highperformancecomputing, advanced mechanical engineering, and human psychophysics and biomechanics, there are pressing needs for interdisciplinary collaborations as well as basic disciplinary advances. these key areas include the following:¥better understanding of the biomechanics of human interaction withhaptic displays. for example, stability of the haptic interaction goes beyond the traditional control analysis to include simulated geometry andnonlinear timevarying properties of human biomechanics.¥faster algorithms for rendering geometric models into haptic input/output maps. although many ideas can be adapted from computer graphics,haptic devices require at least 1,000hz update rates and a latency of nomore than 1 millisecond for stability and performance. thus, the bar israised for the definition of òrealtimeó performance for algorithms suchas collision detection, shading, and dynamic multibody simulation.¥advanced design of mechanisms for haptic interactions. real hapticinteraction uses all of the degrees of freedom of the human hand and arm(as many as 29; see above). the most advanced haptic devices have 6 or 7degrees of freedom for the whole arm/hand. to provide highqualityhaptic interaction over many degrees of freedom will continuously createmany research challenges in mechanism design, actuator design, and control over many years to come.some of the applications of haptics that are practical today may seemarcane and specialized. this was also true for the first applications ofcomputer graphics in the 1960s. emerging applications today are theones with the most urgent need for haptic interaction. below are someexamples of what may become possible:¥1999: a medical student is practicing the administration of spinalepidural anesthesia for the first time. she must insert the needle by feelmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies97(without visual guidance) through the skin, fat, muscle, and spinal dura,and inject the anesthetic without visual guidance. like all physicianstrained before this year, her instructor learned the procedure on actualhuman patients. now, she is using a haptic display device hidden insidea plastic model of the human back. the device simulates the distinct feelof each of these tissues as well as the hard bones that she must avoid withthe needle. after a few sessions with the simulator and a quantitativeevaluation of her physical proficiency, she graduates to her first real patient with confidence and skill.¥2000: an automotive design engineer wants to verify that an oilfilter that he knows will require routine maintenance can be removedfrom a crowded engine compartment without disassembly of the radiator, transmission, and so forth. he brings the complete engine compartment model up on the graphics screen and clicks the oil filter to link it tothe sixaxis haptic display device on his desk next to the workstation.holding the haptic device, he removes the oil filter, feeling collisions withnearby engine objects. he finds that the filter cannot be removed becausecoolant hoses block the way. the engine compartment is thus redesignedearly in the design process, saving hundreds of thousands of dollars.the first of these examples is technically possible today; the second is not.there are critical computational and mechatronic challenges that will becrucial to successful implementation of evermore realistic haptic interfaces.because haptics is such a basic human interaction mode for so manyactivities, there is little doubt that, as the technology matures, new andunforeseen applications and a substantial new industry will develop togive people the ability to physically interact with computational models.once user interfaces are as responsive as musical instruments, for example,virtuosity is more achievable. as in music, there will always be a phaseappropriate to contemplation (such as composing/programming) and aphase for playing/exploring. the consumer will do more of the latter, ofcourse. better feedback continuously delivered appears to take less prediction. being able to predict is what expertise is mostly about in a technical/scientific world, and we want systems to be usable by nonexperts, hencethe need for realtime interactions with as much multisensory realism as ishelpful in each circumstance. research is necessary now to provide theintellectual capital upon that such an industry can be based.tactile displays for low or novision environments or userstactile displays can help add realism to multisensory virtual realityenvironments. for people who are blind, however, tactile displays aremore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.98more than screen deepmuch more important for the provision of information that would beprovided visually to those who can see. for people who are deaf andblind and who cannot use auditory displays or synthetic speech, it is theprincipal display form.vibration has been used for adding realism to movies and virtualreality environments and also as a signaling technique for people withhearing impairments. it can be used for alarm clocks or doorbells, but islimited in the information it can present even when different frequenciesare used for different signals. vibration can also be used effectively incombination with other tactile displays to provide supplemental information. for example, vibratory information can be used in combination withbraille to indicate text that is highlighted, italicized, or underlined, or toindicate text that is a hyperlink on a hypertext page.vibrotactile displays provide a higherbandwidth channel. with avibrotactile display, small pins are vibrated up and down to stimulatetactile sensors. the most widespread use of this technique is the optacon(optical to tactile converter), which has 144 pins (6 24) in its array(100 pins on the optacon ii). the tactile array is usually used in conjunction with a small handheld camera but can also be connected directly to acomputer to provide a tactile image around a mouse or other pointingdevice on the screen.electrocutaneous displays have also been explored as a way to createsolidstate tactile arrays. arrays have been constructed for use on theabdomen, back, forearm, and, most recently, the fingertip. resolution forthese displays is much lower than for vibrotactile displays.raisedline drawings have long been òking of the hilló for displayingof tactile information. the principal problem has been an inexpensiveand fast way to generate them òon the fly.ó wax jet printers showed thegreatest potential (especially for high resolution), but none are currentlyavailable. for lower resolution, there is a paper onto which one canphotocopy and then process with heat, to cause it to swell wherever thereare black lines (although at a much lower resolution). printers that createembossed braille pages can also be programmed to create tactile imagesthat consist of raised dots. the resolution of these is lower still (the besthaving a resolution of about 12 dots per inch), but the raiseddot form ofthe graphics actually has some advantages for tactile perception.braille is a system for representing alphanumeric characters tactiley.the system consists of six dots in a two wide by three high pattern. to dothe full ascii character set, an eightpin braille (two by four) was developed. braille is most commonly thought of as being printed or embossed,where paper is punched upward to form braille cells or characters asraised dots on the page.19 there are also dynamic braille displays, wherecells having (typically) 8 pins that can be raised or lowered independentlymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies99are arranged in lines of 12 to 20 or more cells on small portable devicesand 20 to 40 cells on desktop displays. a few 80cell displays have beendeveloped, but they are quite expensive and large. by raising or loweringthe pins, a line of braille can be dynamically changed, rather like a singleline of text.virtual page displays.because of the difficulties creating fullpage tactile displays, a number of people have tried techniques to create a òvirtualó fullpage display. one example was the systems 3 prototype, wherean optacon tactile array was placed on a mouselike puck on a graphicstablet. as the person moved the puck around on the tablet, he or she felta vibrating image of the screen that corresponded to that location on thetablet. the same technique has been tried with a dynamic braille display.the resolution, of course, is much lower. in neither case did the tactilerecognition approach that of raised lines.fullpage displays.some attempts have been made to create fullpagebrailleresolution displays. the greatest difficulty has been in trying tocreate something with that many moving parts that is still reliable andinexpensive. more recently, some interesting strategies using ferroelectric liquids and other materials have been tried. in each case the objectivewas to create a system that involves the minimum number of movingparts and yet provides a very highresolution tactile display.ideal displays.a dream of the blindness community has been the development of a large plate of hard material that would provide a highresolution solidstate tactile display. it would be addressable like a liquidcrystaldisplay, with instant response, very high resolution, and variable height. itwould be low cost, lightweight, and rugged. finally, it would be best if itcould easily track the position of fingers on the display, so that the tactiledisplay could be easily coupled with voice and other audio to allow parallelpresentation of tactile and auditory information for the area of the displaycurrently being touched.an even better solution, both for blind people and for virtual realityapplications, would be a glove that somehow provided both full tactilesensation over the palm and fingertips and force feedback. elements ofthis have been demonstrated, but nothing approaching full tactile sensation or any freefield force feedback.integrating input/output technologiesfilling out the range of technologies for people to communicate withsystemsñfilling in the research and development gaps in the precedingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.100more than screen deepsectionñis only part of the input/output requirement for ecis. integration of these technologies into systems that use multiple communicationsmodalities simultaneouslyñmultimodal systemsñcan improve peopleõsperformance. (these ideas are discussed in more detail in chapter 6.)integration can also ensure that at least one mechanism is available forevery person and situation, independent of temporary and/or permanentconstraints on their physical and cognitive abilities. virtual reality involves the integration of multiple input and output technologies into animmersive experience that, ideally, will permit people to interact withsystems as naturally as they do with realworld places and objects.multimodal interfacespeople effortlessly integrate information gathered across modalitiesduring conversational interactions. facial cues and gestures are combined with speech and situational cues, such as objects and events in theenvironment, to communicate meaning. almost 100 years of research inexperimental psychology attests to our remarkable abilities to bring allknowledge to bear during human communication.the ability to integrate information across modalities is essential foraccurate and robust comprehension of language by machines and to enable machines to communicate effectively with people. in noisy environments, when speech is difficult to understand, facial cues provide bothredundant and complementary information that dramatically improvesrecognition performance over either modality alone. to improve recognition in noisy environments, researchers must discover effective procedures to recognize and combine speech and facial cues. similarly, textualinformation may be transmitted more effectively under some conditionsby turning the text into naturalsounding speech, produced by an animated òtalking headó with appropriate facial movements. while a greatdeal of excellent research is being undertaken in the laboratory, researchin this area has not yet reached the stage where commercial applicationshave appeared, and fundamental problems remain to be solved. in particular, basic research is needed into the science of understanding howhumans use multiple modalities.abilityindependent interfacesstandard massmarket products are still largely designed with singleinterfaces (e.g., they are designed to work with a keyboard (only) or theyare designed to work with a touchscreen (only)). there are systems designed to work with keyboard or mouse, and some crossmodality effortsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies101have been made (e.g., systems that support both keyboard and speechinput). usually, though, these multiple input systems are accomplishedby having a second input technique simulate input on the firstñfor example, having the speech interface create simulated keystrokes or mouseclicks rather than having the systems designed from the beginning toaccommodate alternate interface modalities. this approach is usually theresult of companies that decide to add voice or pen support (or otherinput technique support) to their applications after it has been architected.this generates both compatibility problems and very complicated userconfiguration and programming problems.a similar problem exists with media, materials, databases, or educational programs designed to be used in a visualonly presentation format.companies (and users) run into problems when the materials need to bepresented aurally. for example, systems designed for visual viewingoften need to be reengineered if the data are going to be presented over aphonebased information system.the area where the greatest crossmodality interface research has beencarried out has been the disability access area. strategies for creating audiovisual materials that also include timesynchronized text (e.g., captions) aswell as audio descriptions of the visual information have been developed.interestingly, although closed captioning was added to television sets forpeople who are deaf, it is used much more in noisy bars, by people learningto read a new language, by children, and by people who have muted theirtelevision sets. the captions are also useful for institutions wishing toindex or search audiovisual files, and they allow òagentó software to comprehend and work with the audio materials.in the area of public information systems, such as public kiosks, interfaces are now being developed that are flexible enough to accommodateindividuals with an extremely wide range of type, degree, and combinationof disabilities. these systems are set up so that the standard touchscreeninterface supports variations that allow individuals with different disabilities to use them. extremely wide variation in human sensory motor abilities can be accommodated without changing the user interface for peoplewithout disabilities.for example, by providing a òtouch and hearó feature, a kiosk can bemade usable by individuals who cannot read or by those who have lowvision. holding down a switch would cause the touchscreen to becomeinactive (e.g., touching buttons on the screen would cause no action).however, any buttons or text that were touched would be read aloud tothe user. releasing the switch would reactivate the screen. a òtouch andconfirmó mode would allow individuals with moderate to severe physical disabilities to use the kiosk by having it accept only input that ismore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.102more than screen deepfollowed by a confirmation. an option that provides a listing of the items(e.g., text and buttons) down the left edge of the screen can be combinedwith the talking òtouch and confirmó mode to allow individuals who arecompletely blind to easily and accurately use a kiosk. the use of captionsfor audiovisual materials on kiosks can allow individuals who have hearing impairments to access a kiosk (as well as anyone else trying to use akiosk in a noisy mall). finally, by sending the information on the popuplist out through the computerõs infrared data association (irda) port, itis possible for individuals who are completely paralyzed or deaf andblind to access and use a kiosk via their personal assistive technologies.all of these features can be added to a standard multimedia touchscreen kiosk without adding any hardware beyond a single switch andwithout altering the interface experienced by individuals who do nothave disabilities. by adding interface enhancements such as these, it ispossible to create a single public kiosk that looks and operates like anytraditional touchscreen kiosk but is also accessible and usable by individuals who cannot read, who have low vision, who are blind, who arehearing impaired, who are deaf, who have physical disabilities, who areparalyzed, or who are deaf and blind. kiosks with flexible userconfigurable interfaces have been distributed in minnesota (including themall of america), washington state, and other states.these and similar techniques have been implemented in other environments as well. since the 1980s, apple computer has had options builtinto its human interface to make it more useful to people with functionallimitations (look in any macintosh control panel for easyaccess). ibmhas them built into its hardware and software (accessdos and os/2), andunix has both options in its human interface and modifications in itsunderlying structure to support connection to specialized interfaces. windows 95 has over a dozen adjustments and variations built into its humaninterface to allow it to be used by individuals with a very wide range ofdisabilities or environmental limitations, including those with difficultyhearing, seeing, physically operating a keyboard, and operating a mousefrom the keyboard.as we move into more immersive environments and environmentsthat are utilizing a greater percentage of an individualõs different sensoryand motor systems simultaneously (e.g., vr, multimedia), identifying anddeveloping crossmodal interface techniques will become increasingly challenging. in the techniques developed to date, however, building interfacesthat allow for crossmodality interaction have generally made for morerobust and flexible interfaces and systems that can better adapt to newinterface technologies as they emerge (e.g., allowing wimp (windows,icons, menus, pointers) systems to accommodate a verbal interface).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies103virtual reality and artificial immersive environmentsthe past 10 years has brought nearly a complete changeover fromcommand line to wimp interfaces as the dominant everycitizenõs connection to computation. this happened because hardware (memory, display chips) became cheap enough to be engineered into every product. italso happened because the first step to the office of the future requiredreplacing the typewriter with the laser printer, an event neatly handledwith the òdesktop metaphoró and word processing/spreadsheet software.however, the nii implies a complex of technologies relevant to far morethan office work, which is a practical reason not to expect it to be accessedby every citizen with mice and windows interfaces alone (van dam,1997).20 another transition is now at hand, one that potentially liberatesthe interface from the desktop, one that presents information more likeobjects in a shopping mall than printing on a pile of paper. the virtualshopping mall (or museum) is the next likely application metaphor; theparking lots will be unneeded, of course, as will attention to the laws ofphysics when inappropriate, but as in threedimensional user interfacesgenerally, the metaphor can help in teaching users how to operate in asynthetic environment. such a metaphor helps also to avoid the constraints that may derive from metaphors linked to one class of activity(e.g., desks and whitecollar work) at a time when researchers shouldthink about the needs and challenges posed by all kinds of people.at siggraph 96, the major conference for computer graphics andinteractive techniques, fullquality, realtime, interactive, threedimensional, textured flight simulation was presented as the next desirable feature in every product. this visual capability, usually augmented withsound and multidimensional interactive controls, presents information aslandscapes and friendly/hostile objects with which the user interacts athigh speed. visual representations of users, known as avatars, are onetrend that has been recognized in the popular press. typing is not usuallyrequired or desirable. the world portrayed is spatially three dimensionaland it continues way beyond the boundaries of the display device. in thiscontext, input and output devices with more than 2 degrees of freedomare being developed to support true direct manipulation of objects, asopposed to the indirect control provided by two and threedimensionalwidgets, and user interfaces appear to require support for many degreesof freedom,21 higherbandwidth input and output, realtime response,continuous response and feedback, probabalistic input, and multiple simultaneous input and output streams from multiple users (herndon etal., 1994). note that virtual reality also expands on the challenges posedby speech synthesis to include synthesis of arbitrary sounds, a problemmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.104more than screen deepthat is hampered by the lack of available sound samples analogous to thevoice samples used in voice synthesis.economic factors will pace the broader accessibility of technologiesthat are currently priced out of the reach of every citizen, such as highend virtual reality. virtual reality technology, deriving from 30 years ofgovernment and industry funding, will see its cost plummet as development is amortized over millions of chip sets, allowing it to come into themainstream. initially, the software for these new chips will be crafted andoptimized by legions of video game programmers driven by teenagemassmarket consumption of the best play and graphics attainable.coupled with the development of relatively cheap wideangle immersivedisplays and hundredfold increases in computing power, personal accessto data will come through navigation of complex artificial spaces. however, providing the everycitizen interface to this shared information infrastructure will need some help on the design front.ten to 20year challenges for virtual reality systemsvery little cognitive neuroscience and perceptual physiology is understood, much less applied, by human interface developers. the decade ofthe brain is well into its second half now; a flood of information will beavailable to alert practitioners in the computing community that will be ofgreat use in designing the everycitizen interface. teams of sensory psychologists, industrial designers, electrical engineers, computer scientists,and marketing experts need to explore, together, the needs of governance,commerce, education, and entertainment. the neuroplasticity of childrenõscognitive development when they are computationally immersed early inlife is barely acknowledged, much less understood.1.a prioritized list of challenges includes the following:a.enumerate and prioritize human capabilities to modulateenergy.this requires a comprehensive compilation of publishedbioengineering and medical research on human performance measurement techniques, filtering for the instrumentation modalitiesthat the human subjects can use to willfully generate continuous orbinary output. modalities should be ranked according to quality/repeatability of output, comfort, intrusiveness, cost, durability,portability, and power consumption. note that much is knownabout human input capacity, by contrast.b.develop navigational techniques, etc.this is akin to understanding the functional transitions in moving around in the wimpdesktop metaphor and is critical to nontrivial exploitation of theshopping mall metaphor of vr. note that directional surroundmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies105sound audio and tactile feedback rich enough to assist a visionimpaired person in navigating a mall would also likely help a fullysighted person. schematic means need to be developed to displaythe shopping mall metaphor on conventional desktop computers,small video projectors, and embedded displays.c.develop several universal methods for input/output deviceconnectivity.currently, the personal computer clone is the universal input/output adapter because of its open architecture and theavailability of cheap mailorder input/output devices, but manypersonal computers, each doing one filtering task, trying to communicate with one another on serial lines, are not directly adaptable tothe eci set of needs. both software and hardware need to be provided in a form that allows òplug and play.ó custom chip sets willdrive the cost down to consumer level; adapting video game input/output devices where possible will help in achieving similar priceperformance improvements as computing itself.d.store and retrieve visualization/vr sessions.despite the easilyavailable technology in chip form, it is still clumsy if not impossible for an ordinary user to make and edit a video recording todocument a computer session, unless it is a video game! imaginetext editing if you could only cut and paste but never store theresults. one would like to play back and edit visualization/vrsessions in ways akin to the revision mode in word processors. akey technological development here is extension of the videoserverconcept to visualization/vr capture and playback.e.connect to remote computations and data sources.this is inevitable and will be driven by every sector of computing and webusage.f.understand the computer as an instrument.this is inevitableand will be marketdriven as customers become more exposed togood interfaces. note that the competition between web browsercompanies is not about megahertz and memory size!g.create audio output matched to the dynamic range of humanhearing.digital sound synthesis is in its infancy. given the speedof currently available highend microprocessors, this is almost entirely a software tools problem from the engineering side and atraining problem from the creative side. (note that flawless voicerecognition is left out here!)2.controversial: because they seem to be developing for a postliteratesociety whose members will no longer (!) be able to type and readfrom screens :a.eliminate typing as a required input technique.many computermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.106more than screen deepapplications, of course, already do this (e.g., cad, video games,touchscreen map displays). related: provide for typing whennecessary in walkaround situations such as vr or warehouse dataentry. possible solutions are wearable chord keyboards, voice recognition, and gesture recognition. issues include whether trainingwill be essential, ranging from the effort needed to learn a videogame or new word processor to that required to play a musicalinstrument or to drive a bulldozer.b.reduce reliance on reading.road signs have been highly developed and standardized to reduce the reliance on reading fornavigation in the real world. the controversy here may stem fromthe copyright (if not patent) protection asserted by commercialdevelopers on each new wrinkle of look and feel on computerscreens. a fine role for government here is to encourage publicdomain development of the symbolism needed to navigate complex multidimensional spaces.3.barrierladen challenges:a.develop haptic devices.safe forcefeedback devices capable ofdelivering fine touch sensations under computer control are stilllargely a dream. keyboards and mice injure without the help offorce feedback; devices capable of providing substantial feedbackcould do real injury. some heavy earthmoving equipment designs are now òflybywireó; force feedback is being simulated togive the operator the feel once transmitted by mechanical linkage.the barriers are providing failsafe mechanisms, finding the applications warranting force feedback, and providing the software andhardware that are up to the task.b.provide enough antialiased image resolution to match human vision (minimally 5,000  5,000 pixels at 50 hz). crt technologyseems limited by market forces and development to 2,048 2,048this decade. lcd screen sizes and resolutions seem to be drivenby market needs for laptop computers. twentytwenty vision isroughly 5,000 pixels (at a 90 degree angle of view); less is needed atthe angle people normally view television or workstation screens,more for wideangle vr applications. a magazine advertisementis typically equivalent to 8,000 pixels across, on average, which iswhat a mature industry provides and is paid for, a suggestedbenchmark for the next decade or so. more resolution can be usedto facilitate simple panning (which is what a person does whenreading the wall street journal, for example) or zooming in (as aperson does when looking closely at a real item with a magnifyingglass), both of which can be digitally realized with processing andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies107memory without requiring more resolution from the display device. certain quality enhancements may be achieved with higherrefresh rates (e.g., 100 hz) including less strobing during panning or the capability of doing stereo visuals by sending two 50hz images, one for each eye. low latency, not currently a featureof lcd displays, is needed for 100 hz or greater devices.micromirror projectors show promise in this area.desirable, of course, would be wallsized screens with veryhigh resolution (>20,000 pixels) whose fidelity would be matchedto a personõs vision even when closely examined. multiple projectors tiled together may achieve such an effect (woodward,1993) where warranted; monitors and lcd screens do not lendthemselves to tiling because the borders around the individualdisplays do not allow seamless configurations. truly borderlessflat displays are clearly desirable as a way to build truly highresolution displays.c.providing enough computer for the eci.(this is probably theleast of the problems because the microprocessor industry, having nearly achieved the capability of 1990 vintage crays in singlechips, is now ganging them together by fours and eights intopackages.) gigaflop personal computers are close; teraflop desktop units are clearly on the horizon as massive parallelism becomes understood. taking advantage of all this power is thechallenge and will drive the cost down through mass productionas the interfaces make the power accessible and desirable. morefuturistic goals such as the petaflop computer and biologicalòcomputingó will likely happen in our lifetimes.d.providing adequate network bandwidth to the end user.someof the challenges in network infrastructure are discussed in thenext section (òthe communications infrastructureó). with respect to vr specifically, current data transfer rates between diskdrives and screens are not up to the task of playing back fullscreen movies uncompressed. the 1997 state of the art for national backbone and regional networking is 622 megabits per second. the goal of providing adequate bandwidth depends on thedefinition of òadequateó and how much computing is used tocompress and decompress information. fiber optics is capable oftremendous information transmission; it is the switches (whichare computers) that govern the speeds and capacity now. assuming that network bandwidth will be provided as demandincreases, it seems likely that within 10 years a significant fraction of the population will be able to afford truly extraordinarybandwidth (cstb, 1996).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.108more than screen deepthe communications infrastructurebecause ecis must work in a networked environment, interface design involves choices that depend on the performance of network accessand networkbased services and features. what ramifications does connection to networks have for ecis? this question is relevant because a userinterface for any networked application is much more than the immediateset of controls, transducers, and displays that face the user. it is the entireexperience that the user has, including the following:¥response timeñhow close to immediate response from an information site or setup of a communications connection;¥media quality (of audio, video, images, computergenerated environments), including delay for realtime communications and being able tosend as well as receive with acceptable quality;¥ability to control media quality and tradeoff between applicationsand against cost;¥òalways onóñthe availability of services and information, such asstock quotes on a personal computer screen saver, without òdialing upóeach time the user wants to look;¥transparent mobility (anytime, anywhere) of terminals, services,and applications over time;¥portable òplug and playó of devices such as cable television settopboxes and wireless devices;¥integrity and reliability of nomadic computing and communications despite temporary outages and changes in available access bandwidth;¥consistency of service interfaces in different locations (not restrictedto the united states); and¥the feeling the user has of navigating in a logically configured,consistent, extensible space of information objects and services.to understand how networking affects user interfaces, consider thetwo most common interface paradigms for networked applications: speech(telephony) and the òpoint and clickó web browser. these are so widelyaccepted and accessible to all kinds of people that they can already beregarded as òalmostó everycitizen user interfaces. research to extend thefunctionality and performance of these interfaces, without complicatingtheir most common applications, would further nii accessibility for ordinary people.speech, understood here to describe information exchange with otherpeople and machines more than an immediate interface with a device, is amore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies109natural and popular medium for most people. it is remarkably robustunder varying conditions, including a wide range of communicationsfacilities. the rise of internet telephony and other voice and videooriented internet services reinforces the impression that voice will always bea leading paradigm. voice also illustrates that the difference between acuriosity such as todayõs internet telephony and a widely used and expected service depends significantly on performance:22 technologicaladvances in the internet, such as ipv6 (internet protocol version 6) androuters with qualityofservice features, together with increased capacityand better management of the performance of internet facilities, are likelyto result in much better performance for voicebased applications in theearly twentyfirst century.research that would help make the nii as a whole more usable includes making internetbased information resources as accessible as possible from a telephone; improving the delay performance and other aspects of voice quality in the internet and data networks generally;implementing voice interfaces in embedded systems as well as computers; and furthering a comfortable integration of voice and data services,as in computercontrolled telephony, integrated voice mail/email, anddataaugmented telephony.the òpoint and clickó web browser reflects basic human behavior,apparent in any child in a toy store who points to something and says(click!) òi want that.ó because of the familiarity of this paradigm, peopleall over the world use web browsers. for reaching information andpeople, a web browser is actually far more standard than telephony,which has different dial tones and service measurement systems in different countries. research issues include multimedia extensions (includingclicking with a spoken òi want tható), adaptation to the increasing skill ofa user in features such as multiple windows and navigation speed, andadapting to a variety of devices and communication resources that willoffer more or less processing power and communications performance.the network hierarchy andhow it affects user endtoend performanceamong the elements of communications infrastructure that affect performance, the access network is one among several network elements (including networking in the local area of the user and networking within thepublic network) that have considerable influence on performance. accessnetwork bandwidth is an important parameter affecting performance.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.110more than screen deeplocalarea communicationsphysical communications networking can be categorized as an interworking of three networking levels: local, access, and core (or òwideareaó). almost any networkbased activity of a residential user is likely touse all three.local area networks (lans) are on the enduserõs premises, such as ahouse, apartment or office building, or university campus. ethernet, themost widely deployed lan technology, is already appearing in homesfor computer access to cablebased data access systems such as timewarnerõs roadrunner, com21õs access system, and @homeõs access system. it could be in millions of american homes by the year 2000. ingeneral, the 10megabitpersecond (mbps) ethernet is the favored communications interface for connecting personal computers and computingdevices to settop boxes and other network interface devices being developed for highspeed subscriber access networks. a properly engineeredsharedbandwidth architecture such as ethernet allows multiple devicesto have the high òburst rateó capability needed for good performance,such as fast transfer of an image, with only rare degradation from congestion. it is òalways on,ó allowing devices always to be connected andready to satisfy user needs immediately, as opposed to a tedious connection setup.a residence will be able to simultaneously operate not only severalhumanoriented user interfaces in personal computers, heating/coolingand appliance controls, light switches, communicating pocket calendarsand watches, and so on, but also user interfaces used by such devices asfurnaces, garage doors, and washing machines. the introduction of ipv6in the next decade will create an extremely large pool of internet addresses, allowing each human being in the world to own hundreds orthousands of them. this development will foster the interconnection of awide range of devices with embedded systems, a phenomenon that underscores the concern not to cast the nii or eci challenges in overlypersonal computercentric terms.local networking is not necessarily restricted to one shared wiredfacility such as ethernet, which is beginning in the home at 10 mbps butwill likely evolve to òfast ethernetó commercial versions or to atm (asynchronous transfer mode) connectionoriented communications, at 100 mbpsand higher. it can include wireless local networking, generalizations of thecordless phone to cordless personal computers and other devices, withburst rates of at least several megabits per second. local networking islikely to include assigned (not shared) digital channels in various media forsuch applications as video programming and other stream or bulk uses, ataggregate data rates of hundreds of megabits per second.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies111how much bandwidth is enough? assuming òalways connectedóand good performance from the other network elements to be described,10 mbps symmetric should be adequate for almost all processorbasedapplications including fast response image transfers (a 5megabyte imagein 0.5 second) and highquality mpeg2 or h.323 (conferencing/videophone) video at 4 mbps. for streaming media such as video, additionalrequirements of reserved capacity and minimal queuing delay may beneeded, requirements for which atm is well suited. atm breaks trafficinto uniformlysized òcellsó that can be efficiently switched and reassembled with specified qualityofservice guarantees. forecasts of howsoon atm will be available directly at consumer communicating devicesvary, but there is likely to be significant availability in 5 to 10 years. forfuture applications with very complex immersive environments, multiplehighdefinition video streams, or other bandwidthintensive needs, fastethernet and atm should suffice. additional transmission facilities forprogram distribution could use these or other technologies.both sharedbandwidth networks such as ethernet and dedicatedhighcapacity channels could reside in the same physical medium, whichmight be fiber, coax, or twistedpair. the cost of a lan has been fallingsteadily, with ethernet cards for personal computers well below $100.the cost of wiring a new house or apartment building with cable forethernet is low, but the cost could be substantial for rewiring an oldresidence. wireless networking, to bypass the wiring problem, is available now, and it may be priced comparably to ethernet, for comparablecapacity, in 4 to 5 years.access communicationsthe access network is the set of transmission facilities, control features, and networkbased services that sits between a userõs premises andthe core public network. the twistedpair subscriber line running from atelephone office to a userõs residence is part of the telephone access network, for example. there are four basic paradigms offered (and in development): telephone company services via the twistedpair subscriber line,cable company services via a coaxial cable (coax) feed, wireless access viahigherpowered cellular mobile or lowerpowered pcs (personal communications services), and direct broadcast satellite service. there areadditional paradigms, such as terrestrial microwave, that are of secondary importance compared with these four. the access network has longbeen regarded as a performance bottleneck. the telephone channel, restricted to 3khz (kilohertz) bandwidth (and data rates of about 30 kbpsfor reliable transmission) by filters and transmission systems designed formore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.112more than screen deepvoice, presents both bandwidth limitations and connection delays thatseriously degrade performance.òaccessó can be a confusing term. an internet service provider offersaccess service to the internet and some access facilities such as tcp/ipsoftware, but may not provide the physical pipe into the home. for themoment, the discussion is restricted to access networks that include thephysical transmission facilities but returns later to internet service provider facilities because they have a critical influence on the performanceof web browsers and other internetoriented user interfaces.twisted pairbased telephone company services.the first paradigm,access via a twistedpair subscriber line, is advancing with isdn (integrated services digital network), adsl (asymmetric digital subscriberline), vdsl (veryhighspeed digital subscriber line), and hdsl (highspeed digital subscriber line).23cablebased access services.a local cable television (catv) servicecompany maintains a cable distribution system that is still largely dedicated to broadcasting video programming. the coaxial cable network,now actually combining optical fiber trunks with coaxial branches andòdropsó to subscribers, is a òtree and branchó architecture well suited tobroadcast and not so well suited to upstream communications from theuser. it is not well suited to upstream communications because of noiseaggregation problems from many drops and branches coming togetherand because the capacity of the cable, however large, is being shared withbandwidthhungry downstream video services and by a great many subscribers.nevertheless, the cable industry has succeeded in evolving a promising hfc (hybrid fiber coax) network architecture that can service bothvideo distribution and interactive communications needs.24 the hfcsystem provides digital channels with signals produced by cable modems, for which a downstream channel may generate a 30mbps signalwithin a 6mhz bandwidth. instead of one analog video signal, thisdigital transmission can carry seven or eight highquality mpeg2 digitalvideo signals or one digital hdtv (highdefinition television) signal plustwo mpeg2 ordinary digital video signals. more important for the nii,the digital capacity can be used for an arbitrary mix of signals, supportingmedical imaging, language instruction, software downloads, and an infinite array of other applications. a cable system could typically implement up to a few dozen such 30mbps channels plus 80 oldfashionedanalog channels for subscribers who have not yet purchased the digitaltv sets expected to hit the u.s. market in 1998.upstream capacity shared among many subscribers is much moremore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies113constrained. standards are being developed that will allow a user toshare with neighbors a 1.5mbps upstream channel (one of about 20 suchchannels serving a group of 125 to 500 subscribers). other modem designs allow a pool of users to share a 10mbps upstream channel, mimicking the behavior of ethernet. here, just as with adsl, the operator isbetting that traffic will be asymmetric and that the user will not have aperformance complaint even though the upstream bandwidth is not especially generous.above this physical channel level, the cable industryõs model usuallyincludes ip services with the same òalways onó flavor that professionalsenjoy at work. this is an important performance advantage for cableaccess, supporting broadcast information services that flash the latest bulletin on a computer or tv screen, quick internet telephony perhaps bytouching a miniature picture in the screen directory, and immediate linking to a distant web site (contingent on performance being good fartherupstream). if the service, including getting started and customer premisesetup,25 is done well, the popular conception of internet service as difficult to get started and unreliable after that could change radically, and theweb browser could indeed become a universal user interface.wireless access services: location transparency and consciousness andpower/bandwidth tradeoffs.wireless access, currently in cellular mobile networks and soon in pcs networks, supports mobility of persons,devices, and services. it makes possible carrying wearable or pocketdevices, doing computing in a car (perhaps with a òheadsupó display onthe windshieldñused only when it is safe to do so, of course), readingdocuments and messages on an electronic òinfopadó at meetings, andsending òelectronic postcardsó from digital cameras and camcorders. thenew and large unlicensed nii supernet spectrum authorized by the federal communications commission, in the relatively high 5ghz band,will give a large boost to interactive multimedia services when massproduced, lowcost radio modems become a reality. that could happenwithin 3 to 4 years.wireless access can support both location transparency, in which theuserõs application appears the same regardless of location, and locationconsciousness, in which the application finds and exploits local resourcesand can offer locationdependent services, such as giving directions to thenearest drugstore. these two features are not incompatible, and bothcontribute to the utility and usability of a user interface.because of the power constraints imposed by small portable devices,including but not limited to pocket telephones, medical monitoring andalerting devices, communicating digital cameras and camcorders, communicating watches, communicating pocket calendars, and even somemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.114more than screen deeplaptop computers, it is important for the quality of the user interface thatthe wireless access system offer appropriate tradeoffs between communications and processing resources. one way this is realized is to concentrate the power of the portable device on display functions, such as abright sharp display, and leave media processing (such as mpeg andvideoconferencing digital video coding/decoding) to processors accessedthrough the wireless network. however, this balance of function mayimply an unacceptable cost for the substantial communications capacityto carry the unencoded video information. another issue is how to minimize power use on portable systems that are always listening. furtherresearch will be required to identify a reasonable balance between processing and communications power in the system.the microcellular pcs and supernet networks are well suited to thisneed, aiming for burst transmission rates of 25 mbps or more in small(perhaps 300meterwide) microcells. this compares very favorably withpresentday telephonyoriented cellular mobile networks, where modemsmay provide up to about 20 kbps communications rate. higher rates arepossible in the digital cellular mobile systems becoming widely deployednow, but probably not more than 256 kbps, still far below microcellularnetworks.the low earthorbiting satellite (leo) systems planned for personalcommunications from anywhere in the world, which will compete to someextent with terrestrial microcellular pcs systems, could offer the significant user interface advantage of having exactly the same user interfaceanywhere in the world. this would remove a major anxiety for manyusers.direct broadcast satellite distribution services.satellite services couldaugment wired facilities to improve the performance of the user interface.in particular, downloading of large information files to proxy servers innearby network offices or in the enduserõs equipment itself would reduce the delays of access to information in distant servers. there arecache memories in web browsers that save web html objects requestedby users because there is a high probability that the objects will be requested again, but a proxy server does something else. it caches information when it has been requested by one user, under the assumption that ifthe material is popular other users may request it as well. this has theeffect of improving response time considerably for those users and offering added possibilities for customization. there are many important research questions in selecting material for proxy servers, updating strategies, customization for users, and integrating the satellite facility smoothlywith the wired network.direct broadcast satellite service in the nii would also include itsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies115present function of distributing video programming directly to user tvs.in the future it is possible that continual magazinestyle broadcasting ofvideo information clips, captured and displayed immediately by userdevices rather than retrieved from cache servers, also will be part of thenationõs information infrastructure. this would offer the freshestpossible material, supporting, for example, a customized user informationservice in which information is updated even as the reader observes it.core network communications: qos, interoperability, and valueaddedservicesthe core network interconnects access networks. it aggregates traffic,and is, or should be, designed to provide differing qualityofservice (qos)treatment for different classes of traffic.26 continuous voice and videomedia should enjoy minimum delay, and data files should be transferredwith minimum error rate. atm is already widely deployed in the corenetwork. research and development on qos control is already extensive,and further work, on topics such as renegotiation of offered capacity anddynamic user control over qos, would improve the performance of future user interfaces. for example, a user with several applications running could trade qos among them, improving video resolution, for example, at the expense of the rate of transfer of a new software modulebeing downloaded in the background.there are additional services that either the core network or the access network, or indeed parties other than the network operators, canprovide to enhance user interface performance. for example, a multiparty desktop audio/video conference can be displayed on one userõsscreen as a custom combination of pictures of the other participants witha corresponding spatial distribution of their voices. this can be doneeither in the user equipment by processing multiple audio/video information streams all coming to that user or by a processing service in thenetwork (or offered by a third party) called a òmultimedia bridgeó thatcreates the customized display for the user and supplies that user withonly a single audio/video information stream. if access bandwidth is at apremium, the networkbased bridging service provides a highqualityuser interface at a minimum cost in access bandwidth.performance impacts of internet services architecturethe internet, which utilizes all of the communications hierarchy outlined above, is considered by many to be the heart of the nii. as themultimedia internet evolves and assumes much of the quality control(and charge for service!) functionality of the telephone network, this ismore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.116more than screen deeplikely to become true by definition. the internet is defined by use of ip,which carries packets from one kind of network to another without theapplication having to directly control any services in those networks.although they do not, in general, provide the access transmissionfacilities, internet service providers do supply other access facilities thathave a large influence on the performance of user interfaces. these include at least the following:¥adequate modem pools and fast logon for dialup service;¥direct lowlevel packet interconnection to the internet, as well ashigherlevel services such as email, usenet servers, domain nameservers, and proxy web servers;¥gateway services between internet telephony and public networktelephony (evolving in the near future to multimedia realtimecommunications); and¥documentation and instruction for use of browser applications, email, and various internet services and resources.it would require a lengthy report to describe how each of these affectsuser interface performance. suffice it to say that a major objective in providing good service is the avoidance of server congestion, by means of theuse of proxy web servers to give users the impression of fast responsefrom uncongested access to a nearby server, when in fact the originatingserver is far away and highly congested. fast response time is, as emphasized earlier, an important measure of good performance of the user interface.we might also reemphasize the importance of being òalways connectedó to internet access for applications such as receiving timely information from òpushó servers (such as the fastdeveloping customized current information services producing everchanging displays in screensavers), immediate delivery of email, fast receipt and initiation of realtime audio/video calls, and participating in the online work of a distributed group. an alwaysconnected transmission access facility is required,of course, which must be matched by similar facilities27 for the internetservice provider.as with providers of wireless access services, internet service providers will soon be required to support mobility services, such as locatingand characterizing nomadic users. there are significant research questions in coordinating internet routing and serviceclass support policieswith the movement of individuals, in transferring customer profiles forinternet services, and in other aspects of mobility support.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies117software architecture: distributed object environments andtransportable softwaremanagement of a mobility environment, particularly location transparency and location consciousness, is complex, and further research isneeded. distributed object environmentsña software structure beingused more and more in communications as well as applications systemsñhas a large potential to help resolve the complexities and improve performance.28 for example, the global availability of a distributed object environment would make abstract service objects available in a consistentformat everywhere, with those objects translating user needs into instructions to local systems.transportable software is another important objectoriented technology that proceeds from a different assumption, that a common òvirtualmachineó (a special operating system on top of the real one) can be createdon different platforms, so that software in òappletsó (and applications) canbe moved around from one machine to another.29 java is a widely acceptedlanguage and virtual machine structure. web browsers now commonlyimplement the java virtual machine, allowing application applets to bedownloaded from web sites and executed in the userõs computer. thisfacilitates animated displays and other features in the user interface, withmuch better performance than if the software executed in the web serverand large quantities of display information had to be transmitted to theuserõs browser. it also facilitates customization of the web browser userinterface for users with special needs and constraints.transportable software also has great potential for òprogrammablenetworksó in which communications protocols and services are not fixedbut can be changed on user request by sending the appropriate applets tonetwork elements, such as switches, where they execute. this, too, canimprove performance where alternative protocols are better matched toapplications needs, making the user interface more responsive and pleasant to use.notes1.see gunter (1992), semantics of programming languages, for more extensivediscussion.2.for example, the two sentences below differ only in a single word, but the resulting structure of the preferred interpretation is significantly different (frazier and fodor,1978; shieber, 1983, gives a computational model that elegantly handles this particularpsycholinguistic feature). in the first sentence, òon the rackó modifies òpositioned,ó whereasin the second, it modifies òdressó: susan positioned the dress on the rack. susan wantedthe dress on the rack.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.118more than screen deep3.texas instruments had an early natural language system that did this.4.this example was discussed by john thomas, of nynex, at the workshop.5.concatenative synthesizers achieve synthesis by concatenating small segments(e.g., diphones) of stored digitized speech. formant synthesizers use a rulebased approachto achieve synthesis, by specifying acoustic parameters that characterize a digital filter andhow these parameters change as different phonemes are sequenced.6.personal communication, john c. thomas, nynex, december 12, 1996.7. a system introduced by ibm in 1996 for voice recognition software was designedto enable radiologists to dictate reports into a personal computer. recognizing 2,000words and requiring some training, its support for conversational discourse, in a contextwhere certain technical phrases may be used frequently, was contrasted in the press tothe need to pause after individual words in older commercial software (zuckerman, 1996).8.candace sidner, of lotus development, and raymond perrault, of sri, contributed much of the content of this subsection.9.indexing and retrieval constitute a growing application area, especially withthe increased desire to organize and access large amounts of data, much of which isavailable as text.10.this section concentrates on the state of the art of complete endtoend naturallanguage processing systems and does not describe research in individual areas. thesteering committee notes that there has been significant progress, ranging from new grammatical formalisms to approaches to lexical semantics to dialogue models.11.there is much promising research on syntactic models, such as the tag (treeadjoining grammars) work (see joshi et al., 1981, 1983, 1995; shieber, 1983), which arecomputationally tractable syntactic formalisms with greater power than contextfreegrammars, and on lexical semantics.12.although space prevents including detailed references here, the interestedreader is directed in particular to the recent yearsõ conference proceedings of the association for computational linguistics, the european association for computational linguistics, the international meeting in computational linguistics (coling), the darpa spoken language and muc workshops, and the journals artificial intelligence, computationallinguistics, and machine translation.13.for applications involving database query, or for more sophisticated commandand control, the mapping between the sequence of words and their meaning can be verycomplicated indeed. darpa has funded applicationsoriented research in language understanding (roe and wilpon, 1994; cole et al., 1996) in the context of database query,where the user requests the answer to a query by typing or uttering the query. in mostlanguage understanding systems to date, a set of syntactic and/or semantic rules is applied to the query to obtain its meaning, which is then used to retrieve the answer. if thequery refers to information obtained in previous queries, another set of rules that dealwith discourse is used to disambiguate the meaning. pragmatic information about thespecific application is often encoded in the rules as well. even for a simple applicationlike retrieval of air travel information, hundreds of linguistic rules are hand coded bycomputational linguists. many of these rules must be rewritten for each new application.14.the linguistic data consortium at the university of pennsylvania, which issponsored by government and industry, now makes much of this data available, fromdifferent sources, for different tasks, and in different languages.15.note that portable devices raise the larger issue of data durability: portabledevices may be easier to lose or break, which raises questions about ease of backup forthe data they contain.16.much of the crossindustry disagreement revolved around interlacing, a technique that has long been used in television to increase resolution and that takes advanmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.input/output technologies119tage of the extremely high linetoline and temporal coherence of images produced bytelevision cameras. computer output, especially text and graphics, tends to be hardedged and to flicker badly when displayed on interlace monitors. although one canconvert interlaced broadcast tv to noninterlaced at the receiver end easily enough, thereis a cost issue that affects the likelihood of flooding the market with the cheapest setspossible, hence affecting penetration and return on investment. the computer industry(hardware, software, and netware), of course, wants the lowend tvs of the future tohandle digital output in a reasonable format; the television industry wants a 16 9 interlaced format (which is really a 32  9 format noninterlaced).17.the web is, of course, a great source for visual input. copyright concepts of fairuse and royalties will necessarily adapt, as they will for text, and audio quotations, samples,and outright theft.18.blake hannaford, of the university of washington, contributed much of the content of this subsection.19.in fact, the graphics produced are not braille but simply dot graphics printed on abraille printer with the same resolution or dot spacing as braille. this is a common technique, but it produces relatively low resolution graphics.20.the wimp interface will not serve this future, though elements will be involved(keypads, pointing, etc.). in its current form it is arguably dangerous to people susceptibleto repetitive stress disorders, unusable by a large segment of the population with disabilities, and far too simple for navigation in complex spaces.21.as noted in herndon et al. (1994), a slider or dial for volume control has 1 degreeof freedom; the mouse for picking, drawing, or twodimensional location has 2 dof, a 6dmouse or headtracker for docking or view control has 6 dof, a glove or face device forhand/face animation can have 16 or more dof, and a body suit for wholebody animationcan have over 100 dof.22.many users of todayõs internet telephony services experience a long delay, sometimes of the order of a second, in transmission, actually due more to buffering in the userõscomputer to smooth out arriving packets.23.òbasic rateó isdn, providing an aggregate 144kbps symmetric service to a subscriber, suffered from a toolong development, unattractive rate structure, and general ambivalence on the part of telephone operators, but is now widely available and popular forinternet and òwork at homeó access needs. the usual access rate is 128kbps symmetricfrom tying together 2 64kbps channels provided within the 144kbps aggregate service.from the userõs point of view, isdn still suffers from the need to set up a connection,although setup is usually quite fast, and from perminute charges even for local calls.adsl, now focused on the generally asymmetric traffic requirements of computer communications sessions, offers 1.5 to 6 mbps downstream (network to subscriber)and up to 384 kbps upstream (from the subscriber). a subscriberõs adsl service has thepotential to be always connected, permanently linked, for example, through a router in thetelephone office into a highspeed data network. it is not yet clear that telephone companies have the òalwaysconnectedó paradigm in mind. telephone companies have waveredin their commitment to adsl, so it is a very tentative forecast that adsl service at acceptable cost will be available to millions of telephone subscribers in 5 years.although adsl could vastly improve the performance of multimedia user interfaces, it should be recognizedñand this will hold for the other broadband access mechanisms as wellñthat contention for capacity on networks upstream, and congestion at servers, may also seriously constrain performance.hdsl, which provides symmetric capacity of 1.5 mbps and up and usually isdesigned to work over two twisted pair lines, is not generally associated with residentialusers but could quickly overtake adsl if households begin to generate highcapacity trafmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.120more than screen deepfic. vdsl, at rates of 25 mbps or higher, requires a distribution point closer to the subscriber than a presentday telephone office. its potential penetration is difficult to predictand depends a great deal on the success and competitive implications of cablebased dataservices.24.cable interactive access services are just beginning to be commercially available.it is a fairly safe prediction that by mid1999 millions of cable subscribers will be offeredthis service.25.it is a challenge to the cable industry to make subscription and service provisioning simple and fast, and some standards interoperability questions discussed later, such asòplug and playó of digital settop boxes, remain to be resolved.26.the conventional òbesteffortó ip service does not require any special capabilitiesfrom the core network, but the new qosconscious ip services and, of course, atm do. thecore network must deploy technologies such as edge switches and access multiplexers thataggregate traffic arriving under various communications protocols, and must closely control qos parameters for multiswitch routings.27.for the modembased isps this implies higher rates, but the cable model mayallow òalwaysonó capability without major increases in hardware investment.28.corba (common object request broker architecture), standardized by the object management group, is a leading candidate for a universally accepted architecture,although there are other distributed object systems proposed by major software vendors,such as microsoftõs activex.29.transportable software and object broker systems such as corba are complementary more than competitive. corba provides important object location and management services and facilitates use of existing applications software by wrapping applications(written in whatever computer language) in corba objects with standard idl interfaces.the java virtual machine requires new applications, all in the java language, and appletsmay not execute as efficiently as software written for the underlying operating system, butit facilitates the movement of executable software, with appropriate security constraints,with the benefits outlined above. there are many examples now of corbabased systemsin which corba objects are invoked by transportable java applets.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation121121designing any sort of computermediated device for ordinary peoplefor effective and pleasant everyday use has proven to be surprisinglydifficult. the evidence for this observation comes from the myriad problems cited above in this report and at the workshop organized by thesteering committee, from systematic empirical studies cited in this chapter, and from anecdotes involving frequent complaints from ordinarypeople when they are required to use the currently most common publicoriented applicationñtelephonebased voice response menu systemsñaswell as from more sophisticated users of world wide web concerning thecomplexities and frustrations that have led as many to abandon the online life as to join it. (consideration of the experiences and needs ofpeople without specific special needs, referred to here as òordinaryópeople, is an important complement to discussion of those with specialneeds (see chapter 2) for developing ideas for research to support interfaces that work for more, if not most, of the population.)it is, of course, possible that the greater power, utility, and desirability of computerbased functions as compared to traditional massmarkettechnologies (e.g., television, telephony) mean that greater difficulty ofuse is inevitable, worth a high price in human effort and inconvenience,and solvable only by increased education with its concomitant risk ofleaving out those with insufficient time, resources, or ability. however,an alternate view is that it should be possible to use the power of the newtechnologies not only to do more and better things but also to do most ofthem at least as, or more, easily. much of the burden of introducing new4design and evaluationmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.122more than screen deepinformation technologies to the public can be removed or relieved bybetter design of the functions and interfaces with which most people willdeal.the steering committee assumes that it is often or usually possible todesign more widely useful functions and to make them easier to usethrough design activities specifically aimed at these goals. proof of theexistence of this opportunity is readily available, beginning with popularknowledge of such consumer devices as cars and television sets, whichwere very complex initially but became, from the userõs perspective, lessso through sequences of adjustments over time. the handbook of humancomputer interaction (helander, 1988) contains many examples of prohibitively difficult systems made very much easier and more effective byredesign, and many more recent examples are reviewed by nielsen (1993)and landauer (1995). some of these successes are reviewed in more detailbelow in this chapter. to set the stage, one is mentioned here that involves comparatively simple storeandforward (as opposed to more complex multimedia, hypermedia, or collaboration support) technologyñacase that has particular relevance to much of the expected uses in theeverycitizen interface (eci) environment.gould et al. (1987a) designed an electronic message system for the1984 olympics in los angeles. the system was to be used by athletes,coaches, families, and members of the press from all corners of the globe.the original design was done by a very experienced team at ibmõs j.t.watson research center. when first tested in mockup with representatives of its intended user population, it was virtually impossible to operate effectively. by the time an extensive program of iterative user testingand redesign was finished, more than 250 changes in the interface, thesystemuser dialogue, and the functionality were found to be necessary oradvantageous. the final system was widely used without any specialtraining by an extremely diverse population. another example comesfrom the digital libraries context and relates to the cypress online database of some 13,000 color images and associated metadata from the filmlibrary of the california department of water resources (van house,1996). iterative usability testing led to improvements for two groups ofusers, a group from inside the film library and a more diverse and lessexpert group of outsiders. both direct user suggestions and ideas basedon observing usersõ difficulties gave rise to design changes that wereimplemented incrementally.a central research challenge lies in better design and evaluation forordinary use by ordinary users and, more basically, in how to accomplishthese goals. the future is not out there to be discovered: it has to beinvented and designed. the scientific challenge is to understand muchbetter than we do now (1) why computer use is difficult when it is, (2)more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation123how to design and ensure a design for easier and more effective use, and(3) how to teach effectively both school children and those past school ageto take advantage of what there is to use (a complex topic outside thescope of this report).available research and expert opinion point to at least three reasonswhy many computermediated tools (including, especially, communications systems) are currently difficult or ineffective for use by a large partof the population: (1) complexity and power of computermediated tools,(2) emphasis on users with unusual abilites, and (3) sophistication ofdesigners and their discipline.the problemcomplexity and power of toolscomputermediated tools, as compared with traditional technologies,can be extremely powerful and complex, doing a vast array of differentthings with enormous speed. of course, this is their advantage and appeal, but it is also their temptation. it means that a communicationsfacility such as email can be designed not only to let a user send anasynchronous text message to another subscriber but also to send multiple messages, create mailing lists, respond automatically, forward, save,retrieve, edit, cut and paste, attach attachments, create vacation messages,fax, and so on. if the design is not handled extremely well, users will haveto learn how to negotiate this vast array of options, to know about themand how to operate them if they want to use them, and at least how toignore them if they do not, and will always be required somehow tochoose whether and what. the situation can become analogous to providing the cockpit control panel of an airliner for use by its passengers toturn on their reading lights. the consequences in computing range fromthe proliferation of features in software products to observations thatmost amateur spreadsheets contain serious errors, and that employeehandholding costs as much as hardware for business personal computerusers, to additional but seldomused features on standard computer keyboards.1 the concept of multimodal interfaces that would accommodatealternative approaches to input and/or output, discussed in chapters 2and 3, will introduce considerable complexity into the technology development process, without adding any new functional features.great power and complexity also bring the opportunity to make verycostly errors. pressing the wrong key on an ordinary telephone touchtone pad leads at worst to a wrong number. with a computermediatedsystem it can, and often does, lead to hours of lost work or inadvertentlysending, for example, a òtake me off this mailing listó message to 300more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.124more than screen deeppeople, many of whom also wish they were not on it. laboratory studieshave found repeatedly that the majority of user time spent with popularapplications such as word processors (which will be incorporated intomany eci applications) or spreadsheets is occupied with recovery fromerrors (see, for example, card et al., 1983). this is one of two reasons whycomputermediated activities (see below for the second) create very muchmore variability in task completion times than do traditional technologies(egan, 1988). contemporary discussions in the business and personalpress about the òfutz factoróñextra time and effort to adjust variousaspects of a computerbased systemñattest to continuing problems resulting from increased complexity and power. the irony is that in somecases (e.g., early cellular phones, personal computer software), a significant amount of complexity appears to derive from software and sometimes hardware added with the intention of òenhancingó usability.2emphasis on users with unusual abilitiescomputermediated tools emphasize individual differences in abilitymore than do traditional technologies. egan (1988) reviewed a large number of studies of individual differences in the time taken and errors madein using common computer applications. in every case in which comparisons could be made, the variability among different people was muchgreater when they used computers rather than precomputer approachesto doing the same sorts of operations. an approximate summary of thedata from these studies is that while most traditional tasks, such as operating a conventional cash register, calculating a sum (manually), or running around the block, will take about twice as long for the slowest of 20randomly chosen people than for the fastest, in computermediated tasksthe range is never that small; typically, it is around 4 or 5 to 1, and may beas high as 20 to 1, even among welltrained and experienced users such asprofessional programmers.in several instances a good portion of the greater betweenindividualdifferences in computerized tasks has been traced to measurable differences in cognitive abilities. in the aggregate, workshop participants commented, such differences contribute to observations about the concentration of computer use among teenage males; they also contribute to reportsin the business press about the frustrations of òinformation overload.ó3egan (1988) and landauer (1995) reviewed studies in which measures ofspatial memory, logical reasoning, and verbal fluency, as well as age andinterest in mathematics and things mechanical, show greater than twotoone differences between the highest and lowest quarter of the sampledpotential user populations (see figures 4.1 and 4.2 for examples). theparticipants in the studies illustrated were mostly noncareer middleclassmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation125suburban women with little or no computer experience, fairly representative of the average citizens one might expect to be future network users,although not of their range. how significant a problem is this? one guesscomes from studies of the efficiency gains expected for computer applications to common business tasks. from the sparse available data, landauer(1995) estimated that computer augmentation speeds work by 30 percenton average (with large variations). combining this with the individualdifference estimates and a normal probability distribution suggests thatabout a third of the population would usually be better off without computer help as now provided because they do not possess the basic abilitiesprerequisite to its effective use. this is without consideration of the partof the population ordinarily designated as disabled or disadvantaged.while education and training can usually reduce individual differences, there are two reasons why computermediated tasks may be lesssusceptible to this solution. one is the aforementioned vastly greatercomplexity usually offeredñthe much larger variety of different functions available and alternate means for achieving the same effects (e.g.,five or more ways to cut and paste in most recent text editors). thisvariety often means that it can take longer to acquire high skill, akin on asmaller scale to the greater difficulty of learning to fly a jetliner than todrive a car. it also means, often, that some users will find better ways tooperate their system than will others, not because there are large differences in which method serves which person bestñsuch òtreatmentaptitude interactions,ódespite widespread folk belief in their existence, havevirtually never been found in carefully controlled studiesñbut merelythrough chance variations in which operations users learn first, makehabitual, and thus allow to become dominant over other possibilities thatit thereafter takes excessive time to find and retrain for.the second reason that computer training is less helpful than trainingfor earlier technologies is the much more rapid and challenging changesin the technology itself. the basic automobile, typewriter, and telephonehave not changed significantly from the userõs perspective in almost halfa century, and changes from their very beginning have been few, slow,relatively minor, and learnable without help (nonuse of extra features,such as the clocks on video cassette recorders or cruise control on cars,does not tend to be associated with an inability to use these devices fortheir essential functions). by contrast, every new model of a personalcomputing software package, even from the same manufacturer, comeswith many new features and functions, new menu arrangements withnew labels, and a large instruction book (and builtin help system). suchenhancements can affect even basic tasks. and every few years anothernew computerbased technology is offered. thus, there is simply not thetime available to consider yearlong high school courses for each computermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.126more than screen deeptechnology every citizen might want to useñthis year email, next yearthe world wide webñas there was for typewriters and accounting machines, or 7year apprenticeships, as there were for steam shovels andlooms; the systems would be obsolete and gone before expertise wasgained. the result is that highfunctionality computational systems arenever completely learned nor is their power fully exploited, and the primary learning strategy is based on learning on demand (fischer, 1991).the challenge is to design so as to exploit the potential power for ease oflearning and use as well as for increased functionality. discontent withproliferating features contributed to mid1990s experiments with socallednetwork computers, with fewer features than conventional personal computers, as well as to periodic articles in the business press about the persistently high costs of owning and using personal computers.4several members of the steering committee and reviewers of a draft ofthis report wondered whether the lowefficiency gains and large individual differences found in studies in the 1980s may have been overcomeby technological advances in the 1990s. although market statistics attestto growing use of information technologies, the sparse empirical evaluations of these issues in earlier periods appear to have become no morecommon in the past 5 years. while it was not possible to mount a systematic search for empirical evidence on trends in usability, the consensus ofthe usability engineers on the steering committee and among workshopparticipants was that things have not in general improved: for the mostpart, technological advances, particularly in software, have increased complexity, and, while some vendors are doing more usability testing, increased competition to be first to market with new features has brought agrowing tendency to omit the kinds of early and iterative design andevaluation activities these experts think is essential to ensure ease of learning and use. in addition, what testing is done often generates results thatvendors hold closely in the interests of gaining or preserving proprietarycompetitive advantages.market forces alone are unlikely to yield interfaces for every citizenbecause the rapid pace of the commercial market fosters an emphasis onsales performance as an indirect measure of value or effectiveness ratherthan direct presale evaluation of interface quality. at the workshop, dennis egan suggested several reasons for the lack of attention to interfaceevaluation by the industry. first, industrial research groups have reoriented themselves toward identifying nearterm profitmaking productsand services, not performing longerterm research to evaluate new interface concepts and technologies and usually not publishing helpfully detailed results when they do. second, the acceleration of product lifecyclesñparticularly softwareñleaves little time for interface evaluationstudies. third, information technology products may succeed despitemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation127having inferior user interfaces by supporting highly desired functions,reaching the market before their competition and becoming de facto standards. workshop participants from industry and report reviewers emphasized the commercial dependence on marketplace darwinism, notingthat vendors seem to find fielding their best guesses in products morecost effective than added precommercialization testing. some went further to suggest that the world wide web had provided a mechanism forharnessing market cycles, noting that some vendors are using web sitesfor beta testing of products and for eliciting feedback from those users(mostly sophisticated and eager òearly adoptersó unrepresentative of theaverage citizen) who opt to try the products. the constant release of betaversions of software over the web represents a limited kind of softwareevaluation and user involvement on a massive scale; some of these releases are now reviewed, sometimes even on the basis of modest empirical tests, in trade publications, and usability and other design experts arededicated by some vendors to some releases. several companies are using this mechanism for iterative design. however, work by hartson et al.(1996) suggests that methods for using òthe web as a usability labó effectively, while promising, are in their infancy and face a number of problems that will be resolved only by considerable research. for example,this approach will require significant innovation in system instrumentation and user sampling techniques because, as outlined later, the untutored opinions of programmers and other power users are usually of littlevalue for detecting the functionality and usability problems that are important for ordinary people (nielsen, 1993). tracking such efforts inbroadbased user involvement and assessing their effectiveness mightprovide a productive starting place for research on largescale participatory design and evaluation methods.sophistication of computer hardware and softwaredesigners and their disciplinemost of the people involved in the design and implementation offunctions and interfaces for computer applications are themselves sophisticated computer users. feature requests and inventions come primarilyfrom experienced users and are supplemented and implemented by programmers. the situation is unlike that in other consumeroriented technologies in two important respects. as noted earlier, computers offer andusually provide a larger range of functions and controls and thereforealmost always greater complexity in the choices and actions required ofthe user. hence, expertise with a computer technology can often play amuch greater role in its use. computer technology started as an aid for ahighly technical portion of the populationñscientists, engineers, andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.128more than screen deepmathematicians, most of whom were capable of designing at least somesoftware themselves, and often did.5 to a considerable extent, computerdesigners have designed for their own use and for that of people likethem; the design of computer applications is still primarily in the hands ofprogrammers and other software specialists, albeit now as leaders of largeteams and abetted by marketers, physical designers, and managers. perspectives of other kinds of peopleñthe differently abled, those with lowlevels of income and education, those resistant to technology merely forits own sake, and so onñhave been represented most commonly by proxyor surrogate, if at all.not only are software specialists typically more experienced with thetechnology, but they are also, in general, quite different from the averageuser in the characteristics and abilities currently needed to deal effectivelywith computers: youth, mechanical and mathematical interests, good spatial memory, verbal fluency, and logical ability. they also tend to be lesssocially and pragmatically oriented in personality (tognazzini, 1992).although they may attempt to incorporate models of user behavior, behavioral scientists at the workshop noted that in practice designers tendto assume model usersñusers whose behavior poses fewer problems thanactually experienced. as a result, it is extremely difficult for todayõscomputerbased systems designers to have good intuitions about whatwill and will not be easy and gratifying for all citizens. this situation isillustrated by a press account of a microsoft consumer product teamõsvisits to five families for 3 hours each, reporting surprise about and betterunderstanding of presumably ordinary households (pitta, 1995).the rise of the world wide web and experimentation with it by awidening range of people provide many illustrations of the challenge todesigners. in a recent email discussion on the topic, it was mentionedthat ordinary citizens might experience difficulties in finding email andweb addresses, to which a wellmeaning expert replied that there werethree universal resource locators (urls) on the web that could besearched and that at least one of them would usually locate a personõsaddress. it seems unlikely that this procedure would be very appealingor effective for most citizens who are not already frequent and accomplished usersñthe suggestion is consistent with an expert rather than aneverycitizen interface. true, the availability of these searchable databases means that the possibility of eventually providing a good directoryservice for every citizen exists, but the necessary next steps need taking.the anecdote suggests that this may be a larger than obvious task, sincethe difference between usually and always locating a personõs addressmay affect how broad a segment of the population finds the service desirable and how much the internet can contribute to a truly national information infrastructure (nii). the trends toward supporting doityourselfmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation129activity that extends to assembly and customization of software systemsfrom components and modules by users appear likely, in the near term, toexacerbate the challenge of serving more of the population. (one of thesteering committee members has been told by a major manufacturer thatless than 10 percent of office workers ever change the factory configuration of their ergonomically adjustable chairs.)in short, evidence discussed at the workshop indicates that an organized design and development process that ensures that the needs andabilities of potential average citizen users will be well taken account ofhas not yet become standard practice in software to nearly the extent thatit has in the manufacture of most other massmarket products. workshopdiscussions among technical experts and social scientists knowledgeableabout specific population segments attested to the diversity of needs,reactions, and other qualities within the population as well as the unevenappreciation for that diversity.the possibility of easiertouse,more effective systemsthere is ample evidence that computer systems with highly usefulfunctions can be designed and built for easy, pleasant, and effective useby every citizen. figures 4.1 and 4.2 give two examples. in both cases afunction that could be used at an adequate level by only a minority ofpeople was redesigned so that everyone could use it well. moreover,improving usability for the less capable users did not penalize the morecapable. these cases and others like them show that paying attention tothe needs of novice users can often be accomplished without undesirabletradeoffs for expert users. indeed, it is commonly the case that redesignsthat help occasional users are even more helpful for frequent users; forexample, effective freeform queries such as those provided by excite andlatent semantic indexing will allow both novices and the most sophisticated systems analysts to search the web more easily and effectively andwith fewer frustrating, timeconsuming errors than are common withstandard query language (sql) or boolean search formats.two additional examples of success in improving usability throughredesign are instructive. in one case, an email system was redesigned forsimple text message interchange, emailõs most popular use. the systemwas always on (no logon was required), like a telephone, and had ascreen that said òto,ó a simple backspace and retype editor, a buttonlabeled òsend,ó and a printer that printed only when a message arrived.a group of elderly womenña segment of the population shown by dataand demographics to be especially technophobic and less likely to succeed at computingñlearned the system after about 30 minutes of trainingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.130more than screen deepand used it eagerly. (the same email system was preferred by severalhighlevel executives of a telecommunications research company, all technical ph.d.s who had easy access to a much more powerful system.) bycontrast, todayõs typical email systems are usually introduced to business employees in fullday training classes. the second example involveshypertext. in the majority of experiments evaluating how well people canfind information in the same large book, manual, or encyclopedia usingtraditional print versions and online hypertext versions, people did significantly better with paper (see, for example, gould and grischkowsky,1984; gould et al., 1987b6). but in a few cases, people using the hypertextsystems have greatly outperformed those using the old technology (seelandauer, 1995, for a review). the difference has been attributable to thedesign of the hypertext system, and especially the methods by which thedesign was done.when conflict between ensuring usability for relative novices andproviding power for the highly trained is unavoidable, perhaps becausefigure 4.1using a standard relational query language (sql) to make simpledatabase searches after a halfday of training required greaterthanaverage logicexpressing abilities. based on user studies, a new query language was invented that everyone finds easy to use and effective. source: landauer (1995).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation131of entrenched development and marketing techniques or the inherentsophistication of some applications, two complementary approaches arepossible. one is to provide differing levels of functionality for differentusers. several usability specialists at the workshop reported routinelyadvising designers to provide as many functions, features, and options aswill be useful, feasible, and in demand by experts, but to òhideó themfrom users who want only basic functionsñby, for example, retaining thesimplicity of short menus that emphasize only the best general functionsand offer the option of selecting an òadvanced functionsó button for access to special features. the second approach is, of course, to increase thesophistication of users through education, training, and access to goodguides and manuals (e.g., òtraining wheelsó and òminimal manualó techniques, and scaffolded and staged advancement). future computing functions of use to many citizens may well require fundamental understanding of concepts and operations that are not now taught in schoolñiterativefigure 4.2when people had to compose queries in a natural language to findinformation, only those with aboveaverage verbal fluency succeeded. when,instead, people could submit examples of documents they wanted, everyone didwell. source: landauer (1995).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.132more than screen deepand simulationbased problem solving, for example. some research hasbeen done on speeding the acquisition of such expertise, but the basicissue of what knowledge and skills are most important to teach itselfwarrants assessment7ñthe history of computing machines and the difference between bytes and bits, ram and rom (random access memoryand readonly memory), as often taught in òintroductoryó computerclasses may not even be among them.existence of effective design methodsit is by now well established that iterative testandredesign methodsalmost always result in substantial gains in usefulness and usability.landauer (1995) summarizes a large number of published reports of comparisons of task performance efficiency before and after a redesign basedon some kind of empirical evaluation of the use of a computerbasedsystem. the modal gain is around 50 percent, and new methods and newevidence of their success appear regularly (see, e.g., sawyer et al., 1996).unfortunately, there is almost no discernible commonality to themethods used in the studies surveyed, other than that they all empiricallyevaluated the performance of users trying to do what the system wasdesigned to help them do and that in all cases the evaluation was formative rather than summativeñthat is, done early enough and with a viewto guiding improvements rather than just certifying adequacy. sometimes the evaluation was done by systematic experiments in laboratorysettings, sometimes by careful examination of the interface and dialogueby two or more experienced usability experts, sometimes by detailed examination of usage logs, sometimes by analysis of videotapes of usersworking, sometimes by informal observation of users or by asking usersto talk about what they were doing. in one telling example, as recountedat the workshop by john thomas, researchers at nynex used a simulation model to estimate and measure the work efficiency of a new graphical user interface intended to improve the efficiency of a computer systemfor use by thousands of employees. the simulation model, which emulates the perceptual and motion time demands of wellpracticed repetitive tasks, predicted a decrease in efficiency. field results after the systemwas deployed without revision confirmed the prediction; and at the sametime, a revision in the laboratory taking into account the discovered flawsreversed the unfavorable result (gray et al., 1992).while there are known ways to ensure improvements, there are twovery serious outstanding problems in the design process. the first is thatthese methods are not applied often enough, well enough, or early enoughin design and development cycles to help most systems. in part thisresults from a persistent myth among technical practitioners and managmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation133ers that iterative empirical usability engineering methods are too slowand expensive to bring to bear in todayõs competitive environment. infact, as has been shown repeatedly, usefulness/usability testing almostalways shortens delivery times by removing the need to develop unneeded features and expensively rework designs. moreover, if done right,it actually takes only about 4 to 12 hours per week during development, atrivial addition in most projects. in addition, even faster and more economical feedback techniques are still evolving (virzi et al., 1996) andwould undoubtedly make even more progress with greater than theirpresent meager support. indeed, this is the second part of the problemñtoo little is known about what methods work best for what purposes:which are fastest, most accurate, most cost effective, and what new methods might be even better for some purposes. workshop participant dennis egan, of bellcore, put it this way:some people have the view that evaluation studies do not matter, thatany interface that has to be systematically evaluated and whose obvioussuperiority does not hit you between the eyes must not be worth much.the idea is to focus on entirely new interface designs and concepts, theòhome runó rather than the incremental improvement. clearly, we needpeople creating totally novel interface concepts, seeking breakthroughtechnology. but there are many instances where a creatorõs intuitionabout the use of novel technology has proved very wrong. we need tounderstand how best the new (and older) technology can be harnessedto support work, aid in instruction and training, and provide entertainment. the skeptics and scientists among us often are left wonderingwhether a new technology really serves well for a particular task or job.the challenge is compounded with the advance of such innovations asthreedimensional interaction interfaces, which can involve different tasksand metrics than twodimensional interfaces. comprehensive usefulnessand usability evaluation of entire threedimensional user interfaces, forexample, remains to be undertaken (herndon et al., 1994).too little use of known methodswhile more empirical evaluation of usefulness and usability is beingdone, especially by large producers on major products, the quantity andintensity of such research is still very slight relative, for example, to themechanical testing of auto engines, wind tunnel testing of airframes, cyclespeed and reliability testing of computer chips, or code correctness andperformance testing of computer programs. often, lessons learned inempirical tests, especially when some features are found to be undesirmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.134more than screen deepable and simplification is called for, are ignored in favor of featurelistdriven marketing considerations. often, testing is postponed until theend of development, when it is both in danger of being omitted entirelyand too late to inform revision. some of this projectõs industry participants reported that recent reductions in product development times resulting from market pressures have made timely testandfix efforts evenless common than before.evaluation needs to be done very early and at all stages of developmentñindeed, starting even before invention and development, at theneeds analysis, wants identification, and ideasaboutwhattobuildstages. a recent study suggests that paper mockups of screens and interaction dialogues are often as effective as fullscale prototype testing (sawyer et al., 1996). what will cause there to be much more empirical evaluation of whether all citizens can easily use what is provided to do thethings they want to do? ideas proposed at the workshop ranged fromencouraging broader education of software engineers (which might befacilitated by federal agency sponsorship of summer schools, workshops,and fellowships) to the creation of a new professional category of computer system designer, separating the design activity from the buildingactivity much as the structural architect job is separated from that of thegeneral contractor, plumber, or carpenter. professional societies wouldhave a role or at least a position on possible mechanisms. another suggested approach was to get appropriate evaluation activities better specified in development process standards and their certifications. consistent with the project objective to identify areas for research werediscussions of the need for more interdisciplinary research and suggestions for combining or better linking research on concepts with evaluationof implementations. one idea voiced by several workshop participantswas that government (at different levels) might play a leading role byestablishing requirements for usability and usefulness testing in procurement processes and by exploring and demonstrating everycitizen usability assurance in the design of publicserviceoriented systems offered overthe nii.8 comments by federal observers at the workshop suggested thatthe basis for some government activity can already be seen in activitiesunder the aegis of the u.s. department of defense (captec program)and the general services administration as well as specific agencyprojects involving kiosk installations.appropriate incentives for better design of what are becoming massmarket products are complicated by the inherent need to balance economic and social interests. at the workshop, industry participants emphasized that additional evaluation, design, and features all have costs.controversies related to regulatory interventions (e.g., requirements forcertain product features) under the aegis of the occupational safety andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation135health administration and the americans with disabilities act, for example, illustrate this tension. they raise the question of whether researchcan make both more usable technology and associated evaluation lessexpensive. this is one reason why some workshop participants called forresearch to develop better tools to support design and evaluation.one of the issues energetically argued at the workshop was the problem of assessing the potential value of a new technology before it exists.some participants worried that attempts to do so stifle creativity becausepeople cannot be expected to imagine with any accuracy whether theywould like or find useful an entirely novel way of doing things. examplesare rife: alexander graham bell did not think the telephone would beuseful for interpersonal communication but only for entertainment broadcasting. early ibm leaders thought a handful of computers would fill thenationõs needs. xerography met long and strong investor resistance because few could see a need. until recently, large numbers of people whohad not tried it, including most telecommunications company executivesand marketers, could not see any benefit in email. these examples illustrate that evaluation calls for doing more than simply describing a noveltechnology and asking people whether they would want it.other workshop participants, including especially social psychologists and human factors specialists, were of the opinion that, while suchassessments are more difficult and less sure than, for example, comparative evaluation of existing and widely used technologies, methods already exist that can give good early hints. some methods are associatedwith scholarly research; some are associated with market research (muchof which draws on social science techniques, such as conjoint analysisñusing analysis of statistical variance to explore tradeoffsñand constantsum point assignmentñto assess priorities).an illustration of the technologyforecasting dilemma is video telephony. on the strength of the technical promise, this technology has beenreinvented and tried repeatedly, in approximate 10year cycles. but fromthe earliest laboratory and field trials, through many succeeding oneswith better and better (and often, because the trials were not constrainedby cost, quite excellent) technology, it has been found repeatedly thatmost people do not choose to use these facilities. trials accompanied byusage data, observation, and surveys repeatedly find that peopleñfromexecutives to researchers, engineers, and middle managers, to homemakersñusually prefer not to be seen when conveying a short message. whilenonverbal cues can convey information, the amount and validity are muchless than is popularly believed. moreover, what is conveyed is not necessarily relevant to the function at hand and may even detract from it.studies suggest, for instance, that obscuring information about gender orsocial status can result in moreñand more egalitarianñparticipation inmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.136more than screen deeponline group activities. on the other hand, the added value of a visualchannel for communication is often not for provision of affective cues butrather to enable references to or manipulation of shared visual artifacts(such as photographs, engineering drawings, and proposed budgets). thelikely value of these facilities for ordinary citizens and for special populations is among the questions that need answering. these and other examples indicate that, while it is sometimes possible to forecast what technologies will emerge soon in the marketplace with some confidence, morethan intuitive hunches are needed to predict whether, how, and why theywill be widely used.among the methods cited as reasonably effective for predicting thevalue of a new technology were the following:¥task analysis.broadly conceived, task analysis means observingpeople in reallife situations to see what they are trying to accomplish,how well they are succeeding, and what is preventing success, and askingquestions about goals, frustrations, and important incidents. this mayoccur in the context of ethnography, an anthropological approachinvolving observation of people in their natural environments, or bydesigners involving themselves as natural participants in the task in itsnatural setting, sometimes called contextual inquiry. applied in 1870, atask analysis approach might have discovered that people spent a gooddeal of time writing letters in order to pass small bits of news or to obtainshort answers: reports of sickness, requests for prices, dinner invitations,social maintenance greetings. an analyst might have gone on to countthe number of occasions in which circumstances arose that would be wellserved by different means of communication if they were available and, ifclever, would have noted that people often took long periods out ofdemanding days to walk miles to merely chat with friends, thatoccasionally runners were sent in all possible haste to fetch midwives orrelatives. from such observations would come at least an educated guessthat a faster means of interpersonal communication would be useful anddesirable. then the analyst might ask people to imagine talking at adistance, but would do so carefully and with informed interpretation.task analysis is implicit in the development of domainorienteddesign environments (fischer, 1994a), which (1) reduce the learningproblem by supporting human problemdomain interaction by bringingtasks to the forefront, (2) allow users to learn more about functionality inthe context of a task at hand (thereby supporting the integration of working and learning), and (3) assist users through an agentbased critiquingmechanism (fischer et al., 1991) to reflect and improve the designedartifacts. the use of these systems of domainoriented design environments has been demonstrated in a variety of different domains, rangingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation137from kitchen design to voice dialogue design, multimedia design, andlunar habitat design.¥performance analysis, which goes a step finer.the word òanalysisóis important here and has a meaning not unlike its use in chemistry.performance analysis involves observation and experimentation to findout what people can do easily and what they can do only with difficultyor not at all. the research that raised the low ends of the curves in figures4.1 and 4.2 was of this kind. for example, in the database query research,experimental analysis revealed that the majority of the population cannotform logical expressions to describe an object of search even though theycan recognize with high accuracy the things they want (landauer, 1995).the invention that flowed directly from this was a recognitionbasedquery method (a truth table of possible data).¥special forms of focus group discussions.in these, an analyst takesparticipants step by step through scenarios of increasingly futuristic technologies, at each step eliciting discussion of possible uses, values, anddefects. one variant, known as òladdering,ó involves interviewing peopleabout what they are familiar with in order to get them to think aboutnewer concepts (reynolds and gutman, 1988). the result is not necessarily a prediction of utility and market success but the raising of importantand often unanticipated issues.¥mockups, wizardofoz experiments, and rapid prototypes.very often new interfaces, sometimes new functionality, can be given an informative initial exploration by a mockup using paper, slides, or video andeither walking people through scenarios of using the proposed screensand functions, seeing what they understand, and listening to what theysay (statements such as, òwhatõs this for?ó or òi wish i could do xó) orasking them, where òthemó is both ordinary potential users and usabilityexperts, what they think of what the system does and has to offer (lundand tschirgi, 1991). at the workshop, bruce tognazzini showed the workshop the òstarfireó vision video produced by sun microsystems. similarto apple computerõs òknowledge navigatoró video, òstarfireó gives anenactment of a futuristic scenario in which an anticipated or imaginarytechnology is being used by people. these videos were designed forvarious purposes; the status of òstarfireó as an engineering project outputillustrates the potential value of such vehicles to inform design (e.g., panels of people, both ordinary and expert, could discuss and critique them;see tognazzini, 1996).in the wizard of oz technique, a human, often assisted by software, performs some of the functions of an imagined system before it canbe built. for example, gould et al. (1987a) used a human to transcribespoken input to emulate a much better automatic voice dictation transcription machine than could be built at the time (or now) in order tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.138more than screen deepstudy how useful and desirable it would be and to understand some ofthe design alternatives and parameters that eventually should be implemented. the technique is only good for functions that humans withcomputer help can emulate, but with ingenuity this can cover a considerable range.finally, there are rapid prototypes, perhaps a more familiar idea.essentially, the technique is to build a system that does only part of whatthe invention will call for in actual deployment, using much more easilyconstructed software and, perhaps, much more expensive hardware sothat something like the intended technology can be tried with real usersbefore its design (or attempted production) is settled. one especiallyappropriate target for the discussion here might be advanced voice recognition, graphics, multimedia, or virtual reality interfaces. early usefulness and usability trials with approximations to such systems using human participants could reveal what functions and features are and are notpromising for everycitizen use before great effort and expense are devoted to their realization. for example, at the workshop, robert virzidescribed how gte progressed from a 1990 case study of how peopleshopñidentifying unmet needs for information about how to find vendors or special sales and difficulties in communicationñthrough designof a service for which the underlying network technology was not adequate at the time to the 19951996 superpages effort to provide onlinenational yellow pages, intended to be a basis for broader services supporting communications and information exchange among vendors andconsumers. this anecdote illustrates the blending and balancing of studies of user preferences with judgments about whether and how to addressthem with available technologies.beyond individual interfaces: computersas social machinesearlier research on interfaces tended to presuppose a view of humancomputer interaction as an exchange involving a single individual performing an independent action by means of a computer. this view, perhaps influenced by the òinputprocessoutputó paradigm, has stronglyinfluenced the design and evaluation of user interfaces. not surprisingly,that orientation yielded a substantial body of information about the significance of individual differences in ability and prior experience for easeof use and judged and measured usefulness of alternative system designsas well as guides for improved research and evaluation (see above). now,however, advances in information and communications technologies havecreated a much more complicated context for the design and evaluationof interfaces for everyday use.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation139the move toward network access, distributed architectures, and opensystems has made this medium a social one: computers provide a meansfor taking part in social activities, doing collaborative work tasks, engaging in educational pursuits with other learners and teachers, doing commerce, playing group games, contributing to and benefiting from sharedinformation stores, and so on (see chapters 2 and 5). the good news isthat these kinds of distributed architectures and tools come much closerto reflecting the ways people learn, work, socialize, and more generallyparticipate in the varied activities that comprise everyday life. the badnews is that òsocialó computing adds another layer of complexity to thealready difficult design and evaluation issues just summarized. whetherinterconnected computers are viewed as media for enhancing interactions among individuals in physical communities or for forming information spaces in which people, representations of people (e.g., avatars), andintelligent agents interact in a built environment (or both), it is likely thatnew or significantly improved design and evaluation methods will beneeded to make such interchange accessible to everyday citizens.although useroriented research in this field is relatively new, it isworth reviewing the main findings that can be expected to figure importantly in the design and evaluation of interfaces for computerbased collaborative activities. the term ògroupwareó was coined to refer to computerbased technologies that primarily target groups as users (box 4.1).roles, relationships, and boundariesas some of the definitions in box 4.1 indicate, groupware must accommodate many individuals, not all of whom have the same roles (incontrast to individually oriented research, in which humans interactingwith a computer application were assumed to be engaging in the samefunctions). typically, roles are captured by rules that attempt to expressrelationships, permissions, and limits. for instance, in collaborative learning environments the teacher role may be accompanied by some options(e.g., annotating student submissions) that students do not have, or students may be allowed to see and comment on one anotherõs term papers,but only after their own papers have been submitted. in health care, morecomplicated scenarios are envisioned involving, for instance, the roles ofpatients, health maintenance organizations, expert systems provided bydrug companies, and pharmacists (see position paper by michael traynoronline at http://www2.nas.edu/cstbweb).social applications of the sort citizens might use to support routineaspects of daily life like education and health care complicate underlyingsystem design issues: how much social knowledge of roles and relationships is appropriately incorporated into application development, andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.140more than screen deephow are such decisions to be made? whatever decisions are taken, howare the resulting rules and constraints most readily made evident to usersin the interface design? further, besides understanding how the application itself operates, users will require additional information about privacyñwhen are their communications restricted to authorized others andwhen is privacy not guaranteed? creating social context awareness in theinterfaceñso that it is not as easy inadvertently to broadcast personalhealth status information as it is to spam (flood) a listserv with anòunsubscribe meó message, for instanceñis yet another challenge. asthis enumeration of issues suggests, the decentralization of computingpower that underlies groupware is what differentiates it from telephony,which could be considered a simpler forerunner technology. realizingthe promise of groupware implies aiming to achieve more than is possiblethrough the telephone system, per se.it is important to underscore that nothing about groupware as a socialmedium invalidates the prescriptions set out earlier for improving thedesign of novel technologies. instead, the inference to be drawn is thattaking into account the social nature of most citizensõ everyday activitiesand the range of actors and contexts involved makes advance use of taskanalysis, performance analysis, focus group discussion, and rapid prototyping both more important and more difficult.box 4.1some definitions of ògroupwareó¥specialized computer aids designed for use by collaborative work groupsñrobert johnson¥software applications that are designed to support . . . groupsñespeciallysoftware that recognizes the different roles the users of the application haveñjonathan grudin¥the class of applications arising from the merging of computer plus communications technology. these systems support . . . users engaged in a common taskand provide an interface to a shared environmentñclarence ellis¥computerbased tools that can be used by work groups to facilitate the exchange and sharing of information (including user adaptations of individual tools tosupport group functionality)ñchristine bullen and john bennett¥loosebundled collection of multifunction tools in an interactive system . . .that are susceptible to use by all the members of a group, plus the user practices thatincorporate them into daytoday service to accomplish group tasksñtora biksonnote: the term ògroupware,ó while variously defined, refers to current efforts tomake distributed computer technology meet the needs of multiperson groups engaged in varied work or social interactions.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation141interdependency and critical massa second differentiating factor is that, unlike computer applicationsfor individual use, groupware not only presupposes but also requires amultiplicity of users for its functionality to be experienced and evaluated.an example is provided in an early study by grudin (1988) of why collaborative applications fail. he targeted electronic scheduling as the application of interest because market research had consistently found managers and professionals saying that it would be highly desirable to lettheir computers handle the tedious task of arranging appointments andmeetings automatically, once provided with information about when relevant individuals were available; but when such applications were installed in organizations, they were rarely if ever used.the reason for the discrepancy between anticipated and actual use isinstructive and turns mainly on the interdependent nature of social applications. the payoff from programs that schedule meetings or appointments depends on the proportion of potentially relevant users who in factuse them; if a òcritical massó of people whose calendars are affected donot use the program, others derive no benefit from entering and updatingtheir own schedule information and so they soon stop. the schedulingprogram thus imposed user costs (in the form of added tasks) withoutgenerating the expected benefits. in this way it differs from independenttechnologies that yield individual benefits to those who adopt them, regardless of whether there are other users.9the same interdependency characterizes shared discretionary databases (markus and connolly, 1990) and computerbased communicationssystems (anderson et al., 1996). more generally, while the design anddevelopment costs are borne up front, the value of interdependent applications is apparent only later, after a substantial portion of the intendeduser community engages in their actual use. besides necessitating a morecareful understanding of the contexts of use in the design of groupwareapplications, these considerations underlie the òextreme difficultyó ofevaluating them (grudin, 1988). they also illustrate how broader usability involves not only the user interface per se but also the social contextand the overall service and what these imply for interfaces.although the more recent growth in sales and apparent use ofgroupware products such as lotus notes suggests that progress has beenmade, the evolving nii also raises the prospect of far larger numbers ofpeople interacting than has been experienced to date. sheer numbers,plus variations between groups of people who interact on a sustainedbasis and those who come together on an ad hoc basis, and variations onwhat people will do with such facilities beyond the current business environment of their uses, are among the emerging technical challenges thatmay affect interface design.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.142more than screen deepiterative test and redesign for social applicationsearlier sections of this chapter made it clear that, while there areproblems with these methods, iterative test and redesign procedures areeffective known ways to improve system usefulness and usability. thisthesis holds true for interdependent as well as independent applications,but the deployment of effective testandredesign procedures is more complicated for social applications.in the first place, whatever methods are chosen, they will need toinvolve trial users playing the interdependent roles relevant to the application in sufficient number and over sufficient time to exercise, assess,and redesign the varied functions that the application is supposed tosupport. this consideration by itself suggests that iterative test and redesign of groupware may take longer and cost more than the same methodsapplied to independent applications if sufficient ingenuity is not broughtto bear on the evaluation methods, for example, by embedding usefulnessand usability analysis in the instrumentation of experimental designs offered over the world wide web.second, getting good answers to design questions depends on havingboth realism and control in user trials, and there can sometimes be atension between them (cf. mason and edwards, 1988). many humancomputer interaction studies, for example, have relied on laboratory experiments that presented a computerbased task to individual subjectsand measured their performance. while strong on experimental control,such studies are typically weak in realism. in particular, they do notaccount for the influence of the varied contexts (environmental and social) within which computerbased tasks are usually situated, and theymeasure performance by means of variables that assume noninterdependency among users. on the other hand, achieving realism means havingan adequate scope (enough users and uses) and a realistic time frame aswell as an appropriate task context for judging an applicationõs usabilityand usefulness. typically, such realism is achieved at the expense ofcontrol, in a oneshot field trial (not infrequently, the user group is thedevelopment department, as noted above); outcomes do not generalizebeyond the unique case. further, the tensions between realism and control are heightened when social applications are the evaluation focus.the techniques outlined above for assessing the likely value of a newtechnology improve evaluation in part by trying to join realism and control, and their extension to social applications is promising (e.g., olsonand olson, 1995). in addition, betterdesigned laboratory studies (e.g.,kiesler et al., 1996) and field experiments (e.g., bikson and eveland, 1990),as well as innovative approaches to research on the implementation anduse of computerbased media over time in nondirected realworld casesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation143(e.g., homenet (kraut et al., 1996); blacksburg (va.) electronic villageproject, (http://duke.bev.net)), are helping to address the need for bothrealism and control in evaluating social applications. however, as thesize of user groups increasesñas reference to òevery citizenó suggestsñsome participants were not certain about how well any of these approaches would scale up. (these concerns surface above in discussions ofsocialinterest applications of the nii.) several workshop participantsnoted that once one moves beyond a focus on personal computers as theaccess device and considers all manner of devicesñtelephones, televisionremote controls, and so on, as well as embedded systemsñthe problemsand opportunities add up to a very large set.inherent unpredictability of usefor reasons both practical and theoretical, predicting the performanceof social applications in realworld use on the basis of prior research isinherently difficult. practically speaking, cutandtry or designandfixmethodsñthose most likely to yield accurate resultsñare least likely tobe employed for social applications because of the time frame and scopeof uses they entail, as suggested above.in theory as well, groupware uses are hard to anticipate because theyare embedded in a social system that exerts effects quite independently ofthe technology. for instance, the social system of work had a significantinfluence on the automatic scheduling applications studied by grudin(1988; see above). managers, who most often called meetings, were mostlikely to have secretaries who kept their online calendars up to date andhandled òworkaroundsó by phone when others had not put their schedules online; so managers benefited from the application but experiencednone of its burdens. lacking secretaries, professional users experiencedall of the burdens but few of the benefits and soon gave up on it (grudin,1988). there had been several task analysis studies of the problems andpromise of schedulers, and many had predicted just the problems grudincites, but they were ignored or unknown to proponent designers.as markus and connolly (1990) have pointed out, managers sometimes solve these kinds of problems simply by mandating the use of anapplication. in turn, however, clever professionals respond by gaming thesystem so that what appears in the online calendar is what is most convenient or most socially desirable, regardless of the actual status of theindividualõs time commitments. similar results have been reported foruse of shared databases by patriotta (1996). these outcomes, reflectinginterventions by the social system, are even more removed from expectations based on untested designer intuitions. it should be emphasized thatmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.144more than screen deepsocial òreinventionsó of technology are not necessarily negative; on thecontrary, research literature provides a great many instances of userbasedimprovements (e.g., bikson, 1996; orlikowski, 1996). the point, rather, isthat unpredictability inevitably characterizes the use of groupware because of the reciprocal adaptations of the technology and the social context in which it is situated.implementation as a critical success factorimplementation, construed as the complex series of decisions andactions by which a new technology is incorporated into an existing context of use, assumes critical importance as a success factor for groupwaregiven the reciprocal influence of social and technical sources of effectcited above. during implementation, the new technology must beadapted to work in particular user settings even as users must learn newbehaviors and change old ones to take advantage of it. at the workshop,sara kiesler cautioned that experiences related to the performance of specific tasks (e.g., by telephone operators) will not necessarily generalize tothe larger nii. specific tasks tend to be tightly delimited and jobs of theperformers in typical studies depend on their use of the system; in thenii, in contrast, there is a huge variety of tasks, a huge variety of users,and the users have more choice in what they do and how. walterfeurzeig, of bbn, argued that it is nevertheless difficult to consider userinterfaces independent of specific activities. sara czaja, for example, drewfrom her work in medical trauma settings to emphasize that real experience in real contexts is necessary to understand interface needs at, forexample, physician workstations. help features of the system and usertraining as well as modifications of the application and changes in usersõbehavior, for example, affect the course of implementation.current research on work group computing corroborates the conclusion that the effectiveness of the implementation process itself has a substantial impact on the usability and usefulness of social applications somewhat independently of their design features (mankin et al., 1996; see alsothe literature reviews in bikson and eveland, 1990). the vital role ofimplementation also emerges as a salient factor in the life of new civicnetworks, according to their administrators (see anderson et al., 1995).nonetheless, evaluation efforts frequently target technology designas it bears on specific functions, leaving implementation processes andrelated features (e.g., help screens, online tutorials, user manuals) out ofaccount in attempting to predict use. further, although it is clear thatmany desirable changes in social technologies cannot be anticipated before their deployment in specific user settings, these applications are notusually designed with a view toward ease of modification either by endmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation145users or by service providers who maintain enduser systems. on thecontrary, desires on the part of end users or those who provide information technology assistance are usually regarded with suspicion by designers and developers (ciborra, 1992).given the significant variation in uses, users, and user contexts represented by everyday citizens, along with serious questions about how theirniibased interactions can be supported, such implementation issuesmerit considerable attention.directions for improvementfor reasons like those reviewed here, it is manifest that systems intended for use by communicating social groupsñincluding large populationsñraise many kinds of questions that individual applications do not.the design and evaluation techniques appropriate for individual applications need to be extended or supplemented with approaches more suitable for the envisioned nii environment. while there is not a large bodyof empirical work on which to draw for this purpose, research on computersupported cooperative work and technologies for collaborationyields suggestive directions for improvement. some promising approaches are summarized below.involve representative users in substantive design and evaluation activityearly and oftenparticipatory design is difficult to arrange, as noted above, and so morelikely to be slighted. the goal is to understand how interfaces to connectedcommunities may prove more than skin deep, how they may affect how welocate and remain aware of one another and find shared information, aswell as how we understand, enact, and track our roles in group activities,recover from errors, merge our work with others, and so on.an illustrative example comes from an exploration of how new technologies could assist wildlife habitat development by the u.s. forest service. to support wildlife habitat protection, forest service teams neededan interface to varied databases (e.g., about soil, vegetation, water quality,forest wildlife) that would permit different experts literally to overlaytheir views of a geographic territory on a shared map, create and manipulate jointly devised scenarios, and observe the results. the design of suchan application required the participation of users with specialized domain expertise from its inception to its evaluation in field trials. niibased applications envisioned for ordinary use (see chapter 2) are no lesscomplex and are similarly likely to require participatory design with representative users; offering lifelong learning, continuing education, or tarmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.146more than screen deepgeted training, for instance, or delivering selected health services online,are cases in point.in these and other social applications, methods for design and evaluation that discover and fix problems before they are widely promulgatedare especially important. many workshop participants believe these needsare particularly acute in areasñsuch as education and health careñthatare now being eagerly promoted and anticipated for nii applications.one obvious approach is to conduct field trials with smaller than universal, but still representative, population samples; this procedure is as yetseldom followed. often, as workshop participants noted, expertsñbothsystem designers and such specialists as speech or occupational therapistsñmay play the role of representative users; sometimes a thinkaloudapproach is used in which users comment on their experiences as they usea system. a related question is simply how to design and evaluate withthe full range of the population in view, rather than drawing on educatedmiddleclass citizens who have constituted the potential or actual computer user samples typically studied in the past.expand the repertoire of research methods to be more inclusive andinnovativethere is a pressing need for socialpsychological, sociological, andorganizational research into how innovation, development, and implementation processes should be arranged and managed so that the goal ofeverycitizen utility is effectively pursued. issues like those raised aboveclearly require techniques for research with large populations, for instance, by survey methods or perhaps sampled observations; as yet thereis little experience in the use of these techniques for design and evaluationof large networked social applications. in discussing the prospects forinstrumenting various systems, an interesting opportunity broached byparticipants was to use the internet itself to conduct experiments andsurveys, to record usage data (in anonymized ways) stratified by usercategories and applications, and to assess the properties of emerging social networks (for examples, see eveland et al., 1994; huberman, 1996;eveland and bikson, 1987; dubrovsky et al., 1991; finholt et al., 1991; andkraut et al., 1996). practical issues may relate to protection of user privacy and to the nature of actual user populations (e.g., early adopters ofthe internet may not be representative). thus, consideration of how to getback good information is itself a research issue. trials and assessments ofthe suitability of these and other designandevaluation techniques forlarge and widely varying populations would be very worthwhile.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation147consider ways to minimize the separation of design and evaluationfrom implementation and useon the one hand, new computerbased technologies continue toemerge in the market at an incredibly rapid pace, and this trend will onlybe accelerated by populationwide access to the nii. on the other hand,recommendations to use methods for research with representative population samples to ensure the usefulness and usability of social applications before their implementation and use seemingly entail a much moreleisurely pace for innovation. this dilemma suggests that it might beworthwhile to reconceptualize as concurrent or overlapping processesthe traditional linear sequence from design, iterative trials, and redesignto implementation, use, and inevitable user òreinvention.óthis suggestion draws, in part, on the concurrent engineering model;in bringing together the designing and building stages of technology development, it reduced the total time involved while enabling designersand engineers to learn more from one another in the course ofcoproduction. it also builds on rapid prototyping approaches that drawno sharp boundaries between prototype trials with representative users,field pilot projects, and earlystage implementation processes (e.g.,seybold, 1994; mankin et al., 1996). finally, it takes into account theunfeasibility of ògetting it right the first timeó as a guiding principle fornii applications. as virtually every study of communicating social applications has shown, these technologies are invariably modified in use inways that respond to user contexts, changes in skills or task demands,and changes in the suite of applications with which they must be integrated. that is, the application should not be viewed as òfinishedó orstatic just because it has left the developerõs world (bikson, 1996).new backend technologies (e.g., clientserver architectures,middleware) make it possible to keep the infrastructure or platform inplace while delivering, updating, and supporting new tools and applications in user environments over a network. this is the principle behindnew efforts to conduct product betatests via the web, as noted earlier.given the desirability of involving greater numbers of representative users in application design and evaluation as well as field trials and implementation, and given the capability of networked systems to enable boththe provision of usable prototypes and the collection of user feedback, itwould be desirable to explore options for leaving applications intentionally underdesigned, to be adaptively developed as they are implementedin contexts of use (see box 4.2).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.148more than screen deepconsider the prospect of researchbased principles for designregardless of the perspective taken, the bottom line is that what weknow now about evaluation and design methods is not good enough tomeet the challenges presented by everycitizen applications in an niicontext.although there are good methods and techniques available for evaluating ideas and systems for individuals at all stages of development andproviding tests of usability and guidance for design, none of the workshop participants thought that evaluation methodology was a solvedproblem. although a few comparative studies have been made of someof the different methods in useñuser testing, heuristic evaluation, cognitive walkthroughs, scenario analysis, ordinary and video ethnographyñthese studies have not reached any unequivocal conclusions; indeed, thereis active controversy about their relative advantages. this is an area inbox 4.2toward informed participationtechnology that genuinely supports informed participation will be inherentlydemocratic and adaptable. it will allow us to take advantage of our social diversityand not force us to conform to the limits of our limited foresight.the philosophical model for understanding knowledge acquisition and the communication of information holds at least three primary lessons for anyone designingor deploying information systems for groups of people, as follows:1.focus more on relationships than things.information technology can andshould change relationships among people; that is where its chief value lies. information technology that changes the nature of relationships can change the fundamental features of a given complex system.2.honor òemergent behavior.óthe new theories of complex adaptive systemshold that the adaptability of any system greatly depends on the ògenetic varianceóñor pluralism of competing modelsñwithin it. therefore, information technologyshould allow the emergence of competing agents (or models or schema) and enhance their interrelationships.3.underdesign systems in order to let new truths emerge.it is a mistake to setforth some a priori notion of truth or to try to design in totality (which requires aninfinite intelligence in any case). rather, one should underdesign a system in orderto assist the emergence of new ideas.the brilliant logic of an underdesigned information system is well illustratedby the constitutional and cultural principles espoused by thomas jefferson, one ofthe preeminent information architects of all time.source: brown et al. (1994).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation149which more and more systematic research would almost certainly havegreat impact. some of the current evaluation methods are orders of magnitude more expensive in terms of time and money than others, oftenprohibiting their use and often inhibiting the use of any evaluation, yetwe do not know for sure whether they reliably produce better, or evendifferent, information or result in better or different products. such research should, of course, also be aimed at finding better methods. inparticular, research is needed on what kinds of evaluation give not justsummative quality estimates but also useful formative guidance that leadsto better design.these kinds of problems and uncertainties about evaluation techniques and methods lead naturally to reawakened interest in the prospectof researchbased principles for design. it has often been hoped by thescientists and technologists involved, and perhaps even more often bytheir managers, that the design of useful and usable interfaces could bebased on theory, engineering principles, and models rather than sheercutandtry and creativity. there have been some modest successes alongthis line. as mentioned earlier, there are models of the perceptualmotorprocesses involved in operating an interactive device that can predict thetimes required with useful accuracy. so far, these have had their greatestutility in the design of computerbased work tools where large numbersof people will do the same operations large numbers of times so that smallsavings in time will add up to large savings in money. in addition, thereare some models and means of analyzing and simulating the cognitiveoperations of users of complex computerbased systems that are oftencapable of yielding important insights for design or redesign (e.g., kierasand polson, 1985; kitajima and polson, 1996; olson and olson, 1995;carroll, 1990). and there are a dozen or so basic principles from experimental, perceptual, and cognitive psychology that can be put to work onoccasion by insightful experts. however, for everyday guidance aboutthe design of everyday interfaces and functions for every citizen, currentscience and engineering theory are of little help. one reason is that boththe human and the potential computerbased agents involved, and especially their combination, are extremely complex dynamic systems of thesort that are not often reducible to practical closedform models. theyappear to be more like the phenomenon of turbulence that plagues airframe design or the chaos that confronts weather prediction than they arelike the design of circuits; they are matters in which testand try is unavoidable. it is often mystifying to usability professionals that testing isresisted as strongly as it is and that calls for doing principlebased designare so frequent in this arena, when practitioners and managers concernedwith other complex dynamic systems (even electronic circuits and software) can easily see the need and strongly support empirical methods.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.150more than screen deepthis hope of avoiding testandfix methods is astonishingly persistent. for example, there is a myth in circulation that the macintosh interface, which for certain basic functions has demonstrated large usabilityadvantages over its predecessors, was accomplished without user testing.the truth could not be more different. at apple computer, the macintoshinterface was developed originally for the lisa computer, building, inturn, on the highly structured design and testing process for the xeroxstar system. during its development, it was subjected to an exemplaryapplication of formative evaluation and involving nearly daily user testing and redesign. moreover, the graphical user interface (gui) components of the macintosh interface can be and have been combined in waysthat do not produce superior results, while some oldstyle commandbased applications that have been iteratively designed are just as usableas the comparable macintoshstyle gui applications (see landauer, 1995,for a review and examples).while research on both the fundamental science of human abilitiesand performance and the engineering principles for better usability certainly could be highly worthwhile in the long run if adequately pressed,progress to date has been slow, and a principlebased approach probablycannot be counted on to underwrite the design of effective everycitizeninterfaces in the near term. on the other hand, many of the scientists whohave worked on these problems believe that attempting to understandthe issues involved in the interaction of people with computerbased intellectual tools and with one another through these tools offers an excellent laboratory for studying human cognition. the problems posed, andthe nature of the response of the world to what a human does, can becontrolled much better in this environment than, say, in a classroom, andyet are much more realistically complex than in the traditional psychological laboratory. moreover, the endresult test, making interactionsamong and between humans and computers go better, requires not justpiecemeal modeling but also complete understanding, an especially useful criterion in studying human cognition and communication that cantake so many new forms and functions. thus, more support (of whichthere is currently very little) of basic humancomputer interaction research, especially at the level of the cognitive and social processes involved, could be quite valuable as science.progressin concluding this discussion, the steering committee notes that sometechnologists, economists, and others have expressed the belief that problems of usefulness and usability are sufficiently solved by market competition and that, in particular, most earlier problems with user productivitymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation151have been overcome. there is indeed some anecdotal evidence that largesoftware producers are paying more attention to these matters, and withgood effect. for example, a report from microsoft (sullivan, 1996) describes iterative userinterface design efforts for windows 95 that followed prescriptions for interface development suggested by recent research (e.g., nielsen, 1993; landauer, 1995; sawyer et al., 1996). as priorresearch has found, user test results showed a gain of approximately 50percent in user task performance efficiency as a direct result of usabilityengineering activities.several lessons can be taken from this and recent, similar reports.first is the encouraging sign that assessmentdriven design is being applied to significant projects and that it is working. a more cautionarylesson, however, is the authorsõ report of how narrowly the microsoftproject escaped neglect of assessment on several occasions, and how important the consequences would have been. in moving the interface design from that of immensely popular windows 3.1 and 3.11, the teamreported, it had originally believed that, because the previous interfacewas so well evolved and so successful in the marketplace, only smallevolutionary changes based on known flaws, user complaints, and bugreports would be needed. however, early direct user tests and observations òsurprisedó the team into a realization that many critical problemscould be solved only by a complete redesign and that many opportunitiesexisted for significant innovative improvements that market response hadnot suggested. by the time the product was delivered, hundreds of flawsdeemed worth remedy had been found and several provably importantinnovations were incorporated. throughout the development, the teamcontinued to be surprised both by how poorly features and functionspreviously thought good actually performed and by how poorly newlyproposed fixes often turned out on actual test.the point here is that the prior interface from the same source, themost òadvancedó windows project, was still, in the mid1990s, very farfrom optimized and there was still room for dramatic improvement basedon explicit assessmentdriven usability engineering. the fact that computer hardware has become much faster and more capaciousñand software commensurably larger and more highly featuredñdoes not in theleast ensure that usefulness and usability of applications have improved;indeed, the effect is often the opposite. thus, it seems certain that therewill continue to be opportunities for major improvements in the design ofinterfaces for some time to come, especially in the many new and so farvery sparsely evaluated mass networkbased applications for social activities.meanwhile, another complementary question needs to be answered.windows 95 got the evaluation attention it needed, but no one knowsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.152more than screen deephow many other products are or are not profiting from formative evaluation. one bit of suggestive evidence comes from informal analysis of thesame publication in which the windows 95 results were reported, theproceedings of the 1996 acm conference on human factors in computingsystems, chi96. this is the major organ in which work on interface development and research is first published. among 67 articles in the 1996issue, of which over half describe newly developed or modified interfacedesigns, only one of every six articles reports any kind of serious usertesting or observation. this small proportion is not significantly differentfrom the numbers reported for relevant publications in the 1980s (nielsenand levy, 1993). thus, it appears that progress toward better interfacesstill has plenty of scope for greater application of this wellestablishedmethodology. also of interest, about onesixth of the papers at chi96were directed toward network interface applications, and another sixthwere about research on general interface components that might be usedin the futureñthe kind of science research toward principled design manyworkshop participants thought should be better encouraged.as mentioned above, it could be hypothesized that greatly increasedbeta testing made possible by world wide web dissemination of softwarehas reduced the need for explicit evaluation. there may be some truth inthis hypothesis in that many (but far from all) of the flaws and remediesdiscovered in usability engineering efforts come from trial user comments.on the other hand, as mentioned, world wide web beta testing is suspectas a usability design methodology because it gets information primarilyfrom relatively expert, relatively heavy earlyadopter users, those willingand able to try faulty versions (the average untested application interfacehas 40 flaws, according to nielsen and levy, 1993) of unproved things,people who are certainly unrepresentative of the target audience of thisreport. in addition, the web has produced an explosion of new softwarethat is often the result of extremely rushed, frequently amateurish, designefforts. indeed, some usability experts think that much current webbased software, and most home pages, have reintroduced longrecognized, serious design flaws (e.g., untyped hypertext links, missing escapeand backout capabilities, and lengthy processes and downloads aboutwhich users are not warned) and that web dissemination may have promulgated and institutionalized more avoidable problems than it has fixed.requiring the using public to weed through the technology because ofinvoluntary subjection to a welter of bad applications does not seem adesirable strategy for rapidly bringing every citizen happily online. research is needed to determine whether, in fact rather than impression,recent trends in software development, such as world wide web betatesting and increasing speed of development cycles, are making thingsbetter or worse.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.design and evaluation153notes1.according to cynthia crossen in the wall street journal (1996, pp. b1, b11) ònoteven computer industry executives can explain the illogic of the modern keyboard . . . adevice jerrybuilt from technology as old as 1867 and as new as this year. because there hasnever been an overarching plan or design, [it] defies common sense. its terminology isinscrutable (alt, ctrl, esc, home), and the simplest tasks require memorizing keystroke combinations that have no intuitive basis.ó2.todayõs elegant cellular phone interfaces emerged after a period of what someobservers deem excessive feature creep. see virzi et al. (1996).3.a reuters business information survey of 1,300 managers reported complaintsabout stress associated with an excess of information, fostered by information technology(king, 1996, p. 4).4.see, for example, munk (1996). she reports estimates that 27 percent ($3,510) ofthe $13,000 annual cost of a networked personal computer goes for providing technicalsupport to the user, and writes, òthereõs a parkinsonõs law in effect here: computer software grows to fill the expanded hardware. this is not to say that all the new software isnõtuseful; it often is. but not everybody needs it. for mundane uses, the older software may,paradoxically, be more efficientó (p. 280).5.in addition to instances of software for scientific and engineering applications,current popular examples, such as the world wide web and assorted approaches to electronic publishing, derived from efforts of technical users to design systems to meet theirown needs.6.gould et al. (1987b) notes that equivalent reading speed for screens and for paperdepends on highresolution antialiased fonts, an element of output display (see chapter 3).7.a meaningful approach to computer literacy, including essential concepts andskills, is the focus of an anticipated computer science and telecommunications boardproject.8.the telecommunications and information infrastructure access program (tiiap),run by the national telecommunications and information administration, funds diversepublicinterest (including government servicesrelated, educational, library, and other) information infrastructure projects that would form a natural platform for evaluation if funding were sufficient. see oõhara (1996, p. 6).9.for independent innovations, òearly adoptersó were regarded as having a competitive advantage over those still using older technologies; for interdependent innovations, early adopters do not achieve full benefits from the new technology until the lateadopters come on board (rogers, 1983).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.154more than screen deep154motivation: why collaboration andcommunication?two trends related to collaboration and communication are fosteringuseful new conceptions of humancomputer interfaces. first, evolvingtheories of interpersonal collaboration and communication are beginningto be applied to humanmachine interactions, demonstrating that thinking about humanmachine interactions as communication and dialogueñrather than, for example, a series of isolated commands and responsesñcan make systems easier to use. second, the increasing use of computersystems in support of communication and collaboration among groups ofpeople (whether for work, education, or entertainment) highlights theneed for understanding interfaces as links among many people and machines, not just one person and one machine. in both of these arenas,better understanding and development of richer theories of collaborationand communication will lead to improvements in the ways people use thenational information infrastructure (nii), whether to interact with the niiitself (e.g., to obtain information and services) or to interact via the niiwith other people in order to communicate, collaborate, and form communities.for an individual using a computer system, as candace sidner says inher paper in this volume, òinterfaces are ôcommunication enginesõ to thefunctionality of software applications; interfaces are how we get our workdone.ó yet the word òinterfacesó suggests a thin veneer (according to the5communication andcollaborationmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration155dictionary, òa surface forming a common boundaryó), too thin to providethe capabilities for communication and support that people should be getting from computer systems. most members of the humancomputer interface community take the òió to refer instead to òinteraction,ó but the abilityto collaborate (òwork withó) and not just interact (òact on one anotheró) isbecoming increasingly important as people use the nii not just to get individual tasks done, but also to communicate and work with others.as explained in chapter 2, the niiõs growth is extending civic life andcommunity to include geographically dispersed individuals. it is thusimportant to expand the conventional conceptualization of interfaces byrecognizing that they may involve more than one person and machineand that collaborative systems can either alleviate or exacerbate problemsin interactions among individuals with different abilities. as explainedby terry winograd in his position paper in this volume, the traditionalidea of òinterfaceó implies a focus on the person and the machine. indesigning interfaces it is important to focus as well on the òinterspaceóthat is inhabited by multiple people and machines in a complex web ofinteractions. the expanded view this interspace implies adds toñbutdoes not replaceñthe conventional requirements of interfaces for facilitating communication between person and machine.with anticipated enhancements in capabilities and reach, the nii mayalso foster new kinds of collaborations. recent work on òcollaboratoriesó(olson et al., 1992) and distance learning over the web and in multiuserdomains (muds; bobrow, 1996) as well as the extensive use that theastronomy and highenergy physics communities make of the web forlargescale scientific experiments involving widely dispersed people, instruments, and data provide examples of collaborations made possible bynetworked systems. graphical interfaces enabling easy access to hyperlinked webbased documents, for example, have made it much easier fordispersed researchers to share new results, articles, and references withintheir community than when they had to mail, fax, email, or personallydeliver articles to one another. the nii has the similar potential to provide new ways of conducting a range of activities important to everycitizen. in health care, for example, there is an increasing emphasis on theconstruction of large patient care systems that coordinate multiple providers from multiple disciplines and care sites. network informationsystems offer the opportunity for new kinds of communication and collaboration and the potential for integrating practices and providers acrosscommunities. with the proper support for collaboration and communication, electronic information systems could play a key role in meeting theassociated challenges of integrating health care practices, providers, andsettings from individuals and families across communities (and individuals with different sensory and cognitive abilities).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.156more than screen deepthe everincreasing modes of communication and media in which topresent information provided by current technology also complicate andenrich the interface challenge. going beyond a shallow view of interfacesto consider communication and collaboration becomes even more important when we consider combining video, voice, and graphics. computersystems have become more than machines used to perform isolated tasks.they are now widely used as machines for communicating different kindsof information using a range of media, and they provide possibilities forstructuring and interacting that were unavailable previously (traditionalprint, graphic, and broadcast media). decisions about what form to useto communicate different kinds of information and techniques for combining different media will require this larger view. there is a wide rangeof difficult technical problems in making such decisions (feiner andmckeown, 1991; roth et al., 1994; moore et al., 1995; marks, 1991).in the resulting complex web of interactions, peopleõs needs for systems to support collaborative activities and to act collaboratively willvary by individual, activity, and situation of use. thus, it is important toemphasize that this chapter argues not that collaboration is the only typeof interaction, but rather that it is an essential element of any system forcommunication (whether that communication is itself in service of cooperation or, alternatively, competition) and that it is important for the niito provide support for collaborative activities.thus, communication and collaboration affect the design of everycitizen interfaces (ecis) in two arenas: (1) personcomputer interactions(e.g., ecis may be designed to collaborate with a person) and (2) personperson interactions (e.g., ecis can provide new ways for people to communicate with one another and support collaboration among groups ofpeople). the former type of support is reflected in software (includinginterfaces) that applies our theoretical understanding of some aspects ofhuman communication and collaboration to improve peopleõs experiencesin working with computer applications. the latter involves software (including interfaces) that facilitates communication among people and collaboration among groups. however, it is important to recognize that formany uses of the nii people may utilize both these types of collaborativesupport (personcomputer and personperson) as several examples inloren terveenõs position paper (in this volume) illustrate. identifyingoptimal ways to integrate the two types of support in ecis is a majorresearch challenge.the roles of theories of collaboration and communication differ acrossthese arenas, but the value of a better understanding of what constitutescollaboration and what is needed for effective communication is essentialto both of them. for example, the need to have certain capabilities to beable to collaborate on a task or the requirement that particular kinds ofmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration157information be shared among participants in a collaborative activity affects the design of support tools for group collaborations (e.g., systemslike lotus notes) as well as the development of interfaces that enable aperson and application to work together more collaboratively than mostcurrent interfaces. this chapter investigates each of these arenas separately to understand the challenges and opportunities each presents. therecommendations encompass research that will contribute to both arenasas well as research focused on arenaspecific needs.the nature of collaboration: criticalfeatures and capabilitiescollaboration entails working together toward a common purpose,although the reasons for the collaboration and the ways in which it fitsinto some larger activity may vary among the participants (bratman, 1992;grosz and kraus, 1996; searle, 1990). for instance, some authors of amultiauthored report may contribute because the report offers a vehiclefor wide dissemination of their ideas, others because they believe thereport may help meet a societal need of great concern to them.workshop participants generally agreed on the importance of research aimed at answering fundamental questions about the nature ofcollaboration and its role in ecis, both for improving the ways in whichpeople and computers interactñthe personcomputer collaborationarenañand for supporting communication and collaboration amonggroups of people. however, different specific questions are highlightedby different research communities. research in artificial intelligence, andcomputer science more broadly, addresses questions of formalizing theinformation that must be exchanged (cohen and levesque, 1990; groszand kraus, 1996; kinny et al., 1994), developing negotiation strategies andprotocols for reaching agreement on how to divide work (rosenscheinand zlotkin, 1994; kraus and wilkenfeld, 1993) developing languages forcommunicating or negotiating such information (sidner, 1994a,b), andmeasuring the difference in theoretical power or system performancemade by adding collaborative capabilities (bender and slonim, 1994;jennings, 1995). analyses within the paradigms of sociology, organizational behavior, and anthropology examine the ways in which groupsfunction. this diversity makes clear the need for interdisciplinary effortsas we examine the introduction of collaborative capabilities into ecis.appropriately defining the capabilities that systems need and thefunctionality that can be expected from them as well as developing waysto design collaboration at different levels into systems are major researchchallenges. from recent research on the modeling of collaboration, it isclear that knowledge about what is being done (the collaborative activitymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.158more than screen deepand the goals to which it relates), how to do it, and the capabilities of theparticipants is essential (grosz and kraus, 1996). as a result, for a systemto be a collaborator, it needs to òknowó what the person using it is tryingto do. this knowledge may be implicit in the system design rather thanexplicit, but it cannot be absent. another feature of collaboration is theneed for participants to negotiate (sidner, 1994a,b; and others). negotiation about terms (òsemantic alignmentó; see below), about means, andabout allocation of responsibility are among the ways in which collaboration entails negotiation. collaboration also requires that participants shareboth commitment to the common task and knowledge of their sharedcommitment (see, e.g., bratman, 1992; searle, 1990; grosz and kraus, 1996;levesque et al., 1990; kinny et al., 1994). establishing the commitmentsand requisite common beliefs requires communication, but here too theextent to which this information must be explicitly represented by a system and thus the communication requirements may vary.in examining the possibilities for personcomputer collaboration,there was a divergence of opinion among workshop participants abouthow much collaborative power one should seek to incorporate into ecisin the near term and more generally how òsmartó they might be. likewise, there was debate about the level at which systems would need tonegotiate. for instance, candace sidner argued that all collaboratorsñhuman and machineñmust be òaware of what the task is,ó with commonknowledge about their shared undertaking. austin henderson arguedthat requiring more than minimal ability on the part of systems to understand what people using them are doing sets too high a barrier; he suggested seeking to develop systems that have some knowledge of whatthey are doing themselves, but not requiring that they understand what auserõs purposes are. as he stated, òmaybe it doesnõt understand whatyou are doing, but it surely understands what it is doing in its terms andcan talk about those.ó in his paper (available online at http://www2.nas.edu/cstbweb), gary olson provides some support for theview that machines cannot be expected to meet a human standard byobserving that groups of people develop unconscious routines that arehard to specify and therefore hard to represent in a computer system.although formal models of collaboration (e.g., grosz and kraus, 1996;flores et al., 1988; winograd, 1988) make reference to beliefs and intentions, computer systems do not necessarily have to reason explicitly aboutsuch mental constructs to behave collaboratively. ants and other insectshave builtin behaviors that lead to their working together (wilson, 1971).computer systems that are restricted to specific tasks could incorporateprinciples of collaboration into their design and work collaborativelywithout explicitly reasoning about belief or intention. for instance, interfaces can embed task and knowledge implicitly; in effect, automated tellermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration159machines (atms) do this. thus, the incorporation of collaborative capabilities does not necessarily entail a requirement that a system have complex reasoning capabilities.it is useful to consider computer systems falling on a spectrum fromvery function specific (e.g., atms, financial software applications such asquicken) to general purpose (e.g., personal computers, database systems).people using largescale information systems will employ systems at allpoints along this spectrum, and systems across the full spectrum shouldhave capabilities for collaborating. the problems presented by communication and collaboration in generalpurpose systems are long term; theyentail many of the difficult problems of representation and reasoning thatresearch in artificial intelligence has been addressing. however, the incorporation of capabilities for collaboration into systems for humancomputer communication does not have to wait. models of collaboration canbe used to constrain and affect the design of functionspecific systems(e.g., rich and sidner, 1996). embodying a set of assumptions into thedesign of an interface for a functionspecific system in the form of a familiar metaphor (e.g., the checkbookbalancing metaphor in quicken) provides another avenue for incorporating some level of collaboration into asystem. organizing an interface around a particular task domain andcognitive principles related to performing that task (e.g., glide1) is another.the functionspecific approach is not, however, an applicationspecific approach, and misidentifying these two may sacrifice the benefits ofconsistency in interfaces for different tasks. ecis must support peopleõsinteraction with multiple applications packages when using the nii. ascandace sidner notes in her paper in this volume, no single interfacemetaphor is powerful enough for all work, yet a multiplicity of smallerapplications, each with its own interface for performing one set of tasks,leaves people with lots of tasks to juggle and creates a need for an interface that communicates and collaborates in terms of the task rather thanthe application.it is also important not to confuse collaborative systems with helpsystems. systems that have collaborative capabilities should prove helpful, but òhelpó systems may operate without information that is crucial tocollaboration. for example, some current help systems not only offeradvice but also take action to help with oneõs task (e.g., apple guide,microsoft wizards). these systems exhibit properties of collaboration(e.g., doing things to assist in the userõs task without being asked). however, at the workshop, sidner argued that such systems do not measureup to what is required for collaboration because the missing consensusthat collaborators share is critical. for instance, systems with featuressuch as automatic spelling correction are helpful when they get thingsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.160more than screen deepright, but because they lack knowledge of the task, they can also causeserious problems. one of the lessons of microsoftõs commercially unsuccessful òbob,ó which proved not to be as helpful as expected, may be thedifficulty of attempting collaboration without adequate builtin models ofcollaboration.2collaboration also requires some shared knowledge about the activity or task being done. because current help systems often lack suchinformation, they are unable to address some critical problems that arisefor users. they do well to provide users with additional uncontextualizedinformation (e.g., microsoft wordõs òtip of the day,ó which acquaintsusers with an arbitrary piece of functionality), and they are able to helpusers find functionality in cases where users are able to identify theirinformation needs precisely. new generations of help systems are needed,ones that are able to analyze what users are doing and complement information access with information delivery by providing contextualized information that is relevant to the task at hand (fischer and nakakoji, 1991).the active help systems currently being explored in research settings (e.g.,fischer et al., 1985) provide examples of such systems.a major challenge for research on collaborative systems is finding theappropriate level of collaborative capability for a given application. determining the tradeoffs undoubtedly will require the kinds of iterateddesign processes described in chapter 4. a general solution is not likelyto be found; one personõs ideal level of query may not be anotherõs, andone individualõs preferences may vary among tasks. thus, peopleõs expectations and the qualities they attribute to systems must be taken intoaccount.an additional risk is that people may attribute greater capabilities tosystems that appear to collaborate than those systems that actually have.as olson observed at the workshop, òpeople really have a tendency toimpute animisms to complicated technical devices, so in the situation ofusing it, it sure feels like a collaboration even if we, as disembodied researchers, can say it isnõt.ó lee sproull noted at the workshop that theongoing relationship built up in collaborations among people is an important nontask component of their activity. if users impute collaborativeabilities to systems, various social aspects of collaborations need to beattended to (nass and reeves, 1996). the section òdeveloping trust insystemsó below examines several of these.3semantic alignmentthe ability to communicate clearly with people is a requirement forecis. clear communication requires a shared understanding of the meaning of terms; this understanding is known as semantic alignment (clark,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration1611996). ecis need to accommodate shifts in terminology, not only forpeople and systems, but also for the multiple systems that may need to becoordinated in a single interaction. at the workshop, austin hendersonobserved that in òall of these situations we have to address the question ofhow it is that collaborating entities negotiate meaning.ó4as explained by terry winograd in his paper in this volume,whenever two people talk, they have only an approximate understanding of each other. when they speak the same language, share intellectual assumptions, and have common backgrounds and training, the alignment may be quite close. as these diverge, there is an increasing need toput effort into constant calibration and readjusting of interpretations.ordinary language freezes meanings into words and phrases, whichthen can be òmisinterpretedó (or at least differently interpreted). thisproblem shows up at every level of computer systems, whenever information is being represented in a wellspecified syntax and vocabulary.. . . even simple databases have this problem. if information is beingshared between two company databases that have a table for òemployee,ó they are apparently in alignment. but if one was created for facilities planning and the other for tax accounting, they may not agree onthe status of parttime, offsite, onsite contract, or other such òemployees.óhenderson argued that collaborating entities òstart from undefined positions but a common context, and they produce enough alignment for thepurposes at hand.óif a computer system is one of the communicating parties, it mustparticipate in establishing the common ground (clark, 1996). many current systems work under the presumption that people will learn thesystemõs meaning, but this assumption is a source of misinterpretationand peopleõs difficulties in understanding how to use systems. as widercrosssections of society use the nii, such assumptions may become untenable.as terry winograd observes in his paper in this volume,ubiquitous networking is leading us to the point where every computersystem supports communication and where every term we use will beseen and hence interpreted by others. there are traditional philosophical and linguistic approaches to making sure we have òcommon understanding,ó but these tend to be based on highly abstract or idealizedexamples and settings. we need to develop new theoretical foundationsfor talking about the kinds of òsemantic approximationsó that are needmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.162more than screen deeped for something as apparently simple as sharing data between twodatabases and as ubiquitous as the nodes of the internet.at the workshop, craig knoblock argued that the problem is not onethat can be solved simply by imposing standards: òthere is going to haveto be some kind of distributed solution.... [systems] have to changetheir model and update things. so there has to be enough information inthe underlying structure that it is easy to make those changes. but there isno way that you can anticipate all those changes.ó moreover, once obtained, semantic alignment can be undermined over time; this is the wellknown problem of semantic drift.collaboration and communicationimproving an individualõs interaction: personcomputercollaboration and communicationthe interface is the òfaceó that meets a person (individual user) whois interacting with the nii. better systems for humancomputer communication are essential if we are to have easytouse, largescale information systemsñsystems that every citizen can use. if we compare currentcapabilities for humanmachine communication to the ways in whichpeople communicate with one another, it is apparent that current interfaces are severely limited. the example in chapter 4 of telephone menuconfusion problems is evidence of the gulf between personperson communication and personcomputer communication. even more telling isandries van damõs tablesetting analogy.5 bruce tognazziniõs equatingof mouse clicks with grunts sheds light on the relative illiteracy of currentinterfaces, suggesting that direct manipulation interfaces hearken back tothe days before language (other than grunting) was used for communication.6communication and collaboration are interdependent: communication requires collaboration (grosz and sidner, 1990; nass and reeves,1996; see also brown and duguid, 1992), and collaboration requires communication, though not necessarily linguistic communication, asterveenõs investigations of ways to organize collaboration around sharedmanipulation of work materials illustrate.in his position paper in this volume, terry winograd notes that peopleuse three primary modes of interacting with others and their environment: manipulation (e.g., grasping, modifying, controlling objects), locomotion, and conversation. each of these modes of acting must be coordinated with ways of perceiving: we manipulate objects within sight andgrasp, sense in various ways as we move among locations, and listen asmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration163well as talk when we converse. direct manipulation interfaces are rootedin the first of these modes, web travel (and many games) in the second.conversations among people have features that have not been captured in either of these classes of interfaces or in the more (human) languagelike commandline and query language interfaces. in her paper inthis volume, candace sidner argues, with reference to research in naturallanguage dialogue processing, that our conversations are themselves collaborative activities (lockbaum, 1994, 1995; stein and maier, 1995; nassand reeves, 1996; clark, 1996; clark and shaefer, 1987). she claims thatwhen we talk to one another, we collaborate not only about what we aredoingñwhether it is building a chair or trying to design a new interfaceñbut also to make the conversation itself happen. even when we are disagreeing or competing, for our dialogue to proceed we must collaborateat some level (e.g., that is why we speak to our interlocutors in languageswe all understand).the extended nature of conversationsñwhich are typically more thanone sentence, or a question and response, longñand the ways in whichthey use context are not evident in current interfaces (moore, 1995). it isworth noting that speech interfaces are likewise single interaction oriented and lacking in these features of conversation. a major deficiency inmost systems is the meager or nonexistent model of the ongoing interaction with a user. history lists and òundoó features are sometimes incorporated into interfaces, but they typically capture only a small part of theinteraction and encode none of its structure. such approaches ignorewhat is known about human discourse and its structure.7in her paper, candace sidner notes that òonly the user does any modeling or remembering of the interaction and its parts.ó capturing someaspects of the structure of a dialogue is required for an interface to track acommunication. òwhile an interface to a given application may havehundreds of socalled dialogue boxes, dialogue in the human sense doesnot take place.ó sidner argues that the inadequacy of current interfacesfrom the perspective of systems that provide a capability for dialoguewith users derives in part from their inadequate models of human communication. for instance, the dialogue is restricted to a single exchangein which the user must respond to a system query (e.g., s: òreplace?ó u:òyesó) or statement (e.g., s: òfile is too large for editor.ó u: òokó), theuserõs response is strictly delimited by the system choices, and often theuser cannot proceed without responding. in contrast, when people carryon a dialogue, it typically comprises multiple exchanges; no one personcontrols what another may say; and all parties are free to change the topic.context setting and tracking have been studied widely and modeled byresearchers in the natural language processing community, but extensions to other modalities and media are needed.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.164more than screen deepthe circuitfixitshoppe system (smith and hipp, 1994) and theminds system (young et al., 1989) are examples of prototype systemsthat integrate dialogue capabilities. specifically, they can have long sequences of interactions with a user and keep track of the roles of theindividual interactions and how they all fit together. they maintain goalstructures that show the required steps for realizing a central objectiveand build dialogue around those necessary steps. they function by selecting unachieved subgoals and carrying out interactions with the userto try to achieve them. coherence of the dialogue is maintained becauseof the natural relationship between the toplevel goals and their supporting subgoals. a dialogue involves the interactions between the participants as they sequentially address the various subgoals needed to eventually achieve or fail to achieve the toplevel goal. the nature of the dialoguemay be to jump around the proof tree from subgoal to subgoal in a seemingly random order in an attempt to find subgoals that can lead to highlevel success. the associated subdialogues resemble common humanhuman interactions that similarly jump around from topic to topic in aproblemsolving situation. these behaviors are in contrast to typical machine capabilities in which there may be little highlevel structure to guidethe dialogue and to guarantee a wellformed sequence of interactions.communication among people is not error free, misunderstandingfree, or perfectly efficient. this fact influences the ways in which modelsof human communication can be useful for interface design in at least twoways. first, designers will not want to incorporate all characteristics ofnatural discourse into their systems. second, as they expand the capabilities of systems to have more of the interaction and contextrelated characteristics of human dialogue, they will need to provide ways of dealingwith errors and misunderstandings. the increased power, naturalness,and flexibility that more truedialogue capabilities provide will undoubtedly engender situations in which a user or system misunderstand oneanother. they should also provide a richer base for error recovery techniques.because interfaces involve the whole experience of a person using asystem (as defined in chapter 1), they need to fulfill more than simplycarrying communications between person and machine. in austinhendersonõs view, interfaces have a fourfold role: (1) to help people dowhat they are doing, (2) to help people learn how to do what they aredoing (e.g., help systems and online training), (3) to assist people tomanage the resources that go into doing their tasks; and (4) to evolve asthe technology and the sociotechnical system in which they are using thistechnology changes. as he said at the workshop, òthat is the domain ofthe interface. to take it any smaller than that is to simply say you areleaving out most of the job the people have in using a machine.ómore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration165the communicationcollaboration view of interfaces is one that doesnot expect flawless, errorless execution or fixed sequences of actions.rather, it requires system designs to provide flexibility and means ofchanging courses of action when things do not go according to plan, aswell as options for recovering. people spend a good deal of the time theyare working with computer systems getting in and out of trouble(suchman, 1987). modeling of the task or intentional context (why theuser is communicating in addition to what he or she is saying) as well asof the structured dialogue history is especially critical to deal with situations in which things do not work out right the first time (sidner, 1983;litman and allen, 1990; lochbaum, 1994).another way of viewing the move toward ecis that communicateand collaborate with their users is to think of having an òinterfacelesssystem,ó a system that allows a person to be immersed in what he or sheis doing without being sidetracked by irrelevant communication details.weld (1995) describes the advantages of intelligent interfacesñones thatfree users from having to know details of where and how information isstored and describe some of the research needed to move beyond thecurrent state of affairs. as discussed in chapter 6, some activities ofintelligent agents involve collaboration and are relevant as enablers ofpersontomachine communication and collaboration.another concern in this arena relates to social stratification and variation. gary olson notes in his paper (available online at http://www2.nas.edu/cstbweb), that the dominant user interface metaphorsemerged from narrow segments of society: the commandbased interfacesof early personal computing came from the world of science and engineering; the popular desktop metaphor emerged from the world of theoffice and whitecollar workers; the hypertext metaphor used in worldwide web browsers came from the world of experimental documentstructures; popular interfaces like muds (multiuser domains) and moos(multiuser domains/objectoriented) emerged from computer games andvirtual worlds. a legacy of these plural roots is that designers have notyet figured out how to present the information infrastructure to the broadrange of potential users. even such putative examples of widespreadsuccess as automated teller machines turn out to have surprisingly narrow distributions of users (on the order of 10 to 15 percent of the public),while more widely used systems, such as video cassette recorders, are thebutt of jokes about the inability of average citizens to make full use ofthem.finally, ecis should do more than make it possible to do things onthe nii; they should make it possible to do things well. at the workshop,loren terveen noted that, although some interfaces make it easy to dothings, òthey donõt necessarily make it easy to do the things well. i canmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.166more than screen deepdesign html (hypertext markup language) pages easily, i can do allkinds of manipulation in photo shop, but i canõt necessarily build goodhtml pages or do attractive graphical images in photo shop. i needexpert assistance.ó he argues further that aiming to have systems thathelp people do things well is additional motivation for having collaborative systems.ecis in support of personperson communicationand group activitiesecis provide support for multiperson activities in two ways: (1) personperson communicationñthey support communication between individuals and among groups of people, for a range of activities only some ofwhich are collaborative; and (2) group collaborationñthey support thecollaborative activities of groups, whether formal or informal, that aredistributed geographically and with members active at different times ofthe day (i.e., support of cooperative and collaborative activities that maybe carried on asynchronously). these two areas are closely related, butneither subsumes the other. on the one hand, multiperson, multimachinecollaborations require communication but also a range of other interfacesupport (e.g., ways of keeping track of the people responsible for variousparts of the activity). on the other hand, people use the nii to communicate even when they are not working on a collaborative endeavor; as thesocial scientists at the workshop observed several times, networks facilitate social communication, and not all communicative uses of the nii arein the service of collaborations.ecis for communication among peopleone of the major uses of the internet is to enable communicationamong people (sproull and faraj, 1995; chung and iacono, 1996; donath,1996). we expect that people will similarly use the more enhanced integrated nii for communicating with one another in a variety of ways.although in some cases they will communicate to get information (herenarrowly construed), often the communication will be directed at otherpurposes.the impact of networked computerbased communications systemssupporting multiple modalities extends beyond those who have theirhands on a keyboard. for example, dourish et al. (1994) in an experimentat rank xerox europarc that involved direct video connections betweenoffices identified four different types of users: people in the wired offices,people who used other peopleõs video links to find someone, the institution that capitalized on membersõ communications activities, and the surmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration167rounding culture that took advantage of those connections to have remotemeetings.people also consult with one another about how to use technologyand about where to find information (constant et al., 1996). at the workshop, aki namioka, in discussing the seattle community network, notedthat being on the net can be a social activity not only with the communityonline but also with others in the same òroom.ó this same phenomenonappears to be occurring in cybercafes and rooms set up for people to playnetworked games together. these are very social activities, and the players appear to get a lot out of being colocated. thus, we should not thinkof technology as marking the end of facetoface meetings. it may evenlead to meetings that otherwise might not occur. people tackling similarproblems want to talk with each other. it is important to understand theways in which groups pass on information to one another whether theyare colocated in the same room or located apart from one other.this experience is part of a larger pattern, according to olson, whocommented at the workshop on people using technologies in social settings. the telephone is an example, including its history of human operators, and today people commonly get web urls (universal resource locators) or help advice from other people (kraut et al., 1996). he concludedthat òthe technologies . . . we are studying are themselves embedded ininteresting collaborative social situations that we need to take into account when we build these technologies.óloren terveen noted in his paper in this volume that such patterns ofbehavior have seeds for new technology tools. for example, systemsmight help mediate collaboration between people. they can provide forpeople to support one another by allowing for asynchronous and geographically remote sharing of information. one set of applications aimedin this direction is work on òsocial filteringó or òvirtual collaborationó(see reidel and miller, http://www.sims.berkeley.edu/resources/collab/for other references). research in these areas aims to use computationaltechniques to help people benefit from each otherõs experience withouttheir having to be aware of, or communicate directly with, each other atall. hill (http://community.bellcore.com/navigation/) draws the analogy to people establishing and using trails: when walking through theforest, people know where to walk because many people have walkedbefore them. they do not have to decide how to go anew nor do theyhave to decide about the people who preceded them to benefit from whatothers have already discovered.as lee sproull explained at the workshop, people attend to socialinformation as well as to task information within an interaction and tocommunity as well as memory across interactions. the result is a need forinterfaces to support people as social actors, not just information procesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.168more than screen deepsors. she cautioned that òa lot of times when people talk with one another, it is not for the purpose of getting information, and if we focus onlyon that subset of why it is that people communicate, we will have missedan extraordinarily large fraction of what it is that is important to peoplewhen they do communicate.ó sproull used the example of usenet groupsdevoted to topics of physical or mental disabilities or disorders, notingthat her research with sara kiesler showed them to be used as electronicsupport groups. òthey are places where one can go...to get information, but, . . . if what you really want is information, the usenet group isnot the place to get the highestquality information, or the most efficientway to get information.ó this is not to say that usenet groups and the likeare never the place to go for highquality, relevant information (suchinformation can be found, for example, at http://cancernet.nci.nih.gov/and http://wwwmed.stanford.edu/cbhp), but to acknowledge thatthey may not be originators of such information, that people may usethem for other reasons, and that establishing the quality of informationcan be difficult (see chapter 2).the use of the nii to facilitate communication among people forces usto consider the social aspects of communicationñthe ways in which communication supports communitiesñnot just the technological means ofgetting bits from one party to another. as lee sproull explained at theworkshop: òwhen people talk with one another, when people communicate with one another, they are not just exchanging information, they arenot just acquiring it, they are not just disseminating it; they are also engaged in social action, social behavior....[w]ithin an interaction, peopleattend to the messenger and the audience, as well as to the message. . ..[they] attend to social information, as well as to task information. acrossinteractions, people attend to community as well as to memory. so thesenew kinds of interfaces that we are thinking about need to be designedand constructed as interfaces for social actors, not just for informationprocessors.óecis for support of group activitiesthe nii needs to support more than individual taskrelated activityand information gathering in the service of such tasks. many tasks require coordinated group efforts, and people need to work with one another. in many corporate and governmental settings, group activity is thenorm. but work is just the beginning, as the social patterns that haveemerged on the internet show. groups of fans make extensive use of theinternet to discuss their favorite shows (e.g., òstar trek,ó òxfiles,ó etc.;clerc, 1994). as gary olson noted at the workshop, òthe kinds of thingsthat ordinary citizens like to do togetherñclubs, hobbies, interests of varimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration169ous kinds, civic groups, political action groups, and so on, practical problem solvingñ[the formal modeling and technology communities] knowalmost nothing about these kinds of collaborative activities, and i thinkthey have very different kinds of needs than the kinds of intellectual tasksthat [these communities] are more familiar with.óalthough a substantial body of work and techniques has been developed in the computersupported collaborative work (cscw) community,8as terry winograd notes in his position paper in this volume, òthe current state of the art can be described as having a large ôhole in the middle.õóat the theoretical level, there are general abstract theories of how peoplework together and the role of communication in the process. at thepractical level, there are large numbers of specialized applications (including such widely differing ones as retail pointofsale systems and thenational science foundation proposal application process) that supportorganized group activity. winograd adds,but we have not yet developed the conceptual and computational toolsto make it easy to bring collaboration into the mainstream of applications. when i work with my research group on a joint paper, we usesophisticated word processors, graphics programs, and the like, but ourcoordination is based on generic email and calendars, and often fails tohelp us at the places where breakdowns occur.furthermore, there is a need for much greater understanding of the waysin which technology can facilitate (or hinder) community formation, especially in nonwhitecollar work settings. the role of computer supportfor communication and a better understanding of privacy concerns (andthe feasibility of various technical solutions to meet them) are among thechallenges presented by this arena. the emerging use of computers tosupport communities of practice in educational settings (see charlesclearyõs paper in this volume) and networked learning communities provide rich sources on which to base some investigations in this area.as in the case of personcomputer communication and collaboration,in building systems to support group collaborations, a significant issue isthe degree to which explicit representations of the interaction are embodied in the software itself. email systems represent very little explicitly;pointofsale transaction systems have detailed representations of the interaction. as terry winograd observed following the workshop (privatecommunication by email), òsome of the most successful software hasbeen at each end of this spectrum (e.g., email and sales terminals). . ..there are few if any examples of systems in this middle area that havehad major commercial success. the benefits of the explicit structuring donot always accrue to those who do the workó (grudin, 1993). claims inmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.170more than screen deepthis arena too often run to the extremes: some claim that real work cannotbe formalized (suchman, 1987), others that the design of effective software requires an explicit analysis of work (keen, 1991; scherr, 1993; denning and dargan, 1996; medinamora et al., 1992; flores et al., 1988).workflow systems have been criticized, and there have been recent attempts to design more flexible workflow representations (glance et al.,1996; dourish et al., 1996).here, too, it is essential to look at intermediate positions, coming tounderstand both the limitations of formalization and the situations inwhich it can be effectively deployed to increase system usefulness.at the workshop, olson argued that it is critical to look beyond whitecollar work. òif you look at the proceedings of cscw, almost all thestudies of collaboration are about whitecollar work, professional work ofthe kind that we all do, and we know almost nothing about what kind ofcollaborative activities occur in much broader social communities.ósproullõs argument, cited in the previous section, that ecis must takethe social aspects of communication and collaboration into account isquite evident in this setting. often the kinds of social interactions thatmust be handled arise subtly. at the workshop, henderson gave anexample: òwhen xerox . . . began to put its copiers online, it was confronted with a problem that up until then was handled beautifully by thestandalone machines, which were surrounded by physical space, namely,if you walk up to a machine, you can tell whether it is in use, there issomebody standing there, or itõs making noise. when you begin to putthem online and introduce the potential for people to compete for thatresource, suddenly, the machine has willynilly created a problem foritself as to how you are going to manage that interaction.óthus, the design of systems to support collaborative work must address interpersonal as well as task aspects of the work. although someapplications are amenable to fixed a priori solutions, others will requirean ability for systems to negotiate with their users. as henderson addedat the workshop, òtrying to figure out ... a social model for interruptionin the use of a copier, say, or any other resource, is probably somethingwhich is a little bit beyond us just now.ó research on computer agentsthat negotiate with one another may offer one approach to this problem.9in other settings, ecis might provide support for personperson negotiation.the setting of many people working together using many machinestoward some common end raises social science research issues as well. inparticular, the interaction between technology and social effortñeffortdevoted to participating in a social interactionñneeds to be understood.determining whether technology increases or decreases social effort andwhy is extraordinarily important. a way to estimate or measure socialmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration171effort is necessary in order to build ecis that help people minimize ormanage social effort. for example, lee sproull argues that we know waysto measure the mental effort that is necessary to use any particular interface but that we need to develop ways to assess the social effort that isnecessary to use any interface for communication or collaboration. weneed to understand better the effort devoted to participating in the socialinteraction, attending to the messenger and the audience, as well as to themessage. storck and sproull (1995) discuss this point in the context ofvideo conferencing; kiesler et al. (1996) demonstrate it in the context ofhow people respond to interface agents.division of laborcomputers and people have different strengths and different skillcompetencies. one challenge in designing collaboration into a system isdetermining the appropriate division of responsibility.10 the negotiationof responsibility is one component of a complete collaboration. in somesettings we might want a system to negotiate with people, but for manyapplications, and certainly in the short term, there will be a need for thesystem designer to manage this division.two sets of issues are raised by the question of how to divide thework to be done between systems and people. first, there is the questionof whether to build into a system a fixed division of labor or to give thesystem a capability for negotiating the appropriate division with usersaccording to the task at hand. second, a critical aspect of agreeing to thedivision of responsibility is having trust in the collaborator to do its part;this raises a range of questions concerning trust in computer systems. inaddressing both these problems, there is the question of whether the extent to which systems working with people should emulate what peopleworking together do.determining which party will do whatsidner argues that in the longterm we should aim to understandcollaboration and negotiation sufficiently well that we can build systemsthat emulate people working collaboratively. henderson argues that òdivision is ... going to be probably a constantly changing matter and therefore needs to be one of the subject matters of the collaboration.ó thedetermination of who is in charge cannot be decided òupfrontó but mustbe worked out along the way. òyou need to be able to negotiate with themachine when it is doing what it is doing.ó this is one of the key areas inwhich eci designers will have to find a middle ground between giving asystem full responsibility and giving it none.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.172more than screen deepsome recent research on systems for interactive graphic design hasproduced very interesting exemplars of such a middle ground. theseòsemiautomatedó design systems do not attempt to have the system takeover the whole task of designing a presentation (as do various packagesthat restrict the user to a small number of static designs and some òintelligent interfacesó (e.g., roth et al., 1994)), nor do they require the user todirectly specify all the details (as do direct manipulation drawing packages). for example, in the glide system (ryall et al., 1996) for networkdiagrams, the person does global optimization, and the system does localoptimization. in the gold system (myers et al., 1994) for business graphics, the user sketches a chart using some of the data and the system completes the diagram for the whole data set. the various sage tools (rothet al., 1994) assist users in creating charts and graphs by providing templates and access to past designs in ways that make them easily modifiable to accommodate new data.a cautionary note was sounded by some at the workshop with respect to computer systems taking on greater roles. olson said,it seems to me that if you look at examples of technologies that haveactually been helpful or useful in human activities, there is a simplicitythat runs through them, and there is a real tendency in building technical systems to want to put lots of things in the system, that the systemcan somehow manage them better than the people can, and i think overand over again, we have gotten burned with that kind of design bias.one of the key features of the semiautomated systems describedabove is their attempt to allocate responsibility to person and machinedepending on the computational complexity or skill required. this approach presents a challenge to the designer in determining the division oflabor and once again leads to questions of designandtest iterative cycles.developing trust in systemsfor participants in a collaboration to agree on who will do what, theymust be able to trust one another. such trust requires in part being able torely on others to carry out a job and their commitment to doing so in thecurrent setting (grosz and kraus, 1996). at the workshop, olson arguedthat simplicity breeds trust and complexity breeds suspicion; this is evident by observation (e.g., people trust paper copies), but little is understood about how trust is established and maintained. hall (1996) presentsa formal approach to showing how a user can gradually come to trust hisor her agent more. hallõs sense of trust is basically that the agent will dowhat the user wants within specified resource constraints.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration173at the workshop, lee sproull related trust to relationships, as didstephen kent, who outlined what information security experts refer to asòthe web of trustóñsocial networks in which the parties trust each otherto interact. sproull explained that human collaborators not only solveproblems but also build and sustain relationships with one another aspart of establishing trust. her observations speak to the question of howmuch systems should be like people. for example, henderson wonderedwhether collaborating with a system requires a person to worry aboutmaintaining a relationship with it.at least four different facets of trust arise when considering collaboration and communication in ecis: trust of a system with information(e.g., privacy), trusting what the system reports about users (authentication), trusting content (credibility), and trusting the system to function(reliability). privacy concerns arise for individuals using systems but alsofor developers as they collect data in seeking to evaluate designs. thequestion of how we negotiate and manage credibility in an online environment is an open research question. we trust things we see in hardbackvolumes in the library more than we trust similar content on a mimeographed circular handed out by an individual. what are the corresponding mechanisms in computermediated information?11another aspect of trust relates to the handling of information shared,stored, transmitted, and processed in computerbased systems. in addition to determining the kinds of information that are needed to informsystems design, we also need to seriously consider the ways in which wehandle that data. because collaborations typically require significant information exchanges, incorporating collaborative capabilities into systemsmay also raise questions of data confidentiality and associated personalprivacy issues. this set of issues is receiving considerable attention inother niirelated contexts and is beyond the scope of this study, but theconnection of system trustworthiness vis ‹ vis information that is sensitive is relevant to the broader context of making systems more useful toevery citizen, as noted in chapter 2. thus, although security may seem tobe beyond the scope of eci design, it will impose some constraints thatmust be understood for the eci to be useful. as a result, eci designersmust take security concerns into account. information security or trustworthiness can affect the kinds of information presumed necessary for asystem to collaborate effectively, the way in which it is provided, theways in which it is used, the granting of access to it, the capacity (andassociated mechanisms) for providing anonymity or minimizing recordsof transactions, and so onñissues that can affect the design and use ofinterfaces and that should be assessed in the kinds of testing recommended throughout this report. at the workshop, for example, sproullremarked on autologging:more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.174more than screen deepwe now have the ability to do a lot of autologging of data about peoplewhen they use systems. we havenõt had much public discussion aboutwhen or the conditions under which those data should be collected andshould be made accessible, and i see this as, in some sense, a division oflabor between users and systems, but it is an issue that has to be framedwithin a larger political and social context, and we donõt usually think ofit that way.designer as collaboratorone way of achieving the partial level of collaboration hendersonargues for may be to explicitly design into a system ways of obtaining andworking with information important for collaboration (e.g., informationabout what the user is trying to do at a level beyond an individual actionor system call). such systems would have only a limited understandingof a userõs goals embedded in their design. they would not understand(in any of the usual senses of the word) what the person wants, but thesystem designer would have done so. this situation places a spotlight onthe skills and abilities of designersñwhat is the norm, what is the idealñand what they imply in the context of intrinsically nonordinary designspecialists designing systems for use by specific groups or whole populations (every citizen) of people.speaking as a successful designer, at the workshop bruce tognazzinicharacterized an ideal as follows:as a designer, i feel when i am designing that i am collaborating withmy eventual users. it is in the same way that i would collaborate overthe telephone with somebody and communicate with them. at the veryleast, i am communicating with them, and i would claim i am also collaborating with them. the machine is just the medium for what is essentially a timeshifted conversation between the designer and the enduser. now, since many applications are not designed by designers butare designed by engineers, who are weak in communication skills, a lotof software doesnõt look like it is very communicative, but my experience has been when you have a design team that collaborates on thedesign, and part of that collaboration is bringing in users to test it, andso forth, in this very kind of rich iterative environment, you end up witha very communicative and collaborative piece of software.some systems aim to gather information while a system is in use tofeed back to the designers. thus, they give substance to the notion thatthere is an ongoing collaboration between designers and users and provide technological support to make the collaboration more successful (seegirgensohn et al., 1994; also see hartson et al., 1996).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration175in the scenario tognazzini describes in his paper (this volume), systems designers identify and work with people who are representative ofthe target user community. they collaborate during the design stage sothat the resulting systems are able to collaborate with the people who usethem. at the workshop, henderson noted that òas long as you are playing by that tune, everything goes fine; you fit those capabilities into yourwork, but it is basically you and the designer. the machine isnõt changingmuch.ó from this we might conclude that if designers take into accountthe capabilities and properties needed for collaboration (e.g., establishinga common purpose, a way of achieving that purpose, ways of negotiatingover the various choices that arise), identify and consult with target users,and tests designs in realistic environments (see chapter 4 for discussionof relevant design methods), systems can be produced that collaboratewith their users. a systemõs actions and responses will be structured in away that aligns with what the user is trying to do. there are thus twocollaborations: the design team with a sample user population collaborates to yield a system design that will result in a system that is able tocollaborate with users. although this model may represent the best wayto proceed for communication between a single user and a system, research on how to extend òiterated designó to systems being used by multiple people and groups will be needed before it can be used for designingsystems to support communication or collaboration among groups ofpeople.the concept of designer as implicit collaborator evoked two sets ofconcerns among some workshop participants. the first is that of technologist hubris. lee sproull cautioned that when designers talk aboutuser models they mean usersõ models of the technology rather than models of users. the resulting inference is that what designers are doing isimagining model users, yet almost no one behaves like the model user thedesigner has in mind. as a result, it is important to broaden our understanding of what it is that users are actually about. austin henderson,coming to the defense of designers, maintained that many of the techniques of design are pushing designers to understand that the user doesnot behave as an idealized, troublefree user and that the model user is, infact, someone who is prone to all sorts of error. gary olson observed thathumancomputer interface efforts typically focus on individuals in construing model users, whereas there are model social systems and modelorganizational systems that mostly are invisible to designers.conclusions: research issues and challenges¥theories of collaboration should be developed that support thedevelopment of systems that collaborate with people and systems thatmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.176more than screen deepassist group collaborative activities. various research communities havebeen developing models and theories of collaboration (e.g., bratman, 1992;grosz and kraus, 1996; levesque et al., 1990; cohen and levesque, 1990;grosz and sidner, 1990; searle, 1990; olson and olson, 1995; flores et al.,1988), but there is much work to be done to extend them to cover therange of behaviors required for ecis, to use them in developing ecis, andto experiment with their use in nii settings.¥methods should be developed to integrate capabilities for personcomputer and personperson collaborations.¥research should investigate what is needed for people to come totrust computer systems. the information that needs to be communicatedby the system should be identified. ethical responsibilities that systemdesigners incur when producing systems that give assurances of trustworthiness to people should be examined.¥the ways in which technology facilitates community formation,the communication capabilities needed to do so, and the privacy concernsraised should be investigated.¥the social effects of different interface choices should be investigated, particularly the ways in which different presentation and communication choices affect peopleõs interactions with media.research issues for personcomputer collaboration¥to develop the conceptual and computational tools to make iteasy to bring collaboration into the mainstream of application requires abetter understanding of the tradeoffs between explicit representations(which may engender more complex computations) and collaborativepower (systems that only implicitly embody certain capabilities neededfor collaboration may be less general or less powerful). it should focus inpart on determining how to derive system design principles from generaltheoretical results on modeling of collaboration.¥research should investigate the extent to which humancomputercollaborations can be usefully made more like humanhuman collaborations. this research is necessarily interdisciplinary; for example, it isconceivable that a technical solution could be found that would proveundesirable for sociological reasons. it must consider both the systemsociological problem of human attribution to machines of capabilitiesgreater than they may have and the modeling problem presented bypeople being less than òidealó (perfect) collaborators.¥research should investigate the tradeoffs in presentational powerof the full range of modalities for interaction and media in which topresent information and the effects of context on choice. the use of sysmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration177tems to support multiperson activities in these different modalities andthe kinds of multiperson collaboration we want to support with ecisintroduce challenging questions both technological (e.g., coordination ofinformation presentation at different locations, delivery of video) andsociological (e.g., developing ways of measuring the effectiveness of ecisfor supporting different kinds of interaction).¥theories of negotiation should be developed that will enable systems to handle the division of labor more flexibly. principles should bedeveloped for guiding the design time choice of òwho will do wható inecis. methods should be developed for measuring/evaluating differentapproaches to the division of labor.research issues for computer support of personpersoncommunication and group collaborations¥the design of ecis to support communication among people andgroups should be investigated. the scientific base should be providedand the technologies developed so that interfaces can be designed andconstructed as social actors, not just information processors.¥ways should be provided to support community building andother social aspects of communication. supporting communication meansemail, chat, muds and moos, video links, and so forth for every person,not just for the computer literate (i.e., lots of kids and those of us whohave used machines at work) and technically sophisticated (computerscience types).¥ways in which systems can support collaborations among people,perhaps even participating in collaborations with groups, should be determined. in doing so, we must look beyond business and professionalwork to consider the kinds of collaboration that arise in civic groups,clubs, hobbies, and political action groups.¥an understanding should be developed of negotiation and collaboration sufficient for building into the technology the capability forpeople to build the social systems that will allow for handling the socialinteractions that arise (e.g., in a resource competition situation).¥understanding how different sensory abilities of participants affect multisensory collaborative system design, and understanding howthe design is affected by varying interface technologies, which may havedifferent multimedia capabilities (e.g., the implications of someone operating over a voiceonly connection in a collaborative interaction with others using other kinds of connection), should be developed.¥ways should be developed for ecis to support communicationand collaboration among multiple people, each with a personal and orgamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.178more than screen deepnizational background that shapes and guides their interactions with others; within these òinteraction spacesó ecis must support communicationstructures at all levels, from the generic document structuring of the webto highly taskspecific interactions.¥understanding of social effort in mediated collaborations shouldbe studied.¥technologies should be developed to support virtual collaborations.notes1.glide is a presentation package, like powerpoint, but optimized for and restricted to drawing network diagrams (ryall et al., 1996).2.òbobó is a software product that guides novice users, via animated charactersand settings, in starting up various home computing applications. customers found theinterface cute but lacking in the capability to help them with complex, difficult tasks. seearar (1996).3.there are, in fact, a range of social effects inherent in interfaces. recent research(nass and reeves, 1996) has demonstrated that interactive media generate fundamentalpsychosocial cues regardless of whether the media are explicity designed. the wording ofcommands and messages and the presentation of images, for example, can also affect aninterface in very subtle ways.4.although this problem resembles one that arises for distibuted databases in whichdifferent databases associate similar terms/data with different meanings, the challenge ismuch greater in the nii setting than for databases because the world in which the system isoperating is both open (in contrast to the òclosedworld assumptionó that database systemspresume) and very dynamic.5.i want jeeves (the p.g. wodehouse butler); i want somebody who has my context, knows how i operate, and can anticipate what i need, and then help execute it in acompletely unobtrusive kind of way, and yes, in that sense i do want to collaborate with mymachine. if my machine is sufficiently intelligent, then i will call it collaboration. todayõsmachines donõt permit me to do that . . . . [as an analogy] instead of being able to say, òsetthe table, we are having company for dinner,ó and have that translate automatically into awhole number of smaller specifications, i have to say, òpick up the dinner plate, put thefork on the lefthand side,ó and so on. everything i want to do in my application, i have todo explicitly.6.this is not to say that direct manipulation is never the right way to communicate.for instance, it works well for many games (e.g., checkers, chess) whether played on acomputer or in the physical world. however, not all extensions from the noncomputer tocomputerbased interactions are straightforward, as a comparison of recent research onsemiautomated drawing systems with commercial computer drawing packages makes clear.(see division of labor discussion of sage, glide, gold systems.)7.grosz and sidner (1990) have pointers to work in this area.8.see proceedings of computersupported cooperative work conferences, 19861996.9.examples of such work may be found in the proceedings of the internationalconferences on multiagent systems, the distributed ai sections of the proceedings ofamerican association for artifical intelligence (aaai) and international joint conferenceon artificial intelligence (ijcai) conferences, and in rosenschein and zlotkin (1994).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.communication and collaboration17910.here òresponsibilityó means òresponsibility for doing a jobó or òburden,ó and isnot used in the sense of moral or legal responsibility between people and systems.11.cryptography offers mechanisms for authentication and privacy. various operating systems techniques provide for reliability.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.180more than screen deep180some problems associated with the deliveryof function todaycurrent interfaces to the national information infrastructure (nii) require that the user form a detailed plan to accomplish the tasks he or shedesires. many in both industry and research argue that if ordinary citizens are to use the nii effectively, interfaces must be developed thatallow users to specify their needs at a higher level, in terms of their goals.as maes (1994) has written, òthe currently dominant interaction metaphor of direct manipulation . . . requires the user to initiate all tasksexplicitly and to monitor all events. this metaphor will have to change ifuntrained users are to make effective use of the computers and networksof tomorrow.ó the argument is that we must move away from interfacesthat require the user to òmicromanageó a systemõs actions and towardinterfaces that allow users to delegate actions to digital proxies (oftencalled software òagentsó or òsoftbotsó) that use information about usersõgoals and interests to act on their behalf. some of these proxies willsimply make the networked world more manageable by hiding technicaldetails, much like operating systems and highlevel programming languages hide details from users.an example of the kind of interaction that happens too often withcurrent technologies appears in box 6.1, which describes a prospectivestudentõs attempts to obtain information about scholarships. we can fol6agents and systems intelligencemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence181low the studentõs search on the current internet and obtain a good idea ofthe state of existing facilities. the student follows a number of reasonablepaths, conscientiously reads the entries, and makes selections. however,the search requires a troublesome number of difficult decisions, takesconsiderable time, and often results in frustration. the student mustenter multiple databases that may be formatted in different ways, mustinteract with each on its own terms, and may have to restate his or herspecial interests and constraints again and again in each new environment. eventually, the student will, in all likelihood, become frustratedand decide to ask a high school teacher or guidance counselor for help.searches of this kind and with this level of success are more the rule thanthe exception with presentday facilities. if a person wants to accessgovernment services, look for merchandise, or report a downed powerline, a multiplicity of choices, an inordinate amount of time, and a lack ofsatisfaction are common experiences.the main problems are as follows:box 6.1a student looks for scholarship information on the interneta reasonable place to start is with one of the wellknown indexes. our usermight look for the heading òeducationó and do a search on òscholarship information.ó this yields two items: òloan and scholarship programsó and òscience: mathematics: organizations: professional: american mathematical society.ó the latter isnot of interest to this student, but the former returns 291 sites where the student canseek further information. because this flood of information is overwhelming, a reasonable response is to go back to òeducationó and follow a link to òfinancial aid.óhere the categories are òcollege aid officesó (144), òcompaniesó (14), ògrantsó(35), òloan and scholarship programsó (34), and òregional resourcesó (10). severalof these look attractive, particularly òloan and scholarship programs and grants.óthe student does not know where he or she wants to go to college, so the 144individual offices do not seem to be a good place to look. the prospective studentfollows a link and finds a site advertising ò180,000 scholarships, grants, fellowships,and loans representing billions of dollars.ó wow, this is getting interesting! thestudent is asked to enter a major but does not want to commit to one. hitting ògoógives an error message. trying òundecided,ó ònone,ó and òscienceó leads to frustration. there is a button labeled òmore.ó here the student is asked to enter name,address, and more information. but he or she may not want to provide such information. following a previously discovered link, the user can find a list of special loanand scholarship programs, but they all turn out to be narrowly aimed at such groupsas beauty contest winners, specialists in cardiac electrophysiology, and so forth.following yet another idea, the student looks for militarybased scholarship programs, but the maze of paths is similarly extensive and unrewarding.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.182more than screen deep1.information overload for the user. the amounts of information available are astronomical, and any attempt to read the information can lead toan avalanche response. there is no mechanism that prunes the sourcesfor quality or for applicability to the userõs need.2.system, application, and task complexity. the functions available onthe network may require special command syntax and may have complexfacilities not easily accessed by the user. furthermore, the solution of anygiven user request could involve calls to many such systems.3.rigidity. the system may have only very specific ways of receiving input, finding solutions, and returning them to the user.how agents and system intelligence can helpa solution to the above problems is to have a software system between the user and the network that deals with the user in a convenientmanner and that interacts with the network and its many facilities in thelanguages that the network requires. this is analogous to the task of anoperating system that may receive a command to òprint file1ó (eithertyped or via a direct manipulation command) and that may issue anarray of commands to machine facilities to find file1, format it for printing, allocate space for its transfer, open communication to a printer, manage a file transfer to it, receive messages back from the printer as it does itsjob, and so forth. the user is only aware of the simple command and thefact that the desired file was printed. yet the complexities involved inservicing the request can be tremendous. in the current situation, however, the job of the intermediary may be considerably more complicated.the facilities on the network may have greater diversity, it may be necessary to decide how many resources can reasonably be invested in a task,there may be a need for commonsense reasoning to decide the relevanceof one facility or set of information versus another, and so forth.the tasks of the agent are (1) to interact with the user to determine thenature of the request, (2) to interact with the network to obtain the bestpossible solution, and (3) to present to the user the response that has beenobtained in the most useful form. figure 6.1 shows these functions in adiagram.following the flow arrows around the loop, the first step is interaction with the user. this could involve any of the media and/or modalitiesdescribed in previous chapters: speech, graphic inputs, typing, or others.it could also involve a full dialogue because the user may have a requestthat is complex. then the system must translate the results of this interaction to an internal form, which could be an extensive data structure. nextit executes a variety of computations to obtain a response. these mayresult in a series of additional interactions with the user. finally, themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence183internal form from the computation is translated into userappropriateterms. again, one or several of the media and/or modalities could beused, and this could involve more user interactions.the type of system that delivers these kinds of behaviors is called anagent. such a system has the properties that it can undertake goals onbehalf of its sponsor (presumably the user), and it can act autonomouslyand initiate actions according to its own agenda. such a system usuallyhas an ability to undertake responsibility over time, persistently seekingits assigned goals and accounting for significant historical events. it maybe designed to handle information searches, communication jobs, educational or recreational functions, commercial buying or selling tasks, orany other function that may be available on the network. it may guide theuser through complex information spacesñfor example, the way a travelagent guides a customer through the maze of possible itineraries or aresearch librarian guides a library user through the various referencesearch facilities. agents may monitor information sources and inform theuser of events that match the userõs interest profile or may actively searchfor new information to call to the userõs attention. agents may look foropportunities to assist the user or to teach the user new things. thedefinition of an òagentó is, in fact, a controversial issue. various sourcesemphasize its ability to perceive and act (russell and norvig, 1995), itsfigure 6.1the intelligent system mediates between the user and the network.multimediainputagent systemmultimediaoutputnationalinformationinfrastructurecodedqueriesandcommandstoniicodedresponsesfromniimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.184more than screen deeprole in doing a specialized task (minsky and riecken, 1994), its networkinteractive capabilities (genesereth and ketchpel, 1994), and its ability tocarry out an agenda (maes, 1994).the technologies used to deliver these functions may come from traditional computer science with standard programming languages andmethodologies or from more contemporary technologies, such as neuralnetworks or rulebased deduction.diagnosing the userõs needsthe first convenience a system can offer to a user is some flexibility inthe form of the input. the user may wish to make a request by speakinginto a telephone, by pointing to items on a displayed menu, by typing acommand, by some combination of all of these, or by some other method.it may also be true that the hardware device that is locally available willnot allow all media or modes of input. a very attractive feature of anintelligent system is that it may be able to function properly regardless ofthe input mode or device. whatever the means of input, the task of sucha system is to convert it into an internal form that can be used by themachine.it is common that a userõs input will be inadequate from some pointof view. perhaps the userõs syntax cannot be meaningfully parsed, orthere may be ambiguity in the request. the system may need to enter intoa clarifying dialogue. it must generate a proper internal message to bereturned to the user and then translate it into the appropriate media modalities for presentation. corresponding to the given input, there may bea particularly appropriate output: a menu clarification of some kind for amenu input, a spoken language output for a spoken input, and so forth.the clarification dialogue may continue for several iterations to addressvarious aspects of the request. some clarifications may come as the taskgoes forth and problems are encountered.the agent may have some information about the user. this is called auser model, and it may contain a history of the userõs typical requests, anyspecial input/output preferences of the user, and a list of informationgathered in the current interaction. the user model may be constructedexplicitly by asking the user questions or implicitly by monitoring keystrokes or selections made. all of this information can be used by thesystem in the interaction to reduce redundancy and to efficiently movetoward the goal. the system may be adaptive to improve efficiency. ifthe user often makes the same request, the interaction might be able tojump over the repetitive parts and move directly to the desired result. ifparticular interactions with the network prove to be unsatisfactory, thesystem may vary its behavior to avoid them.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence185servicing the userõs requestupon receiving the userõs request, the agent must then undertake avariety of actions such as those described at the beginning of this chapter.this requires an ability to search diverse databases at distant places andto assemble discovered information into a useful form. it could requireextensive calculations, calling other agents, and/or resorting to contacting other people and asking them for help. it could also involve makingsome kind of judgments concerning the reliability of the data being acquired. for example, are data provided by a generic source of scholarshipinformation as reliable as the data presented by the institution making theoffer? simultaneously, the system should be able to inform the user aboutthe nature of the search taking place. the user may want to know whatsources are being accessed and where successes and failures have occurred. the user should be informed on the extent of the resources beingaccessed and the time likely to be required. if the undertaking is not ofthe nature desired, the user must be able to modify it appropriately.presenting the user with a responsethe system response could be a list of 10,000 documents, a complexdiagram with extensive annotations, an audio signal, or some other collection of complex objects. its task on response is to present this in acomprehensible form. the system must undertake content selection anddecide which information will best satisfy the userõs needs. then it mustdo presentation design to structure and format the information in a comprehensible form. this includes media allocationñthe decision as towhich media will best display which information. finally, it must realizeindividual media, ensuring coherency across media (e.g., crossmodal referring expressions, temporal coordination) and a layout that is consistentwith the content and intent of the communication.current agentssome examplesmany types of agents have been developed and tested in recent years.an example is the entertainment ratings agent by maes (1994), whichrequires the user to rate a series of items on which he or she has anopinion. the system then compares that local userõs responses to manyother usersõ responses who have submitted their own ratings to similaragents and finds groups of users with profiles of likes and dislikes that aresimilar to those of the local user. having found such groups, it compilesa list of their average ratings for a variety of items the local user may notmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.186more than screen deephave seen and thus provides a group evaluation of items that should becorrelated with the local userõs own tastes. such an agent leverages thepower of the network to automatically and conveniently deliver to peopleadvice that is personally tuned and would not be easily obtainable anyother way, as discussed by loren terveen at the workshop.liebermanõs (1995) letizia is an agent that recommends web pages asa user is browsing the web. it operates in conjunction with a standardbrowser such as netscape, tracking the userõs behavior and using simpleheuristics to form a profile of the userõs interests (e.g., if the user saves abookmark to a document, that document is assumed to be of high interest;if a user follows a link and then returns immediately, that document isassumed to not be of interest). while the user is browsing, letizia tries tolocate other information that may be of interest to the user by performinga resourcebounded bestfirst search of web pages starting at the currentpage. at any time the user may request a list of recommendations and thesystem will display a page containing its current recommendations, whichthe user can then follow or ignore. this is another example of a currenttechnology agent in that its main mechanism depends on keyword frequency measurements to represent document content for information retrieval (salton, 1989).an example of what can be done with more detailed models of usertasks and more sophisticated processing is horvitzõs lumiere (http://www.research.microsoft.com/%7ehorvitz /lum.htm), which monitors auserõs actions and determines when the user may need assistance.lumiere continuously follows a userõs goals and tasks as the user workswith a suite of software tools (e.g., microsoft office), and performs a typeof task recognition; individually observed events are combined intohigherlevel modeled events, which are variables in a bayesian model. todevelop the models, studies were performed to determine how experts inspecific software applications came to understand problems that usersmight be having with software from the userõs behaviors and the evidential distinctions that experts used in their reasoning about the best way toassist a user. as a user works, lumiere generates a probability distribution over topic areas that the user may need assistance with, along with aprobability that the user would not mind being bothered with assistance.this research has led to the development of a product, the office assistant in office 97, which monitors user behaviors and assists the user basedon underlying models of each of the office 97 applications.another example of an agent that monitors a personõs daily behaviorsand then can offer help is the calendar apprentice (mitchell et al., 1994).this system enables a user to manage his or her calendar by hand andthen it builds rules that attempt to capture the userõs typical behaviors.maes (1994) has described agents that help a user classify and process emore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence187mail and classify news articles based on collections of keywords and nominal information related to author, publication source, and other items. ineach case the userõs behavior in carrying out daily activities becomes thetraining data for mechanisms that can later aid the user.etzioni and weld (1994) created the internet softbot, which receives auserõs request and then employs a goaloriented controller to seek a solution. it handles networkbased problems, such as sending a message toan individual whose address may not be immediately available. thesystem uses its goaloriented mechanisms to determine the tasks necessary to satisfy the request; this may involve accessing remote databasesand assembling the necessary information to achieve the goal. theinternet softbot provides a shell in which implementers can embed knowledge to handle a variety of network tasks automatically that can then beused by anyone.concerns about agentsthe term òagentó conjures in some criticsõ minds the picture of ahumanoid facade and possibly simulated humanlike responses. individuals with this image may object to agents on the grounds that such aninterface is condescending to the user and distracting to the goal of doingthe work. while there may be populations or situations where such aninterface is desirable, such anthropomorphic interfaces are certainly not apart of the concept of an agent as presented here. the choice of the facadeand the interaction style are a design decision and are independent of thedecision to build an agent. an agent may exist with menus, keyboardcommand line, voice, or other input modes and still carry out its function.in fact, one of the goals listed above is to provide the user with the choiceof a variety of input/output techniques, any of which will work.another concern of some observers is the loss of control implied byhaving a system that carries out its own òagenda.ó will a person òtrustóa software system (as discussed in chapter 5)? the apparent preferredmode for many users is the socalled direct manipulation paradigm thatpresents the user with a world of objects and methods to control them. ofcourse, there is a long tradition of automatically handling lowlevel details for users, as done, for example, by compilers and operating systems.having a system agenda and automatic processing at such levels is accepted practice, and what is new occurs when the machine offers to carryout tasks automatically that the user might ordinarily do. here the important thing is to keep the user in charge, either to accept the automaticactions of the system or to reject them and maintain complete stepbystep control.another worry relates to the robustness and reliability of a knowlmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.188more than screen deepedgebased reasoning or learning system that may be a part of an agent.a reasonable policy on this issue is simply that conservative decisionmaking should predominate if such a system is to be used. one can setobjective criteria for measuring performance and use experimental ortheoretical means to guarantee that standards are met.many of these concerns can be addressed by following the guidelinesfor agents presented by pattie maes at the 1997 international conferenceon intelligent user interfaces:¥make the user model available (inspectable, modifiable) to theuser.¥the agentõs method of operation should be understandable to theuser.¥the agent should be able to explain its behavior to the user.¥the agent should have the ability to give continuous feedback tothe user about its state, actions, and learning.¥the agent should allow variable degrees of autonomy, and theuser should decide how much and what type of tasks to delegate to theagent. the user should be able to òprogramó the agent (e.g., teach itthings, make it forget things).¥the user should not have to learn a new language to deal with theagent. a goal is to use the application to communicate between the agentand the user.suggested research: near and far termconservative versions of agents exist and are being used today, asdescribed above. the input mode can be restricted to current technology,menus, or a keyboardoriented commandline language. the computation undertaken for the user can be any traditional computation, mailhandling, browsing, information retrieval, and so forth. the output facilities can employ any current technology. an example is the agent mentioned above for providing a person with personally tuned ratings forentertainment events. such a system is well within the capabilities ofcurrent technologies and provides an example of a currently realizableagent. there are many kinds of research projects that begin at this level.for example, one can study human problem solving in the absence oftechnology and try to determine its characteristics and needs. or one canstudy the dynamics of human group behaviors. in each case the goal canbe to determine whether and how technology, specifically software agentsand networking, might be used to augment or improve what occurs naturally. as a part of this, it is necessary to develop measures of effectivenessmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence189in problem solving, for humans or humanmachine collaborations, so thatcomparative studies can be done.other important research projects could study or create new architectures for agents. for example, can architectures be found that provide thecapabilities called for by maes and described in the above section? another area of interest is the development of agent shells that can be created once and then specialized repeatedly to provide a variety of agentsthat users may need. a part of this research will be the development ofcommon languages for agents to communicate with each other, so thatthey can pass around requests and answers to requests without regard towhich particular agent is being accessed.more ambitious projects with substantially greater payoff, but withgreater risk and longer time periods, involve pushing the state of the artin many areas. an example is the problem of accessing and utilizingdiverse sources of information. data may exist on the net in a variety ofstandard database formatsñfree text, tables, or many other forms. datamay be multimodal, time varying, and quality graded. the need of thenetwork user is to input a request in a convenient language and thenreceive a response regardless of how varied the storage techniques maybe. research is needed into the modeling of knowledge sources and theiruse and the integration of knowledge from diverse sources. research isalso needed into methods for summarizing data (darpa, 1992, 1993,1995a) or enabling a person to peruse large amounts of data in an efficientmanner. clearly, enough progress can be made in these areas to achieveuseful results within a 10year time frame. but there are hard enoughproblems to keep researchers busy long beyond that.another area where progress will come slowly but surely is in theutilization of the input/output technologies described earlier in this report. for example, threedimensional imaging methodologies will beuseful for presenting the òshopping malló paradigm, where an agentmight enable a user to òflyó to a place of interest and make choices amongalternatives, as noted by thomas defanti at the workshop. progress inspeech recognition will make it usable, broadening the variety of inputtechniques available.the multimedia/multimodal input/output methodologies describedabove are possible now in primitive forms (maybury, 1993; feiner andmckeown, 1991; wahlster et al., 1993). but advances are required tomake progress in fundamental issues such as crossmodal integrated referring expressions, and temporal/spatial synchrony of dynamic mediarealization. the several decades of language research into formal andnatural language theory is needed again for multimedia/multimodalcommunication. this work is essential if the important goal of mediamode independence is to be approached for ordinary citizens.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.190more than screen deeprelated to these studies is the need for dialogue theory (grosz andsidner, 1986, 1990; lochbaum, 1994; moore, 1995), which relates individual input/output transactions to an interacterõs overall goal. it maintains a model of what has happened and what needs to happen to achieveultimate success and provides the fundamental mechanisms for successful collaboration. rich and sidner (1996, 1997a,b) have demonstrated thatthere is much to be gained from applying this theory to the design ofcollaborative agents. smith et al. (1995) have demonstrated a speechinteractive system that utilizes dialogue theory as developed by groszand sidner (1986) to process equipment repair dialogues.another area with a lessthan10year payoff but with more distantultimate goals is reasoning or inferential systems. users performing standard tasks such as the scholarship search mentioned above will be helpedby inferential capabilities that guide them down logically valid and wellworn paths rather than the plethora that knowledgefree search can find.expert systems successes of the 1980s provide examples of inference systems that have found use in the real world and similar techniques can beapplied immediately in ordinarycitizen applications. more ambitiousknowledgeintensive systems will ultimately be needed to provide citizens help on more difficult problems. a reasonable project would be tobuild a large database of commonsense knowledge for a particular domain that could be used by any system designed to work in that domain.an example of an important and broadly applicable knowledge source isthe wordnet system (miller et al., 1990). such systems are, in many cases,beyond the 10year time frame.a final area of great importance that also will extend beyond the 10year time frame is user models (kobsa and wahlster, 1989) and theirutilization. the goal is to enable a system to specialize its actions toaccount for what the user knows and needs. if a user is entering a systemfor the first time, he or she should possibly be treated differently from anexperienced user. if a user has unsuccessfully followed a given path,perhaps he or she should be encouraged in a new direction. if the usercan reasonably be expected to know something, he or she should not betold it again unless specific evidence arises indicating that it has beenforgotten. a longterm and very difficult problem is information presentation that accounts for a user model. thus, if one gives instructions onhow to go from point a to point b in a city, the instructions will be verydifferent in nature depending on whether the user is new to town or is alongtime resident. either individual may be irritated to receive instructions intended for the other.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.agents and systems intelligence191recommendationswith respect to agents and systems intelligence, the steering committee makes two recommendations on the basis of its discussions:recommendation 1. agents and intelligent systems technologiesshould be a priority for research. a major goal of computer science fromits beginning has been to build systems that enable people to interact inlanguages and with paradigms that are comfortable to them and to applythe best current technologies available to deal with the array of detailsrelated to the computation. the field of agent technologies is aimed ataccomplishing this for users of the nii.recommendation 2. a major emphasis should be on the development of technologies for translating between machine internal representations and any of a range of external media or combination of external media for both input and output. mode and media independenceare an important goal for the benefit of ordinary citizens, differently abledand otherwise. this recommendation addresses the technologies thatwill make such independence possible.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.192more than screen deep192assuming that private industry will take the lead in mainstream product development and shortterm research, the steering committee presents here recommendations for research that it believes federal researchagencies should encourage.1 federal initiatives that emphasize longtermgoals beyond the horizon of most commercial efforts and that may thusentail added risk have the potential to move the whole information technology enterprise into new modes of thinking and to stimulate discoveryof new technologies for the coming century. of course, work shouldcontinue in current areas that have demonstrated promise, but the emphasis here is on opening up new opportunities. five of the areas elaborated on under recommendations 2 and 3 in this chapter are designatedfor highestpriority attention because of their potential for contributing tothe development of effective everycitizen interfaces.recommendation 1: break away from 1960s technologies and paradigms. major attempts should be made to find new paradigms for humanmachine interaction that employ new modes and media for inputand output and that involve new conceptualizations of application interfaces.needed in the technical community is a period analogous to the 1960swhen a variety of paradigms were tried using emerging technologies ofthat time. the view then was of a single user interacting with a single7conclusions andrecommendationsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.conclusions and recommendations193terminal using a mouse, menus, and windows to open documents withina local application. the new view should take into account the tasks andtechnologies of the present and should enable a variety of interactionsbetween humans and machines for communication, information retrieval,and performance of tasks in any of a variety of environments. moreover,new approaches should enable users to immerse themselves in computermediated interactions and should include the option of involving manyhumans and machines in collaborative activities. new paradigms shouldemphasize the new role of information technology in society as a mediator among individuals, groups of individuals, and networked machines.the steering committeeõs first recommendation is a call not to replacevisual interfaces but rather to infuse them with new power and capabilitythrough documentcentric design, speech, gesture, agents, positionawareand pressuresensitive input devices, touch screens, and other emergingtechnologies and techniques. it also emphasizes bringing to fruitionequally important new interface strategies, such as speech and voice response, that will carry the power of computing to environments and populations not served today. todayõs interfaces often require too much of auserõs vision and motor control in situations, such as driving, that presentenvironmental distractions, or they assume physical or other abilities thatmany potential users may lack.coordinated research across several disciplines is necessary to develop new technologies and paradigms that address the psychological,organizational, and societal characteristics of every citizen. this interdisciplinary research should include the testing and evaluation of new interface technologies and paradigms in laboratory or field experiments orother empirical studies involving people who are representative of thecitizenry.the research agenda should acknowledge that the humanmachineinterface is more than screen deep and should consider every aspect of apersonõs experience in using computing and communications. peopleshould be able to concentrate on the tasks or purposes for which they areusing applications and should experience the interface as an aid ratherthan an obstacle to achieving success. people should experience a humanproblem domain interaction rather than a humanmachine interaction.several technological and design constraints should be considered indeveloping a research agenda:¥architectures are needed for interfaces that have wide spectrumand are easily learnable. such systems should have simple and semantically obvious commands so that novices can use them immediately. theyalso should have many levels of increasingly sophisticated capabilitiesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.194more than screen deepthat can be learned incrementally, so that people can move gracefully intomore advanced and efficient uses. such systems could be used in verysophisticated ways by experienced users.¥systems should support modality and medium independence.research should be fostered to enable anytime, anywhere, anyone interfaces that enable people to interact with systems using whatever modalities and media are available and convenient at a given time (consistentwith the functions being performed). such interfaces would support thegoals of (1) ubiquitous and nomadic access so that a user can communicate on the road, down the hall from the office, calling in via telephone,and so forth; (2) equipment and communications system independenceñuse of low versus high bandwidth, one medium (e.g., audio, video, text)versus another, and so on; and (3) user ability independence, with specialconcern for people with disabilities and for the changes in abilities thattypically accompany aging.¥humanmachine interfaces should support group (multipersonand multimachine) activities that are work oriented, social, or conductedfor other purposes; the groups could be formal, established, or short termand ad hoc. in particular, interfaces should support communities of practice in which many individuals can participate, each contributing incrementally. to build interfaces that provide such support requires furtherdevelopment of theories of dialogue, theories of group behavior, andtheories of joint planning and problem solving.¥interfaces to the national information infrastructure should treatthe two directions of communicationsñto and from individual citizensñmore evenhandedly. historically, with respect to elements of the niisuch as broadcast television, citizens have been passive consumers ofinformation. the evolving nii opens prospects for systems and interfacesthat provide more flexibility in who can send and receive information,from what locations, and in what manner, as well as more flexibility andease for people to move between communications and informationcentric activities.¥information resources should have more attractive means of entrythan those available so far. two possibilities that could merit furtherresearch include (1) the concept of hypertelevision that enables a viewerto pursue a presented object or event into cyberspace or (2) electronicencyclopedias with ubiquitous pointers into electronic libraries and othersources.¥methods are needed that enable citizens to achieve the securityand privacy they desire. securityrelated features can be inconvenient touse; better interfaces could lower the barriers that have deterred their usehistorically.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.conclusions and recommendations195recommendation 2: invest in the research required to provide thecomponent subsystems needed for everycitizen interfaces. research isneeded that is aimed at both making technological advances and gainingunderstanding of the human and organizational capabilities these advances would support.¥determine the needs of citizens: highest priority. apply availablesociological, psychological, and humancomputer interface methodologies to try to understand the problems and the needs basic to effectivehumanmachine interaction. undertake studies to find the kinds of functionality and interfaces that will be most important. such studies may beempirical or historical to determine what was successful in the past. forexample, the usefulness and success of existing public information accessprojects, such as the library of congress system, could be examined.proposed new technologies could be simulated and measurements madeof their levels of success in reallife situations. information so gatheredshould then guide decisions on what the most important technical areasare for research emphasis.¥input technologiesñexplore the promise of speech recognition and associated natural language processing: highest priority. do the work necessaryto open up speech as a viable input for as many new uses as possible. thesteering committee is impressed that the range of potential applicationsfor spoken input is tremendous, especially for handsbusy, eyesbusy situations; telephone applications; and differently abled persons. this need,coupled with the rate of progress in speech recognition, points to theimportance of continued emphasis on this line of research. an importantarea that needs more attention is the construction of prototype speechinteractive systems and their measurement and refinement in actual use.¥improve understanding of computer vision, gesture sensing, andmultimodal languages for user input. computer vision can be used to gatherdata a user may wish to transfer to the network and to keep the systemupdated regarding the userõs presence and responsiveness. gesture recognition could involve the development of gesture languages and gesturesupport of multimodal languages.¥measure the effectiveness of all of the above technologies whenused by humans in problemsolving situations.¥output technologies, including eyeglass displays; flexible, portable,and compact displays; highresolution displays; virtual reality; hapticdevices; mechanical actuators; voice and artificial sound; and multimodalgeneration of output. develop display technologies to match human vision. create audio output matched to the dynamic range of human hearing. measure the effectiveness of these technologies in a systematic program to evaluate their relative strengths for human users.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.196more than screen deep¥ensure modality and medium independence: highest priority. mediaindependence and modality independence are goals that, to this time,have not been extensively researched and, in the new context, shouldbeñfor nomadic systems, for lowcost systems, and for people with disabilities. develop mechanisms that enable translations between internalmachine representations of information and various human representations (e.g., visual, audio, haptic). research in this area will encourage theuse of a common machine representation that can be flexibly translatedinto or from any available modes or media. determine human multimedia and multimodal communications capabilities. enumerate and prioritize human capabilities to modulate energy (as described in chapter 3).¥agent technologies. an important option for delivering services tousers will involve agent technologies that interact with people to helpdetermine their needs and then select domainappropriate mechanisms torespond. the required technologies include traditional computer sciencemechanisms (such as those needed for database retrieval) and artificialintelligence capabilities (including representation of concepts and reasoning). an array of research topics needs to be addressed, including acquisition of user requests, user modeling, problem solving, and methodologies for summarizing and presenting internally stored data.¥network access devices. a large variety of devices are needed, including mobile terminals, inexpensive minimalist systems, and full multimedia systems with virtual reality capabilities. the steering committeeexpects that industry will perform most of this work.recommendation 3: encourage research on systemslevel design anddevelopment of humanmachine interfaces that support multiperson,multimachine groups as well as individuals.¥develop theories and architectures for collaboration: highest priority.develop theories of collaboration and problem solving. develop architectures for networked people and machines that enable mutual awareness,easy communication across space and time, and individual and joint contributions to common goals. provide ways to support community building and other social aspects of communication. theories of collaborationhave not been well developed historically, and the advent of networkingmakes this an important new priority for research.¥humancentered design methodologies. continue the study of human behavior in the use of technology for problem solving and the designof systems for improved productivity. investigate the social effects ofdifferent interface choices, particularly the ways in which different presentation and communications choices affect peopleõs interactions withmedia. to obtain feedback and to facilitate efforts at improvement, enmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.conclusions and recommendations197courage social science research into how well the public is being servedby such technology.¥test proposed new designs: highest priority. build experimental humanmachine systems, for individual users or groups, using proposedtechnologies or simulations of them. test, refine, and install them inapplications environments, and measure their effectiveness. industry,under the pressure of competition, has in recent years tended to minimizeuser testing in favor of quickly getting products to customers. marketplace success has become the de facto test for usability by humans. unfortunately, this approach does not lead to the kind of understanding thatenables reasoned design of useful devices. better understanding gainedfrom testing and evaluation is needed to achieve breakthroughs to newparadigms, and to address the needs of differently abled individualswhose market buying power may be inferior to that of majority groups.note1.in addition to supporting research, the government can encourage forwardlooking approaches to accessibility for every citizen to the national information infrastructureby requiring adequate development processes and evaluation in the procurement and useof systems for public service facilities under government control.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.198more than screen deep198anderson, david. 1996. òdiamond park and spline: a social virtual reality system with3d animation, spoken interaction, and runtime modifiability,ó technical report tr9602, mitsubishi electric research laboratory. also available online at http://atlantic.merl/com/reports/index.html.anderson, d.b., tora bikson, sally ann law, and bridger m. mitchell. 1995. òuniversalaccess to email: feasibility and societal implications, ò rand, santa monica, ca.anthes, gary h. 1993. ònew devices to propel technology into social fabric, report says,ócomputerworld, august 23, pp. 78.arar, yardena. 1996. òregistering disappointmentñmicrosoftõs bob celebrates lonely firstbirthday,ó computer retail week, no. 624, january.argyle, m., et al. 1976. gaze and mutual gaze, cambridge university press, cambridge,england.asiapacific telecommunications network. 1995. òconference on competition in asiaõstelecom markets,ó asiapacific telecommunications network, ibc technical services,ltd., singapore.austin, j.l. 1962. how to do things with words, harvard university press, cambridge, ma.badler, n., et al. 1993. òrealtime control of a virtual human using minimal sensors,ópresence, vol. 2, no. 1.bank, david. 1996. òmicrosoft moves to control the pc screen,ó wall street journal, december 5, p. b2.bates, joseph. 1994. òthe role of emotions in believable agents,ó communications of theacm, vol. 37, no. 7, pp. 122125.bear, john, john dowding, and elizabeth shriberg. 1992. òintegrating multiple knowledgesources for detection and correction of repairs in humancomputer dialog,ó proceedings of the 30th annual meeting of the association for computational linguistics, newark, de, acl, somerset, nj.bender, michael a., and donna k. slonim. 1994. òthe power of team exploration: tworobots can learn unlabeled directed graphs,ó proceedings of the 35th annual sympobibliographymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography199sium on foundations of computer science, ieee computer society press, los alamitos,ca, pp. 7585.benford, s., et al. 1995. òuser embodiment in collaborative virtual environments,ó proceedings of sigchi õ95, acm, new york, pp. 242249.bertino, e., and l. martino. 1993. objectoriented database systems: concepts and architectures, addisonwesley, reading, ma.bikson, t.k. 1996. ògroupware at the world bank,ó in groupware and teamwork, c. ciborra,ed., john wiley & sons, chichester, england, pp. 145183.bikson, t.k., and j.d. eveland. 1990. òthe interplay of work group structures and computer support,ó intellectual teamwork, r. kraut, j. galegher, and c. egido, eds., erlbaumand associates, hillsdale, new jersey, pp. 245290. also available from rand as n3429mf.blanchard, c., and s. burgess. 1990. òreality built for two,ó symposium on interactive 3dgraphics, acm siggraph, dallas, acm, new york.boden, margaret a. 1994. òagents and creativity,ó communications of the acm, vol. 37,no. 7, pp. 17121.boff, kenneth r., and janet e. lincoln. 1988. engineering data compendium, volume i, h.g.armstrong aerospace medical research laboratory, wrightpatterson air force base,oh.bratman, michael. 1992. òshared cooperative activity,ó philosophical review, vol. 101, pp.327341.bretier, p., and m.d. sadek. 1996. òa rational agent as the kernel of a cooperative spokendialogue system: implementing a logical theory of interaction,ó ecai96 workshopon agent theories, architectures and language, budapest, hungary.bretier, p., m.d. sadek, v. cadoret, a. cozannet, p. dupont, a. ferrieux, and f. panaget.1995. òa cooperative spoken dialogue system based on a rational agent model: afirst implementation on the ags application,ó proceedings of the esca/etr workshopon spoken dialogue systems, hanstholm, denmark.bricken, w., and g. coco. 1993. òthe veos project,ó technical report, human interfacetechnology laboratory, university of washington, seattle.brill, eric. 1993. òautomatic grammar induction and parsing free text: a transformationbased approach,ó proceedings of the 31st annual meeting of the association for computational linguistics, columbus, oh, acl, somerset, nj.brown, john seely, and paul duguid. 1992. òenacting design for the workplace,ó usability:turning technologies into tools, paul adler and terry winograd, eds., oxford university press, u.k., pp. 164198.brown, john s., paul duguid, and susan haviland. 1994. òtoward informed participation:six scenarios in search of democracy in the information age,ó aspen institute quarterly, vol. 6, no. 4, pp. 4973.bullen, c., and j. bennet. 1990. òlearning from user experiences with groupware,ó proceedings of the conference on computer supported cooperative work, acm, new york, pp.291302.burdea, g. 1996. force and touch feedback for virtual reality, john wiley & sons, new york.burrows, peter. 1996. òthe day of the designer,ó business week, june 24, pp. 114.buttolo, p., d. kung, and b. hannaford. 1995. òmanipulation in real, virtual, and remoteenvironments,ó proceedings of the ieee international conference on systems, man, andcybernetics, vancouver, bc, october, ieee computer society press, los alamitos, ca.cabinet minister for public service (united kingdom). òa prospectus for the electronicdelivery of government services,ó u.k. green paper. available online at http://www.open.gov.uk/citu/cituhome.htm.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.200more than screen deepcarbonell, j. 1992. òmachine learning: a maturing field,ó machine learning, vol. 9, no. 1,pp. 57.card, stuart k., thomas p. moran, and allen newell. 1983. the psychology of humancomputer interaction, lawrence erlbaum associates, hillsdale, nj.carlsson, c., and o. hagsand. 1993. òdive: a multiuser virtual reality system,ó proceedings of the ieee virtual reality annual international symposium, ieee computer societypress, los alamitos, ca.carlton, jim. 1995. òacer is launching personal computers designed to fit in as fixture inhomes,ó wall street journal, september 5, p. b2.carroll, j.m. 1990. òthe growth of cognitive modeling in humancomputer interactionsince goms,ó human computer interaction, vol. 5, pp. 221265.chung, woo young, and suzanne iacono. 1996. òwhy do people use online services?,óworking paper, boston university, boston, ma.ciborra, c. 1992. òfrom thinking to tinkering: the grassroots of strategic informationsystems,ó the information society, vol. 8, no. 4, pp. 297310.ciborra, c., and g. patriotta. 1996. ògroupware and teamwork in new product development: the case of consumer goods multinational,ó groupware and teamwork, johnwiley & sons, london, pp. 121144.cindio, f.d., and g.d. michelis. 1986. òchaos as a coordinating technology,ó proceedingsof the conference on computer supported cooperative work, acm press, new york.clark, don, and kyle pope. 1995. òpoll finds americans like using pcs but may findthem to be stressful,ó wall street journal, april 10.clark, don, and evan ramstad. 1997. òzenith, thomson move to bring internet to tvs,ówall street journal, january 8, p. a6.clark, herbert h. 1996. using language, cambridge university press, cambridge, england,and new york.clark, h.h., and e.f. shaefer. 1987. òcollaborating on contributions to conversations,ólanguage and cognitive processes, vol. 11, pp. 123.clerc, s. 1994. òestrogen brigades and ôbit titsõ threads: media fandom online and off,ówired women: gender and new realities in cyberspace, l. cherny and e.r. weise, eds.,seal press feminist, seattle, wa.codella, c., et al. 1993. òa toolkit for developing multiuser, distributed virtual environments,ó proceedings of the ieee virtual reality annual international symposium, ieeecomputer society press, los alamitos, ca, pp. 401407.cohen, p., and h. levesque. 1990. òintention is choice with commitment,ó artificialintelligence, vol. 42, pp. 263310.cohen, philip r., and sharon l. oviatt. 1994. the role of voice input for humanmachinecommunication, department of computer science and engineering, oregon graduateinstitute of science and technology, beaverton, or.cole, r.a., and l. hirschman. 1995. òthe challenge of spoken language systems: research directions for the nineties,ó ieee transactions in speech and audio processing,vol. 3, pp. 121.cole, r.a., et al., eds. 1996. survey of the state of the art in human language technology,cambridge university press, stanford university, stanford, ca. available online athttp://cse.ogi.edu/cslu/hltsurvey/.cole, ron, and lynette hirschman. 1992. the challenge of spoken language systems: researchdirections for the nineties, national science foundation, arlington, va, february.collins, michael john. 1996. òa new statistical parser based on bigram lexical dependencies,ó proceedings of the 34th annual meeting of the association for computational linguistics, santa cruz, ca, acl, somerset, nj.computer science and telecommunications board (cstb), national research council.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography2011994a. realizing the information future: the internet and beyond, national academypress, washington, dc.computer science and telecommunications board (cstb), national research council.1994b. information technology in the service society, national academy press, washington, dc.computer science and telecommunications board (cstb), national research council. 1995.evolving the high performance computing and communications initiative to support thenationõs information infrastructure, national academy press, washington, dc.computer science and telecommunications board (cstb), national research council. 1996.the unpredictable certainty: information infrastructure through 2000, national academypress, washington, dc.conklin, jeff. 1987. òhypertext: an introduction and survey,ó computer, september, pp.1741.constant, david, sara kiesler, and lee sproull. 1996. òthe kindness of strangers: on theusefulness of weak ties for technical advice,ó organization science, vol. 7, pp. 119135.cortese, amy. 1996. òsoftwareõs holy grail,ó business week, june 24, pp. 8392.crossen, cynthia. 1996. òprint scrn, num lock and other mysteries of the keyboard,ó wallstreet journal, october 22, pp. b1 and b11.crossindustry working team. 1995. ònomadicity in the nii,ó corporation for nationalresearch initiatives, 1895 preston white drive, suite 100, reston, va 220915434.deerwester, s., s.t. dumais, g.w. furnas, t.k. landauer, and r. harshman. 1990. òindexing by latent semantic analysis,ó journal of the american society for information science,vol. 41, no. 6, pp. 391407.defanti, t. 1996. òrealtime visualization and virtual reality as a future everycitizeninterface for the national information infrastructure,ó toward an everycitizen interface for the national information infrastructure workshop, washington, dc, august.available online at http://www.nap.edu.defense advanced research projects agency (darpa). 1992. proceedings of the fourthmessage understanding conference (muc4), june, san mateo, morgankaufmann, losaltos, ca.defense advanced research projects agency (darpa). 1993. proceedings of the fifth message understanding conference (muc5), august, san mateo, morgankaufmann, losaltos, ca.defense advanced research project agency (darpa). 1995a. proceedings of the sixth message understanding conference (muc6), november, columbia, md, morgankaufmann,san francisco.defense advanced research project agency (darpa). 1995b. proceedings of the spokenlanguage systems technology workshop, january, austin, tx, morgankaufmann, sanfrancisco.denning, peter, and pamela dargan. 1996. òactioncentered design,ó bringing design tosoftware, terry winograd, ed., addisonwesley, reading, ma, pp. 105120.dewitt, d., et al. 1994. òclient/server paradise,ó proceedings of the 20th international conference on very large data bases, santiago, chile, morgankaufmann, san francisco.donath, judith. 1996. òinhabiting the virtual city: the design of social environments forelectronic communities,ó unpublished doctoral dissertation, massachussetts instituteof technology, cambridge, ma.dourish, p., a. adler, v. bellotti, and a. henderson. 1994. òyour place or mine? learningfrom longterm use of video communication,ó technical report, rank xeroxeuroparc, number epc94105.dourish, p., j. holmes, a. maclean, p. marqvardsen, and a. zbyslaw. 1996. òfreeflow:more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.202more than screen deepmediating between representation and action in workflow systems,ó proceedings ofthe conference on computer supported cooperative work, boston, ma, nov. 1620, acmpress, new york, pp. 190198.dubrovsky, v.j., s. kiesler, and b.n. sethna. 1991. òthe equalization phenomenon: statuseffects in computermediated and facetoface decision making groups,ó humancomputer interaction, vol. 6, pp. 119146.dumais, s., and d. schmitt. 1991. òiterative searching of an online database,ó proceedingsof the human factors society, human factors society, santa monica, ca, pp. 396402.edmonds, ernest a. 1994. òsupport for collaborative design: agents and emergence,ócommunications of the acm, vol. 37, no. 7, july, pp. 4147.egan, dennis e. 1988. òindividual differences in humancomputer interaction,ó handbookof humancomputer interaction, martin e. helander, ed., elsevier science, new york.elstrom, peter. 1996. òôoperator, get me cyberspace,õó business week, june 24, pp. 103110.etzioni, oren, and daniel weld. 1994. òa softbotbased interface to the internet,ó communications of the acm, vol. 37, no. 7, pp. 7276.etzioni, oren, and daniel s. weld. 1995. intelligent agents on the internet: fact, fiction, andforecast, department of computer science and engineering, university of washington,seattle, may30.eveland, j.d., and t.k. bikson. 1987. òevolving electronic communication networks: anempirical assessment,ó office: technology and people, vol. 3, pp. 103128.eveland, j.d., a. blanchard, w. brown, and j. mattocks. 1994. òthe role of ôhelp networksõin facilitating use of cscw tools,ó proceedings of the conference on computer supportedcooperative work, acm, new york, pp. 265274.feiner, s.k., and k.r. mckeown. 1991. òautomating the generation of coordinated multimedia explanations,ó ieee computer, vol. 24, no. 10, pp. 3141.finholt, t., l. sproull, and s. kiesler. 1991. òcommunication and performance in ad hoctalk groups,ó human computer interaction, vol. 6, pp. 291325.fischer, g. 1991. òsupporting learning on demand with design environments,ó proceedings of the international conference on the learning sciences in 1991 (evanston, il), l.birnbaum, ed., association for the advancement of computing in education,charlottesville, va, pp. 165172.fischer, g. 1994a. òdomainoriented design environments,ó automated software engineering, vol. 1, no. 2, pp. 177203.fischer, g. 1994b. òturning breakdowns into opportunities for creativity, knowledgebased systems,ó special issue, creativity and cognition, vol. 7, no. 4, pp. 221232.fischer, g., and k. nakakoji. 1991. òmaking design objects relevant to the task at hand,óproceedings of aaai91, ninth national conference on artificial intelligence, aaaipress/mit press, cambridge, ma, pp. 6773.fischer, g., a.c. lemke, and t. schwab. 1985. òknowledgebased help systems,ó proceedings of the conference on human factors in computing systems, san francisco,  acm, newyork, pp. 161167.fischer, g., et al. 1991. òthe role of critiquing in cooperative problem solving,ó acmtransactions on information systems, vol. 9, no. 2, pp. 123151.fish, r.s., et al. 1990. òthe video window system in informal communication,ó proceedings of the conference on computer supported cooperative work, acm press, new york,pp. 111.flohr, udo. 1996. ò3d for everyone,ó byte, october. available online at http://www.byte.com/art/9610/sec6/art1.htm.flores, fernando, m. graves, brad hartfield, and terry winograd. 1988. òcomputer systems and the design of organizational interactions,ó acm transactions on office information systems, vol. 6, no. 2, pp. 153172.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography203ford, m., j. bresnan, and r. kaplan. 1982. òa competencebased theory of syntacticclosure,ó the mental representation of grammatical relations, j. bresnan, ed., mit press,cambridge, ma.frazier, l., and j.d. fodor. 1978. òthe sausage machine: a new two stage parsingmodel,ó cognition, vol. 6.freitag, l., et al. 1995. òremote engineering using cavetocave communications,ó virtual environments and distributed computing at supercomputingõ95: gii testbed and hpcchallenge applications on the iway. available online at http://www.mcs.anl.gov/futureslab /cave/apps/super95/boiler/boiler.html.funkhouser, t.a. 1996. ònetwork topologies for scalable multiuser virtual environments,ó proceedings of the ieee virtual reality annual international symposium, ieeecomputer society press, los alamitos, ca, pp. 222228.gaver, w., et al. 1993. òone is not enough: multiple views in a media space,ó proceedingsof interchiõ93, acm, new york.genesereth, michael r., and steven p. ketchpel. 1994. òsoftware agents,ó communicationsof the acm, vol. 37, no. 7, pp. 4853.georgia tech graphics. 1995a. visualization & usability (gvu) center, 3rd survey (gvu3),april.georgia tech graphics. 1995b. visualization & usability (gvu) center, 4th survey (gvu4),october.georgia tech graphics. 1996a. visualization & usability (gvu) center, 5th survey (gvu5),april.georgia tech graphics. 1996b. visualization & usability (gvu) center, 6th survey (gvu6),october.gibbons, boyd. 1986. òthe intimate sense of smell,ó national geographic, vol. 170, no. 3,pp. 324361.girgensohn, a., d.f. redmiles, and f.m. shipman. 1994. òagentbased support for communication between developers and users in software design,ó kbseõ94, september,ieee computer society press, los alamitos, ca, pp. 2229.glance, n.s., d.s. pagani, and r. pareschi. 1996. ògeneralized process structure grammarsfor flexible representations of work,ó proceedings of the conference on computer supported cooperative work, acm, new york, pp. 180189.gomes, lee. 1997. òimmersionõs new joystick ensures the pain of defeat is really painful,ówall street journal, january 21, p. a13d.gould, j.d., and n. grischkowsky. 1984. òdoing the same work with hard copy and withcathode ray tube (crt) computer terminals,ó human factors, vol. 26, pp. 323337.gould, j.d., s.j. boies, s. levy, j.t. richards, and j. schoonard. 1987a. òthe 1984 olympicmessage system: a test of behavioral principles of system design,ó communications ofthe acm, vol. 30, pp. 758769.gould, j.d., et al. 1987b. òwhy reading was slower from crt displays than from paper,óproceedings of the conference on computerhuman interaction + gi, toronto, canada, april59, acm, new york, pp. 711.government information technology service (gits). 1995. the kiosk network solution: anelectronic gateway to government service, interagency kiosk committee for the customer service improvement team of the gits working group, washington, dc.gray, w.d., b.e. john, and m.e. atwood. 1992. òthe precis of project ernestine, or, anoverview of a validation of goms,ó proceedings of the conference on human factors incomputing systems, monterey, ca, acm, new york, pp. 307312.greene, s., l. gomez, and s. devlin. 1986. òa cognitive analysis of database query production,ó proceedings of the human factors society, human factors society, santa monica,ca, pp. 913.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.204more than screen deepgreif, irene. 1994. òdesktop agents in groupenabled products,ó communications of theacm, vol. 37, no. 7, pp. 100105.gross, neil. 1996. òdefending the living room,ó business week, june 24, pp. 9698.grossman, r., et al. 1993. òan object manager utilizing hierarchical storage,ó proceedingsof the twelth symposium on mass storage systems, ieee computer society press, losalamitos, ca.grosz, b., a. joshi, and s. weinstein. 1995. òcentering: a framework for modeling thelocal coherence of discourse,ó computational linguistics, vol. 21, no. 2, pp. 203225.grosz, barbara, and s. kraus. 1996. òcollaborative plans for complex group action,óartificial intelligence, vol. 86, no. 2, pp. 269357.grosz, barbara j., and fernando c.n. pereira. 1994. natural language processing, mit press,cambridge, ma.grosz, barbara j., and candace l. sidner. 1986. òattention, intention, and the structure ofdiscourse,ó computational linguistics, vol. 12, no. 3, pp. 175204.grosz, barbara, and candace sidner. 1990. òplans for discourse,ó intention in communication, mit press, cambridge, ma.grudin, jonathan. 1988. òwhy cscw applications fail: problems in the design andevaluation of organizational interfaces,ó proceedings of the conference on computer supported cooperative work, acm, new york, pp. 8593.grudin, jonathan. 1989. òthe case against user interface consistency,ó communications ofthe acm, vol. 32, no. 10, pp. 11641173.grudin, jonathan. 1993. òthe next generation,ó communications of the acm, vol. 36, no. 4,april, pp. 110120.guha, r.v., and douglas b. lenat. 1994. òenabling agents to work together,ó communications of the acm, vol. 37, no. 7, pp. 127142.gunter, carl. 1992. semantics of programming languages, mit press, cambridge, ma.hall, r.j. 1996. òtrusting your assistant,ó kbseõ96, syracuse, ny, september, ieee computer society press, los alamitos, ca, pp. 4251.hanson, wayne, ed. 1994. òkiosk realities,ó government technology, vol. 7, no. 9, pp. 1, 5054, 62.haring, bruce. 1996. ònew home video games really play with thoughts, emotions,óusa today, september 18, p. 5d.hartson, h.r., j.c. castillo, j. kelso, j. kamler, and w.c. neale. 1996. òremote evaluation:the network as an extension of the usability laboratory,ó proceedings of the conferenceon human factors in computing systems, acm, new york, pp. 228236.harwood, richard. 1996. ò40 percent of our lives,ó washington post, november 30, pp.a19.health and welfare agency data center of california. 1993. òinfo/california: ôasingle face to government,õó health and welfare agency data center of california,sacramento, ca, september.heeman, peter, and james allen. 1994. òdetecting and correcting repairs,ó proceedings ofthe 32nd annual meeting of the association for computational linguistics, las cruces, nm,acl, somerset, nj.helander, martin e., ed. 1988. the handbook of humancomputer interaction, northholland,amsterdam, the netherlands.helander, martin g., and thiagajaran palanivel. 1992. òergonomics of humancomputerinteraction,ó impact of science on society, vol. 42, no. 165, pp. 6574.hennecke, marcus e., et al. 1995. òvisionary speech: looking ahead to practicalspeechreading systems,ó in speechreading by humans and machines, vol. 150 of natoasi series, series f: computer and systems sciences, david g. stork and marcus e.hennecke, eds., springerverlag, berlin.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography205herndon, k.p., a. van dam, and m. gleicher. 1994. òthe challenges of 3d interaction, achiõ94 workshop,ó sigchi bulletin, vol. 26, no. 4, pp. 3643.hirschman, lynette, and donna cuomo. 1995. òevaluation of human computer interfaces: a report from an arpa workshop,ó sigchi bulletin, vol. 27, no. 2, pp. 2829.hix, d., and h.r. hartson. 1993. developing user interfaces: ensuring usability throughproduct and process, john wiley & sons, new york.hof, robert d. 1996. òthese may really be pcs for the rest of us,ó business week, june 24,pp. 7678.hoffman, donna, w. kalsbeck, and t. novak. 1996. òinternet and web use in the u.s.,ócommunications of the acm, vol. 39, no. 12, pp. 3646.huberman, b. 1996. òevolution in cyberspace,ó in future of the internet, new york academy of sciences workshop, xerox palo alto research center, may 6.huff, c., l. sproull, and s. kielser. 1989. òcomputer communication and organizationalcommitment: tracing the relationships in a city government,ó journal of appliedsocial psychology, vol. 19, pp. 13711391.interagency kiosk committee. 1994. òthe kiosk network solution: an electronic gatewayto government service,ó government information technology services workinggroup, washington, dc, november 22.investorõs business daily. 1997. òcomputers and technology,ó january 15, p. a6.jennings, nick r. 1995. òcontrolling cooperative problem solving in industrial multiagent systems using joint intentions,ó artificial intelligence journal, vol. 75, no. 2, pp.146.joshi, a., i. sag, and b. webber. 1981. elements of discourse, cambridge university press,cambridge, england.joshi, a., b. grosz, and s. weinstein. 1983. òproviding a unified account of definite nounphrases in discourse,ó proceedings of the 21st annual meeting of the association for computational linguistics, acl, somerset, nj, pp. 4450.junco, alejandro. 1995. òdigital monopoly: a new cloud on mexicoõs horizon,ó wallstreet journal, june 23, p. a15.kalawsky, roy s. 1993. the science of virtual reality, addisonwesley, reading, ma.kandel, e., and j. schwartz. 1981. principles of neural science, elsevier/northholland, newyork.kandogan, e., and ben shneiderman. 1996. òelastic windows: improved spatial layoutand rapid multiple window operations,ó proceedings of the advanced visual interfacesconference, acm press, new york, may.kautz, henry a., et al. 1994. òbottomup design of software agents,ó communications of theacm, vol. 37, no. 7, pp. 143146.keen, peter. 1991. shaping the future: business design through information technology,boston, harvard business school press, cambridge, ma.ketchpel, s. 1995. òcoalition formation among autonomous agents,ó proceedings of the 5theuropean workshop on modelling autonomous agents in a multiagent world, lecture notesin artificial intelligence, springer, amsterdam, pp. 7388.kieras, d., and p. polson. 1985. òan approach to the formal analysis of user complexity,óinternational journal of manmachine studies, vol. 22, pp. 365394.kiesler, sara, lee sproull, and ken waters. 1996. òa prisonerõs dilemma experiment oncooperation with people and humanlike computers,ó journal of personality and socialpsychology, vol. 70, pp. 4765.king, julia. 1996. òinfo overload: a hazard to career,ó computerworld, october 21.kinny, d., m. ljungberg, a.s. rao, e. sonenberg, g. tidhar, and e. werner. 1994. òplannedteam activity,ó artificial social systems, lecture notes in artificial intelligence, c.castelfranchi and e. werner, eds., springerverlag, amsterdam.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.206more than screen deepkitajima, m., and p.g. polson. 1996. òa comprehensionbased model of exploration,óproceedings of the conference on human factors in computing systems: common ground,acm, new york, april, pp. 324331.klavans, judith l., and philip resnick, eds. 1994. the balancing act workshop: combiningsymbolic and statistical approaches to language, las cruces, nm, association for computational linguistics, somerset, nj.kobsa, alfred, and wolfgang wahlster. 1989. user models in dialog systems, springerverlag, new york.koppelman, j., et al. 1995. òa statistical approach to language modeling for the atistask,ó eurospeech, madrid, september, pp. 17851788.kraus, s., and j. wilkenfeld 1993. òmultiagent negotiation under time constraints,ó technical report, number cs 2649, institute for advanced computer studies, university ofmaryland, college park.krauss, lawrence. 1995.  the physics of star trek, basic books, new york.kraut, robert, j. galegher, r. fish, and b. chalfonte. 1992. òtask requirements and mediachoice in collaborative writing,ó humancomputer interaction, special issue on computersupported cooperative work: articles, vol. 7, no. 4, pp. 375407.kraut, robert, r. fish, r. root, and r. rice. 1993. òevaluating video as a technology forinformal communication,ó communications of the acm, vol. 36, no. 1, pp. 4861.kraut, robert, w. scherlis, t. mukhopadhyay, j. manning, and s. kiesler. 1996. òinternet inthe home, the homenet field trial of residential internet services,ó communicationsof the acm, vol. 39, pp. 5565.landauer, thomas k. 1995. the trouble with computers: usefulness, usability and productivity,mit press, cambridge, ma.lavin, douglas. 1995a. òeuropeõs phone giants talk big, but changes are small,ó wallstreet journal, june 30, pp. b4.lavin, douglas. 1995b. òonline firms face challenge in europe,ó wall street journal, june19, pp. b4.leduff, charlie. 1996. òthe web delivers light in a sightless world,ó new york times,march 28. available online at http://www.nytimes.com/library/cyber/week/0528blind.html.lehner, v. 1996. òcaterpillar collaborative vehicle design,ó technical report, nationalcenter for supercomputing applications, university of illinois at urbanachampaign.available online at http://www.ncsa.uiuc.edu/veg/dvr.leigh, j., and a.e. johnson. 1996. òsupporting transcontinental collaborative work in persistent virtual environments,ó ieee computer graphics and applications, ieee computersociety press, los alamitos, ca.leigh, j., et al. 1993. òrealistic modeling of brain structures with remote interaction between simulations of an inferior olivary neuron and a cerebellar purkinje cell,óproceedings of the scs simulations multiconference, arlington, va, march.leigh, j., et al. 1996a. òcalvin: an immersimedia design environment utilizing heterogeneous perspectives,ó proceedings of the ieee international conference on multimediacomputing and systems, ieee computer society press, los alamitos, ca, june.leigh, j., et al. 1996b. òmultiperspective collaborative design in persistent networkedvirtual environments,ó proceedings of the ieee virtual reality annual international symposium, ieee computer society press, los alamitos, ca, april.lerner, eric j. n.d. òtalking to your computer,ó voicetype, ibm. available online at http://www.software.ibm.com/is/voicetype/human.html.levesque, h., p. cohen, and j. nunes. 1990. òon acting together,ó proceedings of the annualconference of the american association for artificial intelligence, mit press, cambridge,ma, pp. 9499.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography207levin, e., and r. pieraccini. 1995. òchronus: the next generation,ó proceedings of thespoken language systems technology workshop, austin, tx, morgankaufmann, sanfrancisco, pp. 269271.levin, rich. òthe uncommon user interface,ó informationweek, issue 598, september 23.lieberman, henry. 1995. òletizia: an agent that assists web browsing,ó proceedings of thefourteenth international joint conference on artificial intelligence, morgankaufmann, sanmateo, ca, pp. 924929.litman, diane. 1985. òplan recognition and discourse analysis: an integrated approachfor understanding dialogues,ó no. 170, department of computer science, universityof rochester, rochester, ny.litman, diane j., and james f. allen. 1990. òdiscourse processing and commonsenseplans,ó intentions in communication, philip r. cohen, jerry l. morgan, and martha e.pollack, eds., mit press, cambridge, ma.lochbaum, karen e. 1994. òusing collaborative plans to model the intentional structure ofdiscourse,ó technical report tr2594, center for research in computing technology,harvard university, cambridge, ma.lochbaum, karen e. 1995. òthe use of knowledge preconditions in language processing,óproceedings of the 14th international joint conference on artificial intelligence, morgankaufmann, san mateo, ca, pp. 12601266.locke, j. 1995. òan introduction to the internet networking environment and simnet/dis,ó unpublished masterõs thesis, naval postgraduate school, august. available online at http://wwwnpsnet.cs.nps.navy.mil/npsnet/publications/disintro.ps.z.loefler, c. 1993. ònetworked virtual reality,ó proceedings of atr workshop on virtual spaceteleconferencing, pp. 108119.lohr, steve. 1996. òthe network computer as the pcõs evil twin,ó washington post, november 4, pp. d1 and d6.lund, arnold m. 1994a. òameritechõs usability laboratory: from prototype to final design,ó behaviour & information technology, vol. 13, nos. 12, pp. 6780.lund, arnold m. 1994b. òthe evolution of broadband work in ameritechõs customerinterface systems and human factors department,ó usability in practice, academicpress, boston, ma.lund, arnold m., and judith e. tschirgi. 1991. òdesigning for people: integrating humanfactors into the product realization process,ó ieee journal on selected areas in communication, vol. 9, no. 4, pp. 496500.macedonia, m.r., and m.j. zyda. 1995. òa taxonomy for networked virtual environments,ó proceedings of the 1995 workshop on networked realities, october.macedonia, m.r., d.p. brutzman, and m.j. zyda. 1995. ònpsnet: a multiplayer 3dvirtual environment over the internet,ó proceedings of the 1995 symposium on interactive3d graphics, acm, new york, pp. 9394.maes, pattie. 1994. òagents that reduce work and information overload,ó communications of the acm, vol. 37, no. 7, pp. 3040.magerman, david. 1995. òstatistical decisiontree models for parsing,ó proceedings of the33rd annual meeting of the association for computational linguistics, cambridge, ma,acl, somerset, nj.mandeville, j., and t. furness. 1995. ògreenspace: creating a distributed virtual environment for global applications,ó human interface technology laboratory, university ofwashington, seattle. available online at http://www.hitl.washington.edu/projects/greenspace.mankin, d., s.g. cohen, and t.k. bikson. 1996. teams and technology, harvard businessschool press, boston, ma.marchionini, gary, and catherine plaisant. 1996. òuser interface for the library of conmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.208more than screen deepgress national digital library,ó humancomputer interaction laboratory (hcil),university of maryland, college park. available online at http://www.cs.umd.edu/projects/hcil/research/1995/ndl.html.marchionini, gary, et al. 1996. òusersõ needs assessment for the library of congressõnational digital library,ó center for automation research, university of maryland,college park, may.margulies, e. 1995. 236 killer voice processing applications, flatiron publishing, new york.markoff, john. 1994. òreprogramming the hacker elite,ó new york times, january 2, p. f6.marks, j. 1990a. òautomating the design of network diagrams,ó technical report tr 0290, harvard university, cambridge, ma.marks, j. 1990b. òa syntax and semantics for network diagrams,ó proceedings of the 1990ieee conference on visual languages, skokie, il, ieee computer society press, losalamitos, ca.marks, j. 1991. òthe competence of an automated graphic designer,ó proceedings of the1991 long island conference on artificial intelligence and computer graphics, new yorkinstitute of technology, new york, pp. 5361.markus, m.l., and t. connolly. 1990. òwhy cscw applications fail: problems in theadoption of interdependent work tools,ó proceedings of the conference on computersupported cooperative work, acm, new york, pp. 371380.martin, paul, frederick crabbe, stuart adams, eric baatz, and nicole yankelovich. 1996.òspeechacts: a spokenlanguage framework,ó computer, vol. 29, no. 7, pp. 3340.mason, j.a., and j.l. edwards. 1988. òsurveying projects on intelligent dialogues,ó international journal of manmachine studies, vol. 28, nos. 2, 3, pp. 259307.massaro, dominic w. 1997. perceiving talking faces, mit press, cambridge, ma.maybury, mark. 1993. intelligent multimedia interfaces, aaai/mit press, menlo park, ca.maybury, m. 1994. òresearch in multimedia and multimodal parsing and generation,ójournal of artificial intelligence review, special issue on the integration of natural language and vision processing, vol. 8, no. 3.mccartney, scott, and jonathan friedland. 1995. òcatching up: computer sales sizzle asdeveloping nations try to shrink pc gap,ó wall street journal, june 29, pp. a1 and a8.mcgrath, j. 1984. groups: interaction and performance, prenticehall, englewood cliffs, nj.mcneely, w.a. 1993. òrobotic graphics: a new approach to force feedback for virtualreality,ó proceedings of the ieee virtual reality international symposium, seattle, wa,september 1822, ieee computer society press, los alamitos, ca, pp. 336341.medinamora, raul, terry winograd, rodrigo flores, and fernando flores. 1992. òtheaction workflow approach to workflow management technology,ó proceedings of theconference on computersupported cooperative work, november, toronto, acm, newyork.miller, brian. 1994. òturf wars,ó government technology, vol. 7, no. 9, pp. 1, 48.miller, g.a., et al. 1990. òfive papers on wordnet,ó cognitive science laboratory, princetonuniversity press, princeton, nj.miller, s. 1996. òa fully statistical approach to natural language interfaces,ó proceedings ofthe 34th annual meeting of the association for computational linguistics, santa cruz, ca,morgankaufmann, san francisco, pp. 5561.miller, s., et al. 1994. òstatistical language processing using hidden understanding models,ó proceedings of the spoken language technology workshop, plainsboro, nj, morgankaufmann, san francisco, pp. 4852.minsky, marvin, and doug riecken. 1994. òa conversation with marvin minsky,ó communications of the acm, vol. 37, no. 7, pp. 2329.mitchell, tom, rich caruana, dayne freitag, john mcdermott, and david zabowski. 1994.òexperience with a learning personal assistant,ó communications of the acm, vol. 37,no. 7, pp. 8091.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography209mittal, v.o., s. roth, j.d. moore, j. mattis, and g. carenini. 1995. ògenerating captions forinformation graphics,ó proceedings of the 14th international joint conference on artificialintelligence, morgankaufmann, san mateo, ca, pp. 12761283.moore, johanna d. 1995. participating in explanatory dialogues: interpreting and responding toquestions in context, mit press, cambridge, ma.moore, robert, douglas appelt, john dowding, j. mark gawron, and douglas moran. 1995.òcombining linguistic and statistical knowledge sources in naturallanguage processing for atis,ó darpa proceedings of the spoken language systems technology workshop, january, austin, tx, morgankaufmann, san francisco.morningstar, c., and f.r. farmer. 1991. òcyberspace: first steps,ó the lessons of lucasfilmõshabitat, mit press, cambridge, ma, pp. 273302.mossberg, walter s. 1996. ògoing online is still too difficult to lure a mass audience,ówall street journal, february 22, p. b1.munk, nina. 1996. òtechnology for technologyõs sake,ó forbes, october 21, pp. 280288.myers, brad a., j. goldstein, and m.a. goldberg. 1994. òcreating charts by demonstration,ó proceedings of the conference on human factors in computing systems, active support for interaction, vol. 1, boston, ma, acm, new york, pp. 106111.nakatani, christine, and julia hirschberg. 1993. òa speechfirst model for repair detection and correction,ó proceedings of the 31st annual meeting of the association for computational linguistics, columbus, oh.nass, b., and c. reeves. 1996. the media equation: how people treat computers, television, andnew media like real people and places, cambridge university press, cambridge, england, and new york.national research council. 1990a. human factors research needs for an aging population,national academy press, washington, dc.national research council. 1990b. quantitative modeling of human performance in complex,dynamic systems, national academy press, washington, dc.national research council. 1995. virtual reality: scientific and technological challenges,national academy press, washington, dc.national science foundation. 1994. new directions in humancomputer interaction education,research, and practice, national science foundation, arlington, va.national science foundation. 1995. survey of the state of the art in human language technology, national science foundation, arlington, va, november 21.national science foundation. 1996. stimulate: speech, text, image and multimedia advanced technology effort, national science foundation, arlington va, september 1nielsen, j. 1993. usability engineering, academic press, san diego, calif.nielsen, j., and j. levy. 1993. òsubjective user preferences versus objective interface performance measures,ó usability engineering, academic press, boston, ma, p. 36.nielsen, jakob, and robert l. mack, eds. 1994. usability inspection methods, john wiley &sons, new york.noack, david. 1994a. òaccess indiana forming,ó government technology, vol. 7, no. 9, p.55.noack, david. 1994b. òkansas ink connects citizens to information,ó government technology, vol. 7, no. 9, pp. 2223.norman, donald a. 1994. òhow might people interface with agents,ó communications ofthe acm, vol. 37, no. 7, pp. 6871.oõhara, colleen. 1996. òntia funds model internet projects,ó federal computer week,september 23, p. 6.olson, g.m., judith s. olson, and robert e. kraut. 1992. òintroduction to this special issueon computersupported cooperative work,ó editorial, humancomputer interaction,vol. 7, no. 3, pp. 251256.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.210more than screen deepolson, j., and g.m. olson. 1995. òwhat mix of video and audio is useful for small groupsdoing remote realtime design work,ó proceedings of sigchiõ95, acm, new york,pp. 362368.orlikowski, w. 1996. òdeveloping with notes,ó groupware and teamwork, c. ciborra, ed.,john wiley & sons, chichester, england, pp. 3171.oviatt, sharon l. 1996. òusercentered modeling for spoken language and multimodalinterfaces,ó center for humancomputer communication, oregon graduate instituteof science and technology, beaverton, or.oviatt, sharon l., p.r. cohen, and m.q. wang. 1994. òtoward interface design for humanlanguage technology: òmodality and structure as determinants of linguistic complexity,ó speech communication (european speech communication association), no.15, pp. 283300.parise, salvatore, lee sproull, sara kielser, and keith waters. 1996. òmy partner is a realdog: cooperation with social agents,ó proceedings of the conference on computer supported cooperative work, acm, new york.patriotta, g. 1996. òlearning and appropriating groupware in the development of newproducts and processes,ó groupware and teamwork, c. ciborra, ed., john wiley & sons,chichester, england, pp. 138158.perlman, gary. 1989. user interface development, graduate curriculum module seicm171.1, software engineering institute, carnegie mellon university, pittsburgh, pa.pescovitz, david. 1996. òthe future of the pc,ó wired, september, p. 80.pitta, julie. 1995. ònew hope for computer illiterates?ó forbes, january 16, pp. 8889.plaisant, catherine, et al. 1997. òbringing treasures to the surface: iterative design for thelibrary of congress national digital library program,ó proceedings of the sigchi ô97,march, acm, new york.pope, kyle. 1994. òelectric utilities light out for europeõs phone business,ó wall streetjournal, december 2, p. b4.power, kevin. 1994. òneither rain, nor sleet, nor darkness of display . . . ?ó governmentcomputer news, october 17, pp. 1114.preece, j., et al. 1994. humancomputer interaction, addisonwesley, workingham, u.k.proceedings of human language technology workshop. 1993. plainsboro, nj. morgankaufmann, san mateo, ca.proceedings of speech and natural language workshop. 1992. harriman, ny. morgankaufmann, san mateo, ca.proceedings of speech and natural language workshop. 1991. pacific grove, ca. morgankaufmann, san mateo, ca.proceedings of speech and natural language workshop. 1990. hidden valley, pa. morgankaufmann, san mateo, ca.proceedings of the spoken language systems technology workshop. 1994. austin, tx. morgankaufmann, san mateo, ca.raskin, jef. 1997. òlooking for a humane interface: will computers ever become easy touse?,ó communications of the acm, vol. 40, pp. 98101.revzin, philip. 1995. òinfohighway builders seek to change african nationõs development priorities,ó wall street journal, june 9, p. a5e.reynolds, t.j., and j. gutman. 1988. òladdering theory, method, analysis, and interpretation,ó journal of advertising research, vol. 28, pp. 1131.rheingold, harold. 1994. virtual communities: homesteading on the electronic frontier,addisonwesley, reading, ma.rich, c., and c.l. sidner. 1996. òadding a collaborative agent to directmanipulationinterfaces,ó proceedings of uist.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography211rich, c., and c.l. sidner. 1997a. òsegmented interaction history in a collaborative interface agent,ó proceedings of the intelligent user interfaces conference.rich, c., and c.l. sidner. 1997b. òcollagen: a toolkit for collaborative interfaces,óproceedings of the first international conference on autonomous agents, acm, new york.richman, dan. 1995. òspeech replaces point & clickñboeing and others benefit fromvoice recognition, synthesis,ó informationweek, issue 534, july 3.riecken, doug. 1994a. òa conversation with marvin minsky about agents,ó communications of the acm, vol. 37, no. 7, pp. 2329.riecken, doug. 1994b. òintelligent agents,ó communications of the acm, vol. 37, no. 7, pp.2021.riecken, doug. 1994c. òm: an architecture of integrated agents,ó communications of theacm, vol. 37, no. 7, pp. 107116, 146147.rigdon, joan e. 1996. òtesting how easy ôeasyõ really is,ó wall street journal, may 10, pp.b1 and b3.rim”, b., and l. schiaratura. 1991. ògesture and speech,ó fundamentals of nonverbalbehaviour, r.s. feldmand and b. rim” eds., new york press, syndicate of the university of cambridge, pp. 239281.roe, d.b., and j.g. wilpon, eds. 1994. voice communication between humans and machines,national academy press, washington, dc. many chapters from this book were revised and published in the october 1995 issue of proceedings of the national academy ofsciences, vol. 92.rogers, e.m. 1983. diffusion of innovation, third edition, free press, new york.rosenschein, j., and g. zlotkin. 1994. rules of encounter: designing conventions for automated negotiation among computers, mit press, cambridge, ma.rossney, robert. 1996. òmetaworlds,ó wired, june, pp. 142146, 206212.roth, s.f., j. kolojejchick, j. mattis, and j. goldstein. 1994. òinteractive graphic designusing automatic presentation knowledge,ó proceedings of the conference on humanfactors in computing systems, active support for interaction, vol. 1, acm, new york,april, pp. 112117.roussos, m. 1996. òconstructing collaborative stories within virtual learning landscapes,ó proceedings of the european conference on artificial intelligence in education, september.roy, t., and c. cruzneira. 1995. òcosmic worm in the cave: steering a highperformance computing application from a virtual environment,ó presence, vol. 4, no. 2,pp. 121129.rubin, andee. 1996. òeducational technology: support for inquirybased learning,ó terc,cambridge, ma. available online at http://ra.terc.edu/allianceresourcesservices/reform/techinfusion/edtech/edtechintro.html.russell, stuart, and peter norvig. 1995. artificial intelligence: a modern approach, prenticehall, englewood cliffs, nj.ryall, k., j. marks, and s. shieber. 1996. òan interactive system for drawing graphs,ógraphdrawing 96.sager, ira, and robert d. hof. 1996. òthe race is on to simplify,ó business week, june 24, pp.7275.salton, g. 1989. òasis panel on new developments and future prospects for electronicdatabases,ó sigir 1989, acm, new york, pp. 137150.sandberg, jared. 1996. òwhat do they do online?ó wall street journal, december 9, p. r8.sawyer, p., a. flanders, and d. wixon. 1996. òmaking a differenceñthe impact of inspections,ó proceedings of the conference on human factors in computing systems, acm, newyork, pp. 375382.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.212more than screen deepscherr, a.l. 1993. òa new approach to business processes,ó ibm systems journal, vol. 32,no. 1, pp. 8098.schuler, doug. 1996. new community networks, addisonwesley, reading, ma.schulzrinne, henning. 1996. òworldwide web: whence, whither, what next?ó ieeenetwork magazine, march/april, pp. 114.searle, john. 1990. intentions in communication, mit press, cambridge, ma.selker, ted. 1994. òcoach: a teaching agent that learns,ó communications of the acm, vol.37, no. 7, pp. 9299.seneff, s., m. mccandless, and v. zue. 1995. òintegrating natural language into the wordgraph search for simultaneous speech recognition and understanding,ó proceedings ofeurospeech, madrid, september.seybold, p. 1994. òhow to leapfrog your organization into the twentyfirst century:highlights from patricia seyboldõs 1994 technology forum,ó patricia seybold group,new york, pp. 17.shaw, c., and m. green. 1993. òthe mr toolkit peers package and environment,ó proceedings of the ieee virtual reality annual international symposium, ieee computer societypress, los alamitos, ca.shieber, stuart m. 1983. òsentence disambiguation by a shiftreduce parsing technique,ó21st annual meeting of the association for computational linguistics, cambridge, ma,acl, somerset, nj.shimoga, k.b. 1993. òa survey of perceptual feedback issues in dexterous telemanipulation,ó proceedings of the ieee virtual reality annual international symposium, ieee computer society press, los alamitos, ca.shneiderman, ben. 1988. òdirect manipulation: a step beyond programming languages,óieee computer, vol. 16, no. 8, pp. 5769.shneiderman, ben. 1992. designing the user interface: strategies for effective humancomputerinteraction, second edition, addisonwesley, reading, ma.shneiderman, ben. 1994. òdynamic queries for visual information seeking,ó humancomputer interaction laboratory, university of maryland, college park, january.shneiderman, ben, don byrd, and bruce croft. 1997. òclarifying search: a userinterfaceframework for text searches,ó dlib magazine. available online at http://www.dlib.org/dlib/january97/o1contents.html.short, j., e. williams, and b. christie. 1976. the social psychology of telecommunications, johnwiley & sons, new york.shu, l., and w. flowers. 1992. ògroupware experiences in threedimensional computeraided design,ó proceedings of the conference on computer supported cooperative work,acm press, new york, pp. 179186.sidner, candace. 1983. òwhat the speaker means: the recognition of speakersõ plans indiscourse,ó international journal of computers and mathematics, vol. 9, pp. 7182.sidner, c. 1994a. òan artificial discourse language for collaborative negotiation,ó proceedings of the national conference on artificial intelligence94, seattle, mit press, cambridge,ma, pp. 814819.sidner, c. 1994b. negotiation in collaborative activity: a discourse analysis, knowledgebased systems, 7(4): 265267.singh, g., l. serra, h. ping, and h. ng. 1994. òbricknet: a software toolkit for networkbased virtual worlds,ó presence: teleoperators and virtual environments, vol. 3, no. 1,pp. 1934.smith, david c., et al. 1994. òkidsim: programming agents without a programminglanguage,ó communications of the acm, vol. 37, no. 7, pp. 5567.smith, ronnie w., and d. richard hipp. 1994. spoken natural language dialog systems,oxford university press, new york.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography213smith, ronnie w., d. richard hipp, and alan w. biermann. 1995. òan architecture forvoice dialogue systems based on prologstyle theorem proving,ó computational linguistics, vol. 21, no. 3, pp. 281320.sproull, lee, and samer faraj. 1995. òatheism, sex, and databases: the net as a socialtechnology,ó public access to the internet, brian kahin and james keller, eds., pp. 6281.sproull, lee, r. subramani, jan walker, sara kiesler, and keith waters. 1996. òwhen theinterface is a face,ó human computer interaction, vol. 11, pp. 97124.stansfield, s. 1995. òan application of shared virtual reality to situational training,óproceedings of the ieee virtual reality annual international symposium, ieee computersociety press, los alamitos, ca, pp. 156161.stefik, m., et al. 1987. òbeyond the chalkboard: computer support for collaboration andproblem solving in meetings,ó communications of the acm, vol. 30, no. 1, pp. 3247.stein, a., and e. maier. 1995. structuring collaborative informationseeking dialogues,knowledgebased systems, 8(23):8293.steinmetz, greg. 1995. òat&t and others dislike german deregulation plan,ó wall streetjournal, august 10, p. a6.stock, robert w. 1995. òremoving roadblocks to computer use,ó wall street journal,september 14.storck, john, and lee sproull. 1995. òthrough a glass darkly: what do people learn invideo conferences?ó human communication research, vol. 22, no. 2, pp. 197219.stork, david g., and marcus hennecke, eds. 1996. speechreading by humans and machines:models, systems and applications, springerverlag, berlin and new york.suchman, lucy. 1987. plans and situated actions, cambridge university press, new york.sullivan, k. 1996. òthe windows 95 user interface: a case study in usability engineering,óconference on human factors in computing systems, acm, new york, pp. 473480.sycara, k.p. 1987. òresolving adversarial conflicts: an approach to integrating casebased and analytic methods,ó unpublished ph.d. thesis, georgia institute of technology.tang, j.c., and e. isaacs. 1993. òwhy do users like video?ó computer supported cooperativework, pp. 163196.tognazzini, bruce. 1992. tog on interface, addisonwesley, reading, ma.tognazzini, bruce. 1996. tog on software design, addisonwesley, reading, ma.trace r&d center. 1996a. conet: cooperative database distribution network for assistivetechnology, 199697 edition, trace r&d center, madison, wi, spring/summer.trace r&d center. 1996b. trace resourcebook: assistive technology for communication, control and computer access, 199697 edition, trace r&d center, madison, wi.turkle, sherry. 1996. òwho am we?ó wired, january, pp. 146152, 194199.university of udine. 1996. sixth international conference on user modeling, university ofudine, italy, october.u.s. bureau of the census. 1994. americans with disablities, u.s. government printingoffice, washington, dc. available online at http://www.census.gov/hhes/www/disable.html.u.s. bureau of the census. 1995. population profile of the united states, u.s. governmentprinting office, washington, dc.u.s. department of commerce. 1994. òthe information infrastructure: reaching societyõsgoals,ó report of the information infrastructure task force committee on applications andtechnology, national institute of standards and technology, gaithersburg, md, september.u.s. department of education. 1992. 1992 national adult literacy survey, u.s. governmentprinting office, washington, dc.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.214more than screen deepvan dam, andries. 1997. òpostwimp user interfaces,ó communications of the acm, vol.40, february, pp. 6367.vanderheiden, gregg c. 1996. reply comments in response to the federal communicationscommissionõs notice of inquiry 96198 regarding implementation of section 255 of thetelecommunications act of 1996 (access to telecommunications services, telecommunications equipment, and customer premiseõs equipment by persons with disabilities), wt docket no. 96198, submitted by g.c. vanderheiden, trace r&d center,university of wisconsinmadison.vanderheiden g., et al. 1986. òhuman interface design and the handicapped user,óproceedings of the conference on human factors in computing systems, acm, new york,pp. 291297.van house, nancy. 1996. òusercentered iterative design for digital libraries: the cypress experience,ódlib magazine, february.vaughannichols, steven j. 1996. òthe nc follies: a network computer is a small idea,óinternet world. available online at http://www.internetworld.com/1996/12/ncfollies.html.venture development corporation. 1996a. òfive characteristics of good interactive kioskdesign.ó venture development corporation, ma, june 14.venture development corporation. 1996b. òinteractive kiosks, new horizons for advanced computing technology: an executive white paper,ó venture developmentcorporation, ma.venture development corporation. 1996c. òsurging demand for interactive kiosks,ó venture development corporation, ma, january 19.verity, john w., and paul c. judge. 1996. òmaking computers disappear,ó business week,june 24, pp. 118119.vince, john. 1995. virtual reality systems, addisonwesley, reading, ma.virzi, robert a., and paul resnick. 1995. òrelief from the audio interface blues: expanding the spectrum of menu, list, and form styles,ó acm transactions on computerhuman interaction, vol. 2, june, pp. 145176. available online at http://ccs.mit.edu/ccswp184.html.virzi, r.a., j.l. sokolov, and d. karis. 1996. òusability problem identification using bothlow and highfidelity prototype,ó proceedings of the conference on human factors incomputing systems: common ground, pp. 236243, acm press, new york.wahlster, w., e. andr, w. finkler, j.j. profitlich, and t. rist. 1993. òplanbased integrationof natural language and graphics generation,ó artificial intelligence, vol. 63, nos.12,pp. 378428.waldman, peter. 1995. òindia seeks to open huge phone market,ó wall street journal, july25.wang, q., m. green, and c. shaw. 1995. òemñan environment manager for buildingnetworked virtual environments,ó proceedings of the ieee virtual reality annual international symposium, ieee computer society press, los alamitos, ca, pp. 1118.wasser, judith d. 1996. òreform, restructuring, and technology infusion,ó technologyinfusion and school change, terc, cambridge, ma. available online at http://ra.terc.edu/allianceresourcesservices/reform/techinfusion/reform/reformintro.html.weiser, mark. 1993a. òsome computer science issues in ubiquitous computing,ó communications of the acm, vol. 36, no. 7, pp. 7584.weiser, mark. 1993b. òubiquitous computing,ó computer, october, pp. 7172.weld, daniel. 1995. òthe role of intelligent systems in the national information infrastructure,ó ai magazine,vol. 3, no. 16.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.bibliography215wiklund, michael e., ed. 1994. usability in practice: how companies develop userfriendlyproducts, academic press, boston, ma.wilson, e.o. 1971. the insect societies, belknap/harvard university press, cambridge, ma.winograd, t. 1988. òa language/action perspective on the design of cooperative work,óhumancomputer interaction, vol. 3, no. 1, pp. 330.woodward, p. 1993. òinteractive scientific visualization of fluid flow,ó ieee computermagazine, vol. 26, no. 10. october.young, s.r., a.g. hauptmann, w.h. ward, e.t. smith, and p. werner. 1989. òhigh levelknowledge sources in usable speech recognition systems,ó communications of theacm, february, pp. 183194.zuckerman, lawrence. 1996. òibm to market software that can interpret human speech,ónew york times, september 12. available online at http://search.nytimes.com/web/docsroot/library/cyber/week/0912blue.html.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary217part iimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary219part 2background papermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d221221trends in humancomputer interactionresearch and developmenth. rex hartsonvirginia polytechnic instituteintroductionhumancomputer interaction (hci) is a field of research and development, methodology, theory, and practice with the objective of designing, constructing, and evaluating computerbased interactive systemsñincluding hardware, software, input/output devices, displays, training,and documentationñso that people can use them efficiently, effectively,safely, and with satisfaction. hci is crossdisciplinary in its conduct andmultidisciplinary in its roots, drawing onñsynthesizing and adaptingfromñseveral other fields, including human factors (e.g., the roots fortask analysis and designing for human error in hci); ergonomics (e.g.,the roots for design of devices, workstations, and work environments);cognitive psychology (e.g., the roots for user modeling); behavioral psychology and psychometrics (e.g., the roots of user performance metrics);systems engineering (e.g., the roots for much predesign analysis); andcomputer science (e.g., the roots for graphical interfaces, software tools,and issues of software architecture).importance of usabilitythe entire field of hci shares the single goal of achieving high usabilityfor users of computerbased systems. rather than being fuzzy and vague asit is sometimes perceived, usability is tangible and can be quantified. usability can be broadly defined as òease of use,ó including such measurable attributes as learnability, speed of user task performance, user error rates, andsubjective user satisfaction (shneiderman, 1992; hix and hartson, 1993a).however, an easytouse system that does not support its usersõ needs, interms of functionality, is of little value. thus, usability has evolved towardthe concept of òusability in the largeóñthat is, ease of use plus usefulness.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.222more than screen deepdespite many research advances in interactive computer systems,usability barriers still obstruct access to, and blunt effectiveness of, aneverycitizen interface for the national information infrastructureñdisenfranchising and disenchanting users across society. as a result, the unitedstates fails to accrue the potentially enormous returns of our collectiveinvestment in computing technology. these barriers impede human productivity and have a profound impact on computer users in business,government, industry, education, and indeed the whole nation.in the nottoodistant past, computer usage was esoteric, conductedmostly by a core of technically oriented users who were not only willingto accept the challenge of overcoming poor usability but also sometimeswelcomed it as a barrier to protect their craft from uninitiated òoutsiders.ó poor usability was good for the fieldõs mystique, not to mentionusersõ job security. now, unprecedented numbers of americans use computers, and user interface is often the first thing people ask about whendiscussing software. to most users the interface is the system. for the òeverycitizenó of today, communication with the system has become at least asimportant as computation by the system.the goals of most organizations include increased employee and organization productivity, decreased employee training costs, decreasedemployee work errors, and increased employee satisfaction. these arealso exactly the benefits of achieving high usability in user interfaces. toooften, especially in government and large businesses, training is used as acostly substitute for usability, and almost as often it fails to meet its goals.attention to usability by developers no longer requires justification inmost quarters: òusability has become a competitive necessity for thecommercial success of softwareó (butler, 1996).product and processachieving good usability requires attention to both product and process. the product, in this case, is the content of the user interaction designand its embodiment in software. an effective process for developing interaction design is also important, and a poor understanding of the processis often responsible for a productõs lack of usability. while stateoftheartuser interaction development processes are based on formative usabilityevaluation in an iterative cycle, much of the state of the practice is fundamentally flawed in that remarkably little formal usability evaluation isperformed on most interactive systems. this is generally changing nowin many industrial settings. however, ensuring usability remains difficult when evaluation, because of real or perceived costs, is not standardpractice in interactive software development projects.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d223user interaction versus user interface softwaredevelopers attempting to incorporate usability methods into theirdevelopment environments often refer to their efforts in terms of òevaluating softwareó or òevaluating user interface software.ó there are manyreasons for evaluating software, but usability is not one of them. usabilityis seated within the design of the user interaction component of an interactive system, not in the user interface software component, as shown simplistically below:development of the user interfacedevelopment ofdevelopment ofuser interactionuser interfacecomponentsoftwarecomponentdevelopment of the interaction component, toward which most hcieffort is directed, is substantially different from development of the userinterface software. the view of the user interaction component is theuserõs perspective of user interaction: how it works; how tasks are performed using it; and its look and feel and behavior in response to what auser sees, hears, and does while interacting with the computer.in contrast, the user interface software component is the programming code by which the interaction component is implemented. the userinteraction component design should serve as requirements for the user interfacesoftware component. design of the user interaction component must begiven attention at least equal to that given the user interface softwarecomponent during the development process, if usability in interactivesystems is to be ensured.the overview of hci topics, issues, and activities that follows isloosely divided into theory, interaction techniques, and developmentmethods. reflecting its diverse roots, hci is host to activities in manytopical areas, some of which are reviewed here. an attempt has beenmade to capture a broad, inclusive cross section of a very dynamic field,but this paper is not intended to be an exhaustive survey, and no claimsare made for completeness. emphasis is given to topics of most importance to the usability of an everycitizen interface.theoryhci theory has its avid proponents. if the proportion of literaturedevoted to theory is to be taken as an indication, theory plays a strongmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.224more than screen deeprole in hci, but in fact theory has not seen broad, direct application in thepractice of hci.much theory comes to hci from cognitive psychology (hammond et.al., 1987; barnard, 1993). normanõs (1986) theory of action expresses,from a cognitive engineering perspective, human task performanceñthepath from goals to intentions to actions (inputs to the computer) back toperception and interpretation of feedback to evaluation of whether theintentions and goals were approached or met. the study of learning inhci (carroll, 1984; draper and barton, 1993) and fitts law (relating cursor travel time to distance and size of target) (mackenzie, 1992) also havetheir roots in cognitive theory.task analysisto design a user interface (or any system) to meet the needs of itsusers, developers must understand what tasks users will use a system forand how those tasks will be performed (diaper, 1989). because tasks at allbut the highest levels of abstraction involve manipulation of user interface objects (e.g., icons, menus, buttons, dialogue boxes), tasks and objectsmust be considered together in design (carroll et al., 1991). a completedescription of tasks in the context of their objects is a rather completerepresentation of an interaction design. the process of describing tasks(how users do things) and their relationships (usually in a hierarchicalstructure of tasks and subtasks) is called task analysis and comes to hciprimarily from human factors (meister, 1985). there are various taskanalysis methods to address various purposes. in hci the primary usesare to drive design and to build predictive models of user task performance. because designing for usability means understanding user tasks,task analysis is essential for good design; unfortunately, it is often ignored or given only minimal attention.models of human information processinga significant legacy from cognitive psychology is the model of a human as a cognitive information processor (card et al., 1983). the command language grammar (moran, 1981) and the keystroke model (cardand moran, 1980), which attempt to explain the nature and structure ofhumancomputer interaction, led directly to the goals, operators, methods, and selection (goms) model (card et al., 1983). gomsrelated modelsñquantitative models combining task analysis and the human user asan information processorñare concerned with predicting various measuresof user performance, most commonly task completion time based on physical and cognitive actions of users, with place holders and estimated timesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d225for highly complex cognitive actions and tasks. direct derivatives of gomsinclude ngomsl (kieras, 1988) and cognitive complexity theory (cct)(kieras and polson, 1985; lewis et al., 1990), the latter of which is intendedto represent the complexity of user interaction from the userõs perspective.this technique represents an interface as the mapping between the userõsjobtask environment and the interaction device behavior.gomsrelated techniques have been shown to be useful in discovering certain kinds of usability problems early in the life cycle, even beforea prototype has been constructed. some studies (e.g., gray et al., 1990)have demonstrated a payoff in a few circumscribed applications wherethe savings of a small number of user actions (e.g., a few keystrokes ormouse movements) can improve user performance enough to have aneconomic impact, often because of the repetitiveness of a task.nonetheless, these models have not achieved widespread applicationwithin the tight constraints of industrial schedules and budgets becauseof the labor intensiveness of producing and maintaining these relativelyformal and structured task representations, the need for specialized skills,and the difficulty in competing with the effectiveness of usability evaluation using a prototype. furthermore, these techniques generally do nottake into account individual differences in user classes and are often limited to expert, errorfree behaviors (not representative of òevery citizenóas a user). in any case, it is generally agreed that this kind of analyticalapproach to usability evaluation cannot be considered a substitute forempirical formative evaluationñusability testing of a prototype with users in a lab or field setting (see òuserbased evaluationó below).human work activityanother area feeding hci theory and practice is òwork activitytheoryó (ehn, 1990; bodker, 1991). originating in russia and germanyand now flourishing in scandinavia (where it is, interestingly, related tothe labor movement), this view of design based on work practices situated in a workerõs own complete environment has been synthesized intoseveral related mainstream hci topics. for example, òparticipatory designó is a democratic process based on the argument that users should beinvolved in designs they will be using, in which all stakeholders, including and especially users, have equal inputs into interaction design. muller(1991) and others have operationalized participatory design in an approach called pictive, which supports rapid group prototype designusing postitª notes, marking pens, paper, and other òlowtechnologyómaterials on a large table top.this interest in design driven by work practices in context has led tothe eclectic inclusion in some hci practice of ethnography, an investigamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.226more than screen deeptive field rooted in anthropology (lecompte and preissle, 1993), and otherhermeneutic (concerned with ways to explain, translate, and interpretperceived reality) approaches as qualitative research tools for extractingdesign requirements. contextual inquiry/design (wixon et al., 1990) isan example of an adaptation of this kind of approach, where design andevaluation are conducted collaboratively by users and developers, whileusers perform normal work tasks in their natural work environment.much of this collaboration is based on interviews that seek to make implicit work practices more explicit and to draw out structure, language,and culture affecting the work.the task artifact framework of carroll and rosson (1992) and, to someextent, scenariobased design follow an ethnographic focus on task performance in a work context. scenarios are concrete, narrative descriptions of user and system activity for task performance (carroll, 1995).they describe particular interactions happening over time, being deliberately informal, open ended, and fragmentary. scenarios often focus oninteraction objects, or artifacts, and how they are manipulated by users inthe course of task performance.formal methodswhile not theory per se, formal methods have been the object of someinterest and attention in hci (harrison and thimbleby, 1990). the objectives of formal methodsñprecise, welldefined notations and mathematical modelsñin hci are similar to those in software engineering. formaldesign specifications can be reasoned about and analyzed for variousproperties such as correctness and consistency. formal specifications alsohave the potential to be translated automatically into prototypes or software implementation. thus, in principle, formal methods can be used tosupport both theory and practice; however, they have not yet had animpact in realworld system development, and their potential is difficultto predict.devices, interaction techniques, and graphicsin contrast to theory, the influence of interaction devices and theirassociated interaction techniques represents a practical arena of realworldconstraints as well as hardware design challenges. òan interaction technique is a way of using a physical input/output device to perform ageneric task in a humancomputer dialogueó (foley et al., 1990). a verysimilar term, interaction style, has evolved to denote the behavior of a userand an interaction object (e.g., a push button or pulldown menu) withinthe context of task performance. in practice, the notion of an interactionmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d227technique includes the concept of interaction style plus full considerationof internal machine behavior and software aspects. in the context of aninteraction technique, an interaction object (and its supporting software)is often referred to as a òwidget.ó libraries of widgetsñsoftware thatsupports programming of graphical user interfaces (guis)ñare an outgrowth of operating system device handler routines used to process userinput and output in the now ancient and impoverished interaction styleof lineoriented, charactercell, textonly, òglass teletypeó terminal interaction. at first, graphics packages took interaction beyond text to directmanipulation of graphical objects, eventually leading to new concepts indisplays and cursor tracking. of course, invention of the mouse andadvent of the xerox star and lisa macintosh by apple accelerated theevolution of the nowfamiliar pointandclick interaction styles. it is notsurprising that many of the computer scientists who developed earlygraphics packages also introduced gui interaction techniques as part oftheir contribution to the hci field (foley and wallace, 1974; foley et al.,1990). to some extent, standardization of interactive graphical interaction techniques led to the widgets of todayõs gui platforms and corresponding style guides intended for ensuring compliance to a style butsometimes mistakenly thought of as usability guides.this growth of graphics and devices made possible one of the majorbreakthroughs in interaction stylesñdirect manipulation (shneiderman,1983; hutchins et al., 1986; weller and hartson, 1992)ñchanging the basicparadigm of interaction with computers. unlike previous commandlineoriented interaction in which users plan tasks in terms of hierarchies ofgoals and subgoals, entering a command line for each, direct manipulation allows opportunistic and incremental task planning. users can trysomething and see what happens, exploring many avenues for interactiveproblem solving. this kind of opportunistic interaction is also calleddisplaybased interaction (payne, 1991).development methods and software engineeringthe difference between user interaction and user interface software,mentioned in the introduction, results in a need for separate and fundamentally different development processes for the two components of auser interface.development life cyclesstudies deriving principles for user interaction development (e.g.,gould et al., 1991) vary, but all agree that interaction development mustmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.228more than screen deepinvolve usability evaluation. just adding some kind of òuser testingó toan existing software process is not enough, however. usability comesfrom a complete process, one that ensures usability and attests to when ithas been achieved (hix and hartson, 1993a). most researchers and practitioners also agree that an interaction development process must be iterative, unlike the phaseoriented òwaterfalló method, for example, for software development. although software can be correctness driven, userinteraction designñbecause of infinite design possibilities and unpredictable, dynamic, and psychological aspects of the human userñmust beselfcorrecting. thus, interaction development is an essentially iterativeprocess of design and evaluation, one that must, in the end, be integratedwith other system and software life cycles. within this cycle, the interaction design is an iteratively evolving design specification for the userinterface software. the star life cycle (hartson and hix, 1989) for interaction development explicitly acknowledges these differences from software development, being unequivocally iterative, and allows the processto start with essentially any development activity and proceed to anyother activity before the previous one is completed, with each activityinforming the others.development activitiesdesign and design representationdesign is closely coupled to, and driven by, early systems analysisactivities such as needs, task, and functional analyses. good interactiondesign involves early and continual involvement of representative usersand is guided by wellestablished design guidelines and principles builton the concept of usercentered design (norman and draper, 1986). design guidelines address such issues as consistency, use of realworld metaphors, human memory limits, screen layout, and designing for user errors. additionally, designers are expected to follow style guides (lessoriented toward usability than toward compliance with some òstandardóstyle) in their use of widgets.although some more recent guidelines enjoy the support of empiricalstudies, guidelines have typically been scattered throughout the literature, based mostly on experience and educated opinion. in a classic work,smith and mosier (1986) compiled guidelines for charactercell, textualinterface design. others (mayhew, 1992; shneiderman, 1992) have followed to help cover graphical interfaces.many practitioners believe it is enough to know and use interfacedesign guidelines, possibly in addition to an interface style guide (e.g., forwindows). experience, however, has shown that guidelines and stylemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d229guides do not eliminate the need for usability evaluation. experience hasalso demonstrated that, although guidelines are not difficult to learn asfactual knowledge, their effective application in real design situations is askill acquired only through long experience.the creative act of design must also be accompanied by the physicalact of capturing and documenting that design. although many constructional techniques exist for representing software aspects of interface objects, behavioral representation techniques are needed for communicating,among developers, the interaction design from a behavioral task and userperspective. the user action notation (uan) is one such technique(hartson et al., 1990; hartson and gray, 1992). the uan is a user andtaskoriented notation that describes the behavior of a user and an interface during their cooperative performance of a task. the primary abstraction of the uan is a user taskña user action or group of temporallyrelated user actions performed to achieve a work goal. a user interactiondesign is represented as a quasihierarchical structure of asynchronoustasks. user actions, interface feedback, and internal state information arerepresented at various levels of abstraction in the uan. in addition todesign representation, design rationale (maclean et al., 1991) is capturedto record and communicate the history and basis for design decisions, toreason about designs, and to explore alternatives.prototypingrapid prototypes of interaction design are early and inexpensive vehicles for evaluation that can be used to identify usability problems in aninteraction design before resources are committed to implementing thedesign in software. much interest has been focused on lowfidelity prototypes (e.g., paper and pencil). counter to intuition, lowfidelity prototypes have allowed developers to discover as many usability problems asfound using interactive computerbased prototypes (virzi et al., 1996).paper prototypes are most useful early in the life cycle because they aremore flexible in exploring variations of interaction behavior at a cost ofless fidelity in appearance. later in the life cycle, changes made to thebehavior of a coded prototype are more expensive than changes made inappearance. almost all projects eventually move to computerbased rapidprototypes for formal usability evaluation.userbased evaluationsummative evaluation is used to make judgments about a finished product, to gauge the level of usability achieved and possibly compare onesystem with another. in contrast, formative evaluationñthe heart of themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.230more than screen deepstar life cycleñis used to detect and fix usability problems before theinteraction design is coded in software (hix and hartson, 1993a,b; nielsen,1993), aiding in the improvement of an interaction design while a productis still being developed. for formative evaluation, unlike summativeevaluation, statistical significance is not an issue. formative evaluationrelies on both quantitative and qualitative data. the quantitative data areused as a gauge for the processñto be sure usability is improving witheach design iteration and to know when to stop iterating. borrowing anadage from software engineering (and probably other places before that),òif you canõt measure it, you canõt manage it.ó the instruments used toquantify usability include benchmark tasks and user questionnaires.benchmark tasks, drawn from representative and missioncritical tasks,yield objective user performance data, such as time on task and error rates(whiteside et al., 1988). questionnaires yield subjective data such as usersatisfaction (chin et al., 1988). in analyzing quantitative data, results arecompared against preestablished usability specifications (whiteside et al.,1988)ñoperationally defined and measurable goals used as criteria forsuccess in interaction design.even more valuable than these quantitative data are the qualitativedata gathered in usability evaluations. identification of critical incidentsñoccurrences in task performance that indicate a usability problemñareessential in pinpointing design problems. verbal protocol (capturing usersõ thinking aloud) helps designers understand what was going througha userõs mind when a usability problem occurred, which may help inascertaining its causes and in offering useful solutions.these quantitative and qualitative data typically come from labbasedevaluations involving users as òsubjects.ó while very effective, this process can be expensive. the need for faster, less costly usability methodshas led to approaches, such as discount usability engineering (nielsen, 1989),that trade off lessthanperfect and complete results for a lower cost. inspection methods (nielsen and mack, 1994) use systematic examinations ofdesign representations, prototypes, or software products. cognitivewalkthroughs (lewis et al., 1990; wharton et al., 1992) and claims analysis(carroll and rosson, 1992) are effective inspection methods, especiallyearly in development, but can still be labor intensive and require specialtraining, which is intimidating to developers in search of costeffectivemethods. heuristic evaluation (nielsen and molich, 1990; nielsen, 1992),which involves reviewing compliance of an interaction design to a checklist of selected and generalized guidelines, is an even less expensive inspection method but is limited by the scope of guidelines used.inspection methods are effective at finding some kinds of usabilityproblems but do not reliably pinpoint all types of problems that can bemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d231observed in labbased testing. in fact, labbased usability evaluation remains the yardstick against which most new methods are compared informal studies. most realworld development organizations continue tobe willing to pay the price for extensive labbased usability evaluationbecause of its effectiveness in helping them identify and understand usability problems, their causes, and solutions.usability engineeringmany hci practices, such as the employment of usability specifications and various kinds of evaluation, have been gathered under the banner of usability engineering (nielsen, 1993). this is a good appellationbecause it includes a concern for cost in the notion of discount usabilitymethods (nielsen, 1989), the practical goal of achieving specifications andnot perfection, and techniques for managing the process. the latter isimportant because iterative processes are sometimes perceived by management as ògoing around in circles,ó which is not attractive to a managerwith a limited budget and dwindling production schedule.usability specifications provide this essential management controlfor the iterative process. the quantitative usability data are analyzed ineach iteration, and the results are compared with the usability specifications, allowing management to decide if iteration can stop. if the specifications are not met, data are assessed to weigh cost and severity or importance of each usability problem, assigning a priority ranking for designingand implementing solutions to those problems that, when fixed, will givethe largest improvement in usability for the least cost.development toolsalmost any software package that provides support for the interfacedevelopment process can be called an interface development tool, a genericterm referring to anything from a complete interface development environment to a single library routine (myers, 1989, 1993). new software tools foruser interface development are appearing with increasing frequency.interface development tools can be divided into at least four types(hix and hartson, 1993a). toolkits are libraries of callable routines forlowlevel interface features and are often integrated with window managers (e.g., x,windows) interface style support tools are interactive systemsthat enforce a particular interface style and/or standards (e.g., osf motif,common user access). user interface management systems (uims) are development environments that can include both prototyping and runtimesupport, with the goal of allowing developers to produce an interfacemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.232more than screen deepimplementation without using traditional programming languages. ofthese groups, the uimss perhaps are the most interesting, have the mostpotential, and suffer the most difficult technical problems (myers, 1995).these first three categories of development tools primarily addressuser interface software. a fourth category, interaction development tools,provides interactive support for user interaction development. of all theinteraction development activities, the one most commonly supported bytools in this group is formative evaluation (macleod and bevan, 1993; hixand hartson, 1994).although tools now exist on many programming platforms to lay outobjects of a user interface quickly and easily, usability problems are notnecessarily addressed by adding this kind of technology to the process;many interface development tools are potentially a faster way to producepoor interfaces.cost justificationeconomic justification for usability effort in interactive system development is now beginning to be established (bias and mayhew, 1994).broad acceptance in business and industry requires further demonstration of a return on investment; documented cases and success stories areessential. the bottom line is that usability engineering does not add tooverall cost, for two reasons: (1) usability does not add as much cost to thedevelopment process as many people think, and (2) good usability savesmany other costs.considering cost added to the process, one must realize that anyadded cost is confined. interaction development is a small part of totalsystem development. it occurs early in the process, when the cost ofmaking changes is still relatively low, and mainly impacts only a prototype, not the final system software.considering the cost savings attributable to good usability, it is easyto establish that poor usability is costly and that good usability is all aboutlowering costs. usability is simply good business. the most expensiveoperational item in an interactive system is the user. people who developsoftware are concerned with the cost of development, but the people whobuy and use a software application are concerned with the costs of usage.development costs are mostly onetime costs, while operational costsñsuch as training, productivity losses, help desks and field support, recovery from user errors, dissatisfied employees, and system maintenancecosts (the cost of trying to fix problems after release)ñaccrue for years.unless the net of analysis is cast broadly enough, the problem withcostbenefit analysis is that one group pays development costs and another group gets the benefits. people who purchase computer systemsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d233are asking which costs more: userbased tasks that are quick, efficient,and accurate or errorprone tasks that take more time? confused users orconfident and competent users?beyond this kind of argumentation, used in software engineering foryears, substantial measurable economic advantage can be accrued from usability. case studies have demonstrated that large sums of real money can besaved by increasing user (employee) productivity alone (bias and mayhew,1994). in the end, these are the cases that will make the difference.the futurehci is a relatively young and broadly diverse field with a rapidlygrowing impact on the world of computing. usability, especially in everycitizen interfaces, is becoming recognized as crucial for the nationalinformation infrastructure. the future of hci in this context can beviewed from a perspective of product and process.future of hci in productsa rich part of the future of hci is in its application areas, which aregrowing more rapidly than the hci methods needed for their development. as an example, it is unlikely that usability methods developed fordesktop applications will apply directly to virtual environments, one ofthe most exciting areas of applications development. despite intense andwidespread research in virtual environments, very little work has beenapplied toward developing the usability methods that will be required toevaluate this new technologyña necessary coupling if virtual environments are to reach their full potential. similarly, groupware and computersupported cooperative work (baecker, 1993; grudin, 1994), multimedia (blattner and dannenberg, 1992), hypermedia, and interface accessfor the disabled or impaired persons (williges and williges, 1995) willrequire development of new methods for design and usability evaluation.educational technology for the classroom, the world wide web, and thehome is emerging as a giant application area. perhaps nowhere is usability more important than in the discipline of education, where understanding and communication of concepts and ideas are the stock and trade.finally, the internet, the world wide web, and cyberspace are incredibly fastgrowing application domains bringing new kinds of usabilitychallenges. the world wide web is a technological and sociologicalfrontier with many analogies to the frontier that was the american westover a century agoñlawlessness and disorganization, with explorationand expansion in every direction.studies show that users having trouble with an interactive system oftenmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.234more than screen deepcannot find solutions in user manuals or from online help; they are morelikely to ask a friend, colleague, or coworker for help. this strategy canwork in a local setting where there are other users. however, users of thenational information infrastructure will often be remote and distributed,using a network as their work setting. for these isolated users, who are lessable to tolerate poor user interfaces and who will abandon applicationsthey find too difficult to learn and use, there is often no one to ask whenthings go wrong at the computer, and usability will have a large impact ontheir productivity and satisfaction. for this largescale environment withits diversity of user types and characteristics, its variety of application types,and potential user isolation, usability takes on special importance.additionally, the interaction styles and techniques of future productscan be expected to expand beyond the currently ubiquitous wimpñwindows, icons, menus, pointersñor desktopstyle interface. while wimpinterfaces have provided a great step forward for interfaces in static situations (e.g., word processing, spreadsheets), innovative interaction techniques that go beyond the wimp paradigm are necessary to meet userinterface needs of demanding, realtime, highperformance applicationssuch as those found in military applications, medical systems, òsmartroadó applications, and so on. researchers are promoting a greatly expanded vision of interaction beyond the limited interaction styles nowavailable via just keyboard and mouse, including extensions to currentwork in graphic and visual displays (mullet and sano, 1995), use of handsand feet (buxton, 1986), eye movement (jacob, 1993), haptic (touch) feeland force feedback (baecker et al., 1995), audio and sound (brewster et al.,1993; gaver and smith, 1995), voice (mccauley, 1984), and stylus andgesture (goldberg and goodisman, 1995).finally, many technology forecasters have predicted that the mostsignificant area of future applications may be computing embedded inappliances, homes, offices, vehicles, and roads. sometimes called wearablecomputers, these devices can be strapped to oneõs wrist or embedded in ashoe! a recent television news feature (cnn news, july 1996) describeda project at massachusetts institute of technology in which a pair of shoeswill, indeed, be instrumented so that, as the wearer gets milk out forbreakfast, sensors will note that the milk supply is getting low! approaching the grocery store on the way home, the system speaks via atiny earphone to remind the shoeõs wearer of the need to pick up somemilk.the requirements for usability of desktop and other familiar systemswill pale in comparison to the importance of usability in this new era ofcomputing. that òevery citizenó will not tolerate training courses, usermanuals, or online help to operate everyday objects such as refrigeratorsand automobiles will compel designers to take seriously their responsibilmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d235ity for usability. issues of social impact carry high risks if this kind ofeverycitizen interface is threatening, intimidating, or difficult to use. insuccessful designs the computing component will be transparent, withusers not even thinking of themselves as users of computers. when human factors was first adapted to user interfaces (e.g., williges et al., 1987),ergonomics was largely filtered out. interestingly, new devices, combining hardware, software, and firmware as òappliances,ó will require a reintegration of ergonomics as a part of usability.future of hci processesdevelopers of future hci processes will struggle to keep pace withthese new application areas and interaction styles. one area that is already changing among realworld system developers is the representation of roles and skills in interactive system development teams. usability specialists, human factors engineers, and hci practitioners are startingto take their longoverdue places alongside systems analysts and software engineers. these new roles imply the need for new kinds of trainingin hci methods. these roles have already begun to be joined by thosewith technical writing and documentation skills and especially by thosewith graphics and visual design skills (tufte, 1983; mullet and sano,1995)ñfor example, to use color effectively (shubin et al., 1996) and todesign icons, avatars, and rendered images.it is also expected that a significant increase in future hci activity willbe applied to developing new methods. there is an ongoing need for newhighimpact usability evaluation methods. high impact means cost effective, applicable to a wide variety of application types (e.g., world wideweb applications), applicable to many new interaction styles (e.g., virtualenvironments), and suitable for gathering usability data from remote anddistributed user communities.among the approaches to remote evaluation emerging now, most areeither limited to subjective user feedback (abelow, 1993) or require expensive bandwidth to support video conferencing as an extension of theusability lab (hammontree et al., 1994). a method based on userassistedcritical incident gathering (hartson et al., 1996) has been proposed tobypass the bandwidth requirements for fulltime video transmission andto cut analysis costs.methods and software support tools are also in demand for boostingreturn on investment of resources committed to usability evaluation.koenemannbelliveau et al. (1994, p. 250) have articulated this need: òweshould also investigate the potential for more efficiently leveraging thework we do in empirical formative evaluationñways to ôsaveõ somethingfrom our efforts for application in subsequent evaluation work.ó most ofmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.236more than screen deepthe time results from usability evaluation are applied only to specificusability problems in a single design. database tools for informationmanagement of the results would accrue immediate gains in effectiveusability problem reporting (jeffries, 1994; pernice and butler, 1995). moresignificantly, a usability database tool would afford some òmemoryó tothe process, amortizing, through reuse of analysis, the cost of resultsacross design iterations and across multiple products and projects. beyond organizational boundaries, a collective usability database couldserve as a commonly accessible repository of a science base for the hcicommunity and as a practical knowledge base for exemplar usability problems, solutions, and costs.the future of hci is both exciting and challenging. in moving beyondguis and in developing new methods, problems continue to increase. butthe promise of these new products and processes will come to fruition in anevery citizen interface for the national information infrastructure.acknowledgmentmany thanks to dr. deborah hix, of virginia tech, for her help inproviding inputs and in reading this paper.referencesabelow, d. (1993). automating feedback on software product use. case trends, 1517.baecker, r. m. (ed.). (1993). readings in groupware and computersupported cooperative work:assisting humanhuman collaboration. san francisco: morgankaufmann.baecker, r. m., grudin, j., buxton, w. a. s., and greenberg, s. (1995). touch, gesture, andmarking. in r. m. baecker, j. grudin, w. a. s. buxton, and s. greenberg (eds.),readings in humancomputer interaction: toward the year 2000. san francisco: morgankaufmann, 469482.barnard, p. (1993). the contributions of applied cognitive psychology to the study of humancomputer interaction. in r. m. baecker, j. grudin, w. a. s. buxton, and s. greenberg(ed.), readings in human computer interaction: toward the year 2000. san francisco: morgankaufmann, 640658.bias, r. g. and mayhew, d. j. (eds.). (1994). cost justifying usability. boston: academic press.blattner, m. m. and dannenberg, r.b. (eds.). (1992). multimedia interface design. new york:acm press.bodker, susanne. (1991). through the interface: a human activity approach to user interfacedesign. hillsdale, nj: lawrence erlbaum associates.brewster, s. a., wright, p. c., and edwards, a. d. n. (1993). an evaluation of earcons for usein auditory humancomputer interfaces. proceedings of interchi conference on humanfactors in computing systems. new york: acm press, 222227.butler, k. a. (1996). usability engineering turns 10. interactions (january), 5875.buxton, w. (1986). thereõs more to interaction than meets the eye: some issues in manualinput. in d. a. norman and s. w. draper (ed.), user centered system design. hillsdale,nj: lawrence erlbaum associates, 319337.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d237card, s. k. and moran, t. p. (1980). the keystrokelevel model for user performance timewith interactive systems. communications of the acm, 23, 396410.card, s. k., moran, t. p., and newell, a. (1983). the psychology of humancomputer interaction.hillsdale, nj: lawrence erlbaum associates.carroll, j. m. (1984). minimalist design for active users. proceedings of humancomputer interactionñinteract ô84, september, amsterdam: northholland, 3944.carroll, j. m. (ed.). (1995). scenariobased design: envisioning work and technology in systemdevelopment. new york: john wiley and sons, inc.carroll, j. m., kellogg, w. a., and rosson, m. b. (1991). the taskartifact cycle. in j. m.carroll (ed.), designing interaction: psychology at the humancomputer interface. cambridge, england: cambridge university press, 74102.carroll, j. m. and rosson, m. b. (1992). getting around the taskartifact cycle: how to makeclaims and design by scenario. acm transactions on information systems, 10, 181212.chin, j. p., diehl, v. a., and norman, k. l. (1988). development of an instrument measuringuser satisfaction of the humancomputer interface. proceedings of chi conference onhuman factors in computing systems, may 1519, new york: acm, 213218.diaper, d. (ed.). (1989). task analysis for humancomputer interaction. chichester, england:ellis horwood limited.draper, s. w. and barton, s. b. (1993). learning by exploration and affordance bugs. proceedings of interchi conference on human factors in computing systems (adjunct). new york:acm, 7576.ehn, p. (1990). work oriented design of computer artifacts (2nd ed.). hillsdale, nj: lawrenceerlbaum associates.foley, j. d. and wallace, v. l. (1974). the art of natural graphic manmachine conversation.proceedings of the ieee, 63(4), 462471.foley, j. d., van dam, a., feiner, s. k., and hughes, j. f. (1990). computer graphics: principlesand practice. reading, ma: addisonwesley.gaver, w. w. and smith, r. b. (1995). auditory icons in largescale collaborative environments. in r. m. baecker, j. grudin, w. a. s. buxton, and s. greenberg (eds.), readings inhumancomputer interaction: toward the year 2000. san francisco: morgankaufmann,564569.goldberg, d. and goodisman, a. (1995). stylus user interfaces for manipulating text. in r. m.baecker, j. grudin, w. a. s. buxton, and s. greenberg (eds.), readings in humancomputerinteraction: toward the year 2000. san francisco: morgankaufmann, 500508.gould, j. d., boies, s. j., and lewis, c. (1991). making usable, useful, productivityenhancingcomputer applications. communications of the acm, 34(1), 7485.gray, w. d., john, b. e., stuart, r., lawrence, d., and atwood, m. (1990). goms meets thephone company: analytic modeling applied to realworld problems. proceedings ofinteract ô90ñthird ifip conference on humancomputer interaction, august 2731,amsterdam: northholland elsevier science publishers.grudin, j. (1994). groupware and social dynamics: eight challenges for developers. communications of the acm, 37(1), 92105.hammond, n., gardiner, m. m., christie, b., and marshall, c. (1987). the role of cognitivepsychology in userinterface design. in m. m. gardiner and b. christie (eds.), applyingcognitive psychology to userinterface design. chichester: wiley, 1353.hammontree, m., weiler, p., and nayak, n. (1994). remote usability testing. interactions(july), 2125.harrison, m. and thimbleby, h. (ed.). (1990). formal methods in humancomputer interaction.cambridge, england: cambridge university press.hartson, h. r. and gray, p. d. (1992). temporal aspects of tasks in the user action notation.humancomputer interaction, 7, 145.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.238more than screen deephartson, h. r. and hix, d. (1989). toward empirically derived methodologies and tools forhumancomputer interface development. international journal of manmachine studies,31, 477494.hartson, h. r., siochi, a. c., and hix, d. (1990). the uan: a useroriented representation fordirect manipulation interface designs. acm trans. inf. syst., 8(3), 181203.hartson, h. r., castillo, j. c., kelso, j., kamler, j., and neale, w. c. (1996). remote evaluation:the network as an extension of the usability laboratory. proceedings of chi conference onhuman factors in computing systems. new york: acm, 228235.hix, d. and hartson, h. r. (1993a). developing user interfaces: ensuring usability throughproduct and process. new york: john wiley and sons.hix, d. and hartson, h. r. (1993b). formative evaluation: ensuring usability in user interfaces. in l. bass and p. dewan (eds.), trends in software, volume 1: user interface software.new york: wiley, 130.hix, d. and hartson, h. r. (1994). ideal: an environment for usercentered developmentof user interfaces. proceedings of ewhciõ94: fourth eastwest international conference onhumancomputer interaction, 195211.hutchins, e. l., hollan, j. d., and norman, d. a. (1986). direct manipulation interfaces. in d.a. norman and s. w. draper (eds.), user centered system design. hillsdale, nj: lawrenceerlbaum associates, 87124.jacob, r. j. k. (1993). eyemovementbased humancomputer interaction techniques: toward noncommand interfaces. in h. r. hartson and d. hix (eds.), advances in humancomputer interaction. norwood, nj: ablex, 151190.jeffries, r. (1994). usability problem reports: helping evaluators communicate effectivelywith developers. in j. nielsen and r. l. mack (eds.), usability inspection methods. newyork: john wiley and sons, inc., 273294.kieras, d. e. (1988). towards a practical goms model methodology for user interface design.in m. helander (ed.), handbook of humancomputer interaction. elsevier science publishers b. v., 135157.kieras, d. and polson, p. g. (1985). an approach to the formal analysis of user complexity.international journal of manmachine studies, 22, 365394.koenemannbelliveau, j., carroll, j. m., rosson, m. b., and singley, m. k. (1994). comparativeusability evaluation: critical incidents and critical threads. proceedings of chi conference on human factors in computing systems. new york: acm, 245251.lecompte, m. d. and preissle, j. (1993). ethnography and qualitative design in educationalresearch (2nd ed.). san diego: academic press.lewis, c., polson, p., wharton, c., and rieman, j. (1990). testing a walkthrough methodologyfor theorybased design of walkupanduse interfaces. proceedings of chi conference onhuman factors in computing systems, april 15, new york: acm, 235242.mackenzie, s. (1992). fittsõ law as a research and design tool in humancomputer interaction. humancomputer interaction, 7, 91139.maclean, a., young, r. m., bellotti, v. m. e., and moran, t. p. (1991). questions, options, andcriteria: elements of design space analysis. humancomputer interaction, 6, 201250.macleod, m. and bevan, n. (1993). music video analysis and context tools for usabilitymeasurement. proceedings of interchi conference on human factors in computing systems, april 2429. new york: acm, 55.mayhew, d. j. (1992). principles and guidelines in software user interface design. englewoodcliffs, nj: prenticehall.mccauley, m. e. (1984). human factors in voice technology. in f. a. muckler (ed.), humanfactors review. santa monica, ca: human factors society, 131166.meister, d. (1985). behavioral analysis and measurement methods. new york: wiley.moran, t. p. (1981). the command language grammar: a representation for the user intermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.trends in humancomputer interaction r&d239face of interactive computer systems. international journal of manmachine studies, 15, 351.muller, m. j. (1991). pictiveñan exploration in participatory design. proceedings of chiconference on human factors in computing systems, april 27may 2. new york: acm, 225231.mullet, k. and sano, d. (1995). designing visual interfaces. mountain view, ca: sunsoft press.myers, b. a. (1989). userinterface tools: introduction and survey. ieee software, 6 (1), 1523.myers, b. a. (1993). state of the art in user interface software tools. in h. r. hartson and d.hix (eds.), advances in humancomputer interaction. norwood, nj: ablex.myers, b. a. (1995). state of the art in user interface software tools. in r. m. baecker, j.grudin, w. a. s. buxton, and s. greenberg (eds.), readings in humancomputer interaction: toward the year 2000. san francisco: morgankaufmann, 323343.nielsen, j. (1989). usability engineering at a discount. in g. salvendy and m. j. smith (eds.),designing and using humancomputer interfaces and knowledgebased systems. amsterdam:elsevier science publishers, 394401.nielsen, j. (1992). finding usability problems through heuristic evaluation. proceedings ofchi conference on human factors in computing systems, may 3  7. new york: acm, 373380.nielsen, j. (1993). usability engineering. san diego: academic press. inc.nielsen, j. and mack, r. l. (ed.). (1994). usability inspection methods. new york: john wileyand sons.nielsen, j. and molich, r. (1990). heuristic evaluation of user interfaces. proceedings of chiconference on human factors in computing systems, april 15. new york: acm, 249256.norman, d. a. (1986). cognitive engineering. in d. a. norman and s. w. draper (eds.), usercentered system design. hillsdale, nj: lawrence erlbaum associates, 3161.norman, d. a. and draper, s. w. (eds.). (1986). user centered system design: new perspectiveson humancomputer interaction. hillsdale, nj: lawrence erlbaum associates.payne, s. j. (1991). displaybased action at the user interface. international journal of manmachine studies, 35, 275289.pernice, k. and butler, m. b. (1995). database support for usability testing. interactions (january), 2731.shneiderman, b. (1983). direct manipulation: a step beyond programming languages. ieeetransactions on computers, 16(8), pp. 5769.shneiderman, b. (1992). designing the user interface: strategies for effective humancomputerinteraction (2nd ed.). reading, ma: addisonwesley.shubin, h., falck, d., and johansen, a. g. (1996). exploring color in interface design. interactions (july/august), 3648.smith, s. l. and mosier, j. n. (1986). guidelines for designing user interface software (esdtr86278/mtr 10090). mitre corporation.tufte, e. r. (1983). the visual display of quantitative data. cheshire, ct.: graphics press.virzi, r. a., sokolov, j. l., and karis, d. (1996). usability problem identification using bothlow and highfidelity prototypes. proceedings of chi conference on human factors incomputing systems. new york: acm, 236243.weller, h. g. and hartson, h. r. (1992). metaphors for the nature of humancomputerinteraction in an empowering environment: interaction style influences the manner ofhuman accomplishment, 8(3), 313333.wharton, c., bradford, j., jeffries, r., and franzke, m. (1992). applying cognitivewalkthroughs to more complex user interfaces: experiences, issues, and recommendations. proceedings of chi conference on human factors in computing systems, may 3  7,new york: acm, 381388.whiteside, j., bennett, j., and holtzblatt, k. (1988). usability engineering: our experience andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.240more than screen deepevolution. in m. helander (ed.), handbook of humancomputer interaction. amsterdam:elsevier northholland, 791817.williges, r. c. and williges, b. h. (1995). travel alternatives for the mobility impaired: thesurrogate electronic traveler (set). in a. d. n. edwards (ed.), extraordinary humancomputer interaction: interfaces for users with disabilities. new york: cambridge university press, 245262.williges, r. c., williges, b. h., and elkerton, j. (1987). software interface design. in g. salvendy(ed.), handbook of human factors. new york: john wiley and sons, 14161449.wixon, d., holtzblatt, k., and knox, s. (1990). contextual design: an emergent view ofsystem design. proceedings of chi conference on human factors in computing systems,april 15. new york: acm, 329336.additional readingrepresentative supplementary references here are chosen for breadth.cited references also are representative but not all are repeated here.acm. (1990). resources in humancomputer interaction. new york: acm press.baecker, r. m. and buxton, w. a. s. (eds.). (1987). readings in humancomputer interaction: amultidisciplinary approach. san francisco, morgankaufmann.baecker, r. m., grudin, j., buxton, w. a. s., and greenberg, s. (eds.). (1995). readings inhumancomputer interaction: toward the year 2000. san francisco: morgankaufmann.carroll, j. m. (ed.). (1987). interfacing thought: cognitive aspects of humancomputer interaction.cambridge, ma: the mit press.carroll, j. m. (ed.). (1991). designing interaction: psychology at the humancomputer interface.cambridge, england: cambridge university press.hartson, h. r. and hix, d. (1989). humancomputer interface development: concepts andsystems for its management. acm comput. surv., 21(1), 592.helander, m. (ed.). (1988). handbook of humancomputer interaction. amsterdam: northholland.monk, a. f. and gilbert, n. (1995). perspectives on hciñdiverse approaches. cambridge, england: cambridge university press.olson, j. r. and olson, g. m. (1990). the growth of cognitive modeling in humancomputerinteraction since goms. humancomputer interaction, 5, 221265.preece, j., rogers, y., sharp, h., benyon, d., holland, s., and carey, t. (1994). humancomputerinteraction. reading, ma: addisonwesley.rubin, j. (1994). handbook of usability testing. new york: john wiley and sons.thimbleby, h. (1990). user interface design. new york: acm press/addisonwesley.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary241part 2position papersmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.242more than screen deepmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics243243on interface specificsan embedded, invisible, everycitizen interfacemark weiserxerox palo alto research centerthe nationõs information infrastructure is a vast, loosely connectednetwork of informing resources found mostly in peopleõs everyday lives.when considering interfaces to new electronic information sources, andespecially when replacing old information sources with new electronicsources, it is crucial to consider how the existing infrastructure reallyworks. two examples will help.consider how you would find a grocery store in a new town. how doyou solve this problem on first driving in? most likely, by looking around,watching the people and the streets, and making a couple of guesses, youcould find one in no time. the information infrastructure is everydayknowledge of towns (including economic and practical constraints onlayout, walking distances, etc., that are embedded in that knowledge),and physical clues that map that general knowledge into this particulartown. information infrastructure can be physical (see www.itp.tsoa.nyu.edu/~review/current/focus2/open00.html).more conventionally, our national information infrastructure todayincludes tens of thousands of public and school libraries all across thecountry. these libraries are in nearly every elementary, junior high, andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.244more than screen deephigh school; and they are in nearly every community, even the very small.of course, many of these libraries are connected to the internet. but it isvery important to consider the other resources provided by these libraries. thirtyfive percent of all library visitors never use the catalog, and 12percent use no library materials at all, but bring in their own materials.clearly, libraries do something more than just supply data that could begotten over the web (see www.ubiq.com/weiser/situationalaspectsofelectroniclibraries.html).as the above examples illustrate, the existing information infrastructure often functions without calling itself to our attention. it stays out ofsight, effectively not even noticed. so the first challenge for everycitizeninterface is to be invisible (what i have called òcalm technologyó elsewhere; see www.ubiq.com/weiser/calmtech/calmtech.htm).as the above examples also illustrate, the existing information infrastructure is extremely widespread, found in every nook and cranny of ourlives. the second challenge for the everycitizen interface is to be ubiquitous (see www.ubiq.com/ubicomp).finally, not addressed by the above examples but presumably clear toeveryone, the current internet is just the beginning. i like to think of it byanalogy to television channels. once upon a time we fretted about howwe would manage a tv with 500 channels. how could we ever viewthem all? the internet will give us 5 billion channels, one for everyperson on the planetñonly about 30 million so far, but more are coming.and soon these channels will be multimedia, multiway video and soundusing the mbone. this kind of interconnection is a deep technical challenge to the current web infrastructure, which cannot begin to supporteven a few multiway mbone connections, much less 5 billion. i considerthis to be a user interface issue because it is just this infrastructure thatopens up the web to use by anyone who can point a camera or talk on thephone. the third challenge for the everycitizen interface is to supportbillions of multiway realtime interactive connections.of these three challenges i believe that the first is currently the mostpromising of progress, the one most susceptible to interdisciplinary attack, and the one least well addressed by existing projects. how does atechnology become invisible? to some degree, anything can, givenenough practice. invisibility is a property of people, technology, and thesituation in which we find ourselves (a tiger invisible in the tall grassstands out at the zoo).some suggested challenges for developing a òscience of invisibilityófor a every citizen interface are as follows:¥human information processing includes operations at many different levels, the vast majority of them invisible to our conscious thoughtmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics245at any given moment. as we learn a skill, operations that formerly required attention (òturn the steering wheeló) become automatic and arereplaced by higher level directions (òturn left,ó òdrive to cincinnatió).invisible interfaces are those that connect òbelowó the conscious level,through both learning and natural affinity. what computer interfaces aremost appropriate for coupling into a large amount of unconscious information processing? which ones take a long time to learn but are worththe effort (analogous perhaps to piano playing)? which ones fit ourbrainõs affinity for information (information browsing as a walk in thewoods)?¥the difference between something being effectively invisible because it is being processed below conscious thought and something beingmanaged for us (e.g., by a computerized agent) is profound. a key advantage of effective invisibility is the quick refocus from peripheral inattention to center attention. for instance, while ordinarily unaware ofengine noises in our car, we suddenly become very aware if the noiseshould change unexpectedly. we can then focus our attention on thenoise and make decisions about its danger, the distance to the nearestexpressway exit, what lane to be in, and so on. (a silent car with anintelligent agent monitoring engine condition would keep us from anyknowledge at all.) which computer interfaces do well at keeping something invisible most of the time, but allowing quick recentering whenappropriate? which interfaces let the same information be either in thecenter of our attention or in the periphery without even clicking a buttonbut simply changing our attention?¥the concept of an intelligent agent can be a very powerful one if itdoes not take over the function of human judgment and our ability tocontrol the focus of our attention. can we design intelligent agents in ourcomputers that preserve our ability to refocus? if something has been takenover for me, is there a presentation of what has been taken over that i canbring to the fore whenever i like, including retroactively? can i have agentsthat filter for me without losing all of the context of the information after thefilter? for instance, if i use a computerized newspaper clipping service, canit show me one or two lines of articles that were physically near the ones itclipped for me in the physical newspaper? what kind of context helps, andwhat doesnõt help, when dealing with a computerized agent?more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.246more than screen deepintelligent multimedia interfaces foròeachó citizenmark t. mayburymitre corporationfuture interfaces will take advantage of knowledge of the user, task,and discourse and exploit multiple input/output media and associatedhuman sensory modalities to enable intuitive access to information, tools,and other people (see figure 1). the more effectively computers canprocess heterogeneous information and automatically acquire knowledgeabout users, the more efficient they will become at supporting usersõfrequently changing tasks, particularly informationseeking ones. informationseeking tasks range from directed search to casual browsing, fromlooking up facts to predicting trends. each of these goals can be achievedmore or less effectively by the content, form (i.e., media), and environment that support the user. our emphasis at mitre corporation has beenon investigating technologies and tools that enable more effective andefficient information interfaces for a variety of application areas, including command and control, intelligence analysis, and education and training. as a consequence of our experience, we believe we should aim not tofigure 1intelligent interfaces.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics247build a oneofakind interface for every citizen, but rather common interfaces that can be tailored to each citizen in accordance with his or hergoals, knowledge, skills, and preferences.challengesachieving an intelligent interface vision requires addressing somefundamental technology limitations, including:¥lack of a scientific approach to device and user interface design,development, and evaluation.¥lack of interface standards that make it easy to pull out one deviceand plug in a similar one.¥lack of general mechanisms for (1) interpreting input from multiple devices (e.g., mouse gesture and speech, as in òput that there<click>ó) and (2) automatic generation of coordinated multimedia output.¥lack of general mechanisms for constructing dialoguebased interaction that supports error detection and correction, user models, anddiscourse models to ensure tailored and robust communication.¥few tools or procedures that facilitate porting languageenabledinterfaces to new domains (and/or languages); it remains a timeconsuming and knowledgeintensive task.we believe there exist fundamental tasks associated with communication that underlie all interface activities. these can be viewed as ahierarchy of communicative acts, which can be formalized and computationally implemented and by their nature can be realized in multiplemodalities (e.g., linguistic/auditory, gestural, visual). the choice amongmodalities itself is an important, knowledgebased task, as is the broadertask of presentation planning.in supporting information access, our efforts have focused on multimedia analysis (in particular, message understanding and video analysis), including its segmentation into atomic units, extraction of objects,facts and relationships, and summarization into compact form. new requirements have arisen (e.g., resulting in multimedia query mechanismsthat raise issues such as how to integrate visual and linguistic queries).multimedia informationseeking tasks remain perhaps the most important but least well understood area. we believe that careful experimentaldesign, use of instrumented environments, and taskbased evaluation(e.g., measuring at least time and accuracy (false positives, false negatives)) will yield new insights.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.248more than screen deeptable 1research recommendationsareastate of the artnearterm researchlongterm researchtext processingspeechprocessinggraphicsprocessingimage/videoprocessinggestureprocessingcommercial named entity extraction(sra, bbn); many handcrafted,domainspecific systems for eventextraction; large cost to port tonew domains; incrementalsentence generation, limiteddocument generation.commercial smallvocabularyrecognizers (corona, hark);largevocabulary (40,000+ words)recognizers exist in research labs(bbn, sri, cambridge university).graphical user interface toolkits(e.g., objectoriented, reusablewindow elements such as menus,dialogue boxes).color, shape, texturebased indexingand query of imagery.twodimensional mice; eyetrackers;tethered bodymotion tracking.demonstrate portability of tipstertechnology to support multilingualinformation extraction and spokenlanguage; incremental textgeneration; text summarization;topic detection and tracking.speaker, language, and topicidentification; prosodic analysis;naturalsounding synthesis.tools for automated creation ofgraphical user interface elements;limited research prototypes ofautomated graphics design.motionbased indexing of imageryand video; video segmentation.tetherless, threedimensional gesture,including hand, head, eye, andbodymotion tracking.scaleable, trainable, portablealgorithms; documentlength textgeneration.largevocabulary, speakerindependent systems for speechenabled interfaces; largevocabulary systems for video andradio transcription, for example.automated, modelbased creationand tailoring of graphical userinterfaces.visual information indexing andextraction (e.g., human behaviorfrom video).intentional understanding of gesture;crossmedia correlation (with textand speech processing); facial andbody gesture recognition.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics249multimediaintegrationdiscoursemodelinguser modelingvisualizationcollaborationtoolsintelligentagentslimited prototypes in research andgovernment.limited prototypes in research andgovernment.fragile research prototypes availablefrom academia; oneuser modelingshell (bgpms).some commercial tools (e.g.,netmap), textbased, limitedsemantics; computationallyintensive, often difficult to use.multipoint video, audio, imagery; emailbased routing of tasks.agent communication (e.g., kqml)and exchange languages (e.g., kif).content selection, media allocation,media coordination, media realization for multimedia generation.error handling (illformed andincomplete input/output), twoparty conversational model,discourse annotation schemes,discourse data collection andannotation, conversation tracking.track user focus and skill level tointeract at appropriate level;empirical studies in broad range oftasks in multiple media.improve information access interfaces;visualization generation fromextracted (semantic) information;automated graphical encoding ofinformation properties.instrument environments for datacollection and experimentation;multiparty collaborativecommunication; investigateasynchronous, distant collaboration(e.g., virtual learning spaces).mediation tools for heterogeneousdistributed access.multimedia and multimodalanalysis; multimedia andmultimodal generation;investigation of lessexaminedsenses (e.g., taction, olfaction).context tracking/dialoguemanagement; multiuserconversation tracking, annotationstandards; modelbasedconversational interaction.hybrid stereotypical/personalizedand symbolic/statistical usermodels.multidimensional visualization;multimedia (e.g., text, audio,video) visualization.field experiments to predict impactof collaborative technology oncurrent work processes; tools forautomated analysis of videosession recordings; flexible,workflow automation.shared ontologies; agent integrationarchitectures and/or controllanguages; agent negotiation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.250more than screen deepa plan of actionthere are several important recent developments that promise to enable new common facilities to be shared to create more powerful interfaces. a strategy to move forward should include:¥creating architectures and services of an advanced interfaceserver that are defined in the short term using open standard distributed object middleware, namely the object management groupõs common object request broker architecture (corba), and that investigatehigherrisk architectures, such as agentbased communication and coordination.¥fostering interdisciplinary focused science that investigates thenature of multiple modalities, with an aim to understanding the principles of multiple modalities in order to provide insight into such tasksas multimedia interpretation and the generation of coordinated multimedia output.¥utilizing, refining, integrating, and extending (to additional media) existing architectures for single media, including (1) the tipsterarchitecture (for document detection and information extraction) andassociated tag standards (e.g., penn treebank partofspeech tags, propername tags, coreference annotations) for language source markup and (2)leverage evolving applications programming interface (api) standardsin the spoken language industry (e.g., srapi, sapi).¥via an interdisciplinary process, defining common interface tasksand associated evaluation metrics and methods; creating a multimediacorpora and associated markup standards; and fostering interdisciplinary algorithm design, implementation, and evaluation.¥fostering emerging user modeling shells (e.g., bgpms) andstandards.¥focusing on creation of theoretically neutral discourse modelingshells.¥applying these facilities in an evolutionary fashion to improveexisting interfaces, supporting a migration from òdumbó to òsmartó interfaces (s. bayer, personal communication, 1996).¥performing taskbased, communitywide evaluation to guidesubsequent research, measuring functional improvements (e.g., taskcompletion time, accuracy, quality).because they affect all who interact with computers, user interfacesare perhaps the single area of computing that can most radically alterthe ease, efficiency, and effectiveness of humancomputer interactions.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics251recommended researchtable 1 indicates several functional requirements and associated keytechnologies that need to be investigated to enable a new generation ofhumancomputer interaction, indicating nearterm and farterm researchinvestment recommendations. key areas for research include:¥processing and integrating various input/output media (e.g., text,speech and nonspeech audio, imagery, video, graphics, gesture);¥methods to acquire, represent, maintain, and exploit models ofuser, discourse, and media; and¥mechanisms that can provide information visualization, supportmultiuser collaboration, and intelligent agents.referencemaybury, m.t. (ed.) 1993. intelligent multimedia interfaces. menlo park, calif: aaai/mitpress.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.252more than screen deepinterfaces for understandingnathan shedroffvivid studiosover the next 15 years the issues facing interface designers, engineers, programmers, and researchers will become increasingly complexand push farther into currently abstract and, perhaps, esoteric realms.however, we are not without guidance and direction to follow. ourexperiences as humans and what little history we have with machines canlead us toward our goals.computers and related devices in the future will need to exhibit manyof the following qualities:¥be more aware of themselves (who and what they are, who theyòbelongó to, their relationships to other systems, their autonomy, andtheir capabilities).¥be more aware of their surroundings and audiences (who is there;how many people are present or around; who to òlistenó to; where andhow to find and contact people for help or to follow directions; who is aòregularó; how to adapt to different peopleõs preferences, needs, goals,skills, interests, etc.).¥offer more help and guidance when needed.¥be more autonomous when needed.¥be more able to help build knowledge as opposed to merely process data.¥be more capable of displaying information in richer formsñbothvisually and auditorially.¥be more integrated into a participantõs work flow or entertainment process.¥be more integrated with other mediañespecially traditional media like broadcast and print.funding for research and development, therefore, should concentrateon these issues and their related hardware, software, and understandings. these include research into the following:¥display and visualization systems (highresolution, portable, andlowpower displays; hdtv (highdefinition television) and standards inrelated display industries; integration with input/output devices such asmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics253scanners, pointing devices, and printers; fast processing systems for ndimensional data models; standards for these models, display hardware,and software; software capable of easily configuring and experimentingwith visualizations and simulations; etc.).¥perceptual systems (proximity, sounds, motion, and electronicòeyesó for identification and awareness; standards for formating instructions and specifications to help systems òunderstandó what they are, whatis around them, what and who they can communicate with, and what theyare capable of; facilities for obtaining help when necessary; ways of identifying participants by their behavior, gestures, or other attributes; etc.).¥communications systems (standards, hardware, and software tohelp participants communicate better with each otherñas well as withcomputers; naturallanguage interfacesñspoken and writtenñand translation systems to widen the opportunities of involvement to more people;hardware and software solutions for increasing bandwidth and improving the reliability, security, privacy, and scalability of existing communications infrastructure; etc.).¥understanding of understanding (information and knowledgebuilding applications; understandings about how people create contextand meaning, transform data into information, create knowledge forthemselves, and build wisdom; software to help facilitate these processes;standards to help transmit and share information and knowledge withconnections intact; etc.).¥understanding of interaction (a wider definition of interactionused in the òindustry,ó how participants define and perceiveòinteractivityó; what they expect and need in interactivity; historical examples of interaction; lessons from theater, storytelling, conversation,improvisation, the performing arts, and the entertainment industry; etc.).¥increased education(of both participants and audiences, as wellas professionals, and the industry).¥better resources for understanding cultural diversity (in terms ofgestures, languages, perceptions, and needs of different age, gender, cultural, and nationality groups).in addition, there are some procedural approaches to these undertakings that can help the overall outcomes to be more valuable:¥reduced duplication of research and development by governmentsponsored grants and institutions (requiring the disclosure, sharing, and reporting of research efforts, problems, and solutions).¥more means of coordination and knowledge sharing of researchand development scholars and professionals (whether governmentsponsored or not).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.254more than screen deep¥more adventurous spending in òesotericó research (such as thenature of understanding and the meaning of òinteractivityó).¥grant proposal templates and procedures that are easier to complete (simplified and clarified requirements, less paperwork, less processspecific òinsideó information that requires professional grant writers sothat more adventurous people can apply more easily).where did the òuseró go?although the word òuseró is, admittedly, easy to say and use and hassome history, it is important that our understanding of those using computers is broadened to emphasize growing participatory aspects of computer use. while historically, people input, managed the processing, andoutput data and information, the building of knowledge requires moreparticipation and interaction of the type most closely experienced withother people. people are becoming active audiences and participantsinstead of merely users. they are increasingly communicating with others and creating meaningful things rather than merely òviewingó andwatching.the next 100 million computer users (who may begin using computers over the next 3 years) have different needs and understandings thancurrent users. their needs are different not because of their capabilities(all of these people are capable of learning to use existing systems) butmostly because of differences in their perceptions, interests, and understandings of computers. one important reason why these people are notnow buying or making use of current computers is that, in their minds,computers donõt do much that they are interested in doing. existingcomputers are not capable of or equipped for helping these people enjoy,expand, or make meaning of their lives. this is the reason why homecomputer sales have traditionally been dismal and are currently confinedto homeoffice purchases and for kidsõ educations. fifteen years ago thebest use that computer marketers could come up with for people to buytheir own computers was to balance their checkbooks and store recipes.today, while computers have evolved significantly, many peopleõs perceptions have not, and they understand precious few reasons why computers might enhance the lives of this next òuser group.ó part of this is aneducation issue (and, perhaps, a marketing one), but mostly it is a failureof computer systems (hardware and software) to respond to the needsand interests of the general public.the interface starts much before a computer is turned on. consideran analogy to shopping. the shopping experience does not start themoment a transaction is made (perhaps an item is bought or ordered). itdoesnõt even start when someone walks into a store or browses a catalog.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics255the shopping experience starts when people perceive the need for something, at least, and often before they encounter others shopping, productsand services they do not currently need, and even celebrity athletes sporting brand names on their outfits. likewise, the interface to a computerbegins at the fulfillment of life needs and interests and the education ofthe participants about the capabilities and possibilities of computers andinterfaces. automobiles are often held up as examples of easytolearn,universal interfaces, but in reality they are neither. they take monthsñsometimes yearsñto master, are not standardized, and are sometimesnever learned sufficiently well. yet our understanding of driving a carand its fulfillment of our needs make us persevere.what is a computer?what i mean when i use the word òcomputeró is a specific device forprocessing, storing, and transmitting information, aiding the building ofknowledge, and/or facilitating communications more sophisticated than acurrent telephone. to be sure, many objects around us will evolve to be moresophisticated and many already include computers whether this is evident totheir users or not. to what extent computers will disappear as distinct devices is not a question that can yet be answered. however, it does not reallymatter either. the needs and interests of people have changed very little overthe past 100 years and will likely change only slightly over the next 15 to 20.most people will still need to work, create, love, interact, communicate, andbe entertained (as well as entertain each other). interfaces should concentrateon the activities, not the technologiesñnor should they be immediately concerned with the nature of a device itself (is it distinct or embedded?). theseinterfaces may show up in computers, televisions, telephones, door knobs, ordevices not yet invented. what will remain fairly constant, however, are theneeds themselves.what is interactivity?when i use the word òinteractiveó i do not mean what has becomethe standard industry definition of dynamic media or the ability to makechoices when using computer programs. most òinteractive mediaó isnothing more than multimedia presentations (usually with video andanimation) with the ability to click to the next screen of material in anonlinear way. in this sense interactivity has become bad television wherethe audience must click for more in order to keep the stream coming. tome interactivity is much richer and includes the abilities to create, share,and communicate rather than merely watch. interactive experiencesshould change over time and between different people. sadly, few prodmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.256more than screen deepucts or experiences do this now, which is the main reason why the cdrom industry fell apart over the past few years (the products offeredlittle to do that was interesting).however, this is merely the starting point. as an industry (academicsand professionals alike), we understand this word òinteractivityó verylittle and need to explore greatly what it means to people, what it can be,and how to create it. this is one of the points that grants and funding canapply. unfortunately, the commercial end of the interactive media industry offers little chance of exploring and experimenting with the wholenotion of interactivity, as the demands of an overhyped market, skyrocketing costs, too much publicity, and too many expectations preventmost companies from asking these questions. likewise, on the academicend of the spectrum, demands to produce workready students, lack ofinterdisciplinary programs, and the history of computer science studies(emphasis on software, programming, engineering, and computer languages) prevent students and professors from asking these questions because they seem esoteric and òlightó in the phase of other research.about the only people who are explicitly trained in the skills of interaction are those in the performing arts: dancers, actors, singers, comedians,improvisational actors, and musicians. however, these fields are hardlyseen as complementary or valid courses of study in computer science, multimedia, and even design programs. yet the experience and knowledgethat performers can bring to these disciplines are exactly the answers to thequestions that should be asked. grants for programs that try to explorethese issues with the help of many different disciplines would help speedthe development of answers badly needed in this industry.computers that are awareinterfaces need to become more aware of themselves and thosearound them. this is true in both a physical sense (where am i, where areyou, and who else is here?) and a cognitive sense (who am i, what can ido, and how can i communicate with others?). while computers wonõthave truly òcognitiveó capabilities for a long timeñif everñthey alreadyhave a few elements of these capabilities and information and need evenmore. what features these capabilities will eventually create are mostlyunpredictable right now, but we can count on the facilities to respond topeople in a more adaptable and individual manner to make a major improvement in interfaces. developing processes, standards, and technologies to build these capabilities upon will prove mandatory.other technologies that will be needed to develop these more intuitive and adaptive interfaces include perceptual technologies to supportmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics257computer perception in sound, vision, touch, gesture, environment, temperature, airborne particles, and so forth.interfaces to knowledgemost interfaces and applications today have sped the transmission,storage, and processing of data but have hardly changed the accumulation, creation, or quantity of either information or knowledge. certainly,we cannot say that computers have made us more òwise,ó but the interactions computers offer do give us more chances to communicate ourthoughts and build wisdom if we only knew better how to. our understanding of knowledge and wisdom and its processes is inadequate butalso critical to our continued development as a culture and a species.research into the components of these processes, of our minds, and of ourthoughts is needed to advance not only our toolsñof which the computeris one of our bestñbut ourselves. this research is needed not only interms of software and hardware (perhaps finding form in file formats,applications, operating systems, and products), but in the underlying processes and understandings of how we thinkñupon which all of the aforementioned are based. this must be coordinated with the fields of education, psychology, and communications, as well as computer science. itmay even be helpfulñand necessaryñto include those in philosophy.these are the most esoteric and unpredictable of questionsñindeed,they have kept us busy for our entire historiesñbut this should not deterus from seeking their answers. even if we will never truly answer thesequestions completely, each part of the answer gives us new insights intobuilding more valuable interfaces that meet more of our needs.another aspect of interfaces that facilitate knowledge are the technologies involved with representing and displaying data and information. present tools commonly available on the market such as spreadsheets, word processors, databases, and graphics programs are hardlyadequate for representing or visualizing complex relationshipships andinforming communications. the hardware required for betterperforming visualization systems includes displays that are high resolution, portable, and low power so that they are more easily used where needed.standards for evolved displays will need to be established, adopted, andmade prevalent so that engineers, programmers, and audiences can cometo count on their capabilities and availability. integration with input/output devices such as scanners, pointing devices, and printers will needto be advanced as well. devices that enable more direct interaction between display and control are more learnable and more evident to useñin essence, an evolution of what is commonly understood as direct mamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.258more than screen deepnipulation today. systems for processing and working with these deviceswill need to rely on more powerful and faster cpus (central processingunits) and hardware as well.software for representing and manipulating more complex data visualizations will need to build on new understandings of how people thinkand work with data. these applications will need to explore new paradigms in representation and manipulation in order to offer the kinds offlexibility and understandability required by more complex processingand less òprofessionaló audiences.interfaces across mediawhere possible, new interfaces should translate well across mediaand devices, whether portable, stationary, shared, public, private, networked, or personal, and should strive to encompass and integrate traditional media, such as broadcast and print media, where possibleñnotmerely electronic and online media. this is not to say that interfacesshouldnõt take advantage of their unique capabilitiesñindeed, they needto do so more than currentlyñbut they also need to relate to each otherwhere possible and it should be recognized that printed interfaces such asnewspapers, classifieds, catalogs, documentation, and directories are injust as dire need of evolution as technological ones. i am certainly notcalling for computer screens to look like little notebooks of paper withspiral binds nor print paper to look like current computer interfaces withpulldown menus. however, our interfaces to printed information andknowledge have evolved little (outside of stylistic appearances) in thepast 100 years, and, since this still represents a huge proportion of information dissemination and interaction (and will likely continue to be),some funding for the evolution of these critical interfaces should be allocated.interfaces across culturesas interfaces become more complex and deal with more abstract issues, how they address people from different backgrounds and cultureswill become more critical. we have been able to achieve a certain amountof standardization and utilization so far with present interfaces, but this isdue mainly to the nature of tasks currently completed with computers.as computers become more involved with knowledge building, communications, and community and as interfaces facilitate these more socialpurposes, they will need to address how differences between peoplechange their understanding of how to use these devices and of the processes themselves. these differences may be based on age, gender, culmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics259ture, language, or nationality. interfaces in the future will not have theluxury of requiring the same amount of capitulation on the part of theaudience since the next level of computer users (the next 100 millionusers) will not be as willing to change their approach to problems andtheir interaction with devices as the enthusiasts and professionals whocomprise the present base of computer users. issues of language, gesture,understanding, privacy, approach, civility, and òlifeó are not consistentthroughout the worldñand wonderfully soñand must be discoveredand documented. also, systems, standards, and interfaces must be developed that are sensitive to these differences. lastly, the knowledge ofthese difference must be made available to researchers and developers.automatic language translation is one of the most criticalñand mostdifficultñproblems to solve. it is such a complex problem that it is probably not solvable by conventional programming means. efforts to ògrowóor òevolveó complex software for pattern recognition and processing areprobably the best hope for tackling problems of this complexity, and itwill probably require several efforts in coordination.lastly, greater education is needed to inform researchers, professionals, participants, and the industry of these issues, their importance, thestate of their progress, and their details. we cannot merely rely on themedia to inform people about computers or their capabilities since themessages usually get dissolved to the lowest common denominatorñbutone of cynical expectations and far lower than actual capabilities to understand. movies, news, books, and other instruments of culture oftencreate unrealistic understandings, expectations, and often fears of computers and their uses. we must address these and reverse them ourselvesñas no one else willñif we expect future interfaces for everybodyto be more effective.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.260more than screen deepinterspace and an everycitizen interface to thenational information infrastructureterry winogradstanford universitywith the sudden emergence of widely used internetcentered applications, it has become glaringly obvious that the computer is not a machine whose main purpose is for a person to pursue a task. the computer(with its attendant peripherals and networks) is a machine for communicating all kinds of information in all kinds of media, with layers of structuring and interaction that could not be provided by traditional print,graphic, or broadcast media.the traditional idea of òinterfaceó implies that we are focusing on twoentitiesñthe person and the machineñand on the space that lies betweenthem. but a more realistic view recognizes the centrality of an òinterspaceó that is inhabited by multiple people, workstations, servers, andother devices in a complex web of interactions. the hardest task in creating an everycitizen interface will be the design of appropriate theories,models, and representations to do justice to the potential richness of thisinteraction space.as a simple example, consider the web. today we talk of surfingfrom place to place on the web, touching home pages, and followinglinks. these metaphors of spatial locomotion are engaging. they openedup new ways of thinking and doing that had not been explored in thepredecessor desktop metaphor. but the web is not the answer to thefuture of interfaces any more than the desktop was in its day. eachmetaphor is another stepping stone, which in turn creates a way of thinking that creates a blindness to new possibilities.new research and development activities need to enhance our ability tounderstand, analyze, and create interaction spaces. the work will be rootedin disciplines that focus on people and communicationñsuch as psychology,communications, graphic design, and linguisticsñas well as in disciplinesthat support computing and communications technologies. the work willstart from an assumption that a computer system provides a shared space formultiple people, each in a personal and organizational background thatshapes and guides interaction with others. the systems we can build basedon new research will support communications structures at all levelsñfrommore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics261the generic document structuring of the web to highly taskspecific interactions, like those that go on in an airport control tower.some sample areas for research are discussed below.collaboration structuresthere is a body of research on the structure of collaborative work,sponsored under previous national science foundation (nsf) initiativeson collaboration and developed by commercial software developers under labels such as òworkflow.ó the current state of the art can be described as having a large òhole in the middle.ó at the highest level thereare very general (and hence very abstract) theories of how people getwork done through communication. at the low level, there are thousands, even millions, of specialized applicationsñfrom the order systemat a fast food restaurant to the nsf proposal application processñthatsupport organized group activities. but we have not yet developed theconceptual and computational tools to make it easy to bring collaborationinto the mainstream of applications. when i work with my researchgroup on a joint paper, we use sophisticated word processors, graphicsprograms, and the like, but our coordination is based on generic emailand calendars and often fails to help us at the places where breakdownsoccur.semantic alignmentwhenever two people talk, they have only an approximate understanding of each other. when they speak the same language, share intellectual assumptions, and have common backgrounds and training, thealignment may be quite close. as these diverge, there is an increasingneed to put effort into constant calibration and readjusting of interpretations. ordinary language freezes meanings into words and phrases,which then can be òmisinterpretedó (or at least differently interpreted).this problem shows up at every level of computer systems, wheneverinformation is being represented in a wellspecified syntax and vocabulary. even simple databases have this problem. if information is beingshared between two company databases that have a table for òemployee,óthey are apparently in alignment. but if one was created for facilitiesplanning and the other for tax accounting, they may not agree on thestatus of parttime, offsite, onsite contract, or other such òemployees.óthis difference may be nowhere explicit in what is stored on the computer but is a matter of background and context.ubiquitous networking is leading us to the point where every computer system supports communication and where every term we use willmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.262more than screen deepbe seen and hence interpreted by others. there are traditional philosophical and linguistic approaches to making sure we have òcommon understanding,ó but these tend to be based on highly abstract or idealizedexamples and settings. we need to develop new theoretical foundationsfor talking about the kinds of òsemantic approximationsó that are neededfor something as apparently simple as sharing data between two databases and as ubiquitous as the nodes of the internet.building new òvirtualitiesóin designing new systems and applications, we are not simply providing better tools for working with the objects in the previously existingworld. computer systems and software are a medium for the creation ofvirtualitiesñthe worlds in which users of the software perceive, act, andrespond to experiences. software is not just a device with which the userinteracts; it is also the generator of a space in which the user lives. software design is like architecture: when an architect designs a home or anoffice building, a structure is being specified. more significantly, though,the patterns of life for its inhabitants are being shaped. people are thoughtof as inhabitants rather than as users of buildings.the creation of a virtual world is immediately evident in computergames, which dramatically engage the player in exploring the vast reachesof space, fighting off the villains, finding the treasuresñactively living inwhatever worlds the game designer can imagine and portray. but thecreation of worlds is not limited to game designers. there is also a virtualworld in a desktop interface, in a spreadsheet, and in a use of the worldwide web. researchers in humancomputer interfaces have used otherterms, such as conceptual model, cognitive model, userõs model, interfacemetaphor, user illusion, virtuality, and ontology, all carrying the connotation that a space of existence, rather than a set of devices or images, isbeing designed. the term virtuality highlights the perspective that theworld is virtual, in a space that is neither a mental construct of the user ora mental construct of the designer.today, we are all familiar with the virtuality of the standard graphical user interface, with its windows, icons, folders, and the like. althoughthese virtual objects are loosely grounded in analogies with the physicalworld, they exist in a unique world of their own, with its special logic andpotentials for action by the user. the underlying programs manipulatedisk sectors, network addresses, data caches, and program segments.these underpinnings do not appearñat least when things are workingnormallyñin the desktop virtuality in which the user works.there is little theoretical grounding today on which to base the designof new virtualities. obviously, there are considerations from psychologymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics263about how people perceive new kind of objects and activities. there arephilosophical discourses about how we divide the world up into constituent things and properties and how we can formulate our interactions withthem. there is also a more commonsense level of understanding howpeople think about familiar domains and how their expectations fromtheir experiences in life will shape their interactions with computer systems.as a simple example, consider the three primary modes of interactingwith a virtuality that are learned by every normal person in infancy:¥manipulation.perceiving, grasping, modifying, and controllingobjects that are in front of the person. this is a òhandeyeó modality thatfills much of our daily life (from the kitchen to the cash register). it is atthe heart of the current desktop metaphor and most of what has beendone with graphic user interfaces.¥locomotion.observing location and moving from place to place.this is an òeyefootó modality in which the world is primarily stable andthe user moves within it. this is the basis for the webõs placeandlinkfollowing metaphor, as well as many popular computer games (where themanipulative aspects are reduced to òshoot weaponó).¥conversation.using a language to communicate with anotherperson in a twosided discourse. this is an òearmouthó modality thatcomes from our experience in encountering other people. it is the basisfor the traditional commandline interface as well as speech interactionwith machines.what can be said at a theoretical level about the nature of these modalities and the problems that arise in usingñand especially in mixingñthem?are there other conceptual modalities that are fundamentally different fromthese three that will be understandable and practical for people to use?how does the finergrained analysis of interaction structure fit into thislarger picture? and, finally, what is the difference in the nature of multiperson activity in these different modalities, and how does that map ontothe kinds of multiperson collaboration we want to support in an everycitizen interaction space? (see <http://wwwpcd.stanford.edu/winograd>and <http://wwwpcd.stanford.edu/winograd/book.html>.)bibliographyon coordinationdenning, peter and pamela dargan, actioncentered design, in terry winograd (ed.),bringing design to software, reading, ma: addisonwesley, 1996, pp. 105120.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.264more than screen deepholt, anatol, diplans, a formalism for action, acm transactions on office informationsystems 6:2 (april 1988).malone, thomas w. and kevin crowston, what is coordination theory and how can ithelp design cooperative work systems?, mit ccs report 112, 3402/3183, cambridge,ma: massachusetts institute of technology, april 1990.medinamora, raul, terry winograd, rodrigo flores, and fernando flores, òthe actionworkflow approach to workflow management technologyó in the information society,volume 9, number 4, octoberdecember 1993, p. 391.verharen, egon, nardo van der rijst, and jan dietz (eds.), proceedings of the language/actionperspective: international workshop on communication modeling, economisch instituttilburg, tilburg, the netherlands, 1996. <http://infolabwww.kub.nl:2080/infolab/lap96/>winograd, terry (1988), introduction to the language/action perspective, acm transactionson office information systems 6:2 (april 1988), pp. 8386.on semantic alignmentthere are papers on this topic from the point of view of artificialintelligence (òontologyó matching), databases (òschemaó matching), andinformation retrieval (òattribute setó matching). i have not put together agood list or found an integrative article that cuts across them. somegeneral considerations are presented in the following:winograd, terry and fernando flores, understanding computers and cognition: a newfoundation for design, norwood, nj: ablex, 1986, 220 pp. paperback issued byaddisonwesley, 1987.on the design of òvirtualitiesóhutchins, edwin, james hollan, and donald norman, direct manipulation interfaces, in d.norman and s. draper (eds.), usercentered system design, hillsdale, nj.: erlbaum,1986, pp. 87124.lakoff, george, and mark johnson, metaphors we live by, chicago: university of chicagopress, 1980.winograd, terry, with john bennett, laura de young, and bradley hartfield (eds.), bringingdesign to software, reading, ma: addisonwesley, 1996. available online at <http://wwwpcd.stanford.edu/winograd/book.html>. see, especially, introduction, chapter2 (david liddle, òdesign of the conceptual modeló), and chapter 4 (john rheinfrankand shelley evenson, òdesign languagesó).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics265mobile access to the nationõs informationinfrastructuredaniel p. siewiorekcarnegie mellon universityintroductionthe focus of this position paper is mobile access to the nationõs information infrastructure (nii). the goal should be to provide òthe rightinformation to the right person at the right place at the right time.ó inorder for the nii to reach its potential, the average person should be ableto take advantage of the information on or off the job. even while atwork, many people do not have desks or spend large portions of timeaway from their desks. thus, mobile access is the gating technologyrequired to make the nii available at any place at any time.the next section describes the time rate of change of computer technology, indicating what might be expected in the form of technology fromthe computer industry as well as defining a new class of computersñthewearable computer. the third section describes the importance of a variety of modalities of interaction with wearable computers. the paperconcludes with some research challenges.time rate of change of computer technologycomputer systems are typically compared using two classes ofmetrics: capacity and performance. capacity is how large a componentmay be or how much information it may store. performance is measuredin functions per unit of time (often referred to as bandwidth or throughput) or, conversely, the time needed to complete a specific function (referred to as latency). recently, ease of use has become a major differentiating characterisitic between computer systems and hence represents athird class of metrics.because they directly reflect the state of technology, hardware capacity and performance metrics are the easiest to determine or derive. thesemeasures are usually associated with individual components in a computer system. there are six basic functions in a computer system. inaddition, attributes such as energy consumption and physical size gainincreasing importance as computers become more mobile. table 1 summore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.266more than screen deepmarizes eight metrics for a computer system, including their units ofmeasurement. capacity is usually measured in the number of information units such as bytes or pixels. bandwidth/throughput is measured inoperations per second for the processor and bits per second for communications. energy is measured as the reciprocal of kilowatts, while physicalsize is summarized as the reciprocal of the product of the weight times thevolume of space occupied. notice that for all these metrics the larger thenumber the better. the three columns in table 1 include a contemporaryworkstation (an anchored, unmovable system), a contemporary laptopcomputer (a luggable system), and a palmtop/personal digital assistant(a portable pocketable system).since ease of use is so closely associated with human reaction, it ismuch more difficult to quantify. there are at least three basic functionsrelated to ease of use: input, output, and information representation. box 1summarizes several points for each of these basic functions. note that,unlike the continuous variables for capacity and performance, the easeofuse metrics are discrete.siewiorek et al. (1982) considered the concept of the computer class.a computer class attempts to integrate many computer system detailsinto an overall evaluation, grouping similarly evaluated systems together.thus, the workstation, laptop, and palmtop in table 1 can each be considered representative of a computer class. these researchers also observedthat computer classes differ in physical dimensions and price by roughly1.5 orders of magnitude (e.g., approximately a factor of 30). in addition, itwas observed that, as each computer class evolves, new members of theclass are expected to have increased capacity and functionality. the increases in technology serve to increase the capacity and functionality of atable 1examples of computer system capacity and performancepalmtop/personalcomponentsunitsworkstationlaptop digital assistantprocessorinstructions/second100m10m1mrandom accessbytes64m8m1mmemorydisk memorybytes600m100mñdisplaypixels1m0.18m0.045mnetworkbits/second10m2m0.02mcommunicationsdistancemetersñ10010energy1/kw5100500physical size(weight  volume)1162,0001/kg m3xxxmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics267class. thus, the boundary of various attributes can be considered to beincreasing with time.on the other hand, technological changes can be used to initiate newcomputer classes with the same functionality offered by the next higherclass several years before. it is extremely important to remember that allclasses of computers have followed approximately the same evolutionarypaths as their capacity and functionality have increased. the newer computer classes benefit from the evolutionary process of older classes, adapting to proven concepts quickly, where the older classes required a trialanderror process. siewiorek and coworkers also observed that computerclasses tend to lag each other by approximately 5 years. thus, the palmtopcomputer of today could be considered to have approximately the functionality of a laptop 5 years ago or a workstation 10 years ago. thus, wecan expect the palmtop of the year 2006 to have the attributes of todayõsworkstation.one can speculate on the emergence of a new class of computers calledòwearable computers.ó wearable computers will weigh less than a fewounces, operate for months or years on a single battery, and have esthetically pleasing shapes that can adorn various parts of the body. pagers andelectronic watches (complete with calculator and memory to store phonenumbers/memos) represent the first examples of the wearable class of computers. thus, the wearable computer of the year 2006 will have at least thefunctionality of todayõs laptop (as depicted in table 1).as with the capacity and performance metrics in table 1, the easeofuse metrics in box 1 are also moving out with time. for example, thekeyboard with an alphanumerical display using textual information is representative of timesharing systems of the early 1970s. the keyboard andmouse, graphical output, and iconic desktop are representative of personalcomputers of the early 1980s. the addition of handwriting recognitionbox 1easeofuse metricsinput¥keyboard¥mouse¥handwritingrecognition¥speech recognition¥gesturing¥position sensingoutput¥alphanumericaldisplay¥graphical display¥speech synthesisinformation representation¥textual¥ionic desktop¥multimediamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.268more than screen deepinput, speech synthesis output, and multimedia information is emerging inthe early 1990s. it takes approximately one decade to completely assimilatenew input, output, and informational representations. by the early part ofthe next decade, speech recognition, position sensing, and eye trackingshould be common inputs. headsup projection displays should allowsuperposition of information onto the userõs environment.modalities of interaction withwearable computersthe objective of wearable computer designs is to merge the userõsinformation space with his or her work space. the wearable computershould offer seamless integration of informationprocessing tools withthe existing work environment. to accomplish this, the wearable systemmust offer functionality in a natural and unobtrusive manner, allowingthe user to dedicate all of his or her attention to the task at hand with nodistraction provided by the system itself. conventional methods of interaction, including the keyboard, mouse, joystick, and monitor, all requiresome fixed physical relationship between user and device, which canconsiderably reduce the efficiency of the wearable system. among themost challenging questions facing mobile system designers is that of human interface design. as computing devices move from the desktop tomore mobile environments, many conventions of human interfacing mustbe reconsidered for their effectiveness. how does the mobile system usersupply input while performing tasks that preclude use of a keyboard?what layout of visual information most effectively describes system stateor taskrelated data. to maximize the effectiveness of wearable systemsin mobile computing environments, interface design must be carefullymatched with user tasks. by constructing mental models of user actions,interface elements may be chosen and tuned to meet the software andhardware requirements of specific procedures.the efficiency of the humancomputer interface is determined by thesimplicity and clarity of the mental model suggested by the system. bymodeling the actual task as well as the human interface, a linkage can beconstructed between user and machine that can be examined to improvethe overall efficiency of the wearable system. we begin with the assertionthat for wearable systems to be efficient the mental model of the interfacedesign must closely parallel that of the user task; there must be minimalinterference or obstruction posed by the computer in completing jobs.although the number of quantifiable metrics suited for interface evaluation is small, a series of basic observations provide a means for comparison. one characteristic of an application interface is the number of useractions required to perform a given subtask. we define a subtask as anmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics269operation, possibly consisting of multiple inputs, that a user completes inthe process of performing a larger coherent task. for example, in thecourse of performing an inspection, a user might wish to return from hisor her present location in an application to the main menu. this subtaskmay require a single input (perhaps a voice command or an onscreenbutton) or multiple inputs (backing out through a hierarchy of categoriesto reach the top or main level). we assert that an application requiringfew inputs will allow a user to dedicate more attention to the job at hand,while a larger number of inputs will require more concentration on thecomputing system. a comparison of equivalent subtasks in two wearable computers (smailagic and siewiorek, 1996) is shown in table 2. thespeech recognition engine accepts complex commands that allow somesubtasks requiring a series of manual inputs to be executed with a singlephrase. however, the response time to a spoken input is longer and theaccuracy is lower. for these reasons the quantitative aspect of systemlatency and accuracy must be factored into evaluations of usability.research challengesthere are several challenges that research must address to make mobile access to the nii effective. following is a partial list of those challenges:¥user interface models. what is the appropriate set of metaphors forproviding mobile access to information (i.e., the next òdesktopó oròspreadsheetó)? these metaphors typically take over a decade to develop(i.e., the desktop metaphor started in the early 1970s at xerox parc andrequired over a decade before it was widely available to consumers).extensive experimentation working with enduser applications will berequired. furthermore, there may be a set of metaphors each tailored to aspecific application or a specific information type.¥input/output modalities. while several modalities mimicking thetable 2comparison of number of steps toretrieve information using selection buttons andspeechbuttons/menu selectionspeechget information41get photograph51navigate to location32xxxmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.270more than screen deepinput/output capabilities of the human brain have been the subject ofcomputer science research for decades, their accuracy and ease of use (i.e.,many current modalities require extensive training periods) are not yetacceptable. inaccuracies produce user frustrations. in addition, most ofthese modalities require extensive computing resources, which will notbe available in lowweight, lowenergy wearable computers. there isroom for new, easytouse input devices, such as the dial developed atcarnegie mellon university for listoriented applications.¥quick interface evaluation methodology. current approaches toevaluating a human computer interface require elaborate procedures andscores of subjects. such an evaluation may take months and is not appropriate for use during interface design. these evaluation techniques shouldfocus especially on decreasing human errors and frustration.¥matched capability with applications. the current thought is thattechnology should provide the highest performance capability. however,this capability is often unnecessary to complete an application, and fancyenhancements such as fullcolor graphics require substantial resourcesand may actually decrease ease of use by generating information overload for the user. for example, one informal survey of display requirements for military planning estimated that 85 percent of the applicationscould be performed with an alphanumerical display and 10 percent withsimple graphics and that only 5 percent required full bitmap graphics.interface design and evaluation should focus on the most effective meansfor information access and resist the temptation to provide extra capabilities simply because they are available.referencessiewiorek, d., c. g. bell, and a. newell. 1982. computer structures: principles and examples,mcgrawhill, inc., new york.smailagic, asim, and d.p. siewiorek. 1996. modalities of interaction with cmu wearablecomputers. ieee personal communications, vol. 3, no. 1, february.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics271ordinary citizens and the nationalinformation infrastructurebruce tognazzinihealtheon corporationthe original working title for this workshop was òtoward an ordinarycitizen interface to the national information infrastructure.ó it wasthen altered to òeverycitizenó to be inclusive of all of our citizens. whilei support that change, we did lose something quite important in the transition, for of all the people whose lives have been affected by the computer revolution, perhaps none has received as scant attention as ourordinary citizens.today, we face the prospect of millions of havenots shut out of cyberspace, a threat that has little to do with economic status, country of origin,race, creed, color, or physical ability. instead, it has everything to do withage, gender, education, culture, aptitude, and attitude. if cyberspace todaywere to have a deadhonest advertising slogan, it would read: built byboys, for boys!as margie wylie (1995) says: òfar from offering a millennial newworld of democracy and equal opportunity, the coming web of information systems could turn the clock back 50 years for women.ó the 18 to39yearold males with technological talent and aboveaverage intelligence and education who built todayõs cyberspace built it for themselves.large parts of it reflect the delicate ambiance of an automobile junkyard.we must make fundamental changes in the direction of computer designif the true havenots of cyberspace are not to be those rare individualswho do not feel instantly comfortable clattering over mounds of twistedmetallic wreckageñin other words, ordinary people.somewhere along the line, many technology designers lost track ofthe real goal: empowering users. from video cassette recorders to clockradios, designers are adding every button, switch, and other poweruserdoodad they can in the mistaken belief that the true power of technologyis to be measured in the number of features and controls rather than theimpact on peopleõs lives. our computer software has tracked this trend.systems and applications today are festooned with every òwangdoodleóimaginable, offering users plenty of power to blow themselves up whileat the same time inhibiting them from accomplishing their task.if the desktop computer is a dark and mysterious closet, the internetis a positively terrifying, sucking black hole. the advent of the worldmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.272more than screen deepwide web is helping to address part of the problem by making at least thewaystations on the internet visible, but just the sheer immensity of todayõscyberspace is frightening to all but a small group of people. sure, thekinds of tasks users attempt on their computers have become more complex, but something else is leading to the increased difficulty of using ourmachines, something we need to address: we are designing our systemsfor power users, to the exclusion of everyone else.power users versus expert usersmost people want to be seen as power users, but then we have thereal thing. power users typically consist of bipedal, testosteronesoakedlife forms between the ages of 18 and 39. yes, i said testosteronesoakedlife forms. at the risk of offending certain politically correct parties, theredoes appear to be a difference, however minor, between boys and girls.and the overwhelming majority of power users iõve come across aredefinitely male.let me explain what i mean by power user. a òpower useró is aperson driven by hormones to want complete and utter control of everyfunction of his or her computer, even if having such control seriouslydegrades efficiency and productivity. tim allenõs character on òhomeimprovement,ó the abc comedy series, is the prototypical power user.heõs the only guy in the neighborhood with a 120horsepower lawnmower that will do 0 to 60 in less than 7 seconds. itõs not much use on hissuburban lawn, but it makes a really neat noise when he starts it up.i knew several guys at apple who had so many weird publicdomainextensions in their system folder that virtually none of their applicationsran properly. accomplishing the smallest task was like walking througha mine field. so what? as far as they were concerned, it merely increasedthe challenge! they wouldnõt have thought of paring down their systems.most women see their machines as serious productivity tools, therefor the express purpose of helping them accomplish their task. womenwant to do their work, not òplay computeró (bulkeley, 1994). they arenot alone: a high percentage of men donõt want to òplay computeróeither; they just donõt dare complain about it.many people across the board become expert users. expert usersunderstand their craft and are competent at using the tools that will helpthem succeed. they may have no interest in tearing apart their tools,either to understand them or to òimproveó them. itõs the difference between someone who is an expert at driving a car and someone who looksforward to saturday morning because that is when he can tear the carapart and perhaps get it back together. the saturdaymorning powermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics273user may very well not be particularly expert at driving the car (althoughhe will claim to be).changing timesthirty years ago computer users consisted of two classes: youngmale programmers and operators and powerless, minimumwage femaleswho endlessly keypunched 80column cards. (of course, not all keypunch operators were female. i was one of the few powerless male keypunch operators in those days. my cohorts and i quickly escaped, but thewomen were generally not so lucky.)today, twothirds of personal computer users are women, accordingto a logitec inc. poll (1992), and millions of those female users are now inhigher technical and management positions. those who are not wandering the labyrinths of cyberspace today will be in the very near future.the majority of users, according to the same poll, are now more than36 years old. most of us above the age of 36ñmale or femaleñhaveabandoned changing our own motor oil. and we are no longer quite asamused by the prospect of spending 10 hours tracking down the reasonwhy our world wide web connection has become unresponsive eversince we installed our new tax planner.the economic penalty for òboytoyismóa 1992 survey by nolan, norton and company pegged the annualcost of ownership for a standard business personal computer at as muchas $21,500 per year. thatõs a lot of money for a $5,000 computer. whereõsthe money going? a disproportionate percentage can be traced to directand indirect training costs. the study found that the known visible costsper computer ranged from $2,000 to $6,000 annually. these direct costscover hardware, software, initial installation, scheduled maintenance, andpeople taking time from their regular jobs to attend training classes.the indirect costs are more complex: users waste time pressing buttons and flailing through manuals trying to figure out what went wrongwith their machine, when the problem is that they inadvertently triggeredsome unknown and lessthanobvious system state. they waste timewandering around looking for a warm body in another office to ask forhelp. finally, when they find someone who can help, the other party endsup wasting their own time, too. this peertopeer training is expensive.the study pegged the cost at $6,000 to $15,000 per year.according to bulkeley (1992):more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.274more than screen deepòwe all just about fell out of our chairs when we saw the amount ofmutual support,ó says david j. baker, a process consultant for sprintwho participated in organizing the study. òeveryone knew [peertopeer training] was taking place, but when we guessed what the amountwould be beforehand, we missed by a factor of 65.ósupportive family and friendsthe effect of interface complexity can be felt beyond the workplace.ordinary peopleõs access to cyberspace is a direct function of their accessto a family member or friend who can carry out informed peertopeeractivities. should the knowledgeable family member die, divorce, or growup and move out, the other family members may lose their access tocyberspace with the first disk problem or mandatory upgrade. even iftheir hardware and software systems continue to function, they may wellbe unable to gain the full benefit of services offered, just because they donot have the technical skills to access them.ordinary citizens who do not live in a hightech area of the country,who had no one to lean on from the beginning, are just as effectively disenfranchised from the cyber revolution as those who are economically disadvantaged.research issueswhile the solution to the problem of todayõs excessive complexity willinvolve applied technology, the problem has not arisen from a lack of technology, and it will not be solved by blindly throwing more technology at it.the solutions, i believe, lie more in the areas of sociology and psychology.macintosh used to have the slogan, òthe computer for the rest of us.ómacintosh was not. from the beginning, the macintosh was designed to beòthe computer for the rest of them.ó the macintosh team, like the lisa team,alan kayõs xerox parc altos team, and doug engelbartõs original sriteam before them, was keenly aware that they were designing not for themselves but for others. all these teams held a common understanding ofwho their users were and chief in that understanding was a rocksolidbelief that users were not like themselves.ten years later we are expecting ordinary citizens traveling on theworld wide web to follow a naming convention so foreign to humanexperience as to be completely incomprehensible: http://www.goliath.com/~grandma.we need research projects that will enable us to form a bridge between the needs of ordinary people and the inventiveness of our youngtechnological minds. several studies have shown startling differencesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics275between software engineers and ordinary citizens on jungian psychologicaltype tests (sitton and chmelir, 1984; tognazzini, 1992). these testsneed to be repeated and expanded on, using larger populations and varied and more exacting instruments, answering the question: how areengineers different from ordinary citizens? those engineers who do wantto make technology accessible to ordinary people have little to go by sincewe still know remarkably little about our ordinary citizens. what are thecapabilities, needs, and wants of ordinary citizens?today, software engineers master systems of amazing complexityduring the course of their education and often graduate with the attitudethat others can and should experience the same complexity they have: inwhat ways can we improve the education of our engineers so they arebetter able to understand and provide for the needs and wants of ordinary citizens?much of the complexity our computer science students face is necessaryñthey are doing complex things. however, much of it is just baddesign, bad design they often end up emulating in their own products.how prevalent is bad design in the systems that computer science students use? what can be done to improve those systems? what can bedone to sensitize our students to bad design and its consequences, so theywill cease emulating it?we need case studies of projects that resulted in approachable products or services versus those that only an engineer could love. whatmakes a project result in a system that people can use? what caused thatproject to succeed? what changes could have been made early on inprojects that resulted in difficulttouse systems that would have madethem more approachable?while many organizations have embraced the idea of human interaction design as a profession, many still see human interaction design assomething to be done by engineers in the normal course of their work.what are the comparative outcomes of projects done in conjunction withhuman interaction designers versus engineers acting alone? is the investment in human interface specialists worth it? does that investment resultin designs that are more approachable by ordinary citizens?our interfaces to the national information infrastructure must be accessible to ordinary people. the starlisamacintosh interface made afundamental shift in design away from the earlier òblack caveó interfaces.people had previously been expected to navigate blindly through cyberspace, leaping from menu to menu, building in their mindõs eye an imageof what their cyberspace looked like. the new interfaces swept all of thataside. the òlights were turned on,ó with cyberspace objects and actionsrepresented by icons, menu selections, and other visible objects in theinterface. people no longer navigated at all: everything was brought tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.276more than screen deepthe user, with the user staying always in one placeñseated before thedesktop.the web represents a step backward to the old black cave metaphor.true, people can see one home page at a time, but they are back to navigating their way around cyberspace and, once again, can see no visualevidence of their movement. itõs like the tunnel of love: you see a lot ofobjects jumping out at you, but you donõt really know where you are.in the early days of the personal computer, we were attempting to sellan unproven technology to a skeptical world. we could not depend onpeople investing weeks or months of selfeducation in a system they didnot yet know would improve their lives. we had to make things easy.however, sometimes, what was easy in that first 20 minutes was notnecessarily the right solution for maximum efficiency over the long haul.people now recognize the value of the personal computer or workstation. they are willing to make a reasonable commitment toward learning. the interface of today does not necessarily need the training wheelsthat the star, lisa, and macintosh provided, but we need research to findout how much we can increase the difficulty of the learning experience inan effort to further empower users. we need to establish the relevancetoday of the principles that drove the design of the original graphical userinterfaces, as embodied in such lists as the principles of macintosh design(apple computer, inc., 1986). which of the design principles for earlygraphical user interfaces represented òtraining wheels,ó and which represented needs, wants, and limitations of ordinary citizens that are just asimportant today as they were then?since the advent of those early graphical user interfaces, users havefaced increasing complexity. what are the areas of todayõs technologythat act as a barrier to ordinary citizens? what seeming complexities arenot acting as barriers but are in fact embraced by ordinary citizens?it takes 16 years to learn how to drive, with a lot of formal and informal education along the way. how much education should our ordinarycitizen children be receiving in school? what form should this educationtake? based on an understanding that our children would be formallyeducated in information retrieval and other complex computer tasks, howfar can we increase the learning burden for such tasks in our aim toimprove overall efficiency and productivity?finally, we need to explore what, if anything, government or industryneeds to do to bring simple power to our systems. will competition byitself eventually result in approachable systems, or will we need an òunderwritersõ laboratoryó type of institution that can certify our technological efforts? will we need fastmoving standards organizations that canmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics277stay abreast of developments? if so, could there ever be any such thing asa fastmoving standards organization?we have recently seen the result of the computer industry òputting itsfoot downó on the issue of the digital versatile disk (dvd, nee digital videodisk). instead of two competing systems being thrown on the market, therewill be only one, and that one is better than either of the two that wouldhave arrived. the dvd was also designed, rather than just kind of evolving. it had input from marketers, as well as engineers, marketers whoactually went out and spoke to clients. industry cooperation can work.on the other hand, industry has had a miserable overall record ofcooperation and consistency, from the vhs versus beta wars to the windows versus macintosh wars, with ordinary citizens not only paying theprice along the way but often ending up with an inferior alternative in theend. we know governmental supervision can work. weõve seen it withthe standards for ntsc video, for òcompatible color,ó and, more recently,for hdtv (highdefinition television) standards. the question always iswhether any of us will live long enough to see the results. how can weachieve the certainty of governmental supervision with the mercurialspeed of industry cooperation?summarymany of the above explorations could be carried out by a variety ofagenciesñindustry, government, or academia. who does what study isprobably relatively unimportant. what is critical is that it become a matter of public policy that we make our national information infrastructureaccessible to ordinary citizens as well as the technologically gifted. whatis critical is that people drop the belief that the realm of cyberspace shouldrightly be the exclusive province of those boys who worked on cars, thatcyberspace is by nature, not by design, a dark, dangerous, and forbiddingplace.today, every aspect of computers, from the outofthebox experienceto surfing the internet, is a joy to òtechnoguysó and an unpleasant challenge to ordinary citizens. we have the technology to make the nationalinformation infrastructure accessible and attractive to the vast majority ofour citizens. the time has come to make the investment in research andeducation that will enable all of our citizens to participate in the future.referencesapple computer, inc. (1986). the apple human interface guidelines, addisonwesley,reading, mass.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.278more than screen deepbulkeley, william m. (1992). study finds hidden costs of computing, wall street journal,november 2.bulkeley, william m. (1994). a tool for women, a toy for men, wall street journal, march 16.logitec inc. (1992). pcõs and people poll, a national compatibility study of the humanexperience with hardware, sponsored by logitec inc., 6505 kaiser drive, fremont, ca94555, (510) 7958500.nolan, norton and company (1992). managing enduser computing, nolan, norton andcompany, boston.sitton, sarah, and chmelir, gerard (1984). the intuitive computer programmer, datamation,october 15.tognazzini, bruce (1992). tog on interface, addisonwesley, reading, mass.wylie, margie (1995). òno place for women: internet is a flawed model for the infobahn,ódigital media: a seybold report, vol. 4, no. 8, pp. 36, january 2.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics279spokenlanguage technologyronald a. coleoregon graduate institute of science and technologyspokenlanguage systems allow people to communicate with machines by using speech to accomplish some task. the development ofspokenlanguage systems is a true multidisciplinary endeavor, requiringexpertise in areas of electric engineering, computer science, statistics, linguistics, and psychology. the technologies involved in spokenlanguagesystems include speech coding, speech recognition, natural language understanding, and dialogue modeling and may optionally include speakerrecognition, language identification, and speechtospeech language translation.advances in speech technology are of critical importance to the goalof an everycitizen interface to the national information infrastructure(nii). to be sure, speech technology cannot by itself achieve this goal.many people are unable to speak or hear. some information (e.g., paintings) is not in a form that can be appreciated using speech. nevertheless,the vast majority of people in the united states speak and understand alanguage, and speech is an obvious means for them to access information.as spokenlanguage technologies mature, we can imagine spokenlanguage systems performing as cooperative agents, not unlike helpful human operators, to support a wide variety of transactions. for this to takeplace, significant advances in the technology must occur through fundamental research.a significant advantage of using speech as an interface modality isthat it can be transmitted by existing communications networks usingcommon and inexpensive devices such as telephones and televisions.today, use of the internet is limited to people with access to computersand the skills to use them. these requirements exclude a great manyamericans: computers are too expensive for many of us to own, andabout onethird of our citizens are functionally illiterate (national centerfor education statistics, 1993). in the future, computers are unlikely to bethe major appliance for accessing the nii; telephones, cellular phones,televisions connected to cable networks, and inexpensive informationappliances are likely to become the preferred means of access.the state of the art in human language technology was summarizedrecently in an international survey entitled state of the art of humanlanguage technology, sponsored by the national science foundationmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.280more than screen deep(nsf) and the european community (cole et al., 1996). each of the 92authors who contributed to the survey was asked to define a specific areaof human language technology, review the state of the art in that area,and identify key research challenges. the survey is available on the worldwide web at http://cse.ogi.edu/cslu/hltsurvey/ hltsurvey.html.a second source of information on the state of the art of speech technology is the report of a workshop sponsored by the nsf in 1992 and published subsequently as a journal article (cole et al., 1995). the workshopparticipants identified eight areas in which research advances are essential to the development of spokenlanguage systems and the infrastructure needed to support research in those areas: (1) robust speech recognition, (2) automatic training and adaptation, (3) spontaneous speech, (4)dialogue models, (5) natural language response generation, (6) speechsynthesis and speech generation, (7) multilingual systems, and (8) multimodal systems.given the importance of speech technology to an everycitizen interface and to u.s. economic competitiveness, it is important to ask if theactivities of the research community will produce the desired technologyin the shortest period of time. in the remainder of this note, i offer myopinions about the major stumbling blocks to the development of spokendialogue systems for an everycitizen interface. these are (1) an insufficient focus on interactive systems by speech researchers, (2) limitations ofstatistical modeling approaches, and (3) lack of tools for research andtechnology transfer.insufficient focus on interactive systemsthe defining feature of a spokendialogue system is the interactionbetween human and machine. it follows that progress in developingthese systems requires the continued study of how people interact withmachines using speech. such studies will highlight the limitations ofspeech recognition technology in the context of system use and focusresearch efforts on ways to overcome these limitations.today, the primary focus of speech recognition research in the unitedstates is not interactive systems but the transcription of words in continuous speech. largevocabulary continuous speech recognition (lvcsr) isa priority of the defense establishment, which plays a major role in defining the priorities of the speech research community. for the past 12 years,progress in speech recognition research has been measured by recognition performance on benchmark tasks in annual competitions. currentbenchmark tasks include recognition of articles read from newspapers,recognition of speech in news broadcasts, and recognition of speech intelephone conversations.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics281transcription of words in continuous speech is both important andchallenging, but the challenges are different from those needed to produce spokendialogue systems. for example, research in lvcsr does notfocus on such issues as how to phrase a system prompt, how to determineif a recognition error has occurred, or how to engage in conversationalrepair if such a determination is made.limitations of current technologythere is growing evidence that current statistical modeling approaches to speech recognition, which treat speech as a sequence of independent time frames, will not scale to acceptable levels of performance ondifficult tasks. for example, current systems are able to recognize about50 percent of words in telephone conversations. this level of performance is achieved by gathering statistics on the frequency of occurrenceof word sequences; performance drops to below 20 percent when wordsequence constraints are disabled and word recognition is based solely onacoustic information. significant effort has been devoted to this task inrecent years, with only minor improvements in performance. the abilityof statistical modeling techniques to recognize words in natural conversations is not encouraging.a serious limitation of framebased statistical modeling techniques isthe difficulty of incorporating linguistic knowledge into the recognitionparadigm. the ibm speech group, one of the pioneers of speech recognition using hidden markov models, worked with linguists for several yearsto incorporate syntactic and semantic knowledge into ibmõs systems, always with the same resultñan increase in word recognition error rates.this led bob mercer, then of the ibm speech group, to assert in a keynoteaddress to a speech recognition workshop that the most effective technique ibm has found for decreasing error rates is to fire a linguist.the difficulty of incorporating linguistic knowledge into the dominant research paradigm stands as a major stumbling block to progress.accurate speech recognition requires the integration of diverse acousticcues, such as stop bursts, format movements, changes in pitch and comparison of acoustic features across segments. similarly, speech understanding requires the integration of these acoustic cues with syntactic,semantic, pragmatic, and situational knowledge. no paradigm existstoday that allows these information sources to be combined in a principled way that improves system performance. the result is that thosewith the most knowledge about human communication and spokenlanguage are largely excluded from the research process. new paradigmsare needed that enable psychologists and linguists to become vital contributors to the development of human language technology.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.282more than screen deeplack of tools for research and technologytransfera final obstacle to progress in spokendialogue systems is the lack ofavailable tools to support research and technology transfer. the development of spokenlanguage systems is a complex activity, requiring significant computer resources, integration of sophisticated signal processing,training and recognition algorithms, and language resources such asspeech corpora and pronunciation dictionaries. because of the resourcesand expertise required, spokenlanguage systems research is localized ina few specialized laboratories, which produce only five or six ph.d. students each year. the result is that all but a few of the most fortunatestudents are denied the opportunity to participate in this exciting area ofresearch, and we are not training enough researchers in an area of greatstrategic importance.without tools to create and manipulate spokendialogue systems andto support technology transfer, progress will be limited to the efforts ofrelatively few researchers at elite laboratories. for progress in spokenlanguage systems to occur, researchers need tools to rapidly design working systems and manipulate system parameters to test experimental hypotheses.despite these obstacles, i see great hope for the future. this workshop recognizes the importance of interface technologies, as do an increasing number of nsf initiatives in human language technology sponsored jointly by the defense advanced research projects agency andother defense agencies. the growing support for interface research isbringing new researchers and new ideas into the field. some of theseresearchers will focus their efforts on spokendialogues systems, and somewill produce more powerful recognition techniques that will limit theamount of engineering required for each new task. there are also effortsunder way to develop and distribute tools to support research and development of spokenlanguage systems. one such toolkit has been releasedby the center for spokenlanguage understanding at the oregon graduate institute (sutton et al., 1996).referencescole, r.a., l. hirschman, et al. 1995. the challenge of spokenlanguage systems: researchdirections for the nineties, ieee transactions on speech and audio processing, vol. 3, no.1, pp. 121.cole, r.a., j. mariani, h. uszkoriet, a. zaenen, and v. zue (eds.). 1996. survey of the state ofthe art in human language technology, cambridge university press, stanford university,stanford, calif.national center for education statistics. 1993. adult literacy in america, u.s. department ofmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics283education, technical report no. gpo 065000005883, u.s. government printing office,washington, dc, september.sutton, s., d.g novick, r. cole, p. vermeulen, j. de villiers, j. schalkwyk, and m. fanty.1996. building 10,000 spokendialogue systems, to appear in proceedings of the 1996international conference on spokenlanguage processing, philadelphia, pa. (informationon the availability of the toolkit is provided online at http://www.cse.ogi.edu/cslu/toolkit/toolkit.html.)more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.284more than screen deeptoward an everycitizen interfacesteven k. feinercolumbia universityintroductionbuilding user interfaces to the national information infrastructure(nii) that can fulfill the needs of all users, rather than just a privilegedsubset, will be a difficult task. in this position paper, i state my understanding of what the nii will be, lay out a set of goals for future nii userinterfaces, and describe some research issues and projects associated withthese goals.i take the nii to be the public medium supporting all forms of interaction between people and machines that do not require the transport ofphysical matter. a userõs interactions with the nii are accomplishedthrough displays, interaction devices, and controlling software, which together comprise a user interface. i expect that an interfaceõs displays andinteraction devices would in most cases be the property of an individual orprivate company, as would the facilities needed to communicate and storeinformation within a home, office, car, or pocket. the nii would includepublic networks that carry information between these private facilities andpublic sources of information and computation. moreover, it would alsoinclude public displays and interaction facilities (e.g., the global positioningsystem (gps) position tracking infrastructure), and software and standardsneeded to make communication and interaction possible.goalsi have tried to capture the properties that i believe user interfaces to thenii should ideally have in the following list of highlevel characteristics.multimediainteractions should be multimedia and multimodal, taking maximaladvantage of all our senses to communicate information effectively. i intend this to go beyond the combination of graphics, video, text, sound, andvoice typically implied by popular usage of the term multimedia to encompass the goals of research in virtual environments and visualization.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics285adaptiveuser interfaces should adapt to the needs and abilities of the individual user and situation, interactively tailoring both the form and content of the material being presented and providing customized help whennecessary. an adaptive user interface would take into account factors asdiverse as the userõs education, skills, previous experience, and physicalcapabilities or disabilities. recognizing that many activities are long lived,it should accommodate fluid and frequent changes in all aspects of theenvironment: who, what, where, when, why, and how.integratedinteraction through the nii should be integrated smoothly and naturally into our daily activities, rather than being, as it is now, a compartmentalized specialpurpose activity accomplished only when sitting infront of a workstation running special software. that is, the goal is notjust to get the nii into our homes but rather to get it into our lives. in partthis means mobility and wearability but without the compromises thatare built into current pdas.collaborativemany of the tasks we perform are group activities, not solitary endeavors. nii user interfaces should support collaborative work and play,regardless of whether users are collaborating in the same place or at thesame time.instructablea user should be able to describe tasks that are to be carried outthrough the nii. assuming that the lowestlevel steps are within thecapability of the resources available, the tasks should ideally be as richand complex as those that the user could describe to other people. ihesitate to use the word òprogrammableó here to avoid the implicationthat this should involve a conventional programming language, such asjava, or even the simpler languages provided by current systems for enduser programming.responsivelarge enough quantitative differences in performance can make forqualitative differences in how a user interface feels and how it is used.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.286more than screen deepsufficient resources must be available to all users to allow certain baselinetasks to be accomplished comfortably.empoweringindependent of a systemõs style (e.g., òinvisible,ó òintelligent agent,óor òdirect manipulation tooló), its users should be able to accomplishmore with it than without it and should feel a sense of satisfaction indoing so.research issues and projectseach subsection below provides a background overview, followed bya selected set of issues and projects, keyed to the list of characteristicspresented above.multimediabackgroundinterpreting òmultimediaó broadly, i see two major research subgoalshere: developing user interfaces that support realtime interaction withtrue threedimensional (3d) input/output devices (i.e., virtual environments or virtual worlds) and learning how to use these devices to presentinformation effectively, a task known in the graphics community as visualization. i am partial to the term information visualization (card et al.,1991), which is rapidly gaining currency (e.g., see gershon and eick, 1995)and which stresses the diversity of domains and users that can benefitbeyond those targeted by research on scientific visualization. while visualization research embraces work that appeals to senses other than thevisual, the term sonification has been used to refer explicitly to the ways inwhich information can be presented through sound (kramer, 1994).most stateoftheart commercial user interfaces emphasize the use of2d windows, with which users interact using 2d devices such as mice.increasing cpu (central processing unit) power, combined with the popularization of vrml (virtual reality modeling language; vrml, 1996)and the introduction of lowpriced sound, video, and 3d graphics cards,is transforming personal computers into 3d multimedia workstations.the results thus far are evolutionary: 3d graphics appear in 2d windowsand are manipulated under mouse control. research in 3d user interfacesextends beyond this to address the use of interactive 3d graphics, audio,and haptics, presented with true 3d stereo displays and 3d interactiondevices that monitor the userõs actions in threespace. the goal is tomore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics287harness the physiological capabilities and training that enable us to perform physical tasks effectively in 3d, and apply them to develop effectiveuser interfaces for visualizing and accomplishing computerbased tasks.issueswe must develop realtime operating systems support for highly parallel asynchronous input (from large numbers of 3d trackers) and output(to multipledisplay modalities). we need to build effective òaugmentedrealitiesó (caudell and mizell, 1992; bajura et al., 1992; feiner et al., 1993b)that enrich the userõs existing environment with additional information,merging synthesized material with what the user normally sees, hears,and feelsñoverlaying or replacing it, as appropriate. we need to developdisplay and interaction device hardware that matches our abilities betterthan the current offerings do, including highquality, highresolution,widefield displays (e.g., graphics, sound, force, temperature) and tracking (e.g., hand, body, eye). for example, there is a need for lightweight,comfortable, highquality, òseethroughó displays for use in augmentedrealities. a generalpurpose seethrough display technology would allowdifferential visual accommodation, corresponding to real and virtual objects at different distances in the same image. it would also perform fullvisiblesurface determination with all objects, real and virtual: virtualobjects should be able to occlude real objects, and real objects should beable to occlude virtual ones.how can we map abstract task domains effectively to a 3d environment in which we can visualize and manipulate objects in the domain?how can we take advantage of the richness of 3d gesture to reduce ourreliance on icons to express actions in current user interfaces? for example, rather than moving an item to the trash can, could we dispose of itby using an appropriate gesture?in a world of wholebody computer interaction, there may no longerbe any distinction between human factors in general and the human factors of computer interfaces. the existing hardware that limits our capabilities (and that also limits our mistakes) will be gone, making it possibleto create user interfaces that are both far better and far worse than anything we can create now. how can we ensure that 3d user interfaces areusable, especially in an environment that supports enduser programming and customization?projectsmuch of this work is and should be multidisciplinary. for example,the design of display and interaction device hardware and softwaremore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.288more than screen deepshould be informed by research in human psychophysics. the design ofuser interface software should draw on disciplines that have long explored the design and use of 3d space, such as architecture, industrialdesign, theater (laurel, 1993), and dance.adaptivebackgroundthis goal is to develop approaches that make it possible for userinterfaces to adapt interactively to the needs of the current user, situation,and hardware. adaptive multimedia user interfaces should be able todesign and present information to people through multiple output mediaand understand user input provided through multiple input media. theyshould be able to adapt to the userõs work mode, be it direct manipulationand exploration or passive observation.issuesto design highquality adaptive multimedia user interfaces, we mustfirst be able to design ones that function well in a single medium. wemust be able to perform highquality automated generation and understanding of individual media, ranging from those that have long beenexplored by artificial intelligence researchers (e.g., written text and speech)to less wellcharted terrain (e.g., graphics, audio, haptics).how can we predict and evaluate presentation quality? a systemshould be able to predict the quality of a presentation in the course ofdesigning it. based on these predictions, it should be able to refine thepresentation until it is adequate. this requires the ability to evaluate thepresentation (estimating how it will affect the user) and evaluating theuserõs response (estimating how it has affected the user). the ability toevaluate the presentation makes possible timequality tradeoffs. for example, if our time is limited, we might prefer a òrush jobó now over ahigherquality presentation later.temporal media are those in which information content is presentedover time in a way that is controlled explicitly by the producer (feiner etal., 1993a), such as animation, speech, and audio. we must develop generation and understanding capabilities for temporal media. issues include how to òphraseó information (e.g., for maximal comprehension).for example, we must develop the ability to generate output and understand input that communicates complex temporal relationships. if a system can convey the relative order of actions, information need not bemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics289provided in chronological order (e.g., presenting the most important information first, as in a newscast).we must develop facilities for coordinated generation and understanding of multiple media. the key challenge is to assure that materialin different media reinforce, rather than interfere with, each other. multimedia presentations must be temporally coordinated (especially whenusing temporal media such as animation and speech), so that informationpresented in all media is synchronized.given the everincreasing amount of information bombarding us,automated multimedia generation offers the potential for automated summarization, selecting the material most relevant to a userõs needs andpresenting it in a way that meets their time constraints.we must develop models that can be used as a basis for customizingthe interaction between users and systems so that information is presented and obtained as effectively as possible. these models must represent:¥users. including general human cognitive and physical abilities,individual abilities and preferences, and individual usersõ knowledge andskills.¥dialogue history. track and maintain a history of the interactionbetween users and systems. this information makes possible referencesto things that happened in the recent or distant past.¥resources. model the generation and input resources available tothe system, making it possible for the system to choose between differentways of providing or obtaining information, based on what displays andinteraction devices are or will be available.¥activities. the application knowledge per se, both general andspecific to what the users are doing.¥situations. model current situations (e.g., routine versus crisis,individual work versus multiuser interaction).rather than requiring that these models be static, they should be ableto be updated on the fly. difficult problems here include being able todetermine how a user is affected by a presentation. for example, can thesystem determine whether a user has actually learned the material that anexplanatory presentation is intended to communicate? ideally, it shouldbe able to do this based on the userõs normal interactions with the system,without requiring explicit testing.we need to develop the facilities to model the rhetorical structure ofmultimedia dialogues for real, complex multiuser tasks. this includeswhat a user tells the system, what the system tells the user, and whatusers tell other users, in addition to what the user(s) and system(s) eachmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.290more than screen deepbelieves the others have communicated. by studying current multimediainteractions and developing cognitive models that account for how information is being communicated among participants, we can lay thegroundwork for developing rules for generating and understanding multimedia.projectsthis research would center in the artificial intelligence and humancomputer inferface communities, especially in the fields of multimediageneration and understanding (sullivan and tyler, 1991; maybury, 1993)and modeling of users (kobsa and wahlster, 1989) and how they performtasks (card et al., 1983).integratedbackgroundintegration of the nii into our lives will mean, in part, accommodating users who are mobile, and who use the nii as they move about. asdisplays of all sizes proliferate, this will also spell the end of the oneuser,onedisplay metaphor that underlies so many current systems. we needto support interaction in a world in which there are many displays andinteraction devices: handheld, headworn, desktop, and wallmounted.some will be private, others public (or at least shared). as users walkabout, they will move into and out of the presence of some of these peripherals and of other users. we need to build user interfaces that exploitthis rich and constantly changing combination of peripherals.issuesdrawing an analogy to window management, the term environmentmanagement has been used (macintyre and feiner, 1996) to describe theidea of managing large numbers of objects on large numbers of displays.this is a difficult task: unlike the one or two displays that most windowmanagers typically control, the environment may be continually changing as users and resources move and may include displays and devicesthat are shared, such as a wallmounted hallway display. from the userõsstandpoint, however, environment management should ideally be easierthan the current task of window management. this could be possible ifenvironment management were to be carried out through systems thatused knowledge of the userõs needs and effective information presentamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics291tion approaches to determine how to structure the surrounding information environment.projectsresearch projects should build on ongoing research in mobile computing, wearable computing, ubiquitous computing (weiser, 1991), andaugmented reality.collaborativebackgrounduser interfaces should support collaborative problem solving andinteraction among multiple people and computers cooperating in thesame task or in coordinated tasks.issueswe must design systems that account for the personal presentationneeds of individual users while allowing for communication among usersbased on material they have been presented in common. an importantproblem here is how is to accommodate users who have been presentedwith different information and who would like to refer to the presentation as they interact with each other. the system might serve as an intelligent ògobetweenó that mediates between users so that references madeby one user to what she has been presented are translated into referencesto what another user has been presented.the nii has the potential to help create a strong sense of national (andglobal) community. consider the information infrastructure provided bya residential street, town square, or college dorm hallway. by encouraging citizens to interact with others across the country and providing information about our countryõs workings on the nii, we could foster a betterunderstanding of how people depend on each other and ultimately provide more opportunity for an informed populace to participate in government. imagine, for example, a multimedia simcitylike virtual environment that modeled the countryõs economy and supported collaborativeattempts to see how it responded to different situations and assumptions.projectsthere are separate communities of researchers in computersupportedcooperative work (many of whom concentrate on the design of multimemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.292more than screen deepdia systems in the popular sense of the term) and in distributed multiuservirtual environments. joint research projects could be especially fruitfulhere.instructabletwo key research areas for the creation of instructable systems areprogramming by demonstration and agents.programming by demonstrationbackground. research in enduser programming attempts to developways for end users to òprogramó an applicationõs behavior without theoverhead of learning or using a conventional programming language.one promising line of research is òprogramming by demonstration,ó inwhich users demonstrate the tasks to be performed using the applicationõsinterface (cypher, 1993). a simple example is the keyboard macrofacilityin emacs: the user can specify that a series of keystrokes issued in thecourse of editing should be saved (and optionally named and bound to akey), so that it can be applied again, typically at another place in thedocument being edited. since the demonstration is a specific example, ifit is to be applied to other situations, it must be generalized. in the case ofthe emacs keyboard macro, generalization is usually achieved solely byusing keystroke commands that operate relative to the current position inthe file.an allied notion is that of having the system learn patterns in theuserõs behavior and volunteer to complete some recognized pattern whenit guesses that the user has begun to perform it. existing research systemsmonitor the userõs interactions during a session, can present ògraphicalhistoriesó of a session, allow the creation of macros using abouttobeexecuted (or previously executed) commands, and can perform primitiveinferencing to support simple generalization.issues. most existing enduser programming facilities rely on simplestraightline flow of control (or escape into conventional programmingsyntax to perform all but the simplest conditionals and loops). how canenduser programs allow complex flow of control without looking andfeeling like conventional programming? how can they incorporatemultimodal interaction into the programming user interface itself?how can we generalize demonstrational programs in a way that minimizes the amount of enduser involvement while maximizing the placeswhere the system guesses right? when should generalization be permore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics293formedñat program creation time, at execution time? what sources ofinformation can be used?if large numbers of userdeveloped programs exist, how can the userfind the ones that are relevant to some specified task? how can the userdetermine what each does (without necessarily having to execute it)?note that this is a particularly difficult example of online search: the userisnõt looking for a match on a text string but rather on a set of capabilities,which may be implicit in the program.how can a userdeveloped program be modified? how can one develop an enduser programming capability that intrinsically supports cooperation among multiple users and systems?projects.most work in this domain has concentrated on 2d userinterfaces. i think there is much to be gained in trying to take advantageof interactive multimedia and 3d in the design of the language itself.agentsbackground. one kind of instructable interface is based on the metaphorof an òagentó that carries out a task on the userõs behalf, often usingknowledge and abilities that the user may not have herself. there hasbeen a fair amount of heated debate in the humancomputer interfacecommunity, pitting proponents of agentbased user interfaces againstthose who favor directmanipulation user interfaces. among the arguments against agents are claims that people may prefer interfaces overwhich they feel they have direct control and that agentbased interfacesare being unfairly touted as having some responsibility for their actionsbeyond that of their programmer or user.issues. i believe that much of the controversy is due to the popularconception of the agent as a busybody anthropomorphic assistant, in themanner of the nattering bowtied helper in appleõs òknowledge navigatoró videotape. while the argument has been made that users will notwant to sacrifice control to such agentbased systems, people willinglygive up control in other matters that do not involve computers. forexample, although it is common to compare the relative ease of using carsand computers, consider instead the carõs predecessors: horses, mules,and donkeys. environmental issues aside, would you really send even anexperienced driver hurtling down the grand canyonõs trails on a motorcycle? yet each year thousands of folks with no previous riding experience travel those same trails safely on mules. a muleõs rider exerts onlymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.294more than screen deepdiscretionary highlevel control with regard to general speed and direction,especially so for inexperienced riders. riders are even told that, if acrophobia sets in, they should just close their eyes, hold on, and let the mule findits wayñthe original intelligent user interface. mules are hardly anthropomorphic (although the reverse is sometimes true), yet they are possessed ofskills and abilities that we donõt have. while we may be amazed at howmuch more surefooted they are than us, we find this reassuring, not intimidating. instead of asking why computers canõt be more like cars, perhapswe should ask why computers canõt be more like mules.projects. there is already overlap between the programmingbydemonstration and agentbased systems communities, particularly in addressinghow agents can be instructed to perform tasks. coordinated projects couldaddress how users would determine what these systems can do (includingwhat they can learn and what they already know). there is also potentialfor joint research with the multimedia generation community.responsivebackgroundthe goal is to build systems that can utilize the power availablethroughout the nii in a way that doesnõt compromise the responsivenessof the user interface.issuesresources needed to make a responsive system include not only network bandwidth and computational power but also appropriately sizedand sited storage. while we can assume that users will have personalstorage space at home, permanent or temporary mirroring of material atadditional sites throughout the nii might be able to significantly decreasenetwork load and response time. for example, we might have a system oflarge public storage caches located throughout the country to provideusers with relatively local copies of frequently referenced material. thiscould include both conventional òmirroró sites and caches of currentlyaccessed material controlled by some automated paging strategy. thiscould be the next tier in a caching system that would include the individual local memory and disk caches of current web browsers.projectsmany of the issues here build on research being done in the systemsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics295(os and distributed systems) and multimedia storage/transport communities.empoweringbackgroundplainly put, we need to study the kinds of things that people do anddetermine how the nii can best assist in doing them. in part, this willinvolve building the models of activities mentioned previously.issuesi trust that falling prices will ultimately put any technology that hasthe potential to be popular within the reach of all. this has happenedwith television, microwave ovens, walkmanstyle tape players, digitalwatches, and compactdisc changers. it is about to happen with computers, be they nettops, settops, palmtops, or something else. unlike fixedfunction devices, however, computers (in particular, computer programs)have an essentially unlimited potential to confuse and intimidate. whilemuch of this potential can be mitigated through better user interface design, there is no substitute for users having the right skills and mindset.even if we can build powerful systems that are truly òselfteaching,óusers will still need time to learn how to use them effectively. we need toensure not only that computer skills (whatever that might mean in thefuture) are taught in school but also that there is ample opportunity andtime for people who are not in school to acquire them.projectsexperimental studies and model building by academic and industrialresearchers address only one part of the problem. enlightened social andgovernmental policies also will be key.referencesbajura, m., fuchs, h., and ohbuchi, r. 1992. merging virtual objects with the real world:seeing ultrasound imagery within the patient. computer graphics 26(2):203210.card, s., moran, t., and newell, a. 1983. the psychology of humancomputer interaction.lawrence erlbaum associates, hillsdale, n.j.card, s.k., robertson, g.g., and mackinlay, j.d. 1991. proceedings of the computer humaninteractions: human factors in computing systems, pp. 181188. the informationvisualizer, an information workspace. new orleans, la., april 28may 2.caudell, t., and mizell, d. 1992. augmented reality: an application of headsup displaymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.296more than screen deeptechnology to manual manufacturing processes, proceedings of the hawaii internationalconference on system science, january.cypher, a. (ed.). 1993. watch what i do: programming by demonstration, mit press,cambridge, mass.feiner, s., litman, d., mckeown, k., and passonneau, r. 1993a. towards coordinatedtemporal multimedia presentations. intelligent multimedia interfaces, m. maybury (ed.),pp. 139147. aaai/mit press, menlo park, calif.feiner, s., macintyre, b., and seligmann, d. 1993b. knowledgebased augmented reality.communications of the acm 36(7):522.gershon, n., and eick, s. (eds.). 1995. proc. information visualization õ95. ieee computersociety press, los alamitos, calif.kobsa, a., and wahlster, w. (eds.). 1989. user models in dialogue systems. springerverlag,berlin.kramer, g. (ed.). 1994. auditory display: sonification, audification, and auditory interfaces.addisonwesley, reading, mass.laurel, b. 1993. computers as theatre. addisonwesley, reading, mass.macintyre, b., and feiner, s. 1996. future multimedia user interfaces. multimedia systems.maybury, m. (ed). 1993. intelligent multimedia interfaces. aaai/mit press, menlo park,calif.sullivan, j., and tyler, s. (eds.). 1991. intelligent user interfaces. addisonwesley, reading,mass.vrml (virtual reality modeling language). 1996. the vrml forum (available online athttp://vrml.wired.com/).weiser, m. 1991. the computer for the 21st century. scientific american 265(3):94104.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics297nomadicity, disability access, andthe everycitizen interfacegregg c. vanderheidenuniversity of wisconsinmadisonthe challengewith the rapid evolution of the national information infrastructure(nii) and the global information infrastructure (gii), attention has turnedto the issue of information equality and universal access. basically, ifinformation systems become as integral to our future lifestyles as electricity is today, access to these systems will be essential for people to haveequal access to education, employment, and even daily entertainment orenrichment activities.although the goal of equal access seems noble, it can seem somewhatless achievable when one considers the full range of abilities or disabilities which must be dealt with to achieve an everycitizen interface. itmust be usable even if people¥cannot see very wellñor at all;¥cannot hear very wellñor at all;¥cannot read very wellñor at all;¥cannot move their heads or arms very wellñor at all;¥cannot speak very wellñor at all;¥cannot feel with their fingers very wellñor at all;¥are short, are tall, use a wheelchair, and so forth;¥cannot remember well;¥have difficulty learning or figuring things out;¥have little or no technological inclination or ability; and/or¥have any combination of these difficulties (e.g., are deafblind;have reduced visual, hearing, physical, or cognitive abilities, which occurs in many older individuals).in addition, the products and their interfaces must remain equallyefficient and easy to use and understand for those who (1) have no problems seeing, hearing, moving, remembering, and so forth; and (2) arepower users.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.298more than screen deepis it possible?a list like this can bring a designer up short. at first blush, it appearsthat even if such an interface was possible it would be impractical orinefficient to use for people with all of their abilities intact. packages suchas the ez access approach developed for kiosks (http://trace.wisc.edu/world/kiosk), pdas (personal digital assistants), and other touchscreendevices, however, demonstrate how close we can come to such an ideal, atleast for some types of devices or systems. using a combination of talking fingertip and speed list technologies, the ez access package (forinformation, see http://trace.wisc.edu/text/kiosk/minimum.htm)provides efficient access for individuals with low vision, blindness, andpoor or no reading skills. a showsounds/caption feature provides access for individuals with hearing impairments or deafness, as well asaccess for all users in very noisy locations. an infrared link allows thesystem to be used easily with alternate displays and controllers, so thateven individuals who are deafblind or paralyzed can access and use thesystem. thus, with a relatively modest set of interface variations, almostall the needs listed above can be addressed.is it practical?practicality is a complex issue which involves cost, complexity, impact on overall marketability, support, and so forth. to use the ez accessapproach as an example, the hardware cost to provide all of these dimensions of accessibility to a standard multimedia kiosk is less than 1 percentof the cost of the kiosk. addition of this technique does not affect thestandard or traditional mode of operation of the kiosk at all. at the sametime, it makes the system usable by many visitors as well as new citizenswhose native language is not english, and who may have some difficultywith words. implementing crossdisability interface strategies can takeonly a few days with the proper tools. ez access techniques are currentlyused on commercial kiosks in the mall of america and other locations.other examples of builtin accessibility are the access features that arebuilt into every macintosh and windows 95based computer.thus, if done properly, interfaces that are flexible or adjustableenough to address a wide range of individuals can be very practical.there are, however, approaches to provide additional access or access foradditional populations that are not currently practical (e.g., building$2,000 dynamic braille displays into every terminal or kiosk). in thesecases, the most practical approach may be to make the information andcontrol necessary for operation of the device available on a standard connector so that a person who is deaf and blind can connect a braille displaymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics299and keyboard. practicality also is a function of the way the access featuresrelate to and reinforce the overall interface goals of the product.how does an everycitizen interface relate tonomadic systems?the devices of tomorrow, which might be referred to asteletransinfocom (teletransaction/information/communication) devices, will operate in a wide range of environments. miniaturization,advances in wireless communication, and thinclient architectures are rapidly eliminating the need to be tied to a workstation or carry a largedevice in order to have access to computing, communication, and information services and functions.as a result, we will need interfaces for use while driving a car, sittingin an easy chair, sitting in a library, participating in a meeting, walkingdown the street, sitting on the beach, walking through a noisy shoppingmall, taking a shower, or relaxing in a bathtub, as well as sitting at a desk.the interfaces also will have to be usable in hostile environmentsñwhencamping or hiking, in factories or shopping malls at christmas time.many of us will also need to access our information appliance (orappliances) in very different environments on the same dayñperhapseven during the same communication or interaction activity. these different environments will place constraints on the type of physical andsensory input and output techniques that work (e.g., it is difficult to use akeyboard when walking; it is difficult and dangerous to use visual displays when driving a car; speech input and output, which work fine in acar, may not be usable in a shared office environment, a noisy mall, ameeting, or a library). systems designed to work across these environments will therefore require flexible input/output options to work indifferent environments. the interface variations, however, must operatein essentially the same way, even though they may be quite different(visual versus aural). users will not want to master three or four interfaceparadigms in order to operate their devices in different environments.the metaphor(s) and the òlook and feeló must be continuous even thoughthe devices operate entirely visually at one point (e.g., in a meeting) orentirely aurally at another (e.g., while driving a car). many users will alsowant to be able to move from one environment to another, one device toanother (e.g., workstation to handheld), and one mode to another (e.g.,visual to voice) in the midst of a task.does nomadicity equal disability accessible?it is interesting to note that most of the issues regarding access formore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.300more than screen deeppeople with disabilities will be addressed if we simply address the issuesraised by the range of environments described above:¥when we create interfaces that work well in noisy environmentssuch as airplanes, construction sites, or shopping malls at christmas, andfor people who must listen to something else while they use their device,we will have created interfaces that work well for people who cannot hearwell or at all.¥when we create interfaces that work well for people who are driving a car or doing something that makes it unsafe to look at the devicethey are operating, we will have created interfaces that can be used bypeople who cannot see.¥as we develop very small pocket and wearable devices for circumstances in which it is difficult to use a fullsized keyboard or even alarge number of keys, we will have developed techniques that can beused by individuals with some types of physical disabilities.¥when we create interfaces that can be used by someone whosehands are occupied, we will have systems that are accessible to peoplewho cannot use their hands.¥when we create interfaces for individuals who are tired, understress, under the influence of drugs (legal or illegal), or simply in themidst of a traumatic event or emergency (and who may have little abilityto concentrate or deal with complexity), we will have interfaces that canbe used by people with naturally reduced abilities to concentrate or dealwith complexity.thus, although there may be residual specifics concerning disabilityaccess that must be covered, the bulk of the issues involved are addressedautomatically through the process of developing environment/situationindependent (modalityindependent) interfaces.what is needed?interfaces that are independent of the environment or the individualmust have the following attributes:¥wide variability in order to meet the diversity of tasks that will be addressed. some interfaces will have to deal only with text capture, transmission, and display. others will have to deal with display, editing, andmanipulation of audiovisual materials. some may involve vr (virtualreality), but basically be shopandselect strategies. others may requirefull immersion, such as data visualization and telepresence.¥modality independence. interfaces have to allow the user to choosesensory modalities appropriate to the environment, situation, or user.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics301textbased systems will allow users to display information visually atsome times and aurally at others, on highresolution displays when available and on smaller lowresolution displays when necessary.¥flexibility/adaptability. interfaces will be required that can takeadvantage of fine motor movements and threedimensional gestures whena userõs situation or abilities allow but can also be operated by usingspeech, keyboard, or other input techniques when this is necessary because of the environment, the userõs activities, or any motor constraints.¥straight forwardness and ease of use. as much of the population aspossible must be able to use these interfaces and to master new functionsand capabilities as they are introduced.some components necessary to achieve everycitizen interfacesalthough this section does not address all possible interface types,particularly freehand graphic production interfaces (e.g. painting), it doesaddress the majority of commandandcontrol interfaces.1.modality independence. for a device or system to be modality independent or altmodal (i.e., the user can choose between alternate sensorymodalities when operating the device), two things are necessary:a.all of the basic information must be stored and available ineither modalityindependent or modalityredundant form.modality independent refers to information that is stored in a formthat is not tied to any particular form of presentation. for example, asciitext is not inherently visual, auditory, or tactile. it can be presented easilyon a visual display or printer (visually), through a voice synthesizer (aurally), or through a dynamic braille display or braille printer (tactually).modality redundant refers to information that is stored in multiplemodalities. for example, a movie might include a visual description ofthe audio track (e.g., caption) and an audio and electronic text descriptionof the video track so that all (or essentially all) information can be presented visually, aurally, or tactually at the userõs request based on need,preference, or environmental situation.b.the system must be able to display data or information indifferent modalities. that is, it should provide a mechanism for displaying information in allvisual, or allauditory, or mixed audiovisual formas well as in electronic form.2.flexibility/adjustability. the device must also offer alternate selection techniques that can accommodate varying physical and sensory abilities arising from the personal environment or situation (e.g., walking,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.302more than screen deepwearing heavy gloves), and/or personal abilities. suggested alternateoperating modes follow:¥standard mode. this mode often uses multiple simultaneous sensesand fine motor movements. it would offer the most effective device forindividuals who have no restrictions on their abilities (due to task, environment, or disability).¥a list mode. in this mode, the user can call up a list of all theinformation and action items and use the list to select items for presentation or action. it would not require vision to operate. it could be operatedusing an analog transducer to allow the individual to move up and downwithin a list, or a keyboard or arrow keys combined with a confirm buttoncould be used. this mode can be used by individuals who are unable tosee or look at a device.¥external list mode. this would make the list available externallythrough a software or hardware port (e.g., infrared port) and accept selections through the same port. it can be used by individuals who are unableto see and hear the display and therefore must access it from an externalauxiliary interface. this would include artificial intelligent agents, whichare unable to process visual or auditory information that is unavailable intext form.¥select and confirm mode. this allows individuals to obtain information about items without activating them (a separate confirm action isused to activate items after they are selected). it can be used by individuals with reading difficulties, low vision, or physical movement problems,as well as by individuals in unstable environments or whose movementsare awkward due to heavy clothing or other factors.¥autostep scanning mode. this presents the individual items ingroups or sequentially for the user to select. it can be used by individualswith severe movement limitations or movement and visual constraints(e.g., driving a car), and when direct selection (e.g., speech input) techniques are not practicable.¥direct text control techniques. these include keyboard or speechinput.example: using a unilistbased architectureas part of the interfaceone approach to device design that would support this type of flexibility is the unilist architecture. by maintaining a continually updatedlisting of all the information items currently available to the user, as wellas all the actions or commands available, it is possible to provide a veryflexible and adjustable user interface relatively easily. all the techniquesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics303listed above are easy to implement with such an architecture, and it canbe applied to a range of devices or systems.take, for example, a threedimensional (3d) virtual realitybasedshopping mall. in such an application, a database is used to provide theinformation needed to generate the image seen by the user and the responses to user movements or actions on objects in the view. if properlyconstructed, this database could also provide a continually updated listing of all objects in view as well as information about any actionableobjects presented to the user at any time. by including verbal (e.g., text)information about the various objects and items, this 3d virtual shoppingsystem can be navigated and used in a variety of ways to accommodate avariety of users or situations.¥individuals who are unable to see the screen (because they aredriving their car, their eyes are otherwise occupied, or they are blind) canhave the information and choices presented vocally (or via braille). theycan then select items from the list in order to act on them, in much thesame that an individual can pick up or òclick onó an object in the environment.¥individuals with movement disabilities can have a highlight oròspriteó step around to the objects, or they could indicate the approximatelocation and have the items in that location highlighted individually (othermethods for disambiguating also could be used) to select the desireditem.¥individuals who are unable to read can touch or select any printedtext presented and have it read aloud to them.¥individuals with low vision (or who do not have their glasses) canuse the system in the same way as a fully sighted individual. when theyare unable to see well enough to identify the objects, they can switch intoa mode that lets them touch the objects (without activating them) and canthereby have them named or described.¥individuals who are deafblind could use the device in the samefashion as an individual who is blind. instead of the information beingspoken, however, it could be sent to the individualõs dynamic brailledisplay.additional benefits of flexible, modalityindependent architectures and data formatsthe two key underlying strategies for providing more universal access are input and display flexibility and the companion availability ofinformation in sensory/modalityindependent or parallel form.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.304more than screen deepboth input and display flexibility and presentation independencehave additional benefits beyond the everycitizen interface. these include the following:¥nomadicity support (discussed above).¥searchability. graphic and auditory information that contains textstreams can be indexed and found by using standard textbased searchengines, which not only can locate items but also can jump to particularpoints within a movie or a sound file.¥alternate client support. the same information can be stored andserved to different types of telecommunication and information devices.for example, information could be accessed graphically over the internet,via a telephone by using a verbal form, or even by intelligent (or not sointelligent) agents using electronic text form.¥display flexibility. presentationindependent information alsotends to be display size independent, allowing it to be more easily accessed using very small, lowresolution displays. (in fact, some lowresolution displays present exactly the same issues as low vision.)¥low bandwidth. the ability to switch to text or verbal presentationcan speed access over lowbandwidth connections.¥future support. modalityindependent servers will also be betterable to handle future serving needs that may involve access to information using different modalities. creating a legacy system that cannothandle or serve information in different modalities may necessitate a hugerework job in the future as systems evolve and are deployed.limitationstoday, most of the universal access strategies are limited to information that can easily be presented verbally (in words). however, althoughthe grand canyon could be presented in three dimensions through virtual reality, its full impact cannot be captured in words, nor can a picassopainting or mahler symphony easily be made sensory modality independent. also, although planes could be designed to fly themselves, we donot as yet know how to allow a user who is blind to control directly flightthat currently requires eyehand coordination (or its equivalent). thereare also situations in which the underlying task requires greater cognitiveskills than an individual may possess, regardless of the cognitive skillsrequired to operate the interface. it may be a while before we resolvesome of these limitations to access.on the other hand, we also have many examples where interfacesthat were previously thought to be unusable by individuals with a particular disability, were later made easily accessible. the difference wasmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on interface specifics305simply the presence or absence of an idea. the challenge, therefore, is todiscover and develop strategies and tools that can make nextgenerationinterfaces accessible to and usable by greater numbers of individuals andeasier for all to use.summarythrough the incorporation of presentationindependent data structures, an available information/command menu, and several easytoprogram selection options, it is possible to create interfaces that begin toapproximate the anytimeanywhereanyone (aaa) interface goal. someinterfaces of this type have been constructed and are now being used inpublic information kiosks to provide access to individuals with a widerange of abilities. the same strategies can be incorporated into nextgeneration teletransinfocom devices to provide users with the nomadicity they will require in nextgeneration internet appliances.before long, individuals will look for systems that allow them to begin an important communication at their desk, continue it as they walk totheir car, and finish it while driving to their next appointment. similarly,users will want the ability to move freely between high and lowbandwidth systems to meet their needs and circumstances. they will want toaccess their information databases by using visual displays and perhapsadvanced data visualization and navigation strategies while at a desk, butauditoryonly systems as they walk to their next appointment. they mayeven wish to access their personal rolodexes or people databases whileengaged in conversations at a social gathering (by using a pocket keypadand an earphone to ask, what is mary jonesõ husbandõs name?).the approaches discussed will also allow these systems to addressissues of equity such as providing access to those with disabilities or thosewith lowertechnology and lowerbandwidth devices and providing support for intelligent (or notsointelligent) agent software. the aaa strategies discussed here do not provide full crossenvironment access to alltypes of interface or information systems. in particular, as noted above,fully immersive systems that presented inherently graphic (e.g., paintings) or auditory (e.g., symphonies) information will not be accessible toanyone who does not employ the primary senses for which this information was prepared (text descriptions are insufficient). however, the majority of todayõs information and most services can be made availablethrough these approaches, and extensions may provide access to evenmore.finally, it is important to note that not only do environment/situationindependent interfaces and disabilityaccessible interfaces appear tobe closely related, but also one of the best ways to explore environment/more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.306more than screen deepsituationindependent nomadic interface strategies may be the exploration of past and developing means for providing crossdisability access tocomputer and information systems.challenges and research areasfor a system to be more accessible to and usable by every citizen, itmust be (1) perceivable, (2) operable, and (3) understandable.the following areas of research can help to address these needs:¥data structures, compression, and transport formats that allowthe incorporation of alternate modalities or modalityindependent data(e.g., text embedded in sound files or graphic files);¥techniques and architectures for partial serving of information,(such as the ability to fetch only the visual, the auditory, the text, or anycombination of these tracks from a multimedia file or to fetch one part ofa file from one location and another part from a second location (e.g.,fetching a movie from one location and the captions from another);¥modality substitution strategies (e.g., techniques for restructuringdata so that earhand coordination can be substituted for eyehand coordination);¥natural language interfaces (e.g., the ability to have informationpresented conversationally and to control products with conversation,whether via speech or òtypedó text);¥alternate, substitute, and remote interface communication protocols (e.g., robust communication protocols that allow sensory and presentationindependent alternate interfaces to be connected to and usedwith devices having less flexible interfaces);¥voicetolerant speech recognition (ability to deal with disarthricand deaf speech);¥dynamic tactile displays (two and threedimensional tactile andforce feedback 3d);¥better random access to information/functions (instead of treewalking); and¥speedlist (e.g., ez access) equivalent access to structured vrenvironments.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions307307position paperson functionscomputermediated collaborationloren terveenat&t researchinterface . . . interaction . . . collaborationa narrow view of the humancomputer interface focusing on superficial òlookandfeeló issues is unproductive. it offers neither deep understanding nor practical design guidance. even simple interface decisionsmay require significant knowledge about peopleõs interaction with a system. three interfaces provide practical examples: the popcorn button onmicrowave ovens, the vcr (video cassette recorder)+ system, and theatm (automated teller machine) fast cash withdrawal button. each ofthese interfaces was added years into the product cycle in response topeopleõs actual use of the products. at a theoretical level, hutchins et al.(1986) couched their seminal analysis of direct manipulation interfaces interms of usersõ cognitive situation and resources, a general model of tasks,and the coupling between user goals and interface features. their analysis shows why interface design decisions cannot be made on the basis oflook and feel alone.indeed, we also begin to see that people may require even more frommore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.308more than screen deepsystems, namely help with tasks they donõt know enough about to do ontheir own. norman (1986) observed that the pinball construction setmakes it easy to design computerized pinball games but not good games;this takes knowledge about pinball design. more generally, schoen (1983)discussed how skilled professionals can interpret the state of their workobjects to make good decisions; they act and the situation òtalks back.óthe problem is that less skilled people may not be able to understandwhat the situation is òsaying.ó fischer and reeves (1992) studied interactions between customers and sales agent in a large hardware store. theyidentified crucial knowledge only the sales agents possessed, which theyused to help customers. the knowledge included knowing that a toolexisted, how to find a tool, the conditions under which a particular toolshould be used, and how to combine tools for a specific situation.people often work together on tasks. thus, in addition to collaborating with users, another appropriate role for systems is to support humancollaboration. the field of computersupported cooperative work (cscw)seeks to understand the nature of joint work and design technologies tosupport it. important technologies include shared editors, group discussion support tools, and awareness systems.even when people do not work together explicitly, they still can benefit from the prior experience and opinions of others. computationaltechniques for mining such information and turning it into a reusableasset raise the potential for a form of òvirtual collaboration,ó with some ofthe benefits of collaboration without the costs of communication or personal involvement.to summarize, there are three fundamental motivations for collaborative systems and a research approach built on each one:¥tasks require specialized skills and knowledge intelligent collaborative agents¥work is inherently social  computersupported cooperative work¥people can reuse the experience of others virtual collaborationnext i discuss the prospects for collaboration in common tasks supported by the national information infrastructure (nii).the niiñwhat people use it for, wherecollaboration is neededthe change from standalone to networked computers is transforming computers from desktop tools into windows on the world, from information containers and processors into communication devices. themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions309world wide web is the primary innovation ushering ordinary citizensinto this new world, so much of my discussion focuses on the web.the world wide web was designed expressly to support communication and collaboration among geographically distributed colleagues(bernerslee et al., 1994). specifically, it supports information sharing,with the dual aspects of publishing and finding information. as the webhas expanded to embrace a diverse population of users and a broad rangeof uses, more activities have become important:¥personperson communication (e.g., through email or ònewsgroupsó; entertainment, arts, and advertising; from web sites for the latestmovies to highquality online magazines to serious (or notsoserious) artistic sites).¥commerceñoffering items for sale, finding items that match oneõsinterests; brokering between buyers and sellers.¥educationñfor example, online course materials, interactive tutorials, and distributed science experiments.let us next consider the role of collaboration in these activities:¥information sharing. information seekers need assistance in finding highquality, relevant information in the vast, everchanging sea ofweb sites. information publishers need assistance in designing functional and attractive interactive applications.¥personperson communication. all the major cscw issues arise here(e.g., shared document access, discussion support, awareness aids).¥entertainment, arts, and advertising. there is great potential forcomputational agents in interactive fiction, social roleplaying environments, and games (lifelike computer characters conferenceñhttp://www.research.microsoft.com/lcc.htm; maes, 1995).¥commerce. computational matchmaking agents can bring together buyers and sellers. support for communication protocols such asauctions also is important.¥education. computational agents can engage learners. teachersand students need support for communicating and working together(e.g., to complete assignments and carry out experiments).computermediated collaboration:a unifying perspectivea unified research framework offers two main benefits: (1) it advances communication and understanding among researchers by helpingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.310more than screen deepthem to share and compare methods and results, and (2) it makes it easierto explore designs that integrate different types of collaboration. i propose a perspective of òcomputermediated collaborationóñpeople collaborating with people, mediated by computation.a given instance of computermediated collaboration can be characterized by using the following dimensions:¥roles and responsibilities of the human participants;¥nature of the computational mediation, including;ñhow information is acquired, processed, and distributed;ñwhether the information evolves during (and in response to)system usage;ñtemporal properties of the mediation (e.g., synchronous vs.asynchronous, time delays); andñnature of the humancomputer interaction.this framework is adequate for describing cscw and virtual collaboration; both of these explore computational techniques for mediating human collaboration. as applied to collaborative agents, it highlights theinvolvement of the people who create the agents, both domain expertswhose knowledge is modeled in the agents and knowledge engineers (orartificial intelligence researchers) who work with the experts to articulatethe knowledge and develop representations and algorithms for using it.it also reminds us of the time and resource costs of the design process.more deeply, the framework guides us to consider combinations ofvarious types of collaboration. for example, users of a computationalagent may not think about its designers when things work; however,whenthe useragent interaction breaks down, an effective remedy may be toprovide the user access to a knowledgeable human expert, such as thedomain expert involved in designing the agent (terveen et al., 1995). orwhen an agent has inadequate knowledge to perform a task on behalf ofits user, it might be able to obtain assistance from other agents (lashkariet al., 1994).research issuesdividing responsibility among people and computational agentspeople and computers have fundamentally different abilities. thus, abasic issue is creating divisions of responsibility that maximize thestrengths and minimize the weaknesses of each (terveen, 1995). òcriticsó(fischer et al., 1993) represent a wellknown approach that responds tothis issue. critics are agents who observe users as they work in a compumore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions311tational environment and offer assistance from time to time. users areresponsible for the overall course of the work, while critics use domainexpertise to help users solve problems and evolve their conception of theproblem. while much interesting work has been done in this area, mostof it still consists of proofofconcept explorations. the next step is todevelop robust generalizations that can be embedded in toolkits.collecting and evaluating data necessary for virtual collaborationtwo major approaches to virtual collaboration have been explored.systems like the bellcore recommender (hill et al., 1995) and firefly(http://www.firefly.com) ask users to rate objects of interest, such asmovies or music. the systems maintain a database of raters and theirratings, compute similarities among raters, and recommend objects topeople that were rated highly by other people with similar tastes. datamining approaches (hill and hollan, 1994; hill and terveen, 1996) attempt to extract useful information automatically from peopleõs normalactivities, such as reading and editing documents or discussing topics onnetnews. (one goal is to require little or no extra data entry from users.)abstracted versions of this information are then made available to otherpeople engaged in the same activity.one of the major issues for both types of approaches is obtaining thenecessary information. for ratings systems the question is: will enoughpeople rate? for datamining systems, the questions include: can usefulinformation be extracted automatically? can it be extracted efficiently(important since quality often comes from aggregating over large amountsof data)? can it be extracted and reused without violating the privacy ofthe people who produced it?once datañrecommendations or ratingsñare available, the problemis to evaluate them. one good way to do this is to consider the source;some people are more credible for any given topic. therefore, computinga personõs credibility from available data is a second major problem. onecomplication is that most interaction on the world wide web is anonymous; if one cannot even attribute particular actions or opinions to aperson, it is hard to compute his or her credibility. this again raises apotential conflict in values between the privacy of online interaction andthe attempt to mine information that could be used to enhance interaction.the credibility problem can be further refined into that of determining good sources (raters/recommenders) for a specific person. developing effective algorithms for this is precisely what the ratings approachdoes. however, the problem is harder for datamining approaches: theymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.312more than screen deepoperate only on alreadyavailable data, and existing data may not alwaysbe an adequate source for computing similarities among people.introducing computational agents into online communitieswhen an agent participates in an online community, such as anewsgroup or textbased virtual reality (e.g., a mud or moo), interestingissues arise beyond those faced in singleuser humancomputer collaboration. i illustrate these issues using phoaks (hill and terveen, 1996),which serves as a group memory agent that maintains recommendedweb pages for a group.¥will the community accept the agentõs participation? every community has behavioral norms. an agent ought not violate these norms(the norms for an agent may well be different than those for people).some concern has been expressed that the phoaks ranking of web resources by frequency of mention might distort community behavior (e.g.,inducing people to post many spurious messages recommending theirfavorite resources). thus, one must consider not only whether an agentrespects community norms but also whether its participation may causeothers to violate the norms.¥does the agent make a useful contribution to the community? infonerõs (http://foner.www.media.mit.edu/people/foner/julia/julia.html)discussion of the interesting social characteristics of the òjuliaó agent, hepoints out that òsheó serves useful functions, including taking and delivering messages, giving navigation advice, and sharing gossip. we also shouldconsider to whom an agent is to be useful (e.g., community insiders, newcomers, or outsiders), especially since their interests may be different. forexample, phoaks could make it easy to contact community participantsby email (or even by telephone). while outsiders might find this anattractive way to get information, presumably the community participants would be displeased.¥will the community help make the agent smarter? an agent begins its participation in a community with some knowledge. if the agenthas the capability to learn, and the community will offer necessary inputthe agent can improve over time. for example, phoaks maintains aranked set of web pages for each newsgroup based on its categorizationof url mentions in messages. however, it will miscategorize some urls,and some important urls may not be mentioned or may be mentionedinfrequently, perhaps because they are so well known (e.g., they may bein the faq). therefore, phoaks contains forms that allow people togive opinions on the web pages it links to and to add additional links.the general problem is to create techniques that let the system obtainmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions313performanceenhancing feedback and that people are willing and able touse. or machine learning techniques may be used that let agents learn ontheir own.¥who stands behind the agent? sometimes community memberswant to talk to the people behind the agent. maybe they want moreinformation, or maybe the agent has done something that makes themangry. we have seen both in phoaks. people ask questions about thetopic of a newsgroup, like where to find a bagpiper. people complainabout the way phoaks has categorized web pages; for example, in rarecases a condemnation of a web page (e.g., from a hate group) is categorized as a recommendation. sometimes, we have manually changed thephoaks databases, and less frequently we have modified the categorization algorithms or interface. the general problem is how to provideneeded human backup for agents who may be participating in many (e.g.,thousands of) different communities at once.conclusioni would like to conclude with two claims. first, if we take the argument of this paper seriously, we need not one but many everycitizeninterfaces to the nii. it is specific appropriate types of computermediated collaborations that have the potential to increase the access andpower of ordinary citizens, not a standard lookandfeel. second, research must move into the real world. many of the phoaks issuesdiscussed here are ones not anticipated, but discovered only by wadinginto the uncontrolled, unpredictable, messy world wide web. we havebeen able to formulate issues, hone our tools, and evaluate our results inways that we could not have done if we had stayed in our laboratories. atsome stage, all promising new research ideas will have to take the sameplunge to prove their benefits to the ordinary citizen engaging in life onthe nii.acknowledgmentsi thank will hill for our collaboration on phoaks and for our manyconversations developing and exploring the issues mentioned here.referencesbernerslee, t., cailliau, r., luotonen, a., nielsen, h.f., and secret, a. (1994) the worldwide web. communications of the acm, 34(12), 321347.fischer, g., and reeves, b. (1992) beyond intelligent interfaces: exploring, analyzing, andcreating success models of cooperative problem solving. applied intelligence, 1, 311332.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.314more than screen deepfischer, g., nakakoji, k., ostwald, j., stahl, g., and sumner, t. (1993) embedding critics indesign environments. the knowledge engineering review journal, 4(8), 285307.hill, w.c., and hollan, j.d. (1994) historyenriched digital objects: prototypes and policyissues. the information society, 10, 139145.hill, w.c., stead, l., rosenstein, m., and furnas, g. (1995) recommending and evaluatingchoices in a virtual community of use. pp. 194201 in chiõ95. acm press, new york.hill, w.c., and terveen, l.g. (1996) using frequencyofmention in public conversationsfor social filtering. cscwõ96. acm press, new york. (see also http://www.phoaks.com/phoaks/)hutchins, e.l., hollan, j.d., and norman, d.a. (1986) direct manipulation interfaces. pp.87124 in norman, d.a., and draper, s.w., eds., user centered system design. erlbaum,hillsdale, n.j.lashkari, y., metral, m., and maes, p. (1994) collaborative interface agents. in aaaiõ94.aaai press, seattle, wash.maes, p. (1995) artificial life meets entertainment: interacting with lifelike autonomousagents. communications of the acm, 38(11), 108114.norman, d.a. (1986) cognitive engineering. pp. 3161 in norman, d.a. and draper, s. w.,eds., user centered system design. erlbaum, hillsdale, n.j.schoen, d. (1983) the reflective practitioner. basic books, new york.terveen, l.g. (1995) an overview of humancomputer collaboration. knowledgebasedsystems, 8(23), 6731.terveen, l.g, selfridge, p.g., and long, m.d. (1995) living design memory: framework,system, and lessons learned. humancomputer interaction, 10(1), 137.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions315creating interfacesfounded on principles of discoursecommunication and collaborationcandace sidnerlotus development corporationtodayõs user interfaces are just too hard to use: they are too complexeven for the narrow range of users for whom they were designed. at thesame time, they also are impoverished in the range of modalities whichthey provide to users. while new modalities are becoming available, theycould make interfaces even harder to use. whatõs the solution to thisdilemma? principles of human discourse communication and of humantohuman collaboration are two critically overlooked sources for simplifying interfaces. they offer a means of integrating various modalities andof extending the range of computer users.until recently user interface technology has not made use of what isnow understood about the principles of discourse that govern humancommunication or the principles of collaboration that model joint work.this may seem surprising because interfaces are òcommunication enginesó to the functionality software applications; interfaces are how weget our work done. while the field of computersupported cooperativework has directed the majority of its concerns at understanding how computers can be used to help people work together, the computer has notbeen seen as a fullfledged partner in the human collaboration. interfaces are designed to make collaboration between people better and tosome extent they succeed, but the computer is not a collaborator with anyof the people.the current model of communication in interfaces is rudimentary atbest. it is the òinteractionó model, which is to say the user invokes acommand and gets some, perhaps expected, performance by the computer, rather like when oneõs dog does a trick on the basis of a commandsuch as òroll over.ó to communicate, users must choose one or twoword commands from a menu with a mouse or incant a line of mumbojumbo that is meant to command the computer to run a program. anyclarification with the user results from the user responding to òdialogueboxes.óthis interaction model of communication is, in the weakest sense, adialogue: some information flows between two agents who are capableof acting on that information. while an interface to a given applicationmay have hundreds of socalled dialogue boxes, dialogue in the humanmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.316more than screen deepsense does not take place. there is no structure to the overall dialoguebetween user and interface from one dialogue box to the next and nomemory of past dialogues or commands. each command and actionpairing is taken as completely independent of the next, so that there is nooverall organization around the purposive intent of the overall set ofòinteractionsó between the user and the machine.just as a dog doesnõt always do what you tell it to, computers donõteither. the interface is meant to inform users about what the computercan do, but, as we all know, short phrases are especially ambiguous inhuman language. users have little means to resolve this ambiguity. if themeaning of a command is not obvious to them, they can at best try it outand hope that it does what they want, or they can make their way througha help system to determine if they are on the right track. all the while,they are required to be very explicit about every reference to objects, suchas a files, that they make. while the user bears the burden of beingexplicit, the interface often communicates with ambiguity back to theuser. for example, what should the user conclude is the meaning of theòokó button in a dialogue box? òyes, thatõs fine with me, i agree,ó or òiunderstood the words,ó or òwell, i read the wordsó are possible, thoughin human discourse, these uses of òokó convey very different responses tothe content of utterances in the dialogue. because users cannot communicate these distinctions, it becomes clear to them that the computer interface does not really know what it is doing. itõs just a dumb machine.being able to be a collaborator is three steps up on the ladder ofcommunication and work. the first is minimal interaction. todayõs interfaces do not pass the òminimality testó because they do not know enoughto do so. only the user does any modeling or remembering of the interaction and its parts. whatever role the machine has played in the interaction it completely forgets when it completes the action requested. it alsois completely unaware of any difficulty the user may have had in determining the meaning of a command. capturing this level of interactionprovides a bare minimum of interactive understandingñthe interfacewould have a more complete model of the backandforth nature of thecommunication than it does now even if it did not know why the userwanted to communicate in the first place.the second step on the ladder of communication and collaboration isslavelike interaction. to perform this way, the interface must have amodel of what the user wants to do. current interfaces do not have sucha model. the userõs goals and tasks lie completely outside of interface,and there is no means to say anything about them. no part of the userõsgoals and tasks is recorded or even recognized.1 instead, all of this information must reside only in the head of the user. none of it can be foundin the application and its interface.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions317some interfaces seem to be useful and quite satisfying to users. themetaphors on which they are based are highly predictive for users indetermining what to do next. one such example is the interface for checkbook activities. i believe this is because the metaphor has been used tobuild in a model of the task the user is doing and to represent aspects ofthe task. the metaphor has also been used to keep the user narrowlyfocused on the task at handñto balance a checkbook, write checks, orproduce reports based on the checkbook information. as a result, theinterface metaphor helps users work and also helps them predict whatthe interface is likely to do. while the interface is not aware of the task theuser is doing, it is designed to do that task and to keep the user highlyfocused.while it would be wise to continue to design interfaces carefully using wellthoughtout metaphors, it will not solve the larger problemsconcerning interactivity, communication, and collaboration. no one metaphor is powerful enough for all work. furthermore, lots of smaller applications each with an interface for performing one set of tasks leaves theuser with lots of tasks to juggle. we still need an interface that communicates and collaborates, one thatõs at step three on the ladder. how do weget there from here? there is a great deal more known about humandiscourse communication that could be used in interfaces today. recentwork in linguistics, natural language processing, and psychology offersprinciples of communication that can be embodied in interfaces, evenwhen they do not speak full human language. all discourse, of whichdialogue is an example, is purposive behavior, and the structure of thediscourse is organized and segmented according to purpose. the focusof attention of the discourse is used, among other things, to provide context, which means creating locality in the segments of the discourse forinterpreting recent references and to help discourse participants assurethat each of them is paying attention to the same items in the discourse(grosz and sidner, 1986). grounding of utterances in the humancomputer dialogue2 makes conversation more efficient by allowing people toleave out what is truly obvious to both participants, as well as to slow theconversation down in order to reestablish focus, correct for unwantedambiguity, and determine the next participant who has the floor.it is possible to build interfaces that make use of these principles (andassociated algorithms, which i will not discuss here) while at the sametime simplifying the interface itself. we are doing that in our currentwork on collaborative interface agents (rich and sidner, 1996). to do so,designers will need to think in terms of user purposes (not just whatactions the interface permits), the structure of purposes, and the relationship between what the user must communicate and the purposes of thecommunication. maintenance of focus of attention will provide usersmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.318more than screen deepwith a local context in which to complete their subpurposes and may evenmake it possible to introduce implicit means of referring to the objects ofthe application.far more research is needed. most linguistics and natural languageprocessing work is directed at progress in natural language/speech understanding and generation, in machine translation, or at more appliedconcerns such as languagebased information retrieval. uncovering theprinciples of human communication requires considerably more effortthan has been undertaken so far. applying those principles to interfacesis a largely untouched area of research. little of this work is likely tooccur in industrial research settings, as it is not near enough term for theneeds of applied research now typical in industrial labs.recent work in understanding human collaboration and user modeling offers two sources of value to the interface: (1) the nearterm ability toground the interface in the usersõ goals and tasks and (2) the more futuristic ability to make the machine a collaborator with the user once thosegoals and tasks are available. what is known about collaboration makes itclear that collaborators come to share mutual beliefs about their ways ofdoing something (called the recipe), about their ability and intentions todo things, and about their commitment to completing the goal. the models of collaboration can also be linked to discourse not simply by sayingthat collaborators must communicate their beliefs to others, but throughmuch more detailed models of the relationship of belief and intention aspurposes for segments of discourse (cf. lochbaum, 1995).recent work in modeling collaboration and discourse in interfaces(biermann et al., 1993; stein and maier, 1995; rich and sidner, 1996; cf.terveen, 1995, for an overview of humancomputer collaboration) indicates this is a promising direction for research. while industrial groups aswell as some university work has been directed at these problems, onlythe first steps have been taken in modeling interfaces after human collaboration. however, to extend this work to applications that real userswould use on an everyday basis would require further research on human collaboration and more system experimentation in building interfaces. two critical issues in human collaboration are more exploration ofthe means by which humans negotiate in collaboration (cf. guinn andbiermann, 1993; sidner, 1994a; chucarroll and carberry, 1995) and human collaboration in task domains that are richer than the simple ones(e.g., building simple physical equipment, gathering simple information)considered so far.a new technology, which after long delay, is about to splash on thescene: speech. while i will confine my comments to speech input (recognition and understanding), similar comments apply to speech output.speech will force issues about communication and collaboration. at themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions319same time, if applied wisely, speech offers a valuable modality to manyusers who do not fit the profile of use for current interfaces. to usespeech adequately, researchers must continue to address a number oftechnical problems in speech recognition and understanding. there aremany technical problems in using speech well in interfaces. some arerelated to speech recognition per se; others concern how interfaces aredesigned to use speech as the communication medium. concerning thefirst set of problems, one must consider modeling the speech of smalldialect populations. this is possible to do but may be overlooked becausethe cost may seem too high for market return for industrial labs to concern themselves with such populations. yet small dialect groups make uppart of the citizenship of our nation.having good speech recognition/production and understanding/generation technology is only the tip of the interface iceberg. a great dealmore research is needed in understanding users and their interactionneeds in the presence of speech.speech technology for desktop and telephony interfaces offers thepotential of using computers in ways that users interact with other people.it also opens up a host of metaphorical uses3 that could enhance computeruse or exacerbate our current use of metaphors in interfaces. carefulstudies of users and applications with speech (such as the speechactswork of martin et al., 1996) will provide speech interfaces that make useof communication principles. special attention must be paid to the needsof users who communicate with special limitations. research on the useof speech interfaces by visually or motorimpaired users and linguistically limited users4 is not likely to come from industry (as is evident fromthe current problems with recent operating systems providing interfacesfor the blind) and will require industry/university/government collaboration to be feasible. finally, user populations never considered before,such as the multiple millions of semiliterate and illiterate americans, willrequire careful study in speech interfaces; this research is also not likelyto occur in industry and will require joint research between industry anduniversities under government funding.speech as a modality naturally suggests speaking to someone. thespeaking face is compelling not only because it is so imprinted on us frombirth, but because it appears quite valuable to users in communicating.recent research on faces, human or otherwise, has now captured theimagination of some interface researchers (e.g., ball et al., 1996; nagaoand takeuchi, 1994; waters and levergood, 1995). while much of theassociated research concerns believable agents, that is, research on representing agents visually that are generally designed to have some effect onusers (e.g., being persuasive, friendly, or entertaining), faces have inherent value for communication. while little is understood at the computamore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.320more than screen deeptional level about these matters, faces provide a locus for spoken communication and a means of introducing efficiency in the grounding aspects ofdialogue. however, these issues are poorly understood, as are the meansby which we find faces natural in terms of their microlevel changes (butsee work by thorisson, 1994, and walker et al., 1994, for some directions topursue). research in these areas will require the combined efforts of researchers in a number of disciplines, including psychology, computationallinguistics, linguistics, computer science, and media arts. those aspectsthat apply to media and believable agents will probably be heavily fundedbecause of their potential payoff in the new entertainment/computer industry. communicationrelated matters will require some governmentfunding to keep industrial applied research focused on this matter.while current interfaces are hard to use and give few choices of modality, we are on the brink of having available many new technologiesthat can change the nature of interfaces. we must bring to bear ourknowledge of human collaboration and discourse communication onthese interfaces so that they serve a wider range of users. we must extendour knowledge of collaboration and communication so that our interfacescan grow into better collaborative partners as our work needs change.notes1.although interface product groups are now aware of many of the microactionsthat users perform in a given software application, the only method they have come upwith to help users is bottomup recognition of microactions. they will never be able to domore because extending this solution to òhigherleveló actions is computationally too hard.2.by this i mean the process by which dialogue participants establish that the message was understood and determine who speaks next in the conversation and when (cf.clark and shaefer, 1987; sidner, 1994a,b; traum and heeman, 1996).3.a nearterm example is namedialing, which is the ability to call a person on thephone by simply saying the name to a telephone prompt.4.by òlinguistically limited,ó i mean people who have lessthanperfect knowledgeor use of the majority culture language because they are nonnative speakers, have somecognitive/physical handicap, or have not yet been trained in the full range of the languageowing to age or economic circumstances.referencesball, gene, dan ling, david kurlander, john miller, david pugh, tim skelly, andystankosky, david thiel, maarten van dantzich, and trace wax. 1996. lifelikecomputer characters: the persona project at microsoft research. in software agents,jeffrey m. bradshaw (ed.). aaai/mit press, cambridge, mass.biermann, alan w., curry i. guinn, d. richard hipp, and ronnie w. smith. 1993. efficientcollaborative discourse: a theory and its implementation. proceedings of the arpahuman language technology workshop. march. princeton, nj.chucarroll, jennifer, and sandra carberry. 1995. response generation in collaborativemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions321negotiation. pp. 136143 in proceedings of the 33rd annual meeting of the association forcomputational linguistics. acl, somerset, n.j.clark, h.h., and e.f. shaefer. 1987. collaborating on contributions to conversations.language and cognitive processes, 11(1):123.grosz, b., and c.l. sidner. 1986. attention, intention and the structure of discourse.computational linguistics, 12(3).guinn, curry, and alan w. biermann. 1993. conflict resolution in collaborative discourse.proceedings of the 1993 international joint conference on artificial intelligence workshop:computational models of conflict management in cooperative problem solving, august.chambery, france.lochbaum, karen, e. 1994. using collaborative plans to model the intentional structure ofdisclosure. technical report, harvard university. available on http://liinwww.ira.uka.de/ searchbib/index.lochbaum, karen e. 1995. òthe use of knowledge preconditions in language processing,óproceedings of the 14th international joint conference on artificial intelligence, morgankaufmann, san mateo, ca, pp. 12601266.martin, p., f. crabbe, s. adams, e. baatz, and n. yankelovich, 1996. speechacts: a spokenlanguage framework. computer, 29 (7):3340.nagao, k., and a. takeuchi. 1994. speech dialogue with facial displays: multimodalhumancomputer conversation. pp. 102109 in proceedings of the 32nd annual meetingof the association for computational linguistics. morgankaufman. san francisco.rich, c., and c.l. sidner. 1996. òadding a collaborative agent to directmanipulationinterfaces,ó proceedings of uist.sidner, c. 1994a. an artificial discourse language for collaborative negotiation. pp. 814819. in proceedings of the national conference on artificial intelligence94, seattle. mitpress, cambridge, mass.sidner, c. 1994b. negotiation in collaborative activity: a discourse analysis. knowledgebased systems, 7(4): 265267.stein, a., and e. maier. 1995. structuring collaborative informationseeking dialogues.knowledgebased systems, 8(23):8293.terveen, l.g. 1995. an overview of humancomputer collaboration. knowledgebasedsystems, 8(23).thorisson, k.r. 1994. facetoface communication with computer agents. pp. 8690 inaaai spring symposium on believable agents, march 1920, stanford university, paloalto, calif.traum, d., and p. heeman. 1996. utterance units and grounding in spoken dialogue.icslp, october.walker, j., l. sproull, and r. subramani. 1994. using a human face in an interface. pp. 8591 in proceedings of the human factors in computing systems conference. acm press, newyork.waters, k., and t. levergood. 1995. decface: a system for synthetic face applications.journal of multimedia tools and applications, 1(4):349366.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.322more than screen deepdigital mapslance mckee and louis hechtopen gis consortium inc.goal: integrate the national spatial datainfrastructure and the national informationinfrastructurethe national spatial data infrastructure (nsdi), when opened upthrough geoprocessing interoperability interfaces based on the open gisconsortiumõs (ogc) opengistm specification, will expand out of thedomain of geographic information system (gis) experts into the daytoday lives of the general population. ogcõs research and developmentgoal is the development of the opengis specification.one goal of others in the national information infrastructure (nii) research and development community ought to be to examine the ways inwhich digital spatial data (geodata) can be most effectively used by citizensin their everyday way finding and transportation, electronic consumer purchasing, education, and interactive entertainment and also in the manyexisting and future jobs that will involve geodata and geoprocessing. another research goal ought to be to seek new ways in which designers ofvirtual environments and visualization tools can make use of humansõ spatial visualization abilities, including our almost innate ability to understandmaps and aerial views.taking a longer psychological, social, and historical view of everycitizen, we should also research the various òmedia effectsó of digitalmaps. maps of all kinds powerfully condition our thinking about theworld beyond our immediate viewspace. giss, which enable interactiveviewing and intersection of multiple spatially coincident maps representing diverse cultural and natural themes, promote holistic, crossdisciplinary thinking. widespread viewing and use of geographic informationpotentially promote broad public global awareness in the same way thatviews from orbiting spacecraft expand the world views of astronauts, asreported by astronauts. if we assume that humanmachine interfaces andinteractions affect consciousness, and if we care about the evolution ofconsciousness, we ought to study and characterize these effects with aneye toward developing highlevel design principles that support the demore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions323velopment of interfaces and uses that nudge us toward greater awarenessof our relationships with each other and our planet.market and technology driversvarious market and technology drivers are converging to make geodataand geoprocessing a more important part of the nii.current producers of geoprocessing software have long looked for anexpansion of their markets commensurate with the benefits their technology has to offer in many segments of society. that expansion has beeninhibited by noninteroperability and difficulties in sharing data held indiverse proprietary formats. open gis interfaces will remove those barriers.society has a growing need for geoprocessing owing to growingpopulation and worsening environmental problems; geographically distributed government and business activities; rapid globalization of manymarkets and activities; and increasing pressure on businesses, governments, and individuals to operate more efficiently.there is a growing realization that much data (70 percent to 85 percent of data in all databases) has a spatial component that can be exploitedin a variety of ways for more effective analysis and display.faster cpus (central processing units) and highperformance imageprocessing and graphics processing finally provide a base capable of supporting distributed geoprocessing, which often involves intense computation and large data files. widerbandwidth networks and distributedcomputing infrastructure (ole/com, corba, java, etc.) and middleware and componentware architectures are important because so manygeoprocessing applications benefit from transparent access to remote geodata stores and remote specialized geoprocessing functions and from integration of geoprocessing functions into other workflow. ògisó with alowercase g expresses the potential for open systems architectures andobject technology to enable integration of geoprocessing as one (increasingly costeffective) subordinated component of applications and decision support systems. growth in the use of geoprocessing will occur asmiddleware and componentware approaches release geoprocessing fromthe confines of large, expensive, complex monolithic software systems.geoprocessing technology is proceeding as rapidly as the generalcomputing and telecommunications technologies and not only in the areaof geoprocessing interoperability interfaces. all of the following supportthe wider use of geodata and geoprocessing by every citizen: powerfulspatial database technologies introduced by major database vendors;smaller and cheaper geographic positioning systems (gpss); sophisticated, inexpensive, and abundant commercial earth imaging data prodmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.324more than screen deepucts; advances in digital orthophotogrammetry for satellite earth imagingand aerial still and video imaging; continuing specialization and productdifferentiation in the areas of gis, cad (computeraided design), anddigital cartography; distributed interactive simulation; and threedimensional spatial data visualization techniques (including interactive virtualreality approaches). these technologies hybridize in many ways. forexample, highresolution satellite images and digital orthophotogrammetry permit quite precise automatic generation of threedimensionalviews of the earthõs surface.geodata and geographic interfacessimple geodata accumulation is also a driver. there is only one earth,and the set of all geodata is referenced to this one finite spherical volume,like a rapidly growing onion of thematic maps of cultural and naturalphenomena. as networkaccessible geodata accumulate in tens of thousands of archives around the world, it becomes an everricher, evermoresignificant basis for an evergrowing number of local and global activities. it becomes one of the foundations of the new world culture of theinformation age.networkbased geospatial informationbelow are some examples of how networkresident geodata and geoprocessing resources will be used by every citizen. most will involvesimple, specialized, stylized interactive map displays. a set of researchissues can be derived by examining the user interface requirements ofcategories of applications, such as simplicity, information density, andinteractivity modes.citizens will use the nii to help them get from a to b. gpss in carand cell phones will provide the coordinates of a, and a carõs map displayand the cell phoneõs multimedia yellow pages will show the way to b.the necessary geodata will be stored remotely and downloaded on demand, transparently to the user.geoprocessing middleware and componentware will compare thedistances to multiple possible destinations. the multimedia yellow pages,for example, will show driving time or walking time to a selected set ofnearby restaurants. the software need not be stored permanently in theinformation appliance.not just car drivers, but hikers, boaters, and visitors to a city will see ona little screen where they are and how to get to where they want to go. anumbered package en route from a to b will show up on a digital mapdisplay, showing where it is now on its route. (some shippers alreadymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions325provide this service.) people waiting for buses and airplanes will see wherethe bus or airplane is, on a digital map, with estimated minutes till arrival.more than 70 percent of database records contain spatial information.every database and spreadsheet, and the compound documents and workenvironments in which these functions are embedded, will be able tomake maps based on spatial information (usually street addresses) indata records. spatial display and analysis will be important in manyworkflow scenarios.listed below are other geographic applications used by every citizenduring daily life. each has particular user interface requirements:¥education/training, distance learning, research collaboration¥electronic libraries, electronic museums and galleries¥online government geographic information for informed citizens¥maintenance of the individualõs information context and connection (personal logical network) as the individual moves through space,bridging media and modality; mapping electronic locations of devices(addresses) to their physical locations; using concepts of reach space,colocation, and nearby¥virtual reality landscapes from earth images for interactive entertainment¥security monitoring and intrusion response¥special way finding for elderly and disabled people¥product distribution/warehousing optimization¥intelligent vehicle highway systems (ivhss) and parking placelocation¥traffic/weather information¥route guidance and planning, multimodal trip planning, travelerservices¥localespecific resources and recommendations for small farmsand gardens¥city information services¥finding jobs and clients available locally.some geographic applications used by citizens in various jobs are asfollows:¥emergency road services and 911 emergency response systems¥virtual reality landscapes from earth images for military, disasterrelief, and rescue preparedness; civil engineering and landscape architecture¥agriculture and forestry¥climate research, agronomy, biology, ecology, geology, other sciencesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.326more than screen deep¥urban and regional planning¥automated mapping and facilities management¥military surveillance¥natural resource discovery, exploitation, and management¥water resource management¥parolee tracking¥global and local environmental monitoring, advance of environmental sciences¥support for ògreenó standards, local wasteasresource arrangements¥cable, microwave, and cellular transmission installation planning¥telemedicine, better care for rural trauma victims¥global maritime information and rescue system, air traffic control¥commercial vehicle operations¥business siting, market research, and other business geographicsapplications¥geographic matching of prospective employees with available jobsor prospective service providers with prospective clients¥public administration networks¥land tenure systems¥precision farming (gpsguided controlled delivery of nutrientsand chemicals based on earth imagery or automated gpslocated soil orcrop sampling).the number of applications for geodata is growing rapidly and willcontinue to grow as the national and global spatial data infrastructuresdevelop.mapsmaps are a part of most cultures because spatial thinking is an essential part of peopleõs relationship with their physical and cultural environments. even in simpler cultures that do not pass down written records,individuals make temporary maps to remind themselves or to show others how to find their way in unfamiliar territory. all birds and mammalsform mental maps, and, as cooperative huntergatherers, humans developed sophisticated spatial awareness and spatial communications abilities that came to support other cultural activities besides physical wayfinding. for example, we say in a figurative sense that òwe are on ourwayó to making the nsdi an integral part of the nii. user interfaces arecollections of symbols and metaphors, and the map metaphor is inherently important in cyberspace. basic research in spatial reasoning, spatialmemory, and spatial communication would support development of better user interfaces that employ spatial display and manipulation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions327virtual reality will also help geodata users evaluate data sources.because so many geodata are available, and because geodata are oftencomplex, we will often be concerned about geodata quality, content, andlineage. a system of geometric shapes could be used to represent certaincontent parameters, and their shape, color, and motion could representquality parameters. a humancomputer interface could be a map or animage. once you center on a spot you can call up various basic icons thatrepresent data objects. it is easy on the internet to find lots of data buthard to sift through all the data. the interface ought to be able to tellevery citizen easily and intuitively about the ògoodnessó of the data. forexample: how does software communicate to a skier who wants to seethe snow pack at eight rocky mountain ski resorts? the skier findsimagery, but it is summer data, not winter data, so an error signal intervenes. through user configuration of simple preference files, the computer system knows that skiing requires winter data.digital mapspaper maps are a special form of printed communication, importantto motorists, subway riders, explorers, scientists in many disciplines, historians, municipal service agencies, shippers, travelers, property ownersand managers, and marketers. the utility of maps is amplified in severalways by computers and networks. a gis, for example, is like multiplesameregion overlaid thematic maps drawn on clear film, a visualinterface spatial database. you can query a gis to meld thematic maps into anew map showing, for example, all the areas 3,000 feet or higher in elevation, within 50 meters of a standing body of water, within 1,000 meters ofa road, where most of the trees are pines, where the slope of the ground isless than 10 percent, and where the population density is less than 1person per square mile. (more spatial temporal reasoning research needsto be done on how to articulate the conditions of a spatial search.) digitaltechnology allows storage of (and network access to) huge quantities ofgeodata; zooming, panning, and other kinds of interactive manipulationthat overcome the limitations of paper space and human visual acuity;realtime tracking; input from gps and earth observation satellites; andinstant display of nonspatial data (text, pictures, graphs, etc.) associatedwith selected map features or locations.through paper maps every citizen is familiar with graphic abstraction of large terrestrial spaces. digital maps apply this helpful information presentation convention to vastly greater information domains. digital maps and threedimensional virtual flyovers and flythroughs will bean important part of many graphical user interfaces because everyoneintuitively understands maps and aerial views and many kinds of informore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.328more than screen deepmation have a spatial component that makes spatial representation andvisualization appropriate.the new media are òmassaging,ó in marshall mcluhanõs term, ourindividual minds and collective culture away from textinduced linearsequential thinking toward nonlinear thinking characterized by multiplesimultaneous modalities. spatial display and analysis offers a visual, intuitive, and effective means for solving a wide range of complex problems. visualization of geographic information, or visualization of information geographically, helps people cope with information glut. virtualreality applications will employ spatial representations of real spatial phenomena, but they will also employ spatial representations of nonspatialphenomena simply because our brains are hardwired for solving problems in threedimensional space. important parts of the software anddata for configuring and populating cyberspace will be borrowed fromgeoprocessing applications and geodata archives and data feeds. similarly, research into spatial thinking will ultimately benefit both òrealspaceó and cyberspace applications.research issuesseveral research issues are identified in the text above. ogcõs research and development in the area of geoprocessing interoperability isprimary in the sense that spatial data will have a much greater role in thenii when diverse systems can exchange diverse kinds of data and accessother systemsõ geoprocessing resources. many applications will then beusing geodata, and application developers will be looking for ideas andguidance concerning geoprocessing user interface development. usefulresearch will draw inspiration from traditional cartography and fromgeneral ideas about user interfaces.over the next 20 years we will learn more about how people functionwhile immersed or partially immersed in virtual environments. we willlearn what problem simulation schemes work best and what kinds ofproblems are most fruitfully addressed by these schemes. many of theseenvironments, certainly, will include extended landscapes representingreal or imaginary spaces, and the role of spatial reasoning, spatialmemory, and maps will be of interest.everyone views the world differently. this is an issue for open gisspecification developers because different geodata producers and usersgive the same geographic feature different names and sets of descriptiveparameters and different metadata. part of the specification proposessemantic translators that domain experts from two different domains willconfigure to enable semiautomatic translation and integration of geodata.the problem is a difficult one and is much broader than geodata integramore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions329tion because computer users involved with other computer users needcommon interfaces to enable effective communication and collaboration.map interface developers as well as other kinds of interface developersneed to address the issue of standard symbology and usage.undoubtedly, commercial research and development projects andmarket activity will generate many of the dominant productizable ideasand standard graphical and conceptual approaches. academia shouldtake a longer view; it should (1) address the cognitive and broader socialeffects of developments in the spatial subdomain of the multimedia worldand (2) look in very basic ways at how user interface design can layermost elegantly on our legacy wetware and cultural firmware and leverage most powerfully a positive vision for the future. the government hasa role in cataloging and tracking evolving research topics of all kinds andsupporting those that best serve the nation and the world community. byparticipating as technology users in industry consortia (such as ogc) thatinclude users in technology planning and specification efforts, government agencies can ensure that the technology provider community meetsagency needs and can influence the direction of technology that will become part of the larger economy and culture.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.330more than screen deepgathering and integrating information in thenational information infrastructurecraig a. knoblockuniversity of southern californiagoals and issuesa critical and unsolved problem for the world wide web is how togather and integrate the huge amount of available information in an automated fashion. web browsers and search engines are an enormous stepforward in providing access to the available information. yet they relyheavily on hypertext links, which require a human to navigate. i believean important goal for the national information infrastructure (nii) is todevelop the infrastructure, technology, and tools to provide automatedgathering and integration of data. consider an example from the financial domain, where the ability to integrate the large amount of availabledata would make that information much more accessible and useful.someone might be interested in investing in the airline industry but isundecided about which airline stock to buy and wants some additionalinformation. some of the information they might like to have includes theannual report, oneyear price history, and current trading price for allu.s. airline stocks, and they might want them presented in order of increasing pe (price/earnings) ratios. all of this information is publiclyavailable, but knowing where to look and integrating the information isnot a simple task.assuming that users knew where to look (and that is a strong assumption), they could put together this information using the followingsteps. first, they must determine what all of the airline stocks are. thiscould be done by examining the prospectus of each publicly traded stockto see if it falls into the sic (standard industrial classification) category ofscheduled air transportation, but that would be very time consuming.another approach would be to find an information source that contains alist of airlines, such as the eaasy sabre page that includes all of theairlines for which it provides reservations. this information could thenbe used on another page to input the name of a company and get back theticker symbol (the symbol by which the stock is listed in one of the stockexchanges) for that company. using that information, they can then go toanother page and enter the ticker symbol to get the current trade pricemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions331and pe ratio. they would go to yet another page to find the oneyearprice history in a graphical form. and they could go to the securities andexchange commission (sec) edgar archives to find the annual reportfiled with the sec but in this case accessed using the company name.even within the edgar archives, they would need to know that thecode for an annual report is 10k in order to extract it from the 20 or 30reports available for each company. this entire process would have to berepeated for each airline, and they would not know how to order themuntil they had the data for each company.ideally, instead of going through this tedious process, a user couldsimply issue the query to a software agent for the financial domain andthat agent would know where to retrieve the relevant information andhow to process it to produce the data requested by the user. the goal thenis to develop the infrastructure and tools required to easily construct andmaintain software agents for querying and integrating information in anydomain of interest. one could laboriously construct and maintain suchsoftware agents by writing specialized software applications. in fact, thatis the current state of the art. the limitation of this approach is that suchspecialized applications are difficult to maintain and extend. if a newsource becomes available, a programmer must modify the program inorder to exploit that information. also, each new application domainrequires constructing a whole new program.research problems to be addressedthere are a number of research issues that must be addressed in orderto realize the goal described in the previous section:¥modeling the contents of sources. to automate the access to sourcesrequires both a precise syntactic description (e.g., a grammar) of the organization of the data as well as a detailed description of the semanticcontent of the source. the latter can most naturally be described using aknowledge representation language.¥construction of domain ontologies. to describe the information provided by each source such that it can be integrated with other sourcesrequires a comprehensive set of shared terminology.¥planning to access and integrate information sources. given a queryand the models of the available sources, we need a system that can automatically select an appropriate set of sources and generate a plan to efficiently integrate the required information.¥machine learning of source structure and source contents. the problem of modeling all of the currently available information sources on theweb is far too large to be done manually. thus, we need to developmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.332more than screen deepmachine learning technology to automate as much of this process as possible. of course, the hope is that eventually the added information wouldbe so critical that information providers would provide it just as theycurrently format their data.¥data mining for patterns and relationships in sources. a critical aspectof this problem is how to efficiently process queries, since some sourcesmay be very expensive to access (in either time or money). data miningcan be used to learn relationships in the data for optimizing access tosources.¥natural language querying. ideally, users would be able to writenatural language queries. this requires developing natural language systems that can be used to formulate valid queries.proposed research projectsthe various issues described above can be broken down into fourpossible research projects. the first two projects would provide the corework, and the other two projects would be important in making the resulting research useful to everyday users.representation and ontologiesthe problem of representing both the syntax and semantics of sourcesis central to addressing the entire problem. the goal of the first project isto develop approaches to describing the syntax and semantics of webpages. given the size of the task, i would expect that this would be afairly large, longterm problem. the hope is that this would eventuallylead to standards for marking up pages with semantic information and tothe development of domainspecific ontologies that can be used for information integration.planning information gathering and integrationgiven a description of the available sources, the problem still remainsas to how to select and integrate the most relevant information. there area number of challenging aspects to this problem, such as handling semantic discrepancies, resolving syntactic differences, and evaluating reliability and recency. in addition, another critical aspect to this problem isperforming the processing efficiently, since access to many webbasedsources can be very slow, and plans that require access to many sourcescan require hours or days.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions333machine learning and data mining of sourcesbecause of the need for large amounts of information about sourcesand how they relate, machine learning and data mining will play a criticalrole in simplifying the task of the first two projects. machine learning canbe used to help build grammars for parsing sources as well as for buildingmodels that describe the contents of sources. data mining can be used tofind relationships in individual sources and between sources, which canthen be used to optimize the query processing.natural language processing and user interfacesnatural language querying and/or graphical interfaces are needed toprovide userfriendly access to information. in addition, user interfacesare important for displaying various types of multimedia data and forproviding tools to help build models of sources.potential impactthe overall project has the potential to make a dramatic impact. if thework is done right, it could change the nature of the nii. instead of usingbrowsers and search engines, users would have access to a wide range ofspecialized agents that could quickly locate and integrate the huge amountof available data. instead of being a data repository, the nii could be aknowledge repository.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.334more than screen deepintegrating audiences and usersjohn richardsturner le@rning inc.lifelong learningthe national information infrastructure (nii) is designedñfrom atechnological perspectiveñto integrate a wide range of communicationand information systems including video delivery, telephony, computernetworks, and online services. these are, for the most part, known technologies, and the technological integration is a matter of time and money.in contrast, we have not yet begun to think about the integration of diverse media from a human perspective. people relate to even a singlemedium in very different ways, determined by the context of use and bythe individualõs understanding of the situation. the development of functional multiple media learning environments is not simply the result ofcombining different media typesñan additive processñbut consists ofcreating a brand new kind of media, a transforming process. the development of interfaces for these new media types depends on coming tounderstand the ways in which people will come to use the media forlearning. as real video and truly interactive networking are integrated,television audiences do not simply become network users or vice versa.instead, there are qualitatively different experiences in store. in this paper i consider some issues that we should try to anticipate in the construction of a voice, video, and data infrastructure that provides the opportunity for justintime learning throughout life.analog vs. digitalour analog modes of communication by voice, print, and video are gradually being replaced by digital modes. ultimately, most of humanknowledge will be stored in a common digital libraryñkaufman and smarr [1993] (p. ix)this transformation from analog to digital will have deep implications for human knowledge, and, in my judgment, even deeper implications for human communication and relationships. kaufman and smarrmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions335argue that the fundamental idea of replacing the continuous world ofnature with a model of that world, formed of discrete units, has transformed the pursuit of science. they argue that the digital perspectiveprovides a controllable, imaginable representation that, ultimately, provides the key to a more comprehensible world.how, then, does our understanding of the content of media differ aswe move from analog to digital? this is not an arcane question pertaining to the relevance of simulations on supercomputers; rather, it affects allof our interactions with voice video and data technologies. for example,in the most developed of these digitizations, consider how writing emailmessages differs from writing letters. it certainly seems that only yesterday we were seeing paeans to letterwriting as a dying medium. thecommonly accepted explanation was that writing was the problemñculture was deteriorating, and the literacy required for letters was a lost art.in retrospect, given the success of email, the delays in letter deliverywere simply not tolerable, especially when contrasted with the immediacy of telephones. but email did not change the nature of letter writingñit replaced letter writing with a full panoply of alternatives. notonly did a new, more informal genre evolve, but entirely new forms ofwritten communication also evolved with entirely new rules for participation. email evolved into bulletin boards and òlistservsó that do nothave straightforward analogs in the letterwriting or, more generally,precomputer culture. and even more distinct forms of communicationare only now appearing. as argued by sherry turkle [1995], chats, muds,and muses are developing unique, and unprecedented, participationstructures. how will these conversations change with the easy availability of voice on the internet? how will putting telephone (or videotelephone) on the internet change the nature of a phone call? what newforms will evolve?in my judgment, though, the most profound differences will occurwith video. the control added to video through the digitization processchanges the nature of the videoñmore importantly the digitization inherent in the nii brings together television and computers, two technologiesthat have been distinct in development and production. more significantly, these technologies are culturally quite distinct. as we talk aboutan infrastructure that integrates voice, video, and data, we must considerthe power of the cultural differences of these technologies and their complex contexts of use.cable modems vs. cable boxesprior to coming to turner, i lived in newton, massachusetts, and hadcable television installed. the cable came into the basement of my homemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.336more than screen deepand was routed up to my bedroom, into a cable box, through my vcr andinto my televisionñmy òentertainment center.ó in march of 1996, i became part of an early trial of cable modems by continental cablevisionand bbn. the cable into the basement was split and part of it routed intomy home office, into a cable modem, and then into my computer, providing ethernetspeed access to the internetñmy òwork center.ó the twosetups were separated by a thin wall, two different boxes, and two different monitors.what separates these worlds? why arenõt they going to the same boxor the same monitor? when will i see a picture within a picture? whilewatching tv the 2ó square picture in the corner is the internet. whensurfing the web the 2ó square picture is the television signal. what separates these worlds are the viewers/users and the industry standards andexpectations.this is a temporary division. the cable industry has promised a freecable modem to every u.s. school they pass as they provide this service tothe community. these will be 5 to 10 feet from television cable boxes.what will the interface be when these are a single box connected to asingle monitor? how are we to think of television as an inset in softwareñand conversely? are the two streams of data to be integrated forinteractive television or videoenhanced software? once all the technologies are digitized, there is no functional delivery difference between television, email, phone, radio, movies, or even the networked alarm systems in peopleõs homes. from a human perspective, this convergencewill represent remarkable transformations in the nature of the media.participation vs. deliverynetworking has been dominated by a philosophy of participationand user constructibility. from the beginning of the arpanet, for national security reasons networking has been distributed with no centrallocus of control.1 the removal of any node would have no effect on therest of the system. moreover, the wild success of the world wide web isprecisely because it so adeptly fits the underlying participatory philosophy of networking.television and cinema, in contrast, have been dominated by centralized delivery models. beginning with hollywood domination of moviemaking, and continuing with the òbig threeó u.s. broadcast companies,television and cinema content has been tightly controlled, produced, anddistributed. even as television audiences are being analyzed as òactivemeaning producers of texts and technologies . . .ó (ang [1996], p. 8), this isseen as a postmodern development that is only now being taken intoaccount. in particular, as the plethora of programs provides choice, themore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions337audience is seen as being freer to construct meaning through participating in these choices. television itself is evolving as the surrounding technologies change:the vcr disrupted the modern entanglement between centralized transmission and privatized reception because it displaced the locus of control over the circulation of cultural texts to more local contexts.ñang [1996] (p. 12)thus, there is a different experience when the same movie is shown ina cinema, on tv, or as a tape played at home on your vcr. in fact, theaudience is different, with different expectations regarding interruptionsña movie theater is continuous and commercials are resented, television presentations are ògearedó toward the interruptions, and only witha rented tape can the bathroom break be at the discretion of the audience.replays are possible with the vcr. in short, the nature of the medium ischanging because of the role of the active audience.audience vs. userseach of the media carries with it different relationships with its users/audiences. and these relationships are not dependent solely on themedia in isolation. consider the distinctions john ellis [1982] draws between the audience of cinema and the audience of television. the cinemaspectator is a voyeur. the television viewers are òuninvolved in theevents portrayedó and ò. . . are able to see ôlifeõs parade at their fingertips,õbut at the cost of exempting themselves from that parade for the durationof their tv viewingó (ellis [1982], pp. 169170). the spectator pays for thecinema, and resents any commercial intrusion during the showing. theviewer accepts television commercials as a part of the basic structure ofwatching.how does this compare with the audience for video in software? orvideo on the web? as software developers we have naively assumed thatthe introduction of the new media types fit in with the nature of thesoftwareñvideos, pictures, and sounds are included for motivationalpurposes, or as illustrations of some concept, and have little or no fundamental effect on the user.moreover, the deep distinctions between viewers and spectators suggest that the computer/user relationship may, and probably does, changewith the introduction of the web. typically the computer/user relationship is onetoone (or two or three at best), essentially an individual participation structure. the web is somewhat different without many premore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.338more than screen deepcursors. it is essentially a social structure. the underlying metaphor isthat when we are connecting with other individuals there is a dynamic,changing, unstructured, cluttered world.there are different educational philosophies that have grown uparound the technologies. there are two cultures in technology and educationñperhaps this is parallel to the c.p. snow observation. these twoculturesñdigital (computers/networking and education) and analog(tv/cable video)ñknow little of each other.video in software vs. software in videothere is a small stream of research and development that has evolvedin the intersection of video and computing. kristina hooper woolseyand bob mohl produced the aspen project. the user drove through thetown of aspen by manipulating a touchsensitive screen. the branchingstructures themselves are sufficiently constrained that it is possible toanticipate all choices (at an intersection in the road you can stop or goforward, backward, right, or left). it is possible to film alternatives. themapping metaphor provided the basis for the more successful commercial product, palenque. other early attempts to tie tv and computingwere sam gibbonõs and bank streetõs the voyage of the mimi, and johnbransfordõs cognition and technology group at vanderbiltõs the jasonproject (cognition [in press]). another interesting attempt by woolseyand the apple multimedia lab is the watson and crick dna story, basedon a bbc production.more recently, at turner, we have experimented with several qualitatively different attempts to integrate the two cultures. cnn newsroom isbroadcast by cnn at 4:30 a.m. for taping by teachers. traditionally,teachers would receive teachersõ guides by fax or through a centralizeddistribution within a state. more recently, the teachersõ guides may bedownloaded from cnn.com/newsroom on the world wide web. we areworking together with researchers at the center for educational computing initiatives at mit who have set up a system to automatically digitizethe broadcast, separate it into meaningful segments, and make it availablethrough streaming video on the web. the teachersõ guides are also separately available for each segment. this qualitatively changes what teachers can access. they can choose particular segments from the dayõs broadcast, and they have access to an indexed history.turner le@rning has also been experimenting with electronic fieldtrips. students participate in two to four weeks of curriculum activitiesinvolving videotapes, data disks, electronic chat groups, and print materials. the midpoint of the curriculum is marked by two live broadcastswhere experts at the field trip location respond to studentsõ questions,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions339submitted to an 800 number or over the web by students. the studentõsact of asking a question changes the presumption of the broadcast. moreover, the variety of media is specifically designed to foster active participation on the part of the teacher and student in the construction of theirlearning.as the broadcast and cable media become more involved in theinternet, the nature of television is also changing. cnn networks (cnn,cnn headline news, cnn airport news, cnn fn) download feeds fromcnn bureaus worldwide. in each network a team of editors and writersproduce stories that are then televised. cnn interactive is a web site thatis produced and distributed in much the same way. it is this uniquetelevisionoriented model, with constant newsbased updates, that accounts for its immense popularity (over 5 million pageviews per day).how will televisionbased concepts translate onto the web? currently,web sites change weekly, if you are fortunate, and daily at the very bestsitesñcnnõs timely updates are very much an anachronismñrequiringover 140 programmers/writers. at what point will we be programmingthe web as we program television, with sites changing according to thetime of day? and how will this be modified by the webõs ability to adjustfor your interests and history?conclusionthe rise of image in communication is more than a matter of educating ourselves to analyze and interpret visual experiences. rather, as argued by taylor and saarinen [1994], the incorporation of images in presentations has changed the very nature of communication. text by itsvery nature is linear, sequential. a picture or video allows for an infiniteseries of branches.this may not be a new stage of meaning but a return to an old one.mcluhan [1964] argues that prior to gutenberg, story telling relied onimages and metaphors that were much more generativeñtaking into account the multiplicity of the audience and the individual construction ofmeaning.what i am suggesting in this paper is that the integration of videomedia with computer technology is not a quantitative difference but aqualitative difference that requires that we begin to rethink learning inthis digital world.bibliographyang, ien [1996]. living room wars: rethinking media audiences for a postmodern world.london: routledge.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.340more than screen deepcognition and technology group at vanderbilt (in press). the jason series: a designexperiment in complex, mathematical problem solving. in j. hawkins and a. collins(eds.), design experiments: integrating technologies into schools. new york:cambridge university press.ellis, john [1982]. visible fictions. london: routledge and kegan paul.kaufman, william j. and smarr, larry l. [1993]. supercomputing and thetransformation of science. new york: scientific american library.mcluhan, marshall [1964]. understanding media: the extensions of man. new york: newamerican library.taylor, mark c. and saarinen, esa [1994]. imagologies: media philosophy. london:routledge.turkle, sherry [1995]. life on the screen. new york: simon and schuster.note1.to understand that this is not necessarily true of the technology but has arisen asa deliberate design decision, notice the òstarnetsó that mis departments always try toestablish. this design emphasizes the collection of data (attendance and grade information,or inventories, or bank accounts) in one central location, and the distribution of centralizedresources or information (paychecks, reports, decisions).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions341intelligent agents for informationkatia p. sycaracarnegie mellon universitygoals and issuesthe overall goal of the everycitizen interface research program is toprovide fundamental research and enabling technologies for the development of computer interfaces that allow easy access to the national information infrastructure (nii) by many citizens, ranging from software experts to physically or mentally handicapped persons. given the currentnature of computer technology and current characteristics of the nii, thereare many issues that must be addressed.current problemseffective use of the internet by humans or decision support machinesystems has been hampered by some dominant characteristics of theinfosphere. first, information available from the net is unorganized,multimodal, and distributed on server sites all over the world. second,the number and variety of data sources and services are increasing dramatically every day. furthermore, the availability, type, and reliability ofinformation services are constantly changing. third, information is ambiguous and possibly erroneous owing to the dynamic nature of the information sources and potential information updating and maintenanceproblems. therefore, information is becoming increasingly difficult for aperson or machine system to collect, filter, evaluate, and use. currentinterface technology, dominated by the web browser paradigm, besidesbeing slow, lets users do the access, filtering, interpretation of raw datathrough point and click, and text/graphic cognitive processing. currentnii technology has a number of limitations, including the following:¥it does not flexibly support information, access, and filtering.¥it does not easily adapt to user interaction style and informationseeking goals and preferences.¥it does not flexibly transfer task performance from user to system.¥it is not user friendly to many people with disabilities.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.342more than screen deep¥it is not suitable for easy perusal of continuoustime multimedia(e.g., video, audio).¥it is not easily portable across different display devices.¥it does not flexibly support user mobility.addressing the above set of current interface technology limitationscan constitute a list of requirements for shortterm (2 to 3 years) andmediumterm (3 to 5 years) research requirements. additional longerterm requirements include supporting the flexible physical realization ofòactionatadistanceó capabilities and making the computer a real collaborative partner of the user.research issuesto address the abovementioned goals and requirements, researchersfrom different disciplines, such as computer science, cognitive science,human factors, physiology, psychology, design, and engineering, willneed to collaborate.the paradigm of intelligent agents has shown initial promise for handling some of the above problems, especially information location, filtering, and integration. although a precise definition of an intelligent agentis still forthcoming, the current working notion is that intelligent softwareagents are programs that act on behalf of their human users in order toperform laborious informationgathering tasks, such as locating and accessing information from various online information sources, resolvinginconsistencies in the retrieved information, filtering away irrelevant orunwanted information, integrating information from heterogeneous information sources, and adapting over time to their human usersõ information needs and the shape of the infosphere.to make intelligent agents a reliable part of interface technology,some important research issues must be addressed. they include thefollowing:¥development of intelligent agents that locate and retrieve informationfrom distributed multimedia and multimodal information sources according to auser specification. to what extend should agents hide information complexity from users? agent audit trails and behavior explanation alsoshould be investigated. how can agents determine information trustworthiness, so they can give some credibility estimate to users? is this desirable?¥development of intelligent agents that unobtrusively and reliably learnuser information goals and preferences as well as display preferences. to whatextend should agents be proactively presenting information? how aumore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions343tonomous should they be in terms of initiating information searches thattheir learned user model tells them might be useful at this time?¥what òface and personalityó should intelligent agents present to users?utility and tradeoffs of anthropomorphizing agentsñdoes anthropomorphization create particular expectations on the part of users?¥adaptive function allocation and coadaptation. is adaptation alwaysgood? development of methodology and techniques to manage resultingchanges in roles and tasks to avoid undermining system reliability andperformance. identification of characteristics of agent design and presentation that facilitate helpful adaptation and flexibility in use.¥because of the vastness of the infosphere, investigation of protocolsfor collaboration of distributed intelligent agents also is necessary.¥development of ontologies and transformation techniques to support semantic interoperation of distributed agents. can these ontologies be standardized? are there òontology czarsó?¥investigation of the tradeoffs associated with agent mobility in support ofinterface technology.additional research issues include:¥how to display information on different appliances (e.g., workstations,personal digital assistants, wearable computers). while static and mobiletelephones present the same interface to users, this is not true for computer displays. issues of maintaining consistency of interface over appliances with significant differences in display real estate need to be researched.¥how to deal with temporally continuous data modalitiesñfor example,how to let users quickly skim video objects to locate sections of interestand how to aid users in the analysis and reuse of digital video information. in the hands of a user, every medium has a temporal nature. it takestime to read (process) a text document or a still image. however, intraditional media each user absorbs the information at his or her own rate.one may even assimilate visual information holisticallyñthat is, come toan understanding of complex information nearly at once. solutions tothese problems require an intimate understanding of digital video anddigital audio and development of new modes of interfaces based on thismodel.¥research in matching modality to task (e.g., speech is unsuitable fordescribing information that has a lot of spatial content, such as maps, ormechanical parts).¥research in seamless integration of different input (e.g., speech to retrieve a map) and output (e.g., graphic display of the retrieved map) modalities for the same information object.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.344more than screen deep¥research in supporting users in specification of information requests(e.g., through visual retrieval specification cues) and development of principles for ecological interface design.¥searching and skimming video and audio largescale information: justviewing digital video, while useful, is not enough. once users identifyvideo objects of interest, they will need to be able to manipulate, organize,analyze, and reuse the video. whether proffered by a computer or human agent, users would like to peruse video much as they flip throughthe pages of a book. unfortunately, todayõs mechanisms are inadequate.scanning by jumping a set number of frames may skip the target information completely.projectsto make progress along these issues, a variety of projects should beinstituted. small projects to investigate circumscribed issues (e.g., how tostructure agents, interaction protocols, how to determine informationcredibility) and larger projects that should involve collaboration betweenacademic institutions, government, and industry. for the moment, industry seems to lead in the nii. the smaller projects should involve onlyacademia and should investigate fundamental longerterm issues, so thatthe longerterm goals (e.g., computer systems becoming real collaborators and partners of humans) should be addressed.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions345intelligent information agentsjohanna d. mooreuniversity of pittsburghintroductionthe evolving national information infrastructure (nii) has made available a vast array of online services and networked information and networked information resources in a variety of forms (text, speech, graphics, images, video). at the same time, advances in computing andtelecommunications technology have made it possible for an increasingnumber of households to own (or lease or use) powerful personal computers that are connected to this resource. accompanying this progress isthe expectation that people will be able to more effectively solve problemsbecause of this vast information resource. unfortunately, development ofinterfaces that help users identify the information that is relevant to theircurrent needs and present this information in ways that are most appropriate given the information content and the needs of particular users lagsfar behind development of the infrastructure for storing, transferring, anddisplaying information. as grosz and davis (1994) put it, òthe goodnews is that all of the worldõs electronic libraries are now at your disposal;the bad news is that youõre on your ownñthereõs no one at the information desk.ó in this paper i provide desiderata for an interface that wouldenable ordinary people to properly access the capabilities of the nii. iidentify some of the technologies that will be needed to achieve thesedesiderata and discuss current and future research directions that couldlead to the development of such technologies. in particular, i focus onideas related to agents and system intelligence and ways in which advances in these areas could enhance eventual interfaces to the nii.desiderata for an everycitizen interface to the niias i envision it, an everycitizen interface would consist of intelligentinformation agents (iias) that can:¥work with users to determine their information needs;¥navigate the nii to identify and locate appropriate data sourcesfrom which to extract relevant information;more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.346more than screen deep¥present information in ways that are most appropriate to the typeof information being conveyed, as well as usersõ goals, time constraints,and current context (i.e., what other information resources are they currently accessing?); and¥adapt to changes in usersõ needs and abilities as well as to changesin information resources.intelligent interactive query specificationdatabase query languages allow users to form complex queries thatrequest information involving data entities and relationships among them.using a database system, users can typically find the information theyrequire or determine that the database does not contain such information.however, to use a database system, users must know which dataresource(s) to access and must be able to specify a query in the appropriate language. that is, the users must essentially form a plan to identifyand access the information they require to achieve their informationseeking goals. in contrast, keywordbased search engines for the world wideweb allow users to search many information resources at once by specifying their queries using combinations of keywords (and indications ofwhether or not the keywords are required to occur in the document,whether they must occur in sequence, etc.). such search engines do notrequire users to form a detailed plan, but they often turn up many irrelevant documents and users typically do not know what data resourceshave been examined. moreover, keywordbased search engines provideusers with a very crude language for expressing their informationseeking goals. to provide the kind of interface i envision, iias must be able towork with users to help them express their informationseeking goals interms that the system understands and can act on. the iia should thenform a plan to find information that may help users achieve their goals.that is, we would like to provide technology that would allow users totell their systems what informationrelated tasks they wish to perform,not exactly what information they need, and where and how to find it.for example, as an associate editor for a journal, i often need to findreviewers for papers on topics outside my area of expertise. i know thatinformation is out there in the nii that could help me identify appropriatereviewers, but finding it is a difficult task. what iõd like is an iia thatcould accept a goal such as òfind me highly qualified, reliable reviewersfor a paper on parsing using information compression and word alignment techniquesõõ and perhaps a preference on the ranking of solutions,such as òand disprefer reviewers who have recently written a review forme.õõ an interactive agent that did not know how to determine whether aresearcher is òhighly qualifiedó could engage in a dialogue with its usermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions347to determine how to assess this. for example, the user may tell the agentto assess this by counting articles in wellrespected journals or by counting citations in the citation index. again, if the agent did not know how todetermine what the user considered wellrespected journals for this particular situation, it would work with the user to define this term and so on.as a more òeverycitizenó example, imagine a patient who has justbeen prescribed a drug and then catches the tail end of a news storysuggesting that several people have become critically ill after taking thedrug. this user would likely have a goal such as: òtell me about the sideeffects of wonderdrugó and òshow me the serious side effects first.ó if noinformation on òserious side effectsó were found, the agent should workwith the user to define the term more precisely. for example, the agentcould provide the user with a list of the types of side effects it encountered and ask the user which type(s) he or she considers serious.planning for information accessonce the agent has worked with the user to identify his or her goals,it must be able to form a plan to acquire the information that will aid theuser in achieving those goals. iias must be equipped with strategies thattell them how to form such plans and must also be able to trade off theurgency of the request against the cost of accessing different informationsources and the likelihood that a particular plan will be successful. in thejournal editor example i gave earlier, the agent may need to be capable ofdetermining which information sources would be most likely to help findan appropriate reviewer before the end of the day. in the drug examplethe agent may need to take into account the cost of accessing databasesput out by pharmaceutical companies. agents must also reason abouthow much advance planning to do before beginning to act and how muchinformation they should acquire before planning or acting in order toreduce uncertainty.making progress on these issues will require integrating several ideascoming out of the planning community, including planning under uncertainty (kushmerick et al., 1995); reasoning about the tradeoff betweenreactive and deliberative behavior (bratman et al., 1988; boddy and dean,1994); planning for contingencies (pryor and collins, 1996); and techniques that integrate planning, information gathering, execution, and planrevision (draper et al., 1994; zilberstein and russell, 1993).to support agents in forming such plans, new types of automaticindexing schemes must be devised. data may need to be indexed inmultiple waysñfor example, reflecting different purposes the data mayserve or different levels of detail. in the world wide web, links goinginto and out of a document characterize that document and may be usefulmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.348more than screen deepin forming indexes to it (as is done in citation search systems). in addition, automatic indexing schemes that work across modalities are needed.intelligent multimedia presentation ofinformationiias will be able to acquire information from many different information sources in a variety of media. these systems will need to be able toplan multimedia presentations that most effectively communicate this information in ways that support users in achieving their goals and performing their tasks. for example, an iia helping a visitor to the washington,d.c., area identify good thai restaurants may provide a consumer reportslike chart rating the 10 best restaurants on a variety of features, a city mapshowing where the restaurants are located relative to the userõs hotel, andspoken excerpts from restaurant reviews that are coordinated with highlighting of the row in the chart and dots on the map that correspond to therestaurants being described. we would also like such multimedia presentations to be tailored to the userõs background and preferences, the task athand, and prior information displays the user has viewed. in the restaurantexample, if the system can determine that the user is not familiar with thed.c. area, specific directions to the various restaurants may be given,whereas for a d.c. native an address may be sufficient. if the user haspreviously requested detailed directions to one restaurant and then requests directions to another restaurant nearby, the system may describe thelocation of the second restaurant relative to the location of the first.owing to the vast information resources that are now available, improved networking infrastructure for highspeed information transfer,and higherquality audio, video, and graphics display capabilities, intelligent multimedia presentation is an active area of research. as roth andhefley (1993) define them, intelligent multimedia presentation systems(immpss) take as input a collection of information to be communicatedand a set of communicative goals (i.e., purposes for communicating information or the tasks to be performed by the user requesting the information). an immps typically has a knowledge base of communicative strategies that enable it to design a presentation that expresses the informationusing a combination of the available media and presentation techniquesin a way that achieves the communicative purposes and supports users inperforming their tasks. roth and hefley argue that immpss will be mosteffective in situations where it is not possible for system developers todesign presentation software because they cannot anticipate all possiblecombinations of information that will be requested for display. this isclearly the case for an everycitizen interface to the nii.immpss must perform several complex tasks. they typically consistmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions349of a presentation planner, a number of media generators, and a mediacoordinator. the presentation planner uses presentation design knowledge to select content to be included in a display intended to achieve a setof goals for a particular user in a given context. it uses its knowledge oftechniques available to the various media generators to apportion contentto media and generate a sequence of directives for individual media generators. media generators (e.g., for natural language text, speech, andgraphics) must determine how to convey the content given the directivesthey receive from the planner and then report back their results to thepresentation planner and media coordinator. the coordinator must manage interactions among individual media generators, resolve conflicts,and maintain presentation consistency.considerable progress has been made toward systems that performthese tasks for limited domains, user tasks, data, and presentation types.for example, extant prototype systems can coordinate text and graphicaldepictions of devices for generating instructions about their repair orproper useñfor example, comet (feiner and mckeown, 1991) and wip(wahlster et al., 1993). these systems generate multimedia presentationsfrom a representation of intended presentation content and representprogress toward some of the functionality desired in an everycitizeninterface. for example, these systems can effectively coordinate mediawhen generating references to objects (e.g., òthe highlighted knobó;mckeown et al., 1992; andr and rist, 1994) and can tailor their presentations to the target audience and situation (mckeown, 1993; wahlster etal., 1993). in addition, it generates its presentation in an incrementalfashion. this allows it to begin producing the presentation before all ofthe input is received and to react more promptly if the goals or inputs tothe generator are changed. these are important features for an immpsthat will be used in an interface that is presenting information from thenii. another important area of recent research is in coordinating temporal media (e.g., speech and animation), where information is presentedover time and may need to be synchronized with other portions of thepresentation in other media (feiner et al., 1993; andr and rist, 1996).ideally, an immps would have the capability to flexibly constructpresentations that honor constraints imposed by media techniques andthat are sensitive not only to characteristics of the information being presented but also to user preferences and goals and the context created byprior presentations. researchers working in text generation have developed systems that are capable of using information in a discourse historyto point out similarities and differences between material currently beingdescribed and material presented in earlier explanation(s), to omit previously explained material, to explicitly mark repeated material so as todistinguish it from new material (e.g., òas i said before, 1dotsó), and to usemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.350more than screen deepalternative strategies to elaborate or clarify previously explained material(carenini and moore, 1993; moore, 1995; moore et al., 1996).this prior research requires rich representations of the informationthat is presented, as well as models of the userõs goals, tasks, and preferences. extending this work for an interface to the nii will require research on standardized data modeling languages and/or translation kitsand reusable models of common tasks. in addition, immpss capable ofoperating with shallower representations must be developed.finally, we cannot expect and may not even want immpss to bemonolithic systems that completely design presentations according totheir own criteria. thus, systems must be devised that can provide manylevels of assistance to users in the presentation design process. userscannot be expected to fully specify presentation design choices; it is morenatural for them to learn a language for expressing their tasks and goalsthan to learn a language for describing presentation techniques. in somecases, users will have preferences about presentation design in advance ofdisplay generation. in other cases they will want the ability to alter theway information is presented once they have seen an initial presentation.research is needed to develop natural, flexible interfaces to support interactive design, such as those described by roth et al. (1994, 1995).user interface environments forinformation explorationeven if iias can be provided that accept the type of queries i envision,users will want the capability to browse or explore the nii. this may bebecause they could not articulate a query (even interactively) until theysaw some of what was available or because the information they receivedled them to want further information. in addition, users may want to seesome of the information in more detail or see it presented in a differentmanner. for example, a user who is relocating to a new area mightrequest a visualization that shows several attributes of a set of availablehouses and relationships between them (e.g., number of rooms, lot size,neighborhood, and asking price). once this display is presented, the usermay then want to select some subset of the particular houses contained inthe original display, pick up this set, and draganddrop it on a map toolto see more precisely where the houses in the set are located.to provide these kinds of capabilities, software environments need tobe developed for exploring and visualizing large amounts of diverse information. as lucas et al. (1996) argue, this requires moving from anapplicationcentric architecture to an informationcentric approach. thedistinction hinges on differences in the basic currency through whichusers interact with a system. in applicationcentric architectures the basicmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions351currency is the file, and users must rely on applications to fetch anddisplay information from files. each application has its own user interface that defines the types of files people can manipulate and what theycan do with them. with the introduction of graphical user interfaces andthe desktop metaphor, files became concrete visual objects, directly manipulated by the user, stored on the desktop or in folders, and, to a limitedextent, arranged by users and software in semantically meaningful ways.but the contents of those files is still out of direct reach of the user.in their visage system, lucas et al. (1996) take an informationcentricapproach in which the basic currency is the data element. rather thanlimiting the user to files (or documents) as targets of direct manipulation,visage permits direct draganddrop manipulation of data at any level ofgranularity. a numerical entry in a table, selected bars from a bar chart,and a complex presentation graphic are all firstclass candidates for usermanipulations, and all follow the same òphysicsõõ of the interface. userscan merge individual data items into aggregates and summarize theirattributes or break down aggregated data along different dimensions tocreate a larger number of smaller aggregates. these capabilities form thefoundation for a powerful interface for data navigation and visualization.adaptive interfacesalthough the visage approach has proven successful for the simplegraphics implemented in the visage prototype (i.e., text in tables, bars incharts, symbols in maps), continued research is needed to handle thewide range of data and presentation types that populate the nii. inparticular, new approaches that allow richer analysis of the informationcontained in hypertext documents are needed. one area that is developing technology relevant to this need is research on adaptive hypertext andhypermedia systems, which exploit information about a particular user(typically represented in the user model) to adapt both the hypermediadisplays and the links presented to the user. adaptive hypermedia isuseful in situations where the hyperspace is large or the system is expected to be used by people with different knowledge and goals. this isclearly the case for the nii.researchers in text generation (moore and mittal, 1996) are workingon interfaces in which systemgenerated texts are structured objects.during the generation process, the system applies abstract rules to determine which text objects should be selectable in the final presentation (i.e.,which text objects will have òhyperlinksõõ associated with them). to posequestions, the user moves the mouse over the generated text, and thoseportions that can be asked about become highlighted. when the userselects a text object, a menu of questions that may be asked about this textmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.352more than screen deepappears. question menus are generated on the fly using a set of rules thatreason about the underlying concepts and relationships mentioned in theselected text (as represented in a knowledge base). because the systemhas a record of the plan that produced the text as well as a user model, itcan reason about the context in which the selected text occurs and providea menu of followup questions that are sensitive to both the discoursecontext and the individual user. in this system, texts are synthesizedfrom underlying knowledge sources by the system in response to theuserõs question or the systemõs need to communicate with the user. because the text is generated dynamically, the system cannot in advanceidentify the particular text objects that should have associated links orlinks to other texts. indeed, in this framework, traversing a link corresponds to asking the system to generate another text. moreover, thefollowup questions, which correspond to the links in traditional hypertext systems, cannot be precoded and fixed in advance but are generated dynamically using heuristics that are sensitive to domain knowledge, the user model, and the discourse context. as with many otherartificial intelligence approaches, this technology depends on the systemhaving a rich underlying representation of the domain content describedin the generated text as well as a model of the textual structure. but wecan easily imagine adapting this technology for use with the nii. techniques exist for automatically generating indexes from unrestricted textfor information retrieval (evans and zhai, 1996), so we can expect thatsuch indexes will (or could) be available for many, if not all, documentson the nii. in addition, parsers and partofspeech taggers can robustlyidentify the constituents of sentences (brill, 1993). building on these existing technologies would allow an interface in which, say, all noun phrasesin a document become mouse sensitive, and the hyperlinks to other documents are determined on demand by using the nounphrase (synonyms,etc.) as an index to find related documents. techniques developed in thearea of adaptive hypermedia may also be employed to allow the selectionof links to be sensitive to the userõs knowledge and goals.referencesandr, e., and t. rist. 1994. referring to world objects with text and pictures. pp. 530534 inproceedings of the 15th international conference on computational linguistics.andr, e., and t. rist. 1996. coping with temporal constraints in multimedia presentationplanning. proceedings of the national conference on artificial intelligence. menlo park, calif.:aaai press.boddy, m., and t.l. dean. 1994. deliberation scheduling for problem solving in timeconstrained environments. artificial intelligence, 67(2):345385.bratman, m.e., david j. israel, and m.e. pollack. 1988. plans and resourcebounded practicalreasoning. computational intelligence, 4(4):349355.brill, e. 1993. automatic gammar induction and parsing free text: a transformationbasedmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions353approach. pp. 259265 in proceedings of the 31st annual meeting of the association forcomputational linguistics.carenini, g., and j.d. moore, 1993. generating explanations in context. pp. 175182 in w.d.gray, w.e. hefley, and d. murray, eds. proceedings of the international workshop on intelligentuser interfaces. new york: acm press.draper, d., s. hanks, and d. weld. 1994. probabilistic planning with information gatheringand contingent execution. pp. 3136 in k. hammond, ed., proceedings of the 2nd internationalconference on artificial intelligence and planning systems. menlo park, calif.: aaai press.evans, d.a., and c. zhai. 1996. nounphrase analysis in unrestricted text for informationretrieval. pp. 1724 in proceedings of the 34th annual meeting of the association forcomputational linguistics. somerset, nj: acl.feiner, s.k. and k.r. mckeown. 1991. automating the generation of coordinated multimediaexplanations. ieee computer, 24(10):3341.feiner, s.k., d.j. litman, k.r. mckeown, and r.j. passonneau. 1993. towards coordinatedtemporal multimedia presentation. pp. 139147 in m.t. maybury, ed., intelligent multimediainterfaces. menlo park, calif.: aaai press.grosz, b., and r. davis. 1994. a report to arpa on twentyfirst century intelligent systems.ai magazine, 15(3):1020.kushmerick, n., s. hanks, and d. weld. 1995. an algorithm for probabilistic leastcommitment planning. artificial intelligence, 76(12):239286.lucas, p., s.f. roth, and c.c. gomberg. 1996. visage: dynamic information exploration. inproceedings of the conference on human factors in computing systems. new york: acm press.mckeown, k.r. 1993. tailoring lexical choice to the userõs vocabulary in multimediaexplanation generation. pp. 226233 in proceedings of the 31st annual meeting of theassociation for computational linguistics. somerset, n.j.: acl.mckeown, k.r., s.k. feiner, j. robin, d. seligmann, and m. tanenblatt. 1992. generating crossreferences for multimedia explanation. pp. 916 in proceedings of the national conference onartificial intelligence, menlo park, calif.: aaai press.moore, j.d. 1995. participating in explanatory dialogues: interpreting and responding to questions incontext. cambridge, mass.: mit press.moore, j.d., and v.o. mittal. 1996. dynamically generated followup questions. ieeecomputer, vol. 7586. (july).moore, j.d., b. lemaire, and j.a. rosenblum. 1996. discourse generation for instructionalapplications: identifying and exploiting relevant prior explanations. journal of the learningsciences, 5(1):4994.pryor, l., and g. collins. 1996. planning for contingencies: a decisionbased approach.journal of artificial intelligence research, 4:287339.roth, s.f., and w.e. hefley. 1993. intelligent multimedia presentation systems: research andprinciples. pp. 1358. in mark t. maybury, ed., intelligent multimedia interfaces. menlo park,calif. aaai press.roth, s.f., j. kolojejchick, j. mattis, and j. goldstein. 1994. interactive graphic design usingautomatic presentation knowledge. pp. 112117 in proceedings of the conference on humanfactors in computing systems. new york: acm press.roth, s.f., j. kolojejchick, j. mattis, and m. chuah. 1995. sagetools: an intelligent environmentfor sketching, browsing, and customizing data graphics. pp. 409410 in proceedings of theconference on human factors in computing systems. new york: acm press.wahlster,w., e. andr, w. finkler, j.j. profitlich, and t. rist. 1993. planbased integration ofnatural language and graphics generation. artificial intelligence, 63(12):387428.zilberstein, s., and s.j. russell. 1993. anytime sensing, planning and action: a practical modelfor robot control. pp. 14021407 in proceedings of the 13th international joint conference onartificial intelligence. chambery, france.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.354more than screen deepresource discovery and resource deliverykent wittenburgbellcorethe promise of a national information infrastructure (nii) includesthe ability for every citizen to access certain fundamental information andservices. i would assume that examples of fundamental information andservices would include directory information (analogous to the presentwhite and yellow pages); local, state, and federal government information, ranging from tax help to local library and social services to environmental regulations; and, lastly, a panoply of commercial services, such asaudio/video broadcasting and nway conferencing, virtual storefronts,and banking services that will emerge on some form of an infrastructurethat combines elements from present telephony, broadcasting, and datanetworks.todayõs world wide web is the closest approximation we have to thenii of the future. one way to proceed in revealing the pertinent researchissues is to ask where the current world wide web falls short in light ofthe goal of universal access. besides the problem of physical access vianetworks and user premise hardware, i see two major problem areas: (1)the resource discovery problem, which i take to be a product of the chaotic, fundamentally democratic nature of the web, and (2) the resourcedelivery problem, which has many dimensions, including complicationsbrought about by differing bandwidth capacities, differing user interactive devices, and differing user cognitive (dis)abilities.the goals that i see in these two areas can be stated simply:¥with respect to resource discovery, every literate citizen shouldhave access to directory and finding services that are within that userõscapacity to use. for example, every citizen should be easily able to locatethe local library or school systemõs offerings on the nii and select anappropriate service.¥with respect to resource delivery, every literate citizen, includingthose with vision or hearing disabilities, should be able to access information and/or services at a certain minimum bandwidth using any devicewith certain minimum resources (audio, screen size, color, etc.). for example, a blind person who has use of an interactive device based entirelyon audio should still be able to find and access the local library or schoolsystemõs offerings.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions355resource discovery research issuesthe resource discovery problem is one that is patently obvious toanyone trying to use the world wide web today. currently, the strategies for finding resources are:¥ask a friend or colleague;¥subscribe to mailing lists or publications that give updates on resources of interest to subscribers;¥use generalpurpose search services, such as altavista (http://www.altavista.com); and¥use subjectcataloging sites such as yahoo (http://yahoo.com) orthose provided by internet access providers or momandpop miniguides.the first two strategies actually may be more promising as a basis forfuture research activities and tools than we may think at first blush. iwould hazard a guess that most of todayõs knowledge workers whoseresponsibilities include keeping apace with developments in their areasof expertise have evolved a strategy of managing a personal view of theworld wide web that is populated largely by resources found throughserendipitous contacts with colleagues and friends as well as received asthrough netnews, mailing lists, and print or electronic publications. oneof the research challenges i would pose is to create tools and methods forlarger communities to leverage the millions of individual efforts that arealready taking place for organizing information. two exemplars of suchcommunitybased efforts at resource discovery are bellcoreõs group asyncronous browsing project (http://www.w3.orgpub/conferences/www4/papers/98/) and attõs phoaks work (http://weblab. research.att.com/ phoaks/).searchbased services are faced with the problems of how to manageand structure the astoundingly huge hit sets returned by their queries,how to include some form of quality control, and how to surmount, orshall we say circumvent, the inevitable precision/recall tradeoffs. further, there is the problem of combining and manipulating results fromdifferent search services and other relevant information broker sources.efforts to achieve some standardized distributed objectlike protocols sothat different search services can be integrated is a step in the right direction (http://wwwdb.stanford.edu/~gravano/standards). anotherneeded direction is in how to integrate search with structural browsingand in fact with communitybased sources of information as above. ingeneral, there needs to be much more work on how to integrate filters andviews over a domain, so that, for instance, a user does not have to dealwith the results from a general query whose domain is the world when allmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.356more than screen deephe or she is looking for is the library down the street. for an everycitizeninterface there is also the fundamental difficulty that effective use oftodayõs generalpurpose search engines requires a degree of sophistication beyond the reach of a substantial part of the population.as for subject cataloging efforts, the major problems are the magnitude of manual labor required to keep up with the rapidly changing weband the selfevident truth (which not everyone agrees with) that a singleuniversal hierarchical classification of every piece of information on theweb, even if it existed, would not be very useful. the private customizedsubject catalogs one finds on the home screens of certain access providersor networks are fine as far as they go, but they will not scale. one of themajor issues is how to build effective interfaces for browsing multiplehierarchies in an integrated fashion and, again, how to impose views overa massive collection of hierarchies that might be influenced by such factors as quality ratings, personal or group histories, popularity, and geographic locality.proposed projects: resource discoveryin the commercial marketplace we can expect that competing directory and search services will fight it out on the web, but a danger is, ofcourse, that a few companies may monopolize the area and make it difficult for the little guys to make themselves known. the business modelsfor directory services seem at the moment to rely primarily on advertising(or pseudoadvertising) revenues. for instance, one has to pay a lot ofmoney to get a link placed on netscapeõs browser menu (http://www.netscape.com). what is difficult to see coming from the privatesector are efforts that leverage the search services collectively and thatintegrate other helpful sources such as public sites (library of congress,for instance). note that such services would violate the current economicmodels since the private provider no longer has control over the enduserõs screen and cannot then leverage advertising revenue. in that light iwould suggest that at least one major project coming out of a governmentfunding effort concentrate on proposing standards and economic modelsfor information brokering services so that integrated resource discoverytools become possible. we also need to experiment with building publicregistries so that nonprofit and governmental bodies can be easily foundand their services utilized by the appropriate populations. one representative initiative in the earth science area is the usdac project sponsoredby the national aeronautics and space administration (http://usdac2.rutgers.edu/).another major thrust i would see is in projects whose goal is to buildinterfaces that integrate informationbrokering services enabled in partmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions357by the distributed substrate mentioned above. in the relatively shortterm, we can expect to see incremental improvements from the privatesector in interfaces for search and, say, graphical browsing. an appropriate subject for longerterm combined unversity and private research labefforts is to experiment with prototype interfaces for integrating distributed search services, structurally oriented graphical browsing, communitybased sources, geographic location services, and so on.lastly, there needs to be more basic research to understand and modelhuman resource discovery behavior, leading to evaluation metrics thatmight be used to judge competing techniques and systems. the xeroxparc work on information foraging (http://www.acm.org/sigchi/chi95/electronic/documnts/ papers/pppbdy.htm) is one exemplar ofthis line of research. the ultimate test will be success at allowingnonsophisticated users to find what they need, but it is not obvious at thispoint how to compare and evaluate competing systems and methods.research issues: resource deliveryas mentioned, the multidimensional resource delivery problem ischaracterized by constraints such as differing bandwidth capacities, differing user interactive devices, and differing user cognitive (dis)abilities.there are many ways in which to address these issues. my own perspective is approach it from the information providerõs point of view. if i asan information provider need to get fundamentally the same content (andservices) presented along so many dimensions, what is the technologythat will aid me to do so?the situation today is simply a horror show, although the advent ofstandard html, tools for format conversion, and crossplatform java aremajor breakthroughs. the basic issue is how one moves beyond html togenerate truly interactive interfaces for devices ranging from highendworkstations at t1 bandwidth to palmsized wireless devices at less than2k bits per second, for users with their full faculties and university training to economically disadvantaged and disabled users.from a design perspective the problem is how to take the same content and design effective presentations and interactions for certain targetpoints in this multidimensional space. this is a huge problem, and it isunreasonable to expect that each information provider must do this themselves from scratch for each piece of information they supply. the meagerefforts to address this situation, as far as i can see, are coming from theprivate sector in the form of proprietary htmlbased tools that representcontent in proprietary forms and then provide very limited help in designing for a very narrow range of alternatives.the research communities have shown some interest in addressingmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.358more than screen deepmultimodal and informationbased graphical alternatives. i think that themost appropriate issue to address in the context of universal access is howto design effectively in the face of very strong constraints (such as audioonly interfaces) given a common content representation. one must understand not only how to create an appropriate design in general but also howto map to an instance of it from common content. representing designknowledge (http://www.computer.org/conferen/vl95/talks/t1.html) isa crucial element in this enterprise. an example of a proposed mappingarchitecture can be found at http://community.bellcore.com/kentw/rgforap5abstract.html. others can be found in artificial intelligenceorientedwork on automatic presentation coming out of columbia, carnegie mellon,isi, and mitre. however, it strikes me that all of this work is far frombeing able to deliver on the promise of automatic contruction of presentations and interactive interfaces to meet the needs of universal access. themajor bottleneck, as far as i can see, is the lack of a common set of assumptions about the representation of content.proposed projects: resource deliveryfirst, i would propose an effort at defining a common level of representation in the context of one or more particular information sets. for instance, the government might have an interest in seeing certain essentialonline services such as tax help currently available in html designed anddelivered for a wider range of users and user devices. rather than attempting to agree on a common representation in the abstract, which will bevirtually impossible, i would suggest one or more concrete projects out ofwhich a proposal for a common representation may emerge.second, i see a need for cataloging design knowledge relevant toparticular points along this multidimensional delivery spectrum. thesepoints need to be identified, of course, and then bestinclass exampleinterfaces need to be built and abstracted. again, this could be done inthe context of a particular information domain of relevance to the government. defining appropriate forms for design knowledge is, of course, adifficult problem in itself and would need to be addressed.lastly, i think basic research in architectures for systems that mapfrom content to presentation instances needs to be fostered. these threeproposals in the end require integration, but in the short run i think it ismost appropriate to allow some independent efforts that can ultimatelybe brought together.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions359search and publishingrobert a. virzigte laboratories incorporatedsummarythe national information infrastructure (nii) is already here. bits andbytes buzz by us at an astounding rate just about wherever we go. theproblem is not with the infrastructureñthe databases, protocols, andphysical transport media. the problem is that we do not have a nationalinformation superstructureña set of access and publishing tools that arewidely distributed, easy to use, cheap, powerful, and accessible through avariety of terminals that include computers, personal digital assistants,telephones, screen phones, cellular phones, pagers, and television sets. inmy view the web of tomorrow will be nothing like the web of today interms of who is using it and what they will expect from it. to get therefrom here, we need to make progress in three key technologies: (1) intelligent agent technologies, including searching and filtering tools, need tobe made more comprehensive and transparent; (2) publishing tools needto evolve so that a greater variety of content producers can create information, in a greater variety of media; and (3) access needs to be possibleindependent of place (office, car, or home) and device (computer, phone,or tv set).intelligent agent technologiesthe current generation of searching and filtering tools is inadequatein two key respects. first, the tools are not comprehensive, restrictingsearches to a subset of the available sources. for example, searching for abusinessõs name on the web may return me a pointer to the businessõsweb site, but it is unlikely to return a phone number that the business canbe reached at. this is somewhat surprising considering that i can searchfor a businessõs phone number on the web at any of several sites, yet thesesearches are not likely to tell me much about a businessõs web presence.the net effect is that not only do i need to know the specifics of searchingusing any engine, i also need to know where to go to begin searching. thesecond user interface problem i have observed in searching and filteringmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.360more than screen deepmechanisms is that they tend to be rather opaque when it comes to informing the user of what was searched, what was rejected, why itemsmay have been rejected, and how successes are prioritized. an idealintelligent agent would make it easy for the user to express what hewanted done; confirm that the userõs intentions matched the effected actions; convey the breadth of the search, including gaps; and present results in a clear way that matches the userõs expectations.publishing toolsan interface to the nii for every citizen implies to me far more thanthe ability to find information. i have seen many reports in the pressregarding the gap between information haves and havenots. while i donot want to underestimate the importance of gaining access to information, i feel there has been far too little attention given to the gap betweenthe content production capable and the incapable. if we succeed in providing access to information for every citizen, i feel we will have fallen farshort of the mark. what is needed are tools and technologies that willallow any citizen to produce and publish content. we need to breakdown the barriers to production so that the nii doesnõt become the nextform of televisionña oneway pipe for the dissemination of carefullychosen messages by a select few. i believe that the goal of the nii shouldbe not just manytomany communication but anytoany communication. for this to happen, we need to find ways to make it much easier forpeople to produce content. we also need to understand and discuss newpublishing models that include broadcasting but that also allow forònarrowcastingó of information.i see the current barriers to widespread content production and publishing as the high capital costs of computer ownership; the high level oftechnical savvy demanded by todayõs production, editing, and publishing tools; the literacy level required by what is predominantly a textualmedium; and a lack of understanding on the part of the general population of the power of publishing content.place and device independenceas people come to rely on the nii more and more and as commercialendeavors begin to utilize it, the need to provide ubiquitous access willincrease. users will come to rely on the technology, and will demandaccess to it from their offices, homes, cars, hotels, airports, and otherpublic places. in order to provide place independence, we must find away to provide device independence. it should be possible to obtain orpublish information on the nii without a computer. this is not to say thatmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions361full functionality needs be provided from all types of terminals, but ratherthat the data appropriate to a given type of terminal should be presented.once we have achieved device independence, place independence willfollow automatically. and once we have place independence, people willcome to rely on and use the nii heavily and automatically.research questionsbased on the three key technological advances i see as necessary toproviding an everycitizen interface to the nii, i will outline some research questions that i see as ripe for attack.¥search strategies. how do people approach a search task? thedesign of search engines would benefit greatly from knowing what peopleexpect to happen given a variety of scenarios. free search engines such asaltavista seem to demand different kinds of knowledge from the userthan a visit to, say, yahoo!, which relies on defined categories to a greaterextent. do either of these models map more naturally to usersõ cognitivestyles? are there task dependencies? questions such as these seem eminently answerable today. indeed, there is actually a large informationsciences literature relevant to this area that has been strangely ignored.¥deviceindependent data structures. much of the information accessible today is highly tied to a particular class of display devices. evenmultimedia objects (e.g., a movie) are not usually separable into independent streams if, for example, my device could play sound but not showmoving images. this is unfortunate because in many instances degradedaccess to information is preferable to no access. this is a difficult problem, but it would be very useful to be able to separate the representationof the object as data from the device used to present it. the goal of thisline of research would be to define a common representation for published objects, along with translation mechanisms to provide access to theobjects from a variety of devices. such a research project would have afairly far horizon.¥publishing needs. to create usable publishing tools, we need abetter understanding of what it is that people will want to publish. this ismore difficult than it might at first sound, because it is difficult to getconsumers to think about how they will use something that is foreign tothem. however, in order to build tools that support the publishing needsof every citizen, and to evolve the infrastructure in support of those needs,we need a better understanding of how people want to use the system.i would emphasize that this could not be accomplished by lookingat peopleõs home pages today. we are in an age where the broadcastingmodel predominates. people and businesses put on the web what theymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.362more than screen deepare willing to let anyone see. as webbased security improves, we willmove to a narrowcasting model where the publisher can be assured oflimiting access to a select group. in some cases, this may lead to payforservices sites. in other cases people will use the security to òprivatelypublishó information, so that they may, for example, access an appointment schedule via their car phone.¥market research. although it is likely far outside the bounds ofwhat the national research council would consider as a project for study,there is a basic lack of understanding as to what consumers (i.e., citizens)actually want out of the nii. without this basic understanding we run theconsiderable risk of building the wrong thing. in the late 1980s, telephonecompanies were scrambling to find a way to deliver switched video to thehome. luckily, before the huge capital costs were sunk, these same companies began to understand that maybe this was not what their customersactually wanted. in point of fact, something much simpler and cheapercould meet most consumer needs, and that is the direction we are traveling now. i am concerned that we may not have done our homework onthe nii. building it does not ensure that they will come.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions363securitystephen kentbbn corporationevolution of national informationinfrastructure elementsas the national information infrastructure (nii) moves into the twentyfirst century, it is evolving into a more sophisticated collection of informationprocessing and telecommunications systems. one of the most pressing challenges is to offer greater functionality, and incorporate greatersecurity and privacy for these systems while providing a user interface thatis comprehensible, comfortable, and easy to learn by average citizens.residential telephone services, which used to provide only simplepointtopoint connection, now offer call waiting, call answering, callerid, call trace, call back, multiplexing of multiple numbers onto a singleline (with distinct ring patterns), etc. cellular telephones and pocketpagers began as expensive devices affordable only by professionals orthose whose companies paid the bills. now they are used by many òeverydayó citizens, and they offer increasingly sophisticated capabilities(e.g., twoway nationwide paging). airline passengers can initiate andreceive phone calls on many flights.local television was once defined by a small number of channels,dominated by three major networks, and delivered via vhf and uhfsignals. today, cable and satellite (including directbroadcast satellite)systems offer tens (soon hundreds) of channels, many with specializedprogram material. some television delivery systems allow a user to selecta channel via interaction with integrated, onscreen, time and subjectoriented schedules.computers, which used to be large, isolated, centralized systems costing millions of dollars, have become inexpensive, portable, and networked. computer communication, which was initially slow, expensive,and not very extensive, has become fast, cheap, and almost as ubiquitousas telephone service. localarea networks provide highspeed access inbuildings and on campuses, while widearea nets connect systems aroundthe world. emerging wireless computer communications systems promise to make mobile computing connectivity as easy and common as cellular phone service.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.364more than screen deepcitizen interaction with organizations, both businesses and government agencies, used to require facetoface meetings, filing of handwrittenforms, or telephone calls. automated touchtone response systems, tied todatabases and enabled with synthesized voice response technology, havegreatly increased the range of information that citizens can access and haveexpanded the times at which such data can be accessed. credit card balances, frequent flier account information, and tax refund status can all bechecked through calls to tollfree numbers. stock and mutual fund tradesand bank fund transfers can be initiated via similar means, all withoutdirect interaction with a human being and on a 24hour basis.today, many of the systems that have provided automated telephoneaccess capabilities are moving to internetenabled access. this provides amuch more powerful and convenient interface, enabling a wider range ofdata access with faster response and interaction characteristics. businesses and government agencies are moving rapidly to make informationavailable over the internet, via the world wide web. massachusetts nowsupports payment of traffic tickets over the web, as a first step towardmaking government more responsive and accessible to citizens. businesses of every stripe, from financial institutions to mailorder catalogmerchants, are providing client access via the web, in addition to thetelephone.a vision of near and intermediatetermnii interactionswithin the next 5 to 10 years significant improvements in many niielement interfaces will be implemented and widely deployed. the use oftechnologies such as cable modems, adsl, and isdn will significantlyimprove internet access speeds for residential users. continuing improvements in computer technology will increase local processing speed, enabling more sophisticated user interface software. the advent of verylowcost computers, designed specifically for web browsing and using atelevision as a video interface, promises to expand the subscriber baseinto many more households. using this model, one can imagine an nii inwhich citizen interaction with government agencies, businesses, and withone another make substantial use of this environment.requests for generic data from a vast array of government databasescan be made and instantaneously satisfied via web browsers interactingwith servers coupled to massive databases. interactions for a variety ofpersonal transactions with government agencies also will be enabled (e.g.,filing tax forms, making tax payments, or checking oneõs social securityaccount status).many catalogs and periodicals now delivered in hardcopy form canmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions365be delivered via the web, as some already are. after browsing onlinecatalogs, clients will place orders for items to be shipped via the postalsystem or express delivery services, all via the web. all forms of financial transactions (e.g., credit and debit card purchases, checks, cash exchanges, stock and mutual fund transactions) will be available via theinternet, and many will make use of these facilities instead of hardcopyinstruments.security, interfaces, and the niias elements of the nii evolve, as described above, they offer increasedfunctionality and improved performance, usually at lower prices. however, security and privacy concerns often are overlooked in this rush toenhance the nii. cellular phone calls are not only easy to intercept, butthe account information used for billing is even easier to acquire via automated means. it has been estimated that the lack of attention to security,if only for this billing authorization information, has cost the cellularphone industry hundreds of millions of dollars in lost revenue. digitalpaging systems are highly vulnerable to interception, raising privacy concerns. theft of service for cable and satellite tv delivery systems is oftendecried as depriving those industries of significant amounts of revenue.the caller id feature for telephone systems is both a blessing and a curse,from a privacy perspective.as companies have connected corporate computer and network systems to the internet to facilitate user access, the overall security of thesesystems has often been degraded. most of these internet connections aresecured by firewalls, a technology that usually constrains the internet soas to reduce its capability (even for authorized users) and which ultimately fails to provide highquality security for the computers being protected. the ease with which electronic mail can be intercepted or forgedis appalling. as the first tentative steps are taken toward consumerlevelinternet electronic commerce, the online literature is replete with examples of technical opportunities for fraud.for many of these nii elements the technology for improving securityand privacy has been available for some time, but often it has not beenimplemented. sometimes the reasons are purely economic (e.g., the costof adding security technology is perceived to make the resulting productnoncompetitive). sometimes timetomarket concerns prevent incorporation of security features (i.e., the delay imposed by adding security features would allow a competitor to offer a product or service sooner andthereby capture market share). however, in some cases the difficulty ofproviding a good user interface for security technology has been a majorimpediment.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.366more than screen deepas underlying communications and computing systems become morecomplex, there is a natural tendency for the user interface to become morecomplex, though that need not always be the case. for example, wimp(windows, icons, menus, pointers)based operating system interfaces canmask substantial underlying complexity, as illustrated by the contrastbetween the apple macintosh and dos interfaces at corresponding pointsin time. however, within the context of a paradigm such as wimp, increased functionality often results in increased complexity for users, asboth windows 95 and mac users can attest.computer systems have become more complex, and network interactions have become commonplace in the desktop and laptop systems thatusers employ in home environments. providing security for such systemshas become increasingly difficult. in the 1970s and 1980s much researchwas devoted to the development of secure operating systems, primarilyfor use with multiuser systems (e.g., timesharing systems and servers).however, all of this research into secure operating systems yielded verylittle that has been commercially successful or widely deployed. today,operating systems for the desktop computers most commonly used inhome environments (e.g., windows 95 and mac), have very few securityfeatures. yet these may be the models for the systems that citizens willmost commonly employ in their interactions with the nii.an alternative model, suggested by the ònetwork computeró paradigm promoted by companies such as oracle and sun, is a java interpreter and a web browser as the operating system replacement. giventhe many security problems that have been discovered in web browserssuch as the netscape navigator and the rash of javabased security problems that have been described in the literature, this is hardly an encouraging alternative paradigm.in either case, networked computers of some sort will provide aneverycitizen interface to many nii elements. there are fundamental anddifficult problems associated with developing highly functional and secure networked computer systems; these problems are exacerbated whenthere is a requirement to make the systems easy to use by all citizens.what is the hard problem?the fundamentally hard problem, as alluded to above, is one oftrying to make an increasingly complex system, operated by untrainedusers, secure in the face of attacks by sophisticated adversaries. variousaspects of this problem are examined below.as noted above, firewalls are typically used in corporate environments to provide òsecureó connectivity to the internet. one of the majorreasons for adopting this strategy is that those responsible for corporatemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions367computer security find themselves unable to effectively manage securityfor individual desktop computers. instead, by inserting a firewall at theperimeter of the corporate network, the site security administrator canfocus his or her attention on managing a single (or small number) ofcomputers devoted to a welldefined and limited task (i.e., controlling theflow of internet traffic across the security perimeter).in contrast, security management of individual desktop systems ishard because these systems are often directly under the control of users,executing a wide range of software, and based on operating systems thatare insecure out of the box.the control afforded by firewalls is in direct opposition to the internetgoal of facilitating the flow of information between clients and servers.security administrators are constantly fighting a battle to protect desktopsystems and servers by controlling the flow of data (using fairly crudetools), while users clamor for unbridled access to internet resources. thebest a security administrator can hope for is to implement a packetfiltering policy that satisfies most user demands while minimizing attack opportunities. this tug of war has become worse with the advent of theweb and java. the java model calls for loading software from serversinto usersõ computers for local execution, rather than transmitting datafor display by a browser and socalled helper applications.in a home environment, if the typical citizen makes use of the sameoperating system and many of the same applications and is assumed to beeven less technically sophisticated that his or her office counterpart, thereis even less likelihood that he or she will be able to manage the system ina secure fashion. moreover, since the system may connect directly to awide range of internet servers without the benefit of an interveningfirewall managed by a security administrator, the opportunities for successfully attacking such computers are almost boundless. the networkcomputer (nc) model transforms the problem but does not solve it. proponents of lowcost ncs describe simple systems without local disk storage and with a minimal operating system (e.g., similar to a web browser).applications are downloaded onto the nc over the net, for local execution, via highspeed connections.historically, one of the most difficult security problems to address isone in which potentially hostile software is imported into a target machine and executed. the òconfinement problemó refers to this situation,where the imported software is supposed to be constrained in its access touser data, being granted only the access necessary to perform its advertised task. a trojan horse is malicious imported software that performssome apparently useful function but also executes some sort of attack onthe target system (e.g., destroying data or acquiring data for the attacker).in conventional systems the first challenge for an attacker using a trojanmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.368more than screen deephorse was the problem of introducing his or her software into the target.if stealing data is the goal of the attack, the second problem faced by theattacker is one of exfiltration (i.e., sending the data back to the attacker).in an internet environment, especially in the context of web use, thissecond challenge essentially disappears. confinement, if successfullyimplemented, addresses trojan horse attacks by limiting the data andsystem resources available to the imported software.in the past a securitysavvy user would never import software intohis or her system from other than wellknown sources (e.g., major vendors). the introduction of òsharewareó and òfreewareó into a desktopcomputer, distributed over the internet or downloaded from an onlineservice such as aol or compuserve, flies in the face of this traditionalsecurity convention. yet software distributed in this fashion has becomequite popular and is widely used in corporate as well as home computerenvironments. functionality has won out over prudent security practice,even though examples of trojan horse attacks via these software sourcesare not unknown.the java model takes the imported software notion to its ultimate conclusion; it creates a legitimate path for infiltration of software (javaòappletsó) into user computers, typically via the internet and the web. tomake this potentially dangerous situation less so, java applets are supposed to be constrained in terms of the operations they can perform in theclient computer. for example, applets are not supposed to have access tothe local file system, to read or write user files. unfortunately, vulnerabilities in the initial implementations of java interpreters have not successfullyconfined applets, as promised. even if these java security problems arefixed, it is not clear that this simple model of highly constrained appletbehavior will persist. historically, useful applications have required accessto user files, both for reading and writing. if applets are to become powerful tools performing increasingly sophisticated tasks for users, it seemsunlikely that this stringent constraint will remain. thus, one should assume that applets will, in the future, be granted access to user data, whetherthe data are locally resident on a fullfledged computer or stored on somenetwork file server. functionality almost always wins out over security.an even more serious concern is that the user of a javaenabled webbrowser (or of a network computer in the future) may not even knowwhen applets are being loaded into his or her computer. today, manycorporate security administrators urge users to disable java support intheir web browsers to minimize the potential for this sort of securityproblem.while use of java is still rather minimal on the internet, in time manyweb pages may become java applets, and disabling java may preventaccess to so many sites that users are forced to permit java execution. somore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions369even if the user interface were to alert the user when an applet is downloaded, how would a user know whether that event posed a danger?in principle, if java environments evolve to a point where the knownvulnerabilities are successfully addressed, the user could control whichapplets were loaded and what operations they were authorized to perform. but is this a realistic expectation? this represents the critical security user interface issue for the nii.previous research on computer security showed that it was quite difficult to establish a constrained execution environment for imported software (i.e., to address the confinement problem). few operating systemswere successfully developed to meet this challenge, and very few aredeployed today. java does help address this problem by providing aninterpreted environment, and thus it should be possible to remove manymeans by which imported software might try to circumvent the constraints imposed by the user. however, so far the java environment hasproven to be vulnerable to circumvention by interpreted code, just assecurity controls in traditional operating systems have proven vulnerableto circumvention by compiled code.in those operating systems that have attempted to solve the confinement problem, a user interface capable of administering the finegrainedaccess control required for confinement has been very complex. compartmented mode workstations represent the most widely deployed systems that offer some form of operatingsystemenforced confinement.these unixbased systems are exceedingly difficult to administer, and thegranularity of confinement offered is relatively crude compared to what acorporate or home user might require for controlled execution of applets.to date, there is no indication of how to structure a user interface to makeconfinement of imported software generally understandable even to fairlysophisticated computer users.related problems and research directionsas noted above, confinement is a hard computer security problemthat has been studied for almost 20 years. to protect users against malicious imported software (e.g., applets), it will be necessary to offer finegrained access control to confine the execution of this software. thisproblem may be easier to solve in a more restricted environment such asthat envisioned for network computers, but it is still a hard problem.thus, the first research problem is the development of an interface that isintelligible to users to empower them to manage confinement for imported software.many of the forms of interaction alluded to above require authentication in order to provide security. the user must be authenticated to theserver, and the server must be authenticated to the user. the currentmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.370more than screen deepproposals for how to accomplish this requirement center around the useof public key cryptography and certificates (e.g., for validating digitalsignatures and for exchanging keys). however, we have no experiencewith public certification systems of the scale required to support all of thecitizens of the united states, and all of the commercial and governmentservice providers.in smallscale trials of certification systems for applications such as email, one of the problems that quickly becomes apparent is the difficultyof presenting the right amount of authentication information to the user.if one displays full certification path data, the user will almost certainly beoverwhelmed. if the only data displayed are from the final certificate in apath, suitable constraints must be imposed on the certification path validation algorithm to prevent òsurprises.ó however, configuring and managing certification path validation parameters appears to be a fairly complex task in the general case. noting that the average citizen cannotprogram a video cassette recorder successfully, it is hard to imagine howthis individual could manage a more complex certification validation system. this problems shows up in many ways.the java architecture calls for applets to be digitally signed to verifytheir provenance (e.g., to detect modification of the applet after it wasreleased by the developer or vendor). however, if it is hard to display theright level of detail to a user once the signature is validated, the signaturesmay not really address the fundamental problem of provenance. authenticating the identity of a server to which the user has connected poses asimilar problem. small variations in the spelling of a serverõs name embedded in a public key certificate could easily lead a user to believe thathe or she was connected to one (legitimate) server when another hadactually been contacted.this analysis suggests that a critical area requiring additional research ishow to provide a user interface to manage certification graphs, so that users aretruly aware of the identities of the people and organizations with whom they aredealing in cyberspace.many proposals for securing transactions generated by a user rely onthe user employing a private digital signature key to sign the transaction.however, the user never directly sees the data being signed; he or sherelies on software on his or her computer to indicate what is being signed.thus, a userõs signature may be applied to transactions or messages otherthan the ones he or she intends if malicious software manipulates the userinterface.several proposals call for citizens to make use of kiosks for sometransactions, both with government and commercial entities. this seemsespecially attractive as a means to empower lowincome households thatmight not otherwise have access to services via a home computer. howmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions371ever, not long ago, criminals managed to place a fake atm (automatedteller machine) in a shopping mall as a means of acquiring user bankaccount numbers and pins (personal identification numbers). a highertech version of this scam could be effected with kiosks and might be muchharder to detect. the fake kiosks could provide access to legitimate servers on behalf of the user, completing valid transactions on his or herbehalf. however, without the userõs permission, kiosks could also effectunauthorized transactions at the same time (e.g., applying the userõs signature to unauthorized transactions for money transfers).a final research problem area is how to provide a user interface for personalcryptographic tokens so that users will be protected from malicious software thatwill attempt to misapply a userõs digital signature capability.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.372more than screen deepresearch to support widespread access todigital libraries and governmentinformation and servicesben shneidermanuniversity of marylandthe rapid growth of the world wide web provides compelling testimony to the impact of improved user interfaces. although ftp (file transfer protocol), gopher, wais (wide area information service), and otherservices produced active usage, it was the appearance of easytouse embedded menu items and appealing graphics that produced the currentintensity of use. public interest continues to grow dramatically, and national policy is being effected in terms of providing access to governmentinformation and services.early adopters, who are typically technologically sophisticated, arehighly motivated to overcome poor designs and push beyond the difficulties to achieve their objectives. however, the much larger number ofmiddle and late adopters are less likely to tolerate chaotic screens; unnecessarily lengthy paths; slow response times; inconsistent terminology;awkward instructions; inadequate help facilities; and missing, wrong, oroutofdate information.a proactive approach can ensure that the emerging technology willprovide accessible, comprehensible, predictable interfaces that serve theneeds of the majority. a prompt and moderate level of research effort canshape the evolution of user interfaces to match the skills, needs, and orientation of the broadest users. topics might include the following:¥cognitive design strategies for informationabundant web sites,including metaphor choice (library, shopping mall, television channels,etc.), navigation design, and visual overviews;¥recognition and support for the distinct needs of diverse usercommunities, such as elderly, young, handicapped, lowerincome, minority, and rural users, plus those with poor reading skills;¥control panels to allow user tailoring to individual abilities, limitations, and technology;¥strategies to cope with efficient construction and maintenance oftext and graphic versions, multiple browser support, varied user displaydevices, and voice output;more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on functions373¥empirical studies of high versus lowfanout strategies (shallowversus deep trees), compact vertical design to reduce scrolling, benefits ofreduced/increased graphical treatments, and impact of slow responsetime;¥web site construction languages and templates, software tools toverify visual and textual consistency, web site management and terminology control, and thesaurus construction;¥sequencing, clustering, and emphasis of information items according to designer goals;¥weboriented user interface design to support browsing directories, searching for key phrases in document databases, and performingdatabase searches;¥design strategies to support evolutionary learning of complex sitesand services;¥easytouse facilities to permit user construction of informationalweb sites, community services, and entrepreneurial initiatives;¥lowcost computing devices and lowcost network access theòwebtop computeró;¥refined feedback and evaluation methods to guide designers, including usability testing, expert reviews, field trials, interviewing users,focus groups, email surveys, and email suggestion boxes;¥simple privacy protection and secure transmission of financial,medical, or other data;¥image compression methods to reduce file sizes while best preserving image detail, texture, and color richness; and¥logging and monitoring software, visualization of usage patternsfor individuals and aggregates, and costbenefit analyses.coordination with relevant groups can avoid redundant efforts andsupport common goals. current activities include the following:¥library of congress national digital library program, in cooperation with the university of maryland (ben@cs.umd.edu);¥national research council project on ordinarycitizen interfaces(alan biermann, chair, duke university, awb@cs.duke.edu)[the projectreported on in this volume].¥stanford university effort to coordinate database services (contact: hector garciamolina, hector@cs.stanford.edu);¥u.s. government efforts such as gils (government informationlocator service);¥usacm project: the interface between policy and technology inproviding public access to government data (contact: randy bush,randy@psg.com);more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.374more than screen deep¥joint effort on digital libraries by the national science foundation,national aeronautics and space administration, and defense advancedresearch projects agency; and¥international efforts (e.g., canada, singapore, italy).more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas375375position paperson application areascommunity computing projectsaki helen namiokacomputer professionals for social responsibilityintroductionin the fall of 1993, computer professionals for social responsibility(cpsr) published a position paper titled òserving the community: apublic interest vision of the national information infrastructure.ó cpsr,a national nonprofit organization with a history of addressing issues ofcomputing technology and its societal impacts, was in the unique position of being able to articulate concerns about the national informationinfrastructure (nii) from a publicinterest perspective while drawing fromthe technological expertise of its members. since the mid1980s and intothe 1990s, cpsr had taken positions on such topics as privacy, civil liberties, and free speech, with respect to electronic information. the 1993position paper urged the adoption of several policy and design guidelinesthat cpsr believes would serve the public interest in the development ofa new national information infrastructure. the policy guidelines are asfollows:more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.376more than screen deep¥consider the social impact of nii development.¥guarantee equitable and universal access to network services.¥promote widespread economic benefits.¥promote diversity in content markets.¥provide access to government services over the nii.¥protect the public spaces necessary to foster community development.¥encourage democratic participation in the design and development of the nii.¥think globally rather than nationally.¥guarantee functional integrity throughout the network.the policy guidelines are accompanied by the following design recommendations:¥emphasize ease of use.¥provide full service to homes, workplaces, and community centers.¥enable all users to act as both producers and consumers.¥address privacy and security issues from the beginning.¥develop open and interoperable standards.¥encourage experimentation and evolution.¥require high reliability.in addition, cpsr also strongly endorses the principles set forth bythe telecommunications policy roundtable in washington, d.c., of whichcpsr is a member. the principles are as follows:¥universal access: all people should have affordable access to theinformation infrastructure.¥freedom to communicate: the information infrastructure shouldenable all people to effectively exercise their fundamental right to communicate.¥vital civic sector: the information infrastructure must have a vitalcivic sector at its core.¥diverse and competitive marketplace: the information infrastructureshould ensure competition among ideas and information providers.¥equitable workplace: new technologies should be used to enhancethe quality of work and to promote equity in the workplace.¥privacy: privacy should be carefully protected and extended.¥democratic policy making: the public should be fully involved inpolicy making for the information infrastructure.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas377cpsr added one more principle based on its membersõ experiences asdesigners and users of networking systems:¥functional integrity: the functions provided by the nii must bepowerful, versatile, well documented, stable, reliable, and extendable.these guidelines provide a framework for discussion that is just asrelevant today as in 1993. since 1993, local, state, and national legislationand commercial development have eroded many of these principlesñrecent examples being the telecommunications reform act of 1996, washington stateõs harmful to minors bill, and the city of tacomaõs tax oninternet service providers. we have also witnessed the explosive growthof the internet. these developments, combined with cpsrõs experiencesand observations with community technology projects, such as the seattlecommunity network and virtually wired, have given us additional insights into what òpublic interestó really means.everycitizenõs accessñòinfoutopiaó versus realitysince vice president al goreõs introduction of the term informationhighway into our vocabulary during the 1992 campaign, private, public,and commercial organizations have been speculating about what theinfoway might look like and how it will be used. creative scenario builders, science fiction writers, and even successful entrepreneurs like billgates have painted visions of a òwiredó future. but all of these scenariosmake one underlying assumptionñthat the technology will be available(i.e., affordable and accessible) for all who want to participate.gary chapman, director of the 21st century project, in a 1996 articlein cio magazine, cautioned information executives that chief informationofficers in public services must ensure that information technologies willbe the cutting edge and not the cutting wedge of social progress.chapman noted that computer use, particularly internet use, in poorhouseholds (annual incomes of less than $10,000) is almost nonexistent.at the same time, publicsector organizations are being pressured to develop online systems that are available to the public over the ònet.óthe state of washington has been struggling with this type of pressure. in response to public demand and expectations, state agencies werealready putting information on the web and trying to grapple with theimpact of maintaining an òadditionaló mode of dissemination, not a replacement for an existing process. a governorõs task force on electronicpublic information access was legislated to make policy recommendations to assist state agencies in transitioning to the information age. onemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.378more than screen deepof the major issues facing these agencies is the cost of making the information available electronically.in his article chapman suggests that a partial solution to the problemof creating a society of information haves and havenots is to focus moreattention on funding and supporting community computing projects thatmake technology more affordable and accessible. for the past few years,cpsr members, in various locations around the country, have been involved in projects that focus on making technology available to everyone.community computingñpublic access to cyberspacedouglas schuler (1996), former chair of cpsr, in his new book, newcommunity networks: wired for change, discusses two forms of access tocommunity computing resources: community networks and communitycomputing centers. in 1992, cpsr/seattle started a community networkfor the seattle area. one of the purposes of the project was to implementan online service that was grounded in principles that the organizationbelieved inñthus the formation of the seattle community network(scn). it is no coincidence that the policy and principles that govern scnare similar to the cpsr guidelines introduced at the beginning of thispaper. the scn principles are as follows:¥commitment to access,¥commitment to service,¥commitment to democracy,¥commitment to the world community,¥commitment to the future.in addition, scn developed a policy statement as the underlyinggoverning framework. the highlevel guidelines for network users are:¥free speech: scn is committed to maintaining free speech rightsfor all participants.¥free access: scn is committed to maintaining free access to information for all participants.¥right to privacy: scn is committed to maintaining the privacy ofindividuals.¥due process: scn is committed to maintaining the right to dueprocess of individual users of the network.scn is just one of over 200 community network projects in the country, most providing free or very lowcost access to online services tocommunities. scn provides email, discussion forums, newsgroups, andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas379web services to anybody who fills out a registration form. the scnsystem is available through terminals in all branches of the seattle andking county public library system.however, availability of online services is only half of the equationof making technology accessible and affordable. access to the hardwarethat is needed to connect to any online service is the other half. this iswhere community computing centers are filling a societal need. in several american cities people are making computing resources available tothe public in community centers, schools, housing projects, and internetcafes. often these resources are available to the general public at little orno cost. projects such as virtually wired in boston, plugged in in eastpalo alto, and playing to win centers across the country provide a communal space where people can learn computer skills and explore theresources of the internet and world wide web.insightsmany lessons have been learned from observing and participating inmaking computing resources available to a large and diverse group ofpeople. for example, gender balance is possible in the online community. when the scn project started in 1992, the commercial online service subscribers were mostly males (at least 85 percent) and caucasian.from the very beginning, scn has managed to attract an almost 5050mix of male and female volunteers and participants. in 19931994, as scnwas doing its initial community outreach, entire families would attendmeetings on how to become information providers. early participantsincluded the older womenõs league, the seattle folklore society, and theseattle philharmonic.nontechnical people were enthusiastic about the scn project. unlikeother online services, scn was community focused; it provided a lowcost, lowthreat way for people and organizations to be information providers and users. educators, environmentalists, and librarians werescnõs earliest and strongest supporters, even in the days before the worldwide web and mosaic. like other online services, scn provides popularservices like email, forum newsgroups, and web accessñthrough lynx.because scn tries to be sensitive to the lowest common denominatorwith respect to web access, all information providers are strongly encouraged to design their pages for a graphics or a characterbased browser.this is an important design consideration when creating web pages for awide range of people.coralee whitcomb, director of virtually wired, in a recent discussion,shared her requirements for community computing. these include free email for everyone; a stable interface (something that lasts more than 6more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.380more than screen deepmonths); topicfocused search engines organized around specific areas(commercial, government, public sector, health care, nonprofits, medicalresearch hospitals); public access centers (e.g., washington informationnetwork kiosks located in public spaces throughout washington state)containing online government information (including committee reportsand campaign finances) that are as common as public pay phones andfree online services to schools with the schools given controlled freedomto resell it, thereby providing some financial support for a communitycomputing center.participating in these projects has also created indirect benefits thatare not purely related to the services being offered. scn has been thetraining ground for many unemployed volunteers who have later goneon to find jobs in the computing industry. whitcomb also made thefollowing points:1. never underestimate peoplesõ need for other people. we donõt taketo online help and waiting on hold, especially those who have put offlearning about this stuff. 2. public access [and] community networkingare doing the marketing dirty work that industry doesnõt want to do.weõre the ones drawing in the reluctant, fearful, nonenglish speakers,disabled, poor, slow, you name itñthey canõt be bothered. without usthere will be no universality in this technology because industry will notdo what it takes to truly distribute it. 3. people are extremely giving,especially computer geeks. virtually wiredõs most important role isproviding socially disabled, homeless, recovering addicts, lonely hearts,real community with real people. none of our volunteers have anymoney and they have terrific talent, yet they give away their talent tohave a place òwhere everybody knows their name.ó 4. computing canbe terrifically social. sharing, tutoring, and just sitting next to each otheris a good feeling. some use basketball courts; others use public access.midnight computing is a good idea (like midnight basketball). 5. experience is worth a thousand words. no amount of hype will develop thecontext most of us need to invest in a computer and isp [internet serviceprovider] without a solid reason. public access places can provide thekey experience to let people decide whether it is for them or not. 6.public access can help develop an appreciation for the many noncommercial uses of the net. we are going to have a big campaign democracy theme happening this fall, so people will become aware of the potential for citizenship.conclusionlooking back on the cpsr principles that were articulated in 1993and our experiences since then with the public at large, it appears thatmany of them have been validated. providing available computing and amore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas381forum where everybody can be both a consumer and a producer of information is an essential component of a free society.references and further readingchapman, gary. 1996. òno cover, no minimum,ó cio, july.computer professionals for social responsibility (cpsr). 1993. serving the community: apublic interest vision of the national information infrastructure.miller, steven. 1996. civilizing cyberspaceñpolicy, power, and the information superhighway.acm press, new york.schuler, douglas. 1996. new community networks: wired for change. addisonwesley,reading, mass.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.382more than screen deeplifelong learninggerhard fischeruniversity of colorado, bouldera ubiquitous goallifelong learning has emerged as one of the major challenges for theknowledge society of the future. this challenge is recognized by the international community as a variety of recent events indicate: (1) 1996 was theeuropean year of lifelong learning; (2) unesco (united nations educational, scientific, and cultural organization) has included lifetime education as one of the key issues in its planning; and (3) the g7 group of countries has named lifelong learning as a main strategy in the fight againstunemployment. despite this great interest, there are few encompassingefforts to tackle the problem in a coherent way. lifelong learning cannot beinvestigated in isolation by looking at one small part of it, for example, k12education, university education, or worker reeducation.learning as a new form of laborthe previous notions of a divided lifetimeñeducation followed byworkñare no longer tenable. learning can no longer be dichotomized,spatially and temporally, into a place and time to acquire knowledge(school) and a place and time to apply knowledge (the workplace). professional activity has become so knowledgeintensive and fluid in contentthat learning has become an integral and inseparable part of adult workactivities. professional work cannot simply proceed from a fixed educational background; rather, education must be smoothly incorporated aspart of work activities. similarly, children require educational tools andenvironments whose primary aim is to help cultivate the desire to learnand create, and not simply to communicate subject matter divorced frommeaningful and personalized activity.lifelong learning is a continuous engagement in acquiring and applying knowledge and skills in the context of authentic, selfdirected problems. it is applicable to the educational experience of both children andadults; it brings the childõs experience closer to meaningful and personalized work, and it brings the adultõs experience closer to one of continuedgrowth and exploration. lifelong learning is grounded in descriptive andmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas383prescriptive goals such as the following: (1) learning should take place inthe context of authentic, complex problems (because learning is moreeffective when people understand its impact); (2) learning should be embedded in the pursuit of intrinsically rewarding activities; (3) learning ondemand needs to be supported because change is inevitable, completecoverage of relevant information and knowledge is impossible, and obsolescence of acquired skills and knowledge is unavoidable; (4) organizational and collaborative learning must be supported because the individual human mind is limited; and (5) skills and processes that supportlearning as a lifetime habit must be developed.designlifelong learning integrates and mutually enriches the cultures ofwork and education. central to this vision in our own research is thenotion of design activities, a model of work that is openended and longterm in nature, incorporates personalized and collaborative aspects, andcombines technical and aesthetic elements. design (as practiced by engineers and architects designing infrastructure and buildings, lawyers designing briefs and cases, politicians designing policies and programs, educators designing curricula and courses, and software engineers designingcomputer programs) is an argumentative process, involving ongoing negotiations and tradeoffs. it is also a collaborative process, making increasing use of new social structures brought about by the advent ofcomputer networks and òvirtual communities.ó the communality thatbinds design activities together is that they are centered around the production of a new, publicly accessible artifact. it is impossible for designprocesses to account for every aspect that might affect the artifact designed. therefore, design must be treated as an evolutionary process inwhich designers continue to learn new things as the process unfolds, newrequirements surface, and technologies change.rethinking, reinventing, and reengineeringeducationa deeper understanding and more effective support for lifelong learning will contribute to the transformation that must occur in the way oursociety works and learns. investments in information technology have sofar produced disappointing results because both industry and educationtend to use these technologies simply as support mechanisms for existingpractices rather than as vehicles to promote fundamentally new ways tocreate artifacts and construct knowledge. a major finding in currentbusiness reengineering efforts is that the use of information technologymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.384more than screen deephas had disappointing results compared to the investments made in it.although a detailed causal analysis of these findings is difficult to obtain,it is generally agreed that a major reason is the fact that informationtechnologies have been used to mechanize old ways of doing businessrather than fundamentally rethinking the underlying work processes.we claim that a similar argument can be made for current uses oftechnology in education: it is used as an addon to existing practicesrather than a catalyst for fundamentally rethinking what education shouldbe about in the next century. as an example, the òinnovationó of makingtransparencies available on the world wide web rather than distributingpaper copies of them in class takes advantage of the web as an electronicinformation medium, but contributes little in the way of introducing newepistemologies. old frameworks of education do not get changed byusing technology in a ògiftwrappingó approach where traditionalinstructionist, fixedcurriculum, decontextualized, rote learning isòwrappedó with new technologies such as computerbased training, intelligent tutoring systems, multimedia presentations, or the world wideweb. we need computational environments to support ònewó frameworks for education such as lifelong learning, the integration of workingand learning, learning on demand, authentic problems, selfdirected learning, information contextualized to the task at hand, (intrinsic) motivation,collaborative learning, and organizational learning.myths and misconceptionsthe current debate about the ability of computation and communication to change education fundamentally is (in our opinion) based on anumber of basic myths and misconceptions. the most prevalent of theseare the following:¥computers by themselves will change education. there is no empiricalevidence for this assumption based on the past 30 years of using computers to change education (e.g., computerassisted instruction, computerbased training, intelligent tutoring systems). technology is not a òdeusex machinaó that can solve the existing problems of education. traditional, instructionist approaches are not changed by the fact that information is disseminated by an intelligent tutoring system.¥information is a scarce resource. òdumpingó even moredecontextualized information on people does not seem to be a big stepforward in a world where people already suffer from information overload. instead, technology should provide ways to say the right thing atthe right time in the right way.¥the content, value, and quality of information and knowledge are immore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas385proved simply because information is offered in multimedia or over the web.media alone do not turn irrelevant or erroneous information into morerelevant information. we must create innovative technologies (e.g., design environments, simulations, visualizations, critiquing) to let peopleexperience knowledge in new ways.¥ease of use is the greatest challenge or the most desirable goal for newtechnologies. usable technologies that do not serve the needs and concernsof people are of no value. rather than assuming that people should andwill be able to do everything without a substantial learning effort, weshould design computational environments that offer a low threshold forbeginners to get started and a high ceiling for skilled users to do thethings they want.¥the myth of the nobel prize winnerñone of the earlier arguments insupport of the information superhighway was that every school childwould have access to a nobel prize winner. although this argument istrue (or soon will be) at the level of technical connectivity, it is hard toimagine that nobel prize winners will look forward to getting a few thousand email messages a day.¥the single or most important objective of computational media is reducing the cost of education. although we should not ignore any opportunityto use technology to lower the cost of education, we should not lose sightof an objective that is of equal if not greater importance: increasing thequality of education.¥human learning is equal to machine learning. although we havedeepened our understanding of human learning through progress inmachine learning, there are fundamental dimensions, such as motivationand competing requirements for a personõs time, that make human learning a much more complex and interwoven activity than machine learning. there is substantial empirical evidence that the chief impediments tolearning are not cognitive. it is not that students cannot learn; it is thatthey do not wish to.challengesmaking learning a part of life creates many challenges, requiring creative new approaches and collaboration between many different stakeholders. for illustration, a few of them are mentioned here:1.the educated and informed citizen of the future: òsupercouch potatoóconsumers or enlightened designers? the major innovation that many powerful interest groups push for with the information superhighway is tohave a future in which everyone can demonstrate creativity and engagement by selecting one of at least 500 television channels with a remotemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.386more than screen deepcontrol. the major technical challenge derived from this perspective becomes the design of a userfriendly remote control. rather than servingas the òreproductive organ of a consumer societyó (ivan illich), educational institutions must fight this trend by cultivating òdesigners,ó that is,by creating mindsets and habits that help people become empoweredand willing to contribute actively to the design of their lives and communities. this goal creates specific challenges for computational artifacts,such as the support of enduser programming and authoring.2.the òbasic skillsó debate. if the hypothesis that most jobrelevantknowledge must be learned on demand is true, we must ask ourselves thequestion: what is the role of òbasic skillsó? for example, if the use ofsoftware packages dominates the use of mathematics in the workplace,shouldnõt a new function of mathematics education be to have studentslearn to use these mathematical artifacts intelligently? another importantchallenge is that the old basic skills such as reading, writing, and arithmetic, once acquired, were relevant for the duration of a human life;modern basic skills (tied to rapidly changing technologies) will changeover time.3.can we affect motivation? as mentioned above, there is substantialempirical evidence indicating that the chief impediments to learning arenot cognitive but motivational. this raises the challenge of creating learning environments in which learners will work hard, not because they haveto but because they want to. we need to alter the perception that seriouslearning must be unpleasant rather than personally meaningful, empowering, engaging, and fun. our research has developed computationalenvironments that address these motivational issues; for example, systems have explored making information relevant to the task at hand,providing challenges matched to current skills, creating communities(among peers, over the internet), and providing collaborative access toreal practitioners and experts.4.schooltowork transition. if the world of working and living relieson (a) collaboration, creativity, definition, and framing of problems; (b)dealing with uncertainty, change, and distributed cognition; (c) copingwith distributed knowledge; and (d) augmenting and empowering humans with powerful technological tools, then schools and universitiesshould prepare students to function in this world. industrialage modelsof education and work (e.g., based on skinner and taylor) are inadequateto prepare students to compete in the knowledgebased workplace. amajor objective of the lifelong learning approach is to reduce the gapbetween school and workplace learning. current research addresses someof the major schooltowork transition problems and develops answers tothe following questions:more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas387¥how can schools prepare learners and workers for a world thatrelies on an interdependent, distributed, nonhierarchical informationflow and rapidly shifting authority based on complementary knowledge?¥what basic skills are required in a world in which occupationalknowledge and skills become obsolete in years rather than decades?¥how can schools (which currently rely on closedbook exams,the solving of given problems, etc.) be changed so that learners areprepared to function in environments requiring collaboration, creativity, problem framing, and distributed cognition?¥to what extent will lifelong learning and new approaches tolearning and teachingñsuch as learning on demand, learning whileworking, relations, and the involvement of professionals in schoolsñprepare learners for work?lifelong learning: an impetus for designingeverycitizen interfacesthere is general agreement that as we approach the next century andnext millennium, our society is changing to a knowledge and informationsociety. there will be new opportunities and new challenges in all dimensions of our lives. but the future is not out there to be discovered: ithas to be invented and designed. making learning a part of life and theimplications this has for how, under the influence of new media, humanbeings will think, create, work, learn, and collaborate in the future aremajor considerations for the design of everycitizen interfaces to the national information infrastructure (nii). although the technologies surrounding the nii are important, we should not forget that they are meansto ends and that we need to develop a deep understanding of these ends.further information background information about the ideas articulated in this positionpaper can be found on the world wide web:1.about the center for lifelong learning & design (l3d) at theuniversity of colorado, boulder, and its research activities: http://www.cs.colorado.edu/~l3d/2.a slide show of a presentation to the national science foundationabout lifelong learning: http://www.cs.colorado.edu/~l3d/presentations/gfnsf9.95/more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.388more than screen deep3.about agentsheets, a computational substrate to support the development of design environments, simulations, and visualizations: http://www.cs.colorado.edu/~l3d/systems/agentsheets/4.about the agentsheets remote explorium, an environment to turnthe web from an information dissemination medium into a collaborationmedium: http://www.cs.colorado.edu/~l3d/ systems/remoteexplorium/5.aboutwebquest, a system that exploits the web with interactivelearning games:¥about the system itself: http://www.cs.colorado.edu/~corrina/mud/¥a paper describing the system: http://www.cs.colorado.edu/~corrina/webquest/6.about òsimcity in 10 minutesó describing the philosophy of thecenter for lifelong learning and design on enduser programming: http://www.cs.colorado.edu/~corrina/simcity/more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas389supporting learning in communities of practicecharles clearynorthwestern universitylifelong learning: a key function for the nationalinformation infrastructurethe national information infrastructure advisory council (niiac,1995) has identified education, particularly, lifelong learning, as one offive key areas requiring attention in the development of the nii. although the niiac does not argue for its focus on lifelong learning, thecase for the importance of lifelong learning is now familiar to most education researchers:¥the range of skills and knowledge that individuals now need forsatisfying, productive lives is so broad and unpredictable that we can nolonger hope to teach them all they need during the traditional school years.¥many types of technical knowledge have but short halflives, soindividuals need to continually reeducate themselves if they are to keepcurrent.¥individuals change careers increasingly often, and, when they do,they frequently need to augment or rebuild their skills base.¥learning is increasingly intertwined with òregularó work, as individuals and organizations see continual improvement as an integral partof doing work.¥learning is fun and so people wish to continue learning even afterthe traditional school years end.in short, the need to support lifelong learning is well established, butthe mechanisms for doing so are less well defined. this position paperaddresses the question: how can we apply the nii to foster lifelonglearning?communities of practice as communities oflearningto support learning we must begin by considering how people learnmost effectively. for instance, consider these four themes from recenteducational research:more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.390more than screen deep¥motivation is critical. learning is most effective when learners areable to pursue challenges they care about.¥transfer is hard. it is easiest for people to apply what they learnwhen they learn it in a context like that in which they will need to apply it.traditional òteachemandtestemó methods of teaching often lead toinert knowledge.¥skills are more important than facts. a good speechmaker mustcommand both impressive writing skills and broad factual knowledge.but skills are harder to acquire than facts. so people are more oftenconcerned with learning how (e.g., how to draft a speech) than learningthat (e.g., that george washington was the first president). to learn skills,people must practice them (learning by doing).¥support is essential. people learn to do complex tasks best when theyreceive coaching. people are ready to learn when they have tried something out and have failed. but they need advice to help them understandwhy they failed and to determine how to improve their performance.these themes point out that people learn most readily when they careabout what they are learning, when they try to solve problems in realisticcontexts, and when they have access to coaching when they get stuck.although these constraints may not be satisfied very often within thewalls of todayõs schools, they are satisfied in many situations outsideschool. in particular, they are satisfied when people who share an interestin a domain support each other in advancing their learning. such groups,which have been labeled communities of practice, are quite common. froma group of engineers who are concerned with similar problems to aninvestment club to a swimming team, people often join together in communities of practice.communities of practice can provide fertile support to help individuals learn throughout their lifetimes. as an example, consider a groupinterested in fostering literacy. such a group can help with motivation. acollege student who thinks he may want to dedicate his career to increasing literacy levels can sit in on a few events that the literacy group sponsors to make sure that the field matches his expectations before he commits to it. the group can help with skill building. the literacy group canenable the college student to engage in real tasks (e.g., helping run reading groups) and work on real problems (e.g., selecting appropriate material for a particular reading student). both the group and the collegestudent benefit. furthermore, communities of practice also often provideestablished routes for scaffolding learning, whereby new members beginwith simple tasks and work their way up to expertlevel tasks. finally,the group can also help with coaching. if the college student runs intotrouble when he tries to find appropriate reading materials, he can turn tothe literacy group for advice from a senior member.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas391communities of practice can also serve as engines for advancinggroup learning. an organization learns most effectively when it can harness the experiences and energy of all of its members. often the learningcycle begins with the most junior members in a group. for instance, whena new member asks a question that the group cannot readily answer, thenthe group learns of a need for new learning. when the group works todevelop an answer, the group advances its theory of its domain. whensomeone later tries out that answer and finds a wrinkle in it, the cyclebegins again. acting alone, the members of the community will run intoonly a few problems and be able to generate a few potential answers.when they join in a group, the members can leverage each otherõs specificexperiences to build significantly more powerful understandings of theirdomain.given that communities of practice provide an effective and relatively widespread mechanism for supporting lifelong learning, it is notsurprising that the niiac links them together in its report (niiac, 1995):by providing people of all ages with opportunities for lifelong learningand workplace skills development, the nii should enhance each individualõs ability to create and share knowledge and to participate in electronic communities of learning.still, the question remains: how can we apply the nii to support communities of practice?an approach to supporting communities of practicecommunities of practice can effectively support both individual andgroup learning. for a community to operate smoothly, it requires frequent and flexible communication between its members. furthermore, ifa group is to grow to significant size, it requires some way to leverage theexperience of its thought leaders, so that they do not become overwhelmed with demands for coaching. because of these constraints, fewcommunities of practice function effectively today if they contain morethan a few dozen members or members who are geographically separated.the foundation provided by the nii can potentially enable membersof a community to communicate across the boundaries of space or time.however, this potential is yet to be realized. to effectively support communities of practice, improved applications must be developed that willrun on top of the nii.what sorts of applications are these? as an example case, imaginethat an independent business consultant would like to learn how to betterdiagnose a clientõs problem. he is a member of a geographically dismore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.392more than screen deeppersed group of independent consultants. what sorts of applications canbe provided that will help the consultant take advantage of the resourcesof the group (and that will help the group develop resources that areworth taking advantage of)?three separate classes of applications are needed. the most fundamental is that groups require organizational memories to keep track of whattheir goals are, what they know, and what they would like to learn. as asimple example, the business consultant might tap into a òmemoryó ofbusiness cases to search for one that is similar to his clientõs. however,organizational memories alone are not sufficient because too often theknowledge they contain lies inert. accordingly, groups also require twoclasses of applications that actively deliver knowledge to the point ofneed. first, groups require performance support tools that help users perform tasks effectively. for instance, the consultant could make good useof a performance support tool that leads him through the process of making an effective diagnosis, feeding him appropriate advice or factual content from the groupõs organizational memory as it becomes relevant.additionally, groups require training systems that enable individuals tolearn how to perform tasks in a safe environment. for example, once theconsultant makes his diagnosis, he could benefit from a training simulation that helps him learn how to position his recommendations to hisclient in his final presentation. again, these training systems will rely onthe knowledge contained in the organizational memory, both for raw casematerial and for coaching knowledge about how to respond to commonfailures or queries.organizational memoriesthe most straightforward function of a groupõs memory is to helpmembers of the group publish their expertise to each other and to òoutsiders.ó if my brotherinlaw happens to be an expert investor and i wishto know how to allocate my retirement funds, it would be reasonable forme to want some advice from him. however, the problem arises that 15other people ask for the same advice in the same week, particularly if heis a member of a large investment club. people who develop a specialtydo not want to have to answer the same questions time and again. instead, they require some mechanism for publishing what they know. unfortunately, current media are not particularly effective at publishing largebodies of complex interrelated knowledge. so we require improved groupmemories that provide more effective mechanisms for publishing knowledge.additionally, organizational memories should be dynamic, changingas the group modifies and expands on its ideas. organizational memoriesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on application areas393should help groups keep track of what their goals are, what they know,and what they would like to learn. current systems are not particularlyeffective at helping communities develop new knowledge (or capture thenew knowledge they do develop). when a novice asks a question forwhich the community has not yet developed an answer, what shouldhappen? the question should be posted and perhaps routed to those whohave an interest in (or responsibility for) developing an answer. thesepeople must develop their opinions, perhaps collaboratively. differencesin opinions must be ironed out or at least understood. the results of thisdiscussion need to be captured in a form that makes it readily available,as needed, to those who later develop a need that it can address.today, applications such as email and usenet news support some ofthe functions required to support knowledge building. however, thehard problem is integrating all of these functions, particularly those having to do with capturing the results of discussions, thereby helping groupsto pull together a consensus point of view from a collection of disparateopinions. complicating this task is the observation that the same piece ofcontent may be relevant in quite different situations (e.g., a counterexample to someone making a claim, a piece of advice to someone facinga problem, an illustration to someone asking a question). to build dynamic memories, the indexing problemñdetermining how to label contentso that it can be retrieved in the range of situations in which it will berelevantñmust be tackled.performance supportmembers of a community of practice rely on each other for supportand advice as they perform their work. however, it is not always possibleto access the right expert at the right time. accordingly, we require performance support tools that help members tap into a communityõs organizational memory. this support can take a range of forms, includingproviding cases that are similar to the situation in which a user finds himor herself, abstract templates for how to perform a task, and automatedtools that actually perform the task for a user.when a person tries to leverage each of these types of support, he orshe is likely to have a range of sorts of questions. for example, someonewho is trying to find a case in a performance support system might wantto ask questions such as:¥òhow should i go about choosing a case?ó¥òwhat mistakes am i likely to make?ó¥òwho can help me understand if i have chosen an appropriatecase?ómore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.394more than screen deepif a performance support system only provides raw content (e.g.,cases) and does not also answers such questions, it is likely to leave someusers confused about how to apply the content that it does provide. accordingly, performance support tools should not only provide raw content, they should also allow their users to ask a range of types of questionsabout that content.simulationbased trainingpeople learn by doing. for instance, to become a good investor, onemust do a lot of investing. but investing is a risky business. so it is bestto practice in a safe, controlled environment, one that allows effectivecoaching to be delivered as it is required. simulationbased training environments can allow people to learn by doing without the risk of catastrophic failure.more generally, it is often easiest to explain what a domain is about toprospective members of a community by letting them try completing atask in the domain. similarly, it is often easiest to help existing memberslearn new skills by allowing them to have a go at them. since performingtasks in the real world is often expensive and does not permit adequatecoaching, giving members simulated experiences is a sensible approach.however, good simulations require good content. a simulationbuilder must identify which tasks are important to simulate, what casematerial may be used as grist for the simulation, what errors users arelikely to make, and what coaching is appropriate to deliver when thoseerrors occur. importantly, this is the same type of content that an effectiveorganizational material should provide.the niiõs rolethe nii can, in theory, help those with similar interests work together, even though they may be separated by barriers of space and time.this potential, if realized, promises to revamp how we as individualslearn throughout our lifetimes and how we as a society grow our capabilities. however, to realize this potential, we must move beyond generalgoals to a specification of the types of applications we desire the nii tosupport. only then can we create the particular research agendas neededto develop these applications.referenceniiac. 1995. common ground: fundamental principles for the national information infrastructure.first report of the national information infrastructure advisory council. march.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups395395position paperson selected population groupsextending knowledge access tounderserved citizenswallace feurzeigbbn systems and technologiesissues and goalsif we are serious about making available the rich human and information resources of the national information infrastructure (nii) to all citizens, we have to address the great, and growing, knowledge gulf betweenthe òhavesó and òhavenotsó in american society. this disparity poses areal threat to our political and social lives. it is at variance with ourhistory and our democratic ideals. many citizens who are economicallyunderserved are also òinformationally disadvantagedó (national telecommunications and information administration, 1995). the knowledgeempowerment made possible by the new information technologies mustbecome available to all. we must work toward democratizing access toeffective use of networking technology by all americans who are capableof benefiting from its use. we need to provide the underserved not onlywith access to these potentially empowering information resources butalso support in their use through education, training, and acculturation.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.396more than screen deepresearchers at bbn and elsewhere have done preliminary work alongthese lines to better understand the issues. though neither systematic norcomprehensive, this work identifies some key research questions and suggests specific directions for more substantial actionoriented research efforts.internet use by lowincome familiesa recent study conducted from december 1994 to january 1996 probedthe barriers, benefits, and perceived worth of the internet to six lowincomeurban families in florida, a group representative of the traditionally underserved and informationally disadvantaged population (bier, 1996). theresearchers asked what these families would actually do online given unrestricted internet access in their homes. each family was lent a homecomputer, highspeed modem, and printer; was provided with dialuppointtopoint internet access; and was given training on the use of themouse and keyboard. the computers were equipped with an interfacesecurity program, an integrated productivity package, several educationalgames, a typing tutorial, and a set of internet utilities. families weretaught how to communicate with each other electronically and how tolocate and acquire resources from the internet. additional training andtechnical support were available on demand for the duration of theproject. through interviews, visits, and telephone and email interactions, researchers obtained data on the amount of time participants spentonline, the sites they visited, the information they sought, and the obstacles they encountered. the participants made use of virtual hospitals,medical dictionaries, and physiciansõ desk references. they joined support groups, investigated scholarships, and made local transportation arrangements. they investigated appliances, employment listings, and local calendars of events. they emailed, chatted, and surfed the worldwide web; made friends; felt personally empowered as learners; andgained a new sense of community. the results showed that internetaccess enabled òpowerful emotional and psychological transformationsóon the part of the participants.educational software use by educationallydisadvantaged studentsduring the past two years, my colleagues at bbn have used the computer program rellab (for relativity laboratory) to teach the concepts ofrelative motion to educationally disadvantaged innercity high school students in boston (horwitz, 1995). the program enables users to constructand run relativity òthought experiments.ó the innercity students workedmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups397on the same sequence of activities as the educationally advantaged suburban students with whom we worked earlierñand with almost identicalresults. they advanced steadily from simple galilean (lowspeed) relativity problems to complex ones involving the frame independence of thespeed of light and its implications for simultaneity, time dilation, andlength contraction. along the way they exhibited the same frustrationsand overcame the same obstacles as the suburban students, and theyprogressed at about the same rate. moreover, they showed as muchinterest and had as many breakthroughs as their advantaged peers. theonly real differences were that the innercity students were considerablyless verbally communicative than the suburban students and almost allwere severely educationally deprived. this was particularly evident inthe case of math. their knowledge of the decimal system was spotty andunreliable, and they had great difficulty graphing data. despite theircompetence on the computer, they were hopeless at pencilandpapertasks with the same material, particularly written tests. based on posttestinterviews of the students, it appeared that their poor performance wasdue not only to knowledge gaps but also to significant deficits in readingcomprehension.during the past year bbn researchers have also been using anothereducational computer program, genscope, to teach the concepts of genetics to suburban and innercity students in high school biology classes.genscope enables users to explore and experiment with genetics models.it has proved engaging to both male and female students of widely differing ages, backgrounds, and ability levels. the most interesting resultshave come from the innercity population, where students who hadlearned very little from a conventionally taught biology class learned agreat deal about complex genetic processes working with genscope andused their new knowledge effectively to accomplish a variety of analytical and constructive tasks. moreover, they remembered what they hadlearned, and some were able to give accurate and detailed explanationsweeks later in interviews conducted away from the computer. however,we found the same results as those noted above with rellabñthough theinnercity students often learned to do sophisticated genetics on the computer, their knowledge rarely transferred to paperandpencil tests. theywere unable to express in writing the complex knowledge they exhibitedon the computer. given the software tools and support, educationallydisadvantaged students acquired and applied complex reasoning, buttheir knowledge was locked in. they lacked the basic reading comprehension and communications skills that are fundamental for success in education and skilled occupations. the challenge is to help students likethese acquire the verbal literacy that will enable them to participate morefully as citizens in the knowledge society.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.398more than screen deepresearch issuesthe positive outcomes shown in the study of internet use by lowincome families are indeed impressive and encouraging. this work criesout for replication and suggests new questions for further research. whatare the key requirements for making such internet use productive? whatskills and motivation must users possess to begin with? what kind oftraining and ongoing support are required? how much onsite help isrequired, and how practical and effective is online mentoring in augmenting initial training? can the facilities, training, and support be providednot only or not primarily in the home but also in social settings like community organizations, churches, local schools (afterschool programs), andparticularly librariesñplaces with expert human information resources?the results from the use of sophisticated learning technology by innercity high school studentsñtheir success in acquiring and using complex knowledge contrasting strongly with their difficulty in communicating that knowledgeñare more problematic and troubling and raiseanother set of research questions. can high school students who fail toacquire competence in reading, writing, and communications skills overcome these deficits later? are these difficulties remediable by tutoring?or is there a literacy learning barrier for english (analogous to the putative foreignlanguage age block) that makes the acquisition of fluency inreading and writing english enormously difficult after a certain age ordevelopmental level?these questions provide a rich source of cognitive, educational, ethnographic, and technological research investigations, from intensivesmallscale studies of individual development to longterm longitudinalprograms involving large populations. rather than providing brief summaries of possible research projects across this wide spectrum, i will focuson a single project that is motivated by both of the preliminary studiesdiscussed above and that has important implications for advancing thegoal of universal citizen participation and empowerment through educational networking.the productive use of the internet by lowincome citizens would nothave been possible if they did not bring to these activities a fairly highlevel of functional literacy. the stunted development of literacy skillsamong the innercity high school students severely limited their socialparticipation and learning opportunities, despite their inherent intellectual abilities. effective utilization of the nii, no matter how rich its userinterface and information resources, will require that its users bring amodicum of literacy. but our nation has an enormous number of citizenswho do not meet that test. i describe a research project that seeks toaddress, through the use of new interface technology and associated inmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups399structional activities, a most severe literacy problemñthat of americanadults who are functionally illiterate.the adult illiteracy problemthe development of a technologically literate work force is a nationalimperative for the united states in the face of increasing internationalcompetition. major federal initiatives such as the schooltowork opportunities program and the advanced technology education program havebeen created to address this critical need. however, these efforts will beseverely hampered if the countryõs massive adult illiteracy problem is notsolved. in confronting our formidable economic challenges we need torecognize that the most central and essential prerequisite for virtually alltypes of new jobs is functional literacyñthe ability to read and comprehend text and to use various forms of word processing and other communications software.workplace literacy surveys indicate that over 90 percent of currentoccupations require reading. a recent study by the u.s. department oflabor and the american society of training and development foundthat, on average, workers spend more than 1.5 hours each day readingsuch materials as forms, charts, manuals, electronic display screens, andgeneral literature. further, these requirements are increasing: only 4percent of new jobs can be filled by people with the lowest levels ofliteracy, as compared with 9 percent of existing jobs. according to thestudy, even the onethird of american workers who perform productionand service delivery will need to read at an eighthgrade level. the remaining twothirds will need to read at postsecondary and higher levels.levels of literacy that were once acceptable will be marginal by the year2000.however, the stark reality is that the number of adults in the u.s.population with unacceptable levels of literacy is enormous. already,more than one out of five adult americans are functionally illiterate, andtheir ranks are swelling by about 2.3 million persons each year. nearly 40percent of minority youth and 30 percent of semiskilled and unskilledworkers are illiterate. illiteracy costs the united states over $225 billionannually in corporate retraining, lost competitiveness, and industrial accidents. the implication is clear: our goal of providing a modern competitive work force hinges very directly on our ability to achieve a massive improvement in adult functional literacy during the next decade.this cannot be accomplished through the use of human teaching alone.there simply are not enough reading instructors. their teaching must beaugmented by the creation and widespread application of an effectivetechnology for automating literacy tutoring.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.400more than screen deepalthough for a small fraction of illiterates the ability to read is impeded because of neurological problems, and for others there are learningdifficulties that are not associated with sensory or motor problems, theprimary cause of illiteracy among americans is a failure to learn to read.learning to read requires time and practice. research indicates that oncethe basics of learning to read are in place, a gradelevel gain in readingability takes approximately 100 hours of engaged literacy training time.further, at beginning levels of reading, individual feedback, motivation,and guidance are critical. for most adult illiterates a major obstacle toeffective reading development lies in two simple factsñthe human resources do not exist to provide the teaching support that is needed, andthere is no way to adequately increase their number to provide suchsupport during the next several years. a sufficient force of trained professionals and paraprofessionals at the level of expertise required cannot bedeveloped, even with a massive injection of funding. the only option isthe effective introduction of appropriate technology.research project on adult illiteracymy thesis is that one technology in particularñcomputerbasedspeech recognitionñprovides the central and essential capability requiredfor launching a significant attack on a major segment of the adult illiteracy problem. the reason for this view is straightforward. many adultswho have serious reading difficulties can speak english intelligibly, evenwhen their speech is in a dialect other than standard u.s. dialects. we atbbn plan to begin from their strengthñtheir ability to speak english.they know how easy it is to talk and how hard it is for them to read. theydo not know that their own speech can be transformed into text, that thereis a direct, albeit complex, correspondence between the two forms oflanguage. even though they cannot initially read the text that is produced, they know that it is their own, that they created it from their ownspeech. so in a very real sense they know what the text òsays.ó further,they can repeat the utterance, either in its entirety or partially, a word orphrase at a time. in doing so, they begin to get a handle on the translationproblem through a procedure they substantially control, in ways and atrates they find comfortable.the starting point in this instructional strategy is to have the computer generate a speech utterance. the trainee is then asked to repeat theutterance, to òsay the same thing.ó the speech recognition system printsthe correct text corresponding to the utterance, but it remembers thetraineeõs articulations of the constituent words and phrases, includingthose not spoken in standard english. so the system develops a knowledge of the traineeõs idiosyncratic pronunciations and the text of the wordsmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups401and phrases to which they correspond. this information will be used togenerate the correct english text in activities where the trainee takes theinitiative in generating the utterances.this training strategy is distinctly different from traditional approaches based on giving trainees a reading task from the start. instead,reading skills are developed in a more natural and gradual way fromspeaking and listening skills that, to begin with, are a great deal stronger.the transition from the scaffolding of speechdriven pattern matching totextdriven decoding and interpretation is not simple, but the confidenceinspired in the trainee by being able to begin to make sense of text shouldsubstantially help in confronting and bridging this gap. in later phases ofthe training, students will be engaged more in practice activities to extendtheir vocabulary and to apply reading in contexts of use through taskoriented activities. the training sessions will involve the use of workplace literacy materials, including interactive simulations, games, andextended stories, gradually increasing in the level of challenge and complexity. the functional literacy tasks will be based on those defined bythe national adult literacy survey, particularly those in the first threelevels (e.g., interpreting bus or airline schedules; following written andillustrated instructions from a manual or display for such tasks as repairing a paper jam in a copying machine). interactive computer simulationsof such tasks will involve the development of procedural reasoning andproblemsolving skills in addition to reading comprehension skills.this approach requires continuous, realtime, highaccuracy, dialectsensitive speech recognition. with the introduction of such new andpowerful facilities, the development of a literacy trainer incorporatingtwoway interactive speech technology has become feasible. earlierspeech recognition systems were not capable of recognizing with highaccuracy, naturally spoken utterances involving large vocabularies andcomplex grammars. moreover, they were not òspeaker independentó inthat their accuracy for any speaker was highly dependent on whether thesystem was tuned to the speech characteristics of that speaker, through atedious, timeconsuming òtrainingó process. all this has changed withthe introduction of systems such as the bbn hark recognizer. given thevocabulary and grammar associated with a student session, hark canrecognize utterances with a word accuracy of around 95 percent. furthermore, the system can readily be configured to recognize speakers withhaitian, cambodian, hispanic, and other common dialects.this experimental research and development project would be conducted jointly by industry and university researchers. i envisage a 10year program to implement a comprehensive yet inexpensive trainingsystem, demonstrate its instructional capabilities, and evaluate its learning benefits with a representative group of trainees chosen to exemplify amore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.402more than screen deepwide range of literacy problems. a twoyear smallscale pilot to developa prototype system and demonstrate the instructional approach mightconstitute the first stage of the project. it would endeavor to show howspeechmediated literacy training technology can effectively be used tomake major inroads on our national illiteracy problem. speech scientists,instructional researchers, and software developers are keenly interestedin participating in the proposed work. the project would have the longterm goal of substantially reducing the adult illiteracy problem in theunited states and opening the way for fuller participation of all citizens inthe knowledge society.referencesbier, melinda. 1996. personal empowerment in the study of home internet use by lowincome families. world wide web article, http://www.educ.ksu.edu/projects/jrce/v1/bier/article.html.horwitz, paul. 1995. electronic communication, department of education discussion groupon a national technology plan, march 20, kirk winters, moderator. archived ininet.ed.gov under ntplan.national telecommunications and information administration. 1995. falling through thenet: a survey of the òhavenotsó in rural and urban america. washington, d.c.: u.s.department of commerce.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups403electronic access to services forlowincome populationsadam porteruniversity of marylandintroductionmuch of the internetõs popular appeal stems from its potential toprovide a global virtual marketplace for goods and services. alreadyhighprofile projects are under way to develop video on demand, virtualmalls, and massive digital libraries. in addition to these glamorous products, more mundane government services will some day be delivered (inwhole or in part) via the internet. these services might include medicare,welfare and unemployment, immigration, and job placement and training assistance. since many of these services exist to serve lowincomepopulations, it is important to determine whether lowincome users differfrom other internet users and, if so, what implications this has on userinterface design.for the past several years i have been working with a nonprofit groupcalled raising hispanic academic achievement (rhaa). rhaa is located in the washington, d.c., metropolitan area and provides academictutoring and mentoring to several hundred latino children and their parents. over 70 percent of these children come from families whose annualincome is below $20,000 and many receive government services such asthose described above.surveying the user communityi conducted an informal survey of this user community to help understand its characteristics and needs. this is not a scientific sample, andit is clearly incomplete. nevertheless, it provides some insight into issuesto consider when designing interfaces for these types of government services. the survey identified several characteristics that might not be foundin other user communities:¥nonenglish speaking. many respondents are first or secondgeneration americans. consequently, many do not speak english at all orhave limited proficiency.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.404more than screen deep¥limited educational background. many of the respondents have notcompleted high school. moreover, they have had little exposure to computers and computer programming.¥limited literacy. since many of the respondents do not speak english and have limited education, functional illiteracy in english is high.furthermore, 20 percent (estimated) of the parents i surveyed are alsoilliterate in spanish.¥limited access to computers. few of the respondents have computers in their homes. those who do tend to have lowerend machines withlimited storage and printing capabilities. almost all have phone or pagerservice. some of those without home computers have access to theinternet through schools and/or public libraries.considerations for user interface designbased on this survey i have identified several issues and concernsthat should be considered when developing user interfaces. many ofthese, of course, will apply to other communities as well. i have groupedthese issues into three categories: (1) computer literacy, (2) languageliteracy, and (3) limited computer resources.computer literacy¥simple predictable interfaces. users often have to formulate queriesto search large information spaces. frequently, they must write thesequeries using sql or logic programming languages. since many of theseusers have no programming experience, this type of interface leads toerrors and should be avoided when possible. also, interfaces should bepredictable, not changing from use to use, since this can lead to confusion.¥rapid, incremental, and reversible control. users should be encouraged to navigate large information spaces quickly and easily. rather thanprogramming queries, users should be able to visually define queries andthen refine them rather than recomputing from scratch. also, each operation should be reversible.¥training. one research area that should be explored is the development of novice versus expert interfaces. to support novice users better, error recovery and prevention schemes will be important, as willfurther study into architectures for òhelpó systems.language literacy¥direct manipulation. since even experts make frustrating typingmistakes when using textual interfaces, the illiterate will find these intermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups405faces unusable. although direct manipulation interfaces alleviate someof these problems, there is still a strong need for more effective visualpresentation approaches.¥audio support. for people who cannot read or whose language isunwritten (e.g., certain creole languages), audio support may be necessary. in these cases, texttospeech systems may provide lowcost conversion of written content.¥culturally appropriate presentation. different languages are presented and organized differently. they have different accent marks, character sets, and orientations in which words are read and written. (thisproblem also appears in commercial software development where products must be internationalized.) rather than expending scarce resourcesto translate content, reformat output, and redevelop characterprocessingcode, some research should be devoted to lowcost translation systems,flexible software architectures, reconfigurable browsers, and so forth.limited computer resources¥presentation on lowbandwidth devices. many people do not havecomputers in their homes and have limited access elsewhere. as interfacedevelopers we cannot assume that everyone is using netscape. we needto explore methods for lowcost conversion of content for different devices (e.g., phones, beepers). for example, lucent technologies has developed a language that allows html documents to be presented in oneway for a phone and in another way for a standard browser.¥users without fixed internet addresses. lowincome people may havecomputer access only through public channels, such as libraries andschools, rather than at home. notification services that assume a fixed ora forwarding address will be inadequate. some research issues to consider are secure identification mechanisms and flexible locator services.¥longrunning services. providing services may require many steps,with human intervention at several points. therefore, users may need tosuspend longrunning services and resume them later (possibly from adifferent physical location, with different computer resources, user names,etc.). consequently, architectures need to be developed for incrementalinteraction and interfaces that summarize interaction histories.summarythis paper explores the design of user interfaces for systems thatprovide electronic access to government services. since these systemsexist to serve lowincome populations, i conducted an informal survey ofone lowincome population to understand their needs. the survey indimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.406more than screen deepcated that lowincome populations will have many novice computer users, require support for languages other than english, and have limitedaccess to computer resources. since redeveloping content for every usercommunity would be prohibitively expensive, this situation presents awide variety of research challenges. three of the most interesting topicsare (1) visual presentation and searching of large information spaces, (2)lowcost translation and conversion of content, and (3) flexible softwarearchitectures and interaction patterns.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups407access for people with disabilitieslarry goldbergwgbh educational foundationintroductionthe barriers that prevent persons with limited sight, hearing, or mobility from gaining access to the fruits of the emerging national information infrastructure (nii) are not all that different from the barriers thatface all the other millions of americans who have, voluntarily or not,opted out of participation. limited bandwidth, limited technological resources, limited technological facility, limited income, limited time, andlimited interest are the restraints bifurcating our society. this division isselfperpetuating in that without interventions like the promotion of everycitizen interfaces the gap will widen and feed on itself.for people with disabilities, input/output issues are the core concerns. disabled people share with their ablebodied colleagues concernsabout the complexity of systems, training needs, flexible and intelligentinterfaces, and so forth. but without the ability to input commands anddata and receive appropriate output, the rest of the issues are irrelevant.todayõs mediafor the more basic, oneway components of the nii (i.e., television inits broadcast, cable, satellite, videoondemand formats), provision of access to the content flowing over these pipelines continues to be an afterthefact retrofit. that is, upon finalization of programming, closed captions or video descriptions are added. in the case of the former, captiondata are encoded into the vertical blanking interval (vbi) of the televisionsignal and delivered and displayed to the end user via a settop box orbuiltin decoder chip. in the case of the latter, an additional audio track isadded to the master video and delivered to the enduser via an auxiliaryaudio channel (the second audio program) on stereo televisions andvideo cassette recorders.though widely utilized for decades (closed captioning) and years(descriptions), these technologies are by no means 100 percent reliable,owing to both system errors and human errors. research into failsafemore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.408more than screen deepmechanisms for delivery of these data would provide the benefit of consumer confidence and programmer satisfaction.in addition, the distribution plants of the major broadcasters and cablesystem operators often either cannot traffic the extra audio channel forvideo description or will strip those descriptions prior to delivery to thehome. preliminary research into digitization of the auxiliary audio channel and encoding into the vbi (like in the captioning process) has beenconducted with promising but inconclusive results. the added questionrequiring an extra user appliance for decoding vbiencoded audio needsto be examined. research may determine means of adding such capability into todayõs or nextgeneration television systems.production of access services also is time and labor intensive. thoughtrivial in terms of the overall cost of mass media production, budgets foraccess services are carefully scrutinized. this has become an even greaterconcern as the sources of information and entertainment continue to grow.as we approach the ability for every citizen to become a programmer/distributor, the need to facilitate and lower the cost of producing andadding access adjuncts or alternate means of output (text and audio) becomes more dire.potential research in this area needs to focus on the utilization ofspeechtotext and texttospeech technologies. neither has yet been developed to the point of aiding in the production or distribution process ofeither captions or descriptions, but both show tremendous promise. today, most of the burden for providing captioning on live programmingfalls on a extremely small group of highly skilled òstenocaptionersó whocan outgun any speech recognition engine available today.captioning has clearly proven itself to be a service that serves populations far beyond the originally intended audience. early optimistic explorations into the use of captioned television for early and remedialreaders has been followed by exploitation of captioning for students ofenglish as a second language.computer manufacturers are now building caption displays into theiròpersonal computer/televisionsó with the added capability of downloading caption data for archiving and indexing purposes. and researchers inthe field of digital video storage have long been excited about the use ofcaptions as indices for largescale video databases for research, archiving,and production uses.perhaps more trivial but ever more evident, captioned television hasbecome widely used in environments that require an alternative to audiooutput, such as health clubs, bars, libraries, and for latenight televisionwatching.video description uses for additional populations have just begun tobe explored and would certainly benefit from significant research projects.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on selected population groups409preliminary work has begun to determine the potential of description toassist students and adults with learning disabilities, especially attentiondeficit disorder. additional similar benefits may be discovered throughresearch into video descriptionõs impact on information retrieval wheremasses of data and information clutter could be reduced through òdescriptive guides.óembedded description has also been suggested as a potentially usefulway of indexing large visual databases if coupled with intelligent speechrecognition. little or no research has yet been conducted in this area, butthat may point the way to another repurposing of an access technology.new mediain the worlds of nonlinear and digital multimedia, interactive media,and advanced television, many problems remain to be solved. standardsare either evolving or have not yet been considered for incorporation ofcaptioning and description in all of these venues. early efforts at creatingsuch standards ignored the ancillary uses of these technologies and threatened to lock in bad designs.for example, the ability to display text in the emerging dvd (digitalvideo disk or digital versatile disk) format has been designed with language translation as the primary purpose for text display. since the dvdformat has mostly been designed in japan, the text is being createdthrough bitmapped graphics files, not ascii text as in broadcast closedcaptioning. this has resulted in many unforeseen design flaws: the inability of a dvd player to address the closedcaptioning circuitry in television sets, the inability to flexibly change fonts or type sizes, and theinability to use the text as a search engine.these decisions are made as new media products rush to market,with little attention paid to the bestpossible design for the builtin accessservices and how they can be configured for universal applicability. similar concerns are being directed toward the designs of the alternate audiofeatures of advanced television and dvd.as great a concern has been expressed about the òappliancesó peoplewill be using to access the internet or other digital information and entertainment systems. with personal computers the ability to add software orhardware to assist those with special needs is relatively straightforward(though not without significant programming and development efforts).but if every citizen will be accessing the new services via òthin clients,ósmart phones, settop boxes, or lowend, lowcost browsing boxes attached to television sets, the ability to add such services as speech synthesis or output to refreshable braille or largeprint displays is problematic.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.410more than screen deepwhen digital sound files are sent over the internet and received via theseboxes, how will the boxes turn the sound into text for deaf people?research into the ability to incorporate these alternate output modesinto inexpensive information appliances can result in more accessible lowend browsers for every citizen, including blind and deaf people. incorporation of new access standards into digital media formats (such asquicktime, active video, and realaudio) will facilitate the ability oflowend browsers to display incorporated access technologies. all ofthese research challenges can be addressed in the short term (one to fiveyears), except perhaps for the need for a fully capable speech recognitiontechnology, which, after 20 or more years of effort, still requires manyyears to approach the speed, accuracy, and other capabilities needed foruse by deaf people.it has been the experience of those in the world of media access thatthese design and research challenges are not complex (certainly not ascomplex as the creation of the new media themselves). when focusedattention and resources are applied to the problems, solutions are readilydiscovered, especially when approached by consortia of public and private practitioners and researchers. early awareness and designfromtheblueprintstage thinking obviate the need for expensive and inefficientretrofits that are resisted by producers and consumers alike.suggested uniform resource locatorshttp://www.wgbh.org/captionhttp://www.wgbh.org/dvshttp://www.wgbh.org/ncamhttp://trace.wisc.edumore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes411411position paperson key processescrossdisciplinary, socialcontext researchjohn leslie kinguniversity of california, irvinea key challenge in developing an everycitizen interface to the nationalinformation infrastructure is in recognizing the ongoing evolution in ourconcepts of what the òinterfaceó encompasses. the development of concern over interface issues in the past 30 years reflects the complexities ofthese issues and provides some direction for improving these interfaces.backgroundthe term interface in the computing field has been appropriated by arelatively narrow community of interest, namely those interested in humanmachine interactions at the ergonomic and perceptual level. most ofthis study, which goes under the name of humancomputer interaction(hci or chi) is strictly limited to studies of individual human actorsinteracting with specific packages of hardware and software. this focusof work has been very successful, producing among other things the innovations of òpointingó aids such as the mouse, trackball, touchscreen, anddigital pad, as well as the graphical screen interface ubiquitous in allmodern operating systems. these advancements have their intellectualmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.412more than screen deeproots in fairly circumscribed zones of disciplinary concern, namely cognitive psychology and human factors engineering. in essence the focus ofthis line of work is on the human working with a computerbased system.in the past several years the hci focus has broadened somewhat toinclude small groups of individuals each working with a computerbasedsystem but for the purpose of working collaboratively with other members of the group. this is a significantly different conceptual focus, withindividuals working through the computer to interact with other individuals. prominent developments in this domain have been technologiesfor computermediated communication, ògroupware,ó and computersupported cooperative work. the intellectual roots of this work go beyond cognitive psychology into other realms of the social sciences, especially social psychology, but also into anthropology, organizationalpsychology and sociology, and economics. the applications of these technologies have caught the attention of scholars interested in fundamentalquestions of human discourse, social network construction and maintenance, identity and personality formation and expression, and the socialconstruction of meaning and reality. these rapidly growing areas ofinterest have been stimulated by the stunning speed with which majorcomponents of the national information infrastructure such as the internetand the world wide web have invaded social life in all dimensions.these developments illustrate the evolving capacity of computerbased systems to affect basic human activities and reflect the fact that theconcept of òinterfaceó between humans and information technology is anelastic concept that expands to deal with the new opportunities and problems presented by technological change. three observations can be madefrom this evolving concern with interface.1.the parochial concerns of any particular group that engages interface issues at any given moment tend to appropriate and dominate theevolving meaning of interfacerelated research. the routine disciplinarypolitics of research institutions affect researchers in the interface field.interface research was for many years (and to a considerable degree stillis) politically marginalized within the field of academic computer science.even within the interface field, some researchers whose work is fundamentally grounded in psychology feel themselves to be marginalized bythose whose work is based on traditions of engineering in which psychology plays little part. the lesson here is that the dominant definitions ofwhat constitutes the òrealó issues in interface research and what constitutes the òrightó approaches to doing such research are very misleading.it is necessary to look beyond these politically constructed definitions ofwhat ought to be done and focus on the broader challenges of what emerging applications will require.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes4132.the trend in conceptual evolution of interface concerns is generally òupwardó in the layers of social focus, from the individual to smallgroup, to organizational, sectoral, institutional, and cultural. to the extent that being human involves essential attributes of group identity, organization of production and consumption, formation and sustainmentof social order and culture, and so on, these too require attention in interface research. this notion is captured well in recent use of the termusability to describe research aimed at developing information technologies that actually accomplish what those who use them desire. this focushas clearly emerged in the computersupported cooperative work (cscw)research community and has appeared as well in discussions of organizational usability and even institutional usability of information technologies. it is certain that a concern about everycitizen interfaces to thenational information infrastructure must embody such perspectives.while it is true that at some level all interface issues can be traced torudimentary humancomputer interface concerns as represented by theparochial hci community, these broader issues of usability involve concerns that have nothing at all to do with the narrow hci focus and mustbe addressed by research methods that traditional hci researchers wouldnever consider.3.although the concern with interface issues is usually tied to theevolving hci, cscw, and other perspectives, important aspects of research into group, organizational, and institutional usability have beenunder way for many years. although largely ignored by the computerscience research community, the vast range of economically vital computing applications in organizational information processing have drawnmuch attention from researchers in management information systems,library and information science, medical informatics, and other fields.transactionprocessing systems, which remain among the largest andmost complex computerized information systems, were made possibleonly by careful study and learningbydoing design to meet interfaceneeds at the individual, work group, organizational, and institutionallevels. to pick just one case in point, designers of the airline reservationssystem, which literally revolutionized air travel, had to overcome numerous complicated problems at all social levels, including being modified tocomply with courtordered remedies against unfair competitive practices.similar stories can be told regarding credit datareporting systems, financial accounting and reporting systems, personnel management systems,computerintegrated manufacturing systems, and so on. the lesson hereis that a great deal of useful information on the development of effectiveinterfaces at the higher social levels is available in the applicationsoriented research communities.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.414more than screen deepresearch needsthe point of the discussion above is not to argue against further investment in the wellestablished traditions of research in computer science, hci, and so on. such investments have yielded great payoffs andwill continue to do so in the future. instead, the point is to place in theforeground the need for focused research on the òhigherleveló issues ofinterface development at the group organization, sectoral, institutional,social, and cultural levels. moreover, these are not merely desirable venues for research investment, but rather are as essential to the goal of aneverycitizen interface as wellestablished domains of federally supportedresearch. unfortunately, such research has been comparatively underfunded. there are numerous advocates of more traditional research needsto articulate requirements for such research. i will focus on the needs ofthe higherlevel challenges.the primary goal of research into the higherlevel challenges of interface design is to reduce the cost and increase the speed of effective design.a great many extraordinary information technologies have been developed that demonstrate the virtues of good interfaces and that are highlyusable in routine production. but the cost of developing them has beenquite high because most of the systems have been built on the ruins ofexpensive failed efforts. it has been estimated that as many as half oflarge information systems projects fail to meet their objectives, and asignificant fraction of those fail altogether. many examples can be drawnfrom publicsector projects such as the disastrous world wide militarycommand and control system (more than $5 billion), the federal aviation administrationõs advanced technology program to replace the agingair traffic control system (more than $2 billion), and californiaõs writeoffof its ambitious overhaul of motor vehicle information systems (a mere$55 million). similar failures abound in the private sector, but they aremore easily hidden from view. the american airlines effort to replicateits marvelous success in airline reservations systems in the french national railways and in its encompass freight management system come tomind as just two examples. research into higherlevel challenges is aimedat learning what works and what does not and putting that knowledge towork.the following constitute important areas of needed research investment at the higher level:¥synthetic studies that pull together the extensive social learning alreadyaccumulated through important development projects. most largescale systemdevelopment efforts occur in operational settings, not research laboratories.research on such systems must be done in vivo, in the living systems.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes415there are significant problems with doing such research that need to beacknowledged. among others, such research usually presents researcherswith difficulties in gaining access to the right study sites, reluctance oforganizations to reveal their failures due to fear of embarrassment, reluctance to reveal details of successes for competitive reasons, and the highcost of travel and time on site. but these are really no more troublesomethan the challenges faced by numerous other research communities thatmust go to the field for their data collection. the synthetic research suggested here must be theoretically driven, but ultimately it is empirical innature and akin to research traditions in engineering and management.the questions are: what works? what doesnõt work? and why?¥analytical studies of the likely evolutionary pathways of complexsociotechnical systems over time. it is increasingly recognized that information technologies do not merely allow efficiency and effectiveness improvements in wellestablished activities. much more importantly, theyenable fundamental changes in the nature of the activities themselves.the whole òreengineeringó movement, which was articulated by peoplefrom organizational information systems backgrounds, is predicated onthe argument that fundamental changes in what is to be done are required, displacing the traditional focus on how things are to be done.much of the learning about what will òreallyó happen is inevitably goingto be empiricalñwe will watch and see. but advances in conceptual toolssuch as game theory have made possible much more sophisticated modeling of possible interactions among actors under different assumptions,including enablement from new information technologies. such studiesseldom provide real predictive power in the sense that they can tell designers or decision makers exactly what to do. but they have been applied with great success in narrowing the search space around the likelyoutcomes under different assumptionsña contribution that can greatlyimprove the efficiency in design of complex systems that must be builtthrough learning by doing processes such as prototyping. significantincreases in investment in such research are needed.¥collaborative research and development projects that allow different development strategies to be tested in real settings. there are numerous recommended strategies for improving the design of complex sociotechnicalsystems. many of these have evolved from the traditions of system design and software engineering and range from structured analysis anddesign techniques to participatory design. unfortunately, our understanding of the efficacy of these approaches amounts to little more thanfolklore. there have been few systematic studies to demonstrate the utility of these approaches in real development situations and the contingencies under which the different approaches offer advantages. moreover,more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.416more than screen deepthis lack of systematic study makes it difficult to identify holes in existingknowledge and theory that require further research attention.these kinds of studies require multidisciplinary research approaches,involving specialists from information and computer sciences, management, and the social sciences. in many cases, particularly where applications are in expert domains (e.g., medicine), subject matter specialists willbe needed as well.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes417audio access to the national informationinfrastructurejohn c. thomasnynex science and technologygoalsthere are tradeoffs among the goals given below and the costs. whileeach is a desirable direction, any of these goals, if pushed to an extreme,could render other goals impossible.¥universality. every citizen should have some way of gaining accessto information that has been made public. in some cases this may requirespecial devices, language help, training, or economic assistance.¥privacy. individuals should have the ability to create, store, andmodify information and restrict the access others have to that information. information created about individuals by others should also berestricted in ways that the individual has some power over. at a minimum, individuals should know who has what information about themand should know when new information is being collected.¥security. information should be safe from unauthorized destruction, alteration, or copying.¥usability. information should be presented in a form that is maximally useful. this depends on the person, the task, the context, and theiraccess to the system.¥empowerment. the individual should be free to determine how,when, and where he or she access information. for example, some peoplemay prefer, for certain tasks, a very òactiveó system in which agents makefrequent suggestions. others may prefer a more passive system.¥responsibility. economic or other incentives should be in place sothat limited resources (bandwidth, storage capacity, computer power, creative human power that produces new information) are not simplyòtakenó for free by whoever gets there first. there should also be someincentive for those who create information to keep on creating.¥translatability. information entered in one medium should be capable of being translated into another medium. not only should documents be easily translatable into another machineõs format, but faxesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.418more than screen deepshould be translatable into ascii, spoken words into ascii, and, ultimately, even pictures and video should be somewhat describable as text.¥ubiquity. people should have access from anywhere to information (perhaps at a premium). they should not have to physically movevery far to gain this access.research approachin 13 years at ibm i saw many excellent results (in humancomputerinteraction and effective software development process) of research in ourlabs; other labs and universities have a minuscule impact on what wasactually done at ibm. in starting the artificial intelligence laboratory atnynex, i led each group to have a longterm vision of where to push thetechnology but to choose a portfolio of short and mediumterm projectsthat pushed toward that vision but also provided a real benefit for nynex.this was not motivated primarily by a desire to stay fundedñthough thatwas a consideration tooñbut because i believe it is far too easy to òpartialoutó the really difficult issues of artificial intelligence (ai) if one works onòtoy systems.ó i do not believe there are òfrictionless planesó when itcomes to human psychology or building complex systems. only throughapplied work is real progress made.the ultimate goal of speech synthesis, for example, might be to readtext as a good human actor might. however, a little reflection will showthis (and all other similar problems!) to be coextensive with the ògeneralaió problem. while this is a worthy vision, a mundane step we took in thisdirection was to work on a better synthesizer for names and addresses,focusing on improving the prosody. here the approach of the main investigators (kim silverman and ashok kalymanswamy) was not to òproveóthat a particular approach to prosody was the òrightó one but to use everything that worked and to do their own original research when they hitunsolved problems.none of this philosophy should be taken as meaning that there is noplace for theory or no place for university research. we have had a numberof good collaborations with universities, including mit and the universityof colorado, where we work on real problems for a while and then spendtime theorizing. but the theorizing is based on experiences with real problems, and the theory is then applied to the next real problem.i also believe that working on complex, realworld problems requiresthe cooperation, and perhaps the friendly competition, of numerous research groups. the speech community has shown remarkable progressworking together through the defense advanced research projects agencyin collecting and sharing data, trying various approaches, and publishingresults. the dawning commercial success of this technology is a furthermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes419driver toward progress. i believe, therefore, that the way to develop theresearch agenda for issues about providing an everycitizen interface tothe national information infrastructure is to start doing it. as we run intoproblems, we should use those problems to define the research agenda.research issuesi propose that we develop an audio access to the internet. such asystem would allow anyone access to the internet over an ordinary potstelephone line by using spoken commands. quite obviously, this wouldnot provide the identical experience that sitting in front of a keyboard (foran experienced typist) and a huge fullcolor monitor might. nonetheless,such a system will have several major practical benefits and would serveas a focal point for pushing some important technologies.first, the penetration of personal computers into the lowest socioeconomic status quartile is low and staying low. this would allow peoplewithout the financial resources immediate access to the internet. it wouldalso allow people who are reluctant to buy a computer because they donõtsee the value of internet access (or other computer applications) to òtry outóinternet access without a significant upfront investment. individuals coulduse such access to listen to speeches of political candidates on particularissues, find out about their benefits and bills, find out about communityevents and safety messages, find transportation schedules, get sports results, and so on. some of this information currently does exist in variousaudio forms, but typically it is not updated very frequently, and users mustdial a different number for each type of information.second, there are families and work groups where most of the grouphas internet access but a few do not. an audio access to the internet wouldallow such a group or family to communicate much more effectively.third, even people who do have computer access to the internet findthemselves in situations (e.g., in their cars, at payphones, at hotels withoutmodems) where they do not have computer access but could use a phone tofind important financial and trip information, listen to their email, etc.fourth, audio input/output is already becoming an important enhancing medium for the internet. welsh lessons that include audio areavailable from brown university. one can listen to music, peopleõs voices,and sounds. ideally, one might well navigate more easily through voicecommands. in addition, speaker verification could add another level ofsecurity to internet transactions.fifth, there are people with special needs (blind or paralyzed users)for whom audio access to the internet would be crucial. in addition tothese special needs, there is a huge population of people in the unitedmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.420more than screen deepstates who can speak and listen to english but cannot read or write it. ina stroke, such an interface would help enfranchise and educate them.in addition to providing practical benefits, a workable audio access tothe internet will force us to improve several important technologies.¥speech recognition. while some access to the internet could beginimmediately, access could be improved via larger, speakerindependentvocabulary. another improvement could be made if the system òadaptedóonline to the dialect and vocal tract configuration of individual speakers.performance in some conditions will also be enhanced by better noisecancellation techniques.¥speech synthesis. while current levels of intelligibility would beuseful, certainly further enhancements can and should be made in theareas of aesthetic appeal, proper name and special symbol pronunciation,and prosody. in some cases, the internet may provide additional clues forthe synthesizer. for instance, in email, the name and subject fields givepotential clues about how the contents should be pronounced. hypertext markup language (html) tags in web sites may give additionalstructural information about pauses and emphasis.¥picture and video understanding. to provide some (not complete)audio information about pictures, graphics, and videos available on theinternet, an automatic scene describer would provide a cheaper solutionthan having human beings try to keep up with the exploding informationby describing each scene. by having html tags and verbal materials toprovide some structure and context, the task for machine scene understanding could be made more tractable, but there are still unsolved research issues here. the solutions would have other applications as well,including digital movie making and editing and security.¥natural language processing. much of the information on theinternet is in the form of text. being able to do a better job of indexing,summarizing, and locating text would drive better natural language processing. again, the html tags of web sites provide a potential additional source for natural language understanding systems.¥user interface design. how should a dialogue over the phone bestructured? under what conditions should it be all speech and whenshould dtmf also be used? when is explicit confirmation needed? howcan speech/audio be used as an adjunct to screenbased systems?¥system integration. perhaps a mobile phone user would like tobrowse for certain kinds of information and bookmark web pages forlater perusal on a screen. how can the various networks beinternetworked?¥speaker verification. perhaps the user could be presented with aphrase to repeat in his or her own voice. this could be used to helpmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.on key processes421authenticate transactions. clearly, better verification techniques wouldhelp make the system more secure and user friendly.¥media translation. speech recognition and synthesis are specialcases, but it would also be nice to be able to translate a fax document intoan email document that could then be read over the phone. in general,information should be capable of being input in any medium and outputin any other medium. while the (typed) fax to email issue is nearlysolved, handwriting still provides a challenge. we still do not see systemsadapting to handwriting as well as humans do.¥adaptive recognition. the human being seems to be very good atòspeakerindependentó speech recognition. yet a selection made by òpasting togetheró words from a random speaker seems very difficult for ahuman to understand compared to one from any single speaker. todayõsspeech recognition systems donõt seem to care. apparently, humans aredoing something in the way of rapid speaker adaptation that we do notunderstand well enough to incorporate into a machine. similarly, we arequite good at òadaptingó to a particular individualõs handwriting. again,we donõt know how to program a computer to do this very well. similarly, if we view a graph, photo, or movie on a particular device in aparticular lighting context, we make a fairly quick adaptation to the styleand other aspects of context. and, again, we donõt know how to do thisvery well in a machine. i believe a key to significant improvement in anumber of the technologies listed here is a better understanding of howhumans do adaptive recognition. rather than studying it in a toy domain, however, i believe we should observe and test how people do thisin a real context doing a real task.¥intelligent searching. todayõs search engines on the internet are notvery precise. they typically return very many falsepositives. audio input/output with natural language processing gives the possibility of moreselective searches and also provides strong motivation since audio scanning is more onerous than visual scanning. one potential source of information is to use the userõs current task and past history to help focus asearch. such an approach forces us to examine privacy and security issues.all of these technologies could be explored in their own right, but ithink that exploring them in the context of trying to provide a realworldsystem will produce the best research results as well as a practical benefit.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.executive summary423appendixesmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.appendix a425425aworkshop agenda andparticipantsagendawednesday, august 21, 19966:007:30 p.m.welcoming receptionthursday, august 227:308:30 a.m.continental breakfast8:308:45workshop introduction and objectivesalan biermann, steering committee chair8:4510:15people and functions: uses of information infrastructure and implications for interfacesmoderator: tora biksonpanel: larry goldberg, sara kiesler, john king, robertkraut, bruce tognazzini10:1510:30break10:30nooncommunication and collaborationmoderator: barbara groszpanel: austin henderson, gary olson, candace sidner,lee sproull, loren terveennoon1:15 p.m.lunchmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.426more than screen deep1:152:45information dimensionsmoderator: bruce tognazzinipanel: susan hockey, mark weiser, moshe zloof2:453:00break3:005:00inputoutput methods and paradigmsmoderator: gregg vanderheidenpanel: ron cole, thomas defanti, john makhoul, alannewell, daniel siewiorek, andries van dam, stephenweinstein5:005:15 p.m.day 1 wrapup: comments from invited observersand instructions for day 2alan biermann5:156:15reception and demonstrations6:157:30dinnerfriday, august 237:308:30 a.m.continental breakfast8:3010:15parallel sessionsparallel session a1: agents and system intelligencemoderator: alan biermannpanel: steven feiner, craig knoblock, mark maybury,johanna moore, katia sycara, kent wittenburgparallel session a2: design and evaluationmoderator: thomas landauerpanel: sara czaja, dennis egan, alan newell, johnthomas, robert virzi10:1510:30break10:30noonparallel sessions: application dimensionsparallel session b1: lifelong learningmoderator: gerhard fischerpanel: charles cleary, wallace feurzeig, john richards,elliot soloway, john thomasparallel session b2: work and home lifemoderators: john makhoul and stephen weinsteinpanel: louis hecht, stephen kent, sara kiesler, robertkraut, mark laubach, adam portermore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.appendix a427parallel session b3: public interest and health caremoderators: tora bikson and bruce tognazzinipanel: patricia brennan, david crocker, sara czaja, johnking, aki namioka, lee sproull, michael traynornoon1:15 p.m.lunch1:152:15parallel sessions concludedcomplete reports for presentation in plenary session2:152:30break2:303:00parallel session presentations3:005:00synthesisñsetting the research agendamoderator: alan biermannpanel: steering committee5:00adjournparticipantsalan biermann, chair, duke universitytora bikson, rand corporationpatricia brennan, case western reserve universitycharles cleary, learning sciences corporationron cole, oregon graduate institutedavid h. crocker, brandenburg consultingsara czaja, university of miamithomas defanti, university of illinois at chicagodennis egan, bellcoresteven k. feiner, columbia universitywallace feurzeig, bbn corporationgerhard fischer, university of coloradolarry goldberg, national center for accessible mediawgbh educational foundation, corporation for public broadcastingbarbara grosz, harvard universitylouis hecht, open gis consortium inc.austin henderson, apple computersusan hockey, university of alberta (affiliation at time of workshop:center for electronic texts in the humanities, rutgers university andprinceton university)stephen t. kent, bbn corporationsara kiesler, carnegie mellon universityjohn l. king, university of california, irvinecraig knoblock, university of southern californiarobert e. kraut, carnegie mellon universitymore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.428more than screen deepthomas landauer, university of coloradomark laubach, com21 inc.john makhoul, bbn corporationmark t. maybury, mitre corporationjohanna moore, university of pittsburghaki namioka, computer professionals for social responsibilityalan newell, university of dundeegary olson, university of michiganadam porter, university of marylandjohn richards, turner educational services inc.candace sidner, lotus development corporationdaniel siewiorek, carnegie mellon universityelliot soloway, university of michiganlee s. sproull, boston universitykatia sycara, carnegie mellon universityloren terveen, at&t research laboratoriesjohn thomas, nynex science and technologybruce tognazzini, healtheon corporationmichael traynor, cooley godward llpandries van dam, brown universitygregg vanderheiden, university of wisconsinrobert virzi, gte laboratoriesstephen weinstein, nec america inc.mark weiser, xerox palo alto research centerkent wittenburg, bellcoremoshe zloof, hewlett packard laboratoriesinvited observerssusan a. brummel, general services administrationy.t. chien, national science foundationdinah f.b. cohen, department of defense, computer/electronicaccommodations programeileen collins, national science foundationhelen gigley, office of naval researchthomas kalil, national economic councilmichael r. nelson, office of science and technology policygary w. strong, national science foundationmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.appendix b429429bsteering committee membersõbiographiesalan w. biermann is a professor of computer science at duke university.his research is in the areas of automatic programming and naturallanguage processing. in recent years, he has developed, with the helpof colleagues and students, a series of voiceinteractive dialogue systems for office applications, equipment repair, and tutoring.he has coedited two books on automatic programming and isauthor of great ideas in computer science: a gentle introduction, themit press, 1990 (second edition, 1997). he is on the editorial boardsof the journal of symbolic computation and the international journal ofspeech technology. biermann received the bee and ms degrees fromthe ohio state university in 1961 and a ph. d. from the university ofcalifornia, berkeley in 1968, all in electrical engineering and computer science. he is a member of the institute for electrical and electronic engineers, the association for computing machinery, theamerican association for artificial intelligence (aaai), and the association for computational linguistics (acl). he is a fellow of theaaai and past president of the acl.tora bikson is a senior scientist in rand corporationõs behavioral sciences department. she received b.a., m.a., and ph.d. (1969) degreesin philosophy from the university of missouri at columbia and m.a.and ph.d. (1974) degrees in psychology from the university of calimore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.430more than screen deepfornia at los angeles. since 1980, dr. biksonõs research has investigated properties of advanced information technologies in varied usercontexts, addressing such issues as what factors affect the successfulincorporation of innovative tools into ongoing activities; how thesenew work media influence group structures and interaction processes; what impact they have on task and social outcomes as wellas user satisfaction; and what individuals and organizations needto know to use them effectively. she has pursued these questionsas principal investigator for projects funded by nsf, the office oftechnology assessment, and the john and mary r. markle foundation. her work emphasizes field research design, intensive casestudies, and largescale crosssectional studies addressed to the use ofcomputer based tools in organizational settings. dr. bikson is a memberof data for development (a united nationsõ secretariat providingscientific guidance on the use of information systems in developingcountries) and a technical consultant to the u.n. advisory commission on the coordination of information systems. she is a frequentreviewer for professional papers and has authored a number of journal articles, book chapters, and research reports on the implementation of new interactive media. she is a member of the aaas, acm,apa (fellow), computer professionals for social responsibility, andthe society for the psychological study of social issues. dr. biksonrecently served on the nrcõs cstb committee to study the impact ofinformation technology on the performance of service activities.thomas a. defanti, ph.d., is director of the electronic visualizationlaboratory (evl), a professor in the department of electrical engineering and computer science, and director of the software technologies research center at the university of illinois at chicago (uic).he is also the associate director for virtual environments at the national center for supercomputing applications (ncsa) at the university of illinois at urbanachampaign.defanti is an internationally recognized expert in computer graphics. in the 24 years he has been at uic, defanti has amassed a number of credits, including: use of his graphics language and equipmentfor the computer animation produced for the first star wars movie;early involvement in video game technology long before video gamesbecame popular; contributor and coeditor of the 1987 nsfsponsoredreport visualization in scientific computing; recipient of the 1988 acmoutstanding contribution award; an appointment in 1989 to the illinois governorõs science advisory board; and, his appointment as auniversity scholar for 19891992. defanti is also a fellow of theassociation of computing machinery. he serves on the technicalmore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.appendix b431advisory board of the internet ii and is a coprincipal investigator ofthe national computational science alliance.gerhard fischer is director for the center for lifelong learning anddesign (l3d) at the university of colorado at boulder. he is also aprofessor in the computer science department and a member of theinstitute of cognitive science at the university of colorado. dr.fischerõs research interests are human computer communication, artificial intelligence, and education and computers, design, cognitivescience, and software engineering. he is a member of the associationfor computing machinery, american association for artificial intelligence, cognitive science, gesellschaft fr informatik, institute ofelectrical and electronics engineers, and computer professionals forsocial responsibility. dr. fischer has written extensively in his field.he received his m.a. in mathematics from the university of heidelberg, germany, his ph.d. in computer science from the university ofhamburg, germany, and a degree in habilitation in computer scienceat the university of stuttgart, germany.barbara j. grosz is gordon mckay professor of computer science in thedivision of engineering and applied sciences at harvard university.she has written several seminal papers in discourse processing, anddeveloped the discourse component of a number of natural languageprocessing systems. she is widely regarded as having established theresearch field of computational modeling of discourse. a fellow ofthe american association for the advancement of science and theamerican association for artificial intelligence (aaai), she is pastpresident of the aaai, was chair of ijcai91, and is a member andformer chair of the board of trustees of the international joint conferences on artificial intelligence, incorporated. her current researchencompasses four problem areas: computational theories of discourseand discourse processing, computational models of collaborativeplanning, investigations of the interactions between intonation anddiscourse, and techniques for combining natural language and graphics. before joining the faculty at harvard, she was director of thenatural language program at sri international, and cofounder ofthe center for the study of language and information. professorgrosz received an a.b. in mathematics from cornell university and aph.d. in computer science from the university of california, berkeley.thomas landauer is a professor of psychology and fellow of the instituteof cognitive science at the university of colorado. he received hismore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.432more than screen deepb.a. in anthropology in 1954 from the university of colorado, hism.a. in anthroplogy and psychology in 1958, and his ph.d. in socialpsychology in 1960. his work includes basic and applied research,prototype building and testing, exploratory development, and designmethodology studies on a variety of topics, including (1) electronic text delivery systems (hypertext, digital libraries, multimedia),(2) simplified email for residential use, (2) advanced informationretrieval methods, e.g., latent semantic indexing (lsi), fisheye views,and unlimited aliasing, (3) methods for evaluating and improvinguser interfaces, e.g., heuristic evaluation, (4) empirical and theoreticalstudies of interface design issues, e.g., command names and menuorganization, and (5) a wide variety of other topics, including cryptographic time stamping for digital documents, neural nets for speechrecognition, and computerenhanced communication sytems (muds).he was awarded a fellowship with the aaas and the american psychological association (apa) (experimental psychology and engineering psychology) and is a charter member of the american psychological society (aps). dr. landauer has two patents, one pending,on software design for text and multimedia information retrieval using latent semantic indexing.john makhoul received his b.s. degree in electrical engineering from theamerican university of beirut in 1964, his m.s. degree in electricalengineering from the ohio state university in 1965, and his ph.d.degree in electrical engineering from mit in 1970. dr. makhoul ischief scientist for speech and signal processing at bbn corporation,cambridge, massachusetts, and a research affiliate with the speechcommunication laboratory at mit. dr. makhoul conducts researchin speech analysis, synthesis, and compression, speech enhancement,automatic speech recognition, neural networks, and digital signal processing, including linear prediction, spectral modeling, lattice structures, and adaptive filtering. dr. makhoul is a fellow of the ieee andof the acoustical society of america.bruce tognazzini, a leading authority on software design, has been designing humanmachine interfaces for more than 35 years. at apple,he headed up both the apple ii and macintosh human interface efforts. at sunsoft, as distinguished engineer in the office of strategictechnology, he led the starfire project, outlining the future of computing. he is currently chief designer at healtheon, a new startupdevoted to moving the medical industry onto the internet. òtogó haswritten dozens of papers, articles, and columns, is a contributing author of three books on human interface design, and is the sole authormore than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.appendix b433of two books, tog on interface and tog on software design, both fromaddisonwesley.gregg vanderheiden is a professor in the human factors division of thedepartment of industrial engineering at the university of wisconsin,madison. he is also director of trace research and developmentcenter at the waisman center at the university of wisconsin. hereceived his b.s. in electrical engineering (1972), m.s. in biomedicalengineering (1974), and ph.d. in technology in communication, rehabilitation, and child development, all from the university of wisconsin, madison. he is the principal investigator on more than 140 grantsand projects in the area of rehabilitation engineering, access to national and nextgeneration information systems, computer access systems, and augmentative communication and writing for children andadults with disabilities. his activities include research, development,commercial facilitation, information summary, and training (preservice and inservice). dr. vanderheiden has worked with industrieson topics in a wide range of areas relating to more flexible interfacedesign, disability access, and nomadicity. interface extensions fromdr. vanderheidenõs work are included in most all of the major operating systems today, including macos, windows 95, windows nt,os/2, and unix/xwindows.stephen weinstein is employed at nec america, incorporated. prior tothat, he was a member of the multimedia communications researchdivision at bell communications research. his research concentrations are network communication of data, modems, and informationtransfer and retrieval. he is a fellow of ieee and received the centennial medal from ieee in 1984. dr. weinstein received his s.b. in 1960from mit, his m.s. in 1962 from the university of michigan, and aph.d. in 1966 in electrical engineering from the university of california.more than screen deep: toward everycitizen interfaces to the nation's information infrastructurecopyright national academy of sciences. all rights reserved.