detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/10193embedded, everywhere: a research agenda for networkedsystems of embedded computers236 pages | 6 x 9 | paperbackisbn 9780309075688 | doi 10.17226/10193committee on networked systems of embedded computers, national research councilembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywherea research agenda fornetworked systems of embedded computerscommittee on networked systems of embedded computerscomputer science and telecommunications boarddivision on engineering and physical sciencesnational research councilnational academy presswashington, d.c.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.notice: the project that is the subject of this report was approved by the governing board of the national research council, whose members are drawn fromthe councils of the national academy of sciences, the national academy of engineering, and the institute of medicine. the members of the committee responsiblefor the report were chosen for their special competences and with regard forappropriate balance.support for this project was provided by the defense advanced research projectsagency and the national institute of standards and technology. any opinions,findings, conclusions, or recommendations expressed in this material are those ofthe authors and do not necessarily reflect the views of the sponsor. moreover, theviews, opinions, and findings contained in this report should not be construed asan official department of defense position, policy, or decision, unless so designated by other official documentation.library of congress control number: 2001093511international standard book number 0309075688additional copies of this report are available from:national academy press2101 constitution avenue, n.w.box 285washington, dc 20055800/6246242202/3343313 (in the washington metropolitan area)http://www.nap.educopyright 2001 by the national academy of sciences. all rights reserved.printed in the united states of americaembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.the national academy of sciences is a private, nonprofit, selfperpetuating society of distinguished scholars engaged in scientific and engineering research, dedicated to the furtherance of science and technology and to their use for the generalwelfare. upon the authority of the charter granted to it by the congress in 1863,the academy has a mandate that requires it to advise the federal government onscientific and technical matters. dr. bruce m. alberts is president of the nationalacademy of sciences.the national academy of engineering was established in 1964, under the charterof the national academy of sciences, as a parallel organization of outstandingengineers. it is autonomous in its administration and in the selection of its members, sharing with the national academy of sciences the responsibility for advising the federal government. the national academy of engineering also sponsorsengineering programs aimed at meeting national needs, encourages educationand research, and recognizes the superior achievements of engineers. dr. wm. a.wulf is president of the national academy of engineering.the institute of medicine was established in 1970 by the national academy ofsciences to secure the services of eminent members of appropriate professions inthe examination of policy matters pertaining to the health of the public. theinstitute acts under the responsibility given to the national academy of sciencesby its congressional charter to be an adviser to the federal government and, uponits own initiative, to identify issues of medical care, research, and education.dr.kenneth i. shine is president of the institute of medicine.the national research council was organized by the national academy of sciences in 1916 to associate the broad community of science and technology withthe academy’s purposes of furthering knowledge and advising the federal government. functioning in accordance with general policies determined by theacademy, the council has become the principal operating agency of both thenational academy of sciences and the national academy of engineering in providing services to the government, the public, and the scientific and engineeringcommunities. the council is administered jointly by both academies and theinstitute of medicine. dr. bruce m. alberts and dr. wm. a. wulf are chairmanand vice chairman, respectively, of the national research council.national academy of sciencesnational academy of engineeringinstitute of medicinenational research councilembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.committee on networked systems ofembedded computersdeborah l. estrin, university of california at los angeles, chairgaetano borriello, university of washingtonrobert paul colwell, intel corporationjerry fiddler, wind river systems, inc.mark horowitz, stanford universitywilliam j. kaiser, sensoria corporationnancy g. leveson, massachusetts institute of technologybarbara h. liskov, massachusetts institute of technologypeter lucas, maya design groupdavid p. maher, intertrust technologies corporationpaul m. mankiewich, lucent technologiesrichard taylor, hewlettpackard laboratoriesjim waldo, sun microsystems, inc.stafflynette i. millett, program officer (study director beginningseptember 2000)jerry r. sheehan, senior program officer (study director throughaugust 2000)suzanne ossa, senior project assistantvembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.computer science and telecommunications boarddavid d. clark, massachusetts institute of technology, chairdavid borth, motorola labsjames chiddix, aol time warnerjohn m. cioffi, stanford universityelaine cohen, university of utahw. bruce croft, university of massachusetts at amherstsusan l. graham, university of california at berkeleyjudith hempel, university of california at san franciscojeffrey m. jaffe, bell laboratories, lucent technologiesanna karlin, university of washingtonmichael katz, university of california at berkeleybutler w. lampson, microsoft corporationedward d. lazowska, university of washingtondavid liddle, u.s. venture partnerstom m. mitchell, whizbang! labs, inc.donald norman, unext.comdavid a. patterson, university of california at berkeleyhenry (hank) perritt, chicagokent college of lawburton smith, cray, inc.terry smith, university of california at santa barbaralee sproull, new york universitymarjory s. blumenthal, executive directorherbert s. lin, senior scientistalan s. inouye, senior program officerjon eisenberg, senior program officerlynette i. millett, program officercynthia patterson, program officerjanet briscoe, administrative officermargaret huynh, senior project assistantsuzanne ossa, senior project assistantdavid drake, project assistantdavid padgham, research assistantbrandye williams, office assistantviembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.prefacecontinued advances in information technologies are enabling agrowing number of physical devices to be imbued with computing and communications capabilities. aircraft, cars, householdappliances, cellular telephones, and health monitoring devices all containmicroprocessors that are being linked with other information processingdevices. such examples represent only the very beginning of what ispossible. as microprocessors continue to shrink, wireless radios are alsobecoming more powerful and compact. as the cost of these and relatedtechnologies continues to decrease, computing and communications technologies will be embedded into everyday objects of all kinds to allowobjects to sense and react to their changing environments. networkscomprising thousands or millions of sensors could monitor the environment, the battlefield, or the factory floor; smart spaces containing hundreds of smart surfaces and intelligent appliances could provide access tocomputational resources.getting to this point will not be easy. networks of embedded computers pose a host of challenges qualitatively different from those facedby more traditional computers or standalone embedded computers because they will be more tightly integrated with their physical environments, more autonomous, and more constrained in terms of space, power,and other resources. they will also need to operate, communicate, andadapt in real time, often unattended. enabling such innovation willrequire that a number of research challenges be overcome. how can largenumbers of embedded computing devices assemble themselves seamviiembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.viiiprefacelessly into an integrated network? how can their performance be guaranteed? how can social issues raised by the advent of more pervasiveinformation collection and processing—for example, concerns about privacy, robustness, and usability—be addressed?charge to the committeeto improve understanding of these issues and help guide future research endeavors, the defense advanced research projects agency(darpa) and the national institute of standards and technology (nist)asked the computer science and telecommunications board (cstb) ofthe national research council (nrc) to conduct a study of networkedsystems of embedded computers (emnets) that would examine the kindsof systems that might be developed and deployed in the future and identify areas in need of greater investigation. this report identifies opportunities for the use of emnets, examines the ways emnets differ from moretraditional systems, and delineates the research topics that need to beaddressed. the objective is to develop a research agenda that could guidefederal programs related to computing research and inform the researchcommunity (in industry, universities, and government) about the challenging needs of this emerging research area. this report examines bothissues related to components of embedded computers—such as hardwareneeds, operating systems, programming capabilities, and human interfaces—and systemslevel issues resulting from the interconnection ofmultiple embedded computers—system architectures, coordination, adaptation, reliability, security, safety, interoperability, stability, and guaranteed performance. to that end, the committee attempted to answerquestions such as the following:•what are networked systems of embedded computing systems?how do networks of embedded computers differ from more traditionalcomputer networks? how do these differences affect research needs?•what types of applications could arise from greater networking ofembedded systems? what are the general characteristics of different applications? what would be the benefits and capabilities of such systems?•how can systems of interconnected embedded processors be moreeasily designed, developed, and maintained? how can system reliability,safety, operability, and maintainability be ensured in networked systems?how do such considerations differ for embedded and more traditionalforms of computing?•what kinds of advances are needed in enabling component technologies, such as hardware devices, operating systems, and communications networks, to make emnets possible and more capable?embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.prefaceix•what types of user interfaces are needed to allow users to interactwith and to program systems composed of large numbers of interconnected embedded systems? how do these requirements differ fordifferent kinds of users (experts, novices, system integrators)? what typesof “programming” will consumers be expected to perform?•how can the stability and effectiveness of interconnected systemsof embedded computers be assured if individual components come froma wide variety of developers and use a variety of hardware and softwareplatforms, some of which may run the latest versions of the software, andothers of which may be several generations behind?committee composition and processto conduct the study, cstb assembled a committee of 15 membersfrom industry and academia with expertise in areas of apparent importance to emnets, such as computing devices, verylargescale integratedcircuit technology, networking, wireless communications, embedded operating systems, software safety, distributed computing, programminglanguages, humancomputer interfaces and usability, and computer system security.1 several committee members brought with them a familiarity with federal research programs related to emnet technologies andprovided invaluable insight into the challenges of organizing researchprograms in this area. several committee members changed their organizational affiliation during the course of the study, attesting to the dynamic nature of this field. indeed, because of growing commercial interest in ubiquitous or pervasive computing technology, two of the originalcommittee members, walter davis from motorola and ajei gopal fromibm, were unable to continue their participation in the project.the committee met six times between december 1999 and march 2001to plan its course of action, solicit testimony from relevant experts, deliberate its findings, and draft its final report. it continued its work byelectronic communications into the spring of 2001. during the course ofthe project, the committee heard from information technology researchersin industry and universities and from directors of government agenciesinvolved in funding computing research (including research related toemnets).2 it also met with people involved in developing and deployingemnets to serve a range of missions, from controlling lighting and heating systems in office buildings and automating manufacturing lines, to1see appendix a for biographies of committee members.2see appendix b for a list of briefers to the committee.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.xprefacemonitoring the health of astronauts in space and of patients in emergencyrooms. the committee also gathered information on major initiatives topursue research on ubiquitous and pervasive computing, and it collecteddata on microprocessors, microcontrollers, wireless communicationsnodes, and their applications in order to track the emergence of an emnetenvironment.acknowledgmentsas with any project of this magnitude, thanks are due to the manyindividuals who contributed to the work of the committee. first, thanksare due to the members of the committee itself, who volunteered considerable time during the course of the study to attend meetings, engage in email and telephone discussions, draft sections of the report, and respondto comments from external reviewers.beyond the committee, numerous persons provided valuable information through briefings to committee meetings: andrew berlin, xeroxpalo alto research center; stephen p. boyd, stanford university; januszbryzek, maxim integrated products, inc.; david d. clark, massachusettsinstitute of technology; alan davidson, center for democracy and technology; robert dolin, echelon corporation; john hines, national aeronautics and space administration; rodger lea, sony distributed systemslaboratory; k. venkatesh prasad, ford research laboratory; jonathansmith, university of pennsylvania; karen sollins, national sciencefoundation; and keith uncapher, corporation for national researchinitiatives.thanks are also due to those who sponsored the study. davidtennenhouse, formerly the director of the defense advanced researchproject agency’s (darpa) information technology office (ito) and nowvice president of research at intel corporation, provided the original impetus for the study, identifying networked systems of embedded computers as a potentially revolutionary set of technologies and laying out avision for the field. shankar sastry and janos sztipanovits ensured continued darpa support for the project as they expanded ito’s researchefforts in emnets of different kinds. sri kumar, also of darpa’s ito,provided considerable guidance and input related to sensor networks.jerry linn, formerly of the information technology lab at nist, generated interest and financial support from several laboratories within nist.other members of the technology policy working group also supportedthe concept of the study, even if they did not provide financial support.many others also provided valuable input or services to the committee that should not go unnoted. martin herman and alden dima of nistprovided relevant information about nist programs near the end of theembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.prefacexistudy process. as she has done so many times in the past, laura ost, afreelance editor, provided invaluable assistance in preparing the manuscript for review. jim igoe, with the national academies library, washelpful with background research. craig kaplan of the university ofwashington assisted with cover design. jeffrey risberg of tibco software, inc.; maja mataric of the university of southern california; gauravsukhatme of the university of southern california; scott stadler of themassachusetts institute of technology’s lincoln laboratory; gregory j.pottie of the university of california at los angeles; and steven t. sonkaof the university of illinois at urbanachampaign also provided background information to the committee.finally, the committee would like to acknowledge the work of thenrc staff. during the first 12 months of our study, jerry sheehan shapedthe content and process of the report. he contributed vision, guidance,feedback, and discipline. moreover, he continued to act as a key consultant after his official departure. we were all quite anxious about jerry’sdeparture midway through our process; frankly, i was not sure we couldcarry it off without him. however, we were tremendously pleased to findthat his replacement, lynette millett, was able to come in and march us tocompletion without missing a beat. she ferreted out our inconsistencies,turned our bullets into prose, implemented innumerable reorganizationsand rewrites, and last but not least, came up with the title for the report!lynette’s contributions are certainly embedded everywhere in this report. alan inouye worked with lynette behind the scenes during thefinal phases of the project, providing advice and feedback and helpingshepherd the project to completion. liz fikre made significant editorialcontributions to the final manuscript. claudette baylorfleming, carmelachamberlain, and david padgham assisted with final report preparation.suzanne ossa provided the committee with excellent support duringmeetings and assisted with background research and editorial work.finally, we thank marjory blumenthal, whose vision and commitmentdirectly and indirectly shaped the report through her hiring andmentoring of excellent staff and her detailed comments on many versionsof the report.deborah l. estrin, chaircommittee on networked systemsof embedded computersembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.acknowledgment of reviewersthis report has been reviewed in draft form by individuals chosenfor their diverse perspectives and technical expertise, in accordancewith procedures approved by the nrc’s report review committee. the purpose of this independent review is to provide candid andcritical comments that will assist the institution in making its publishedreport as sound as possible and to ensure that the report meets institutional standards for objectivity, evidence, and responsiveness to the studycharge. the review comments and draft manuscript remain confidentialto protect the integrity of the deliberative process. we wish to thank thefollowing individuals for their review of this report:michael dewalt, certification services,batya friedman, university of washington,matthew s. jaffe, emory riddle aeronautical university,randy h. katz, university of california at berkeley,alan kay, walt disney imagineering,edward a. lee, university of california at berkeley,john mchugh, cert, software engineering institute, carnegiemellon university,kristofer s.j. pister, university of california at berkeley,rush d. robinett, sandia national laboratories,daniel p. siewiorek, carnegie mellon university, andandrew j. viterbi, viterbi group, llc.xiiiembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the conclusions or recommendations, nor did they see the final draft of the reportbefore its release. the review of this report was overseen by robert j.spinrad, xerox parc (retired), appointed by the division on engineeringand physical sciences, who was responsible for making certain that anindependent examination of this report was carried out in accordancewith institutional procedures and that all review comments were carefully considered. responsibility for the final content of this report restsentirely with the authoring committee and the institution.xivacknowledgment of reviewersembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.contentsexecutive summary11 introduction and overview14examples, 16example 1: automotive telematics, 17example 2: precision agriculture, 20example 3: defense systems, 21understanding networked systems of embedded computers, 24how emnets differ from traditional systems, 26emnets are tightly coupled to the physical world, 27emnet nodes are often resourceconstrained, 28emnets’ long lifetimes, 29emnet size and scale are significant, 30emnet users are not system experts, 31why a new research agenda?, 31what this report does not do, 33advanced sensors and actuators, 34public policy issues, 34commercialization issues, standards, business models, 35standalone embedded systems and other networkedinformation systems, 36organization of this report, 37references, 38xvembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.xvicontents2enabling technologies39silicon scaling, 40computing, 41growing complexity, 42simpler processors, 43power dissipation, 45communication, 49wireline communications, 50wireless communications, 53geolocation, 57computing software—operating systems and applications, 59realtime and performancecritical aspects of embeddedoperating systems, 64microelectromechanical systems, 65summary, 68 references, 73bibliography, 743selfconfiguration and adaptive coordination76terminology, 77selfconfiguration and adaptive coordination in distributedsystems, 79discovery in distributed systems, 80interfaces and interoperability, 84adaptive coordination in existing networks, 90research challenges for configuration and adaptivecoordination, 93research issues in selfconfiguration, 93research issues for adaptive coordination, 101summary, 117references, 1184building trustworthy networked systems of119embedded computersreliability, 121reliability research topics deserving attention, 123safety, 123safety research topics deserving attention, 126security, 128protecting system boundaries, 129managing scale and complexity, 130mobile code and security, 131embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.contentsxviidenial of service, 132security research topics deserving attention, 133privacy, 134privacy as related to security, 137privacy research topics deserving attention, 138usability, 140creating mental models, 141emnetspecific usability issues, 143usability research topics deserving attention, 144references, 145bibliography, 1465 models of computation147what are models of computation?, 149distributed computing models: current practice, 152new models for networked systems of embedded computers, 156models with resource constraints, 158models dealing with failures, 160new data models, 162models of trust, 165models for concurrency, 165models of location, 167conducting research on models and abstractions, 168references, 1716conclusions and recommendations:172an agenda for researchan emnetspecific research agenda, 174predictability and manageability, 175adaptive selfconfiguration, 176monitoring and system health, 177computational models, 178network geometry, 179interoperability, 180integration of technical, social, ethical, and public policyissues, 181enabling technologies, 183structuring the research enterprise for emnets, 184stimulating interdisciplinary research, 185what can government do? recommendations to federalagencies, 189embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.xviiicontentsrecommendations to the defense advanced researchprojects agency, 190recommendations to the national institute of standards andtechnology, 197recommendations to the national science foundation, 199recommendations to other federal agencies, 201summary, 202references, 202appendixes205abiographies of committee members 207bbriefers at plenary meetings214embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywherea research agenda fornetworked systems of embedded computersembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.1executive summaryinformation technology (it) is on the verge of another revolution.driven by the increasing capabilities and ever declining costs of computing and communications devices, it is being embedded into agrowing range of physical devices linked together through networks andwill become ever more pervasive as the component technologies becomesmaller, faster, and cheaper. these changes are sometimes obviousñinpagers and internetenabled cell phones, for exampleñbut often it isburied inside larger (or smaller) systems in ways that are not easily visibleto end users. these networked systems of embedded computers, referredto as emnets throughout this report, have the potential to change radically the way people interact with their environment by linking together arange of devices and sensors that will allow information to be collected,shared, and processed in unprecedented ways. the range of applicationscontinues to expand with continued research and development. examplesof ways in which emnets will be applied include the following: emnetswill be implemented as a kind of digital nervous system to enable instrumentation of all sorts of spaces, ranging from in situ environmental monitoring to surveillance of battlespace conditions; emnets will be employedin personal monitoring strategies (both defense related and civilian), combining information from sensors on and within a person with informationfrom laboratory tests and other sources; and emnets will dramaticallyaffect scientific data collection capabilities, ranging from new techniquesfor precision agriculture and biotechnological research to detailed environmental and pollution monitoring.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.2embedded, everywherethe use of emnets throughout society could well dwarf previousmilestones in the information revolution. the effects of mooreõs law1andrelated trends in computing and communications are making all of thispossible. ongoing work in microelectromechanical systems (mems) willenable sensing and actuation on the scale of a nanometer. the possibilities for miniaturization extend into all aspects of life, and the potential forembedding computing and communications technology quite literallyeverywhere is becoming a reality. it will eventually become an invisiblecomponent of almost everything in everyoneõs surroundings.what is different about emnets?emnets are more than simply the next step in the evolution of thepersonal computer or the internet. building on developments in bothareas, emnets will also be operating under a set of constraints that willdemand more than merely incremental improvements to more traditionalnetworking and information technology. emnets will tend to be tightlycoupled to the physical world. unlike a desktop computer, which is itselfa piece of office furniture, emnets will be integrated into furniture andother objects in the environment. individuals will interact with the objects and devices of which emnets are a part, but it is unlikely that theywill think of it as interacting with a computer system. a complex, networked, computational system will often be invisible when things areworking properly.emnet components will also be highly resource constrained. in contrast to the internet, which still consists primarily of tethered devices,emnet components are likely to be small, untethered devices operatingunder physical constraints such as limited energy and the need for adequate heat dissipation. emnets will also be constrained by bandwidthand memory limitations.in addition to the physically coupled, resourceconstrained nature ofthese systems, another constraint on emnets is the fact that often theywill be integrated into objects or systems that are likely to last for longperiods of time. emnets in buildings, bridges, vehicles, and so on will beexpected to last as long as the objects in which they are embedded. thisexpectation of longevity will need to be taken into account when designing, deploying, and managing these systems. a further constraint is the1mooreõs law refers to the observation by gordon moore in 1965 that each new microprocessor contains roughly twice as much capacity as its predecessor, and each chip is usuallyreleased within 18 to 24 months of the previous chip. as this trend has continued, computing power has risen exponentially.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary3likely heterogeneity and large number of interacting elements that willmake up an emnet; this makes interoperability a key concern. finally,emnets will often be used and interacted with by people who are notexperts in emnetrelated technology. managing all of these constraintsand creating a system that functions properly for the application domainwhile remaining understandable and manageable by human operators,users, andñin many casesñcasual passersby, is a large challenge foremnet designers.as an example, consider a transportation information system basedon emnet technology. such a system will certainly be large in size andscale, possibly encompassing the entire highway system of the unitedstates. components of it would probably be embedded in longlivedphysical structures (such as bridges, traffic lights, individual cars, andperhaps even the paint on the roads). some components will be tethered,but many would be resource constrained while computing data and communicating it wirelessly when necessary. the many pieces of such asystem will of necessity be heterogeneous, not only in form but also infunction. there may be subsystems that communicate to consumers inprivate vehicles, others that relay information from emergency vehicles tosynchronize traffic lights, still others that provide traffic data and analysisto highway engineers, and perhaps some that communicate to law enforcement. issues of how information will be communicated to thoseinteracting with the system are of great importance in such an environment. safety is a critical concern; issues of privacy and security arise aswell, along with concerns about reliability.the rest of this report identifies areas in which research is needed toenable such emnets and to make them a successful reality. below arehighlights of some of these areas as well as particular recommendationsto federal funding agencies.key areas of inquiryrealizing the great promise of emnets requires more than the mereadvance of individual technologiesñit will rely on numerous subsystemsworking together in an efficient, unattended, comprehensible, and trustworthy manner. many aspects of the needed research are highly interdisciplinary because of the intricate ways in which emnet systems interactwith the physical world. in the absence of programs aimed at solvingsome of the basic research problems, it is likely that many of the benefitsof emnets will simply not be realized.as with any technology there are risks. in the case of emnets, thepotential benefits come with associated risks that may be exacerbated bythe emnetsõ very pervasiveness. pervasive information creates security,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.4embedded, everywheresafety, and privacy protection issues. as emnets become increasinglycritical to our communication, transportation, power distribution, andhealthcare infrastructures, the consequences of failures and securitybreaches will become increasingly severe. by the time emnets are broadlydeployed, it may not be feasible to give them technological fixes becausetheir components are so widely dispersed.this report by the committee on networked systems of embeddedcomputing, convened by the computer science and telecommunicationsboard of the national research council, identifies and explores the manyresearch questions that must be answered before there can be implementation and use of widespread networked embedded computing devices.it examines the enabling technologies that will facilitate the developmentand broad deployment of emnets, and it explores three key areas inwhich a great deal of new research will be required for emnets to achievetheir full potential: (1) selfconfiguration and adaptive coordination,(2)building trustworthy emnets (including issues of privacy, security,reliability, safety, and usability), and (3) models of computation. enablingtechnologies and these key areas of research, explored in depth in chapters 2, 3, 4, and 5, are briefly described below.selfconfiguration and adaptive coordinationgiven the expected pervasive and ubiquitous nature of emnets, itwill be necessary for these systems to be able to configure themselves andadapt to their environments automatically. selfconfiguration and adaptivecoordination comprise a spectrum of changes that a system makes to itselfin response to occurrences both internal to it and external. emnets willbe relatively long lived, which greatly increases their chances of beingupgraded, extended, and otherwise modified. moreover, emnets will beexposed to both continual environmental and component dynamics. ineffect, the original emnet must be designed with automatic reconfiguration and adaptation in mind, especially when the specifics of that reconfiguration cannot be known at design time. current work in distributedsystems has not solved the problem of systems operating under the constraints that networked systems of embedded computers will experience,particularly with respect to computational resources, communication limitations, and energy restrictions.selfconfiguration is the process of interconnecting available elementsinto an ensemble that will perform the required functions at the desiredperformance level. selfconfiguration in existing systems is evidenced bythe notions of service discovery, interfaces, and interoperability. in thisreport, the research challenges related to selfconfiguration focus on mobile code and discovery. emnets present a number of constraints: theyembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary5will appear in hybrid environments of mobile and static networks; theirnodes will be diverse in capability, energy availability, and quality ofconnectivity; the wireless layer is both diverse and limited by energyconstraints, making low power discovery a challenge. some of the issuesthat will need to be investigated and resolved for configuration and adaptation to succeed in emnets include stable localized control, abstraction,and memory use. research issues related to service discovery include thescaling of discovery protocols, security, and the development of adequatefailure models for automatically configured networks.adaptive coordination involves changes in the behavior of a systemas it responds to changes in the environment or system resources. coordination will not be mediated by humans because emnets are so largeand the time scale over which the adaptation will need to take place is tooshort for a human to be able to intervene. achieving adaptive coordination in emnets will not only require drawing on the lessons learned fromadaptive coordination in existing distributed systems, but it will also require meeting the radical new challenges of emnets that are due to thephysically embedded nature of the collaborative control tasks and themassive numbers of elements, all combined with the relatively constrained capabilities of individual elements. adaptive coordination is afairly new area of investigation, particularly as it applies to emnets. toobtain necessary adaptability in emnets, research is needed in three areas: exploiting massive redundancy to achieve system robustness andlongevity, decentralized control, and collaborative processing.building trustworthy emnetsemnets will be deployed in large numbers and will become an essential part of the fabric of everyday life. in the same way that people oftenassume that electric power and telephone service will be available (recentevents in california notwithstanding), they will assume the availabilityand proper functioning of emnets. but in contrast to those utility services, emnets will be deployed in situ, often without the dedicated expertservice and maintenance associated with utilities, making the trustworthiness of emnets triply difficult: emnets are realworld systems, oftendirectly affected by wind, weather, and interference; they must embodythe redundancy needed for dependability without compromising the basic economics, and they must adequately and safely convey to a nonexpert user how much of that redundancy is available (thereby determiningthe systemõs safety margins) so that users can make reasonable decisionsconcerning their use. this report discusses five features that must beaddressed in the design of emnets from the outset: reliability, safety,security, privacy, and usability.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.6embedded, everywherereliability is the quality of a system that is satisfying its behavioralspecifications under a given set of conditions and within defined timeperiods. current verification techniques are not readily applicable toemnets because of the large number of elements, highly distributed nature, and environmental dynamics. simply testing individual components is insufficient. moreover, it is not clear that the community has thevocabulary to fully characterize what will be required of emnets. research is needed on fault models and recovery techniques for emnets,monitoring and performancechecking facilities, and verification tools andtechniques.safety refers to the ability of a system to operate without causing anaccident or unacceptable loss. it is distinct from reliability and posesanother set of research problems for emnets. emnets increase the number of possible behaviors and the complexity of the possible interactionswithin the system. further, they operate in real time and with limitedhuman intervention and are likely to exhibit emergent or unintendedbehaviors. analyzing and designing such systems with regard for safetyconsiderations is a challenge. several safety topics deserve further research effort, including hazard analysis for emnets, validating requirements, designing for and verifying safety, and ensuring safety in upgraded hardware.security is difficult to achieve in virtually all information systems, butemnets again present particular challenges. the networking of embedded devices will greatly increase the number of possible points of failure,making security analysis even more difficult. defining and then protecting system boundaries where physical boundaries are likely to be nonexistent and where nodes can automatically move in and out of the systemwill be a serious challenge. further, managing the scale and complexityof emnets while at the same time handling the security challenges ofmobile code and the vulnerability to denialofservice attacks will requiresignificant attention from the research community.related to but separate from the issue of security is the issue of personal privacy. emnets of the future will be able to gather more information than current systems and will do so in a much more passive manner.achieving consensus on privacy and confidentiality policies will be exacerbated by the pervasiveness and interconnectedness of emnet systems.notifying users that they are being monitored, especially in the case ofwideranging sensor networks, is a challenge, and acquiring consent in ameaningful fashion is an even greater challenge. determining how tohandle the vast amounts of personal information that will be collectedand implementing privacy policies once they are decided on is a largearea ripe for research.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary7finally, and related to all of the above, emnets will need to be usableby persons with little or no formal training. unfortunately, usability andsafety often conflict, and decisions on tradeoffs will need to be made.understanding the way people create mental models of the systems theyuse and interact with is a good way for designers to begin to address theissues of usability and manageability. in particular, more research isneeded in designing for a range of personsñincluding system administrators, users who are explicitly operating the emnet, and persons whoare interacting with objects in their environment without explicit knowledge of the system behind themñand in enhancing mental models anduser training.models of computationwhile there is always some divide, the gulf between theory and practice in emnets seems to be extremely wide and continuing to grow. inaddition to the systems research proposed, more theoretical work is alsorequired. in particular, new models of computation are needed todescribe, understand, construct, and reason about emnets effectively. acritical question is, how should large aggregates of nodes be programmedto carry out their tasks in a distributed and adaptive manner?current distributed computing models such as distributed objectsand distributed shared memory do not fully address all of the new requirements of emnets. emnetsõ tight coupling to the physical world, theheterogeneity of their systems, the multitude of elements, and timing andresource constraints, among other things, demonstrate the need for amuch richer computing model. computational models for emnets willneed to incorporate resource constraints, failures (individual componentsmay fail by shutting down to conserve energy, for example), new datamodels, trust, concurrency, and location.developing these computational models for emnets will require anew approach. as experience is gained with applications and implementations of the technology, designers and implementers will discover whichof the new abstractions are useful. research in this arena will thus requirea balance between system implementation and experimentation and thedevelopment of the model itself. runtime environments will also berequired that support the models being developed, allowing for fasterconstruction of the experimental systems. this cycle of concurrent developmentñwhereby the computational model feeds into the implementation, experimental results from which feed back into the computationalmodelñwill facilitate more accurate and effective models for emnets.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.8embedded, everywhereenabling technologiesthe evolution leading to emnets derives from the revolutionary advances in information technology during the last several decades, withsilicon scaling as the driving force. exponentially increasing processorperformance has contributed to a world in which sophisticated chips canbe manufactured and embedded easily and cheaply. continued improvements (in line with mooreõs law) in the price and performance of chiptechnology are expected throughout the decade. even though the creation of emnets will be supported in general by advances in the enablinginformation technologies, research is needed on specific aspects of communications, geolocation, software and operating systems, and mems.as silicon scaling has drastically reduced the cost of computation, ithas also driven down the cost of communication for both wireline andwireless systems. as wireless technology continues to become less expensive and more sophisticated, the vision of connecting embedded processors everywhere becomes increasingly feasible. however, most of theprogress to date in wireless technology has focused on medium to longrange communications (as in cellular phones and pagers) and is not sufficient for the widespread deployment of emnets. work is needed tounderstand how to create network architectures and designs for lowpower, shortrange wireless systems.related to wireless are the issues surrounding geolocation technology. unlike conventional computer networks, which are more dependent on the relative positioning of elements in a network topology,emnets are often inextricably tied to the physical world (a primary purpose often being to measure and control physicalworld attributes or objects), so location in physical space is more important. many emnets willtherefore require ready access to absolute or relative geographic information.work should continue in mems technology in order to achieve realworld physical sensing and actuation. experimental progress in emnetswill be enabled by the availability of a wider range of memsbased sensor components. while this technology has advanced tremendously inthe past decade, attention must be given to the effective integration ofmems devices into emnets.continuing research into operating systems for networks of embedded computers and into the development of software that has the required characteristics will also be necessary. emnets software will needto be tailorable to physical constraints and application requirements indeployment, be upgradable, have high availability, and be able to workwith new hardware. emnets will be embedded in longlived structuresbut will also have to evolve, depending on changing external conditionsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary9and advances in technology as time passes. software (operating systemsand applications) that can cope with this type of evolution will be critical.further, emnets will often impose realtime and performancecritical constraints on software. new methods of software development may beneeded in order to ensure that complex emnet software is up to copingwith the constraints placed on it.recommendations and research themes distilledresearch themesnetworked systems of embedded computers will be implementedand deployed even if there is no additional research. some of them maysucceed, and others may appear to have succeeded at least for a time. butany such attempts will somehow have to overcome the fundamental gapsin knowledge that are described throughout this report. to realize functionally powerful, flexible, scalable, longlived, and trustable systems, aspectrum of research is essential. moreover, the committee (composed ofpeople from both academia and industry) believes that while some of thequestions raised in this report may be answered without a concerted,publicly funded research agenda, leaving this work solely to the privatesector raises a number of troubling possibilities. of great concern is thatindividual commercial incentives will fail to bring about work on problems that have a larger scope and that are subject to externalities: interoperability, safety, upgradability, and so on. moreover, a lack of government funding will slow down the sharing of the research, since thecommercial concerns doing the research tend to keep the research privateto retain their competitive advantage. the creation of an open researchcommunity within which results and progress are shared is vital to making significant progress in this arena.the committee generated eight overarching themes that intersect thethree key areas for research described above (selfconfiguration and adaptive coordination, trustworthiness, and computational models). researchinto all of the themes is required before emnets can fulfill their potential.research in broadly relevant areas such as networking and usability thatpervade many of the themes described below is also essential:¥predictability and manageability. methodologies and mechanismsfor designing predictable, safe, reliable, manageable emnets;¥adaptive selfconfiguration. techniques to allow adaptive selfconfiguration of emnets to respond to volatile environmental conditions andsystem resources in an ongoing dynamic balance;¥monitoring and system health. a complete conceptual framework toembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.10embedded, everywherehelp achieve robust operation through selfmonitoring, continuous selftesting, and reporting of system health in the face of extreme constraintson nodes and elements of the system;¥computational models. new abstractions and computational models for designing, analyzing, and describing the collective behavior andinformation organization of massive emnets;¥network geometry. ways to support and incorporate network geometry (as opposed to just network topology) into emnets;¥interoperability. techniques and design methods for constructinglonglived, heterogeneous systems that evolve over time and space whileremaining interoperable;¥integration of technical, social, ethical, and public policy issues. fundamental research into the nontechnical issues of emnets, especially thosehaving to do with the ethical and public policy issues surrounding privacy, security, reliability, usability, and safety; and¥enabling technologies. ongoing research into the various component and enabling technologies of emnets.the committee also recognizes that to ensure that the right kinds ofresearch are conducted to advance emnets, the structure and conduct ofthe research enterprise need to be adapted. achieving these adaptationsmay not be easy, but the committee identifies them as goals: effectivecollaboration between industry and academia, with support from federalfunding agencies, is a necessity. further, inter and multidisciplinaryendeavors will be crucial to the success of this field. balancing the roles ofindustry and university, balancing applications with fundamental research, and incorporating multidisciplinary perspectives are all requirements for the emnet research endeavor that will require a fresh perspective from the community.recommendations to federal agenciesthe defense advanced research projects agency (darpa), the national institute of standards and technology (nist), the national sciencefoundation (nsf), and other federal agencies all have significant roles toplay in the development of robust emnets and emnetrelated research.defense advanced research project agencydarpa has an ongoing investment in emnet technologies. indeed,emnets will be incredibly important and have tremendous implicationsfor almost all aspects of defense activities, from battlespace monitoringand coordination to asset monitoring to logistics. emnets will supportembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary11defense activities from the seafloor to space. it is now time for darpa tobuild on past programs in this area; to expand research in informationtechnology, networking, and the particular areas described above; and tomove forward to meet the challenges posed by networked systems ofembedded computers. without darpaguided investment in this area,systems issues will not get the critical attention that they need, resultingin more expensive and much less robust systems. the effort requiresimmediate and sustained attention. a single program will not meet thechallenges presented by emnets. several programs could be set up,including the following:¥designing for predictability, reliability, and safety;¥collaborative signal processing;¥multiscale locationaware systems; and¥interoperability over time and space.while the committee considers that work in these programs is necessary, this list is by no means comprehensive. instead, it is intended toserve as a starting point for ideas for future programs.the research agenda for emnets (outlined in depth in this report) isbroad and deep, requiring longterm attention. followon programs evenbeyond the ones described above will be critical. darpa should aggressively pursue programs that build upon and interact with one anotherõsintellectual contributions and with some of the seed programs that havealready begun explorations in related areas. to better meet the needs ofemnetrelated research, the committee also makes two specific recommendations to darpa:recommendation 1. the information technology office of thedefense advanced research projects agency should revise boththe substance and process of its emnetrelated programs to betteraddress the research needs identified in this report. darpa hasseveral ongoing programs that could be revised or expanded to bettermeet the needs outlined here.recommendation 2. the defense advanced research projectsagency should encourage greater collaboration between its information technology office and its microelectronics technologyoffice to enable greater experimentation. greater collaboration between these offices would facilitate rich and significant experimentation in emnetrelated areas.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.12embedded, everywherenational institute of standards and technologynist has worked in a variety of areas to help make information technology more secure, more reliable, more usable, and more interoperable.all of these characteristics are crucial to current and future emnetrelatedtechnologies. specifically, the committee recommends as follows:recommendation 3.the national institute of standards and technology should develop and provide reference implementations inorder to promote open standards for interconnectivity architectures.it will be important to promote open standards in the area and promote system development using commercial components by makingpublic domain device drivers available.recommendation 4.the national institute of standards and technology should develop methodologies for testing and simulatingemnets in light of the diverse and dynamic conditions of deployment. comprehensive simulation models and testing methodologiesfor emnets will be necessary to ensure interoperable, reliable, andpredictable systems. in particular, the development of methodologiesfor testing specification and interoperability conformance will beuseful.national science foundationnsfõs multidisciplinary efforts, its work to integrate research andeducation, and its coordinated systems efforts will be of great importancein the support of emnetrelated research projects. nsf should continuethese efforts and include crossdivisional efforts where appropriate. specifically, the committee recommends as follows:recommendation 5. the national science foundation should continue to expand mechanisms for encouraging systemsorientedmultiinvestigator, collaborative, multidisciplinary research onemnets. nsf can facilitate collaborative multidisciplinary researchboth through the programs it supports and through the use of a flexible process that encourages the incorporation of perspectives from abroad range of disciplines.recommendation 6. the national science foundation should develop programs that support graduate and undergraduate multidisciplinary educational programs. it could take the lead in tacklinginstitutional barriers to interdisciplinary and broad systemsbasedwork. nsf has a history of encouraging interdisciplinary programsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.executive summary13and could provide venues for such work to be explored as well asfoster and fund joint graduate programs or joint curriculum endeavors.other agenciesother agencies such as the department of energy (doe) and thenational aeronautics and space administration (nasa) can play an important role by sharing their specialized knowledge in this area withothers working in less specialized areas in the broader community. theseand other federal agencies should coordinate their emnetrelated development efforts with the programs at darpa, nsf, and nist to ensurethat openplatform systems of various scales, lowpower components andtheir software drivers, debugging techniques and software, and trafficgenerators can all be shared among research programs when applicable,avoiding redundancy in those parts of the system where there is morecertainty. it is expected that this sharing and associated coordinationneeds can be supported by the various organizations and groups associated with federal information technology research and development.looking forwardemnets will radically transform the way in which people interactwith and control their physical environment. they have tremendousimplications for all aspects of society, from national defense and government applications to wideranging commercial concerns to systems thatprivate individuals will use in everyday life. as it moves forward in theresearch areas described above, the research community, includingacademia, industry, and funding agencies, must remain cognizant of onebasic message: new approaches to the study of systems (not just individual components) must be developed in order to harness the emergentproperties of the many networked, physically embedded computing elements that will make up emnets. attention must be paid to designingsystems in a way that incorporates strategies from a range of disciplinesand to designing systems that can address a range of problem domains.without concerted effort on the part of the research community to address the questions outlined in this report, the potential inherent in networked systems of embedded computers will not be realized. with significant inter and multidisciplinary research efforts that focus on thesystems issues that emnets bring to the fore, the promise of this technology can be realized.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.141introduction and overviewinformation technology (it) is on the verge of another revolution. fueled by the increasing capabilities and everdeclining costs of computing and communications devices, it is being embedded into agrowing range of physical devices linked together through networks.these changes are sometimes obviousñpagers and internetenabled cellphones, for exampleñbut often it is buried inside larger (or smaller)systems in ways that are not easily visible to endusers. audiovisualequipment, home or office appliances, automobiles, aircraft, and buildings themselves all contain growing numbers of microprocessors that arenetworked together. the range of applications continues to expand withcontinued research and development. aircraft manufacturers are alreadyexamining the possibility of incorporating processing devices into thewings of aircraft to allow finegrained control of airflow and, hence, liftand drag; health researchers are investigating microscopic sensors thatcould traverse the bloodstream, monitoring health conditions and reporting them wirelessly; consumer electronics and information technologycompanies envision homes filled with intelligent devices that can interactwith each other, homeowners, and appliance manufacturers to improvethe quality of daily life. the internet, wireless networking, inexpensivecameras, and automotive telematics can be combined to pass informationto millions of commuters in large cities so as to reduce delays, frustration,energy use, and air pollution. sensor networks can be deployed in largeagricultural areas to monitor and report on crop quality and the environment, adjusting irrigation and fertilization as necessary.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview15to some extent, the emergence of networked systems of embeddedcomputers (emnets) is simply a natural evolution of the historical trendin computing and communications technologies toward smaller, morepowerful information technology devices that have become more ubiquitous (see box 1.1). as computing has migrated from mainframe computers to minicomputers, personal computers, laptops, and, most recently,palmtop computers and information appliances, it has become more widespread and more a part of everyday life for millions. meanwhile, embedded computers have been used in automobiles, aerospace engineering,and military applications for quite some time. advances in networkingtechnologies, including the expansion of the internet and wireless communications networks, have amplified these trends by making information easier to share and increasing the amount of information that isshared.at the same time, the shift to emnets represents a radical departurefrom this lineage. while most traditional computers tend to interact directly with human operatorsñtypically accepting input through a keyboard and providing output on a visual displayñemnets will interactmore directly with the physical world. they will sense their environbox 1.1toward ubiquitous, networked computingthe vision of a world filled with large numbers of computing elements, manyof which are hidden inside other objects and networked together, is not new.trends in the miniaturization of computing and communications elements havebeen manifested for decades, leading to numerous predictions of computing power being integrated imperceptibly into daily life. one of the leading visionaries, thelate mark weiser, formerly the chief technologist at the xerox palo alto researchcenter (parc), described in the early 1990s a concept of ubiquitous computing inwhich computation would blend invisibly into the environment, much as writtencommunication has become so common a part of the physical world that littlethought is given to the technology of writing (weiser, 1991; 1993). others haveelaborated on related themes, coining terms such as pervasive computing (nist,1999) and invisible computing (norman, 1998) to describe the proliferation of information technology into myriad devices and applications. although differing somewhat in their details, these visions of the future of computing derive from a commonset of observations about the rapid pace of innovation in information technology:namely, advances in verylargescale integrated circuits (vlsi), the increasingbandwidth of wireless and wireline communications media, improvements in wireless communications technologies, and significant efforts in architecture and infrastructure. (see chapter 2 for a more detailed discussion of enabling technologies.)embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.16embedded, everywherements directly, compute necessary responses, and execute them directly.emnets will also need to operate in a highly resourceconstrained environment. there may be limited power, limited communications bandwidth, limited time, and limited memory. emnetsõ heterogeneous components will often be embedded in longlived structures, thereby makinginteroperability over time an important issue. all of the above will require new ways of thinking, not just at the input and output ends, butabout the very fundamentals of computing and communications. wayswill be needed to ensure that such systems operate reliably, safely, andpredictably; that they provide their users with necessary informationabout their current operating state; and that they can accommodatechanges in the overall system configuration or in their operating environment. in addition, emnets present new opportunities for pervasive, transparent monitoring and information aggregation while at the same timegenerating a host of privacy and other ethical concerns.1this report identifies and examines research challenges posed byemnets and provides guidance for addressing them. it addresses fundamental research issues, primarily at the system level, with some attentiongiven to components. the report recognizes that if current technology isapplied naively to emnets, the results could be disastrous. failures thatare all too common today in information technology systems (e.g., security lapses, system outages, safety problems, unanticipated performance)could have even more serious consequences. as such, this report buildson previous work by the computer science and telecommunicationsboard (cstb) in the areas of largescale systems and applications andtrustworthy networked information systems (cstb, 1999; 2000), but inthe context of emnets. it offers recommendations for organizing researchand education programs to better ensure that the challenges are beingadequately addressed.examplescharacterizing emnets precisely and uniquely is a challenge. tofacilitate this task, the committee decided to introduce three examples,which help to show the variety of systems this report is addressing. manyexamples could have been chosen to illustrate emnets, so those selected1bill joyõs wideranging discussion of robotics, nanotechnology, and genetic engineeringand their ethical and social concerns (joy, 2000) attracted attention because of the authorõsreputation as a technologist. but only a little imagination is required to link emnets toscenarios that would call for considering ethical and social issues while the technologies areunder development.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview17should not be seen as canonical in any sense. moreover, it is virtually acertainty that emnets will be used in ways that are currently unforeseeable. these examples, which are very distinct applications, should beviewed as representing the potential of emnet technology. all threecombine a number of separable subsystems that would normally be developed independently, preferably with an eye toward interoperation andintegration over time. they all offer significant functional and economicincentives for deployment and proliferation. in addition, they exemplifytensions between often opposing forces: complexity and comprehensibility, information aggregation and privacy, and safety and autonomouspower.notwithstanding all of the above, these examples can be seen as demonstrating, in broad strokes, the potential of emnets at several differentscales. the first example discusses automotive telematics, where the mainlocus of interaction is a vehicle. the second describes precision agriculture, where the emnet is distributed over a wide area. the final exampleincorporates individuals, vehicles, and the surrounding environment intoa comprehensive defense systems scenario. a further complication arisesthat increases the already formidable challenges presented by emnetswhen one imagines the experiences of an individual who òjoinsó andsubsequently òleavesó various emnets while moving through space andtime. whether location or domainspecific, emnets will be connected toeach other for certain functions, adding yet another level of complexity.example 1: automotive telematicsit should come as no surprise that the modern automobile is already arolling network of embedded computers. in model year 2001, cars havebetween 20 and 80 microprocessors controlling everything from the running of the engine to the brake system to the deployment of the airbags.these numbers are expected to grow dramatically over the next severalyears as automobile manufacturers look for ways to transition electromechanical control systems into electronic control systems. microprocessorsalso control the windshield wipers and the door locks and are increasingly used in the entertainment systems. these microprocessors are rarelyselfcontained; almost all interact with other microprocessors in the automobile through a network, which can be one of half a dozen proprietaryor industryspecific designs.currently, these networks are highly engineered systems in whicheach microprocessor and the overall network are carefully designed as awhole. in fact, there are generally two distinct networks in todayõs cars.the first is the network of safetycritical components, such as those thatcontrol the engine and the braking system. the second, often called theembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.18embedded, everywheretelematics system, controls nonsafetycritical functions such as the entertainment systems, door locks, and trunk release. these two networks arecompletely separate, ensuring that the safetycritical portions of the carcannot be compromised by the telematics components.however, as the complexity of the network and the functionality ofthe networked elements grows, the ability to approach the networks assingle, fully engineered, closed systems is being strained. in particular, anumber of forces work against the fully engineered, closed systems approach, including the following:¥the disparity between the design cycle of the car and the design cycle ofthe embedded components. a car takes approximately 5 years to design, andthe embedded components are among the first things designed into thecar. this has meant that cars contain embedded systems that are significantly less functional than the systems available at the time of the carõsmanufacture.¥the desire to allow easy upgrade, either by the manufacturer (in the caseof safetycritical components) or third parties (in the case of telematics), over thelifetime of the car. such flexibility generates cost savings, as the recall of apart can be tremendously expensive, and also reflects the reality that thelifetime of a car is now 8 to 10 years rather than 3 to 5, so building a postpurchase income flow has become important.¥the desire to allow owners to integrate their own devices into the auto.such devices include personal digital assistants (pdas) and cellularphones, which can be made more useful (by, for instance, integrating theaddress book in a pda with the navigation system in the car) or safer (by,for instance, integrating the cell phone with the speaker system of the car,making the phone handsfree) if such integration is possible.there is also pressure to break down, to some degree, the strongdivision between the safetycritical network in the car and the telematicsnetwork. many automobile manufacturers want to move away from thecurrent model of diagnostics to a model of prognostics, which allowsthem to monitor their products for upcoming faults and allow those faultsto be corrected before they happen. for this to be possible, there needs tobe a way for the information gathered by the safetycritical parts of theautomobile to be sent to the automobile manufacturer. one obvious wayof doing this is through the use of automated cellphone technology (separate from personal use phones) that most cars will have. currently, however, the cell phone is part of the telematics network of the car, not part ofits safetycritical network.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview19all of these possibilities are taken from current thinking about thenetwork of embedded systems in the car. the outlook for the future complicates the intraauto network considerably. the major automobile companies plan to change the car from a selfcontained network (or pair ofnetworks) into a node in a much larger network. one approach to this isgeneral motorsõ immensely successful onstar offering.2 onstar connectsthe car to the manufacturer, allowing the latter to monitor emergencysituations and give ondemand help to the occupants of the car. not onlyhas this service provided gm with a market differentiator, it has alsoallowed the company to begin to provide a very profitable subscriptionservice, giving it a revenue stream that is less prone to the fluctuationstraditional in the automotive market. the notion of the automobile as amobile, networked recipient of content is an outgrowth of this seeminglysimple beginning.as envisioned by the automobile companies, the driver of a car willbe able to get ondemand directions to anywhere desired, including thoselocations that are contextually based. from the carõs current position, thedriver will be able to get directions to the nearest restaurant of a particular type, or the closest automatic teller machine, or an available parkingspace. the occupants of the car will be able to receive information aboutthe history of the place they are seeing or about its landmarks, or they willbe able to get ondemand video or audio stream. the car will be monitored, in real time, to support safe operation, and the driver will be informed of the maintenance needed to keep the car from breaking down.software upgrades to emission controls or safety systems will bedownloadable (obviously at some safe time) to where the car is, making itunnecessary to take the car into the shop. while many of these innovations seem farfetched, they are in fact being prototyped now;3 it is likelythat new advances and applications will emerge as the technology becomes widely deployed. for example, instrumented vehicles and highways could provide data that would inform a traffic management or control system. emergency vehicles could be networked to traffic lights toadjust their timing and facilitate passage through crowded areas. undoubtedly, many new applications of automotive telematics systems connected to larger emnets are as yet unforeseen.2for more information, see <http://www.onstar.com/>.3a presentation to the computer science and telecommunications board by akhtarjameel of daimlerchrysler research in january 2001, òthe future of vehicle computing,ótouched on many of these issues.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.20embedded, everywhereexample 2: precision agricultureincorporating emnet technology into agriculture can be seen as alogical followon to the great advances in crop management over the lastseveral decades. fertilizers, water supply, and pesticides, among otherthings, have been experimented with and adjusted in order to learn howbest to manage crops and to increase productivity. even with these adjustments, variations in terrain (soil, elevation, light exposure, microclimates, and so on) can make solutions based on largescale averages suboptimal, especially for highly sensitive crops such as wine grapes andcitrus fruit.this is where emnets, in the form of precision agriculture,4 are beginning to play a role.5 precision agriculture features the deployment ofsensing and actuation at a much finer and more automated granularitythan has been available before. this will allow adjusting water, fertilizer,and pesticides to the minimal levels needed for a particular local area,resulting in better yields, lower costs, and less pollutioncausing runoffand emissions. the data collected will be analyzed later on (imagine aviticulturist searching for the best places to cultivate grapes for the nextvintage).adaptation to changing environments will be a crucial component inemnets used for precision agriculture. sensors and actuators can be usedto very precisely control the concentrations of fertilizer in the soil, basedon information gathered from the soil itself, the ambient temperature,and other relevant environmental factors. while there are models forhow much fertilizer and water are needed for crops under various conditions, those models are imperfect, mainly because not enough accuratedata have been collected across diverse agricultural systems. emnets canprovide that data. incorporating feedback into the system through theuse of sensors, actuators, and adaptation will allow a more finegrainedanalysis that could adjust flow rate and duration in a way that is informedby local soil conditions and temperature. one can imagine the use of suchprecise information in particularly sensitive crops. sensors that are ableto monitor the crop itself (sugar levels in grapes, for example) to providelocationspecific data could prove very effective. emnets will need to beadaptive, multimodal, and able to learn over time in order to solve theproblems described above.information gathered by sensor networks in a field could be used to4for more information on precision agriculture, see banr (1998).5see li and wang (2000) for a description of a wireless sensor network for precisionagriculture.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview21guide planting for maximum yields, in addition to monitoring and reporting on the status of the crops. a future application of emnets mightbe to deploy sensors for the early detection of bacterial development incrops or viral contamination in livestock. another application might beto employ emnets to monitor flows of contaminants from neighboringareas and send alerts when necessary.emnets are also being extended to livestock management. currentcomputerized feeding systems for dairy cattle, for example, can adjustfeed and vitamins for individual animals. networked sensors, includingswallowable sensors, to monitor amounts of food eaten, activity/exercise,and vital signs will provide valuable health information about individualanimals and the state of the herd as a whole.these systems are moderately engineered (along a spectrum fromhighly engineered to ad hoc), but the need to work under a wide range ofunpredictable environmental conditions, as well as to interact with farmvehicles and new elements of the system as they become available, arguesfor adaptability within the emnets at multiple time scales.example 3: defense systemsemnet applications to defense systems include battlespace surveillance, monitoring the condition and location of materiel and vehicles,monitoring the health status of personnel, and making information accessible to individuals in the field.6 as efficiency and speed of deploymentbecome more important, the requirements for network access to assetsand information become more important too. each of these applicationareas is discussed briefly below.distributed emnets in the battlespace will provide seismic, acoustic,magnetic, and imaging tactical information. emnets can be dispersed byairdrop, inserted by artillery, and/or individually placed by a team securing a building. military forces are expected to exploit emnet battlespacesurveillance systems to provide capabilities for battlefield shaping andforce protection. battlespace shaping capabilities restrict the movementof an opponent or constrain its advance or retreat. emnets can providethe critical threatidentification information that enables remote engagement of targets and the halting or redirection of opponent forces. forceprotection capabilities provide security on the battlefield and act as aforce multiplier. emnets enable a new forceprotection capability byproviding threat identification and early warning of an infiltration or6emnet research in these areas will probably prove particularly relevant for darpaõsfuture combat systems program. see <http://www.darpa.mil/fcs/index.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.22embedded, everywherethreatening advance. force protection may be implemented by distributing emnets around a protective perimeter or deploying them in advanceof maneuvering troop formations. emnets may allow a small force tooperate with the security of a larger force by exploiting densely distributed, autonomous emnet detection networks.emnets offer a new approach to battlespace surveillance. in the past,battlespace sensor systems were large and required large teams fordeployment. as expensive assets, they were deployed only sparsely.emnets, in contrast, involve less expensive, even disposable, devices thatmay be deployed in large numbers with a high spatial density. thisallows the typical emnet sensor to detect stronger signals from threatsthan the signals detected by more sparsely distributed sensors, facilitating a response to those threats. because they are closer to the targets theyneed to detect, emnets also engage fewer threats within their area ofregard, simplifying signal identification and data association. emnetscan exploit their networking capabilities to cooperatively identify andtrack the motion of threats.emnets in battlespace situations must be highly interoperable andable to accept data from and provide data to other systems. data fromvarious kinds of sensor platforms (airborne, vehiclemounted, groundbased, and so on) will need to be integrated and processed. combininglocally derived information with information from remote locations willbe important, enabling updates to situational descriptions on a very shorttime scale. in addition to accruing and processing the data, emnets willneed to make such data readily accessible to personnel, requiring gooduser interfaces. such dissemination might involve airborne relays or satellite communications, making communications another major challengefor emnets in the application. these communications will need to remain secure while resisting jamming, detection, and interception. challenges are also faced in the implementation of distributed computing foremnets that must operate at low energy dissipation while maintaining anetwork for exchanging the appropriate threat signal characteristics.in addition to battlespace shaping and force protection, emnets willalso be used for asset management. defense forces rely on diverse vehicles, weapons, and equipment that require a missioncritical, high levelof availability.7 emnets enable distributed, conditionbased monitoringfor detecting wear and faults in vehicle chassis systems and vehicle powertrains. applications include wheeled and tracked land vehicles androtary and fixedwing aircraft. prototype emnet networks have ap7large quantities of equipment in many locations create significant logistical challengesthat may also benefit from the use of emnets.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview23peared in conditionbased monitoring onboard navy ships for powerplant monitoring. emnet conditionmonitoring applications require compact, lowpower devices that measure and locally evaluate vibration andtemperature signatures from rotating and reciprocating equipment.emnet monitoring also applies to battle damage assessment and firesafety. the challenge of battlespace monitoring for emnets includes theimplementation of lowpower, compact devices capable of both highperformance sensing and signal processing, along with networking, selfconfiguration, adaptation, and collaborative sensing, to exploit the distributed processing capabilities. all are needed to achieve unattended,robust, longlived systems.emnets will also be applied in more tightly coupled systems, such assmart materials and structures. collections of sensors and actuators onairplane and submarine hulls will enable new modes and efficiencies ofoperation by adjusting the physical properties of the surfaces to environmental and task conditions. in addition to developing the requisite memscomponents, this application will require many of the developments described in this report, from computational models to distributed coordination and safety evaluation.emnets also appear in health status monitoring of personnel. animportant emerging requirement is for technologies that provide troopswith personal location capabilities to enable security within a platoon andthat monitor health, detect injury, and provide notification of injury. here,emnets must be wearable and integrated into existing or dedicated networks. the technologies may also be used to detect the use of biologicalor chemical warfare agents. challenges include the need for security andlowpower operation and the support of multiple biomedical sensor channels. ultimately, the combination of emnets for surveillance, conditionmonitoring, and personnel health status will enable a new tasking, control, and safety capability accessible at multiple command levels.finally, making all of the information described aboveñalong withother dynamic, missionspecific informationñreadily accessible to thewarfighter is a task for which emnets as described throughout this reportwill be well suited. vast amounts of information are available in battlespaces that, put to use, could increase the survivability and effectivenessof warfighters. for example, sensors and wireless communications couldbe used to keep track of the exact location of team members and enemies.providing warfighters with data on asset locations and readiness, teammembersõ health and capabilities, and overall battlespace information inan accessible, manageable fashion could greatly increase their capabilitiesand effectiveness.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.24embedded, everywhereunderstanding networked systemsof embedded computerswith the above examples as starting points, this section describessome of the features of emnets and issues related to them that should bekept in mind when developing a research agenda. without attempting arigid definition of networked systems of embedded computers, this report discusses systems with the following general characteristics:¥multiple interacting nodes. emnets involve the interaction of morethan two embedded computing elements or nodes. the systems of greatest interest are those in which the number of interacting elements is verylarge (for example, on the order of thousands of nodes).¥embedded in control systems operating without human intervention.emnets are intended to operate largely without human intervention.although they may provide information to human operators and requiresome degree of supervisory control, they are often part of an automatedcontrol loop (that is, the system adjusts itself when necessary and directscomponent behavior), and they tend to interact more directly with theirenvironment than traditional computing systems and to assume a highdegree of autonomy. computation can be local (at the nodes/elements)or centralized or somewhere in between, with localized or regional levelsof hierarchical control. in any case, they tend to be tightly coupled to thephysical world. they are therefore usually located close to the elementsthey monitor or control, and they operate in real time.¥purpose other than general computing and communications. the computing elements in emnets are themselves components of larger systemswhose primary purposes are other than generalpurpose computing orcommunications. the elements do not form a generalpurpose computereven though particular components of the system may be general purpose. the individual computing elements help to monitor and control thelocal system, acquiring information from a variety of sensors, implementing changes through a variety of actuators, making decisions locally, and/or possibly relaying processed information to decision makers.¥natural or engineered contexts. emnets may be incorporated intoeither natural or engineered systems. the emnets themselves are engineered, but they may be deployed in a natural system such as the localenvironment to provide information for scientists, urban planners, or military commanders. they may also be deployed as part of a larger engineered structure such as an aircraft or building.within systems that meet these criteria there are useful distinctions tobe made. in particular, the following dichotomies characterizing howembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview25emnets, their requirements, and the applicable technical solutions differwill often be referred to:¥energyconstrained nodes versus nonenergyconstrained nodes. energyconstrained devices are those that are not tethered to an easilyreplenishable energy source and have a small form factor (size, shape,and total volume), as well as those that exist where heat dissipation is anegative factor. small form factor implies a fundamental limit on batterysize, which in turn sets a fundamental limit on the number of bits that canbe processed and/or communicated by the device during its entire lifetime. other energy sources can be exploited in some cases, but in thegeneral case components will rely on traditional battery technology forthe foreseeable future. in this context, energy is the one system resourcethat is not easily renewable. memory can be reclaimed and bandwidthconsuming data can be delayed to a time when congestion has dissipated,but once a unit of energy has been used, it cannot usually be replenishedwithout intervention beyond the scope of what software can accomplish.when energy is a constraint, communication is often the major consumerof the energy. this, in turn, will have significant influence on the waysystems are designed.¥fixed topology versus flexible topology. virtually all the systems considered here must continue to operate in the presence of node arrival,departure, and failure. that is, configuration will not remain constantthroughout a systemõs lifetime. however, some of the systems are dominated by a fixed topology, whereas others are dominated by a flexible andvariable topology that changes significantly during the course of regularoperation. a fixed topology facilitates testing and repeatable deployment. flexible topology introduces a new dimension of variability underwhich a systemõs performance must be verified.¥safetycritical applications versus nonsafetycritical applications. someof the systems described will be used in safetycritical applications. whenthese systems malfunction, property can be damaged irreversibly andpeople harmed. the implications for designing and engineering suchsystems are fundamentally different from those for systems in which malfunction produces only degraded speed or visual quality, or even economic harm. further, many emnets will utilize general networking protocols. these protocols were originally precluded for safetycriticalenvironments such as aircraft, but newer tools and techniques are startingto emerge and could be greatly enhanced by appropriate research.¥highly engineered versus unconstrained, ad hoc systems. some emnetsare highly engineered systems, such as those used in ships and aircraft toperform particular functions, like monitoring and controlling the performance of the engine. these are more traditional applications of embeddedembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.26embedded, everywherecomputing, and they have been the subject of considerable engineeringdesign work. they must, in general, meet strict criteria for system performance, reliability, and safety. they are highly constrained in that systemelements are determined during the design and implementation of thesystem and the configuration of the system is fully controlled. the addition of networking into such systems allows the embedded computingdevices to be remotely upgraded (e.g., new code can be downloaded tothem to provide new or improved capabilities) or to relay information toa centralized source (e.g., for monitoring performance or use of resources).it also allows information to be shared among embedded devices to aid inlocal (and global) decision making. other emnets are unconstrained, adhoc systems that have limited a priori system design and limited (or no)control over the overall system configuration, such as in sensor networksdeployed in battlefield situations or in public smart spaces.8 newelements can be introduced into such systems by a number of actors/participants, and the systems will automatically reconfigure. such systems can be expected to have a high degree of heterogeneity in the computing elements they contain and a dynamic structure as elements enterand leave the network. a particular challenge is ensuring that the overallsystem can meet global levels of performance as components are added toor removed from the system. there are, of course, emnets that fallbetween the highly engineered and completely ad hoc categories.how emnets differ from traditional systemsemnets are a composite technology, built as aggregations of softwareand hardware elements. any given part of a network of embedded computers will look familiar to technologists: the networking constraints willfind partial solutions in todayõs literature; the software controlling thenodes will start out as a variant on todayõs realtime control code; thehardware at the nodes will be developed from todayõs best microcontrollers, mems sensing devices, and interconnect transceivers. however,as the rest of this report makes clear, incremental improvement to todayõssolutions will not suffice to realize the full potential of emnets.the development of packetswitched networks was in a similar nascent period in the late 1960s and early 1970s. few at the time could havepredicted the development of this basic technology into todayõs internet,8smart spaces are home or work environments containing information appliances, embedded computers, sensors, cameras, and microphones that allow people to perform tasksefficiently by offering access to information and assistance from computing technologythrough a variety of input devices and by monitoring on the part of the space itself.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview27a worldencompassing, ubiquitous communication network that has already eclipsed the telegraph and telephone in the variety of activities andservices it supports. by the 1990s, its processing, routing, and interconnection aspects were becoming well understood. the extrapolation toweb sites, search engines, portals, and so on was by no means obvious,even to people working in related fields. the power, universality, andpotential of emnets will stem from combining these components into asystem that is more than the sum of its parts. the dangers and difficultieswill likewise emerge once the components have been combined, but theywill not be immediately visible from any particular piece.while many of the solutions found for emnets might apply to otherkinds of systems to one degree or another, what is unique about theproblems posed by emnets is the set of constraints on their solutions,several of which are discussed below. while one or even more of theseconstraints might be present for a traditional system, the combination iswhat poses one of the largest research challenges for the development ofemnets. more specifically, emnets present the challenge of buildinglarge systems that are¥tightly coupled to the physical world and each other in a¥resourceconstrained environment that will¥persist for long periods of time while consisting of¥many interacting components and being¥used and interacted with by nonexpert users.research needs to turn, as it did at the corresponding time for packetswitched networks, to developing the appropriate models, abstractions,and methodologies that will make it possible to build these systems on alarge scale, for a wide variety of uses, by a necessarily large collection ofpeople. these factors are elaborated on below.emnets are tightly coupled to the physical worldas noted previously, a major distinguishing characteristic of emnetsis that they interact strongly with the physical world. one emnet mightcontrol all of the major systems of a large battle cruiser. another mightcontrol tens of thousands of actuators based on tens of thousands of sensors to maximize the efficiency of a farm (banr, 1998). they sense thephysical world (e.g., its temperature, air quality, soil factors, or enginevibrations), they communicate and process those sensory data, and in realtime they cause physical actions to be taken. each node of an emnetmight be responsible for, say, one square meter of a farm. in the event ofa onenode failure, data from geographical neighbor nodes might beembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.28embedded, everywhereinterpolated, so that the affected square meter of farmland does not gounattended until repairs can be made. accordingly, the precise geolocation of that node is important in a way that is seldom true of todayõsnetworks.an emnet (hypothetically) controlling a ship will necessarily be heldto a much higher standard of performance and trustworthiness than, say,a traditional local area network (lan) in an office whose primary function is to provide intraorganizational communications capability. if sucha lan goes down, productivity is lost and users become disgruntled.the loss of a shipõs control at an inopportune time due to failures in anemnet physically coupled to critical control mechanisms could result in acollision. this physical coupling of many emnets means that safety considerations play a paramount role.emnetsõ tight coupling to the physical world also raises issues ofusability. individuals interacting with emnets are not likely to think ofthemselves as interacting with a computer or computational device butrather with the objects to which emnets are coupled (e.g., a sprinklersystem as opposed to a digitally controlled irrigation device.) this hasbroad ramifications for usability research and for safety, reliability, andsecurity as well.emnet nodes are often resourceconstrainedemnet nodes are likely to be untethered so that they can be deployedin very close proximity to, or even embedded within, the physical systems they are designed to support. this factor places important constraints on the emnet nodes, organization, system policies, and hardware. untethered and/or mobile computing elements are usually batteryoperated, or perhaps they are very low power and run from solar panels.the limited amount of raw power available will have a substantial effecton all aspects of emnets, from the amount of computation that can beperformed on a local physical sensing node to how much bandwidth canbe achieved, across what distance, by the emnet node input/output links(e.g., radio). emnet nodes may also have important physical constraints,such as allowable thermal dissipation or radio bandwidth limits. forexample, an emnet consisting of a large set of detectors deployed over anarea of countryside will have to limit overall radio transmissions in orderto avoid massive interference with other emnets, normal communications traffic, and local regulations. emnets that include sensors carriedby the human body will have to be thermally cool to be practical. thereare other kinds of resource constraints aside from power. emnet components may have limited memory and/or bandwidth available to them.energy constraints may limit the amount of storage available. suchembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview29resource limitations place constraints on the amount of computation andcommunication that can be accomplished.emnetsõ long lifetimes the artifacts within which emnets are embedded will undoubtedlyhave very long lifetimes compared with the lifetimes of the rapidly changing technologies that support the emnets. just as it has taken many yearsto upgrade the basic telephone wiring systems to homes, despite growingdemand for bandwidth, emnets deployed in buildings, on farms, or inthe countryside will face this same problem. the longevity of emnetswill thus have to be taken into account during design, as the basic technology will continue to evolve and the previously deployed system willeventually have to interoperate with the new technologies. as networked,embedded devices are scattered throughout the environment, their usefultechnological life will be determined by mooreõs law. older devices mayconsume too large a share of valuable resources, so mechanisms for identifying, locating, and replacing or upgrading them will be necessary. theupgradability of todayõs computing systems is a marketing feature, butfor emnets it is a basic requirement.the uses to which emnets will be put may vary considerably overtime. a system may have components that are used to measure physicalproperties and provide raw data that will be elaborated by other components or other systems. it is not always possible in advance to predictwhat the data will be used for.9 a change in the application, or in theoverall computing structure, may take place while the system and itscomponents persist. in addition, it is very unlikely that entire emnetswill be replaced; instead, individual components may be replaced, upgraded, or decommissioned from time to time. the system lifetime islikely to far exceed the component lifetime.complicating longterm planning, emnets will have to interface witha wide variety of sensors, network gateways, displays, actuators, powersources, antennas, and other emnets. this heterogeneity, which is itself amajor challenge to designing economical emnets, is multiplied by thelongevity requirement. good interface standards will play a part in solving hardware interconnectivity, but striking a good compromise amongcost, performance, and feature set has always been problematic. solving9as an example, consider city buses with sensors that can provide information abouttheir location. this information could also be used to turn the buses themselves into sensors for traffic congestion. such technology is being developed in several localities (see, forexample, <http://www.gcn.com/archives/sl/1998/july/1b.htm>).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.30embedded, everywherethe analogous problems in the software domain may be even moredifficult.emnet size and scale are significantnetworked systems of embedded computers can grow extremelylarge. it is easy to imagine deploying sensor technology with which onecould sense various conditions within buildings or the environment; suchnetworks might embody thousands or tens of thousands of nodes. in fact,building control systems with tens of thousands of nodes already exist.10networking many of these systems would yield systems of millions ofnodes.11 economics will allow such large systems to be built, and demand will come from many sources, ranging from environmental researchers to government regulators to the general public. military applications and battlespace emnets are also inherently large, encompassingmillions of nodes in a threedimensional space anywhere from the seabedto satellites in space.scale mattersñsystems designed to work properly at one size willoften fail at a larger (or even a smaller) size. in systems the size of theemnets being contemplated here, it is very reasonable to expect thatmany of the networking, software, and hardware solutions known atpresent will be unsuitable, or even dangerous. emnets are particularlyvulnerable in this regard, because they appear at first glance to be reasonable extrapolations of current technology. the committee fears that theywill be built naively in exactly that way and, worse, that they may evenappear to work as desired for a time. the ability to predict accuratelyhow complex engineered systems will behave, especially under unusualor boundary conditions, is limited at best. emnets will stretch the abilityto analyze system behavior beyond current capabilities, making it likelythat such systems will exhibit emergent, or unexpected, behaviors.1210see for example, products made by the echelon corporation, <http://www.echelon.com/>.11with just a little more imagination, systems of billions of nodes can be conjured.12emergent behavior is often described as behavior of a whole that seems more organized and purposeful than that of its component parts. this notion often arises in thecontext of complex systems, where there are many pieces interacting with one another suchthat the study of individual pieces in isolation is insufficient to predict the behavior of theentire system (rapaport, 2000).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview31emnet users are not system expertsemnets will increasingly be used by people who have little or nosystems training. modern aircraft cockpits have extensive computerbased systems with which the pilot must interface. even with extensivetraining, pilots (who are expert users of the systems they operate) makeerrors a disturbing share of the time.13 an emnet that requires extensiveuser training will have failed in its fundamental promiseñcomputingsystems must adapt to users, not the other way around. yet combiningextremely complicated systems with casual or inexperienced users is apotential recipe for disaster. if history is a guide, such users will drive thesystem into operating conditions that were never considered by the system designers, they will misunderstand what the system is trying to tellthem about its own health, and they will put themselves inadvertently atrisk by trusting the emnet when it is no longer trustworthy. an additional complicating factor is that people will less often interact withemnets per se than with the devices and objects within which emnetcomponents are embedded. peopleõs expectations of objects in their environment are likely to be very different from their expectations of explicitly computational or communication devices such as pcs or cell phones.the computer industry has a very poor record overall of designing effective user interfaces, much less interfaces that, if misunderstood, can stillprevent danger to the users themselves (cstb, 1997; laurel andmountford, 1990; norman, 1998). designing for casual interaction (asopposed to explicit use) is arguably an even larger challenge. the changeof attitude required of the system designers is profound and infrastructural, and attitudes will need to be quite different from the attitudesthat created todayõs successful networks.why a new research agenda?this report explores how the characteristics of emnets demand newkinds of research. it examines the different kinds of applications andconfigurations in which emnets may be deployed and identifies technical challenges that have not heretofore been addressed by the researchcommunity or resolved in a way that is amenable to emnets. the report13the software in hightech avionics systems is extremely complex, and most trainingprograms now concentrate on teaching pilots how to use the automation but not necessarilyhow the automation works. existing training material is based on a proceduralized, operational model with little attention to causality or the structure of the underlying system. infact, there have been suggestions that a limiting factor in aircraft automation design may bethe level of complexity a pilotõs mind can maintain and readily access (billings, 1996).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.32embedded, everywhereattempts to be as far reaching as possible, identifying research challengesin a broad range of areas. the goal is not to specify particular technologies or solutions that need to be developed but to articulate fundamental,underlying research problems that need to be addressed. the areas identified are therefore candidates for fundamental exploratory research thatwill try as much to understand the problems as to solve them.to the extent that emnets represent a continuation of longstandingprogress in it, it is reasonable to ask why special consideration needs tobe paid to the research needs for emnets. in a broad sense, the potentialimpact of emnets themselves is justification for an emnetspecific nationalresearch agenda. but as described previously, emnets present uniquetechnological challenges as well. research into developing and understanding these systems is vital, for the reasons outlined below.as emnets mature and extend into even more areas of society, research will be needed into ways of thinking about designing systems.one can envision systems that are selfmonitoring and selfhealingñthatis, systems that provide active agents to monitor possible problems (aswell as their own health) and take appropriate actions, such as to defendagainst denialofservice attacks or attempted injection of malicious code.at the same time, continued advances will be needed in enabling technologies. research will also be needed (1) to make emnets easy to construct, (2) to make emnets selfconfiguring and adaptive, (3) to ensuretheir performance and safety, and (4) to make them easy to use. theseresearch areas involve systemlevel issues that arise from the interconnection of large numbers of longlived information processing devices managed by users who are likely to be experts in a particular applicationdomain but not necessarily in emnet technology. these users will needto know not just whether the system is working or has failed, they alsoneed to know how close to its safety margins or how healthy the system isso they can make intelligent decisions on whether to use it or take itoffline and repair it. while work has progressed in many of these areasover the past decade, it has not generally occurred in the context of embedded computing. clearly, a number of familiar topics will need to bereexamined, and new topics will need to be addressed.the potential benefits of emnets are accompanied by risks that maybe exacerbated by the emnetsõ very pervasiveness and by the fact thatthey may be invisible to most who interact with them. the creation anddistribution of vast amounts of information about people creates privacyconcerns. as emnets become increasingly critical to our communication,transportation, power distribution, and healthcare infrastructures, failures and security breaches will be increasingly dangerous. by the timeemnets are broadly deployed, it will be too late to call them back easily.therefore, it is critical that we study these systems now, in order to mitigate the risks as much as possible and maximize the benefits.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview33as this report documents, the technological research issues that areimportant to emnets are not unique in and of themselves. issues ofscalability, adaptation, reliability, safety, and performance have all beenfaced to some extent by other it systems and have been addressed byresearch in the more general computing and information technology arenas. what differentiates emnets and necessitates a new research agendais that the solutions that have been worked out in areas for more generalcomputing and information technology systems will not work foremnets. existing solutions often make a number of assumptionsñamongthem: that energy is readily available, that there is sufficient computingpower to allow various layers of abstraction, that the computational elements are generally in static relationships with respect to the physicalworld, that bandwidth is not terribly constrained, that the computationalelements are expensive and therefore rarely duplicated, and that the computational elements are the entities that need to be identifiedñthat simply do not hold for emnets. while emnets have many characteristicsthat distinguish them from traditional systems, it is very likely that thetechniques developed to realize emnets will have enormous positiveimpact on the design of traditional systems as well; a key example istechniques for selfconfiguration (see chapter 3).it is important to note that networked systems of embedded computers will be and are being implemented, even without the benefit of additional research. some of these may actually succeed, and others mayappear to have succeeded, at least for a time. however, if the maximumbenefits are to be gained from emnet technology at minimum overallrisk, much research is needed. it is extremely important that the researchcommunity take the lead in this area if there is to be any hope of significant impact. once systems are established, it is incredibly difficult toupgrade or update them, as has been the case with pcs and the internet.designing and deploying them well initially will probably be more costeffective in the long term, and if the research community can, in a timelyfashion, articulate a notion of what is more correct, efficient, secure, safe,reliable, and so on, companies may well adopt it. once they are deployed, though, history suggests that it will not be possible to effect significant changes or upgrades. it is therefore critical to start addressingthe challenges presented by emnets. specific research recommendationsare provided throughout the remainder of this report.what this report does not dothis report is intended to be broad and comprehensive, but there areseveral topics it does not, by design, treat in depth. these include sensorand actuator technologies that might be used as elements within an emnet(especially within a sensor network); ethical and policy issues associatedembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.34embedded, everywherewith different applications of emnets and the use of the data they mightcollect; particular issues of commercialization and market acceptance; andstandalone (as opposed to networked) embedded systems. these are allextremely important issuesñin fact, each is worth its own separatestudyñthat could not be given full consideration here in light of thecharge to the committee.advanced sensors and actuatorsthe inexorable march of siliconbased technology is making possiblethe design and deployment of extremely inexpensive, highly capable,lowpower sensors (saffo, 1997). advances in mems technology havealready made it feasible to sense odors, vibration, acceleration, pressure,temperature, and many other physical phenomena in ways that will beextraordinarily useful across a wide range of human endeavors. newsensors for sound, visible light, infrared, and extremely low light, combined with ever faster and cheaper digital signal processors, will makelargescale system sensing practical and commonplace. likewise, newmemsbased actuators, such as micromotors, will allow emnets to affectthe world in unprecedented ways. the implications of these improvingsensor technologies are profound, and this report explores many of them,but the technology of the sensors themselves is largely outside its scope.public policy issues there are few, if any, ethically neutral technologies. powerful technologies such as computing, especially on the scale addressed in thisreport, have the potential to be utterly pervasive in peopleõs lives. thesetechnologies will be deployed with the best of intentions, but as with allprevious technologies, an array of forces will come to bear on them thatcan be only partially anticipated. these forces will bring a correspondingarray of ethical, legal, and policy issues.the committee believes that the issues will be profound and important. they will require consideration at all levels during the conception,design, deployment, and use of large emnets. this report can offer no apriori prescription for the ethical, legal, and policy questions posed byemnets, so its focus has been purposely restricted to technological issuesand implications. however, the policy issues are numerous, important,and evident in many contexts. privacy may be at much greater risk thanat any previous time in history, security is a pressing concern when oneõsattackers can be physically anywhere, and system reliability will becomeparamount when these new systems have supplanted previous triedandtrue (and simpler) solutions such as telephones, home security systems,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview35agriculture management, and industrial automation. other issues thatwill undoubtedly arise concern intellectual property (to whom does thedata collected by emnets belong?), liability (who is responsible whensystems fail?), and the òdigital divideó (who will have access to whatkinds of systems?). there is also an important sense in which the committee believes the technology will permit the easy accretion of large systemsñthat is, that smaller, selfcontained systems will be combined in anad hoc manner to create much larger systems. the difficulties of engineering a system that is, by definition, unplanned pale in comparisonwith grappling with its ethical implications.the reader should not misconstrue the focus on technology in thisreport to mean the authors believe the policy implications are trivial orbenign. the truth is, the committee believes they deserve far more attention than can be given here if the basic task of exploring the technologyitself is also to be fulfilled. powerful technologies can be used for good orill (or both). emnets qualify as powerful technology by any definition.the ethical, legal, and policy issues must be addressed during the designand use stages of these systems. in this report the committee raises theseissues when they seem particularly pertinent to the discussion in order todraw attention to some of the farreaching implications of this technology. however, a more indepth analysis of public policy issues is urgently needed that would lead to appropriate recommendations for solving likely problems.commercialization issues, standards, business models deploying very large numbers of anything is unavoidably an exercise in both technology and economics. the technology must be inexpensive enough for large numbers of people to be able to afford it, yet it mustbe powerful enough to solve some need. and ultimately, there must beenough profit in the venture for the purveyor of the technology to develop products and support them. it is by no means a given that the besttechnology will prevail, and if there is no economic benefit (or too high aperceived risk, particularly of consequential damages), no vendors maywish to participate. for the purposes of this report, the committee assumed that the technology will be associated with large markets but thatpart of the research and development challenge may relate to loweringcosts for a given level of performance or quality. one area of uncertaintyabout emnet markets relates to instances where an emnet may have abroad public benefit that cannot be easily captured by one or more vendors. sensors that collect data on individual exposure to toxins whoseaggregation could identify the source of the pollution and its distributionpatterns are an example of an application with primarily public benefit,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.36embedded, everywhereand as in other instances of environmental technology deployment, thechief customer (or motivator of purchases by others) may be one or moregovernmental units. the environment, which is an area where there is anunderstanding of the economics and a government framework in place,may embrace relevant emnets as it has embraced other technologies. forpublicbenefit emnets that constitute new applications domains, the wayforward may be less clear and market development more uncertain. bycontrast, for emnets with inherent commercial value (such as smart officebuildings), the committee expects significant markets to develop.standards are expected to be important for emnets because of thefundamental concern about interoperability and the variety of other kindsof interfaces. a dominant producerñand, like other products, most itproducts seem to have a small number of major producers once theirmarkets matureñmay drive a de facto standard. alternatively, variousgroupsñindustry groups concerned with specific enabling technologies,applications domains that may work through trade associations or focused consortia, or groups such as those convened under the auspices ofthe national institute of standards and technology (nist) or even theinternet engineering task force (ietf)ñmay work to develop standardsthat may or may not be open. however, it is not a purpose of this reportto attempt to identify such standards.standalone embedded systems andother networked information systemsthis report emphasizes the characteristics of emnets that stem fromthe embedded, physically coupled aspects of the nodes in combinationwith the networked aspects of these systems. there are still many research challenges for standalone embedded systems, and indeed anyprogress there will have an important impact on networked embeddedsystems. networking allows innumerable new kinds of interactions. italso provides an ability to coordinate across multiple, heterogeneous devices and make use of information gathered by geographically distantactuation devices. in this report, the committee focuses explicitly on networked systems of embedded computing devices, while acknowledgingthat many of the issues that arise with standalone systems will be relevant in the networked arena as well.while the research recommendations and discussion in this reportcan and should be seen as part of a larger networking research agenda,the emphasis here is on emnets that are purposefully built to performspecific sets of tasks, as opposed to ad hoc interconnections of pdas andlaptops for generalpurpose application support. largescale societal itsystems, such as financial systems, are not included. these systems areembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.introduction and overview37engineered, like emnets, and they have processors and networking capabilities embedded in the fabric of their operation. they are not consideredin this study because the computing elements are generally not embedded in devices that have an apparent purpose other than computing andcommunications. cellular telephone systems are a particularly interesting case for definitional purposes. they are clearly engineered systems,and they clearly involve embedded processors. they are also, by theirvery nature, networked, powerconstrained, and mobileñas the cellphone moves around in the physical world, realtime handoffs are madebetween the various transceiver towers so as to keep the user continuously connected to a given phone call. cellular telephony can provide anumber of valuable lessons for the design and operation of emnets, butthere are also circumstances specific to cell phones that the committeebelieves will cause some of its solutions to be inapplicable to the kinds ofemnets anticipated here. this report tries to carefully distinguish theaspects of cell phone technology that are relevant to emnets from thosethat are not.organization of this reportthe remainder of this report elaborates on the themes introduced inthis chapter. the report can be read as a progression from very concreteissues involving component technologies such as chips and wireless communications all the way to the abstract computational models that will beused to reason about these systems. chapter 2 examines several enablingtechnologies without which emnets as they are described here would notas easily or as flexibly come to pass. it discusses component technologiesused to construct emnets. readers who are interested in learning aboutthe larger systems issues related to emnets should feel free to movedirectly into chapter 3, which explores selfconfiguration and adaptivecoordination as these concepts pertain to emnets and how emnets organize themselves and respond to changes within the environment and thesystem. in other words, chapter 3 examines how the component technologies in chapter 2 should be arranged to form an emnet and whatkinds of technologies will be needed to achieve this. chapter 4 moves upanother level and examines the features that emnets will need to have. itexplores trustworthiness of emnets, including the issues of safety, reliability, security, privacy, and usability. chapter 5 examines the need forbetter kinds of abstractions and computational models to describe andanalyze emnets that incorporate the features described previously. finally, chapter 6 considers the current research infrastructure and how itcould be adjusted to better address the challenges that emnets present.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.38embedded, everywhereit outlines several broad areas in which research is needed and makesrecommendations to various federal funding agencies.referencesbillings, charles e. 1996. aviation automation: the search for a humancentered approach.mahwah, n.j.: erlbaum.board on agriculture and natural resources (banr), national research council. 1998.precision agriculture in the 21st century: geospatial and information technologies in cropmanagement. washington, d.c.: national academy press.computer science and telecommunications board (cstb), national research council. 1997.more than screen deep: toward everycitizen interfaces to the nationõs information infrastructure. washington, d.c.: national academy press.cstb, national research council. 1999. trust in cyberspace. washington, d.c.: nationalacademy press.cstb, national research council. 2000. making it better: expanding information technologyresearch to meet societyõs needs. washington, d.c.: national academy press.joy, bill. 2000. òwhy the future doesnõt need us.ó wired, 8.04. available online at <http://www.wired.com/wired/archive/8.04/joy.html>.laurel, brenda, and s. joy mountford, eds. 1990. art of humancomputer interface design.new york, n.y.: addisonwesley.li, y., and r. wang. 2000. òprecision agriculture: smart farm stations.ó ieee 802 plenarymeeting tutorials, document no. 00362r0p80215lrsgprecisionagriculturesmartfarmstations.ppt.national institute of standards and technology (nist). 1999. testing and standards forpervasive computing. gaithersburg, md.: information technology laboratory, nist.norman, donald. 1998. the invisible computer. cambridge, mass.: mit press.rapaport, d.c. 2000. computer simulation studies in condensed matter physics. volume xiii,d.p. landau et al., eds. new york: springerverlag.saffo, paul. 1997. òsensors: the next wave of infotech innovation.ó 1997 tenyear forecast.menlo park, calif.: institute for the future.weiser, mark. 1991. òthe computer for the 21st century.ó scientific american (september):94104.weiser, mark. 1993. òsome computer science issues in ubiquitous computing.ó communications of the acm 36(7):7583.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.392enabling technologiesto understand the forces shaping networked systems of embeddedcomputers it is useful to look at some of their underlying technologiesñthe devices used to compute, communicate, measure, andmanipulate the physical world. the trends in these devices are whatmake emnets such a compelling and interesting research question at thistime. the current components are making large emnets feasible now,and as these components continue to evolve, emnets will soon becomeessential, even dominant, parts of both the national and global infrastructure.through the economics of silicon scaling, computation and communication are becoming inexpensive enough that if there is any value to bederived from including them in a product, that inclusion will probablyhappen. unfortunately, while these òstandardó components will enableand drive emnets into the market, without careful research the characteristics that emerge from these collections of components may not alwaysbe desirable. emnets present many new issues at both the componentand system level that do not need to be (and have not been) addressed inother contexts.this chapter provides a brief overview of the core technologies thatemnets use, the trends that are driving these technologies, and what newresearch areas would greatly accelerate the creation of emnettailoredcomponents. because the scaling of silicon technology is a major driver ofcomputing and communication, this chapter starts by reviewing siliconscaling and then looks at how computing and communication devicesembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.40embedded, everywheretake advantage of scaled technologies. in communications technology,attention is focused on wireless communications technology since thiswill be an essential part of many emnets and on wireless geolocationtechnology since geographic location is a factor in many emnets. theremaining sections review other components critical to emnets, namely,the software systems that make emnets work and mems, the new way tobuild lowcost sensors and actuators. scattered throughout the chapterare boxes that provide more details on many of the technologies discussed. readers who are already well versed in these subject areas orwho are more interested in understanding the systemslevel issues thatarise in emnets should move on to chapter 3.silicon scalingmuch of the driving force for the technological changes seen in recentyears comes from the invention of integrated circuit technology. usingthis technology, electronic components are òprintedó on a piece of silicon,and over the years this process has been improved so that the printedcomponents have become smaller and smaller. the ability to òscaleó thetechnology simultaneously improves the performance of the componentsand decreases their cost, both at an exponential rate. this scaling hasbeen taking place for over 40 years, giving rise to eight orders of magnitude change in the size and cost of a simple logic element, from chips withtwo transistors in the 1960s, to chips with 100 million transistors in 2001.scaling not only decreases the cost of the devices, it also improves theperformance of each device, with respect to both delay and the energyneeded to switch the device. during this same 40 years, gates1 havebecome 1000 times faster, and the power required per gate has droppedmore than 10,000fold. this scaling is predicted to continue for at leastanother 10 to 20 years before it eventually reaches some fundamentaltechnical and economic limit (borkar, 1999).silicon scaling continues to reduce the size, cost, and power and toimprove the performance of electronic components. reliability of thebasic electronics has also improved significantly. vacuumtube electronics were limited by the poor reliability of the tubes themselvesñfilamentsburned out regularly and interconnections were generally made by handsoldering wires to sockets. transistors were much more reliable due tocooler operation temperatures and the absence of filaments, but therewere still huge numbers of soldered interconnects. as integrated circuits1a logic gate (ògateó) is the elementary building block of a digital circuit.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies41have subsumed more and more functionality, they have also subsumedhuge amounts of interconnections that are generally much more reliablethan soldered pins on a printed circuit board.coupling this manufacturing process to the notion of a computer hasdriven a huge industry. for example, mainframe computers that occupied rooms in the 1980s now can fit on a single chip and can operate fasterand at much lower power than the older systems. the scaling of technology has not only enabled the building of smaller, faster computers, it hasmade computing so cheap that it is economical to embed computing inside devices that are not thought of as computers to increase their functionality. it is this rapidly decreasing cost curve that created and continues to expand a huge market for embedded computing, and as this sametechnology makes communication cheaper, it will allow the embeddedcomputers to talk with each other and the outside world, driving thecreation of emnets. just as electronic locks seem natural now (and soonit will be hard to imagine a world without them), it will soon seem naturalfor embedded systems inside devices that are not typically thought of ascomputers to communicate with each other.computing the ability to manufacture chips of increasing complexity creates aproblem of its own: design cost. while design tools continue to improve,both the number of engineers needed to design a stateoftheart chip andthe cost of said chip continue to grow, although more slowly than chipcomplexity. these costs add to the growing expense of the initial toolingto produce a chip, mainly the cost of the masks (ònegativesó) for thecircuits to be printedñsuch masks now cost several hundred thousanddollars. thus, chips are inexpensive only if they are produced in volumeslarge enough to amortize such large design costs. the need for largevolumes poses an interesting dilemma for chip designers, since generallyas a device becomes more complex, it also becomes more specialized. themost successful chips are those that, while complex, can still serve a largemarket. this conflict is not a new one and was of great concern at thedawn of the largescale integration (lsi) era in the 1970s. the solutionthen was to create a very small computer, or microprocessor, and use itwith memory to handle many tasks in software that had previously required custom integrated circuits. this approach really created embedded computing, since it provided the needed components for these systems. over the years the microprocessor was an essential abstraction forthe integrated circuit industry, allowing it to build increasingly complexcomponents (processors and memory) that could be used for a wide variety of tasks. over time, these processors have become faster, and they areembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.42embedded, everywherenow the key component in all computers, from internetenabled cellphones to mainframe servers.the evolution of microprocessors over the past three decades hasbeen unprecedented in the history of technology. while maintainingroughly the same user model of executing a sequential stream of instructions, these machines have absorbed virtually all of the extra complexitythat process scaling provided them and converted it to increased performance. the first microprocessor was the intel 4004, developed in 1971; ithad 2300 transistors and ran at 200 khz. a mere 30 years later, thepentium 4 processor has almost 42 million transistors and runs at 1.7ghz.computer architects have leveraged the increased number of transistorsinto increased performance, increasing processor performance by overfour orders of magnitude (see box 2.1).growing complexityincreasing processor performance has come at a cost, in terms of boththe design complexity of the machines and the power required by thecurrent designs (on the order of 10 to 100 w). the growing complexity istroubling. when does the accumulating logical complexity being placedon modern integrated circuits cause enough errors in design to begin todrive overall system reliability back down? this is not a trivial concern inan era where volumes may be in the tens or hundreds of millions andfailures may be life threatening. another problem with the growing complexity is the growing cost to design these machines. new microarchitectures such as that for intelõs pentium 4 processor require a design teamof several hundred people for several years, an upfront investment ofhundreds of millions of dollars.also of growing concern is the fact that continuing to scale processorperformance has become increasingly difficult with time. it seems unlikely that it will be possible to continue to extract substantially moreparallelism at the instruction level: the easytoreach parallelism hasnow been exploited (evidence of this can be seen in figure 2.1), and thecosts in hardware resources and implementation complexity are growingout of all proportion to additional performance gains. this means that theimprovement in instructions per clock cycle will slow. adding to thatconcern, it also seems unlikely that clock frequency will continue to scaleat the current rate. unless a breakthrough occurs in circuit design, it willbecome very difficult to decrease clock cycle times beyond basic gatespeed improvements. overall microprocessor performance will continueto grow, but the rate of improvement will decrease significantly in thenear future.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies43simpler processors up to this point the focus has been on the highest performance processors, but technology scaling has also enabled much simpler processorsto have more than sufficient performance.2 rather than adding complexbox 2.1communication is costly in complex designsthe dominant technology used to build integrated circuits is complementarymetaloxide semiconductor (cmos) technology. as the integrated circuit shrinksin size, the characteristics of the basic transistors improveñthey speed up. historically the speed of a basic cmos gate has been roughly proportional to its size.this performance increase will continue, although various problems might slow therate of improvement in the future (sia, 1999).in addition to gates, the other key component on an integrated circuit is thewire that connects the gates. the scaling of wires is more complex than that of thegates and has led to some confusion about how the performance of circuits willscale in the future. as technology scales, the delay of a wire (the length of time ittakes for a signal to propagate across the wire) of constant length will almostcertainly increase. at first glance this seems like a huge problem, since gatedelays and wire delays are moving in opposite directions. this divergence has leda number of people to speak of wirelimited performance. the key point is, astechnology scales, a wire of a given length spans a larger number of gates than thewire in an older technology, since all the gates are smaller. a circuit that wassimply scaled to the new technology would also shrink in length, since everythinghas shrunk in size. the amount of delay attributable to this scaled wire is actuallyless than that of the original wire, so wire delay decreases just as a gate does.while the wire delay does not scale down quite as fast as the gate, the differenceis modest and should not be a large problem for designers.one way of viewing the wire delay is to realize that in any given technologythe delay of a wire that spans more gates is larger than the delay of a wire thatspan fewer gates. communicating across larger designs (that is, designs withmore gates per unit area) is more expensive than communicating across smallerdesigns. technology scaling enables larger designs to be built but does notremove the communication cost for these complex designs. so, scaling does notmake wire performance proportionally worse per se; rather it enables a designer tobuild a more complex system on a chip. the large communication delays associated with systems are starting to appear on chips. these growing communicationcosts of todayõs large complex chips are causing people to think about smaller,more partitioned designs, and they are one driver of simpler embedded computingsystems.2the words òsimpleó and òcomplexó are not used here as a shorthand reference to thereduced instruction set computing versus complex instruction set computing (risc vs.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.44embedded, everywherefigure 2.1 instructions executed per cycle.ity in order to wrest better performance from the chip, it is possible to usethe added transistors for other functions, or not use them at all, makingthe chip smaller and cheaper and, as will be seen in the next section, lesspower consuming. it is these òsimpleró processors that are used in mostembedded systems, since they often do not need the highest performance.for many applications, the extra complexity can be and is used to interface to the outside world and to reduce the amount of offchip memorythat is needed to reduce the system cost.as technology scales, these simpler processors have gotten faster,even if the design does not use more transistors, simply because the gateshave become faster. often a slightly more complex architecture is used,since it is now cheap enough. this scaling trend in the embedded procescisc) debates of the 1980s. they refer to the complexity of a computerõs microarchitectureand implementation, not its instruction set.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies45sor space has dramatically increased the performance of the processorsbeing deployed and will continue to do so (see box 2.2). the fastestembedded processors have a processing power that is within a factor offour of todayõs desktop processors (e.g., an 800mhz strongarm processor compared with a 1.5ghz pentium 4), but most embedded processorshave performance that is an order of magnitude worse. with increasedprocessing power comes the ability to build more sophisticated softwaresystems with enough cycles to support various communication protocols.the existence of very cheap cycles that can support richer environments isanother factor pushing emnets into existence.power dissipation power dissipation in generalpurpose central processing units (cpus)is a firstorder constraint, requiring more expensive power supplies andmore expensive cooling systems, making cpu packages more expensive;it may even affect the final form factor of the computer system.3 powerhas always been constrained in embedded systems, because such systemstypically cannot afford any of the remedies mentioned above. for example, the controller in a vcr cannot require a large power supply, cannot have a fan for cooling, and cannot make the vcr be taller than suchproducts would otherwise be.there are two major strategies for taking advantage of the benefits ofnew processor technology: maximize performance or minimize power.for each new technology, the power needed to supply the same computation rate drops by a factor of three (see box 2.3). the reason that generalpurpose microprocessor power increases with each new generation isthat performance is currently valued more than cost or power savings, soincreased performance is preferred in the design process over decreasedpower requirements.as power has become more important in complementary metaloxidesemiconductor (cmos) designs, designers have developed a number oftechniques and tools to help them reduce the power required. since incmos much of the power is used to transition the value on a wire, manyof the techniques try hard to ensure a signal is not changed unless it reallyshould be and to prevent other ways of wasting power. the power saving ranges from simply turning off the processor/system when the ma3for example, microprocessors that dissipate too much heat may require very large fansor heat sinks for cooling. if that physical package is too large, it may be impossible torealize a server in a oneunithigh form factor, drastically reducing the modularity andscalability of the design.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.46embedded, everywherebox 2.2microprocessor program performancewhile scaling technology allows the building of faster gates, it primarily allowsthe construction of designs that contain many more gates than in previous iterations. processor designers have been able to convert larger transistor budgetsinto increased program performance. early processors had so few transistors thatfunction units were reused for many parts of the instruction execution.1 as a resultit took multiple cycles for each instruction execution. as more transistors becameavailable, it became possible to duplicate some key functional units, so each unitcould be used for only one stage in the instruction execution. this allowed pipelining the machine and starting the next instruction execution before the previousone was finished. even though each instruction took a number of cycles to complete execution, a new instruction could be started every cycle. (this sort of pipelining is analogous to a car wash. it is not necessary to wait until the car aheadexits the car wash before introducing a new car; it is only necessary to wait until ithas cleared the initial rinse stage.) as scaling provided more transistors, evenmore functional units were added so machines could start executing two instructions in parallel. these machines were called superscalar to indicate that theirmicroarchitectures were organized as multiple concurrent scalar pipelines.the problem with a superscalar machine is that it runs fast as long as thememory system can provide the data needed in a timely fashion and there areenough independent instructions to execute. in many programs neither of theserequirements holds. to build a fast memory system, computer designers usecaches2 to decrease the time to access frequently used data. while caches workwell, some data will not be in the cache, and when that happens the machine muststall, waiting for the data to be accessed. a socalled outoforder machine reducesthis delay by tracking the actual dataflow dependency between instructions andallowing the instructions to execute out of program order. in other words, thechine is inactive, a technique that is used in almost all portable systems, tocareful power control of individual components on the chip. in addition,power is very strongly related to the performance of the circuit. a circuitcan almost always be designed to require less energy to complete a task ifgiven more time to complete it. this recently led to a set of techniques todynamically control the performance as little as necessary to minimizethe power used.4 two recent examples of this are the transmeta crusoeprocessor (geppert and perry, 2000) and the intel xscale processor (clarket al., 2001).4see darpaõs power aware computing/communication program for more information on work related to this problem. available at <http://www.darpa.mil/ito/research/pacc/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies47the drive for low power causes a dilemma. (see box 2.4 for a discussion of micropower sources for small devices.) while processorbasedsolutions provide the greatest flexibility for application development, custom hardware is generally much more power efficient. early work inlowpower design by brodersen et al. (1992) and others showed that formany applications, custom solutions could be orders of magnitude lowerin power requirements than a generalpurpose processor. this is unfortunate, since the economics of chip production, as described earlier, make itunlikely that most applications could afford to design custom chips unless the design process becomes much cheaper. there are a couple ofclear reasons why custom chips need less power. their main advantage isthat they are able to exploit the parallelism in the application. whileexploiting parallelism is usually considered a way to increase performachine finds other work to do while waiting for slow memory elements. whilemuch more complex than a simple superscalar machine, outoforder processingdoes expose more parallelism and improves the performance of the processor.each architectural stepñpipelining, superscaling, outoforder executionñimproves the machine performance roughly 1.4fold, part of the overall threefoldperformance improvement. figure 2.1 plots a number proportional to the numberof instructions executed each cycle for six generations of intel processors. thedata clearly show that increasing processor complexity has improved performance.figure 2.2 gives the clock rate of these same processors; it shows a roughly twofold increase in frequency for each generation. since a scaled technology comesout roughly every 3 years, 1.4 of the overall performance increase comes from thisimprovement in speed. the remaining factor of 1.4, which comes from improvements in the circuit design and microarchitecture of the machine, is illustrated infigure 2.3. this shows how many gates one can fit in each cycle and how thisnumber has been falling exponentially, from over 100 in the early 1980s to around16 in the year 2000. the decrease has been driven by using more transistors tobuild faster function units and by building more deeply pipelined machines. multiplying these three factors of 1.4 together yields the threefold processor performance improvement observed. it should be noted that recent designs, such as thepentium iii and pentium 4 chips, have not been able to achieve the increases inparallelism (instructions per cycle) that contributed to the threefold increase. thisprovides some concrete evidence that uniprocessor performance scaling is starting to slow down. 1an adder, for example, might have been used to generate the instruction address andthen reused to do the operation or generate the data address. 2in this instance, a cache is a temporary storage place for data on the chip that allowsmuch faster retrieval than accessing the data in memory.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.48embedded, everywherefigure 2.3 gates per cycle.figure 2.2 clock rate of various processors.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies49mance, since performance and power are related, one can take higherperformance systems and make them lower power. in addition to parallelism, custom solutions have lower overheads in executing each functionthey perform. since the function is often hard wired, there is no need tospend energy to specify the function. this is in contrast to a processorthat spends a large amount of its power figuring out what function toperformñthat is, determining what instructions to fetch and fetchingthem (see gonzalez and horowitz, 1996).as mentioned earlier, the downside of these custom solutions is theircomplexity and the cost of providing a new solution for each application.this conflict between good powerefficiency and flexibility leads to a number of interesting research questions about how to build the more general,powerefficient hardware that will be needed for emnets. some researchers are trying to generalize a custom approach,5 while others are trying tomake a generalpurpose parallel solution more power efficient.6 the bestway to approach this problem is still an open question.communicationas discussed earlier, it is very clear that silicon scaling has madecomputation very cheap. these changes in technology have also driventhe cost of communication down for both wireline and wireless systems.the continued scaling of cmos technology enables cheap signal processing and lowcost radio frequency circuits. this has been evident in thepast several years with the rapid expansion of wireless networking technology, first into the workplace and now into the home (e.g., wirelessethernet and apple airport), which permits laptops and tablets to have alocally mobile highspeed network connection. as the technology improves, more sophisticated coding and detection algorithms can be used,which either decrease the power or increase the bandwidth of the communication. soon it will be possible to place a lowcost wireless transceiver on every system built, a development that would seem to make itinevitable that these embedded systems will be networked. one constraint is that while bandwidth is increasing and cost is decreasing, thepower demands are not becoming significantly lower. communication5see, for example, the work being done at the berkeley wireless research center, availableat <http://bwrc.eecs.berkeley.edu/> or at the company tensilica, <http://tensilica.com/>.6see, for example, the work being done at the stanford smart memories project, availableat <http://wwwvlsi.stanford.edu/smartmemories/> or at the company arc, <http://www.arccores.com/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.50embedded, everywherebox 2.3power in cmos circuitsin cmos circuits, power is dissipated by two different mechanisms: static,resulting from current flow through resistive paths from the power supply to ground,and dynamic, resulting from current needed to change the value of a signal on awire. dynamic power is frequency dependent, since no power is dissipated if thenode values do not change, while static power is independent of frequency andexists whenever the chip is powered on. in modern cmos chips, the explicit staticpower is usually very small, and dynamic power dominates. the static power isnever zero, since some leakage current flows when the transistors are nominallyoff. today there is a tradeoff between leakage current and dynamic power, so insome highpower chips the leakage current can be quite large. this tradeoff isdescribed in more detail at the end of this box.the physical cause of dynamic power is the charging and discharging of thecapacitance associated with the wire. capacitance is a characteristic associatedwith all physical objects and depends on the shape of the wire. roughly, thecapacitance of a wire is proportional to its length. the dynamic power of a chip isjust the sum of the dynamic power of each node on the chip, which in turn is justthe energy used per cycle multiplied by the average number of cycles per second.the energy used to change the value of a capacitor is proportional to the value ofthe capacitance, c, and the square of the power supply voltage, v, used to powerthe chip. this leads to the common cv2f formulation for power in cmos chips,where f is the frequency of the chip (the number of cycles per second).if an existing design is scaled to a new technology, all of the transistorsmechanisms, which are critical for emnetsñthey are what make up thenetworking aspectsñare described in this section.wireline communicationsthe wireline infrastructure is important both because some emnetswill connect to it directly and because those using wireless may generatecommunications flows with it. the evolution of the wireline infrastructure reflects both a historic emphasis on telephony as the principal application and the rise in data communications applications over the past fewdecades, a trend accelerated by the commercialization of the internet inthe 1990s. advances in technology and the entry of new providers ofwireline services in competition with traditional telephone companieshave combined to lower costs and prices of data communication, in turnstimulating yet more demand for it.the wireline infrastructure can be divided into segments that involveembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies51different technologies and different capacities for communications. differential improvement of these segments affects the infrastructureõs ability to support the increase in communications anticipated from emnets.optical fiber has become prominent in the network backbones, and itscapacity has been multiplied by the advent of wavelengthdivision multiplexing, which exploits the ability to communicate through different colors in the optical spectrum and which was enabled by allopticalfiberamplifiers. together, these and other advances have lowered the cost perbit of transmission in the backbone and for the wireline infrastructuregenerally, although the connection from end users (especially residentialor small business users) to the backbone remains something of a bottleneck. digital subscriber line (dsl) and cable modems increase the bandwidth to the end user, but they are unevenly deployed and will probablyremain so through at least 2010.advances in silicon technology have also improved networking speedinside offices and homes. for structures with good quality wiring,become smaller by , and the wires become shorter by . this means that all thecapacitances scale by too. additionally, the power supply is generally scaled by as well, so the energy needed to switch a gate changes by the scaling factorcubed (3). if this chip is run at the same frequency, it will take about three timesless power for a 1.4fold scaling of the technology. with this scaling, the gates willrun about 1.4 times faster, so the machine could run at 1.4 times the frequency andstill cut power consumption in half. the power dissipation of highend microprocessors increases with scaling, since the additional transistors are spent on making a more complex chip (with concomitantly higher capacitance) that runs at twicethe frequency rather than the nominal 1.4 times. this overwhelms the gain byscaling, and the power of the resulting processor increases.to continue to reduce the chip power with scaling, it is very important that thepower supply voltage be scaled down. as the supply voltages scale down, anotherproblem occurs. there is a transistor parameter, its threshold voltage, that affectsboth the transistor leakage current and the gate speed. it is the voltage where thetransistor turns on. to maintain gate performance, it would be ideal for the voltageat which a transistor turns on to scale down at the same rate as the power supplyvoltage scales down. unfortunately, the leakage current through an off transistoris also set by this parameter and increases rapidly as the threshold voltage approaches 0 v. one needs a threshold voltage of around 0.4 v for low leakage. insome highperformance systems it makes sense to use a lower threshold and dealwith higher leakage currents, since the leakage power is still a small percent of thetotal power. in lowpower systems, it is often decided to take the decrease inperformance rather than increase the leakage. how to get around this interactionis an open research question.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.52embedded, everywherebox 2.4alternative power sourcesthe power requirements of emnets, like those of embedded and mobile computing environments, present difficult challenges. some emnets can, of course,be built with all mainspowered nodes. others will require portable power, butcurrent batteries will suffice (electronic watches, for example, require little enoughpower that batteries last for many years). technology such as lithium polymerbatteries already allows one to create energy sources in a wide variety of formfactors. however, emnets will stress power sources because of their need forlong operating lifetimes and higher energy density.one can envision emnets (as described elsewhere in this report) as consisting of large numbers of very small networked and often wireless components. thelow data rates and activity factors will make clever onchip powermanagementschemes and low operating voltage essential, but such approaches will not besufficient to address the energy problem. for some applications that have verylow average energy, it might be possible to extend lifetimes by extracting energyfrom the environment (light, vibration, rf), but further work is needed in this area.some work in this area has been funded by the defense advanced researchprojects agency (darpa) and the jet propulsion laboratory (jpl).other systems simply need higher energy densities than current batteriesprovide. while battery technology continues to improve, energy density changesslowly. to obtain much higher densities generally means storing a fuel and supporting a chemical reaction to generate energy. the problem with these chemicalsolutions is that they generally become more efficient when made largerñbuildingefficient small generators is hard. fuel cells are an interesting option; however,more work is needed to devise small fuel cells that are superior to batteries andadequate for mobile platforms. a more ambitious approach is to miniaturize a combustion engine/electrical generator. mitõs micro gas turbine generator project1is looking at the technology needed to create a miniature turbine 0.5 inch indiameter to create 50 w of electrical power. while there are many difficult problems with these combustion solutions, they would provide the best energy densityif successful and should be part of the emnets research program.1for more information, see <http://web.mit.edu/aeroastro/www/labs/gtl/>.ethernet speeds have been improved from 10 to 100 mbps and will continue to improve with new gigabit systems. even in homes without anynew wires, signal processing has allowed people to create a network ontop of the old phone line infrastructure. one good example of this effortis the home phoneline networking alliance.7 other contexts that may7for more information, see <http://www.homepna.org/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies53use wireline infrastructure for emnets include vehicles and smart spaces;all contexts may eventually use a mix of wireline and wireless communications.these technologies and infrastructure segments have been developing based on demand associated with conventional computers and telephones. planning has been informed by speculation about other kinds ofnetworked devices, and there has been some experience with televisionvideo being carried on these networks. because the backbone economicsmost clearly supports optical systems, the potential for growth in capacityseems greatest there; the inhome network market is developing in partbased on speculation about embedded systems in conjunction with computers and phones; broadband access to the home, the socalled last mile,continues to be problematic, however. 8wireless communicationsemnets will often involve wireless communications, in part becauseof the ease with which wireless networks can be deployed and connected,and in part because of the wide array of environments in which emnetswill operate. wireless has been proven inasmuch as cellular telephonyand paging networks have proliferated and grown in scale and coverage,both nationally and internationally. movement beyond conventionaltelephony and paging to data applications, through personal digital assistants (pdas) and advanced phones providing email and web access, hasbeen reinforced by the rise of thirdgeneration technology and standards.however, the new applications and services are limited in their data communications capabilities compared with wireline internet capabilities.beyond these larger area networks, where there are large, powerful, energyrich base stations with large antennas and relatively capable units,much work is being done in shortrange wireless systems. there are amultitude of new wireless technologies and accompanying standards thatfill this space. for 10 to 30+ mbps wireless communications, the 802.11band 802.11a (sometimes known as wireless ethernet) standards exist inthe united states; the corresponding standards outside the united statesare hiperlan29 in europe and multimedia mobile access communication (mmac) in japan. for wireless personal area network (pan) systems such as bluetooth (which was initially envisioned as a small formfactor, lowcost, cable replacement technology for devices such as cell8see cstbõs forthcoming examination of broadband issues, expected in 2001.9hiperlan2 was created to be a global standard with complete interoperability of highspeed wireless lan products. see <http://www.hiperlan2.com/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.54embedded, everywherephones, laptops, and headphones), ieee 802.15 is defining new generations of these systems.although wireless communication seems to be flourishing, the realityis that it involves overcoming many problems inherent in overtheaircommunication.10 the radiofrequency spectrum is a scarce resource andwill need to be shared among a multitude of highly heterogeneous devices with drastically different requirements for bandwidth and communication range. sharing of the spectrum can occur in time, space, andfrequency. already, conflicts over frequency are arising between emerging technologies that make use of unregulated bands (e.g., at 2.4 ghz,802.11 wireless ethernet conflicts with many new cordless telephones,and both are now being widely deployed.) lowcost radio transceiversare being developed that have very limited range, which isolates them inthe space dimension. this has the beneficial effect of dramatically lowering the power consumption for communication but complicates communication by potentially requiring multiple hops when communicating withmore distant nodes (and thus requiring intermediate nodes to expendtheir own power to route packets). an advantage of multihop, however,is that it provides the opportunity to do data aggregation and collaborative processing at an intermediate node. many portable devices are alsoseparating their communication in time to avoid interference, by havinglowduty cycles of transmission. these devices are also trying to avoidinterference by spreading themselves out in the frequency spectrum using spread spectrum techniques. box 2.5 discusses bluetooth as it relatesto the need to share the available spectrum.two fundamental concerns for emnets are scaling and heterogeneity. in wireless communication, scaling means maintaining adequatebandwidth per volume by decreasing the range, dividing up the spectrum, and taking turns using it. which devices are brought into proximity can have important consequences if they can interfere with each otherõscommunication or have cumulative bandwidth needs that cannot be met.an important issue arises with longlived emnets: they will occupy aportion of the spectrum for their lifetime, impacting any other devicesthat come within range.11 it may very well be necessary to consider not10for an overview of these challenges, see cstb (1997).11consider vanguard 1, the second u.s. satellite launched in the late 1950s, which had asits primary function an experiment on the use of solar cells for power supply. owing to itssmall size and capability, it merely broadcast a continuous signal. there was no anticipation of the need for a cutoff switch, and the satellite operated for years, providing littleuseful information but consuming a valuable portion of the rf spectrum.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies55box 2.5bluetooth and shared spectrumbluetooth exemplifies an attempted solution to the need to share availablespectrum. it was originally developed by cellular telephone manufacturers to simplify and thus increase the use of the cellular phone for longrange communicationby a variety of consumer devices. the concept is simple: provide a replacementfor cables that are used to connect laptops, mp3 players, etc., to network services.bluetooth is short rangeñapproximately 30 mñso that many users can interconnect the same devices within a small geographic area. the idea is to have highbandwidth per unit volume by providing smaller cells packed more closely together.bandwidth density is just as important as bandwidthñas anyone can attest whohas unsuccessfully tried to use a cellular phone in a crowd where hundreds ofothers were trying to do the same. by having a short range, it is possible forbluetooth transceivers (now at power consumptions of less than 50 mw) to beincluded in a wide range of batterypowered devices with minimal impact.bluetooth uses frequency hopping to further isolate users. conversely,devices that do want to communicate must synchronize precisely so that they hopfrequencies in unison (the bluetooth specification includes a discovery procedurefor this purpose). synchronization inherently limits the number of devices that cancommunicate at any one time. as long as only a handful of devices are being usedat one time, this is not an issue. the active devices synchronize, while the otherspark and conserve power. however, for many of the emnets envisioned in thisreport, large numbers of devices will be actively communicating. bluetooth doesnot adequately support these needs because it synchronizes devices into smallclusters. although devices can be part of more than one cluster, they and theirentire cluster pay a considerable performance penalty in switching between clusters. an important open question for technologies such as bluetooth is, how will agiven device know (or be told) with which other devices it is to communicate? ifmultiple other devices are in range, how are the important ones for an applicationidentified? ownership may be important when users want to connect their personal laptop to their personal phone, but this may make it difficult to use a differentphone. this problem is much more difficult when what is at issue are embeddedelements of emnets that are deployed as part of an active environment. movingbeyond phones, pdas, and laptops to applications such as wireless sensor networks and other emnets, bluetooth and its ilk may have a role to play. however,significant additional development will be needed.only principled ways to claim a portion of the spectrum but also how toreclaim it when needs change. heterogeneity means that large emnetswill require multihop networks that will forward data packets betweendevices that have to exist in different parts of the spectrum (possibly as farapart as radio frequency (rf) and infrared (ir)) or that are limited inrange.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.56embedded, everywhereboxes 2.6 and 2.7 describe two areas where emnets stress wirelesscommunications in new ways. both focus on shortrange, lowpowerissues, in which there is more uncertainty and need for work than in theother more mature technologies. the first looks at constraints on thecircuits used, and the second examines the networking issues.box 2.6communications constraints forlowpower, shortrange systemsthe constraints on communications for lowpower, shortrange wirelesssystems stem from environmental effects on radio frequency propagation. theseeffects, such as spatial separation of the nodes along with antenna gain, multipathpropagation, and shadowing, arise from attenuation due to ground scatteringeffects. the spatial separation issue has both positives and negatives. spatial,time, or frequency diversity can help with the issue of multipath propagation, and amultihop network can be employed to deal with path loss and shadowing. each ofthese is discussed in more detail below.spatial separation is an important factor in the construction of wireless communication networks. for lowlying antennas, intensity can drop as much as thefourth power of distance (rappaport, 1996; sohrabi et al., 1999b; sommerfeld,1949; wait, 1998; chew, 1990).1 this presents a problem when attempting tocommunicate along the ground. surface roughness, the presence of reflectingand obstructing objects, and antenna elevation all have an impact on propagation.in general, power falloff rarely approaches the freespace limit, and particularly incluttered or nearground environments a fourth power loss falloff is seen. thelosses make longrange communication a powerhungry exercise; the combination of maxwellõs laws (equations describing electromagnetic fields) and shannonõscapacity theorem (describing the connection among error rates, transmission rates,and the capacity of the communications channel) together dictate that there is alimit on how many bits can be reliably conveyed given power and bandwidthrestrictions. on the other hand, the strong decay of intensity with distance provides spatial isolation along the ground, allowing reuse of frequencies throughouta network.multipath propagation (due to reflections off multiple objects) is also a veryserious problem. it is possible to recover most of the loss generated therebythrough diversity. diversity can be obtained in any of the three domains of space,frequency, or time, since with sufficient separation the fade levels are independent. by spreading the information, the multiple versions will experience differentfading, so that the result is more akin to the average, whereas if nothing is done itembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies57is the worstcase conditions that dominate error probabilities. if the sensor nodesare not physically mobile and the terrain is static, the multipath losses will be invariant with respect to time. likewise, spatial diversity is difficult to obtain, since multiple antennas are unlikely to be mounted on small platforms. thus, diversity ismost likely to be achieved in the frequency domainñfor example, by employingsome combination of frequency spread spectrum or hybrid spread/orthogonalfrequency division multiplexing systems together with interleaving and channelcoding. networks of embedded computers that may be placed anywhere and thatmay grow in numbers and density with time will have a critical need for reliablecommunication; yet the interference among elements will grow proportionally, andfrequency reuse may be of little or no value because of mobility and, possibly,uncertainty as to location. for such an application, spread spectrum and directsequence guarantee a constant flat, wide spectrum for each user and are a goodchoice for maximizing both the capacity and the coverage of the network. it is notclear, however, whether the inherent inefficiencies will prove too complex and/ortoo costly. measures that are effective against deliberate jamming are generallyalso effective against multipath fading and multiuser interference.shadowing (wavefront obstruction and confinement) and path loss can bedealt with by employing a multihop network. if nodes are randomly placed in anenvironment, some links to near neighbors will be obstructed while others willpresent a clear line of sight. given a sufficient density, the signals can in effect hoparound obstacles. multihop also presents opportunities for networking processingand reduction of data. exploitation of these forms of diversity can lead to significant reductions in the energy required to transmit data from one location in thenetwork to another; such exploitation becomes limited chiefly by the reception andretransmission energy costs of the radio transceivers for dense peertopeernetworks. in wireless systems there is thus a close connection between the networking strategy and the physical layer. the connection is even stronger whenconsidering the multiple access nature of the channel, since interference amongusers is often the limiting impairment.1the path loss exponent can vary from less than 2 to more than 4 in different environments.see, for example, parsons (1992) as an introduction to the body of literature dealing withpropagation in personal mobile environments.geolocation in many electronic systems the geographic location of objects is notimportant; instead, it is the network topology, the relative position ofobjects within a network, that is important. yet for many systems, geographic data can be very usefulñfor example, to find the nearest printerembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.58embedded, everywherebox 2.7network architecture for lowpower wireless systemsin contrast to conventional wireless networks, emnets must potentially support large numbers of sensors in a local area with short range and low average bitrate communication (fewer than 1 to 100 kbps). the small separation betweennodes can be exploited to provide multihop communication, with the power advantages outlined earlier. since for short hops the transceiver power consumption forreception and listening is nearly equal to that for transmission, the protocol shouldbe designed so that radios are off as much of the time as possible. this requiresthat the radios periodically exchange short messages to maintain local synchronization. it is not necessary for all nodes to have the same global clock, but the localvariations from link to link should be small to enable cooperative signal processingfunctions. the messages can combine healthkeeping information, maintenanceof synchronization, and reservation requests for bandwidth for longer packets. theabundant bandwidth that results from the spatial reuse of frequencies and localprocessing ensures that relatively few conflicts will result in these requests, sosimple mechanisms can be used. one such protocol suite that embodies theseprinciples has been developed that includes bootup, media access control(mac), energyaware routing, and interaction with mobile units; see sohrabi et al.(1999a). it indicates the feasibility of achieving distributed lowpower operation ina flat multihop network.an alternative to a flat architecture is the use of clustering, possibly with clustering at many levels with respect to different network functions. this is particularlyconvenient if there are multiple classes of nodes, some with special capabilitiessuch as longrange communications, or connections via gateway nodes to theinternet. different approaches for performing network selforganization into clusters have been developed. typically, clustering is implemented in ad hoc networks to reduce the number of instances of network reconfiguration in situations ofhigh mobility relative to the messaging rate. it comes at the price of an increasedenergy burden to the cluster head and some inefficiency in multihop routing. thereduction in routing table updates and the relatively frequent role changes in situations of mobility take care of both concerns. in static networks, hierarchy may beimposed to simplify signal processingñfor example, to avoid frequent leader election for processes that must be coordinated over large areas. this could occureven if routing takes place without clustering.a question that naturally arises is where processing and storage shouldtake place. as indicated previously, communication, while becoming cheaper,costs a great deal compared with processing, so energy constraints dictate doingas much processing at the source as possible. further, reducing the quantity ofdata to transmit significantly simplifies the network design and permits scaling tothousands of nodes per network gateway.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies59in terms of meters, not network connections. in emnets, this ability todetermine oneõs location in space is often criticalñas a way to both nameand identify objects and data and coordinate activity within an emnet.12for example, using location information in conjunction with static information about a building would allow the creation of logical location information, enabling an emnet to determine which objects are in the sameroom or are cooled by the same air conditioner. location information canalso be used to determine when two (or more) nodes are in close geographical proximity to one another. this would be useful when trying toensure redundant coverage of a particular area, but needing only onenode in the area to be powered on at any given point. boxes 2.8 and 2.9provide details of techniques that can assist in determining the location ofnodes and, consequently, the larger network geometry (encompassinggeographic location, colocation, and proximity information). the firstdescribes the global positioning system (gps) and the second examinesalternative geolocation techniques.computing softwareñoperating systems and applications embedded systems have been around at least as long as the microprocessor. the software for these systems has been built, more or lesssuccessfully, using several different paradigms. some systems are builtfrom scratch by the manufacturer with all software being created specifically for the device in question. this software may be written in assemblylanguage or may use a higherlevel language. other systems are madeusing existing software modules and wrapping an application aroundthem. these preexisting modules might include an operating system,network protocols, control algorithms, drivers, and so on. such modulesare available from independent software vendors and in some cases asopen source software. finally, a very few systems are created using formal methods, highlevel design tools, and rigorous design methodology.12location systems generally measure the relative geographical positions of objects because measuring absolute positions directly is all but impossible. if one or more of theobjects has a known fixed position, then absolute geographic positions can be derived.measuring relative positions directly is difficult, so most location systems measure thedistance between the objects and use the measurements to triangulate the relative locationsof the objects. the distance between the objects can be measured in a number of ways, butthe most popular is to measure the time delay of a signal transmitted between two objects.this time delay can be measured directly, or it can be measured indirectly by measuring thephase of some oscillating carrier wave (see, for example, the omega and decca navigationsystems.)embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.60embedded, everywherebox 2.8global positioning systemby far the most common geolocation system in use today is the global positioning system (gps), which was completed by the department of defense in1994. twentyfour satellites circle earth in a pattern in which at least five satellitesare visible from any location. these satellites contain very precise clocks, andtheir locations are known to a high degree of precision. they transmit a messagethat contains both the time on the satellite and the satelliteõs position. the receiptof four signals provides enough information to solve for the location of the receiverand the time offset of the local clock.1 what makes gps reception difficult is thatradio frequency (rf) signals from the satellites are very weak. special coding isused to allow receivers to detect these weak signals, but even with coding, gpsreceivers generally work only if they have a direct line of sight to the satellites.performance inside buildings or in an area covered by foliage is generally quitepoorña severe limitation for emnets, which will often operate entirely inside buildings. a secondary issue is the large computation needed by current receivers tofind the signals from the desired satellite quickly, which can consume considerableresources.designing a geolocation system would be much easier if the receiver knewroughly where it was and what signals it should be looking for. this notion of anassisted geolocation system (assisted gps) has recently been proposed to handlethe need to locate a cell phone within a few tens of meters for emergency 911calls. assisted gps leverages the following facts: (1) the nodes have a means tocommunicate with an outside server (that is, they donõt need to be completely selfcontained, (2) the position of the nodes relative to the outside server is roughlyknown, and (3) it is possible (and inexpensive) to build highquality gps receiversto the outside servers to assist in determining the location of the nodes.revisiting the gps receiverõs task, the hard problem is finding the satelliteõssignal in the background noise. yet if the rough location of the node relative to theserver is known, the server could calculate the signal that the receiver should see.with this added information, the receiverõs search space is much smaller, and thereceiver can actually make intelligent guesses about where the signal is. thisallows the receiver to integrate over longer sequences of data and improves itsability to find very small signals that are buried in noise. in the cell phone systemthese latter systems have been very small in number compared with themore ad hoc designs (lee, 2000).today, as described elsewhere in this report, embedded systems arebecoming highly networked and are changing in fundamental ways. thiswill necessitate important changes in the way the software for these systems is created. for most computers, the software running on a typicalembedded system usually consists of an operating system, which is deembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies61signed to be useful for many systems with little change, and some application software. (see box 2.10 for a discussion of requirements in traditional embedded systems.) in todayõs emnets, the line between application and operating system often blurs, with reusable components such ascommunications protocols sometimes considered an operating systemand sometimes an application and virtual machines considered neither atrue operating system nor an application but rather a sort of middleware.example, the system roughly tracks the location of a phone using signal strengthindications to switch between cells. the base station would know the visible satellites and their doppler frequency shifts, which could be fed to the receivers tomake it easier for them to find the needed signals. in many emnets, the initialposition estimate could be even better, which would improve the possibility of finding the weak satellite signals.whether an assisted gps can be made to work for emnets is still an openresearch question and needs to be explored.2 in addition to the obvious issue ofsignal to noise for the gps satellite broadcasts, a number of other issues need tobe resolved. a critical requirement in these systems is that the time at the receivers be synchronized to the clocks at the server to better than the uncertainty of thesignal delay; if it is not, the clock errors will decrease the gain achieved from theserver station. this need for good time synchronization is a challenge for manyemnets since for power and cost reasons they may use lowdutyfactor networks,which have large latency, and lowpower, lowcost clocks, which have higher uncertainty. another issue is the multipath problem that occurs in urban situations,where a reflected satellite signal can confuse the receiver. still another concernwith incorporating gps location technology into emnets is nontechnical: gps is acreation of the united states department of defense, and it may be that manyother countries would prefer not to have their positioning systems depend on it assuch, notwithstanding the defense departmentõs position that it will not interferewith the accuracy of gps.1one way to visualize the problem is to imagine the devices as small balls and the distancesmeasured as sticks that connect the balls together. it takes at least four devices (three distances to each device) to fix the relative threedimensional locations for each of the objects,and in some cases it takes more than four devices to obtain robust position estimates. delaymust be measured quite precisely given the fast speed of propagation, 3 × 108 m/s. the keyto these systems is that they only need stable clocks, not necessarily clocks with extremelyhigh precision (rappaport, 1996).2the federal aviation administrationõs wide area augmentation system is an example of asystem that incorporates gps information in a geographically expansive augmentation to basic gps service. for more information, see <http://gps.faa.gov/programs/waas/waas.htm>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.62embedded, everywherebox 2.9alternative geolocation techniques the biggest disadvantage of gps for a robust sensor network is the dependence on the external signal from each satellite and thus the sensitivity to multipath signals, signal absorption, jamming, and satellite loss. implementing a nonsatellitebased rf geolocation framework as part of a sensor network couldprovide a robust location algorithm and, ideally, would leverage the communication transceiver to limit system redundancy. the biggest hurdle to overcome forrf geolocation is the timing accuracy needed for useful submeter location capability. onemeter position accuracy requires discerning signaltiming differences of 3ns. clock accuracies may not need to be this fine if averaging and edge detectionare used to compensate for clock error. however, multipath signals in clutteredenvironments also cause substantial errors in position accuracy to accumulate.twoway measurements in which relative synchronization is not necessary areone way to get around synchronization problems (mccrady et al., 2000). however, much development remains to be done, as rf systems are still orders of magnitude in price, size, or accuracy from feasible integration in widely deployed emnets.ultrawideband (uwb) shows promise for delivering centimeteraccurate,multipath, integrated communications and position location capability. however,fully developed uwbbased systems with lowcost, compact clocks are not yetcommercially available. in addition, the propagation characteristics of uwb signals have not been widely explored, and size, cost, and federal communicationscommission (fcc) certification issues have not been finalized for developing uwbsystems. a working group has been set up that describes some of these issues inmore detail.1as an alternative to using rf communication, acoustic signals could be used.acoustic signals suffer from similar multipath, dispersion, and propagation problems in cluttered environments, but they require a much coarser time scale (sixorders of magnitude coarser) for accurate positioning.2 while acoustic geolocabecause in any case emnets need to work as a whole, operating systemsand application software are discussed together.traditional embedded systems are often networked, but generally inrather simple ways, or at least the connectivity roles of the embeddedsystems themselves are rather simple. however, with hardware powerincreasing rapidly and available bandwidth increasing even more rapidly, new modes of connectivity (both wired and wireless), richer userinterfaces, and new standards such as java, the functionality and resulting complexity are about to increase dramatically. these new emnetschange the rules of the game in a number of ways. they are still embedded systems, but they are also a part of an extremely complex, heterogeneous distributed system. they therefore retain the requirements of traembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies63ditional embedded systems, as described above, but also have a numberof new requirements. several of these new requirements are discussed indetail elsewhere in this report: security, safety, reliability, usability, andprivacy (chapter 4); virtual machines and communication protocols(chapter 3); complexity and analysis tools (chapter 5); and service discovery (chapter 3). boxes 2.11, 2.12, and 2.13 expand upon upgradability,high availability, and the ability to work with new hardware as additionalways in which software will need to be refined to handle the requirements of emnets. an additional concern is the cost of correcting failures in emnetsoftware, which will often far exceed the corresponding cost in moretraditional desktop and server environments. this is because the emnetstion requires a separate acoustic transmitter, depending on an emnetõs sensingrequirements, the receiver may be integrated into existing sensing capability.acoustic geolocation takes advantage of the relatively slow propagation of soundwaves, but it requires development of an alternative subsystem and further exploration of the propagation issues involved before operational use with emnets canbe contemplated.the methods discussed above first measure distances between objects andthen deduce their position; other approaches are possible. in some systems, precise location might not be needed. for example, a few beacons might be able todetermine which side of a line an object is on; this might be enough for determiningwhat is in a room but not exactly where. extending this type of determination mightenable the device (or the beacons) to estimate distance and angles between theobject. these estimates again provide the basis for calculating geolocation. thereare a number of ways to estimate angles and distance other than measuring timeof flight. for example most cell phone systems track signal strength as a positionestimate (for cell handoff) and are starting to use antenna arrays to estimate theangle as well. optical signals can also be used in this manner. for example, laserrange finders use a laser and a camera to determine the location of different objects by changing the angle of the laser and measuring when it hits the object.given the laser angle and the distance between the laser and the camera, one canestimate the distance to the object. these techniques are often much simpler thangps and merit further research in the context of emnets.1more information is available at <http://www.uwb.org/>.2acoustic signals travel relatively slowly, moving at roughly 330 m/s. to measure distancethis way requires a pair of ultrasonic transducers and some signal processing to detect accurately the signal and measure the delay. it also requires a clear acoustic path between the twodevices to propagate the signal.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.64embedded, everywherebox 2.10traditional embedded software requirementstraditional, nonnetworked embedded software can be quite complex andhave a number of requirements. these have implications both for the applicationand for the operating system. several such requirements are the following:¥real time. because many embedded systems interact intensely with thereal world, they often have strict realtime requirements.¥portability. many different types of cpus, peripheral chips, and memoryarchitectures may be used in embedded systems. thus, for low cost, any embedded os or other reusable component that is meant to be used on multipleapplications should be widely portable to custom hardware platforms.¥resourceconstrained computing. since embedded systems may have nodisk and little memory and may be power and cost constrained, the operatingsystem must be able to operate in resourceconstrained environments.¥high reliability. embedded systems are deployed remotely, often ininfrastructurecritical applications. software faults are thus very problematic andare extremely expensive or even impossible to fix.¥safety. software can be analyzed on the local system to determine itsimpact on the system safety objective.will often be deployed in ways that make it difficult to deliver or testcorrected software. also, the costs of the failures themselves may be veryhigh, since many emnets will perform infrastructurecritical or even lifecritical applications. the cost issue is complicated by the fact that the costof updates and failures may be borne by the end user and not by thedeveloper of the software, which may have no compelling economic rationale for developing reliable software and so may be tempted to cutcorners at this critical juncture.realtime and performancecritical aspects ofembedded operating systems the new requirements listed above imply more complex, highly functional applications and services to support the systems. these servicescould be provided by specialized hardware but in most cases will probably be provided by an operating system. however, as mentioned, traditional embedded system requirements do not disappear. in particular,the requirement for realtime response is still critical for many productsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies65and remains a challenge, as new functionality must be added withoutadversely affecting response.a realtime operating system must enable applications to respond tostimuli in a deterministic amount of time, known as the latency. theactual amount of time is dependent on the application, but the determinism requirement is nonnegotiable. all design decisions in the operatingsystem must therefore optimize system latency. this stands in contrast tomost desktop and server operating systems, which are optimized forthroughput and for protection of multiple processes, with latency far lessimportant. critical design decisions as basic as system data structures(queues, tables, etc.), memory protection and paging models, and callingsemantics are driven by these very different optimization requirements,making it difficult or impossible to òaddó real time to an operating systemthat was not designed from the beginning with that as a core requirement.like any modern operating system, most realtime embedded operating systems are multitasking. unlike most desktop and server operatingsystems, however, embedded operating systems are split between thosesystems in which there are multiple processes, each residing in its ownmemory, and those in which all tasks live in the same memory map, withor without protection from one another. furthermore, new systems arebeginning to appear based on entirely different memory protection models, such as protection domains. some of the issues that arise in embedded systems with respect to memory management, tasks, and schedulingare described in box 2.14.microelectromechanical systemsmicroelectromechanical systems, or mems, had their start in afamous talk by the physicist richard feynman entitled òthereõs plenty ofroom at the bottomó (feynman, 1960; trimmer, 1997.) feynman pointedout that tremendous improvements in speed and energy requirements, aswell as in device quality and reliability, could be had if computing devices could be constructed at the atomic level. mems represent the firststeps toward that vision, using the best implementation technology currently available: the same silicon fabrication that is used for integratedcircuits.mems devices generally attempt to use mechanical properties of thedevice, in conjunction with electronic sensing, processing, and control, toachieve realworld physical sensing and actuation. the accelerometers inmodern cars with airbags are mems devices; they use tiny cantileverbeams as the inertial elements and embody the extreme reliability required of such an application. other mems devices take advantage of thewave nature of light, incorporating regular patterns of very fine combembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.66embedded, everywherebox 2.11upgradability traditionally, most embedded devices, once deployed, have rarely beenupgraded, and then only very proactively and carefully, for instance by physicallyreplacing readonly memory (rom). in a world of networked embedded systems,and with rewritable, nonvolatile storage widely available, field upgrades will bemore frequent and often far more invisible to end users of the systems.1 this willoccur because emnets may be in service for many years, and the environment towhich they are connected and the functionality requirements for the device maychange considerably over that time. in some cases, such upgrades are driven bya knowledgeable user, who purchases a new component of functionality and installs it, a nearly automatic procedure. in other cases, updates or upgrades maybe invisible to the end user, such as when protocols or device addresses change.devices like home gateways, automobiles, and appliances may be upgraded online without the consumer ever knowing about it and in ways well beyond theconsumerõs understanding, raising the issue of usability and transparency to theuser.transparent software upgrade of deployed emnets, while probably necessary and inevitable, presents a number of difficulties. the very fact that the upgrades are transparent to the end user raises troubling questions of who has control of the emnet (the user or the upgrader?) and creates potential security andsafety issues if such an upgrade is erroneous or malicious. what if the software iscontrollable or upgradable by parties that are not to be trusted? further difficulty iscaused by the heterogeneity of many emnets. many individual nodes may need tobe upgraded, but those nodes may be based on different hardware and/or differentoperating systems. deploying an upgrade that will work reliably across all thesenodes and emnets is a challenge closely related to the code mobility issues disstructures, arranged to refract light in useful ways under mechanical control. a texas instruments mems device is the heart of a projector inwhich each pixel is the light bounced off one of millions of tiny mirrors,hinged such that the amounts of red, green, and blue light can be independently controlled.microfluidics is an emerging mems application in which the fluidcapillaries and valves are all directly implemented on a silicon chip andcontrolled via onboard electronics. still other mems devices implement amembrane with a tunneling current sensor for extremely precise measurements of pressure. the combination of mems sensing plus the computation horsepower of embedded processors opens the way to largenetworks of distributed sensing plus local processing, with communication back to central synthesis engines for decision making.however, there are challenges to be overcome before mems can realembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies67ize this promise. one is in the nature of real world sensing itself: it is anintrinsically messy business. a mems device that is attempting to detectcertain gases in the atmosphere, for instance, will be exposed to manyother gases and potential contaminants, perhaps over very long periodsof time and with no maintenance. such devices will have to be designedto be selfmonitoring and, if possible, selfcleaning if they are to be used invery large numbers by nonexperts.the aspects of silicon technology that yield the best electronics are notgenerally those that yield the best mems devices. as has been discussed,smaller is better for electronics. below a certain size, however, memsdevices will not work well: a cantilever beam used for sensing acceleration is not necessarily improved by making it smaller. yet to meet the lowcost needed for large numbers of sensing/computing/reporting devices,the mems aspects and electronics will have to be fabricated onto thecussed in chapter 3. finally, there may be simultaneity requirementsñthat is, allnodes in an emnet, which may be widely dispersed geographically, may need tobe upgraded at the same time. this requirement may need to be addressed bymultistage commits, similar to those used in transaction processing.online update is largely an application issue rather than an operating systemissue. however, most system designers will expect the operating system to makethe task easier and to handle some difficult problems like upgrade policy, verification, and security. furthermore, in some cases the operating system itself mayneed to be field upgraded, a process that almost certainly requires operating system cooperation and that extends beyond the device being updated. a serverinfrastructure is required to set policies, supply the correct information to the correct devices, manage security of the information, and verify correctness. thisinfrastructure is likely to be supplied by a few providers, akin to internet serviceproviders (isps) or application service providers (asps), rather than to be created anew for each individual deployed product.as of 2001, there is no consensus on how online field upgrade will work forthe billions of networked embedded systems components that will be deployed,nor is there any significant move toward applicable standards. field upgrade islikely to become an important focus of research and development work over thenext several years as numerous systems are deployed that challenge the ability ofsimple solutions to scale up to adequate numbers and reliability. 1the problem of field upgradability of emnet elements is similar to the problem encounteredin downloading software for softwaredefined radios, which is being studied by a number ofcompanies and the sdr (software defined radio) forum, a de facto standards organization.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.68embedded, everywherebox 2.12high availability and fault tolerancemany emnets must work continuously, regardless of hardware faults (withindefined limits) or ongoing hardware and software maintenance, such as hardwareor software component replacement. reliability in an unreliable and changeableenvironment is usually referred to as high availability and fault tolerance (ha/ft).ha/ft may require specialized hardware, such as redundant processors or storage. the operating system plays a key role in ha/ft, including fault detection,recovery, and management; checkpoint and failover mechanisms; and hotswapcapability for both hardware and software. applications also need to be designedwith ha/ft in mind. a layer between the application and the operating system thatchecks the health of the system and diagnoses what is wrong can be used tocontrol the interaction between the two.ha/ft systems have not been widely used; instead, they tend to have nichesin which they are needed, such as banking, electric power, and aircraft. thosewho need them, often communications equipment manufacturers, have built themin a proprietary fashion, generally for a specific product. the first portable, commercial embedded ha/ft operating systems, as well as reusable components forfault management and recovery, are just starting to become available,1 but theyhave not yet been widely deployed in a generalpurpose context. emnets will verylikely be used in a variety of contexts, and transferring ha/ft capabilities toemnets is a challenge the community must meet.1as examples, see wind riverõs vxworks ae at <http://www.windriver.com/products/html/vxworksae.html>, eneaõs ose systems at <http://www.enea.com/>, and lynuxworks at<http://www.lynuxworks.com/>.same silicon. much work remains to find useful mems sensors that canbe economically realized on the same silicon as the electronics needed forcontrol and communication.summarythis chapter has provided a brief overview of the core technologiesthat emnets will use, the trends that are driving these technologies, andthe research areas that will accelerate the widespread implementation ofemnets. it has argued that silicon scaling, advances in computing hardware, software, and wireless communications, and new connections tothe physical world such as geolocation and mems will be the technological building blocks of this new class of largescale system.large systems will comprise thousands or even millions of sensing,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies69computing, and actuating nodes. the basic trends are clear: these large,inexpensive, highly capable systems are becoming feasible because of thecumulative effects of silicon scalingñas eversmaller silicon feature sizesbecome commercially available, more and more transistors can be applied to a task ever more cheaply, thus bringing increasingly capableapplications within economic range. there are also some countervailingtrends, in the form of constraints: communication is costly, both onchipand between chips; there are problems looming in the areas of powerbox 2.13ability to work with new hardwaresoftware needs hardware, and the nature of hardware is changing. fordecades, the relationship between hardware and software has been well defined.computer architectures, whether microprocessor or mainframe, have changedslowly, on a time scale of many years. software has resided in random accessmemory (ram) or readonly memory (rom) and has been executed on an arithmetic logic unit (alu) on the processor in the computer. new developments in thehardware world will challenge some of the assumptions about this relationship.multicore processorsñmultiple concurrent processing elements on a singlechipñare becoming economical and common. they often include a single controlprocessor and several simpler microengines specifically designed for a task suchas networking or signal processing. thus, a microprocessor is no longer a singlecomputer but is becoming a heterogeneous multiprocessing system. configurableprocessors, created with tools from companies such as arc and tensilica, makeit very easy for a user to craft a custom microprocessor for a specific application.these tools can create real performance advantages for some applications. programmable logic chips are growing larger, with millions of gates becoming available; they are also available in combination chips, which include a standard cpucore and a significant number of programmable gates. these make it possible tocreate multiple, concurrent processing elements and reconfigure continuously tooptimize processing tasks.all of these advances hold great promise for performance, cost, and powerefficiency, but all create real challenges for software. applications and operatingsystems must be able to perform well in reconfigurable, multiprocessing environments. new frameworks will be required to make efficient use of reconfigurableprocessing elements. interestingly, all of these advances put compilers and programming languages back in the forefront of software development.11for examples of this kind of work, see the oxygen project at mit, <http://oxygen.lcs.mit.edu/>,and the ptolemy project at berkeley, <http://ptolemy.eecs.berkeley.edu/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.70embedded, everywherebox 2.14operating systems and emnetsa multiprocess system uses virtual memory to create separate memoryspaces in which processes may reside, protected from each other. a multitaskingoperating system usually implies that all tasks live in the same memory map, whichcomes with its own host of security implications. since many embedded systemshave no virtual memory map capability, these simpler systems are prevalent formany applications. a multitask system can also run much faster, since the operating system does not need to switch memory maps; this comes at the cost of lessprotection between running tasks, however. those switches can make determinacy difficult, since all planning must take place around worstcase scenariosentailing significant swapping of page tables. a further concern is preemption.preemption occurs when the system stops one task and starts another. the operating system must perform some housekeeping, including saving the preemptedtaskõs state, restoring the new taskõs states, and so on. the time it takes to movefrom one task to another is called the preemptive latency and is a critical realtimeperformance metric.not all embedded operating systems are preemptive. some are runtocompletion, which means that a task is never stopped by the operating system.this requires the tasks to cooperate, for instance by reaching a known stoppingpoint and then determining whether other tasks need to run. runtocompletionoperating systems are very small, simple, and efficient, but because most of thescheduling and synchronization burden is pushed to the individual tasks, they areonly applicable to very simple uses. almost all embedded operating systemsassign each task a priority, signifying its importance. in a preemptive system, thehighest priority task that is ready is always running. these priorities may changefor a number of reasons over time, either because a task changed a priorityexplicitly or because the operating system changes it implicitly in certain circumstances. the algorithms by which the operating system may change task prioritiesare critical to realtime performance, but they are beyond the scope of this study.preemptive realtime embedded operating systems vary significantly in performance according to the various decisions madeñboth overt (multitask vs. multiprocess, number of priorities, and so on.) and covert (structure of the internal taskqueue, efficiency of the operating systemõs code). unfortunately, there are nostandard benchmarks by which these systems are measured. even commonlyused metrics, such as preemptive latency, interrupt latency, or time to set a semaphore, can be very different because there is no universal agreement on preciselyembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies71what those terms mean. when the application is added to the system, the resulting behavior is very complex and can be difficult to characterize. it may be verydifficult to understand how settable parameters, such as task priority, are affectingsystem behavior. there are a number of methodologies, however, that can helpwith these problems.other considerations beyond realtime execution and memory managementemerge in emnets. numerous efforts address the realtime executive aspects,but current realtime operating systems do not meet the needs of emnets. manysuch systems have followed the performance growth of the walletsize device.traditional realtime embedded operating systems include vxworks, wince,palmos, and many others. table 2.1, taken from hill et al. (2000), shows thecharacteristics for a handful of these systems. many are based on microkernelsthat allow for capabilities to be added or removed based on system needs. theyprovide an execution environment that is similar to that of traditional desktop systems. they allow system programmers to reuse existing code and multiprogramming techniques. some provide memory protection, as discussed above, giventhe appropriate hardware support. this becomes increasingly important as thesize of the embedded applications grows. these systems are a popular choice forpdas, cell phones, and television settop boxes. however, they do not yet meetthe requirements of emnets; they are more suited to the world of embedded pcs,requiring a significant number of cycles for context switching and having a memoryfootprint on the order of hundreds of kilobytes.1there is also a collection of smaller realtime systems, including creem,posek, and ariel, which are minimal operating systems designed for deeply embedded systems, such as motor controllers or microwave ovens. while providingsupport for preemptive tasks, they have severely constrained execution and storage models. posek, for example, provides a taskbased execution model that isstatically configured to meet the requirements of a specific application. however,they tend to be controlcentricñcontrolling access to hardware resourcesñasopposed to dataflowcentric. berkeleyõs tinyos2 is focused on satisfying theneeds of emnets. additional research and experimentation are needed to develop operating systems that fit the unique constraints of emnets.1unfortunately, while there is a large amount of information on code size of embedded operating systems, very few hard performance numbers have been published.2for more information, see <http://tinyos.millennium.berkeley.edu/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.72table 2.1 characteristics of some realtime embedded operating systemsnamepreemptionprotectionrom sizeconfigurabilitytargetsaposektasksno2kstaticmicrocontrollerpsosystemposixoptionaldynamicpii arm thumbvxworksposixyes~286kdynamicpentium strong armqnx neutrinoposixyes>100kdynamicpentium ii nec chipsqnx realtimeposixyes100kdynamicpentium ii 386sos9processyesdynamicpentium sh4chorus osposixoptional10kdynamicpentium strong armarieltasksno19kstaticsh2, arm thumbcreemdata flowno560 bytesstaticatmel 8051athe arrows in this column are used to indicate the range of capabilities of the targets.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies73dissipation, battery life, and design complexity; and many of the areasknown to be problematic for todayõs systems are likely to be substantiallymore problematic with emnets.networking solutions that work well enough for todayõs systems arebased on many assumptions that are inappropriate for emnets. for instance, the potentially huge number of nodes, the ad hoc system extensions expected, the extended longevity, and the heavy reliance on wireless communications between nodes will collectively invalidate somebasic assumptions built into todayõs network solutions. increased needsfor system dependability will accompany the use of emnets for realtimemonitoring and actuating, but existing software creation and verificationtechniques will not easily or automatically apply. other emnet requirements, such as the need for software upgradability and fault tolerance,willalso require great improvements in the state of the art.other technological enablers for emnets will be mems and betterpower sources. mems devices show great promise for realworld sensing(temperature, pressure, chemicals, acoustical levels, light and radiation,etc.). they also may become important for realworld actuation.emnet nodes will be heterogeneous. some will be as powerful as anyserver and will have more than sufficient power. but system nodes thatare deployed into the real world will necessarily rely on very carefulenergy management for their power. advances in power managementwill provide part of the solution; advances in the energy sources themselves will provide the other part. improved batteries, better rechargingtechniques, fuel cells, microcombustion engines, and energy scavengingmay all be important avenues.predicting the future of a field moving as rapidly as information technology is a very risky proposition. but within that field, certain trends areunmistakable: basic silicon scaling and the economics surrounding thesemiconductor/microprocessor industry, power sources, and software.some of these trends will seem almost inevitable, given the past 20 yearsof progress; others will require new work if they are not to impede theoverall progress of this emerging technology.referencesborkar, s. 1999. òdesign challenges of technology scaling.ó ieee micro 19(4):2329.brodersen, r.w., a.p. chandrakasan, and s. cheng. 1992. òlowpower cmos digital design.ó ieee journal of solidstate circuits 27(4):473484.chew, w.c. 1990. waves and fields in inhomogeneous media. new york, n.y.: van nostrand reinhold.clark, l., et al. 2001. òa scalable performance 32b microprocessor.ó ieee internationalsolidstate circuits conference digest of technical papers, february.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.74embedded, everywherecomputer science and technology board (cstb). 1997. the evolution of untethered communication. washington, d.c.: national academy press.feynman, richard p. 1960. òthereõs plenty of room at the bottom: an invitation to enter anew field of physics.ó engineering and science. california institute of technology:american physical society, february.geppert, l., and t.s. perry. 2000. òtransmetaõs magic show.ó ieee spectrum 37(5).gonzalez, r., and m. horowitz. 1996. òenergy dissipation in general purpose microprocessors.ó ieee journal of solidstate circuits (september):12771284.hill, j., et al. 2000. òsystem architecture directions for networked sensors.ó proceedings of the9th international conference on architectural support for programming languages and operating systems, cambridge, mass., november 1215.lee, edward a. 2000. òwhatõs ahead for embedded software?ó ieee computer (september):1826.mccrady, d.d., l. doyle, h. forstrom, t. dempsey, and m. martorana. 2000. òmobileranging using lowaccuracy clocks,ó ieee transactions on mtt 48(6).parsons, david. 1992. the mobile radio propagation channel. new york: john wiley & sons.rappaport, t.s. 1996. wireless communications: principles and practice, englewood cliffs,n.j.: prentice hall.semiconductor industry association (sia). 1999. semiannual report. san jose, calif.: sia.sohrabi, k., j. gao, v. ailawadhi, and g. pottie. 1999a. òselforganizing sensor network.óproceedings of the 37th allerton conference on communications, control, and computing,monticello, ill., september.sohrabi, k., b. manriquez, and g. pottie. 1999b. ònearground wideband channel measurements.ó proceedings of the 49th vehicular technology conference. new york: ieee, pp.571574.sommerfeld, a. 1949. partial differential equations in physics, new york: academic press.trimmer, william. 1997. micromechanics and mems. new york: ieee press.van trees, h. 1968. detection, estimation and modulation theory. new york: john wiley &sons.wait, j.r. 1998. òthe ancient and modern history of em groundwave propagation,ó ieeeantennas and propagation magazine 40(5):724.bibliographyagre, j.r., l.p. clare, g.j. pottie, and n.p. romanov. 1999. òdevelopment platform for selforganizing wireless sensor networks.ó presented at aerosenseõ99, orlando, fla.asada, g., m. dong, t.s. lin, f. newberg, g. pottie, h.o. marcy, and w.j. kaiser. 1998.òwireless integrated network sensors: low power systems on a chip.ó proceedings ofthe 24th ieee european solidstate circuits conference.bult, k., a. burstein, d. chang, m. dong, m. fielding, e. kruglick, j. ho, f. lin, t.h. lin,w.j. kaiser, h. marcy, r. mukai, p. nelson, f. newberg, k.s.j. pister, g. pottie, h.sanchez, o.m. stafsudd, k.b. tan, c.m. ward, s. xue, and j. yao. 1996. òlow powersystems for wireless microsensors.ó proceedings of the 1996 international symposium onlow power electronics and design, pp. 1721.chatterjee, p.k., and r.r. doering. 1998. òthe future of microelectronics.ó proceedings ofthe ieee 86(1):176183.dong, m.j., g. yung, and w.j. kaiser. 1997. òlow power signal processing architectures fornetwork microsensors.ó proceedings of the 1997 international symposium on low powerelectronics and design, pp. 173177.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.enabling technologies75jones, mike. 1997. òwhat really happened on mars?ó the risks digest: forum on risks to thepublic in computer and related systems 19(49), available online at <http://catless.ncl.ac.uk/risks/19.49.html#subj1> .lin, t.h., h. sanchez, r. rofougaran, and w.j. kaiser. 1998. òcmos front end components for micropower rf wireless systems.ó proceedings of the 1998 international symposium on low power electronics and design.merrill, w.m. 2000. òcoax transition to annular ring for reduced input impedance at 2.4ghz and 5.8 ghz.ó proceedings of the 2000 ieee antennas and propagation society international symposium, salt lake city, utah, july 1621.merrill, w.m. 2000. òshort range communication near the earth at 2.4 ghz.ó proceedings ofthe 2000 usnc/ursi national radio science meeting, salt lake city, utah, july 1621.pottie, g.j. 1999. òwireless multiple access adaptive communication techniques.ó in encyclopedia of telecommunications, vol. 18. f. froelich and a. kent, eds. new york: marceldekker inc.proakis, j.g. 1995. digital communications, 3rd ed. boston, mass: wcb/mcgrawhill, pp. 855858.reed, j.h., k.j. krizman, b.d. woerner, and t.s. rappaport. 1998. òan overview of thechallenges and progress in meeting the e911 requirement for location service,ó ieeecommunications magazine (april): 3037.reeves, glenn. òre: what really happened on mars?ó the risks digest: forum on risks to thepublic in computer and related systems 19(49). available online at <http://catless.ncl.ac.uk/risks/19.54.html#subj6>.yao, k., r.e. hudson, c.w. reed, d. chen, f. lorenzelli. 1998. òblind beamforming on arandomly distributed sensor array system.ó ieee journal of selected areas in communications 16(8):15551567.yu, t., d. chen, g.j. pottie, and k. yao. 1999. òblind decorrelation and deconvolutionalgorithm for multipleinput, multipleoutput systems,ó proceedings of the spie, 3807.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.763selfconfiguration andadaptive coordinationmany of the anticipated applications of networked systems ofembedded computers (emnets) will be realized only if the systems are capable of configuring and reconfiguring themselvesautomatically. this chapter focuses on mechanisms needed to achieveautomatic reconfiguration. in many emnets, individual nodes will needto assemble themselves into a networked system, find available resourceson the network, and respond to changes in their desired functionality andin the operating environment with little human intervention or guidance.1a set of basic underlying mechanisms will be required to ensure thatemnets are selfconfiguring and adaptive. for example, components willneed to be able to discover other resources on the network and communicate with them. systems will need to be able to sense changing environmental conditions or changing system capabilities and respond appropriately so that the entire system, as well as individual components, canoperate as effectively and efficiently as possible. both software and hardware adaptability will be important; emnets will consist not only of elements that can change their software but also of those that take advantageof reconfigurable computing technologies to adapt limited hardware to1this requirement is central to darpaõs selfhealing minefield program, for example.for more information on this program, see <http://www.darpa.mil/ato/programs/apla/contractors.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination77the operating environment. many emnets will contain components thatare constrained in terms of their physical size, amount of memory available, and/or availability of local energy sources. for these system components, both the need for efficiency and the constraints on how it isachieved will be more severe than is the case for more traditional distributed computing systems. efficient system designs will exploit highercapacity and resourcerich components where they exist in the overallsystem and will exploit the redundancy provided by deploying largenumbers of inexpensive components. many current efforts do not focuson systems that operate under these kinds of constraints. work on thedesign of personal digital assistants (pdas) and cell phones, for example,does not need to take into account very large numbers of interactingelements, distributed control, severe energy constraints, or the kinds ofphysical coupling that many emnets must accommodate. approachestaken in the design of smart spaces for homes or office environments arerelevant, but such systems generally have more infrastructure to supportthem than many of the emnets discussed here.this chapter examines approaches to providing the mechanismsneeded to support selfconfiguration and adaptive coordination ofemnets. the first section defines these key concepts. the second discusses the elements of selfconfiguration and adaptive coordination inexisting distributed systems, serving as a primer on the state of the art.the final section of this chapter outlines the research needed to realize thevision for robust, scalable emnets.terminologyselfconfiguration (sometimes referred to as reconfiguration) and adaptive coordination (sometimes referred to as adaptation) refer to the spectrum of changes that a system makes to itself in response to occurrences inits environment and internally. neither of these terms is meant to conveyinfinite flexibility. the changes that selfconfiguration and adaptive coordination induce in a system should always be within the constraints of thesystemõs planned functionality (admittedly, one such change might be tomodify the functionality of the system). for the purposes of this report,the terms selfconfiguration and adaptive coordination differ with respectto the frequency and degree of change they induce in or respond to fromthe emnet. making a sharp distinction between the two is not as important as recognizing that some techniques are more relevant to one than tothe other. in the rest of this chapter the terms are distinguished in orderto highlight the techniques that are more appropriate for each.selfconfiguration involves the addition, removal, or modification ofelements contained in an emnet, along with the resulting process of esembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.78embedded, everywheretablishing interoperability among the components and locating essentialservices (such as data aggregation nodes in sensor networks). put another way, selfconfiguration is the process of interconnecting availableelements into an ensemble that will perform the required functions at thedesired performance level. as such, selfconfiguration changes the composition of an emnet and may alter the distribution of functionality acrossthe components that make up the system or may even alter the systemõsoverall function based on which components are available.adaptive coordination involves changes in the behavior of a systemas it responds to changes in the environment or system resources. forexample, to achieve a long lifetime, a system may need mechanisms bywhich nodes can mediate their actions based on the density of redundantcomponents. nodes with redundant capabilities might be programmedto alternate responsibility for a given task in the style of sentry dutyrotation. similarly, emnets could implement multiple levels of service,depending on locally perceived conditions or detected events. thus,adaptive coordination refers to changes in operational parameters thatare made because of variations in available resources or load. included inthese resources are available energy, computational resources, and communication bandwidth. in general, adaptive coordination induces lessdramatic changes in system architecture than does selfconfiguration anddoes not alter the systemõs function. the two processes often occur ondifferent time scales. adaptive coordination tends to take place morequickly than does selfconfiguration, with a very short lag time betweenthe moment a change is detected in the operating environment and thetime the system adapts its behavior.another dimension to bear in mind is the level at which the configuration or adaptive coordination occurs. this level can range fromreconfigurable hardware to operating systems and runtime environmentsall the way to applicationspecific code. levels vary in the extent of theeffect of the reconfiguration and/or adaptive coordination as well as inthe amount of code that needs to be stored or retrieved to make thechange. a crucial facility that must accompany emnetsõ ability toadaptively reconfigure themselves is the facility for selfmonitoring. despite some of the most rigorous testing in existence, many of todayõshighly complex systems are prone to failure when reconfigured. telephone switching systems, for example, have suffered severe outages whennew software is brought online. yet this report suggests that emnetsmust be able to change along many distinct axes, perhaps without anexpert present. new system testing and software update technology willhave to be developed. meeting this challenge has proven to be verydifficult, even in more conventional systems; emnets intensify this need.they will have to be able to convey their current operational state to theirembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination79users. as argued elsewhere in this study, establishing that state requiresfar more than just tallying hardware resources. an emnet will require away to monitor how well it is performing and to compare this resultagainst its goals; it will also require a means for reporting such information to users.2the nature of the configuration or adaptive coordination dependsheavily on the type of application the emnet supports. in automobiles,for example, the focus of selfconfiguration would probably be on accommodating the heterogeneity of system components introduced to, andremoved from, the system continuously as, for example, the people, conditions, equipment, and procedures vary. unlike more standard computer networks, such embedded monitoring networks must be built assuming that there is no professional system administration, such that theconfiguration is highly (if not completely) automatic. further complicating such networks are two typical requirements (as, for example, wouldbe needed for automobile control): that the overall network be capable ofmaking certain service guarantees and that some operations (such asnotifications of life or safetythreatening events) take precedence overother forms of network traffic.in sensor networks that might be used for precision agriculture orenvironmental monitoring, system composition will vary less because theapplication is more constrained, while more attention must be paid toadapting the nodesõ operational parameters to unpredictable and varyingenvironmental conditions. this is particularly challenging and critical inenergyconstrained devices that must minimize their expenditure of communications resources on overhead functions and in which opportunisticlistening can be relatively expensive because of the dependence on powerconsuming communication resources (for example, a radio or other wireless communications device). extensive capabilities that incorporate bothadaptive coordination and reconfiguration will be required in systemssuch as those used on a battlefield, where changes in both the environment and system makeup can occur rapidly yet certain service guaranteesare absolutely required.selfconfiguration and adaptive coordination indistributed systemsthis section discusses the elements of selfconfiguration and adaptivecoordination in existing distributed systems. these elements include the2a longterm trend of diminishing margins against the goal could alert the users to thesystemõs need for attention, for example.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.80embedded, everywherenotion of service discovery, as well as the critical issues of interfaces andinteroperability. the discussion is primarily applicable to selfconfiguration; however, it is likely that adaptive coordination will require similarelements (e.g., mobile code). this background is useful in preparing toanalyze the issues posed by emnets. how emnets differ from othertypes of distributed systems will become clearer as the analysis proceeds;later in this chapter, research challenges in these areas are examined. ingeneral, emnets present more extreme versions of the problems encountered in distributed systems, but they also pose a few unique problems oftheir own, such as low power requirements.discovery in distributed systemsautomatic selfconfiguration requires the ability to interoperate withnew and old system components without human intervention. systemcomponents must be able to automatically discover each other and theservices they represent. building on the interface concepts of networkconfiguration, wire protocols, and code mobility, this subsection discussesthe issues involved in device and service discovery and how they relate toselfconfiguration. how entities on an existing network communicate isgenerally viewed as the interoperability problem. how those entities findeach other, advertise their own services, or join the network is generallytaken to be a separate problem, referred to as the discovery problem.generally, the discovery problem can be divided into four parts:¥how does a network entity join the physical network; that is, howis it authorized and given a network address and a network identity?¥once an entity is on the network and wishes to provide a service toother entities on the network, how does it indicate that willingness?¥if an entity is looking for a service on the network, how does it goabout finding that service?¥how does geographic location affect the services an entity candiscover or select for use?joining the networkin traditional computing networks, the task of joining a system to anetwork has been done by hand: a system administrator configures thesystem with a particular network identity and then updates the appropriate routing and/or naming tables with the information needed to find thenew member of the network. as networks have been scaled up, techniques have been introduced that allow the partitioning of the large network into smaller subnets and the propagation of (manually entered)bootstrapping information from the subnets to the larger networks. howembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination81ever, the advent of larger networks and networks that have little or noprofessional administration (such as those in the home or in networks ofembedded systems) has led to an interest in automating this bootstrappingmechanism.mechanisms that automate the joining to a network have been aroundfor some time. the apollo domain system, for example, allowed a node(workstation or server) to be connected to the network by finding a location broker with which the new node registered. then, having completedthis registration, the new node could be found by any other node in thenetwork. the appletalk protocol enabled not only computers but alsoperipheral devices, such as printers, to join the network and be foundautomatically by other entities in the network. however, these mechanisms have been confined to particular (proprietary) networks and havenot been generally adopted, especially in networks of smaller, embeddedsystems. one reason is that such mechanisms are based on resourcerichenvironments as opposed to the resource and energyconstrained environments that many embedded systems and most emnets must contendwith.the actual mechanism most generally used for such bootstrappingtends to be conditioned (if not fully determined) by the physical networkto which the device is attached. in an ethernet transmission controlprotocol (tcp)/internet protocol (ip) environment, for example, the dynamic host configuration protocol (dhcp) is commonly used to handout addresses to entities that are connected to the network. a part of theuniversal plug and play (up&p) specification is a mechanism allowingdevices to selfassign a network address to themselves on networks wheredhcp is not present. for ieee 1394 (otherwise known as firewire),however, a very different mechanism is needed because the network itselfwill produce the equivalent of a bus interrupt when a new device isplugged in, thus informing every other device of the presence of a newentity. networks designed for cell phone use have yet another way ofallowing the phone to be recognized in the cell. the roaming functionallows a phone to register its new location with a central database thatthen tells the phoneõs home location how to reroute calls. the range ofservices achievable by automatic discovery and joining mechanisms is inpart determined by whether nodes have unique identifiers or whether atboot time they are literally identical.joining the network entails locating essential services as well as obtaining networklevel address and routing information. existing mechanisms make use of multicast3 and wellknown servicelocation addressesto bootstrap this process.3multicast describes communication on a network between a single sender and multipletargeted receivers.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.82embedded, everywhereadvertising and finding servicesthe problem of advertising a service once a physical connection to thenetwork has been established has been approached in a number of different ways. perhaps the most common approach in general computingsystems has been naming and directory services, in which the service thatwishes to advertise itself creates an entry in a naming service or a directory service that allows others who know the name or description of theservice (or at least the type of service) to get a reference to the new offering. such mechanisms generally assume that there is a human beingsomewhere in the loop, because both naming systems and directory servers are string based, with the meaning of the string left to the user. whenprograms look for services, they need to know the name or descriptionunder which the service is registered. some directory services haveevolved rather complex ontologies in the form of description schemas toallow such programmatic access to services.a different approach has been taken by service traders and the jinisystem (arnold and waldo, 2000), in which services are identified by theinterfaces they support. in a traditional trader system (such as thosefound in the distributed computing environment (dce)4 or the common object request broker architecture (corba)5 trading service), aservice registers itself by indicating what interfaces it supports; clientslook up a service by asking for a reference to something that supports aparticular interface. if more than one object has been registered thatimplements a given interface, then any of the objects can be returned bysuch a query. in the jini lookup service, services register by their javalanguage type; they can be returned to any client asking for somethingthat is at least an instance of the requested class (for example, the returnedobject might be a subclass of the requested class).the problem of how an entity finds the place to advertise its servicesis not always addressed by the systems described above; most naming ordirectory systems consider this problem to be part of the general bootstrapping mechanism and assume that it is dealt with in some fashionoutside their scope. the service location protocol (slp) is a mechanismthat enables either clients or services to find a service directory. essentially, the entity interested in finding a service directory (either to registera service or find one that has been registered) issues a multicast request4dce is an industrystandard software technology for setting up and managing computing and data exchange in a system of distributed computers.5corba is an architecture and specification for creating, distributing, and managingdistributed program objects in a network.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination83that will return the address of a servicefinding service. this servicesupports a wellknown interface that allows querying for a service directory, which is much like a standard directory service in which servicescan be registered under a description or found if they match a description.the jini system is similar to slp in that it begins (on tcp/ip networks) with a multicast request to the local network neighborhood.rather than returning a directory of service locators, however, the jinimulticast request returns a reference that implements the interface to ajini lookup service (including the stub code, or driver, allowing communication with the service) that can be used by the service provider (orclient) to access that lookup service directly. universal plug and play(up&p) also makes use of a multicast request, but in up&p what ismulticast is a description (in the form of a universal resource locator(url) indicating where the description can be found) of the device that isjoining the network. all entities that might want to use such a devicemust watch for such a multicast, and based on the description they willdetermine if they have the code needed to communicate with that device.there is no central repository of services in the up&p mechanism.bluetoothõs service discovery protocol (sdp) is specifically for bluetoothcommunications and focuses on discovering services available from orthrough bluetooth devices and can coexist with other service discoveryprotocols.not all basic networking systems support multicast, so any extensionof these types of servicefinding protocols to such networks would require that some other bootstrapping mechanism be used to find the initialrepository of descriptions or objects. this mechanism could be as simpleas a conventionally agreedupon url that would be used to identify sucha repository or a wellknown name of some other form. such approacheswould need to find a way of preventing the entity with the conventionalname from becoming a single point of failure (or they would need todetermine that such a single point of failure was acceptable in the particular application). other networks might allow entirely different approaches.an example of this is ieee 1394 (firewire), in which, as mentioned previously, attaching a device to the network generates a wirelevel interruptto all other devices attached to the network. on such a network, theservice repository could simply notice when a new device was attached tothe wire and send to that device the information needed to connect to theservice repository.locationfor systems deployed in the physical infrastructure, a serviceõs location (either absolute or relative to another entity) may determine how it isembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.84embedded, everywhereused or even selected. the mapping between physical location and network connectivity is important. (see chapter 2 for a discussion of thetechnologies that enable the determination of geographic location.) inwired or hybrid networks, two devices that are physically close may be,in fact, quite distant in terms of network communication. for example, adesktop personal computer (pc) and a cell phone may both be networkenabled, but for them to communicate, packets must travel through manynetwork segments, including the buildingõs network, the link between thebuilding and local backbone, the connection between the backbone andthe cellular phone company, another hop to the appropriate base station,and finally, from the base station to the phone itself. thus, when a deviceneeds to determine, for example, the closest printer, network proximity isnot at all likely to be an accurate measure.geographic location is intimately connected to discovery. if eachdevice knows its own geolocation and can provide that information to thediscovery servers, then it may be possible to answer the question aboutòclosenessó during the discovery phase. access to services may also bebased on location. if one assumes physical security measures permit auser to enter a particular space, then services locally available in thatspace can be put at that userõs disposal without requiring further authentication. without location information, users would have to obtain accessto the local networks, with accompanying security risks. thus, locationcan be quite useful in optimizing service discovery as well as in connecting the physical and virtual worlds so that security measures in one canbe applied in the other.in other types of emnets, particularly resourceconstrained, wirelessnetworks, network organization needs to correspond more closely withgeography in order to be efficient in its use of scarce energy resources(since communication over longer distances consumes significantly moreenergy). in these systems, geolocation may serve as a building block fororganization of the network itselfñfor example, through the use of geographic routing (karp and kung, 2000).interfaces and interoperabilityboth selfconfiguration and adaptive coordination require interfaces,or standardized ways of communicating between components. an interface is simply a convention that is agreed to outside the scope of thecommunication of interest but that permits the communication to occur.these interoperability agreements can exist at every level of system abstraction, including electrical, signaling, transport, network, and application levels. moreover, these agreements extend to code mobility andapplication adaptation. when emnets communicate, they must assembleembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination85a collection of information that will be interpretable by the receiver. thisinformation may include not only data but also code that the receiver canexecute to interpret the data, process it in some way, or forward it to otherentities. the format of the information must comply with the interface onwhich both entities agree in advance.at the lowest level, interoperability requires the assembling of information (data and code) into a sequence of bits that will be properly interpreted by receivers on the network. at higher levels, this means supporting an abstract machine for which the sender can include instructionswithin the information it sends. if there is agreement with the receiver onthe execution semantics of these instructions, this serves as a powerfulmodel for extending the functions that each device is capable of performing. that is, it becomes possible to move code from one entity to anotherso that functionality can be modified and extended in ways not predictedby those who originally deployed the device. other levels of interoperability include transport protocols (e.g., tcp/ip) that permit a sequenceof network packets to be generated and reassembled at the other end, aswell as remote procedure calls (rpc) and remote method invocations(rmi) that permit one entity to execute an operation on another by sending parameter data and having the result returned.how interoperability is to be achieved is often one of the major design decisions that needs to be made for networked systems.6 in traditional distributed systems, methods such as dce, rpc, and corba areimplemented to pass a method or procedure identifier to the receiver toindicate the code that is to be invoked on the data by the receiver. parameters are linearized and included in the rpc packet. more specializedsystems can make either or both of these classes of information (procedure identifier and input parameter data) implicit. in a simple system inwhich data are sent from embedded sensors to a central processing node,only the data need be transmitted, because the operation to be performedon the data is known by the receiving node. in some publish/subscribesystems, even the data that triggered the notification of an event need notbe explicitly passed, because the notification itself is enough to indicatethe data that triggered the notification. in a more complex, ad hoc sensor6this discussion describes interoperability from the perspective of systems that use acallreturn or remoteprocedurecall model of communication. networks can also be set upto communicate through message passing by using events in a publish/subscribe fashionor by using various forms of shared memory with adaptive coordination technologies. atsome level, however, all of these communication approaches are equivalent with respect tothe problems discussed. although the exact details of the problems may vary from oneapproach to another, the basic outlines of the problems and the solutions are similar in all ofthese approaches.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.86embedded, everywherenetwork, intermediate nodes between the originator and its final destination may aggregate the data. thus, the interpretation of the data maychange as it travels from node to node. each node may want to indicateto the next how to properly interpret and process each data item.the remainder of this section discusses address configuration, wireprotocols, and code mobility as illustrative examples of key interface andinteroperability concepts.address configurationone of the most familiar types of selfconfiguration is the process bywhich new devices are added to local area networks. the dynamic hostconfiguration protocol (dhcp) performs this function on ip networks. adevice new to the network must obtain a new ip address in order to havepackets routed to it appropriately. a dhcp server for a network allocates a set of ip addresses to acceptable visitors for a limited period oftime. dhcp servers do not have to be present on every subnetwork butmust be reachable through the standard routing mechanisms. a devicefinds a dhcp server using a discovery message that is propagated by thenetwork routers to a nearby dhcp server. the server then responds withthe ip address for the device to use. this address may be dynamicallyallocated or determined based on the physical address of the deviceõsnetwork interface card (providing a mechanism for mobile devices tostore and later retrieve their network parameters). devices can easilydetermine if they need to obtain an address using dhcp if their requestpackets are not acknowledged. this is an indication that the ip addressbeing used is no longer compatible with the network at which the deviceis now located.the dhcp packet format provides a standard interface for devices touse in connecting in a new network environment, thus ensuring interoperability at the level of ip packets. the serversõ functions provide ahigherlevel interface that provides addresses only to authorized visitorsand only for limited periods of time.wire protocolsthe most common way of ensuring interoperability is to define astandard protocol that all entities on the network will use to identifyoperations and convert to and from their own internal data representations to the data representation used on the wire. each entity on thenetwork contains some code that performs this conversion. in a standardrpc system, the code used by a client for this purpose is called the stubcode and the corresponding code on the server side is called the skeletonembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination87code. this code is often produced by a compiler, which uses as input adescription of the interface offered by the server, although handwritten ormanually specialized code is often used to improve the performance ofthe overall system.this approach to interoperability has a number of advantages. itmakes very few assumptions about the devices that make up the network,requiring only that they have the computational power to create thestream of bits and transmit them over the wire (if the entities are sendinginformation) or to recreate information from a stream of bits receivedfrom the wire (if the entities are receiving information). much of the codeneeded to create the wire stream or recreate the data from the wire streamcan be generated automatically from fairly highlevel descriptions, allowing a higher level of abstraction to be presented to the human programmer.there are disadvantages to this approach as well. because such systems are defined by the wire protocol, the patterns of communicationbetween the various entities are very difficult to change. such a changeessentially requires a revision of the wire protocol, which in turn requiresthe eventual updating of all of the communicating entities on the network. such changes are generally needed because of changing hardwareor changing requirements, which can be thought of as a scaling of thenetwork over time. the longer the network is expected to run, the morelikely it is that changes will be needed to accommodate new hardware (ornew software services offered to existing hardware) or that the tasks expected of the network of devices will change or evolve (or, perhaps, a flawin the original design will need to be fixed). sometimes these changes canbe made using the existing protocols; however, because those protocolsdefine the information sent from one entity to another, it is often necessary to enhance the protocol before such changes can be made.mobile codemobile code, or the capability to dynamically deliver and load newcode to be installed on network nodes, provides a mechanism for extending the lifetime of a system. the idea is to create a higher level of abstraction, an interface agreement for communicating information that is morecomplex semantically. by elevating the level at which the common interface is defined, mobile code enables the protocols used by system nodesto be updated over time or modified for specialization or optimizationpurposes. mobile code still requires an initial interface agreement regarding how the code will be transmitted and loaded, but given this foundation and a constant physical layer for communication, it provides a graceful upgrade mechanism for network nodes.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.88embedded, everywhererunning mobile code in current clientserver systems, what is known byeach of the communicating entities is the (programmatic) interface usedby the client to talk to the service. when the client wishes to use thisinterface, the client receives from the service a reference, which includesthe stub code needed to talk to the service. this code is loaded into theclient and presents to the client the programmatic interface that is expected for that service. because the actual form of the bits on the wire isencapsulated in stub code that comes from the service itself, the wireprotocol becomes a private matter between the service and the code ithands out. the client can be, in some sense, far more ignorant; rather thanneeding code that knows how to translate into a common wire protocol,the client needs only the knowledge of which call method to use. thedetails of how information is encapsulated into a stream of bits are knownonly to the code supplied by the service.the disadvantage of this approach is that it requires considerablymore from the entities participating in the network. in particular, it requires that all of the entities be able to load code dynamically and thatthere be a form of code that all of the participants can understand. forthis to be possible there needs to be some platformlevel homogeneity inthe network that allows code moved from one machine to another to runon the receiving machine. there is a spectrum of approaches to providingthis common level. one approach (used in some active networks research7) is to construct the network out of devices that are homogeneousat the lowest level, meaning they use the same processor and operatingsystem. among the advantages of this approach, optimized binary codecan be moved and run on another machine, and resource use on thevarious devices can be controlled. however, the approach limits theflexibility of the overall network, making it difficult to introduce newtypes of nodes; it also presents problems in scaling over time, because thenetwork of devices will not be able to make use of new processor orbinary code environments. it is thus highly impractical. it also requires alarge amount of trust in the code being moved, as there are no restrictionson what that code can do and no ways of establishing that the code iseither well meaning or well written.at the other end of the spectrum is an approach that uses a highlevelscripting language, such as tcl or python, as the homogeneity layer.7according to a darpafunded program at the massachusetts institute of technology,active networks òallow individual users, or groups of users, to inject customized programsinto the nodes of the network [and] enable a massive increase in the complexity andcustomization of the computation that is performed within the network.ó see <http://www.sds.lcs.mit.edu/darpaactivenet/> for more information.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination89this approach requires that every member of the network have both theinterpreter for the common language and the necessary native librariesavailable so that the portable scripts can be run. it provides a good layerof insulation from the hardware but requires a fairly large execution environment and set of libraries; it pays the price in performance (most of thescripting languages are between one and two orders of magnitude slowerthan object code performing the same functions) and, correspondingly, inpower consumption. however, this approach is safer than moving binary code, because the scripting language can incorporate limits on whatthe code can do (as achieved in òsafe tcló).a middle ground between these two divergent approaches is to define a virtual machine and move code that assumes the existence of thatmachine; this is the method used in systems (such as jini) built on java.this approach allows a more compact representation of the mobile codethan can be found in most scripting languages, because byte codes aremoved rather than text. the environment is far safer than those in whichpure binary code is moved, because the virtual machine can make checkson the incoming code and enforce security policies. a rather large environment is still required, but it is often no larger than that required by thescripting approach, and work is being done to make it smaller. theperformance degradation is smaller than that found in the scripting approach, although still in the range of 10 to 20 percent.resourcesnewly introduced code may require more resources than doesthe code already extant at a node. these resources may or may not beavailable at that node or may be beyond a limit set for the function themobile code performs. therefore, negotiation and resource allocation areclearly important aspects of this mechanism. a device seeking to introduce code into another device may first have to negotiate for the necessary resources and must expect to propagate the code only if it is grantedthose resources. the negotiation will include presenting the appropriateaccess privileges for modifying the code to be run on another node.advantages of mobile codemobile code has many advantages over wireprotocols. first, the way services represent information on the wire canbe updated without the need to coordinate updates with all clients andservices simultaneously. because the stub code used by the client is obtained, when needed, from the service itself, the service can change thecommunication protocol used between the client and the service by simply updating the code handed out. the client will receive the new codeautomatically on an asneeded basis when it next wants to contact theservice. second, this approach allows different implementations of thesame service to use different communication protocols. because the comembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.90embedded, everywheremunication protocol is used between the servicesupplied stub and theservice, the protocol can differ among services, even if those services areimplementations of the same interface.third, if the method of code movement is combined with a polymorphic language and virtual machine such as java or inferno, then the service can evolve in an upwardly compatible fashion to offer new functionality without being incompatible with old clients. if the new functionalitycan be expressed as an extension or subtype of the existing functionality,then the code handed out by the service to the client can implement all ofthe existing procedures or methods as well as the new procedures ormethods. this design enables old clients to treat the service just as theyalways did, while allowing new clients (or clients that can reflectivelydiscover and use the new functionality) to use the new aspects of theservice. this advantage can be obtained, however, only by requiring auniversal type system in addition to code mobility.adaptive coordination in existing networksmaking any network of systems adaptive is a challenge, and emnetsincrease the challenge by adding constraints not found in other systems.moreover, the type of adaptive coordination needed in emnets has onlyrecently begun to be studied in more traditional networks of computingsystems, so there is little existing knowledge on which to draw. as background for an analysis of research needs related to emnets, this sectionprovides examples of how adaptive coordination is handled in more traditional systems. the problems addressed are load balancing, ad hocrouting, and tcpõs adaptive congestion control mechanism.load balancingload balancing in distributed systems received much research attention in the 1980s as distributed computing became more prevalent. theessential problem is how to distribute processing, storage, or access demand across a set of servers as that demand increases and in some casesas the availability of underlying resources (e.g., servers) increases or decreases (mullender, 1992). typical load balancing requires collecting loadstatistics from servers and assigning new demand based on those statistics. some approximations may be used in the absence of current loaddata. systems may reassign demands based on data or reassign only ifthere is a failure. techniques vary with regard to optimization level,robustness, communication cost, and convergence time. the more distributed the system, and the greater the delay and delay variance, theembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination91more difficult it is to collect timely statistics and achieve a solution that isboth efficient and stable.load balancing in networks, usually in the form of adaptive routing,addresses one extreme situation at a time in a highly distributed system.the problem is most challenging when the network is large and covers awide area, in which case global load information for all network nodesand links is clearly unachievable. therefore, adaptive routing relies onpartial information, which may be partial in scope, coverage, or time (thatis, out of date). a classic story of early arpanet design was the moveaway from highly adaptive distributed routing to a more stable andslower adaptive routing scheme. the old arpanet routing scheme(mcquillan et al., 1980) attempted to move traffic away from congestedlinks, but by doing so it encouraged the congestion to move to the newpath in the network, eventually causing all the traffic to move back to theoriginal path! these oscillations are a simple example of the challengesassociated with building adaptive systems. load balancing is appliedsuccessfully when the information required can be obtained in a timelyfashion and when the rate of controlled change is much slower than thephenomena to which it responds. within isp networks (which are reallysubsets of the larger internet), such techniques are applied in the form ofòtraffic engineering.ó however, even in this more limited context, thereis a lot of manual configuration involved.more recently, verylargescale distributed services have been proliferating in the context of the world wide web. there are web servers thatcan be expanded on the fly, by adding more computing capacity withoutshutting down the existing web server and then using the added capacitywhen traffic is heavy.8 these systems adapt to heavy load by allowingthe addition of new machines to the web server cluster in a way that istransparent to system users. this approach can be viewed as humanassisted configuration of the system; once the administrator adds the system to the physical cluster, the software is able to automaticallyreconfigure itself to make use of the extra capacity.ad hoc routingin recent years, other forms of adaptive behavior have been exploredin networked systems. one is ad hoc routing (corson and macker, 1997).traditional routing starts with a fixed location for nodes and links andadapts only to occasional node and link failures and recoveries and to8see, for example, the hosta system from concept technologies, ltd., available at<www.concepttechnologies.com>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.92embedded, everywherevariable congestion. ad hoc routing was developed to provide automatic, nonmanual construction of a network when the network routingelements are not in a fixed topology, that is, when they are mobile. adhoc routing protocols continually adapt to changing topology, whereastraditional protocols adapt to topology changes much more slowly andless frequently. the form of adaptive coordination required in ad hocrouting is fairly well understood and seemingly manageable, althoughthere are few examples of operational ad hoc networks. there are clearlylimits to the ability of any scheme to keep up with continual rapid change,and there is ongoing work to develop methodologies for characterizingsuch limits, as well as the behavior of adaptive coordination mechanismsas they approach these limits. related to the work in ad hoc routing ispoweraware routing (sohrabi and pottie, 1999), which attempts to adaptroutes in such a way as to maximize the total network lifetime as determined by battery depletion. this work is indicative of the type of adaptive algorithms that will be needed to realize the vision of robust, longlived, and scalable emnets.adaptive congestion control in tcpanother form of adaptive behavior has a completely distributed, local natureñtcpõs adaptive congestion control mechanism. tcp is thetransport protocol run in the internet over the ip protocol. tcp is an endtoend protocol run on endsystem computers (from laptops to desktoppcs to workstations to large servers). tcp provides a virtual connectionto the applications that use it, offering inorder, reliable delivery of data.the internet over which the data are sent exhibits varying data rates dueto the heterogeneity of underlying link speeds and variable loading onthe links. van jacobson introduced adaptive congestion control into tcp(jacobson, 1988) by which the source of a data stream would reduce itssending rate when it experienced packet loss, an indicator of congestion.when no loss was experienced, the sending rate was slowly increaseduntil all data were sent or additional loss was experienced. in this way,each of the multitude of end systems on the internet independently adaptsits behavior to the dynamic conditions experienced on the network, resulting in a more or less stable systemñcertainly more stable than it wasbefore adaptive congestion control was introduced. the specifics of thetcp congestion control algorithm have evolved over the years, and asizable body of research has emerged concerned with the characterizationof tcp and the aggregate effect of tcp adaptation on the network (falland floyd, 1996). however, this remains an area of active research because of the challenge associated with characterizing such a large systemof adaptive elements.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination93research challenges for configuration andadaptive coordinationthis section outlines key research challenges related to configurationand adaptation in emnets. the subsection on adaptive coordination isthe most extensive because the concept is fairly new, especially as it applies to emnets, and there is still no extensive research base on which torely.research issues in selfconfigurationas background, it is useful to outline some design basics and criteria.emnets will appear in hybrid environments of mobile and static networks. users will expect to connect to networks and services as theyenter vehicles, buildings, and outdoor environments. the nodes themselves will be diverse in capability, energy availability, nature and qualityof connectivity, and priority. physical node access will depend on context. variability in priority will dictate when and if a node is revealed orhas services revealed to it at the physical layer. variability in the nodepopulation will introduce further complexity. the addition of new nodesto a local cluster may not be permitted owing to performance constraints.at other times, conversely, it may be desirable or even necessary to incorporate highpriority nodes and their services into the network.the wireless physical layer is limited by low data communicationsrates, the sharp decay of radiated power with increasing range, and susceptibility to interference. this implies that network resources may notbe consistently available at a given point in the network and may exhibithighly variable performance across space and time. nodes may appearand disappear according to variations in the wireless channel environment. the wireless physical layer is also diverse. simultaneously presentin the environment are systems ranging from localarea, spreadspectrumnetworks to widearea cellular, pager, and even satellite communicationsystems. methods are needed for joining these different networks andbridging across adjoining cells. support for networked embedded systems must include capabilities for lowbitrate, lowpower, lowcost accessfor virtually all nodes.ad hoc sensor networks provide an excellent example of the issues tobe addressed. many applications require the deployment of sensors overwide areas with no predetermined arrangement. the devices must discover each other (or at least their nearest neighbors) and decide howsensor information will flow through the network they collectively form.different devices may take on different roles as generators, routers, oraggregators. global efficiency can be achieved only if locally derivedembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.94embedded, everywhereinformation is propagated to other nodes in the network. devices willneed to configure their functions to produce the desired overall effectrather than optimizing for strictly local concerns. thus, a node may takeon the role of router and act as a communications hub, but at the cost ofincreased energy use. when it eventually loses its ability to perform thefunction, another device will take its place. determining how local decisions can lead to efficient global effects is a fundamental challenge foradaptive coordination in ad hoc systems.emnets will necessarily be composed of heterogeneous elements.devices will be optimized for specific functions. for example, some sensors may be small and numerous but also highly constrained, while localaggregators may be more powerful devices with longerrange communications capability and larger power supplies. in addition, the long lifetimes of these systems and the need for adaptation may very well requirethe ability to upgrade and/or install new code. trust models need to bedeveloped that will not only control the admission of new code but alsopolice it to verify it works as advertised prior to gaining admission.finally, these systems must be resilient in the face of failures that occurwhen devices, communications, or other resources become unavailable.the following paragraphs elaborate on these themes.heterogeneityconfiguration via mobile codegiven the expectation of a rapid evolutionin hardware, networking protocols, and basic networking algorithms inemnets, an approach to discovery and configuration based on mobilecode seems promising. such an approach allows these components toevolve separately, rather than requiring that the whole emnet evolve inlockstep. however, interesting and important research issues are stillpresented by approaches that use mobile code.although all of the approaches to implementing mobile code havesome advantages and disadvantages, certain issues are common to all ofthe approachesña point that often gets lost in the discussion of whichtechnique is best. these issues highlight some of the fundamental engineering tradeoffs that will need to be made in constructing networks ofembedded systems, especially those made up of devices that are constrained in terms of memory, processor speed, power, and bandwidth.9the most obvious issue is the tradeoff that needs to be made between9many of the issues raised by amorphous computing (abelson et al., 2000) may be relevant to the heterogeneity of emnets, including how to obtain coherent behavior fromlarge numbers of diverse components and how to develop methods for programming suchsystems.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination95memory use and the use of mobile code. for many of the small, embedded components in the systems that are the focus of this report, memoryis one of the most precious resources. in some ways, the whole notion ofmobile code conflicts with memory conservation; the idea that the recipient of the mobile code needs to know only the interface to the receivedcode, and that all else is hidden behind an interface that is implemented(as needed) by the supplier of the mobile code, means that the recipient ofthe code has given up the capability to control memory use. any piece ofmobile code may exceed the amount of memory available at the recipient.even if no single piece of code violates the memory constraints on therecipient, as the network scales up (and more code is moved), there willcome a point at which an otherwise acceptable (and perhaps small) pieceof code will need more memory than is available.this issue cannot be dealt with at the component levelñeven if eachpiece of mobile code is written to be as small as possible (which might notalways be the case)ñbecause it is the sum of the pieces of mobile codethat causes the problem. this exemplifies the need to understand howlocal decisions can affect global properties, and vice versa. the codeactually loaded onto a node is determined by the use of the network in aspecific situation. thus, it is an aspect of the design of the network, notthe components. on the other hand, the network should not have toknow the details and limitations of the components present. its properties are abstract and implemented by the underlying components. indeed, one reason for using mobile code is to allow building the networkwithout having information about the individual components.protocolbased configurationmobile code offers the opportunity to tailordevices to new applications and evolve their functions over time. however, the resource requirements for mobile code may dictate other approaches instead, especially on the smallest devices used in emnets. suchapproaches, based on prearranged wire protocols used for communication between the various components, present their own research issues.the first issue is the need to develop an ontology of devices so thatthey can be described in a way that is natural and consistent across different systems. if services are to be discovered, then they must be discovered with a description that ensures they will be able to use the wirerepresentation sent to them and to generate data in the wire representation expected from them. how such a convention can be described andhow it can be reasonably enforced in largescale systems such as thoseenvisioned in emnets is an open research question.once this ontology has been described, a set of associated wire representations for the data to be transferred to and from devices of each typeneeds to be defined. these wire representations need to allow queries ofembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.96embedded, everywheredata that has been sensed in the environment as well as the transfer ofcontrol information from one member of an emnet to another. how todefine these representations in a way that will allow the system to evolveis an open research question. in fact, the research issues surroundingprotocolbased, selfconfiguring systems seem to be the converse of theproblems posed by mobilecodebased systems. each approach can solvesome problems that arise with the other but is also subject to problemsavoided by the other. protocolbased approaches allow solutions thatapply to devices that are severely resource constrained, but they producesystems that are brittle and lack easy paths of evolution. mobilecodebased approaches allow easy system evolution, but at the price of abstraction, which consumes what could be scarce resources such as memoryand communications capabilities.a promising area of research might center on combining the twoapproaches in a hierarchical fashion. small groups of devices could bebuilt using a protocolbased approach. together, these groups could possess enough resources to allow utilization of the mobile code approach.this method would allow the overall system to evolve, although groupsof nodes in the hierarchy would need to evolve in a coordinated fashion.such localized, planned evolution is much easier to accomplish than global planned evolution in largescale systems. at the large scale, sharedresources could enable use of the mobile code approach, which allowspiecewise evolution of the overall system. thus some devices in emnetsthemselves or in the networking infrastructure to which they are connected can serve as code proxies that can offload computation andmemory resources from the more resourceconstrained devices in the system. of course, it will now be necessary to communicate with theseproxies or groupings more frequently than if the computation could havebeen performed locally. this degrades power consumption and reliability but could provide a more flexible evolutionary path than simply overprovisioning every device. in an agricultural context, for example, theirrigation and fertilization system might operate as a sensor network withrelatively constrained devices running wire protocols. however, the controller for the systems might be a more capable, generalpurpose computing element that would interoperate with the rest of the enterpriseõs inventory and control processes and would benefit from the longtermflexibility of using mobile code technology.discovery protocolscurrent discovery protocols, whether based on wireprotocols or mobile code, require that the entity entering the network beable to find, either directly or indirectly, the other entities of interest in thelocal network neighborhood. considerable research (and product development) is being done on discovery protocols and join protocols overembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination97ethernetbased tcp/ip networks. these networks have a number ofproperties that are assumed to exist, a prerequisite for such protocols towork; in particular, the ability to multicast with limited scope is requiredby all of the existing or proposed discovery mechanisms. not all networks that are currently in use or being thought about support thesemechanisms, however; how discovery would work over such networks isan open issue.a research issue that needs to be addressed is how discovery mechanisms of any sort can be scaled to larger networks. for discovery mechanisms that are purely peer to peer (that is, there is no rendezvous entity atany level), it is not clear how this can be done other than by specifyingsome form of region of interest in the networkña concept that is not wellsupported in existing network topologies. this issue is further complicated by the potential dissonance between geolocation and network proximity, discussed earlier in this chapter.for discovery protocols that rely on the collection of entity information in some sort of lookup or directory structure, an approach to scalingcould be to form a hierarchy of such lookups, with the leaf nodes of thehierarchy consisting of the lookups contacted by the discovering entitiesand higherlevel lookups consisting of information about the previouslevel of lookup. this approach is standard in hierarchical naming systems, but it is less clear how the approach would work in systems designed to allow programs to find other programs. in such systems, inwhich the entity to be found is often represented as something other thana humanreadable name, it is not clear how to propagate the informationabout the contents of a lookup service into upper levels of the hierarchy.some work has begun in this area, and it may be a scalable alternative tothe multicastbased, publishsubscribe mechanisms that are used locally(yu et al., 1999). in some contexts, this lookupbased approach is preferable to the alwayslisten approach of multicast because of the energy costsassociated even with òlisteningó on lowpower wireless channels (seechapter 2).the issue of lowpower discovery is key for emnets with large numbers of small sensor nodes. at this time, lowpower discovery emphasizes the assembly of the physical layer at low power. this means, forexample, that both the transmit and receive duty cycles are maintained ata low rate. unique complexities arise when discovery of nodes and physical layer assets must occur in a multihop context. the need for correlationto physical location further complicates this issue. the cluster architecture is often required for typical deployments. for example, in a healthcare environment, individual clinical spaces will form embedded systemclusters, which may have weak interactions with neighboring clusters.energy, bandwidth, synchronization, and information sharing will motiembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.98embedded, everywherevate clustering. despite the progress that has been made in developingapproaches to discovery and interoperability, additional research will beneeded to extend these principles to emnets. trust and failure modelsthe ability of emnets to selfconfigure brings up a set of issues related to trust among system components, admission and allocation toresources, monitoring and policing, and the ability to deal with failures,some of which may be intentionally inflicted. in addition, means areneeded to oversee and administer the status of the whole system; thisincludes its upgrade status, patterns of resource usage, and overall system health.admission controla critical unresolved issue has to do with how tocharacterize components and the code they run. components must beable to make local decisions about what code they will run, whether itresides locally or needs to be imported as mobile code from another node.the strength of mobile code draws, in part, from the ability to distinguish between the interface (which is all that the client of the mobilecodeservice needs to know) and the implementation of that service (whichgets moved into the clientõs address space and hides the details of theservice from the client). the implementation of the mobile code canchange as new hardware, wire protocols, and software services evolve.the client that will run the mobile code knows only about its functionalinterface. the challenge is that there may well be a set of characteristicsimportant to the client that is normally not discovered. such characteristics might include the timing constraints or guarantees that the serviceneeds to meet to function properly, the amount of bandwidth or power itrequires, and its memory requirements, including the potential downloading of the code of subcomponents.the problem is that an interface describes only the syntax needed totalk to the service and the broadest notion of the semantics of the service.other semantic aspects of the service may also be important, but there is alack of agreedupon methods for specifying such semantic characteristics.techniques that have been developed for software abstraction offer nowelldefined middle ground between the interface and the full definitionof the implementation. an example of a characteristic that might beneeded is quality of service. information about average and worstcasedelay bounds might be required for some application domains. considerthe problem of trying to track a vehicle and then collect an image. thenodes that are detecting and exchanging information for localization purposes must do all the tracking in time to trigger the correct imaging deembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination99vice. how to combine a description of the guarantees that a service canprovide with the requirements of the client on the service and the requirements of the service on the client is an area open for research.emnet elements need to be able to gather this information about theservice they want to use so as to make intelligent admission decisions.however, this is not the end of the issue. once they make the decision torun the code, they need to ensure that it functions as was advertised.monitoring and policing are therefore needed to verify the service codedoes not overstep the agreedupon bounds. mechanisms are needed tostop code that does not live up to its contract. admission control andpolicing decisions are further complicated by negotiations betweenemnet elements as to who should run which services. if a device agreesto run a service that other devices are counting on, it has to devise a planfor offloading those functions if it finds itself unable to meet the serviceõsrequirements or if the service oversteps its bounds. all of these issuespresent difficult challenges for the developers of software for emnets andcall for significant research.trust and securitytrust models that can be applied to code (as opposedto people) need be investigated. when code is moved on behalf of aservice or device on the network into the address space of a client, theclient and service need some way to decide on the level of trust betweenthem. in some embedded systems, trust may not be an issue (for example, when only trusted sensors are allowed into a sensor network). inothers, however, several trust issues will be important:¥whether the receiver trusts the mobile code and allows it to run inany fashion,¥what local resources code can access if it is allowed to run, and¥what rights the local client might want to delegate to the code if itmoves on or needs to make calls to other members in the network.although some ideas have been developed about notions of trust inprincipals, it is not clear that mobile code is a principal, or if such codeworks on behalf of a principal. indeed, there are cases in which it makessense to distinguish between different levels of trustñhow much the codeis trusted to be accurate and nonharmful (which can be thought of as trustin the producer of the code) and what the code is trusted to access (whichcan be thought of as trust in whoever or whatever the code is running onbehalf of). it may well be that all of the problems in the trust model ofcode can be accounted for with current trust models and an appropriatemapping of the new entities involved in such systems and the entitiesalready dealt with in the trust models. but currently there is no suchembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.100embedded, everywheremapping, nor is there any reason to believe that new problems will notarise.security in distributed systems has been investigated for some time.most security mechanisms, however, rely on the ability to trace an actionback to a principal, generally a human being, on whose behalf an operation is performed. in an emnet, however, most of the requests or resources will be made on behalf of a program, which may not have the fullidentity of a principal. even if each program or embedded processorcould be treated as a principal, it is not clear how that program or processor should go about authenticating itself.beyond these fairly standard sorts of security issues, emnets canpose security concerns that go beyond those generally thought of in distributed security. for systems in which code is moved from one processor to another, it is not enough to mutually authenticate the interactingentities; the code that is moved from one entity to the other needs to betrusted to some degree and must be given (or denied) access to the resources on the system in which it runs. how this is best done, or even ifit can be done, is an unanswered question at this time. some progress hasbeen made in performing code verification prior to the loading of thecode through the use of virtual machines, but the principles behind thecode verification mechanism are not well understood. further, theamount of space taken up by the verifier is large, and it may exceed thebenefits offered by code verification on small devices. there have beensome investigations into the possibility of performing verification beforethe code is moved and then signing that code to ensure that it is safe (gunsirer et al., 1998), but further research in this area is necessary.the design of operating systems that can support this type of resource accountability and allocation is also an open research area. accountability is necessary for resources such as power and bandwidth aswell as for the more traditional processor cycles and memory. allocationmay be based on any or all of these considerations, and the code run bythe operating system must be guaranteed not to be able to obtain moreresources than it originally negotiated.failure models and monitoringadditional research needed in the area ofdiscovery has to do with the failure models for automatically configurednetworks. once a device has joined such a network, how is it discoveredthat the device has failed? if the automatically configured network hassome conceptually central place where members of the network are found,what happens when that place fails? the jini system has a reasonablywellspecified failure model, covering both the failure of components thatare registered with a lookup service and the failure of the lookup serviceitself. this model is implemented using the concept of leases. leases areembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination101granted for a specified period of time. if the device does not return torenew the lease, then it is assumed that the device has failed or left thenetwork and is no longer available. leases can be used in this manner inboth directions, helping a client keep track of a server andñas is morecommonñhelping a server keep track of a client. however, this does notsolve all the problems, because the lease server itself may fail and a newnode may need to take on this responsibility. the approach taken in thejini system is not the only possibility; others should be investigated.an issue related to failure is system health. in many emnet applications it will be necessary for an administrator or user to know what issuesthe system is dealing with. for example, a lack of elements in one area(owing to malfunction or outside attacks) could create a lowbandwidthbottleneck or a surplus in another area (owing to malfunction or intentional interference) could cause communications interference. this is important because emnets are unlikely to be deployed for applications thatcan tolerate total system failure and be fixed by simply rebooting. a keydesign goal is thus to have them degrade gracefully (for example, havingnodes or elements take over for other nodes and elements when they fail.)the internet provides a reasonable example of how this might be accomplished, although it is not, of course, subject to the additional constraintsthat emnets are operating under.additional research is needed in how to characterize systems andtheir components based on this concept. there may be much to borrowhere from the ideas of dual control. in dual control, the behavior ofsystem elements is characterized in situ by stressing them purposefully.what is learned from the interaction can then be used to recognize aproblem when it is seen in regular operation. in addition, it will beimportant to record system behavior so that unintended behavior thatemerges when a particular combination of elements or emnets interactscan be studied and remedied. in fact, doing this automatically mightcreate a sort of immune system that monitors operation and takes corrective actions. of course, such an immune system as this would itself haveto be monitored. this opens up an entirely new area of research thatfocuses on techniques for restricting the behavior of emnets within aparameter space that is comprehensible to both humans and machines.research issues for adaptive coordinationseveral factors make it unlikely that adaptive coordination in emnetswill be mediated or even aided by human operators. one factor is size:emnets will often be very large, and adaptive coordination will need totake place over a scale (in terms of both numbers of networked elementsand size of the covered physical space) that will preclude human involveembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.102embedded, everywherement. a second factor is the time scale. the time scale over which theadaptive coordination may need to take place is too short to be open tohuman intervention; by the time a human operator decides what to do,the environmental factors will have changed in such a way as to require acompletely different adaptation. a third factor is that the operators, users, and individuals interacting with emnets may be untrained in thespecifics of the system and should not be expected to understand thetechnology to the depth that would be required to address adaptive coordination. (see chapter 4 for a discussion of human factors and the usability of emnets.) the rest of this discussion focuses on the technical considerations mentioned above.the large number of elements in such systems suggests a brute forcemethod of achieving adaptive coordination: adding more elements to theemnet to allow high levels of redundancy without modifying the designed behavior of the nodes. however, this method would require communication bandwidths that would drain the available energy of batterypowered elements. simple replication is predicated on the idea thatbandwidth (and the power needed to use the bandwidth) is an abundantresource, which is not the case in many of the emnets of interest. inaddition, issues of stability might arise with increasing numbers of nodesin the networkñadditional work in control for emnets is required tocharacterize and manage stability.monitoring system health is a critical issue for two reasons. first,many envisioned applications of emnets have reliability and safety concerns that are more severe than those for traditional desktop distributedsystems (see chapter 4), so it is critical that system degradation and signsof imminent failure be detected. more germane to the discussion in thischapter is the need for resourcepoor components to adapt to variations inavailable resources in other components so as to achieve overall systemefficiency. however, these same resource constraints make extractinginformation on dynamic system state expensive. variations in availableresources could arise in the context of normal operation or be due tointruders or malicious attacks. system health monitoring will thus needto incorporate intrusion detection and antijamming facilities.there are some promising avenues for obtaining the adaptabilityneeded. the low cost of the elements in many applications will enable theuse of large numbers of elements in ways that supply redundancy whenneeded, while lowering or at least limiting the amount of communicationrequired over the system itself. however, this approach will work only ifnodes are designed to be adaptive to their environment and to the behavior of other elements in the system. for example, a node might set thefrequency of periodic sample communication or its transmit power basedon the density of nodes observed within its proximity.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination103these large numbers of system elements might also allow the systemto monitor itself much more carefully so that adaptive coordination canbe predicted or expected in new and interesting ways. for example,traffic generated by a node could be monitored by the nearest neighbor,which could quickly determine when that pattern changed or endedabruptly, indicating failure or loss of power. such continuous monitoringwould permit nodes to react quickly to losses in the network.exploiting redundancyone general area for research is how to exploit the redundancy thatmay exist in many emnets. especially in sensor networks and othersystems based on large numbers of inexpensive nodes, some degree ofredundancy can be expected. in sensor networks, for example, multiplenodes may provide coverage of overlapping geographic areas. in a smartspace, multiple printers, displays, or databases might exist. not only canthis redundancy improve reliability, but it might also ease the process ofselfconfiguration. for example, when nodes need to be upgraded, only asmall percentage of the nodes might be upgraded manually, and the others could be instructed to check the new nodes for updates. with inexpensive components, the possibility exists of deploying multiple solutions rather than focusing on finding a single optimal one. in this section,the discussion is primarily about systems in which components are relatively inexpensive, allowing large numbers of them to be deployed.in some cases, the cost of deployment is fixed within a certain rangeand grows only slowly as the number of deployed nodes increases. inthese contexts, redundancy can be exploited to help achieve long systemlifetimes (offering both robustness in the face of environmental dynamicsand energy efficiency) if algorithms can be identified for nodes to use inselfconfiguring. for example, nodes can identify when they need to beoperational and when they can sleep, thereby conserving energy to beused when other nodes go to sleep or use up their energy reserves. suchmethods of exploiting redundancy require new computational modelsand abstractions so that elements have the information needed to determine the steps they should take to maintain system performance in thenear term while preserving longterm capabilities.over the years, a number of approaches have been developed to helpinformation technology systems make more efficient use of available resources. indeed, some key issues in system scalability can be thought ofas a set of methods for determining how nodes should take turns, sharesystem resources, or coordinate actions to boost their efficiency and effectiveness. clustering is an approach in which a single node collects information from other nodes and takes on the task of communicating thatembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.104embedded, everywhereinformation to other clusters on behalf of individual nodes. time divisionmultiple access (tdma) is an example of nodes taking turns using communication slots. ethernet is an example of the use of carrier sensing andcollision detection to coordinate use of the shared channel. it uses randomization to help coordinate system operations. tcp/ip congestioncontrol scales in the sense that the users of a shared, congested resourceuse signals (dropped packets) to coordinate their respective use of thechannel, thereby taking turns sending packets through the bottleneck.multicast transport protocols such as rtp/rtcp10 and srm11 expandedthe use of ethernet randomized and localized techniques for scalablysharing a resource (see box 3.1).the systems in which these techniques will be most useful have alarge potential solution space. in other words, if there is just one or a verysmall number of acceptable solutions (for example, if just a few particularnodes out of hundreds or thousands need to take an action), then completely distributed, localized techniques alone are unlikely to provide agood solution. however, if there are many satisfying solutions, then onecan envision energyefficient techniques based on localized algorithmsthat find satisfying solutions in unpredictable contexts.the generalizations of the rtcp and srm techniques, referred to asadaptive fidelity, have potential for uses beyond simply achieving robustness. for example, in a smart space application, wall panels might bemanufactured with very large numbers of sensors and actuators embedded. adaptive fidelity schemes could be used to arrange for smallernumbers of these elements to be active during times of relative inactivity,conducting relatively longdutycycle scanning and offering relativelyslow response. triggered by detection of greater activity, additional nodeswould move into the lowduty cycle mode and focus on a smaller area ofinterest; in this way, the collection of nodes would achieve higher fidelitybehavior when there was more action to be observed or managed.another technique for exploiting redundancy might be to program ordesign emnets to take advantage of opportunistic behaviors. for ex10rtp (realtime transport protocol) (internet rfc 1889) is the internetstandard protocolfor the transport of realtime data. the data part of rtp is a thin protocol providing supportfor applications with realtime properties such as continuous media (e.g., audio and video),including timing reconstruction, loss detection, security, and content identification. rtcp(realtime transport control protocol) provides support for realtime conferencing of groupsof any size within an intranet. it offers qualityofservice feedback from receivers to themulticast group as well as support for the synchronization of different media streams.11srm is scalable reliable multicast, one of many proposed transport protocols proposedfor multicast (floyd et al., 1997).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination105 box 3.1exploiting redundancy/longlived systemsrtp/rtcp is a pair of protocols used to facilitate networked multimediaapplications (floyd et al., 1997). rtp provides timing information in applicationlevel data to allow smooth and possibly synchronized playback of data types thatmust be played back to the user in a smooth manner. rtcp is the control channelfor rtp. rtp/rtcp was designed to support potentially very large groups wherea small number would be transmitting simultaneously but a large number could besimultaneously listening. one of the scaling issues that arose was how to keep thecontrol traffic (the periodic session messages sent by each receiver) from consuming too many resources. the designers developed a technique later referred to asscalable session messages in which each receiver monitors the number of othersession participants currently sending session messages and adjusts the period ofsession message transmission so as to maintain the combined average sessionmessage transmission below a defined small percentage of overall data trafficbeing sent/received in the session. this technique was applied again in the reliable multicast transport protocols, srm. the potentially very large set of datarecipients must send session messages to communicate successful/unsuccessfulreceipt of packets. the same local algorithm for determining the frequency ofsession message reporting is used. srm went on to use localized randomizedalgorithms more extensively as a means of achieving scalability. in particular,srm uses localized algorithms for determining who should send requests for retransmissions and who should send repairs for retransmissions. this is an example of exploiting redundancy in that all members of a session that have lost apacket are potentially redundant in their role of requesting a retransmission. similarly, all members who correctly received the lost packet are potentially redundantsenders of the message repair. srm elaborated on ethernet distributed, randomized, resource usage techniques to identify local algorithms for each node to runthat would result in efficient sending of requests and replies. note that srm doesnot result in perfect efficiency. a centralized scheme with global knowledge willalways do better in any particular case. but srm, by defining localized algorithmsfor each node to run, allows the collection of members to selfconfigure to anefficient state. it is more scalable than centralized approaches when the locationof packet loss is unpredictable and nonstationary.ample, they could delay some basic reporting functions (for example,transmitting, reorganizing, calibrating, and reporting system health) untilgreater bandwidth, energy, or processing capabilities become available.some nodes could enter a sleep mode when redundancy is detected,thereby saving power and contributing to longer system lifetimes. selfconfiguration itself could take competing paths in which mobile codemay be distributed at times when, or to locations where, the combinationembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.106embedded, everywhereof circumstances (bandwidth, operational realtime constraints, etc.) enables a selfconfiguration operation. distribution of selfconfigurationcommands, code, and verification acknowledgements may all adapt accordingly. this type of capability will require nodes to contain algorithms that provide flexibility in operating conditions.an important part of adaptive coordination is the capability of individual nodes to monitor their own status and that of their operating environment. nodes will need to gather information about changes in thestatus of other nodes (for example, that a nearby node has failed or entered a different operating state), changes in the availability of resources(for example, limited power or loss of a communications link), andchanges in the environment that are being sensed and responded to. thenodes will need to rely on a variety of sensing modalities. for example,they may need optical sensors to indicate whether they have lost line ofsight to another node with which they communicate frequently. theywill need checks on their power levels. one of the most critical areas ofresearch, as yet unexplored, will be the characterization of largescaledistributed systems composed of physically coupled, autonomous and/or adapting elements and operating under unpredictable, highly resourceconstrained environmental conditions.centralized versus decentralized controlan issue that needs to be addressed with regard to both selfconfiguration and adaptive coordination is control of the system configuration. ifindividual elements of an emnet can change their technical characteristics, capabilities, and operating modesñeither through upgraded hardware or software or through adaptive coordinationñhow can the systemguarantee its overall performance and stability or be sure that individualelements have access to the bandwidth, quality of service, or other properties they need in the system? conversely, if a system contains largenumbers of nodes, how can a central node control the overall configuration of the network in a timely fashion?issues of adaptive coordination, configuration, and, more generally,control can be addressed through any of several schemes. at one end ofthe spectrum are centralized schemes in which individual componentsare not selfconfiguring but the overall system is. at the other end of thespectrum are decentralized schemes in which individual components arethemselves selfconfiguring. all cases require that some policy be expressed at the time the system is deployed (and probably afterward) thatguides and focuses the selfconfiguration, with respect to not only thehumans involved and the selfconfiguring system but also the centralizedembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination107controller and the distributed elements. (see box 3.2 for a discussion ofcooperative behavior and control.)the viability of a centralized versus a decentralized scheme dependson several factors, including the scale of the system and the rate of anticipated change. central control across a large network may be impossibleto implement in a timebounded fashion. (for a brief discussion of traditional control and systems theory as it relates to emnets, see box 3.3.)local functions need to be optimized and reconfigured as the environment changes. if environmental conditions are not predictable and changefaster than information can be extracted and analyzed, then a decentralized scheme is needed. but decentralization introduces issues of adaptivecoordination and overall system performance. how can overall systemperformance be optimized if decisions are made locally? how can requirements for overall system performance be specified from a singlepoint?to provide for a degree of centralized control in a large emnet withnumerous elements, some sort of hierarchical, tiered structure will beneeded. many emnets will be composed of heterogeneous collections ofelements, each with different sets of capabilities and constraints. someelements may be far less restricted than others in terms of, for example,the amount of power available to them; the system ought to be able toadapt by making such elements bear the brunt of powerintensive tasks.other elements may be less restricted in terms of available memory orbandwidth, or they may have persistent storage easily available. adaptive mechanisms can exploit system heterogeneity by using extra powerwhere it exists in the overall system to offload work from elements withlower energy capacity.even when all nodes start out with equivalent capabilities, it may beefficient from a systemlifetime perspective to have the system select asmall number of nodes to execute higherpower operations using higherpower resources (for example, longrange radio). robustness can still beachieved by arranging for the òhierarchyó to selfconfigure using automated mechanisms for selecting which nodes will run the higherenergyresources. automated hierarchy formation and clustering imply a needfor automated reelection and selection in the face of failures. the adaptive coordination can take place efficiently and rapidly as the variouselements adapt based on local measurements of environmental conditions and available resources.as such systems adapt by reconfiguring the tasks that each elementperforms based on its capabilities, the distinction between configurationand adaptive coordination may begin to blur. how those capabilities arecommunicated and allocated is an open area of research, as are questionsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.108embedded, everywherebox 3.2cooperative behavior and controla possible approach to distributed control is directed diffusion. directeddiffusion amounts to controlling a system by means of activation and inhibitionmessages, the sum of which can either reinforce or discourage a course of action.1as an example, consider a sensor network in which multiple nodes have access tothe outside world through a specialized node with longrange communicationscapabilities and that communicates to the rest of the nodes by passing messagesfrom one node to another (that is, via multihop connections). if several nodesobserve an event, then directed diffusion can help determine which nodes shouldbe involved in deciding whether to report the event, which one should do the processing, and what information should flow to the longrange link given a desire tominimize energy expenditures. if latency (delay) in making a decision is not an issue and the probability of anode accurately detecting an event is related to the strength of the signal it receivesrelative to background noise (the signal to noise ratio, or snr), then the nodes canwait a period of time based on the snr before alerting or inhibiting neighbors. thenode that receives the signal with the highest snr will send its alert first, communicating a message to the longrange link and sending short inhibition signals to itsneighbors. the other nodes then avoid transmitting their decisions or activatingone another to engage in cooperative detection. if the signal at the node with thehighest snr is still below the threshold for reporting the event, the node couldinstead activate its neighbors, asking for their decisions and the relative certaintyof those decisions. these activation messages will propagate outward withreduced intensity (that is, they will require progressively higher certainties torespond), and nodes with higher snrs will reply sooner. when enough replieshave been combined to allow the original node to make a decision with the desiredof how groups of machines with different capabilities could be organizedto perform a set of activities that are presented to the rest of the system asa single unit. similar hierarchical organizations have been used in moretraditional systems, but they are not based on the capabilities of the individual components in the manner described above. how to adapt theoverall system configuration (or subsystem configuration) to maximizethe information obtained while minimizing the use of scarce resources isa promising area for future research.some systems may benefit from decentralized control schemes, whichalso require further research and analysis. the minimum number of bitsthat must be communicated to make a reliable decision is unknown for allbut the simplest of problems involving more than one sensor node. giventhe high power cost of communications, it would be useful to know whatthe threshold is and thus to learn whether particular algorithms are anyembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination109where near optimal. (for a discussion of local computation vs. communication as related to emnets, see box 3.4.) if the processing problem is castas a ratedistortion problem, in which (weighted) false alarm and misseddetection probabilities constitute the distortion and the communicationsenergy takes the role of rate, then additional questions can be explored.for instance, what is the effect of array density on the ratedistortionregion for a given communications and signal propagation law and set ofsource statistics? this is a deep and difficult problem (for example, underwhat conditions is there a convex ratedistortion region?), but its solutioncould have a large payoff. preliminary progress has been achieved withsimple versions of this problem, but a huge problem space remains to beexplored.the interaction between a system element and its neighboring elements is not typically considered in control theory but is essential tolevel of certainty, that node can issue inhibition signals to its neighbors whilepropagating its decision to the longrange link.this procedure progresses through several distinct phases of operation:detection of a stimulus, formation of subnetworks of communicating nodes, gathering and processing of information, destruction of subnetworks, and longrangecommunication of results. to minimize energy expenditures, it avoids using complicated setup signals to establish subnetworks, instead employing the naturaldecay of communications signals with distance to establish a perimeter. althoughperhaps failing to pick the optimal fusion center or routing of information, thisapproach can dramatically reduce the overall amount of sensor information transmitted within the system and help conserve energy. varied behavior can beobtained with a few control signals (with feedback), with no need to designate acentral controller before the procedure starts. of course, the longrange link couldalso serve as a master node, commanding different thresholds to become active orinhibiting their behavior. in this way, behaviors can be adapted over time to meetchanging global objectives. human operators could perform this adaptive coordination, but as understanding of the system grows, networks could be designedwith increased autonomy.note: some work in this area has been done by the chair of this study committee(intanagonwiwat et al., 2000). 1this approach is similar to that used by ants for a variety of highly complicated functions,such as establishing trails to food and removing them when the food supply dwindles. successive use of a trail reinforces it, but small random deviations that provide a more direct route toa food can alter (e.g., straighten) the trail and lead to increased energy efficiency. othersignals can terminate an activity and focus attention on other tasks.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.110embedded, everywherebox 3.3control theoryemnets bring together two established research communitiesñdistributedsystems and control. control is a rich research area that studies how to use feedback to optimize the behavior of electromechanical systems. control has its rootsin simple servo control systems but is now used in the design and operation of awide class of electronic and electromechanical systems. often these systemshave hundreds of processors and components from multiple vendors. some ofthese systems run chemical plants, manufacturing plants, and even buildings. bybringing together these two areas, emnets create a number of new research areas.control theory is used to solve a number of difficult problems. for example inflight control systems, the dynamics of the plane are carefully studied, creating anoptimal controller for this system. often this controller is combined with a numberof estimators that produce an estimate of what the measured parameters shouldbe. the estimator can be used to provide input from sensors that might not beread each cycle (for example, the computation might require 25 data points whileonly 10 are being collected at any given time) or check that the current model ofthe system represents the actual system. in some highly critical situations, banksof estimators can be used to model how the system would behave under variousfault conditions. during normal operation, these estimators will poorly match thesystem, but under a fault condition one of these estimators might become a bettermatch than the original system. thus, when a fault does occur (such as the loss ofan engine in an aircraft), that faultõs estimator has current information and can beused to update the control equations for the plan, to allow it to continue to functionat some reduced performance until the error is repaired.rather than using a fixed system model, model predictive control adapts thesystem model and the control formulation. it solves an optimal control problem ateach step, using current sensor data and measured system performance. thistype of control was initially used in largescale refineries, where cycle times arevery long (tens of minutes), providing sufficient control for the required computation.modeling emnets. the interaction between a node and its immediateneighbors is critical, because physical stimuli are often correlated to physical space and because the communications costs and latencies to nearneighbors are likely to be less than average. centralized control rules canbe devised for such a group, but the complexity of the decisionmakingprocess, even for a relatively small collection of nodes, will demand somedecentralization and probably hierarchy as well. layered control hierarchies are notoriously difficult to optimize, but perhaps by scaling to largenumbers designers can reduce the demand for efficient use of the individual components. in any scheme, the fundamental issue of stabilityarises. once the design moves away from centralized control, the theoryembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination111for characterizing the system and guaranteeing stability is not well developed. note that actuation, signal processing, and communications (ormore likely, a combination of these) all raise fundamental questions ofresource allocation in response to a physical stimulus. accordingly, asolution in any one of these domains may well have applications to all therest. the problem of cooperation thus appears to offer an excellent opportunity for multidisciplinary research; there are probably lessons to belearned from diverse disciplines, with a potentially high payoff. (anexample of an area in which multidisciplinary approaches are used isdistributed robotics, described in box 3.5.)both types of system rely on getting sensor measurements at fixed time increments. while networks are often used in control systems, their properties arenot considered in the problem formulation. for highperformance control loops,sensors are given logically separate networks (or even physically separate wire) tocollect the data, making variable packet delay and possible data loss nonissues.in addition, in almost all cases the control algorithm is centralized and not run in adistributed fashion. the long cycle time of many process control systems makesthe issue of networks in these systems uninteresting, and in any case existingtechnology meets the requirements of these systems. while robust operation iscritically important, with commands being issued to individual pumps, valves,heaters, and the like (in a factory setting), the long cycles provide time to considerand reject outlying data and every actuator is likely to have a secondary sensor forredundancy and prediction checking.while the notion of fixed time samples is fundamental to most control theory,there are some methods that might migrate to networkbased systems more easily.one possibility is to use lyapunov methods, where the idea is for each unit togreedily minimize a value function that serves as a coordinator. this transposes toasynchronous systems very nicely. in general, the actions of each unit would haveto be coordinated carefully (simple examples show that activating two feedbacksystems simultaneously can lead to disastrous loss of performance or instability),but if there is a value function that each is separately minimizing, the actions areautomatically coordinated.to the standard control issues emnets add the issues of resource constraints, distributed systems, and networks. in control environments, networks areassumed to be stable, not to lose information, and not to have delays. all of theseare likely to be violated at some point for emnets posing new research challenges.note: the committee thanks stephen boyd of stanford university for his guidance indeveloping this description.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.112embedded, everywherebox 3.4local computation versus communicationone of the design choices that must be made in emnets is the balancebetween local computation and the communication of data back to a more centralized processing node. in other words, to what extent should an individual nodeprocess the data it has collected or been sent when it also has the option of communicating raw, unprocessed data to another node for processing? this issue isparticularly important in emnets that operate with limited stores of energy andmust therefore minimize energy consumption. it is extremely important in systemsthat rely on wireless communications to transport data because of the energyrequirements of wireless systems. many sensor networks will be in this category,as will mobile elements of other emnets, such as smart spaces.the high energy consumption of wireless communications systems leads tounique conclusions about the distribution of tasks in the distributed embeddedsystem network. for example, in a typical wireless sensor network, the networkõstask is to identify events that occur in the network environment and communicatethese occurrences to a remote user. conventionally, this would be done by transmitting received sensor information to a remote asset for processing. emnetscomposed of many distributed devices become collectively more capable if significant computation is performed locally, with the goal of recognizing local eventsand communicating only event identification codes, as opposed to complete datasets.as an example of the tradeoff between computation and communication inan emnet, consider a wireless sensor system that is distributed over a large surface. communication between devices occurs between nodes in a multihop architecture in which information is passed from the source node to the destinationnode by traveling through a number of intermediate, proximate nodes. underthese conditions, the power transmitted from any one node declines rapidly as thedistance from the transmitting node increases.1,2the severe decay of wireless communications has a profound influence onthe balance between communication and computation resources. system designersmust decide between communicating data directly for remote processing or performing local processing and communicating a shorter message or perhaps noneat all to a remote node. the energy required to transmit even short messagescould power significant amounts of computational processing locally. the largecomputation budget is available for potentially quite powerful information processing that could reduce the amount of information that needs to be communicated.hence, considerable design and development effort will need to be directed to thedeployment of emnets that leverage powerful local computation and cooperativeprocessing to identify local events and even command local action. lowpowerwireless embedded systems will therefore create demands for a rich set of novelnetwork and distributed computing solutions that have not been previously neededin conventional wireline systems.1see, for example, parsons (1992) as a starting point into the total body of literature dealingwith propagation in personal/mobile environments.2see also sohrabi et al. (1998).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination113collaborative processinga sensor network is an example of an emnet that illustrates the benefits of using system architectures and adaptive coordination to improveoverall system performance in the face of stringent resource constraints.sensor networks generally require constant vigilance by at least a subsetof the sensors so that desired events can be reliably detected. at the sametime, the system must avoid generating false alarms when a particularevent has not occurred. sensor networks can employ a powerconservinghierarchical detection scheme to meet these objectives. for example, individual sensors may use energyefficient procedures for detecting acoustic, magnetic, infrared, or other forms of energy and then attempt to makea detection decision independently. if the sensor cannot reliably make adecision, it could employ some processing and sensing to seek information from nearby sensors. these processes involve larger expenditures ofenergy, especially if the sensor and its neighbors must communicate.additional processing, using a large neural network or some other sophisticated procedure, could be used to provide greater assurance if necessary. in the worst case, raw data might be transmitted back to a remotesite where human operators analyze the data and determine whether anevent has been detected. this step consumes large amounts of energyand must be avoided, except when absolutely necessary.as this example illustrates, there are tradeoffs to be made with regard to the extent of processing to be conducted by individual sensorsand the amount of information communicated among them. in manyapplications, there will be no events to report much of the time and noneed to apply the most expensive algorithm, which is transmitting data tohuman operators for analysis. but, there may be too many circumstancesin which the least expensive detection algorithm will fail. a processinghierarchy can lead to huge reductions in energy consumption while assuring the required level of reliability. processing hierarchies are intertwined with networking and data storage issues. how long and wheredata are stored (or queued) will differ at different levels in the hierarchy;the decision on whether to communicate with neighboring nodesñandwhich onesñwill depend on the signalprocessing task. the amount ofenergy consumed by communications and the degree to which energy isscarce will affect the processing strategy (that is, the willingness to communicate and whether processing is centralized or distributed). all ofthis, in turn, depends on the physical constraints that the system faces,allowing the physical layer to intrude.given the amount of energy needed to communicate a short message,it often pays to process the data locally to reduce the volume of traffic andmake use of multihop routing and advanced communications techniques,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.114embedded, everywherebox 3.5distributed roboticsdistributed robotics is the study of algorithms for the control and coordinationof groups or teams of robots. a multirobot group is a superb example of a networked embedded system that embodies challenges in control, communication,and coordination as it faces uncertainty in sensing and action, unexpected failures,and a dynamic environment. the notion of a single, centralized controller coordinating a distributed robot group is considered untenable, as it is neither scalablenor robust. thus, control must be distributed to the individual robots, which mustcommunicate and adapt as necessary to produce globally efficient behavior of thesystem as a whole.several key methodologies are relevant to multirobot control, as they are toindividual robot control. reactive control involves the lookup and execution ofprecompiled, stateless collections of rules, with no looking into the past or planningfor the future. deliberative control uses centralized world models and planning butscales poorly with the complexity of the control problem and the group size. hybridcontrol attempts a compromise between reactive and deliberative approaches byemploying both and compromising between them as necessary; this is a dominantparadigm in robotics. the other dominant paradigm is behaviorbased control,which is of particular relevance in distributed robotics.behaviorbased controllers consist of collections of behaviors, timeextendedprocesses or control laws that achieve and maintain goals. for example, òavoidobstaclesó maintains the goal of preventing collisions, and ògo homeó achieves thegoal of reaching some destination. behaviors can be implemented in software orhardware and as processing elements or as procedures. each behavior can takeinputs from the robotõs sensors (for example, camera, ultrasound, infrared, tactile)such as coding, to reduce energy consumption. collaborative processingcan extend the effective range of sensors and enable new functions. forexample, consider the problem of target location. with a dense array ofnetworked sensors, one means for tracking the position of an object (forexample, a target or a detected event) is for all nodes that detect a disturbance to make a report. the centroid of the reporting nodes is one possible estimate of the position of the target. this approach requires theexchange of very few bits of information per node.much more precise position estimates can be achieved with a technique called beam forming, in which individual sensors exchange information about detected events and the time they were detected. althoughthis approach consumes more energy, it offers several benefits: higherquality data for subsequent classification decisions, longrange positionlocation, and even some selflocation and calibration possibilities for theembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination115nodes.12 in some applications, sparse clusters of nodes that use beamforming techniques might be preferable to dense deployment of lessintelligent nodes, or it might be better to enable both sets of functions. forexample, a dense network of lessintelligent sensors deployed in conjunction with a lessdense array of intelligent nodes could capture information on demand for beam forming. such collaborative processing can beregarded as a further extension of the signal processing hierarchy to multiple nodes, with the collaboration being extremely expensive in terms ofenergy use but performed only rarely, such that its marginal energy costmay be acceptable.key to any network collaboration is the idea of synchronization amongand/or from other behaviors in the system and send outputs to the robotõs effectors(for example, wheels, grippers, arm, speech) and/or to other behaviors. thus, abehaviorbased controller is a structured network of interacting behaviors. behaviors themselves embed state and can form arbitrary representations when networked together. thus, behaviorbased systems are not limited in their expressiveand learning capabilities, and they are well known for their realtime response andscalability. the metaphor of a robot being controlled by a collection of behaviorsscales well to systems of robots being themselves behavior collections. currently,behaviorbased control appears to be the de facto standard for distributed multirobot control, owing to its robust and scalable properties.as emnets evolve to include actuation and mobility, lessons can be learnedfrom the area of distributed robotics. the significant open problems in distributedrobot control include the synthesis and analysis of adaptive group behavior, groupcoordination, and communication strategies that facilitate dynamic, runtime, efficient resource allocation within a distributed system. distributed robots need to beselfconfiguring and will usually be unattended. latency is also an important concern for both types of systems. both are likely to interact with humans at somepoints or on some level, and it may be the case that usability and interaction issueswill overlap. however, the constraints on emnets differ in some ways. manyemnets will have severe power limitations, whereas many distributed robots maybe large enough to incorporate more than adequate battery power. in addition,emnets will probably consist of many more components and nodes than distributed robots would need to incorporate.note: the committee thanks maja mataric and gaurav sukhatme of the university ofsouthern california for their guidance in developing this description.12see, for example, parsons (1992) as a starting point into the total body of literaturedealing with propagation in personal/mobile environments.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.116embedded, everywhereelements of the network. synchronization depends on both the accuracyof the local clocks and the ability of the network to coordinate local clockaccuracy. both long and shortterm clock drift are important for providing various levels of functionality. for spreadspectrum communication,highaccuracy clock synchronization with the received signal is necessaryto decode the information sent. however, only relative synchronizationis needed for nodetonode communication, because the propagation delay is not quantified at each node. in addition to enabling communication, coordinated synchronization is important as a means to enhancepower savings, enable collaborative sensing, and allow multisensor selflocation.local power requirements on a remote emnet must be reduced to thebare minimum needed to supply continuous sensing and a minimumlevel of event detection, while incorporating functionality to expendpower as needed for communications or more intensive processing. thisis appropriate for situations in which the frequency of events is expectedto be high enough that every emnet in a network needs to be ever vigilant. for longerlifetime sensors in environments with a lower eventprobability, support communication and processing may be set up tooperate intermittently. if the network is operating in a form of tdmacommunication, then for low latency event reporting, each sensor muststay synchronized. in addition, to coordinate sensing times and enablecoherent collaborative processing, each emnet needs to be synchronizedto a global time scale. thus, clock drift on each sensor limits the length ofnoncommunication between sensors or the power savings achievable bypowering down the radio. additionally, if a sensor field is put in a somnolent state in which only selected sensors are powered down, total network power savings will be greater if the multiple sensors coordinatetheir sleep time (requiring synchronization) as opposed to randomly powering down to provide a reduced alert state overall.collaborative sensing (by, for example, using beamforming algorithms) benefits from synchronizing all the sensing inputs. the combining of results from multiple sensors at different locations to counter jamming, enhance resolution, or enable distributed sensing requires relativetiming information. on the coarsest scale, timing is required to coordinate which event occurs where. finer resolution of timing allows recognizing coordinated events by coherently combining results from multiplesensors, thereby fully realizing the utility of a distributed sensor system.in fact, the effective resolution of coherent combinations of inputs frommultiple sensors is limited by the time synchronization of the sensors.programming emnets to achieve significant collaborative processingraises some of the same challenges as are faced in parallel computing anddistributed databases. neither model adequately addresses the combinedembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.selfconfiguration and adaptive coordination117constraints of emnets, however. for example, in contrast to parallelcomputing environments, the data in an emnet will be inherently distributed. and in contrast to distributed databases, emnets are much moreresource constrained. an assumption in distributed databases is thatmoving the data from place to place is relatively inexpensive. in emnets,the emphasis will be on performing the processing where the data arelocated. some techniques from each of these models may prove useful,however, and their applications to emnets merit further investigation.finally, the cooperative and collaborative nature of emnets mightfrequently create requirements for configuration actions that are implemented across all or nearly all the nodes in a network. if a system is selfconfiguring, at times there may be a need to clearly identify the subsets ofthe system that have changed or been upgraded. this is referred to as aneed for òatomicity,ó in which the system as a whole is considered asingle, atomic (indivisible) entity. specifically, the configuration of network protocols or security functions may be an action that must be applied with complete assurance across all nodes in a network. errors inconfiguration for one node in a vast area may have unbounded impact.atomicity of some kind may be needed when a change must be collectiveor coordinated, but it might not be achievable using standard techniquesbecause there is no enumeration or unique identification of individualcomponents. moreover, there is a possibility that not all elements need tobe upgraded; some components may be disconnected or obstructed forsignificant periods of time. if a piece of the system is changed, there mustbe a way for the system to detect whether the resulting final state isworkable. how does one determine that enough components have beenupgraded to take on the new behavior? how do old components detectthat they should change their behavior when they encounter new ones?summaryselfconfiguration involves the addition, removal, or modification ofelements in an emnet and the subsequent process of establishinginteroperability. in contrast, adaptive coordination addresses changes inthe behavior of a system as it responds to changes in the environment orsystem resources (such as remaining energy). together, these processesare critical for creating robust and scalable unattended emnets. the stateof the art in selfconfiguration is fairly well developed, with wellunderstood approaches to address assignment, service discovery, and mobilecode. however, significant research progress is needed to achieve automatic selfconfiguration among large numbers of distributed nodes, whilestill conforming to welldefined trust and failure models, which are critical to embedded systems applications. adaptive coordination is a wellembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.118embedded, everywheredeveloped discipline for centralized systems, and distributed coordination is widely applied outside of embedded applications (for instance, ininternet applications and protocols), but there is much work to be done inthe area of distributed adaptive coordination to support embedded applications. promising directions include techniques for exploiting systemredundancies and localized processing and collaborative signalprocessing techniques. such techniques are particularly critical for unattended,resourceconstrained systems.referencesabelson, harold, don allen, daniel coore, chris hanson, george homsy, thomas f.knight, jr., radhika nagpal, erik rauch, gerald jay sussman, and ron weiss. 2000.òamorphous computing.ó communications of the acm 43(5). also as mit artificialintelligence memo 1665, august 1999.arnold, ken, and jim waldo, eds. 2000. the jini specifications, 2nd ed. cambridge, mass.:addisonwesley.corson, m. scott, and joe macker. 1997. presentation of draft entitled òmobile ad hocnetworks: routing protocol performance issues and evaluation considerations,ó ietf.rfc 2501.fall, k., and s. floyd. 1996. òsimulationbased comparisons of tahoe, reno, and sacktcp.ó computer communication review 26(3):521.floyd, s., v. jacobson, c. liu, s. mccanne, and l.a. zhang. 1997. òreliable multicastframework for lightweight sessions and application level framing.ó ieee/acm transactions on networking 5(6):784803. an earlier version of this paper appeared in acmsigcomm õ95, august 1995, pp. 342356.gun sirer, emin, robert grimm, brian bershad, arthur gregory, and sean mcdirmid. 1998.òdistributed virtual machines: a system architecture for network computing.ó eighthacm sigops european workshop.intanagonwiwat, chalermek, ramesh govindan, and deborah estrin. 2000. òdirected diffusion: scalable and robust communication paradigm for sensor networks.ó proceedings of the sixth annual international conference on mobile computing and networks(mobicom 2000), boston, mass. available online at <http://lecs.cs.ucla.edu/~estrin/papers/diffusion.ps>.jacobson, v. 1988. òcongestion avoidance and control.ó acm sigcomm ô88.karp, b., and h.t. kung. 2000. ògpsr: greedy perimeter stateless routing for wirelessnetworks.ó proceedings of the sixth annual international conference on mobile computingand networks (mobicom 2000).mcquillan, j., i. richier, and e. rosen. 1980. òthe new routing algorithm for the arpanet,óieee transactions on communications 28(5):711719.mullender, sape. 1992. òkernel support for distributed systems.ó distributed systems, 2nded. s. mullender, ed. cambridge, mass.: addisonwesley.parsons, david. 1992. the mobile radio propagation channel. new york: john wiley & sons.sohrabi, k., and g.j. pottie. 1999. òperformance of a novel selforganization protocol forwireless adhoc sensor networks,ó ieee vts 50th vehicular technology conference2:12221226.sohrabi, katayoun, gregory j. pottie, and bertha manriquez. 1998. ònearground widebandchannel measurement in 8001000 mhz.ó ieee 1998 vehicular technology conference.yu, h., d. estrin, and r. govindan. 1999. òa hierarchical proxy architecture for internet scale event services.ó proceedings of weticeõ99, june.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.1194building trustworthy networkedsystems of embedded computers1for an indepth treatment of trustworthy networked information systems that incorporates many of these aspects, see cstb (1999).users of networked systems of embedded computers (emnets)will demand certain characteristics, including reliability, safety,security, privacy, and ease of use (usability). these features can beencapsulated in the term òtrustworthiness.ó1 such features must be builtinto a system from the start; it is difficult, if not impossible, to add them inan adequate and costeffective manner later on. a large challenge toadding these sorts of features to emnets is the combination of an opensystem architecture with distributed control.the need for high reliability in almost all emnets is obvious, but howto ensure it is less obvious. todayõs techniques for designing reliablesystems require knowledge of all components of a systemñknowledgethat cannot be ensured in the rapidly changing environments in whichemnets will be used. testing mechanisms that apply to standard networks of computing devices may well fail to apply in the context ofemnets, where components may shut down to conserve power or may belimited in computing power or available bandwidth. these and otherreliability questions will need to be studied if emnets of the future are tobe trusted.some emnets may operate unattended and be used to control dangerous devices or systems that, through either normal or flawed operaembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.120embedded, everywheretion, could lead to significant human, economic, or mission losses. similarproblems were encountered early on in manufacturing automation; herethe systems are potentially larger, certainly more distributed, and operatein much less controlled environments. the constraints on emnetsñincluding long lifetimes, changes in constituent parts, and resource limitationsñstrain existing methods for evaluating and ensuring system safety.in addition, many emnets will be operatedñand perhaps even configuredñby end users with little technical training. new designs may beneeded that allow untrained users to operate these systems safely andeffectively. accidents related to software already are starting to increasein proportion to the growing use of software to control potentially dangerous systems (leveson, 1995). networking embedded systems together,as envisioned for many new applications, will only add to these problemsby enabling a larger number of potentially more complex interactionsamong componentsñinteractions that cannot be anticipated or properlyaddressed by system users. new system and software engineering frameworks are needed to deal with these problems and enhance the safety ofemnets. security and privacy will also be required in many systems. theamount of information that can be collected by emnets is staggering, thevariety is wide, and the potential for misuse is significant. capabilitiesare needed to verify that the information cannot be compromised or usedby those who have no right to it and/or to cope with the likelihood thatmisuse or other problems are going to occur. in addition, these systemswill need to be protected from tampering and attacks mounted from outside the system. new networking technologies will introduce the potential for new types of attacks. security can help with elements of reliabilityand safety as well since it involves not only satisfying objectives but alsoincorporates protective mechanisms.finally, emnets need to be usable. the systems must be easy to learn,easy to use, and amenable to understanding, often at different levels ofdetail by different types of users. as these systems become more complexand open to more varieties of computermediated interaction, they needto be designed in such a way that end users and operators understandwhat a system is doing. systems that violate usersõ expectations lead tofrustration at best and errors at worst; it will be important to keep userexpectations in mind in design decisions as these systems become morecomplex and pervasive. in addition, many of these systems will not bedirectly used by individualsñrather, individuals will interact withemnets in various contexts, often without realizing it. understandinghow such interactions will take place and what peopleõs conscious andeven subconscious expectations might be is an additional challenge forusability design in emnets.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers121the unique constraints on emnets raise additional concerns; thischapter discusses the challenges inherent in designing emnets to be reliable, safe, secure, private, and usable, and suggests the research needed tomeet these challenges.reliability reliability is the likelihood that a system will satisfy its behavioralspecification under a given set of conditions and within a defined timeperiod. the failure of a particular component to function at all is only oneform of unreliability; other forms may result when components functionin a way that violates the specified behavior (requirements). indeed, acomponent that simply stops functioning is often the simplest to dealwith, because such failure can be detected easily (by the other components or the user) and, often, isolated from the rest of the system. farmore difficult failure cases are those in which a component sends faultyinformation or instructions to other parts of the networked system (examples of socalled byzantine faults); such a failure can contaminate allcomponents, even those that (by themselves) are functioning normally.systems need to be designed with great care to address the expectedfailures. because emnets will often be unattended or operated by nonexpert users, operator intervention cannot be relied upon to handle mostfailures. current failure models for distributed systems revolve aroundthe ways in which individual components or communications infrastructure can fail (schneider, 1993). faulttolerant designs of such systemsgenerally assume that only a small number of failures of any type willoccur. it is not at all clear that these models apply to emnets, in which theindividual components are assumed to be easily and inexpensively replaceable, and the usual mechanisms for detecting faults (such as a request for a keepalive message) may be prohibitively expensive in termsof power or bandwidth or may generate false failure notifications (in thecase of components that shut down occasionally to conserve power.) thedevelopment of techniques for faulttolerant designs of systems in whichthe individual components are resourcebound and easily replaceable isan area ripe for investigation.nor are current techniques for verifying the reliability of design implementations readily applicable to emnets. while significant work onthe hardware verification of nontrivial systems dates back to at least themid1980s (see, for example, huntõs work on the fm8501 microprocessor(hunt, 1994)), it is more appropriate for individual components and maynot be applicable to emnets. each component, to be reliable, must correspond to its specification, and the overall system will be considered reliable if it adheres to the system specification. experience has shown,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.122embedded, everywherehowever, that merely confirming the reliability of individual componentsof a system is insufficient for understanding the behavior of the overallsystem. existing methods for ensuring reliability are tied to tests of system implementations against the appropriate specification. it should benoted that testing traditionally occurs after design and implementation.while testing and validating complex designs after the fact tends to havemore appeal than building in reliability and assurance from the beginning (which calls for greater rigor and costs more), it is an extremelydifficult task that already consumes a large fraction of the overall expense,schedule, and labor of an engineering project. microprocessor designteams typically allocate one validation person for every two designers,and the trend is toward parity with future designs. many softwareprojects report deploying one validation person for every software writer.companies are investing heavily in testing because (1) shorter productdevelopment schedules no longer permit a small set of testers to work ona project for a long time, (2) the overall complexity of the designs ismaking it increasingly difficult to achieve the product quality necessaryfor introducing a new product, and (3) the volumes of product beingshipped today make the possible expense of product recalls intolerable tomost companies.òif you didnõt test it, it doesnõt workó is a general validation philosophy that serves many hardware or software design projects well. theidea is that unless the designer has anticipated the many ways in which aproduct will be used and the validation team has tested them comprehensively, then any uses that were overlooked will be the first avenues offailure. but the problem is not as simple as listing the productõs featuresand checking them one by one (although that is indeed one aspect ofnormal validation). design flaws that manifest themselves that simplyare usually easy to detect. the more insidious product design flaws appear only when multiple product features are combined or exercised inunusual ways. the complexity of such situations hampers efforts to detect flaws in advance.for emnets, the challenge of testing every system feature againstevery possible realworld usage will be daunting, even for an accuratelyconfigured system in initial deployment. but what happens a few monthslater when the system owner begins to extend the system in ad hoc ways,perhaps upgrading some nodes and adding others supplied by anothervendor? the central challenge to emnet reliability is to extend todayõstools and validation methodsñfor example, the willow project on survivable systems2 and easel (fisher, 1999), a simulator for modeling2for more information, see <http://www.cs.colorado.edu/serl/its/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers123unbounded systems,3 may offer insightsñto the much more difficultscope of largescale emnets.reliability research topics deserving attentionthe following research topics deserve attention:¥fault models and recovery techniques for emnets that take into accounttheir scale, long life, open architecture, distributed control aspects, and thereplaceability of their components. appropriate models of failure and howto deal with failures in systems that are distributed and have the scale,longevity, openness, and component characteristics of emnets have yetto be investigated. until such investigations take place it will be difficultto design reliable systems, much less test implementations of those designs. such research should be linked to research into the computationalmodels appropriate for such systems (see chapter 5).¥emnet monitoring and performancechecking facilities. over the pastseveral decades, considerable research has gone into monitoring and system health management, but emnets pose unique problems owing totheir potential scale and reconfigurability and the scarcity of componentenergy.¥verification of emnetsõ correctness and reliability. the size and distributed nature of emnets may preclude complete system testing outsideof simulation. advances in analysis and simulation techniques wouldincrease confidence in cases where complete testing is virtually impossible before the system is used in the field.4safetysafety refers to the ability of a system to operate without causing anaccident or an unacceptable loss.5 many emnets (for example, a homeentertainment system) will not present significant safety problems even ifthey fail, although such failures might frustrate or inconvenience users.other failures may raise significant safety issues.safety and reliability do not necessarily go hand in hand. an unreliable system or component is not necessarily unsafe (for example, it may3for more information, see <http://www.cert.org/easel/easelfoundations.html>.4see making it better (cstb, 2000c) for a discussion of the limitations of the simulation ofcomplex systems today.5òaccidentó is not an engineering term; it is defined by society. in the aviation community, for example, the term òaccidentó is used to refer to the loss of the hull of an aircraft;anything else is considered an incident, even though human life may be at risk.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.124embedded, everywherealways fail into a safe state or an erroneous software output may notcause the system to enter an unsafe state, or a system that stops workingmay even decrease safety risks), whereas a highly reliable system may beunsafe (for example, the specified behavior may be unsafe or incomplete,or the system may perform unintended functions). therefore, simplyincreasing the reliability of the software or system may have no effect onsafety and, in some systems, may actually reduce safety. reliability isdefined in terms of conformance with a specification; accidents usuallyresult from incorrect specifications. whether viewed as a constraint on, or a requirement of, the systemdesign, safety concerns limit the acceptable design space. like the otherdesirable characteristics addressed in this chapter, safety cannot effectively be added onto a completed design, nor can it be tested or measuredòintoó a design. safety constraints need to be identified early on in thedesign process so that the system can be designed to satisfy them. testingand measurement simply provide assurance on how effectively the design incorporates alreadyspecified safety considerations.engineers have developed a range of techniques for ensuring systemsafety, many of which have been extended to systems with embeddedcomputers; however, much more research is needed (leveson, 1995) inthis area, which has attracted comparatively little attention by computerscience researchers. in system safety engineering, safety efforts start earlyin the concept development stage. the process involves identifying system hazards (i.e., system states that can lead to accidents or unacceptablelosses), using them as the basis for writing system safety requirementsand constraints, designing the system to eliminate the hazards and theireffects, tracing any residual safetyrelated requirements and constraintsthat cannot be eliminated at the system level down to requirements andconstraints on the behavior of individual system components (includingsoftware), and verifying that the efforts were successful.emnets introduce added difficulties to this process. they greatlyincrease the number of states and behaviors that must be considered andthe complexity of the interactions among potentially large numbers ofinterconnected components. although all large digital systems experience similar problems, emnets are unusual in that many operate in realtime and with limited direct human intervention. often they are eitherunattended or managed by human operators who lack technical skills orare untrained. furthermore, emnets afford the possibility of more dynamic configuration than do many other types of systems. many emnetsare likely to arise from ad hoc extensions of existing systems or fromseveral systems tied together in ways unanticipated by the originaldesigners. historically, many accidents have been attributed to operator error.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers125indeed, a common reason for automating safetycritical systems (apartfrom increasing efficiency) is to eliminate operator error. automation hasdone this, but it has also created a new type of error, sometimes calledtechnologyinduced human error. many of these new errors are the resultof what human factors experts have labeled technologycentered automation, whereby designers focus most of their attention on the mappingfrom software inputs to outputs, mathematical models of required functionality, and the technical details and problems internal to the computer.little attention is usually given to evaluating software in terms of whetherit provides transparent and consistent behavior that supports users intheir monitoring and control tasks. research on various types of systemmonitoring, including hierarchical monitoring and standards thereof, mayprove useful here.without the kind of support mentioned previously, technologycentered automation has changed the reasons for accidents and the types ofhuman error involved. humans have not been eliminated from mosthightech systems, but their role has changed significantly: often, theyare monitors or highlevel managers of the automation, which directlycontrols the system. on modern flybywire aircraft, for example, all pilotcommands to move the control surfaces go through a computerñthereare no direct mechanical linkages. automation designs seldom supportthe new roles humans are playing. and yet, when the inevitable humanerror results from what aircraft human factors experts have called clumsyautomation (wiener and curry, 1980), the accident is blamed on thehuman rather than the system or automation design. all of the recentairbus accidents and some of the recent boeing accidents involved pilotconfusion arising from the design of the automation (leveson et al., 1997).examples include mode confusion and the lack of situational awareness(both related to inadequate feedback, among other things), increased pilotworkload during emergencies and high stress periods, automation andpilots fighting over control of the aircraft, increased amounts of typing,and pilot distraction. human factors experts have tried to overcomeclumsy automation by changing the human interface to the automation,changing user training, or designing new operational procedures to eliminate the new human errors resulting from poor automation design. theseefforts have had limited success. some have concluded that òtrainingcannot and should not be the fix for bad designó (sarter and woods, 1995)and have called for more humancentered automation. currently, however, coping mechanisms are required until such automation becomesmore widespread.if researchers can identify the automation features that lead to humanerror, they should be able to design the software in such a way that errorsare reduced without sacrificing the goals of computer use, such as inembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.126embedded, everywherecreased productivity and efficiency. emnets complicate the process oferror reduction simply because of their increased complexity and theopacity of system design and operation. today what can be automatedeasily is automated, leaving the rest for human beings. often this causesthe less critical aspect of performance to be automated, leaving to humansthe more critical aspects. worse, the systems often fail just when they aremost neededñwhen conditions are complex and dangerous, when thereare multiple failures, or when the situation is unknown. unfortunately, ifthe routine has been automated, the human controller has been out of theloop, so that when the automated systems fail, it takes time for the humanoperator to regain a sense of the state, time that may not be available.emnets increase the likelihood that human intervention will not bereadily available. approaches to automation should be changed fromdoing what is relatively easily achievable to doing what is most neededby human operators and other people affected by system behavior. thisprinciple is, of course, applicable to more than just emnets. the solutionwill need to incorporate the economic and institutional contexts as well asthe technology.safety research topics deserving attentionwidespread use of emnets will compound the existing challengesinvolved in designing safety into systems. these challenges will need tobe addressed quickly to avoid future problems and to ensure that thepotential of emnets is effectively tapped. to address problems of safetyin emnets adequately, greatly expanded research will be needed in anumber of areas, including the following:¥designing for safety. safety must be designed into a system, including the humancomputer interface and interaction. new design techniques will be required to enforce adherence to system safety constraintsin emnet behavior and eliminate or minimize critical user errors. inaddition, designers often make claims about the independence of components and their failure modes to simplify the design process and makesystems more amenable to analysis, but they lack adequate tools andmethodologies for ensuring independence or generating alerts about unknown interdependencies. the system itself, or the design tools, willneed to provide support for such capabilities. this may well requirechanges in the way computer scientists approach these sorts of problemsas well as collaboration with and learning from others, such as systemsengineers, who have addressed these issues in different domains.¥hazard analysis for emnets. the deficiencies in existing hazardanalysis techniques when applied to emnets need to be identified. deembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers127signers and implementers of emnet technology who may not necessarilybe familiar with such techniques will need to understand them. hazardanalysis usually requires searching for potential sources of hazardsthrough large system state spaces; emnets will complicate this searchprocess for the reasons already discussed. the results of hazard analysisare critical to the process of designing for safety and verifying that thedesigned and implemented system is safe.¥validating requirements. most accidents related to software stemfrom requirements flawsñincorrect assumptions about the required behavior of the software and the operational environment. in almost allaccidents involving computercontrolled systems, the software performedaccording to specification but the specified behavior was unsafe (leveson,1995; lutz, 1993). improved specification and analysis techniques areneeded to deal with the challenges posed by emnets. these techniquesshould take into account that user needs and therefore specifications willevolve.¥verifying safety. in regulated industries, and even in unregulatedones in which liability or costly recalls are a concern, special proceduresare required to provide evidence that fielded systems will exhibit adequate levels of safety. emnets greatly complicate the quest for suchassurance, and new approaches will be needed as the complexity andpotential number and variety of potential failure modes or hazardoussystem behaviors increase.¥ensuring safety in upgraded software. even if the software is designed and assured to be safe in the original system context, software canbe expected to change continually throughout the life of a system as newfunctionality is added and bugs are fixed. each change will require assurances that safety has not been compromised, but because it will not bepractical to redo a complete software system safety analysis for everychange, new techniques will be needed to minimize the amount of effortrequired to verify safety when potential system and software designchanges are proposed and to cope with the consequences of safety failures. users can be expected to extend the system in ways unanticipatedin the original design, adding new components, trying out new functions,and so on.6 in addition, the system and software design may becomeunsafe if there are unanticipated changes in the environment in which the6further complicating the situation is the fact that backup safety features, meant to beinvoked only in emergencies, are often discovered by human operators and used as primary resources. thus, if the system automatically detects a human error and produces anautomatic correction, the human will soon learn always to make the error; oftentimes it iseasier to do the task wrong and let the system correct it than to go through the laborious actof getting it right.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.128embedded, everywheresoftware is operating (a likely occurrence in a battlefield situation, forexample). methods are needed to audit the physical components of thesystem and the environment (including system operators) to determinewhether the changes violate the assumptions underlying the hazardanalysis. approaches to software upgrades must address safety concernsin hardware components, too (for example, component audits could include calls to hardware components to validate their ids).security security relates to the capability to control access to information andsystem resources so that they cannot be used or altered by those lackingproper credentials. in the context of emnets, security relates to controlled access to the subnetworks, the information stores, the devices thatare interconnected, and the computing and communication resources of agiven network. many of the research issues that were raised with respectto safety in emnets also apply to security. in addition, security analysisneeds to assume that an adversary is actively trying to abuse, break, orsteal from the system (an assumption not usually made for safety analysis.)security can be difficult to achieve in information systems of all types,but will perhaps be especially so in emnets. not only will the deployment of emnets containing various sensor technologies allow the physical world to become more tightly interconnected with the virtual world,but the networking of embedded computers will also tend to increase thevulnerability of these systems by expanding the number of possible pointsof failure, tampering, or attack, making security analysis more difficult.the range of products into which processing and networking capabilitiesmay be embedded will greatly expand the number of nodes at whichsecurity will need to be explicitly considered and influence the expectations at each node. many of these nodes will consist of presumably ordinary everyday devices in which security is not currently a concern (thermostats, audio equipment, and so on); however, mischief will become anincreasing risk factor. their close connection to the physical world andinterconnection with larger networks accessible by more people with unknown motives will make lapses of security potentially more damaging,increasing the risks associated with emnets. in a military context, ofcourse, the compromise of even fairly prosaic devices (such as food storage equipment or asset monitoring systems) that are part of a largeremnet could have serious security implications.emnetsõ configurations will be much more dynamic, even fluid, thantypical networked systems. emnet user interaction models may be quitedifferent from those in traditional networks. these properties have sigembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers129nificant impact on security (and privacy). for example, as one movesfrom place to place, oneõs personal area network may diffuse into othernetworks, such as might happen in a battlespace environment. interactivity may not be under an individualõs direct control, and the individual may not understand the nature of the interactivity. various nodeswill engage in discovery protocols with entities in contexts they havenever encountered before. some emnets may be homogeneous and theirconnectivity with other networks may be straightforward. in such cases,traditional network security techniques will suffice, with policy and protection methods executing in a gateway device. in heterogeneous, diffuse, fluid networks, traditional network security methods will not beeffective. rather, trust management and security policies and methodswill be the responsibility of individual nodes and applications. this mayput demands on the operating system (if any) that runs on those individual nodes. they may need to distinguish between secure operatingmodes and more permissive modes (especially during discovery, configuration, and update procedures).protecting system boundariesa key problem is how to protect the network from outside attack.the physical world has a number of wellunderstood and easily recognizable protective barriers and security structures. retail stores, for example,have a physical structure to protect valuables. even though these storesare open to the public, shoplifters can be thwarted by a welldefinednotion of inside and outside and sensors used to overcome attempts toconceal goods. such approaches have few analogues in the virtual world.further, in the case of shoplifting, a risk management calculation is performed: that is, some level of security breach (shrinkage) is acceptable tomerchants because absolute security would be unacceptable to customers. risk management is also required for emnets; however, calculatingthe risk is extremely challenging and variable because there are so manyunknowns in these systems. the physical isolation of a network, togetherwith extremely rigid and secure protocols for attaching terminals, is theonly highly reliable method for protecting networked information systems from external threats (that is, attacks from outside hackers and others without access privileges), but this approach is not viable in manysystems that need to be interconnected to be useful. in emnets, physicalboundaries and remoteness are effectively erased by the presence of sensors and network connectivity, and notions of entry and exit begin tofade. except in physically isolated networks, the concepts of inside andoutside generally do not exist. yet this is one way in which users, andeven designers, think about security problemsña mindset that, in itself, isembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.130embedded, everywhereextremely problematic. two further factors complicating the notion ofinside versus outside are that components of emnets will change overtime (perhaps all of the components, many times, over the life of anemnet) and that much of the communication will take place over wireless networks. the wireless aspects of emnets make them prone to interference and jamming (intentional interference), which affect both reliability and security.the most common way to establish boundaries between the insideand outside of a networked information system is to use firewalls thatcontrol communications at the juncture between two networks. firewallsdo not, however, establish true boundaries; they merely limit the exchangeof packets between networks according to policies that are increasinglydifficult to understand and assure, especially on networks that need toinvite access by growing numbers of users, as in the case of socalledextranets. although new technology, such as the suite of ipsec protocols,7 seems to offer opportunities to define boundaries (for example,virtual private networks), what it actually provides is access control. thecontrols apply to arcane objects (such as packet headers) that are difficultto understand for most users. furthermore, it is almost impossible onmost networks to understand all of the means by which objects may bestored or accessed, making the effectiveness of access controls unclear. inemnets, the system perimeters are even more difficult than usual to define and may change over time. to the extent that emnets are used overever wider areas encompassing space (satellites), land, and ocean (seabedand submarines), between large numbers of vehicles, or spread throughout a large battleship, the difficulties of developing and implementingrobust access controls will only grow.managing scale and complexitythe large scale and high degree of complexity in emnets will furtherfrustrate the attempt to identify boundaries and improve security becausethese characteristics will tend to make system security more difficult toanalyze. what are the threats to a given emnet? how are security risksevaluated? what should be the public policy regarding completion of asecurity threat analysis preceding deployment of an emnet, if òdeploymentó can even be considered an actual, discrete event? it is becomingvery difficult to offer even simple answers to these questions as the physi7internet protocol security (ipsec) is a framework of open standards for security at thenetwork or packet processing layer. earlier security approaches have usually been at theapplication layer.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers131cal and logical connectivity of networks increases.8 methods for evaluating threats and assessing security risks in complex systems whose elements are tightly coupled to physicalworld artifacts are lacking. as recent events on the internet indicate, some types of threats, such asdenialofservice attacks, have a high success rate, and many system usersnaively hope that the motivation for such attacks is slight.the virtual world remains difficult to contain. although cryptographic techniques enable engineers to build arbitrarily secure systemcomponents, assembling such elements into secure systems is a great challenge, and the computing research community does not yet understandthe principles or possess the fundamental knowledge necessary to buildsecure systems of the magnitude necessitated by emnets. it will beincreasingly important to ensure that security issues are addressed at theoutset of system design, so that notions of network isolation can be dealtwith in a straightforward manner. historically, however, networks aredesigned and often deployed before security issues are addressed. withmanyñperhaps mostñemnets, that sort of approach will result in problems. if security design is an afterthought, or a security hazard has already produced consequences, then the system is usually much too complex to even analyze from a security perspective. at present, it appearslikely that systems whose evolvability is already hard to predict will bedeployed without a full understanding of the security implications. thissuggests both the need to accelerate relevant research and the need forcoping and compensating strategies.mobile code and securitythe use of mobile code in emnets will create another potential vulnerability with implications for security.9 the networking of embeddedcomputers allows for remote updates to the programs that run on thosecomputers as well as the use of mobile code. if either capability is implemented, then the system is open to a significant security hazardñnamely,that the code that eventually runs on these computers may not be codethat is legitimately intended to be run on them. furthermore, even if thecode is legitimate, it may have unintentional security flaws. a number ofmechanisms can be used to deal with this problemñexamples include8these questions apply to the other elements of trustworthiness described in this chapteras well. the size, scale, and complexity of emnets complicate issues of privacy, reliability,safety, and usability along with security.9mobile code and its implications for selfconfiguration and adaptive coordination werediscussed in chapter 3.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.132embedded, everywheresecure boot loaders and secure class loaders that check code authenticators and compliance with security policiesñbut such mechanisms are notgenerally used in todayõs embedded computers, let alone in conventionalcomputing and communication systems. as embedded computers become networked, it will be necessary to deploy these and other featuresmuch more routinely.of course, emnet resource constraints, whether of memory, computational capability, or power, will make it difficult to use some of thesetechniques in their current forms. their use will also require deploymentof the infrastructure necessary to support and maintain the policies bywhich these systems abide. in some cases this process will be straightforward, but in other others it will be far more complex. an automobilemanufacturer, for instance, may be able to deploy tools comparativelyeasily that assure that code updates originate from the manufacturer.what is less clear is how to meet the challenge raised by openair contexts,such as a battlespace, where there is less control over the environmentand more opportunities for and likelihood of malicious activity.denial of service denialofservice attacks on emnets could be of significant concernif they are widespread or involve safetycritical systems. indeed, if society relies more on emnets and allows them to be involved in many dailyhuman activities, the invitation to disrupters grows. the wireless aspectsof emnets will be particularly susceptible to jamming attempts, for example. denialofservice attacks are very difficult to defend against ifthey are not anticipated in system design and taken into account in eachsystem service protocol, at both high and low levels of communication.because emnets are often characterized by a lack of òexcessó computingresources, extraneous requests, as found in floodingbased distributedattacks, will more easily swamp these systems. moreover, they will oftenbe constrained in terms of the power available to them, so the mere act ofreceiving requests in a denialofservice attack can cause longterm damage to an emnet, well beyond the duration of the attack. (for more traditional systems, denial of service is a transient attack; when the attackstops, the damage usually stops accumulating. this is not the case withbatterypowered emnets.)the above observations may pose significant challenges to the designof highintegrity networks such as are found in the military. traditionaltechniques that ensure the integrity of executables, such as credentialingand integrity checks, are subject to denialofservice attacks in the form ofvery simple, otherwise innocuous, easily concealed, networkborne viruses that do little more than append themselves to files or memory imembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers133ages, invalidating credentials. systems that rely on precise integrity techniques can turn out to be highly fragile. certainly, operatingsystemleveltechniques may be employed to thwart such denialofservice attacks, butit remains to be seen how effective they will be.security research topics deserving attentionthe security issues discussed above raise a number of research issuesthat need to be addressed, including the following:¥network access policies and controls. how does one devise, negotiate,deploy, and renew network access policies that address the various threatsthat may be of concern to a given emnet? how can this be done in anenvironment in which the emnet itself is reconfigured, often on an ad hocbasis? access controls need to be devised that will be easily understood,able to protect the wide variety of information that may be collectedunder widely varying and often unforeseeable circumstances, and perhaps even selfconfiguring.¥enforcement of security policies. how should security policies beobserved on individual network elements as well as on the network operating system? how are these policies devised and enforced when thereare multiple òownersó of various parts of an emnet?¥critical infrastructure selfdefense. mechanisms need to be identified that are useful for ensuring mobile code safety, defeating virus attacks, and preserving function in spite of the failure or compromise of oneor more nodes. what types of safe operating modes can be devised thatallow for the secure update of an emnet, reducing the risk of attack whilemaintaining performance? this will be especially important for emnetsthat control critical infrastructures and support military applications andbattlespaces as well as for more civilianoriented applications such aselectric power systems, financial systems, and healthcare systems.¥preventing denialofservice attacks. mechanisms are needed that preserve the inherent capacity to communicate over emnets yet effectivelydefend against denialofservice attacks.¥energy scarcity. security in the face of energy scarcity is a significant challenge. new authentication and data integrity mechanisms areneeded that require less communication overhead. it may be possible toexploit heterogeneity and asymmetry within the network to allow smallersystem elements to do less than larger ones. further, when there is redundancy in the emnet, it may be possible to exploit the redundant components in order to detect outliers and possibly sabotaged nodes.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.134embedded, everywhereprivacy the anticipated broad deployment of emnets in public spaces andprivate homes could allow the collection of considerable informationabout individuals. in many cases, individuals may be unaware of sensornetworks deployed in the public spaces or commercial environments theyenter and the associated information being collected about them. even intheir own homes, many users may be unaware of the types of informationthat embedded processors are collecting and possibly transmitting vianetworks to vendors or other recipients.10 the embedding of informationtechnology into a growing number of devices will increase the amount ofpersonal and personally identifiable information that can be collected,stored, and processed.achieving consensus on privacy and confidentiality policies continues to be a vexing problem and will only become more problematic asemnets become more pervasive and interconnected. it should be notedthat most of the issues involved here are not strictly technical but ratherissues of public policy. the question is not necessarily, what can be donetechnologically but rather, what should or should not be done? the technical challenges lie in designing systems that facilitate support of thepolicies once they are decided.11,12consideration of the privacy implications of emnets cannot be limited to these systems alone but must extend to the larger networks ofmore powerful computers to which emnets connect. information abouttransactions and events collected through networks of simple computersand sensors can be and is analyzed for links and correlations in muchmore powerful computers, both online and offline. it is these more powerful computer networks that can turn relatively innocuous data collectedon emnets into detailed data shadows that allow the reconstruction ofcomplicated personal profiles. how, in the face of these prodigious capabilities, can systems provide anonymity whenever it is useful and appro10few automobile drivers, for example, are currently aware that many cars collect andstore information about the way a car has been driven (e.g., driving speed, acceleration,engine speed). this information can be used by manufacturers to better analyze accidentsand, hence, improve safety but could also be used to disallow warranty claims or to provethat an automobile was operated in an unsafe manner.11alan davidson, of the center for democracy and technology, briefed the committee onprivacy issues for emnets, saying, òprivacy should be a critical design value as [these]systems are conceived and implemented.ó12for more information on the notion of designing systems that are sensitive to policiesand human values, see valuesensitive design: a research agenda for information technology(friedman, 1999).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers135priate? what are the limits of the protocols and technologies that assureanonymity and prevent linkages between events and transactions? withmore and varied data being collected, it is becoming increasingly difficultto avoid the linking of these data and, more specifically, associations ofdata with real identities even when protocols that assure local anonymityare used.conceivably, policycontrolled, secure systems can collect data andpolicycontrolled, secure systems can dispense them. but who sets thepolicies, and who enforces them? numerous legal and public policyquestions need to be addressed. who owns the personal data collectedeither with or without the knowledge of the person? should ownershipbe negotiable? if so, how can people extract value from their own personal data in an equitable fashion? what is practical and enforceable insystems in which interactions are fleeting and take place very quickly?can and should protocols be provided whereby people can exchangetheir data for other value, and how can people avoid being unfairly coerced? these are broad issues that are also applicable to the internet. inthe united states, regulation has limited the use of customer proprietarynetwork information (cpni) on telephone networks.13 should there besimilar limitations for other networks? or will it be too difficult to definewhat is proprietary to the customer? how might the government gainaccess to such information, or should there be ways of protecting theinformation from access?a related issue that will need to be resolved is how (and sometimeswhether) to advise people when their actions are being monitored. manyemnets, for example, will be difficult to detect, and users may be unaware that they are being tracked. this issue has already arisen in thecontext of electronic commerce, where consumers have expressed concern about the monitoring of their web surfing and online purchasing. inmost cases, consumers are unaware that their actions are being monitored, stored, and compiled into individual profiles even though individuals are usually aware that they are interacting with a system and areactively providing it data. emnets may become so ubiquitous and soinvisible that people are no longer aware that they are interacting with anetworked system of computers and will often unknowingly and passively provide data. one part of the issue is notification: making peopleaware of the fact that they are being monitored. as experience with13see the code of federal regulations, title 47, volume 3, part 64 (gpo, 1998). in 1999 anappeals court vacated the fccõs cpni order on first amendment grounds in us west vfcc, available at <http://www.fcc.gov/ogc/documents/opinions/1999/uswestcpni.html>.the supreme court let this ruling stand.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.136embedded, everywhereonline profiling has demonstrated, however, notification is not a simpleprocess. many questions need to be answered. when should notificationbe mandatory? how can users be effectively signaled? given individualdifferences in sensitivity and awareness, it may be difficult to provideadequate notification to some without annoying others. this may especially be the case in smart spaces, where all sorts of information may becollected and possibly linked to an individual. more research is neededto address issues like these.additional means may also be needed to control the disclosure ofinformation. the issue of disclosure arises when information is collectedfor one purpose but used for other purposes (often referred to as missioncreep). disclosure is often provided in privacy policies for web sites, butemnets often involve more passive interactions in which disclosure isless convenient. for example, a smart space may collect informationabout an individual and provide it to others with the intention of providing a useful service, but the individual being probed may not be appreciative. are there techniques that would allow users to control the flows ofinformation about them? how can a user answer questions such as, whereis my information? who has it? how did it get there? who is responsibleif something goes wrong? in addition, what conditions are needed so thatusers trust others not to misuse their data, and can emnets be designed toengender an atmosphere of trust that is not due solely to ignorance oftheir existence in a given situation? considerable work has begun ontechnologies that allow consumers to express privacy preferences14 andpurveyors of intellectual property to control the dissemination of theirwork.15 however, these approaches are being developed in the contextof webbased electronic commerce; whether or not they are extendable toa broader set of emnetbased applications is unclear.it would seem to be very difficult for anyone to avoid giving uppersonal information to these networks. there are risks even wheneveryoneõs intentions are well understood. it would be useful to havesome general principles whereby the risk of inadvertent privacy violationcan be minimized. these might include disposing of information as soonas possible after it is used; storing information near the point of use; andavoiding the removal of such data from local control whenever possible.use of anonymity or pseudonymity and of protocols that prevent thelinking of data sets could also be considered.14for example, see the platform for privacy preferences project (p3p) at <http://www.w3.org/p3p/>.15see chapter 5 of cstb (2000a), a report on intellectual property in the information age.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers137the fundamental issue is the ability of individuals to control the collection and dissemination of information about them in an environmentin which daily transactions and eventsñand the events associated withtheir personal environmentñinvolve emnets or are controlled or monitored by them. research is needed to better understand peopleõs expectations about their rights and abilities to exercise such control and resistintrusion. what are the expectations about privacy, and how are theyevolving as people become more exposed to and familiar with varioustechnologies? can one outline the privacy rights that people either expector legally possess, and can one identify ways in which different types ofemnets threaten those rights and run counter to those expectations?conversely, as emnets become ubiquitous, are there ways to use thetechnology to defend privacy rights, or will privacy necessarily be lost?as the ftc has recognized (thibodeau, 2000), many privacy questionswill need to be rethought in a world of increasing automation and instantaneous wireless communication. both privacy expectations and case laware evolving. it will be necessary to clearly understand the tradeoffsinvolved. emnets have more of a propensity to be ubiquitous and enveloping, unavoidable in our environment, where individuals are not incontrol of their interaction. in these cases, privacy issues cannot be addressed by education and personal policies alone. rather, they become(even more) a matter of public policy.16privacy as related to securitywhile security and privacy are very distinct properties, they are related (for example, security can provide mechanisms with which to protect privacy). privacy is often said to involve the right or desire to be leftalone. in the context of emnets, it more often has to do with the right orintention of a person to keep certain personal information confidential. abreach of security may result in breach of privacy by someone withoutproper credentials who gains access to private information; a breach ofprivacy may also occur when information that is freely shared over anetwork is abused or when emnets are deployed into various environments without notification, consent, or full disclosure. breaches of security may also involve the dissemination, through an emnet, of information that is intended to be shared for a narrow purpose but is usednonetheless for broader purposes because of an inability to precisely con16cstb anticipates a policyoriented study on privacy in the information age to beginsometime in 2001. in addition, chapter 5 of the cstb report the internetõs coming of age(cstb, 2001) examines implications for broad public policy, including issues related toprivacy and anonymity on the internet.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.138embedded, everywheretrol data flows or the use of information collected for one purpose for acompletely different purpose. security and privacy are related for another reason, too: both may bestudied and understood in a given context by analyzing threats and risks.the security threats to a given network can be catalogued; countermeasures for those threats specified; and then residual risks of failure, oversight, and inadequacy identified. similarly, the threats to privacy fromthe deployment or specific use of emnets may be catalogued, means forprotecting and preserving privacy specified, and the residual risks analyzed and managed. privacy issues may be somewhat more challengingto deal with than security issues because they entail varying expectationsand values and because access control practices often call for conveyingpersonal information. privacy seems far more malleable than security,because what counts as private is socially negotiated; privacy violationsmay occur when individuals have different understandings about theboundaries and contexts of privacy (this will be especially true with newtechnologies and where the technology moves information across multiple social contexts). expectations are in flux, as the internet is demonstrating that there is less privacy than may once have been assumed.further, people differ with respect to the types of information they wishto keep private, the conditions under which they might allow access todifferent sorts of information (for example, health records, financial information, and online purchases), and the degree to which they value privacy.privacy research topics deserving attentionwhile the privacy issues discussed above raise many public policyquestions, they also raise several technical research issues that need to beaddressed. both the policy and technical issues demand much additionalresearch, but this research need not be emnetspecific. in addition, whilemany of the policy and technical issues may not be directly applicable todefense and military situations, the need in such situations for identification (for example, friend or foe?) and for needtoknow classification ofinformation make some of these points relevant. privacy has largely beendealt with by advocacy, legal, and political processes; however, it willincreasingly involve and require technical mechanisms and contextualizations. the committee strongly encourages additional research in themany policy issues surrounding privacy and makes the following recommendations with respect to technical concerns:¥flexible policy management. emnets, and indeed all informationsystems, do implement some form of privacy policies. often, however,this is by default not by design. research is needed to develop a calculusembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers139of privacy17 and ways to enable flexible, configurable privacy policies insystems so that as external situations or policies change, the system can beeasily adjusted to reflect that. systems should be designed to allow incorporating a wide range of potential privacy policies.¥informed consent. implementing informed consent in technologicalsystems is a difficult challenge. emnets seem likely to make this problemthat much harder. owing to the passive and ubiquitous nature of manyof these systems, users will often not be aware that information aboutthem is being gathered. notifying users who may not even be aware ofthe existence of the emnet is a difficult problem. even more difficult isacquiring meaningful informed consent from those users. research intothese and related issues is essential.¥accountability research. research into possible legal requirementsfor the protection of personal information may be needed to ensure adequate accountability. the goal should be to ensure that specific individuals or agents, probably those who deploy emnets and will use theinformation gained therefrom, are deemed responsible and accountablefor the protection of an individualõs private information collected on thosenetworks.18 privacy and/or anonymity preservation techniques need tofactor in accountability. accountability, like privacy, is not absolute(lessig, 1999). what is needed is technology to support a range of preferences, which may vary with users and contexts, for enhancing privacy,accountability, and other values.¥anonymitypreserving systems. research in designing systemswhose default policy is to preserve individual usersõ anonymity is needed.it is an open question to what extent these systems would need to allowcompletely untraceable use rather than just strict identity protection except in the presence of authorized agents. another possible avenue ofinvestigation would be to enable anonymitypreserving authentication19ñfor example, to enable systems to determine that individuals are membersof a certain group (say, doctors in a hospital) but not to allow more finegrained identification.2017a calculus of privacy can be thought of as a method of analysis, reasoning, or calculation that takes into account the many factors relevant to privacy (peopleõs expectations, thecharacteristics of disclosed information, ease of access, etc.) and the relationships amongthem.18p3p can be seen as the early stages of a technology that gives people more control overtheir data and provides information about how web sites handle personal information.19another cstb committee is currently investigating authentication technologies andtheir privacy implications.20cstbõs report summary of a workshop on information technology research for federalstatistics (cstb, 2000b) has a section on limiting disclosure, which addresses some of theinherent difficulties in protecting identities in the face of extramural information.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.140embedded, everywhereusability usability refers to the effectiveness and efficiency of a system inmeeting the goals and expectations of its users. all complex systems raiseusability issues, and emnets are no exception. usability is not a singletrait of a system but rather an umbrella term encompassing a number ofdistinct (and often conflicting) traits, including learnability, efficiency,effectiveness, and satisfaction. moreover, these traits are not intrinsic tothe system but must each be evaluated with respect to specific classes ofusers. for example, what is intuitive and therefore effective for a casualor beginning user may be tedious and verbose to an experienced user.further, in the case of emnets, it may not be accurate to refer to peoplewho interact with them as òusersó per se. consider the case of an emnetcontrolling various systems of a building; generally the emnet will beessentially invisible to the people interacting with its features. an important distinction must also be made between users who are outside thesystem boundary and operators who are within the system boundary andare, in effect, essential components of the system. users and/or othersinteracting with the system will usually have little formal training,whereas operators will almost always have some training because theyare hired and trained specifically to operate the system. operators, inaddition, often are required to monitor the automation and take over itsfunctions, if necessary, or to share the control function in various ways.the presence of trained operators allows the system designer to engineerspecific training requirements into the systemña luxury that is not generally available in the case of end users. on the other hand, the quality ofadministration for many systems is very low, and it is not clear that theòusersó who will insert components into emnets are any less qualifiedthan many of the administrators.usability and safety are very differentñand potentially conflictingñfeatures. straightforward attempts to improve one negatively affect theother. for example, usability often dictates that operations carried outfrequently be convenient and perceptually salient in order to maximizelearnability and efficiency. but if such actions are also potentially hazardous, safety concerns may suggest that they be hidden or rendered difficultto execute by accident, for example, by requiring redundant inputs orrepeated confirmation. usability concerns, by contrast, would dictate thata user enter the data only once. one way to address this might be todevise a data encoding scheme that uses error correcting and detectingcodes. this would allow detecting simple data entry errors of the sortknown to be most common by humans (for example, transposition ofadjacent items or missed elements) and, upon such detection, producingeither nonsense or correctable states. such design conflicts are not necesembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers141sarily insurmountable, as suggested above, but they are unlikely to bedealt with satisfactorily in complex realworld systems in the absence ofdesign methodologies that explicitly give both issues their due. such efforts are important even where safety has absolute priority over usability,since safety measures that ignore usability are far more likely to be circumvented or otherwise subverted than are those that take usability intoaccount.it should be noted that although complex systems tend to presentmore usability challenges than simpler systems, complexity per se is notthe main deterrent to learnability or other aspects of usability. there arevastly complex systems (for example, the telephone network) for whichhigh levels of usability have been achieved; and there are relatively simpledevices (such as the alarm clocks found in most hotel rooms) that areconsistently baffling to all but the most determined user. usability ofcomplex systems is maximized when (1) complexity that does not need tobe exposed to the user is kept hidden and (2) when complexity that mustbe exposed is exposed according to an underlying cohesive, understandable, conceptual model that maximizes the predictability of the systemõsbehavior, supports the userõs efforts to generalize about those behaviors,and minimizes special cases and arbitrary actions.creating mental modelsmental models are a convenient concept for examining problems ofusability. a mental model of a device can be thought of as an individualõsidea of the expected behavior of the system as a whole (that is, how thesystem works) plus information about the current system state. thus, themental model amounts to a userõs expectations about the behavior of thedevices he or she is using. users form mental models of systemsñhowthey operate or are internally organizedñeven if they know virtuallynothing about the systems. different users will form different models ofthe same device; indeed, research shows that a single individual mayhave several (even contradictory) models of a system (leveson, 1995;norman, 1998). an automobile mechanic will have a much more detailed(and hopefully more accurate) model of a car than will a casual driverwho has never learned how a car works. products aimed at mass marketsand untrained users must be designed with these mental models in mindto ensure easy operation and commercial success.users often generate a mental model for a newly encountered deviceby analogy to other devices perceived to be similar. in many cases, thisanalogy may be loose and casual. for example, a firsttime user of adigital videodisk player probably will attempt to treat it like a videocassette recorder or a compact disk player. in other cases, the match betweenembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.142embedded, everywherethe old and new may be quite deliberate on the part of the designer. forexample, antilock brake systems (abs) were deliberately designed to beas indistinguishable as possible from conventional braking systems. theabs example provides an interesting illustration of the pitfalls of usermodel analogies and the conflict between usability and safety. althoughmost users tend to think of abs systems as exact functional replacementsfor conventional brakes (and newcar user manuals tend to describe themin these terms), the analogy breaks down under poor traction conditions,in which conventional systems should be pumped whereas abs systemsshould not. the analogy has been drawn to enhance usability and learnability (no special training is required and the driver need not knowwhich type of brakes the car has), but it also has led to serious accidents.usability may also be enhanced by designs based on standard metaphors. a familiar example is the desktop metaphor used in the design ofgraphical user interfaces for personal computers. in this paradigm, filesand other abstractions defined by the computerõs system architecture arepresented to the user as graphical metaphorical objects on the screen.these objects are imbued with certain consistent behaviors. for example,screen icons can be dragged around, they stay where they are placed,doubleclicking on them opens the program, and so on. in effect, the userinterface is endowed with a consistent physics more or less analogous tothe physics of the real world and, to the extent that the analogy is appropriate and consistent, the user is able to apply schemata developed indealing with realworld things to the metaphorical òthingsó behind theglass. it is important to realize, however, that metaphor is a means andnot an end. when metaphors are clean and well chosen, they can becomea powerful means of providing consistency in support of user models.but it is the consistency that ultimately has the greatest value, not themetaphor per se, and often the causes of consistency and ease of learningare better served by other techniques.an example of a usability technique is the use of idiom in interfacedesign (see cooper, 1995). idioms are design conventions that, unlikemetaphors, cannot readily be guessed but rather must be learned, byeither instruction or experiment. for example, many computer interfacesthat use graphical interfaces require the user to doubleclick the mousewhile the pointer is at a particular location on the screen to effect a desiredaction, such as opening a document. unlike the process of dragging anicon or window to reposition it, there is nothing metaphorical about thedoubleclicking operationñthat is, it does not obviously correspond toanything the user has encountered in the real world. nonetheless, ifimplemented consistently and with proper attention to human factorsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers143issues, the technique is easy to learn and use. in effect, this arbitrarybehavior becomes an important part of the physics of the interface without ever having been part of the physics of the real world.in designing for usability, good designers will require a grasp of theprobable models that users will tend to bring to (or infer from) the device.as obvious as this may be, such understanding is difficult to achieve, inlarge part because designers typically know things that users do not.they are inevitably better informed about the true nature of the devicethan a normal user is, and designers cannot easily act as if they are typicalusers. yet, this is exactly what is required to design against a user modelthat may be imperfect.21 there is a large literature on methods that helpa designer take the userõs perspective, most notably various approachesto user studies and socalled heuristic analysis techniques (nielson andmolich, 1990; nielson, 1994). more work is needed on developing goodconceptual models of systems.emnetspecific usability issuesmany of the usability issues raised by emnets are common to allcomplex information systems. however, there are characteristics of ubiquitous computing in general and emnets in particular that present newand unique challenges to the usability engineer. in particular, the distributed nature of emnets and their often intimate coupling with the physical environment represent a fundamentally new relationship betweendevice and user. a personal computer is a thing one sits in front of anduses. how will end users think about emnets? probably not as òthings.óthey may think of them as capabilities, as smart spaces, or as propertiesof the built environment. they may think of them as magic. often, theywill not think of them at all. the usability of such systems will not be thesum of the usability of their component parts. it will instead be an emergent property of the behaviors of the visible nodes and their invisiblecounterparts, of their interactions, and of the physical environments towhich they are coupled. what is the source of global coherence in asystem that may be spatially distributed, incrementally designed, andimplemented using heterogeneous and independently developed components? although the existence of such systemlevel behavior, as a supersetof the behavior of the individual components, is not new, it is nonetheless21the relationship between implementation models and user models is discussed atlength by cooper (1995) and tognazzini (1992).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.144embedded, everywheredifficult to address. what is new is that the very existence of the complexsystem may be unknown to the end user.22usability research topics deserving attentionemnets raise interesting challenges related to the usability of systemswith emergent properties. when large networks of devices are used tocreate smart environments, for example, the process of designing thesenetworks to enhance usability and of ensuring helpful effective modelswill be complicated by the very complexity of these systems. more research is needed in the following areas:¥design for users and interaction. approaches need to be developedfor designing emnets of increasing complexity that are usable with minimal training and without detailed knowledge of the system design or ofthe complex interconnections among system components. emnets shouldbe designed to accommodate users with varying skill levels and to accommodate the fact that they will often be invisible to the individuals interacting with them.¥appropriate conceptual models. further study is needed on the construction of appropriate conceptual modelsñthat is, models that describe22a further consideration is the relationship between emnets and their operators. onecould speculate that the experience might be less like running a specific machine thanparticipating in a confederation. a lot will be going on, couplings will often be loose. onecould also imagine the operator finding himself or herself more in the role of influencerthan absolute controller. for example, emnets widely coupled to the outside world mayhave severe responsiveness constraints that prevent the immediate execution of operatorcommands. in spatially distributed systems, communications cannot be instantaneous, andin bandwidthconstrained situations may be extremely sluggish. this, too, may contributeto the operatorõs sense of being only loosely coupled to the system. efforts should be madeto generalize lessons learned from the control of existing emnets or emnetlike systems,such as the telephone network and the power grid, both of which have benefited from agreat deal of rigorous human factors research. research synergies may also exist with areasof distributed control being worked on by darpa and other agencies, such as collaborations between humans and confederations of agents and control of robot swarms.in many cases, the locus of interaction design is likely to shift from user/device interactions to user/information interactions. the emerging disciplines of information architecture and human information interaction (gershon, 1995, lucas, 2000) shift the focus ofdesign from devices as such to the information that those devices mediate. examples ofresearch topics in this area include architectures for universal identity of data objects, replication architectures, techniques for maintaining perceived constancy of identity acrossheterogeneous display media, tangible interface techniques (ishii and ullmer, 1997), andinformationcentric user interfaces and polymorphic rendering (roth et al., 1997).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.trustworthy networked systems of embedded computers145the critical aspects of the system and that are understandable and usableby people. further study is also needed on developing appropriate specifications. people need to learn how to design for both novice and expertuse of emnets and for situations where the person interacting with thesystem is not aware of any interaction. furthermore, attention needs to bepaid to the different types of assistance that various users will need. system maintenance personnel will have a different and often deeper understanding of the system than will system operators.referencescomputer science and telecommunications board (cstb), national research council.1999. trust in cyberspace. washington, d.c.: national academy press.cstb, national research council. 2000a. the digital dilemma: intellectual property in theinformation age. washington, d.c.: national academy press.cstb, national research council. 2000b. summary of a workshop on information technologyresearch for federal statistics. washington, d.c.: national academy press.cstb, national research council. 2000c. making it better: expanding information technology research to meet societyõs needs. washington, d.c.; national academy press.cstb, national research council. 2001. the internetõs coming of age. washington, d.c.;national academy press.cooper, a. 1995. about face: the essentials of user interface design. foster city, calif.: idgbooks.fisher, david a. 1998. design and implementation of easel: a language for simulating highlydistributed systems. pittsburgh, pa.: carnegie mellon university. available online at<http://www.sei.cmu.edu/programs/nss/designeasel.pdf>.friedman, b. 1999. valuesensitive design: a research agenda for information technology. no.sbr9729633. washington, d.c.: national science foundation.gershon, nahum. 1995. òhuman information interaction,ó fourth international worldwide web conference, december. boston, mass.government printing office (gpo). code of federal regulations. title 47, vol. 3, parts 40 to69, revised as of october 1, 1998. available online at <http://frwebgate2.access.gpo.gov/cgibin/waisgate.cgi?waisdocid=177665407+1+0+0&waisaction=retrieve>.hunt, warren. 1994. òfm8501: a verified microprocessor.ó ph.d. dissertation, lncs 795.heidelberg, germany: springerverlag. abstract available online at <http://www.cli.com/hardware/fm8501.html>.ishii, hiroshi, and brygg ullmer. 1997. presentation at chi 97 conference on humanfactors in computing systems, march.lessig, lawrence. 1999. code and other laws of cyberspace. new york: basic books.leveson, n.g. 1995. safeware: system safety and computers. reading, mass.: addisonwesley.leveson, n.g., j.d. reese, s. koga, l.d. pinnel, and s.d. sandys. 1997. òanalyzing requirements specifications for mode confusion errors,ó workshop on human error, safety,and system development, glasgow.lucas, peter. 2000. òpervasive information access and the rise of humaninformationinteraction.ó proceedings of acm chi ô00 conference on human factors in computingsystems. invited session, april.lutz, r.r. 1993. òanalyzing software requirements errors in safetycritical embeddedsystems.ó proceedings of the ieee international symposium on requirements engineering,january.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.146embedded, everywhereneisser, u. 1976. cognition and reality. san francisco, calif.: w.h. freeman and co.nielsen, j. 1994. òheuristic evaluation.ó usability inspection methods. j. nielsen and r.l.mack, eds. new york: john wiley & sons.nielsen, j., and r. molich. 1990. òheuristic evaluation of user interfaces.ó proceedings ofacm chi õ90 conference on human factors in computing systems.norman, d.a. 1998. the invisible computer. cambridge, mass.: mit press.roth, s.f., m.c. chuah, s. kerpedjiev, j.a. kolojejchick, and p. lucas. 1997. òtowards aninformation visualization workspace: combining multiple means of expression.óhumancomputer interaction journal 12(1 and 2):131185.sarter, n.d., and d. woods. 1995. òhow in the world did i ever get into that mode? modeerror and awareness in supervisory control.ó human factors (37) 519.schneider, fred b. 1993. òwhat good are models and what models are good.ó distributedsystems, s. mullender, ed. reading, mass.:addisonwesley.thibodeau, patrick. 2000. òôhugeõ privacy questions loom as wireless use grows.ócomputerworld, december 18.tognazzini, bruce. 1992. tog on interface. reading, mass.: addisonwesley.wiener, earl l., and renwick e. curry. 1980. òflightdeck automation: promises and problems.ó ergonomics 23(10):9951011.bibliographycard, s.k., t.p. moran, and a. newell. 1980. òcomputer textediting: an informationprocessing analysis of a routine cognitive skill.ó cognitive psychology 12:3274.card, s.k., t.p. moran, and a. newell. 1983. the psychology of humancomputer interaction. hillsdale, n.j.: lawrence erlbaum associates.fowler, m., and k. scott. 1997. uml distilled: applying the standard object modeling language. reading, mass.: addisonwesley.gray, w.d., b.e. john, and m.e. atwood. 1993. òproject ernestine: validating a gomsanalysis for predicting and explaining realworld task performance.ó humancomputer interaction 8(3):237309.kieras, d., and p.g. polson. 1985. òan approach to the formal analysis of user complexity.óinternational journal of manmachine studies 22:365394.minsky, m. 1974. òa framework for representing knowledge.ó mitai laboratory memo306. (shorter version in readings in cognitive science, allan collins and edward e.smith, eds., san mateo, calif.: morgankaufmann, 1992.)perrow, c. 1984. normal accidents: living with highrisk technology. new york: basicbooks.schank, r., and r. abelson, 1977. scripts, plans, goals and understanding. hillsdale, n.j.:erlbaum associates.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.1475models of computationas discussed in chapter 2, advances in circuit design, packaging,power management, and networking (especially wireless networking) provide the components needed to construct large networked systems of embedded computers (emnets) for a wide range ofapplications. the opportunities are, in fact, overwhelming, because thesecomponents will be incorporated into systems of increasing complexityon which society will depend in unprecedented ways. the effort neededto design systems so that they can be maintained, configured, and trustedwill be substantial. if emnets are to be designed in a principled wayrather than being assembled using techniques determined on a casebycase basis and specialized to the system being built, computational modelswill be needed to provide a conceptual framework in which the designscan be created, thought about, and tested.designers of complex systems use a range of conceptual models tohelp them construct and reason about systems. these conceptual modelsare built out of a set of abstractions that hide those aspects of the systemthat are considered to be either irrelevant or sufficiently unimportant. bynot being part of the model, these irrelevant or unimportant aspects neednot be thought about in the design of the system, and a variety of ways ofimplementing the abstractions they correspond to can be used when constructing the system. thus, the right computational model will simplifythe system as well as allow different implementations of the design. further, the computational model provides the designer with the conceptualmechanisms that allow trading off one aspect of a design against otheraspects. when given the appropriate abstractions, the designer of a sysembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.148embedded, everywheretem can decide to maximize certain features of the system at the cost ofothers, or decide to design a system that trades functionality in one areafor functionality of some other part of the system.the adequacy of a computational model is determined by two measures. the first measure is the suitability of the abstractions that havebeen chosen: they should allow those aspects that are important to thesystem to be represented in the model and not require the designer tothink about those aspects of the system that are not important. the secondmeasure of adequacy is the implementability of the computational modelon the environment it is meant to encompass. a model may incorporateabstractions that make the design of a system easy, but that is no help ifthe abstractions cannot be implemented in the target technology of thesystem. on the other hand, a set of abstractions might be straightforwardto implement but not allow the designer to focus on the properties thatare needed, because the abstractions do not simplify the system enough tomake the design tractable, or they might simplify it in the wrong way,making it impossible to attain some important aspect of the design.computational models are not required to build working systems.indeed, since one of the questions that needs to be answered in evaluatinga computational model is whether it is possible to implement the abstractions of the model, some systems must be built before a model is completely fleshed out and fully validated. in particular, functioning emnetshave been and will continue to be built without complete computationalmodels for them. however, without such models, these systems must bebuilt in an ad hoc fashion, and problems that are not addressed by theexisting models must be addressed while the system is being constructed.these problems need to be solved anew by each system implementation,making the process more costly and more time consuming. in short,coherent, wellthoughtout computational models will eliminate theseproblems and will facilitate analysis of systems (for example, to ensuretrustworthiness) as they evolve over time.a number of existing computational models might be applicable toemnets. because these systems are built with multiple processors usedfor a particular task, models of parallel computation could be extended tothem. emnets also share characteristics with storage area networks anddistributed databases, so models that have been used in those arenascould also provide insights. however, the computational model mostoften used in thinking about an emnet treats it as a distributed system,focusing on the interaction of computation and communications. in distributed systems, these models describe both how the various processorscarry out the computation and how they communicate with one another.11this discussion intentionally avoids using the word òprocessó because it is possible thatthe units of computing are parallel, and a process is typically assumed to be sequential.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation149because all computational models are really contractsñthat is, particular abstractions can be used given that they can be adequately implemented and particular functionality can be reflected in the abstractionsñit is important to examine the models when the problem domain, theproperties that the system needs to maintain, or the hardware configuration changes. all of these changes come into play with the design ofemnets. hence, it is important to ask the following questions:¥what abstractions used in traditional computational models mightbe applied to emnets, and are those abstractions rich enough to allow amodel that is sufficient for the properties that are needed in emnets?¥are there new abstractions that must be created, either in additionto or replacing those of a traditional computational model, when computational models for emnets are built?¥is it possible, given the abstractions that can form a coherent andadequate computational model for emnets, to implement those abstractions in the technology that will be used for emnets?this chapter examines these and other key modeling issues. the firstsection provides a primer in models of computation. the second sectionexamines the models of computation already developed and in use fordescribing distributed computing systems. the third section identifiesways emnets might strain or require extensions in existing models anddescribes potentially fruitful avenues of inquiry that could lead to thedevelopment of new or enhanced models appropriate to these systems.the last section suggests an overall approach to pursuing this type ofresearch.what are models of computation?existing computational models function at many different levels ofabstraction; often, highlevel abstractions build on simpler ones. theabstractions can involve data, computation, and communication. themost familiar computing model is probably that of a sequential processor,which states that the output of the system can be modeled by a simplesequential execution of the instructions in the program. although almostall processors execute instructions in parallel to enhance performance,and some modern processors execute instructions out of order (see chapter 2), the computational model used by programmers assumes that theprocessors obey a set of constraints that allow this simple, sequentialcomputational model to be retained. computational models evolve over time, as abstractions are introduced to eliminate unnecessary details and clarify the important designembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.150embedded, everywherepoints of the systems being modeled. in the early days of computerscience, the data aspects of a computational model were thought of inlowlevel terms, such as bit strings or integers. such lowlevel abstractions were often tied to particular machine architectures, which used datawords of different sizes, and they were difficult to use in different environments or to reason about. this led initially to the notion of simple datatypes (for example, 8bit bytes and byte streams) and ultimately to theintroduction of the higherlevel data abstractions that are used today,such as abstract data types or objects.abstract data types, rather than focusing on the data structure implementation, model the data and operations at a higher level in terms of thedesired response. one way of implementing these abstract types isthrough objects, which represent information in terms of the operations(often called methods) that can be performed on that information andwhich associate with that information the code needed to manipulate it.thus, rather than representing a geometric point as a pair of integersindicating the x and y coordinates, an object representation would definemethods that returned the x and y coordinates and would allow the pointto be drawn or moved. how the object actually represents the information is left up to the implementation of the object (for example, it can usea pair of integers, polar coordinates, or some other scheme). such objectsallow functionally equivalent representations of information to be treatedas identical from the point of view of the user, allowing the user or ahigherlevel model to concern itself with the use of information ratherthan the representation of it.computational models for distributed computing have followed asimilar evolution. early models were concerned with the communicationof data from one cooperating computer to another. for example, theopen software foundationõs distributed computing environment (dce)remote procedure call (rpc) (zahn et al., 1990) system centered on describing data and communicating them from one machine to another, nomatter what the internal representation of that data might be. abstractdata types in the form of interfaces were introduced in the commonobject request broker architecture (corba) (object managementgroup, 1991), allowing definitions of the types of information that couldbe exchanged from machine to machine without reference to the way themachine represented or computed that information. objectbased systems, such as those in modula3 network object (birrell et al., 1994) or thejava remote method invocation (wollrath et al., 1996), allow objects andassociated methods to be communicated from one machine to another inthe system. these systems can be seen as extensions of the techniquesused on a single machine, adding the communication aspect to the modelfor the distributed system case.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation151such innovations represent important progress because they allow achange in the level of detail, from how bits or other groups of entities aremanaged, to behavior that can be depended on by the rest of the system.this shift enables a modular decomposition of functionality that is criticalfor keeping system complexity under control. thanks to these additionallayers of abstraction, reasoning about the system needs to take into account only the information supplied by the abstract data type or object,not how that information is represented in the underlying executionengine. this specification of what information is supplied (or required)acts as an interface, stating only what is necessary for the information andnot the incidental features of the particular representation of that information. as discussed previously, an increase in the level of abstraction ofthe interfaces on which the system relies also greatly reduces systemfragility, because a system can adapt and change some of the lowerlevelmechanisms while maintaining the higher abstractions needed for systemoperation.by supplying these abstractions, the computational model also limitswhat can be expressed within the computing model. each abstractionlimits the detail that is considered important in the model, simplifyingreasoning about the system at the price of limiting the vocabulary of thedesigner. when applying a computational model for one discipline, suchas distributed computing, to the domain of emnets, the overriding question is whether the tradeoff between abstraction and expressive powerhas been accomplished correctly. if not, the computational model willneed to be extended or replaced by one that gives the proper vocabularyto the designer of the systems in the new domain.whether or not a particular computing model can be implemented isoften determined by the set of presuppositions on which the model isbased. building an abstraction may require certain properties in the underlying system that are not explicitly part of the model. for example,one of the major differences between the distributed computing modelarticulated by the corba abstractions and the model articulated in javaremote method invocation is the latterõs ability to pass objects, includingtheir methods, from one participant in the network to another. this, inturn, is implementable because the system presupposes the existence ofthe java virtual machine on all members of the system, allowing bothbehavior and data to be passed in the distributed system. the corbasystem does not make this presupposition, so it can only allow the passing of behavior in very limited circumstances, since a general model ofmobile behavior, while useful, would be unimplementable.models of computation also allow the precise definition of notions ofresource complexity. in more conventional systems, this has often meanttime, space, and communications bandwidth. in emnets, tradeoffs beembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.152embedded, everywheretween energy, latency, memory, processing, bandwidth, and persistentstorage will be necessary. as algorithms are constructed to work withinthe computational models created for emnets, it will be necessary toevaluate them with respect to these various complexities and the tradeoffs between them.distributed computing models:current practicewhile there are several models for distributed computing, nearly allof them are based on one of two underlying abstractions: distributedobjects and distributed shared memory. both provide a basis for understanding computing systems in which elements are distributed across anetwork and, as such, can offer a starting point for thinking about emnets.other models can be built on top of these basic models, offering higherlevels of abstraction when necessary. these two models, however, forman expressive base that is carried through in the models built on top ofthem. if these basic models lack a way of expressing concepts that areneeded for thinking about emnets, models built on top of them will beunable to add the concepts at a higher level. if these basic models cannotbe implemented in the environment presented by emnets, it will not bepossible to implement computational models built on top of them. aswill be seen, both models have serious deficiencies when used as a basefor emnets.as interesting as the concepts used in building the traditional computational models of distributed systems are the concepts that have beenabstracted out of such models. the traditional model has concentrated onthe mechanisms for passing information from one network component toanother (rpc, message passing, shared memory). however, the traditional model has abstracted away notions such as communication timing,resource use, and memory requirements for the underlying system. theseare not important concepts in traditional distributed systems, since thosesystems assume that the entities that are connected by the network aresufficiently powerful computers, plugged into an adequate source of longterm power, with few limits in terms of the amount of memory availableor the ability to store persistent information. however, a number of theseconcepts that do not appear in traditional computational models of distributed systems are vital to the design and understanding of emnets. asimilar example has to do with the failure models that have been developed for distributed systems (schneider, 1993), which range over a variety of ways in which the communication between systems can fail buthave a simple model of failure in terms of the components of the systemthemselves. this simple model of failure may be inadequate for emnets,embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation153where there are likely to be large numbers of networked systems that mayfail (or turn themselves off) often.differences such as these call into question the use of traditional distributed computing models in the domain of emnets. at the very least, itseems clear that certain concepts that have been abstracted out of thecomputational model for other kinds of systems will need to be added toreach a model that is adequate for reasoning about emnets.2 the rest ofthis section elaborates on some of the assumptions made in traditionalmodels and explores why such assumptions may not be adequate foremnets.both distributed shared memory and distributed objects are based onattempts to abstract over many of the details for the communicationneeded in a distributed system. sometimes this is achieved by assumingthat a robust network is used in the system that can deliver information tothe desired destination. other systems may attempt to mask communication failures or reflect such failures to the next layer or even the application. the goal, in both cases, is to allow the system designer to concentrate on the way the system works without having to worry about thereliability of the underlying communication framework.in the distributed objects model, the entire system is composed ofobjects, or combinations of information and the functions or methodsused to manipulate and access that information. these objects can resideon different machines; in some of these systems, the objects can migrateduring the computation. in this model, objects are created with the knowledge of how to communicate with certain other objects (that is, they areprovided with references to these objects when they are created) or typesof objects (that is, they are provided with references to these objects as theresult of a method call), and they do so by calling the methods associatedwith those objects. when objects call the methods of other objects, theobject being called can be on either the same machine as the caller or on adifferent machine. the call mechanism abstracts away the details of thecommunication needed to make a remote call, thus simplifying the model.this means that in the implementation of the model, the call mechanismmust handle all the communication issues, such as dealing with an unreliable network by retrying the call as appropriate. some systems try tosupply a call mechanism that can deal with all forms of failed communication, but some forms of failure break this abstraction. other systemsattempt to reflect such failures to the caller, perhaps by an error messageindicating communication failure. however, in all of these systems the2in a similar fashion, trust in cyberspace (cstb, 1999) discussed the limitations of security models for networked computer systems.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.154embedded, everywhereassumption is that communication rarely fails and that the cost of communication is at worst the time it takes for the communication to takeplace.in the distributed shared memory model, individual computationunits do not communicate directly with one another. instead, an area ofmemory is provided to each unit and made to appear to be common to allunits. computation units use this area of shared memory to communicate indirectly, by calling methods of objects in this shared system state.a typical way of using this model is to make the objects in this systemstate very simple, so that their only methods are read and write; but themodel can also be applied to objects that allow any kind of method. notethat this technique does not require an actual area of physical memory tobe shared by all computation elements; rather it is an abstraction of apossible, more complex interconnection network that provides this illusion. as in the case of the distributed object model, the communicationmechanism must òdo the right thingó in the presence of network problems and failures and convey the right information to users when problems cannot be masked. the shared memory model attempts to present amodel to the programmer in which there is no communication, only theinvocation of methods on local (but shared) objects. with such a model,either the underlying system must be able to mask all communicationfailures from the participants or the computational model of sharedmemory must be compromised to allow information about such possiblefailures to be visible. implementing the model without accommodatingfailures requires a network that can be made as reliable as memory access,and again the cost of communication is represented as (at most) increasedlatency in the access to shared memory.other models can be and have been built on top of one of these twomodels. an example is the class of models built on the idea of a sharedwhiteboard, which can be seen as an extension of either the sharedmemory model or the distributed object model. in such systems, there isa single shared repository of information objects that is accessible to allparticipants in the distributed system, and communication involves writing information into such spaces and allowing it to be read out by someother member of the distributed system. the shared space can be viewedas shared memory with special access operations or as a special type ofdistributed object. in either case, the new model is a further abstractionon one of the more basic models. rather than adding new concepts to themodel, it builds new abstractions on the old models. lessons may also bedrawn from higherlevel parallel programming models, such as nesl,33for more information on nesl, see <http://www.cs.cmu.edu/~scandal/nesl.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation155bsp,4 and hpf,5 where a rich set of aggregate operations is provided tothe programmer and compiled down into code for the constituent nodesand components. however, with emnets the collection of nodes may beunstructured, constantly changing, and oriented toward real time. thisproblem is also related to database query processing, if one views the databeing collected from the pool of sensors as a finegrained distributeddatabase. this view is attractive, because data are identified by key,rather than by address. however, the model for emnets will not beworking with regular tables and records but with a changing collection ofdata streams, where aggregate query operations must be spread acrossmany tiny nodes and must be placed as close as possible to the data so asto minimize energyconsuming communication. a third and relatedviewpoint is that the emnets are an extremely finegrained tuple space,as in linda6 or javaspaces (freeman et al., 1999). lindalike systems canbe seen as a shared whiteboard in which a particular naming system isused that has been extended to deal with both communication and concurrency issues. many operation sequences take place in the tuple spaceconcurrently, with associative operations utilizing the inherent parallelism. a unique element of emnets is the opportunity to exploit redundancy in an adaptive fashion to manage density and power utilization.the hardware design community employs discreteevent concurrencymodels (as implemented primarily in verilog and vhdl) to design highlyreliable and understandable concurrent systems. synchronous models,which originated in the hardware community, are arguably one of themost powerful concurrency abstractions by virtue of their ability to handlecomplexity in understandable ways. these models have spread to software design, as embodied in such languages as esterel7 and lustre.8even within the culture of the software world, abstractions such as process networks, portbased objects, i/o automata, functional languages,rendezvousbased models (such as csp or ccs), and dataflow models allprovide abstractions for use in their particular problem domain. all of4for more information on bsp (the bulk synchronous parallel computing model), see<http://www.bspworldwide.org/>.5for more information on hpf (high performance fortran), see <http://www.crpc.rice.edu/hpff/>.6linda is a language for parallel programming in which communication occurs by inserting and retrieving tuples, collections of data referenced by a name, into a shared area. formore information, see the linda group at <http://www.cs.yale.edu/linda/linda.html>.7for more information on esterel, see <http://www.esterel.org/>.8for more information on lustre, see <http://wwwverimag.imag.fr/synchrone/lustreenglish.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.156embedded, everywherethese models, however, are built on top of either the rpc model or theshared object models, and similar limitations with respect to emnetsapply.new models for networked systems ofembedded computersemnets have many of the characteristics of traditional distributedcomputing systems, since they are collections of computing elements connected by networks attempting to perform some task in a cooperativefashion. however, emnets are made up of components that have characteristics very different from those that make up traditional distributedcomputing systems, components whose limitations make it difficult toimplement the standard abstractions of the traditional models. becauseof the way emnets will be used, the design tradeoffs made for thosesystems will often be very different from those made in the design ofstandard distributed systems, requiring the introduction of new conceptsand abstractions to allow thinking about appropriate balance.a computational model is useful only when the abstractions in themodel can be implemented in the technology for which the model isconstructed. a useful computational model must also allow the designerto reason about the characteristics of the system that are important. inemnets a number of characteristics are important that are not present inthe standard computational models for distributed systems and that makeit difficult to construct the abstractions common in computational modelsof distributed systems. these characteristics include the following:¥reasoning about time and location. since emnets will often interactwith the physical world in a way that satisfies realtime constraints, designers will require a model that has reified the notion of time and allowsmaking design tradeoffs concerning timely response. the tight couplingof emnets to the physical world allows those systems to make use ofnotions of location, colocation, and proximity that are not possible instandard computational models of distributed systems. because of thiscoupling, the functioning of emnets often depends on inputs or requiresoutputs that are not modeled by an exchange of information betweenparts of the distributed system. thus, a computational model in whichbehavior of the overall networked system is defined by the informationexchanged between the computing elements of the system cannot beimplemented in emnets tightly coupled to the physical world.¥resource limitations. the limited resourcesñin terms of the resources available on the computing elements themselves and of the ability of those elements to communicateñin an emnet will require a comembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation157putational model in which the use of those resources becomes part of themodel. notions such as memory limitations, energy conservation, andaccess to persistent storage cannot be abstracted away but must be anexplicit part of the design of emnets. a computational model that assumes an environment without such constraints will not be implementable in emnets.¥heterogeneity. emnets are built out of components that show ahigh degree of heterogeneity. some of the components will make use oftraditional computing elements with persistent storage and abundantenergy supplies and will be connected by wired networks with high reliability and bandwidth. other components will be built with specializedprocessors having limited processing power, will have limited or no persistent storage, will be connected using lowbandwidth wireless networking, and will have limited, selfcontained power supplies. a computational model that does not allow differentiating the kinds of nodes thatwill be used to construct these systems will not be able to conserve thelimited resources available to the lowestlevel members of the networknor will it be able to capitalize on the power of the most competent members of the system.¥nonexpert users. since emnets will often be operated by nonexpertor casual users who have only a superficial understanding of the technology, the failure of such systems will need to be communicated to thoseusers in ways that allow the failure to be understood and appropriatelyresponded to. the computational model will need to have a rich failuremodel, allowing designers to decide which of the failures can be dealtwith by the system and which will need to be reflected to the users.unless the various kinds of failures in such systems are part of the conceptual model, designing a system with such failure models will be difficult or impossible.¥many redundant components. the ability to produce large numbersof similar components cheaply will allow some emnets to introduce levels of redundancy and scope that are not possible with more conventionalcomputational models for distributed systems.¥long lifetimes. since emnets will often be designed for a lifetimethat exceeds the lifetime of any one of the components, the need to reasonand design around inprocess upgrades of the system requires a computational model unlike those used in more conventional distributed systems. in effect, this means that the already high degree of heterogeneityin these systems will also have a time element, with the componentschanging over time as well as from place to place within the particularsystem. this will require more than just the kinds of reconfiguration andadaptation talked about in chapter 3; it will also require a computationalembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.158embedded, everywheremodel in which the abilities of the various parts of the system can bequeried and reacted to within the software of the system.as has been emphasized throughout this report, no single aspectof emnets is unique to the emerging field. other systems have had realtime constraints. other systems have been built from small, resourcelimited components. and other systems have had to interact with thephysical world.9 all of these systems have been based on, or formed thebasis of, a computational model that has addressed some of the needs ofthe computational model for emnets. what makes developing the computational model for emnets unique is not any particular aspect of themodel, but the combination of large numbers of networked components,resource limitations on those components, duration of deployment, connection to the physical world, and richness of potential connectivity. themissioncritical and, sometimes, lifecritical nature of these systems makesa coherent computational model for these systems a high priority for theacademic and industrial research communities.in the next sections, the committee identifies areas in which the computational model can make use of information or needs to allow forreification if it is to account for the unique combination of features andrequirements presented by emnets. the computational models that arisefor emnets may not include all of the areas that are discussed, or theymay include features that are not included in the discussion. what follows are the features that appear at this point to be the most promising forenriching a computational model for emnets.models with resource constraintsan immediate challenge in creating a computational model adequatefor emnets is to determine the right level of data abstraction. as discussed above, existing distributed system computational models abstract9distributed control systems (discussed in chapter 3) have operated distributed infrastructures such as the electric grid, pipelines, and railroads that (1) are closely tied to thephysical world, (2) must cope with location, and (3) operate under time and resource constraints. however, in each of the above examples, their layout has been predetermined andtheir interaction with the physical world extremely prescribed. the physical coupling discussed in this report is of a much tighter nature (for example, chips embedded in everydayobjects with which the user has experience in interacting directly rather than with the computer system to which it is connected). in addition, the aforementioned systems are generally tethered (that is, connected directly to easily replenishable sources of power and tocommunications infrastructure) and do not have the power limitations under which manyemnets will have to operate.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation159away performance issues, both on a node and in the network, and areconcerned about the order of events but not their timing. this simplification is often useful but sometimes hides too much information. for example, one way of handling diversity in a system with a long lifetime is torun a virtual machine (vm) on each node. although this provides anenvironment in which code can run on any node, it completely preventsthe application from determining the available resources of that node.one of the critical problems is to find some new, lowlevel models thatextend the vm notion to allow designers, and even applications, to reasonabout resources. the difficulty is how to accomplish this while maintaining a general framework that is simple enough to be useful. if applications need to select an algorithm given the current resource constraints,determining which algorithm to run should not consume more resourcesthan are saved by the algorithm selection.resource constraints also affect issues such as data abstraction. dataabstraction will continue to be important for emnets, as will the groupingof abstractions into type hierarchies to allow families of related types ofobjects and the use of various design patterns to hide implementationdetails. such abstractions will be needed to hide the particular types ofcomputing elements used in emnets (which promise to change radicallyand rapidly over the foreseeable future) while still allowing reuse of computational models, system designs, and (in some cases) software. it maybe necessary to redefine certain data abstractions to give applications inthis new domain access to the additional data they need to carry out theirfunctions. the abstractions may need to provide ways for higher levels tonegotiate different qualities of service (for example, time to carry outspecific methods on this object at this time) or performance tradeoffs (forexample, speed of communication versus resolution of data provided).memory constraints can also drive work on finding simpler ways ofimplementing these data abstractions.resource constraints in the network also will stretch current computational models. in the two common distributed system models, communication is abstracted almost completely out of the problem. althoughthis greatly simplifies reasoning about the system, it seems unlikely thatthese models will be rich enough to support emnets. both models buysimplicity at the cost of considerable complexity in the underlying system; it is not clear that this tradeoff will be correct for the small components and subsystems that will constitute emnets. more troubling thanthe need for richer highlevel models is the possibility that the lowlevelmodels for the different communication layers will need to change, too, toreflect the resource constraints and poor link reliability of wireless nodes.the ways that networks are formed, messages routed, and participantsdescribed have evolved for networks of stable, stationary computationalembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.160embedded, everywhereelements. researchers need to explore whether the networking layers onwhich these abstractions are built are correct for emnets. if not, researchers need to explore how these models can be extended to allow additionalinformation to be available for the communication layers, or available in asimpler form for the application, without making the model so complexthat it is no longer useful.models dealing with failuresto design a reliable system, the designer needs a model that includesthe types of failure that the system can experience, so that the design canrespond to those failures. some failures can be handled by the systemitself; other failures can only be dealt with by the application, and stillothers will need to be reflected to the user. failures may compromisesecurity, safety, and/or reliability. standard formal models of distributedcomputing identify failures of the components (such as crash or failstopfailures); failures in the communication infrastructure; and byzantine failures, in which a component can act in random fashion (including actinglike a nonfailed component that sends incorrect information). actualsystems rarely deal with all of these failure models but vary by whichfailures they try to handle and which are exposed to the application.examples of such failure models are provided in box 5.1. however, thesemodels were developed based on the assumption that a component thatfails cannot be replaced, and that failure is generally rare or limited inscope. in the case of emnets, in which the components are low cost andlimited in their resources and functionality, different forms of failure mayneed to be accounted for within the system. a component may fail for afinite period of time, for example, shutting itself down to conserve energy. a network may fail because of limits on bandwidth, allowing someinformation to be passed from component to component but not allowingthe throughput needed for the propagation of all relevant information.these types of failures may require a richer failure model than has typically been provided up to now.responses to such failures may also follow an unusual path inemnets. whereas a component failure in a standard distributed systemmight require failover to some replicated component or the election of anew leader in a master/slave replication, such a failure in an emnetmight require only that information be obtained from a different component of the system. in an emnet that has large numbers of nodes gathering information, the failure of some nodes might be handled by estimationtechniques using the information gathered from the remaining nodes.(this has obvious implications for the reliability and survivability of thesesystems.) similarly, a network failure may require finding a differentembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation161box 5.1failure modelsfailure models can have a significant effect on the overall computationalmodel for a system. the introduction of a failure type into a failure model maymake the building of an application more complex than it would be with a lesscomplete model, but the resulting application may be more reliable because it cansurvive failures that are not part of the simpler model. these differences can beillustrated by comparing systems with different types of failure models.as an example of the simpler model, the object management groupõs common object request broker architecture (corba) includes a remote procedurecall (rpc) system in which communication failure was not originally part of thecomputational model. calls could be made from objects on one machine to objectson a different machine, and it was assumed that the communication infrastructurewould ensure that the call would be made and, if expected, a value returned. inlater versions of the system, the failure model was enhanced by introducing thenotion of an exception that would be thrown when the communication failed. theprogrammer using the system was not required to handle this exception; if anexception was thrown and no part of the program receiving the exception wasexplicitly designed to deal with the communication failure, then the client programwould simply fail.corba can be contrasted with the model found in the java remote methodinvocation (java rmi) system. the rmi is also an rpcstyle system, allowing anobject on one machine to make calls to objects on a different machine. however,the rmi system requires that any method that can be implemented as a remotecall be declared as possibly throwing a special exception that indicates a communication failure. further, this exception must be handled by the calling code; ifthere is no exception handler, then the calling program will not compile. how theexception is handled will be application specific. in some cases, the client maysimply shut itself down. in other cases, the client may try to find an equivalentservice provider or roll back some internal state or contact some administrator todetermine the cause of the communication failure. thus, the notion of communication failure is part of the rmi computational model in a way it is not in the corbamodel.as a result, programs written using rmi are somewhat more complex thanthose using corba in the sense that rmi programs must contain code to dealwith communication failures, whereas programs with similar functionality writtenusing the corba system need not. the rmi programs containing this extra codeare also more robust, in the sense that they will survive failures in a network thatwould cause termination in the equivalent corbabased program.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.162embedded, everywhereneighbor to use as a pathway for the information (consider, for example,communications routing in the internet.) the capability of the overallsystem to adapt to failure rather than to simply replace the failed component with an equivalent offers a new route to failure recovery that cannotbe taken in more traditional systems but can be exploited in the circumstances offered in emnets. this possibility opens up a number of interesting data modeling questions for emnets, as discussed in the nextsection.new data modelsthe kinds of systems that will be built with emnets present a numberof programming model problems. while these problems are not entirelynew, they arise in a unique environment that makes traditional solutionsto the problems difficult or impossible to use.a key question is how to model the information gathered by anemnet. because many of the components are assumed to be unreliable,some will inevitably fail, and when they do, other parts of the systemmust be able to take over critical functions or compensate for the failure insome other fashion. in addition, if the components recover or are replaced, they need to continue doing what they were doing before, whichmay well include knowing some of the information gathered over time.all of these requirements imply a need for persistent data. furthermore,the ability to have one component take over for another argues for apersistent state that is not stored at the component. one promising approach would be to model the system as if components were largelystateless, with a robust storage device in the network. although a directimplementation of this approach would lead to a single point of failureand high cost, it is possible to distribute this store among the elementsthat maintain this abstraction and can tolerate failures in the nodes andnetworks. the computational model presented in such a system has atleast two levels of memory. the first, which is not persistent but which iscommon at the leaves of the network, requires programming techniquesthat guard against the loss of information. the second, found in theinterior of the network, stores the information in a persistent fashion.one of the interesting programming questions in such a system is howmuch processing should take place at the leaf nodes of the system. thecomponents will be able to do some computation, and the more theamount of raw data available to the sensors can be reduced before sending it to the rest of the network, the more bandwidth is conserved. however, such computation means that power is being used at the edges ofthe network and that failures may result in the loss of the data. thesesorts of tradeoffs can only be made in a computational model that reflectsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation163the two levels of memory and allows reasoning about the costs and benefits of the design choices in such a system. whether these methods areappropriate for emnets is an open research question. research is alsoneeded to determine if this information must be handled by explicit programming or if it can be made automatic, and to learn what requirementsand costs are associated with automated backup replication and archiving.explicit programming to generate a consistent, persistent memory ismade more difficult because of issues having to do with concurrency andfailures. when information is spread over a set of machines that can failindependently and are connected by a network that also can fail, it isdifficult to coordinate changes in that information to ensure global consistency. further, as different parts of the system manipulate the sameinformation, it is possible that changes are made at inopportune times,giving inconsistent views of the system. a computational model traditionally used to deal with these issues involves the notion of a transaction.in a transactional model, a coordination convention is introduced to ensure that in all but the most extreme of failure conditions, either all theoperations in the transaction are completed or none of them is. it is notpossible for some to be completed while others fail. further, the transactional model introduces concurrency controls that ensure that each viewof the system is consistent and that all parts of the system will viewchanges as happening in the same sequence. in systems supporting thismodel, one need not worry about what happens if a failure occurs halfway through the operation; in addition, transactions ensure that the intermediate state of the atomic collection cannot be seen by other operationsin the system.the transactional model is an example of a computational abstractionthat makes the job of the application programmer much easier, at theprice of increasing the complexity of the underlying system. the transactional model of memory is very powerful because it simplifies reasoningabout many types of interactions; however, implementing a transactionalmodel of memory is quite complex and may not be possible on all of thevarious kinds of nodes found in emnets. these implementation issuesmay make a pure transactional memory model too expensive to be usedin the design of emnets, and it might be possible to create a compromisemodel for these systems. some weaker notion, with fewer guarantees butalso without some of the implementation problems that accompany thetransactions mentioned above, might be developed both to maintain consistency in the persistent state and to accomplish some of the applicationtasks.the transactional model is also an example of how a single abstraction can be introduced into a computational model to greatly facilitate thedesign of reliable systems. currently, there is no such unifying and simembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.164embedded, everywhereplifying abstraction in the computational model for emnets, and one issorely needed. it might be some variation of the transaction abstraction,or it might be a completely different computational construction. theonly way to develop it is to encourage research in a number of differentdirections to find one that bears fruit.the twolevel model of memory leads naturally to a shared memorymodel of communication, described earlier. but to make a big, persistentstore work flexibly, methods of naming the contained objects are needed.one particularly interesting research question deals with the intentionalnaming of objectsñproviding a name for an object that is related to itsfunction or other attributes. this naming structure might have significantadvantages in systems with high redundancy levels, in which similardata are collected by many different devices. isolating information sothat not all of the information obtained by every component is availableto every other component may also require hierarchical or partitionedmemory models, in which the placement of information determines whichcomponents can access it.the programming models used by these systems may depart fromthe familiar in radical ways, or they may take familiar programming notions and apply them in ways that they have not been applied before.many emnets are highly event and datacentric. especially in sensornetworks, users may be more interested in receiving information about aparticular event that has been detected (for example, a chemical concentration exceeding a particular threshold) or in receiving a particular set ofdata (for example, the chemical concentration in a particular geographicalregion) than in receiving information from a particular node (for example,the chemical concentration reported by sensor number 1234). this mayalso be true in a smart space in which users wish to send data to thenearest network element, to an element with particular characteristics (forexample, highbandwidth communications capability), or to the nearestelement to which they have a direct line of sight. this sort of capabilitybecomes even more important in dynamic systems in which nodes, resources, obstacles, and event triggers themselves move around in unpredictable ways. it implies that many emnets will need to be designed witha focus on naming and operations on data elements instead of namingand operations on node identities. eventdriven programming is common in areas like user interfaces, where the program is driven by eventsgenerated by the user. these techniques, which share the quality of reacting to occurrences in the physical world, are generally not applied in thecontext of a network, but may provide a fertile area of information exchange between practitioners of different fields of computer science andother disciplines.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation165models of trusttrust issues enter into the computational model of emnets for manyreasons (see chapter 4), including the likelihood of changes in the set ofentities that make up those systems and the likelihood that such systemswill make use of mobile code. both likelihoods may require adding trustnotions to a model for emnets that are traditionally outside of conventional computational models.in the case of mobile code, it will often be the case that the environment into which code is moved will need to establish a trust relationshipwith that code. this cannot be done by some interaction with the code,since by the time such an interaction could happen the imported code willhave been loaded into the host environment and will probably have hadaccess to at least one thread of control. waiting until this point to establish a trust relationship with the imported code is dangerous, since thecode could already have damaged the host system. the mechanisms forestablishing trust may in fact reside in the underlying system and willonly be reflected in the computational model as additional failures thatcan occur because of security. however, the computational model mayneed to be enriched beyond that to allow setting various limits on thepower of imported code. what will be required for trusting mobile codeis not clear; what is clear is that research into the establishment of suchtrust relationships is needed.beyond the trusting of mobile code is the reestablishment of trustwhen members of the system are replaced, repaired, or upgraded. thediscussions of reconfiguration in chapter 3 only go as far as to allow theestablishment of communication and cooperation between such nodes;they are essentially questions of how we can make such nodes worktogether. the questions surrounding the reestablishment of a trust relationship are fundamentally different in that they involve the set of circumstances under which such working together is not allowed to occur.however, the decision whether or not to trust either new (mobile) code ornew elements of the emnet will need to be part of the computationalmodel.models for concurrencyemnets are inherently concurrent systems, that is, they are collections of entities that operate independently but attempt to cooperate on acommon task. there are no particularly good programming models forconcurrent programming; in fact, the general wisdom is to avoid the needfor concurrency whenever possible. concurrency in programs tends to beprogrammed directly. for example, an active object might begin with aembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.166embedded, everywheresingle sequence of instruction execution and as part of that execution,create other, independent sequences of instruction execution. thesewould occur either in another processor or on another machine, in a logically separate process scheduled by the operating system of a single machine, or in a separate thread of execution in the same process, scheduledby the underlying operating system or by some library. if these socalledthreads of execution are cooperating, they must do so by communicatingor sharing some information. access to the communication paths orshared information is generally coordinated explicitly by the programmer, using mechanisms such as locks and semaphores. however, thistype of explicit synchronization is a wellknown cause of bugs, the mostcommon of which involves a single thread assuming that a piece of sharedinformation cannot be changed over some period of time by any of theother threads of execution, even though no lock is held on the information.similar explicit approaches to concurrency control, such as shared jobqueues that allow coordinating work among the different threads of execution, are also limited in scale or prone to programmer error. systemsthat attempt to hide or deal with these issues have automatically beendesigned around small networks of very large machines, and it is not atall clear that the same principles apply to large networks of very smallmachines.of further concern, almost all existing ways of dealing (programmatically) with concurrency introduce the possibility of very large time delayswhen there is competition for a resource, a pattern that runs counter tothe need of emnets for predictable, realtime performance. given thatattachment to the real world is a requirement and that it entails knownperformance parameters, it follows that the usual ways of dealing withconcurrency are not applicable to emnets. an additional constraint inemnets is the need to support the model on very small system components (for example, 8bit processors with very limited programming andstorage).there are, however, methods that might be applied to concurrencywithin emnets. optimistic or waitfree algorithms may be applicable inthese systems. in addition, some of the techniques of control systemsñinwhich constant approximations are made of future states that are thencompared to the actual resultsñcan cut down the requirements for concurrent access to information. this is an open area of research both withinthe emnet community and within the larger programming community,and results from both communities should be studied for their applicability to the problems of concurrency in emnets.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation167models of locationas noted before, a defining characteristic of emnets is their connection not only to other computing systems but also to the physical world.because of this connection, there is a mapping from many of the membersof such a network to a particular location in threedimensional space,namely the location at which the system interacts with the world.10 thereare also spatial relationships among the various elements of the emnetsthemselves. by adding location information to the basic computationalmodel, it may be possible to invent new algorithms, techniques, or configurations that exploit this additional information to make advances inreliability, trust, or functionality. a number of locationbased conceptscould be of interest, including absolute location, proximity, relative distance, and relative motion. whether some or all of these are needed orrelevant is an open question that needs to be addressed. in addition, thelayers at which location should become part of the model, and the interfaces used to gain access to that information, need to be investigated.such an approach exploits the impression that many emnets are eventor datacentric: what matters is not the precise part of the emnet that isperforming some computation but rather the sensing of some occurrenceor the computing of some data by any member of the assemblage.traditional networked systems have tended to be closed in the sensethat interactions take place among members of the system, with little orno connection to the physical world (other than, perhaps, the users of thenetworked systems and the physical artifacts that are explicitlyñandonlyñpart of the system itself). because of this, such systems were oftenbased on topological principles that abstracted over the physical locationof network members and relied only on the connectedness relations between the members. by introducing into the equation the physical location of the elements of emnets, one can expand the vocabulary for network relationships to include concepts such as proximity, distance, and ahost of geometric relationships. this vocabulary (and the informationthat it allows one to describe) can be used to produce new algorithms thatcan minimize energy use or maximize computing power in a particulararea. it also allows the naming of areas where information is to be gath10in this discussion, emnets should be distinguished from factory automation systems(for example, systems used to fabricate parts and convey work in progress from one pieceof automated equipment to another or those used to automatically retrieve inventory). in afactory, the physical world is a highly constrained, wellunderstood environment in whichthe interaction is very prescribed (for example, retrieve item y from prespecified locationx.) in emnets, components will be physically coupled to elements of their environmentthat are not as highly prescribed in their function and/or location (for example, a button ona piece of clothing or a freefloating sensor in an urban sewer system.)embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.168embedded, everywhereered rather than the nodes in the network that gather that information,and ultimately the naming of the information itself rather than the sensors that receive that information.11similarly, nodes often use information about their location in threedimensional space to determine their action (for example, which sensorshould be tasked to monitor a particular geographical region or which isthe nearest switch that should operate a particular piece of networkedaudiovisual equipment). traditional computing systems have not neededsuch information, so support for geolocation information is relativelyweak. robotics is the best example of a computer science discipline thathas faced this problem, and work in this field demonstrates the difficultyof the task (see chapter 3 for a discussion of distributed robotics). particular technological approaches for supporting geolocation are discussedin chapter 2; however, even given the existence of geolocation systems,additional effort is needed to define and refine the abstractions used byapplication and system developers as they work with geolocation.conducting research on models and abstractionscomputational models are not developed in a vacuum. the computational model for emnets will evolve as applications of the technologyare developed. full applications need not be completed before this activity can move forward, although enough of a prototype needs to be developed that new models can be tried, measured, and evaluated for theirrelevance and completeness in the new set of environments and with thenew set of assumptions that emnets present. as experience in buildingthese applications is gained, designers will discover which abstractionsare useful, which ones hide information that needs to be visible, and whattypes of connections between the abstractions will allow people to modeland reason about the types of emnets that they want to build.research in this area will require a delicate balance between, on theone hand, application development and underlying system constructionand, on the other, the building of the computational model. althoughsome driving applications will be needed to test the work, the goal needs11this calls into question the general naming or description schemes used in distributedsystems, in which the base naming identifies members of the network and, relative to that,other names or descriptions can be used to identify events that occur on that machine ordata stored at that machine. research into identification schemes that are based on directlyidentifying the events or information may insulate emnets from changes in the particularmembers of the network that happen to be sensing the event or gathering the information.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation169to be the construction of underlying systems that can be used with multiple applications. the underlying system should be the instantiation of acomputational model that presents the right set of abstractions for reasoning about the overall system infrastructure as well as the particular application. thus, the building of the application should not be viewed as theend goal of the research but rather as a means for identifying those partsof the model and infrastructure that can be applied more broadly than theapplication at hand.as these models are built, runtime environments based on them canalso be developed, and this, in turn, will make it easier to develop applications using the models. the development of environments based onthe models will allow the application programmers to develop systemsbased on the models more quickly and researchers to evaluate and modifyboth the models and the environments more quickly. this scenario formsa positive feedback loop in which runtime environments built to reflectmodels allow more rapid application development, which in turn allowsmore complete evaluation of the models. such a cycle can lead to rapidevolution of the model and the runtime environment in response to therapid development of applications; however, the initial stages of buildingthis loop will be lengthy relative to the later stages and seemingly chaoticas well, as basic assumptions are tested and computational models are insignificant flux.this is not to say that the initial inquiries into computational modelsand their associated runtime environments will be completely unstructured. there are a number of areas in which it seems clear even at thisearly stage that fruitful investigation can be undertaken. one such area ofinvestigation is the network model itself. during the past 20 years, bothindustry and academic researchers have worked with a computationalmodel exemplified by the open systems interconnection (osi) sevenlayer reference model. this model describes a set of abstractions definedby the interface presented by each of the layers, giving a modular structure to the model of the network. in addition, the model requires thateach layer obtain information only from the layer immediately below itand provide information only to the layer immediately above it. the endresult is a set of models of a network, each providing more functionality(but at a higher cost) than the layer below. changes in any layer areisolated in that layer, because each layer is defined by an interface, whichby remaining the same, insulates the layer above from changes. (see box5.2 for more details on the osi model.) clearly, the osi sevenlayermodel will be unsatisfactory for emnets, which seem to require something more lightweight. such networks may need different abstractionsat various layers, requiring that different interfaces be defined for themodular constructs. the strict layering of the osi model may hide inforembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.170embedded, everywherebox 5.2the open systems interconnection modelthe open systems interconnection (osi) sevenlayer model is a standardtaxonomic description of networks and a universal reference model for communication protocols. the model is promoted by the international organization forstandardization, a worldwide federation of national standards bodies from some100 countries. the seven layers, together with some examples of the types ofnetwork entities that occupy each layer, are as follows (top to bottom):7. application (network file system (nfs), file transfer protocol (ftp), hypertext transfer protocol (http));6. presentation (extensible markup language (xml), ascii, java serialization, com);5. session (sun remote procedure call (rpc), dce rpc, internet interorbprotocol (iiop), remote method invocation (rmi));4. transport (transmission control protocol (tcp), user datagram protocol(udp));3. network (internet protocol (ip));2. data link (wire formats for messages); and1. physical (wires, signaling).the standard world of computers on a network is largely homogeneous atlevels 3 and 4, permitting great (and largely transparent) diversity at layers 1 and 2and great diversity at the higher levels. this is effectively a computational model ofthe network, specifying (at each layer) the interface to the information at that layer,the information that has to be provided to the next layer up, and what guaranteesare made by an entity at a particular layer. each layer acts as an abstraction overthe actual workings of the network, with each piece of functionality built on morebasic layers. those underlying layers can change without affecting the upperlayers because they are defined by strong interfaces, which do not change fromimplementation to implementation.it seems unlikely that this set of abstractions will suffice for emnets. forexample, an emnet application might need access to the physical layer for information about power in order to save energy or to the network layer in order to dosome creative routing. as the chapter points out, new models and abstractions areneeded to handle the unique constraints and challenges that emnets present.mation needed by emnets (for example, information about specific nodesor components); accordingly, some relaxation of the layering may be afruitful area for research.it should be noted that once models of computation are defined andprototypes have been implemented, significant work will be needed inthe design and analysis of algorithms that work within the new modelsembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.models of computation171for emnets. algorithms that optimize for certain resources, for example,and give nearoptimal tradeoffs between the various relevant resourceswill be very important. designing and implementing algorithms that canboth solve the problems emnets will pose and be implementable withinthe constrained environment that emnets will be operating in are likelyto be a significant challenge. in addition, the question of how the qualityof service might degrade in the presence of partial information (a likelyscenario since it may not always be possible, owing to bandwidth orresource constraints, to have all the information) may well need to beanswered. current work on this sort of question deals with timespacetradeoffs for computation and tradeoffs between the quality of the solution and the precision of the input data, for example. emnets present yetmore kinds of tradeoffs that will need to be addressed.finally, the examples discussed in this chapter share a characteristicñeach identifies an assumption of the current computing model fornetworks that will not hold in the coming world of emnets and proposesan alternative to that computing model based on a more reasonable assumption. as people attempt to build applications of emnets, it will beimportant for them to identify suspicious assumptions or counterproductive abstractions in the current computing model, and to think of alternatives that can be built into the infrastructure for the application. manymore assumptions and abstractions will be identified than have been listedhere. funding agencies should watch for patterns in which researchersidentify a doubtful assumption or abstraction, replace it with another thatseems more useful in the context of the application, and determine if thenew assumption or abstraction can be used in other applications.referencesbirrell, andrew, g. nelson, s. owicki, and e. wobber. 1994. network objects. digitalequipment corporation systems research center technical report 115.computer science and telecommunications board (cstb), national research council.1999. trust in cyberspace. washington, d.c.: national academy press.freeman, eric , susanne hupfer, and ken arnold. 1999. javaspaces principles, patterns, andpractice. reading, mass.: addisonwesley.object management group. 1991. common object request broker: architecture and specification. omg document no. 91.12.1.schneider, f.b. 1993. òwhat good are models and what models are good?ó distributedsystems, 2nd ed., s.j. mullender, ed. reading, mass.: addisonwesley.wollrath, a., r. riggs, and j. waldo. 1996. òa distributed object model for the java(tm)system.ó computing systems 9(4):265290.zahn, l., t. dineen, p. leach, e. martin, n. mishkin, j. pato, and g. wyant. 1990. networkcomputing architecture. englewood cliffs, n.j.: prenticehall.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.1726conclusions and recommendations:an agenda for researchemnets will be embedded everywhere, from automotive instrumentation to precision agriculture to battlefield surveillance. they raisefundamental research challenges in part because they will be performing critical functions and also because they are inherently distributedand tightly coupled to the physical world through sensors and actuators.moreover, while they are rich in the numbers of elements, they are at thesame time highly resource constrained in the capability of the individualelements. this chapter builds on the findings and discussions in chapters 2 to 5 to specify particular research projects and processes that will benecessary to realize the vision articulated throughout this report.as outlined in this report, emnets present a number of research challenges that need to be addressed. an important message for the researchenterprise is that new approaches to the study of systems rather thancomponents must be developed as a deeper understanding of the emergent properties of many interconnected elements is gained. to attain thisgoal, research will need to become more interdisciplinary than ever before as practitioners learn to design, deploy, andñhopefullyñtrust theselargescale information systems. the need to approach the challengespresented by emnets from a systemsoriented, interdisciplinary perspective stands out among the many technological problems delineated elsewhere in this report. failure to meet this need would be the most seriousimpediment to realizing the full potential of emnets in society.1,21a thorough discussion of the systems imperative, of the growing argument for interdisciplinary research, and of related issues for the broader it community can be found inmaking it better (cstb, 2000).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations173the growing complexity of information technology systems will beaccentuated by the evolution of emnets. this complexity arises not onlyfrom the large number of components involved but also from the lack ofdeterminism and the continual evolution such systems will undergo. effort on the part of the whole community (industry and academia, as wellas funding agencies) is necessary. while there are specific emnet applications emerging from industry, they do not encompass the kinds of scalable, robust, physically coupled emnets that are discussed throughoutthis report. in the absence of appropriate funding, issues such as adaptiveselfconfiguration, predictability, and computational models will not beaddressed in ways that will enable comprehensive understanding. thislack of understanding will result in a technology that is both prohibitivelyexpensive and prohibitively brittle and will preclude the widespreadadoption of emnets as envisioned here.the internet has provided one of the first real examples of a largescale, heterogeneous networked system. it serves as an excellent modelfor observation and provides some early indicators of the issues arisingfrom the widespread deployment of emnets that will need to be addressed.3the internet consists of millions of loosely interconnected componentsthat generate communications traffic independently of one another. therehas been standardization in the middle levels of communication protocols, but a wide variety of physical interconnections, from optical broadband to wireless, is supported. however, from the casual userõs perspective, the degree of interoperability has essentially been limited to whatcan be done through a web browser. for the most part, the currency ofthe internet has been in the realm of information. the connections between todayõs various information services are only now starting to evolveinto multilayered and richly connected ensembles.4 connections to thephysical world have been limited to basic sensors (for example, camerasand weather sensors) and very few actuators (for example, camera motorsand home remote control).as noted throughout this report, emnets will build on the internet2emnets provide an excellent illustration of how computer science can benefit from interactions with sister engineering fields, which have long addressed conventional embedded systems.3for a discussion of internetspecific issues, see the cstb report the internetõs coming ofage (cstb, 2001).4the automated shopping agents that query multiple vendors for the best price on arequested item exemplify this. they integrate information in different formats to yield aneasy to understand comparison. automatic purchasing systems are now being built on topof these basic services to trigger automatic purchases that will keep inventory at the specified levels.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.174embedded, everywhereexperience (itself a product of significant federal research investment) butwill also extend it in new directions. the physical world will be coupledto the information space. sensors and actuators will be spread throughout the everyday environment. peopleõs activities will be recorded andaffected by computing systems in virtually all spheres of life. the heterogeneity of the devices that will be interconnected will increase dramatically. from a world of pcs and servers, it will move to smart dust,5swallowable health monitors, and automated buildings. this move willrequire a much deeper understanding of how to build into emnets thechallenging properties of scalability and robustness.in this chapter, several overarching research themes are describedthat draw on the discussions developed throughout the report. following the description of these themes is a discussion of what will be required of the industrial and academic research enterprises in order tomake progress on the substantive research recommendations made inthis chapter and throughout the report. in addition, specific recommendations are made to federal funding agencies that, if followed, wouldfacilitate progress in this area.an emnetspecific research agendathe committee has found eight key areas in which concerted researchefforts are needed: predictability and manageability; adaptive selfconfiguration; monitoring and system health; computational models; network geometry; interoperability; the integration of technical, social, ethical, and public policy issues; and enabling technologies. this researchwill need to be very broad and very deep and so is unlikely to be achievedthrough industry efforts alone. key to developing the research in theseareas is the parallel pursuit of the major thrusts described in this report(see chapters 2 to 5) and the integration of research across the varioustopics as necessary. achieving progress in such a research agenda willrequire forwardthinking, visionary leadership and the willingness to invest in longterm research programs without requiring premature checkpoints or demonstrations and without a priori agreements on specificarchitecture, so as to allow room for reasonable exploration of the designspace.this section draws on the analysis contained in earlier chapters of thereport to identify eight areas that should be part of such a research agenda.5the goal of the darpafunded smart dust project at the university of california atberkeley is to integrate sensor and communication systems into a package that is roughlythe size of a cubic millimeter.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations175these areas fall into three categories: (1) research that is needed to buildrobust and scalable emnets, (2) research on social, ethical, and policyissues that result from the deployment of emnets; and (3) research oncomponent technologies that is unlikely to be addressed by the general itresearch community.it should be noted that networking is an implicit theme pervadingmost of these areas and so does not stand apart as a separate researchissue. the success of networked systems of embedded computers willdepend heavily on the networking research community and work goingon there, including the work highlighted in chapters 2 and 3. progress inemnets is not possible without progress in networking. the researchissues raised by emnets constitute a theme around which new networking research programs can be structured. similarly, issues of usability andmanageability arise throughout this discussion. the human element incomplex, notwellunderstood systems is critical at all levels, includingdesign, programming, deployment, control, manipulation, and interaction. humancentered approaches must therefore be incorporated into allof the research areas discussed below.predictability and manageability: methodologies and mechanismsfor designing predictable, safe, reliable, manageable emnetsdesigning for predictability in emnets requires new methodologiesand design strategies that will support characterizable, understandable,and manageable systems. these systems need to allow for isolation ofsystems components and analysis of the interactions that take place withinan emnet that is exploiting massive amounts of interconnection. at thesame time, methodologies are needed for presenting system behavior(including behavior that emerges throughout the lifetime of the system)to end users and system managers; these methodologies must transmitthe correct information at the correct abstraction level. users of emnetsmay be experts at the task their computing system is helping them accomplish, but they should not need to know a lot about how the computingsystem is doing it. they need to be able to make certain basic inferencesabout what they can expect of their emnet in order to make good, safeuse of it.it is likely that emnets will radically alter the definition of a system.instead of simply designing all the individual components of a systemand their interactions specifically for a particular system function, peoplewill be fielding components that provide basic capabilities. a òsystemówill mean exploiting the capabilities of those basic components in a newway by marshalling the capabilities of what is already deployed, alteringembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.176embedded, everywheretheir function, or adding new elements. pieces of a system deployed forone purpose may be utilized for other purposes not originally planned.moreover, continually changing or adding new elements to the mixwill cause new, unintended behaviors to emerge. the internet is providing some early examples of this: when new services are deployed, theirincreasing use may cause congestion and a decline in service quality atsome points in the network. once the network is embedded everywhere,every new deployment will probably trigger adjustments and possibledetrimental effects on service only because it causes some contention forcommon scarce resources. such behavior should occur in an understandable and reasonably predictable fashion. if something has broken, oreven worse, is about to break,6 how should the emnet inform its users?emnets must have interfaces that let users who are not professionalsystem administrators wield them effectively, through normal as well asabnormal conditions such as partial system failures. sets of abstractionsshould be developed that have meaning within the computing systemitself yet still conform to usersõ conceptions of the tasks they need toaccomplish. emnets have the same human computer interface problemsas existing systems, exacerbated by the other, nontraditional aspects ofemnets, including users who are inexperienced with the intricacies ofemnets, realtime interactions with the physical world, longlived systems that build user trust at the same time as their internal safety marginsmay be decreasing, and enormous overall system complexity.adaptive selfconfiguration: techniques to allow adaptiveselfconfiguration of emnets to respond to volatile environmentalconditions and system resources in an ongoing dynamic balanceemnets will need to exhibit adaptive selfconfiguration in order to beviable. the massive numbers of elements, along with the resource constraints on individual elements and the environmental dynamics in whichthey will need to operate, combine to create a new and likely pervasiverequirement for adaptive systemwide behavior that is unparalleled except perhaps in natural systems. the number of elements, resource constraints, and dynamics imply that systems cannot rely on a priori systemdesign or manual adjustment. the system elements cannot simply be6if the system is obviously broken, users will know not to rely on it and will go abouttrying to get it repaired. if users do not know that all redundancy has been used up and thesystem is on the edge of disaster, they may believe that the system is as trustworthy as itever was and unwittingly take unwarranted risks.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations177configured to operate under worst case assumptions, because doing sowould make them orders of magnitude less efficient and, in many cases,unable to meet system lifetime requirements. moreover, emnets cannotbe dynamically configured centrally using global information becauseacquiring the global information consumes significant amounts of energyand is not scalable. further, some of the adaptation will need to be donein a very short time frame, one that requires that processing of input andaction be completed as quickly as possible to meet the realtime requirements of the application.the current state of the art with respect to adaptation and configuration is exemplified in internet protocols. these protocols are somewhatselfconfiguring and adaptive. however, they have not had to cope withintense input/output, environmental dynamics, and tight energy constraints as a primary design issue. emnets will require the developmentof new distributed algorithms and techniques for provable distributedcontrol. they will also require system models and characterizable behavior in order to support embedded systems with strict time constraints(latency, in particular). emnets will need to provide rich interfaces to theapplication designers as well. for example, a truly scalable sensor network must selfconfigure so that the correct collection of nodes (those thathave collected good signals from stimuli) collaborates in signal processing to detect and identify phenomena of interest inside the network. theparticular sets of nodes that should participate cannot be determined apriori. such a determination clearly depends not only on the nature of theapplication but alsoñand even more soñon the nature of the object(s)being monitored and the signals received by the nodes. emnets willrequire nodes and their system interactions to be designed so that applications can influence the parameters and rules according to which nodesadaptively selfconfigure.monitoring and system health: a complete conceptual frameworkto help achieve robust operation through selfmonitoring,continuous selftesting, and reporting of system health in the faceof extreme constraints on nodes and elements of the systemthe missionreadiness requirements of emnets will vary from oneemnet to another, but all will require a minimal amount of overall computational horsepower, a certain amount of interconnection bandwidthand latency, and some minimum amount of sensing and perhaps actuation. with current technology, this mission readiness will be evaluated byhaving the system perform periodic selfchecks on all of those dimensions, with some kind of overall health indicated to the system user oradministrator.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.178embedded, everywhereemnets will change over time both in the numbers and kinds of theircomponents and in the applications they are designed to perform. current notions of system health, which tend to be based on the health of theindividual components, do not extend to such systems, where no singlecomponent may be critical for the system to perform its intended functionas long as the system can adapt to the current conditions. how suchhealth, which is tied to the overall mission of the system rather than thefunction of the parts, can be defined and monitored by the system itselfwill be an important area of investigation. a critical challenge is that thissystem monitoring must be done in the face of resource constraints. forexample, pulling system health information out of the system may consume valuable, unreplenishable energy. just as the system may need toaggregate information about its function inside the network, it may needto aggregate information about its health.designing and constructing large systems of many heterogeneouscomponents is already an extremely complex task. the added constraintsof emnets make it even more so. it may be possible to turn to fields suchas economics, biology, and statistics for new tools to tackle this growingcomplexity.7 new approaches need to be developed for selfmonitoring,selftesting, reconfiguration, and adaptation, as discussed in chapters 3and 4. systems will have to be built with selfmonitoring and selfregulating devices. statistical approaches will be needed to properly detect situations requiring attention. immune systems will need to be developed tocounteract the unintended (or intended) effects of new deployments.because of the interactions with other requirements of the system, theconceptual framework for robust operation, adaptation, and selftestingcannot stand on its own. it must be part of a large conceptual model thattakes into account the other features, requirements, and restrictions of thesystem, as discussed in chapter 5. research needs to be done not only onhow to monitor and express this notion of system health, but also on thetradeoffs that are possible between these requirements and the otherrequirements of the system.computational models: new abstractions and computationalmodels for designing, analyzing, and describing the collectivebehavior and information organization of massive emnetssystems as complicated as emnets will present enormous challengesfor the analysis of behavior and performance. existing tools and concepts7various efforts to study complexity already reach out to a wide variety of disciplines.see, for example, the work of the santa fe institute at <http://www.santafe.edu/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations179are barely adequate for understanding simple multiprocessor systemswith four cpus. they are clearly inadequate for systems with manythousands of physically coupled, longlived, adaptable, selfconfiguring,interacting nodes. moreover, defining the right model to handle thesemany components is not sufficient; the model needs to ensure that it ispossible to reason about and understand the interactions of the variousparts of the model so that appropriate tradeoffs can be made, whennecessary, in the design of the entire system.in particular, in order to take better advantage of the many potentialuses and impacts of emnets, abstractions are needed for designing interactions with the physical world. sensors and actuators will often play akey role in such systems. moreover, new abstractions are needed fordesigning systems that make use of massive redundancy in order to dealwith the extraneous data and uncertainty of the physical world. unknown at this point is what building blocks will be used in emnet environments that will play the seminal role that transactions and remoteprocedure call (rpc) played in more traditional systems. defining appropriate data structures, process interactions, and apis will require a substantial research effort, one that iterates between experimentation, conceptdevelopment, and theory building.the development of new abstractions for reasoning about collectivebehavior will be one of the biggest contributions of emnets research (seechapter 5). both humans and the artifacts they design will require theseabstractions to reason about and adapt to the new situations that willemerge when interesting new mixes of devices and services are created.abstraction is one of the most powerful tools that mathematics and engineering have brought to the scientific enterprise. each technological erahas associated key abstractions. new eras bring new abstractions andvice versa. it is now time, as the era of emnets commences, to begin thedevelopment of its principal abstractions.network geometry: ways to support and incorporate networkgeometry (as opposed to just network topology) into emnetsin many traditional systems, the geographic location of a particularnode is not important; instead, what matters is the abstract network topology. the fact that emnets are coupled to the physical world requiresunderstanding how to generate and use other forms of location information, such as threespace coordinates or logical coordinates associatedwith a building structure, for example. such information can be both animportant attribute of applicationlevel data and a significant organizational principle for the system itself. when organizing information at theapplication level, knowing which nodes are in close physical proximity toembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.180embedded, everywhereother nodes can be very helpful. for example, location information couldbe useful in determining coverage of a particular physical area. at thesystem level, such information can be used when trying to achieve efficient system behavior. for example, a node might be interested in determining the closest repository for storing longterm data. in such a case,close physical proximity is desirable in order to reduce resource expenditures. location information is useful in another way as well: using threespace information in combination with static environmental informationallows the creation of logical location information that takes into accountthe surrounding environment.as discussed in chapters 2 and 5, global positioning system (gps)technology is not sufficient for all of the network geometry needs ofemnets. gps is a good model for the services needed in many outdoor,threespaceoriented systems but not necessarily for emnets that are indoors, on the battlefield, or in other remote locations. moreover, gps isnot ideal for networks whose nodes are small. new kinds of systems areneeded that are not constrained in the way gps systems are. researchinto systems that can take into account the logical structure of the geographical environmentñfor example, walls separating offices, the location of doors, or the inside of a vehicleñis also essential.interoperability: techniques and design methods for constructinglonglived, heterogeneous systems that evolve over time and spacewhile remaining interoperableemnets will often be embedded in longlived physical structures(homes, office buildings, hospitals, wells, aqueducts, airplanes, roads, andso on) and thus must be longlived themselves in order to be effective. tobe longlived, emnets must be able to evolve, as it is very likely that thefunctionality required of them will change in some way, perhaps to something for which they were not originally designed. further, heterogeneous emnet components will have to interoperate with each other, aswell as with various external devices to which they will connect. achieving such interoperability over the lifetime of the emnet and over thechanging space in which the emnet will be operating is an open researchchallenge. as discussed throughout the report, existing techniques andstrategies for interoperability are not yet up to the many challenges posedby emnets.emnets will typically operate in an unattended mode, wherein manyactions must be taken without human intervention. aspects of the environment may change, and elements may be moving into and out of thesystem in unanticipated ways without user assistance. moreover, whiledaytoday operations will need to occur autonomously, the system itselfembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations181may also have to evolve without human direction. thus, both the normaloperation as well as the system evolution of the emnet need to be selfconfiguring. in addition, the operational details of emnets are oftenhidden from casual users, and thus the evolution of the system needs tooccur as transparently as possible so as not to be obtrusive.the field of emnets is developing rapidly but in an uncoordinatedfashion. because they were so badly needed, a number of emnets havealready been designed, built, and deployed, and many of them have cometo us from fields other than computer science, such as aeronautics andsystems engineering. if emnets are not to risk becoming obsolete beforethey are deployed, system evolution and integration standards cannotreally start from scratch but must allow the integration and evolution ofexisting legacy systems.accordingly, a research program is needed that will actively challenge emnet research projects by requiring the integration of unanticipated elements into the research. these unanticipated elements mighttake the form of new devices, either tethered or mobile, or even legacysystems that could be of use to the overall system. the real aim of thisrequirement is to ensure that the framework developed for the emnet isflexible enough to deal with new elements and new requirements. left totheir own schedules, researchers will design for what they foresee thefuture to be; it is important that this research describe ways to deal with afuture that cannot be foreseen.integration of technical, social, ethical, and public policy issues:fundamental research into the nontechnical issues of emnets,especially those having to do with the ethical and publicpolicy issues surrounding privacy, security, reliability,usability, and safety emnets are capable of collecting, processing, and aggregating hugeamounts of data. with the advent of large numbers of emnets, the technological stage is set for unprecedented levels of realtime human monitoring. the sensors are cheap and unobtrusive, the computing and communications costs are very low, and there will be organizations with theresources and the motivation to deploy these systems. thus, emnetspresent a difficult challenge in terms of passive information disclosure. inthe case of the internet, privacy issues arise because as users browse forparticular kinds of information they are often asked to divulge explicitlyother kinds of information, or their clickstreams through and among sitesproduce information that sites may be storing without the userõs informedconsent. in the case of emnets, inadvertent, even unintentional revelations are much more likely. the monitoring these systems do will beembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.182embedded, everywherealmost completely undetectable. the temptation to use such systems forlaw enforcement, productivity monitoring, consumer profiling, or in thename of safeguarding children from harm will be enormous. at the sametime, we have already seen effects of information moving quickly aroundthe internet (for example, false rumors have had dramatic effects on thestock markets (walsh, 2000)). emnets as they have been described herehave the potential for even greater and more farreaching effects.with respect to security, history has shown that computer systemswill be attacked. data will be stolen or compromised, system functionality and/or availability will be impaired, and the attacks will be incessant.emnets will be very much at risk for such attacks, since they are deployed specifically to collect important information about the real worldand may be capable of acting on it. the security facilities of, say, theinternet, are obviously inadequate. emnets require much better resistance to malicious intrusions and much better means for detecting andreporting such attempts. these issues are not merely technical, however,and will need to be addressed at a procedural and public policy level aswell. the committee believes that purely technical approaches will beinsufficient and that policy and technical aspects should be coordinatedin order to address these problems. privacy, security, and ethical considerations need to be considered and incorporated early, during the designand development phases of these systems. these are areas in which interand multidisciplinary research efforts could pay large dividends.the committee believes that the ethical concerns related to securityand privacyñwhich drive legal and policy activityñrequire a fundamental research agenda. some of that research will relate to technical mechanisms that can help to ensure authenticated use and proper accountabilitywhile safeguarding privacy. but, perhaps more importantly, it may benecessary to develop a new calculus of privacy to be able to evaluate howinteractions between new elements will impinge on security and privacy.users will need ways of comprehending how the aggregation of the information they are divulging to disparate sources can compromise theirprivacy (e.g., connecting automobile sensor logs to location sensing), andthey will need to move beyond concerning themselves only with the security of a web siteõs credit card files.while this reportõs primary focus has been on a technological research agenda, the committee strongly recommends also examining thepolicy and social implications of emnets and other kinds of informationsystems. how can the development of policy and technical mechanismsbe coordinated to encourage realizing potential benefits from emnetswithout paying avoidable societal costs? research that relates technical,social, and policy issues is consistent with the social, economic, andworkforce (sew) component of the federal information technologyembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations183research and development program. this recommendation echoes anearlier cstb recommendation that networking research should have acomponent that looks at ethical, legal, and social implications, drawinginspiration from the elsi component of the human genome initiative.8enabling technologies: ongoing research into the variouscomponent and enabling technologies of emnetsin chapter 2 several fundamental enabling technologies for emnetswere discussed. as described there, research in these areas is still neededin order for the full potential of emnets to be realized. several specificissues are mentioned here, although it should be noted that each of thesetechnologies could generate an entire research agenda on its own.first, continuing research into building lowpower processors is essential for ubiquitous, efficient emnets. exploring the conflict betweenpower efficiency and flexible functionality raises a number of interestingresearch questions, and determining the best way to approach this problem is an open question. continuing research is also needed into wirelesscommunications and network architectures for shortrange, lowpowersystems. open questions remain about where to place communicationsin relation to computation and where storage should take place, as well aswhat appropriate media access control (mac) or maclevel protocolsshould be. alternative power sources are needed that will satisfy theform factor, communications, and computational requirements of emnetsand their individual components. the use of techniques such as ultrawideband (uwb) communications for emnet applications should also beexplored.9emnets will require changes in software functionality and development as well. upgradability, high availability, and the ability to workwith new hardware are just a few of the issues that will need to be takeninto consideration when developing software for emnets. morever, newand better tools for software development will be needed to effectivelyand efficiently build software for these systems. geolocation will alsoneed to be further explored. determining whether assisted gps is anoptimal location technology for emnets is an open research question. atthe same time, alternative techniques such as acoustic signaling should beexplored. finally, further work in mems sensors is needed to develop8see realizing the information future: the internet and beyond, p. 165 (cstb, 1994b).9the committee recognizes that the potential for uwb may be constrained by regulatorydecisions.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.184embedded, everywheresensors that can be realized on the same chips as the electronics neededfor control and communication.structuring the research enterprise for emnetsensuring that the right kinds of research are conducted to advancethe state of the art in emnets will require changes in the way the nationõsresearch enterprise is organized. academia and industry will both haveimportant roles to play. effective collaboration will be needed not onlyamong industry, universities, and government, but also between it researchers and researchers in other areas that will make use of emnets(e.g., the health sciences, manufacturing, and defense). explicit effortswill need to be made to put mechanisms in place for ensuring such collaboration.10 while past attempts to achieve similar goals met with mixedresults, the pressing needs of emnets demand redoubled efforts, drawingupon the lessons of history.research directions, such as those described in the preceding section,are important to articulate, but it is also how that research is conductedthat will determine whether the necessary advances are made. in the caseof emnets, researchers will have to gain experience in building and deploying systems. many of the properties that will need to be studied willemerge only when elements are deployed and begin to be combined andcoordinated in ways not foreseen by their designers.research funding agencies must be ready to promote a longterm,comprehensive vision and ensure that the appropriate communicationoccurs between the members of all relevant communities. building sharing inter and multidisciplinary communities is essential in a critical research area like emnets. once established, these communities fuel research in both universities and industry and further development inindustry. experimental research (not necessarily separate from fundamental research) is key to advancing the emnet agenda.11 this meansbuilding new systems, deploying them, evaluating them, and then redesigning or retuning the elements as well as the system as a whole. this isan iterative process, and many systems and elements will be thrown awayalong each cycle as new and better ideas and artifacts are developed.10cstbõs report making it better elaborates on these themes as related to the broader itcommunity (cstb, 2000).11see academic careers for experimental computer scientists and engineers for an explorationof experimental computer science within university environments (cstb, 1994a).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations185stimulating interdisciplinary researchmechanisms will be needed to promote interdisciplinary approachesto research on emnets, which tie computer science to other sciences andother disciplines in general. (see box 6.1 for a discussion of what may berequired when there is an increased emphasis on interdisciplinary andsystemlevel approaches in educational environments.) domain expertise found in disciplines such as biology, geophysics, chemistry, and medicine will allow the application of emnets in a variety of areas. thesedisciplines and others can provide models that couple the world of thenetworked computer and the physical world and can help in investigations of the wider implications of emnet society. a wide variety of application domains can serve as testbeds for emnet ideas and concepts aswell as bring richly interdisciplinary teams of researchers and scientiststogether. however, it is not simply a matter of bringing emnet expertiseto solve problems in the various sciences.interdisciplinary benefits will also flow in the other direction. it isclear that if emnets are going to interface to the physical world, theengineers and computer scientists who will be developing emnets willneed to connect with those who understand the physical phenomena andall their manifestations and variations. these will include bioengineers,environmental engineers, mechanical engineers, nanotechnologists, earthscientists, and chemical engineers. concepts from control theory andsignal processing will need to be in the repertoire of every researcher.nor does the challenge end here, for the interdisciplinary net willneed to be cast wider still, to bring concepts and techniques from evenmore distant disciplines, such as systems engineering, biological sciences,economics, and even sociology and political science. each has a longtradition of trying to understand the aggregate behavior of systems thatselforganize or that show coordination without centralized control.emnets will be systems that are not open to centralized control in thesame way that traditional computers or networks of it machines havebeen. they will have to be selfregulating, selfconfiguring, and selfmonitoring and will have a much higher degree of autonomy than previous systems, necessitated by the sheer number of devices that will beinterconnected in many applications. moreover, devices will be fieldedthat, because they will be deeply embedded in the environment or inlarger artifacts such as vehicles or buildings, will have much longer lifetimes and will be upgraded by the addition of new elements rather thansimple replacement. it is likely that much can be gained from looking atother disciplines to see what kinds of selforganization and decentralizedcontrols have worked in other fields and whether any of the knowledge isapplicable to emnets. such investigations could add many new pieces tothe toolbox of emnet research and development.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.186embedded, everywherebox 6.1education and emnetsincreased emphasis on interdisciplinary and systemlevel approaches iscrucial to moving forward in emnet research. these two approaches are also theones that require the most attention in the nationõs educational system. related tothem are four areas that are largely absent from engineering curricula today:¥design methodologies,¥broad interdisciplinary education,¥design with reusable components and creating components for reuse,and¥system integration, evolution, and maintenance.most computer science and electrical engineering departments today arehighly compartmentalized. students are specializing in their studies at an earlierage and often come to higher education along a predetermined path that permitsno forays into other disciplines. this tendency to be narrowly focused is often toolimiting. courses that look at the tradeoffs between all the levels in the design ofa complete system are rare. furthermore, few institutions are able to couple traditional education with exposure to system prototyping because the technology isconstantly evolving and the faculty have limited experience. system prototyping isan area ripe for collaboration with industry.interdisciplinary educational approachesinterdisciplinary education is too often interpreted as intersubdisciplinary,since it is usually more expedient to think in terms of a single academic department. students rarely work with students from other departments. some successful examples come from closely related subdisciplines in engineering departments,but much more needs to be done in preparing for a world of emnets.student design teams need to become broader. for example, the design ofa new patientmonitoring and information system should involve students not onlyfrom medicine but also from public policy, law, and business, along with the computer science students who will actually write the code. the code they writeñitsorganization as well as its functionñmay be deeply affected by their collaborationwith students from these other disciplines. electrical engineers developing newenvironmental sensor technologies, for example, would be well served by workingnot only with chemists but also with computer scientists, biologists, and other lifescientists. this interaction will undoubtedly uncover new uses for the technologiesas well as different, possibly much more efficient and/or effective approaches tosolving the original problem.unfortunately, todayõs highly specific courses must be taught by faculty froma single department and do not expose students to the rich fabric that interconnectsall university disciplines. graduate education does not correct this deficiency. infact, it exacerbates the problem by demanding a deeper dive into one subdiscipline. generalists are generally discouraged in most graduate programs. theembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations187emphasis is on depth in a narrowly defined area. few students are lucky enoughto be involved with truly interdisciplinary research projects.the challenges that lie ahead involve devising models for crossdepartmentfaculty collaboration, which is hampered today by antiquated models of teaching.interdisciplinary teaching is rare, because academic institutions have yet to figureout a way to do accounting except at a departmental level. finally, industry has arole to play in creating the kinds of educational programs needed for emnets. bythe very nature of the academic establishment, most faculty stop being practitioners for a large part of their careers. this is even more so in engineering thanin other fields such as law or medicine. involving leading industry practitioners inemnet education is critically important to producing graduate students who thinkalong multiple dimensions and view systems in the large, as integrated wholesrather than individually optimized elements.systemsoriented methodologiesthe fact that components rather than systems are taught is an oftenheardselfcriticism of engineering faculty. but one personõs system is anotherõs component. so what is really meant by this? the fundamental difference is one ofapproach to a problem. should the emphasis be on abstraction or analysis?should reuse of modules be encouraged or everything be constructed fromscratch? are system integration issues of interoperability and testing given firstclass status or are they afterthoughts?the nationõs current educational system is ill equipped to teach design methodologies. many perceive the topic as not difficult enough. furthermore, it is atopic with which faculty have little or no direct experience. yet, it is clearly a topicthat will need much attention as we start to design emnets, for they present a newframework distinct from that of more traditional systems. without appropriatemethodologies, formalizations, and abstractions it will not be possible to meet thechallenge of graduating students at all levels who can function well in this newspace. most engineering disciplines could use courses in aspects of systemdesign from evolution to manufacturing to safety. the focus today is too much oncost or size or power. rarely are these issues considered in combination, andthey are only a few of the many dimensions emnet designers will need to face.reusecurrent teaching methods are based on understanding components, oròdesign in the small.ó there is a bias toward teaching students how to design fromscratch rather than to reuse what is available. many faculty members find it difficultto understand how students can complete a degree without knowing how to doevery component on their own. however, this style of thinking has led to an overemphasis on design in the small and a lack of exposure to design for reuse and thereuse of designs.instead, students should be encouraged to learn not only how to comprehendand build mental models of how othersõ components work but also how to designso that others can share their design artifacts. currently, abstractions permit thisembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.188embedded, everywhereat lower levels (for example, logic gates and protocol stacks), but higher levelsneed to be used (for example, selfupdating code and composable network services) if systems of the scale and complexity of emnets are to be built. fosteringthe development of formal models that support higher levels of abstraction andprovide students with a curriculum that lets them build on othersõ work while alsoproviding building blocks for those coming after them is key to this endeavor.systems integrationfinally, one of the most important educational experiences is to work throughthe process of bringing together a system of many components. this step is crucial to understanding the value of design methodologies and abstractions. systemdesign without the experience of integration is similar to writing code that is neverdebugged. the art of stepwise integration and debugging needs to be imparted tostudents as early as possible in their curriculum, and they should be repeatedlyexposed to these issues throughout their education.it is important to understand that the term òintegrationó is meant in the broadest possible sense. that is, it comprehends not only integration of the componentsbut also the deployment (or integration) of the system into its intended operatingenvironment. any system will alter that environment and thus affect the assumptions that underlie its own design and development. the closure of that feedbackloop is a fundamental lesson in the process of design that few students gain fromtodayõs engineering education.box 6.1 continuedbecause of their scope, emnets offer a new opportunity for cooperation between academia and industry, both in the traditional channels ofthe computing industry and academic computer science departments andin new channels of interaction between a wider set of academic departments and computing and noncomputing industries, such as medicalequipment manufacturers, environmental monitoring consultants, andresource management industries. the committee recognizes that fostering successful interdisciplinary and interinstitutional research is not easy.encouraging such interdisciplinary and nontraditional collaborations willrequire the creation of new research venues and new incentives for industrial and academic partnerships. educational institutions will need to beencouraged to create new centers for research that cross traditional departmental boundaries and ensure that research opportunities withinthese centers are funded and rewarded. funding agencies will need tothink òoutside the boxó about the kinds of collaborations they accept andembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations189promote. new industrial partners will need to be approached, educated,and enlisted in the construction of new systems that solve problems notcurrently thought of as part of networks of computers.what can government do? recommendations tofederal agencies the federal government has long been a strong supporter of broadranging research in information technology. while there have been numerous notable successesñindeed, whole industries have grown out ofthis funding12ñfundamental research in information technology is farfrom complete. this is clearly seen in the context of emnets. for themost part, emnets are currently deployed in applicationspecific, highlyengineered contexts. it is essential to develop mechanisms, algorithms,and models that are broadly applicable and reusable to gain experienceand confidence with various approaches over time. similarly, a base oftrained technical personnel is needed who understand how to design,develop, and implement these systems. while it is powerful and compelling to demonstrate the concepts and see the potential in various prototypes, such demonstrations alone will not develop the discipline and thetechniques to fulfill the vision outlined in this report. longlived researchprograms are essential so that the deeper, harder issues can be addressedand a set of wellunderstood, characterizable primitives developed foruse across many application instancesñthis is where university researchbecomes crucial for complementing the more directed and sometimesnarrower scope and shorterterm focus of industry.federal funding for research guides the focus of the university research community and influences not only what is accomplished therebut also what is accomplished in industry. such funding can cause industry to take a broader perspective and produce more flexible technologyfor users in the federal government and elsewhere than it would if leftstrictly to market forces. collaboration is necessary between industry andacademia as the science of emnets is developed. today, many universityprojects are too close to product development, with the lure of startupshaving done much to push things in this direction. models for jointinvestigation, fostered by appropriately targeted federal funding, shouldbe renewed if the research community and society are to reap the benefits12see evolving the high performance computing and communications initiative to support thenationõs information infrastructure (cstb, 1995), as well as funding a revolution: governmentsupport for computing research (cstb, 1999).embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.190embedded, everywhereof a full collaboration. to that end, the committee next describes severalways in which the defense advanced research projects agency (darpa),the national institute of standards and technology (nist), and the national science foundation (nsf) could facilitate research in these areas. italso makes several recommendations to various federal agencies regarding effective sponsorship and support of emnetrelated research.recommendations to the defense advancedresearch projects agencydarpa has already invested in emnetrelated technologies, but ithas only scratched the surface of what will be necessary to advance thiscritical technology. both its information technology office (ito) and itsmicroelectronics technology office (mto) have developed programs thatrelate to emnets. it is now time to build on the past successes and presentefforts13 and to broaden and deepen the work in this area. a multifacetedprogram or set of programs is needed that will pursue the core computerscience and information technology issues that have been raised throughout this report. as described previously, narrowly focused solutions andsmallscale programs are a good and even essential start, but they are notup to the gigantic task of developing reusable, generalizable, characterizable, and robust techniques for designing, implementing, deploying, andoperating largescale, robust emnets. it is time to build on these endeavors and turn to systems work that will require extensive breadth anddepth in order to be successful.publicly funded research is needed to drive innovation that is ofsufficient scopeñthat is, that covers predictability, adaptability, survivability, system monitoring, and so onñand addresses externalities suchas interoperability, safety, and upgradability. the development of robustemnet technology will require the research community to rethink thefundamentals of information technology and the design of computer andcommunications systems. first and foremost it calls for a systems approach in which design, programming, and control focus on systems composed of massive numbers of networked components and not on optimization of individual or small numbers of elements. a single, isolated,13these efforts include sensor information technology (sensit), mems, distributed robotics, power aware computing/communication (pac/c), networked embedded software technology (nest), next generation internet (ngi), and so on. the networking goalsof the next generation internet project, for example, touch on some of the needs ofemnetsñfor example, the need for largescale systems that can accommodate a wide rangeof uses and applications.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations191shortlived research program will not suffice to address the scope anddepth of the problems that must be addressed to realize scalable, robust,and usable emnets. darpa should aggressively pursue multiple programs that build upon and interact with one another and with some of theseed programs that have already begun to explore related areas. theseseed programsñsensit is oneñhave made important initial contributions. it is in part their successful initial forays that now allow the committee to articulate a fullfledged research agenda. however, as mentioned before, they were not of the scale, duration, or scope needed toaddress darpaõs critical medium and longterm needs for robust, scalable emnet systems technologies, and darpa should now encouragethe development of multiple programs that build upon and interact withone another. to truly harness the power of emnet systems, darpashould manage these programs in a way that fosters their interaction andcreates and builds on conceptual overlaps. the committee emphasizesthe need for intellectual collaboration and communication as opposed torequiring prototypes or deliverables from each project for use by one ormore of the other projects. there is much to be gained by understandingand exploiting the conceptual commonalities across networked embedded control systems, ad hoc sensor networks, low power design, andsmart fabric. and there is much to be lost if such collaborations fail tomaterialize.making progress in an area as large as and, in many ways, as radicalas emnets requires sustained support for research along with a carefulrethinking of how best to organize, communicate, and develop the workover the long term. emnets present an opportunity to continue progressin critical areas of information technology research as well as to discoverand advance new capabilities. a longterm research agenda that beginsto address these challenges in parallel, while promoting crosscollaboration and interdisciplinary, interprogram work where appropriate, willhave tremendous impact. it should have sufficient longevity to exploremultiple approaches without insisting on preaward or preresearch agreement on the general architecture and infrastructure. to this end, tworecommendations are given below, along with a (by no means comprehensive or canonical) list of possible darpa programs in this area.recommendation 1.the information technology office of the defense advanced research projects agency should revise both thesubstance and process of its emnetrelated programs to better address the research needs identified in this report.darpaõs information technology office (ito) took the lead in earlyresearch on sensor networks. however, there are several ways itoõsprograms could more fully address the research needs explicated in thisembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.192embedded, everywherereport. field demonstrations are clearly critical to darpa, and suchdemonstrations should continue. however, the committee suggests thatearly in a technologyõs development, research dollars are better spent onexploration of the design space and experimental exploration than onfield demonstrations of particular point solutions. such demonstrationscan crowd out more systematic investigations and higherrisk investigations and tend to place too much emphasis on early system integrationand convergence to single approaches. carefully crafted experimentalwork, on the other hand, can promote real system development and usein a context that provides invaluable feedback to researchers and developers. while it is important for universities to build prototypes, it iscrucial to remember that these prototypes are built not for future productdevelopment, as are those built by industry, but to understand better theproblems of the application. that deeper and more focused understanding is what brings about innovative solutions to problems by deepeningscientific understanding (determining, for example, formal models andappropriate abstraction layers). experimental projects might even involve the definition of interfaces and integration over time without, however, being limited by the constraints of timesensitive demonstrations.after some period of time, contractors (i.e., industry) should be involvedin developing demonstration prototypes and should share their experiences with researchers.the committee recommends that darpa focus its efforts on fourtechnical areas in order to realize emnet technology that is robust, scalable, and widely applicable across department of defense needs, both onthe battlefield and off (e.g., logistics). these areas are described in box6.2.some of these topics are being addressed by individual principal investigators who are or have been funded under one of darpaõs existingemnetrelated programs, such as ubiquitous computing14 (part of thisprogram focuses on the notion that users do not interact with the computing devices themselves but with the services they provide) and sensit15(the emphasis in this program is creating connections between the physical world and computers by developing the software for networked sensors). box 6.3 describes more of itoõs current and recent programs in thisarea. however, the topics addressed by each of these programs deserveand require more exploratory, broaderbased investigation. the programssuggested in box 6.2 are far from exhaustive, but they could serve as thebeginning pieces of a much larger systematic effort to address the issuesraised in the box.14for more information, see <http://www.darpa.mil/ito/research/uc/index.html>.15for more information, see <http://www.darpa.mil/ito/research/sensit/index.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations193box 6.2suggested emnetrelated programs at darpadesigning for predictability, reliability, and safetyas more and more technology is employed in support of missioncriticaloperations, the inadequacy of system predictability and diagnosability is posingtremendous risks. emnets intensify these inadequacies, because users will typically interface with the object in which the emnets is embedded rather than withthe system itself. a program is needed to develop abstractions and models thatallow users to understand and reason about variable system conditions and failures. rather than developing models for safety, reliability, and predictability separately, it is critically important to develop models that encompass all three andthat address the tradeoffs that will be necessary among them. further, it isincreasingly important to build systems with quantifiable (in some cases, provable)properties such as scoping or isolation of system behaviors.collaborative signal processingwhile darpa has initiated some programs in the area of emnets that applyto sensor networks, there is a particular need to engage the signal processingcommunity in the development of distributed collaborative signal processing acrossmultiple sensory modalities. existing programs in these areas require renewedemphasis and support.multiscale locationaware systemstechnology has been and is being developed to support particular geolocation techniques. however, many forms of geolocation that are related to proximityand logical location must be integrated into emnets. there should be a programpromoting system technology that exploits multiscale location and involves approaches that will work through a variety of media, including rf, acoustics, andimaging. the program should also explore the difference between infrastructuraland noninfrastructural (more ad hoc) approaches.interoperability over time and spaceemnets will be embedded in our infrastructure and therefore will have lifetimes as long as that of the infrastructure. at the same time, new devices willcontinually be introduced into the overall system. a program that addresses thechallenges of integration and interoperability with new devices over long systemlifetimes and changing expectations is needed. it should emphasize research inhow to handle legacy devices (for example, how to decommission them while theyare deeply embedded). further, such a program should incorporate the notionthat units of interoperability vary: a single device may need to interoperate withother devices, or a cluster of devices may need to interoperate as a unit with otherclusters of devices.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.194embedded, everywherebox 6.3a sampling of current and recent emnetrelated projects ofdarpaõs information technology officenetworked embedded software technology (nest)in this project, darpa is seeking novel approaches to the design and implementation of software for networked embedded systems. the coordinated operation of distributed embedded systems makes embedding, distribution, and coordination the fundamental technical challenge for embedded software. the goal ofthe nest program is to enable finegrained fusion of physical and informationprocesses.sensor information technology (sensit)the goal of the sensit program is to create the binding between the physicalworld and cyberspace. sensit is founded on the concept of a networked systemof cheap, pervasive devices that combine multiple sensor types, reprogrammableprocessors, and wireless communication.ubiquitous computingthe goal of the ubiquitous computing program is to create a postpc era ofcomputing in which a scarce resourceñhuman attentionñis conserved in an environment where computing functionality is embedded in physical devices that arewidely distributed. in this environment, users do not interact with any particularcomputing device but rather with the functionality and services offered by the set ofdevices at hand.recommendation 2.the defense advanced research projectsagency should encourage greater collaboration between its information technology office (ito) and its microelectronics technology office (mto) to enable greater experimentation.there is an opportunity to take advantage of collaborations betweenito and mto by enabling experimental emnet projects with real stateoftheart sensors and even actuators. mtofunded research has broughtsignificant advances in mems technology, but that research has not yetemphasized the systemlevel aspects of mems. (see box 6.4 for recentwork in emnetrelated areas in darpaõs mto and its advanced techembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations195nology office (ato).) the idea is to apply wellunderstood mems techniques to produce several types of sensor/actuators that can be integratedinto emnet prototypes by the research community and allow for morerealistic experimentation with a range of physically coupled systems.these might take several forms. examples include a chemical sensor thatcould be used in experimental monitoring systems, a computational fabric that has a mixture of pressure and temperature sensors, and tensionvarying actuators that would enable experimenting with how to controlemnets of this type.the research community could define standard interfaces to thesemodelbased integration of embedded softwarethe goal of this project is to create a new generation of system software thatis highly customizable and responsive to the needs of various application domainsand to the constraints of embedded systems.poweraware computing/communicationthe goal of the poweraware computing/communication project is to enablethe intelligent management of energy and energy distribution, providing the minimum power necessary to complete a given task.adaptive computing systemsthe adaptive computing systems program was designed to create unprecedented capabilities for the dynamic adaptation of information systems to a changing environment. it explores redefining the traditional hardware/software boundaryto enable the rapid realization of algorithmspecific hardware architectures on alowcost cots technology base.embeddable systemsthe embeddable systems program focuses on leveraging and extending thecommercial scalable computing technology base to support defense embeddedcomputing applications.software for distributed roboticsthe goal of this project is to develop software for the employment and controlof large numbers of small, distributed, mobile robots in order to achieve largescaleresults from many smallscale robots.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.196embedded, everywherebox 6.4a sampling of current and recent emnetrelated projects ofdarpaõs microelectronics technology office and itsadvanced technology officedistributed roboticsthe darpa distributed robotics program seeks to develop revolutionaryapproaches to extremely small robots, reconfigurable robots, systems of robots,biologically inspired designs, and innovative methods of robot control. the program focuses on individual robots that are less than 5 cm in any dimension.microelectromechanical systems (mems)the primary goal of the darpa mems program is to develop the technologyto merge sensing, actuating, and computing in order to realize new systems thatbring enhanced levels of perception, control, and performance to weapons systems and battlefield environments.microoptoelectromechanical systems (moems)the primary goal of the moems program is to develop the technology tomerge sensing, actuation, and computing in order to realize new systems thatbring enhanced levels of perception, control, and performance to military and commercial systems.smart modulesthe smart modules program is developing and demonstrating novel ways ofcombining sensors, microprocessors, and communications in lightweight, lowpower, modular packages that offer warfighters and small fighting units new methodsto enhance their situational awareness and effectively control their resources onthe battlefield.future combat systems communicationsthe goal of this program is to produce communications technology for ad hocnetworks that can operate under severe operational constraints, such as a hostileelectromagnetic environment. these mobile networks will have both airborne andterrestrial platforms deployed in an autonomous fashion to provide needed coverage on an ad hoc basis.global mobile information systems (glomo)the goal of the glomo project was to make the environment a high priority inthe defense information infrastructure, providing userfriendly connectivity andaccess to services for wireless mobile users.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations197devices and enable relatively inexpensive prototyping in a widespreadmanner. such technologies would provide the academic research community, in particular, with the kinds of artifacts it will need to betterexplore applications of mems technology to emnets and the systemlevel issues that result.recommendations to thenational institute of standards and technologynist, and in particular its information technology lab, has workedin a variety of areas to help make information technology more secure,more reliable, more usable, and more interoperable. all of these characteristics are, as has been described, crucial to current and future emnetrelated technologies. nist has played a valuable role in promoting standardization and acting as a verification agent (see box 6.5 for informationon emnetrelated nist programs). in this role, nist establishes trust intechniques and mechanisms by establishing testing and evaluation standards. many applications and components of emnets will require verification, and nist is in an excellent position to act as arbiter betweendeveloper and user.nist has already begun to play a role in wireless interference andassociated power and frequency standardization. this effort will becomeeven more critical as more wireless devices are deployed at greater densities.16 new applications of emnets will call for entirely new metrics forevaluation (such as system lifetime and system manageability or instrumentation). a wide range of standardization efforts will be launched asan offshoot of emnet activities, including sensor, actuator, wireless, andcrosssystem interactions.nist is in an excellent position to foster interaction by devising theappropriate metrics for measuring the effectiveness of emnet elements aswell as the requirements for performance and quality of service for themore abstract services that will be built upon those elements. in additionto metrics, nist can also act as a collector of and repository for experimental data. there is a growing gap in access to critical evaluation data.this is already evidenced in the case of the internet. unlike in the earlydays of computing, when most researchers could manage to measure theperformance of their own computing equipment, today a national oreven a globalscale infrastructure is required for collecting datatrafficinformation. such an infrastructure is accessible to only a very few large16it should be noted that the federal communications commission also plays an important role in this area.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.198embedded, everywherebox 6.5a sampling of nistõs emnetrelated programsthe nist smart space laboratorysmart spaces are work or home environments containing embedded computers, information appliances, and multimodal sensors. nistõs goal is to addressthe measurement, standards, and interoperability challenges that must be met astools for these environments evolve in industrial r&d laboratories worldwide. nistis also working to develop industrial partnerships and is sponsoring workshopswith darpa and nsf in this area.networking for smart spacesthis project explores the use of java, jini, and multicast technology in conjunction with wireless systems such as bluetooth and homerf as a networkingfoundation for pervasive computing or smart spaces.the aroma projectthe goals of the aroma project are to help research, test, measure, and standardize pervasive computing technology by, among other things, measuring theresource requirements and performance of emerging pervasive computing software and networking technologies; developing software tools for testing, measuring, and diagnosing pervasive software and networks; and creating standardabstractions and models for developers.companies. expanding access to this data by more researchers is an important role for a government agency.the committee believes that nist also has a particularly critical roleto play in this realm as the agency that establishes confidence in information systems. nist is seen as an outside observer that can provide objective services and analysis. it has an important role in the standardsdevelopment process, allowing the work done in industry to beilluminated in a fair and open fashion. as this report has emphasized,interoperability for emnets will be very important, and standards will beneeded for such interoperability. given that many of the standards in thisarena are likely to arrive as de facto rather than de jure standards, nistcan provide an objective analysis of them and reduce barriers to entrywith reference implementations of the technology itself and/or referenceimplementations of conformance testing tools. more specifically, nist,through activities such as its aroma project,17which focuses on testing,17for more information, see <http://www.nist.gov/aroma/>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations199measuring, and standardizing pervasive computing technology, shouldplay a significant role in the two areas as emnets become ever morewidespread.recommendation 3.the national institute of standards and technology should develop and provide reference implementations inorder to promote open standards for interconnectivity architectures.it will be important to promote open standards in the area and promote system development using commercial components by makingpublic domain device drivers available.recommendation 4.the national institute of standards and technology should develop methodologies for testing and simulatingemnets in light of the diverse and dynamic conditions of deployment. comprehensive simulation models and testing methodologiesfor emnets will be necessary to ensure interoperable, reliable, andpredictable systems. in particular, the development of methodologiesfor testing specification and interoperability conformance will be useful.in the process of these endeavors, nist can play a key role in datacollection and dissemination of emnetrelated information for use by thelarger research and development community.recommendations to the national science foundationthe national science foundation (nsf) has a strong track record inpromoting multidisciplinary research and integrated research and education programs. more recently, it has been increasing its support for integrated systems projectsñfor example, the information technologyresearch (itr) program. all three areasñmultidisciplinary research, integration of research and education, and integrated systems approachesñwill be of great importance in the support of emnetrelated researchprojects, and all of themñin particular, systemsoriented workñshouldbe aggressively pursued and include crossdivisional efforts where necessary. specific recommendations for nsf are below.recommendation 5.the national science foundation should continue to expand mechanisms for encouraging systemsoriented,multiinvestigator, collaborative, multidisciplinary research onemnets.nsf is funding work in several areas related to emnets (see box 6.6).much of this work continues to be done by a single principal investigator(and graduate students) operating on a small budget. as noted in thisembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.200embedded, everywherebox 6.6a sampling of the national science foundationõsemnetrelated programsscalable information infrastructure and pervasive computingnsf is supporting work in scalability, security, privacy, sensors and sensornetworks, and tetherfree networking and communications in this program. its goalis to advance the technical infrastructure to support humantohuman, humantocomputer, and computertocomputer remote communication.wireless information technology and networksthis program funds research to provide a foundation for designing highinformationcapacity wireless communication systems for full mobility. suchdesign will require synergistic, multidisciplinary research efforts encompassing abreadth of communications functions from the physical through application layers.electronics, photonics, and device technologiesthis program funds research in the areas of micro and nanoscale devices,components, and materials, advanced methods of design, modeling, and simulation of such devices and components, and improved techniques for processing,fabrication, and manufacturing.report, research on emnets will require that such single investigator research be complemented by collaborative experimental research thatbrings together researchers from different disciplines to focus on a common problem. had this report been written several years ago, it wouldhave recommended that nsf move toward largerscale, experimentallydriven, risktaking research. nsfõs itr program appears to be doing justthat. itr also reinforces attention to the social and economic dimensionsof information systems. this program, or others like it, could serve as auseful vehicle for pursuing some of the topics pinpointed in this report.the key to achieving successful multidisciplinary research is not just amatter of funding levels. a flexible process is required that can incorporate perspectives from a broad range of relevant disciplines.recommendation 6.the national science foundation should develop programs that support graduate and undergraduate multidisciplinary educational programs.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations201with respect to education (see box 6.1), nsf could take the lead intackling institutional barriers to interdisciplinary and broad systemsbased work. nsf has a history of encouraging interdisciplinary programs and could provide venues for such work to be explored (as is beingdone in the itr programs) as well as foster and fund joint graduate programs or joint curriculum endeavors. one way to do this would be toprovide incentives to programs that successfully cross disciplinary boundaries. for example, faculty working on interdisciplinary research oftenhave difficulty securing institutional support for work deemed outsidethe scope of their home department. a program that removed this drawback by providing funding for such work could stimulate interdisciplinary research and course material in colleges and universities. anotherway would be to expand the graduate fellowship program to supportmore interdisciplinary proposals. suitable evaluations of proposals wouldbe needed to implement this recommendation.recommendations to other federal agenciesthe national aeronautics and space administration (nasa) and thedepartment of energy (doe) were two of the earliest innovators andadopters of emnets. while nasa and doe application domains can bequite specialized, two things are clear: the computer science communitywould benefit from hearing of and seeing this earlier (and contemporary)work, and nasa and doe themselves would benefit from the moregeneral pursuit of this technology by the broader computer science community. both agencies have long histories in systems engineering as wellas in computer science and so could serve as a useful bridge betweenvarious communities, especially regarding the development of emnets.nasa, for example, has a strong interest in safety and reliability, anddoe has long been involved in reliability issues. their expertise, whenapplicable, could be shared with others in related research areas; in addition, the two agencies would benefit from the generalizations that thebroader research community could provide. more explicit cooperationand communication would be beneficial to everyone and would greatlyadvance the field.the agencies with needs for emnets should together promote expanded experimental research with a shared, experimental systems infrastructure. the committee expects that coordination needs could be supported by the various organizations and groups associated with federalinformation technology research and development.18 openplatform sys18the national coordination office for information technology research and development and related groups can facilitate crossagency coordination, for example.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.202embedded, everywheretems of various scales, lowpower components and the software driversfor these components, debugging techniques and software, traffic generatorsñall can be shared across research programs when applicable, avoiding inefficient redundancy in those parts of the system where there ismore certainty. the research communities should combine their efforts increating enabling components, such as a range of memsbased sensorsand actuators that are packaged in such a way as to be easily integratedinto experimental emnet systems. this would enable experimentationwith emnets in environmental and biological monitoring applications,for example, that are relevant to a variety of agencies, such as the environmental protection agency, the federal aviation administration, thenational institutes of health, the national oceanic and atmospheric administration, doe, and nasa, as well as research groups working inthese areas. crosscollaboration and communication and the development of general enabling components will be essential for broadrangingexperimental work with emnet systems.summaryemnets present exciting new challenges in information technology,posing fundamental research questions while being applicable to a broadrange of problem domains and research disciplines. unfortunately,progress in this area will probably be confined to domain and applicationspecific systems unless a concerted, comprehensive effort is made tobroaden and deepen the research endeavor. it is unlikely that such abroadbased, widely applicable research agenda will be undertaken byindustry alone. while systems can be built individually, the accumulatedunderstanding will be insufficient without fundamental work promotedand supported by federal funding agencies. the technology would alsobe much more expensive, only narrowly applicable, and far less extensible and robust. longterm, forwardthinking, and broadranging research programs are crucial to achieve a deep understanding of emnetimpacts on society and of how to design and develop these systems.referencescomputer science and telecommunications board (cstb), national research council.1994a. academic careers for experimental computer scientists and engineers. washington, d.c.: national academy press.cstb, national research council. 1994b. realizing the information future; the internet andbeyond. washington, d.c.: national academy press.cstb, national research council. 1995. evolving the high performance computing and communications initiative to support the nationõs information infrastructure. washington, d.c.:national academy pressembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.conclusions and recommendations203cstb, national research council. 1999. funding a revolution: government support for computing research. washington, d.c.: national academy press.cstb, national research council. 2000. making it better: expanding information technologyresearch to meet societyõs needs. washington, d.c.: national academy press.cstb, national research council. 2001. the internetõs coming of age. washington, d.c.:national academy press.walsh, sharon. 2000. òfeds make arrest in internet hoax case.ó the standard, august 31. available online at <http://www.thestandard.com/article/display/0,1151,18153,00.html>.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.appendixesembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.207abiographies of committee membersdeborah l. estrin, chair, is a professor of computer science at theuniversity of california at los angeles and a visiting scholar at the university of southern californiaõs information sciences institute. she isrecognized for her research in computer networks and internetworking,protocol design, scalability, and multicast routing. her current researchfocuses on the design of protocols for largescale wireless sensor networks. dr. estrin served as chair of the 1998 darpa information scienceand technology study on simple systems, whose focus was networkedembedded computers. she has participated in a number of cstb studies,including those that produced the reports evolving the highperformancecomputing and communications initiative to support the nationõs informationinfrastructure, the changing nature of telecommunications infrastructure,academic careers for experimental computer scientists and engineers, andthe internetõs coming of age. dr. estrin holds a b.s. in electrical engineering from the university of california at berkeley and an m.s. in technology and policy and a ph.d. in electrical engineering and computer sciencefrom the massachusetts institute of technology. she was selected as apresidential young investigator (1987) and is a fellow of the associationfor computing machinery (2000) and the american association for theadvancement of science (2001).gaetano borriello is a professor in the department of computerscience and engineering at the university of washington. he receivedhis ph.d. from the university of california at berkeley in 1988 and wasembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.208appendix aemployed at the xerox palo alto research center in the early 1980s. hiscurrent research interests focus on the design, development, and deployment of embedded systems, with particular emphasis on mobile and ubiquitous devices and the applications they will support. he is also interested in system development environments, user interfaces, andnetworking. these interests are unified by their goal of making newcomputing and communication devices that simplify life by being as invisible as possible to their owners; being highly specialized and thushighly efficient for the task at hand; and being able to exploit their connections to each other and to the greater worldwide networks. dr. borriellois currently director of intelõs seattle research laboratory and is active onthe program committees of several conferences and workshops on systemlevel design topics. in addition, he recently served as program chairand general chair of the institute of electrical and electronics engineers(ieee)/association of computing machinery (acm)/ internationalfederation for information processing (ifip) international workshop ofhardware/software codesign (1998) and the uw/microsoft researchsummer institute on the technologies of invisible computing (1999). heis a member of the ieee computer society and the acm special interestgroup on design automation.robert paul colwell led intelõs architecture development effortfor the p6 microarchitecture (the core of intelõs pentium ii and pentium iiiprocessors) and managed the pentium 4 microarchitecture development.dr. colwell joined intel in 1990 as a senior architect on the pentium proproject and became manager of the architecture group 2 years later. in1996 he was elected an intel fellow, the highest rung on intelõs technicalcareer ladder. from 1985 through 1990, dr. colwell was a cpu architectat vliw pioneer multiflow computer. from 1980 to 1985 he workedparttime as a hardware design engineer at workstation vendor perq systems while attending graduate school at carnegie mellon universityõselectrical and computer engineering department. he was a member ofthe technical staff at the bell telephone labs from 1977 to 1980, workingon the bellmac series of microprocessors. dr. colwell received his bseefrom the university of pittsburgh in 1977, his msee from carnegie mellonuniversity in 1978, and his ph.d. from carnegie mellon university in1985. he holds 44 patents.jerry fiddler is founder and chairman of wind river systems, theworld leader in embedded software and operating systems. wind riverõssoftware is widely used in applications from the very high tech (the operating system for the mars pathfinder) to the very high volume (hewlettpackard printers, general motors engine controllers, kodak digital camembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.appendix a209eras, and nortel telephones). as chairman, mr. fiddler provides technical oversight and guidance, travels and communicates widely within theembedded community, and is a prominent industry expert and spokesperson. he is on the board of crossbow technology, a private companymaking memsbased sensors, and serves on other corporate boards aswell. he is a fellow of the lester center for entrepreneurship at theuniversity of california at berkeley. mr. fiddler holds an m.s. degree incomputer science and a b.a. in music and photography from the university of illinois, champaignurbana. he served as a senior computer scientist at the lawrence berkeley national laboratory from 1978 to 1981,when he founded wind river systems.mark horowitz is director of the computer systems laboratory atstanford university and is the yahoo founderõs professor of electricalengineering and computer science. dr. horowitz received his b.s. andm.s. in electrical engineering from the massachusetts institute of technology in 1978 and his ph.d. from stanford university in 1984. since1984, he has been a professor at stanford in the area of digital systemdesign. his work in this area is quite broad, ranging from circuit designto multiprocessor architecture. while at stanford he has led a number ofprocessor designs, including mipsx, one of the first processors to includean onchip instruction cache; torch, a statically scheduled, superscalarprocessor that supported speculation; and flash, a flexible, distributedshared memory multiprocessor. he has also worked in a number of otherchip design areas, including highspeed memory design, highbandwidthinterfaces, and fast floating point. in 1990 he took leave from stanford tohelp start rambus, inc., a company designing highbandwidth memoryinterface technology. his current research projects include work in highspeed io, lowpower vlsi design, vlsi computer architecture, and newgraphics io devices.william j. kaiser is chief technology officer and vice president ofresearch and development at sensoria corporation and professor in theelectrical engineering department of the university of california, losangeles. he and his team developed wireless integrated network sensors (wins), the first distributed embedded computing technology foròinternetworking and the physical world.ó sensoria, founded in 1998, isa rapidly growing company that provides endtoend wins solutions forwireless network access to distributed vehicles and embedded systems,sensors, and controls. his background includes distributed wireless sensing and computing, lowpower analog and digital electronics, and lowpower rf communication systems. dr. kaiser received a ph.d. in solidstate physics from wayne state university in 1984. his graduate researchembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.210appendix aat ford motor company included the development of automotive sensortechnology ranging from the development of measurement methods,through circuits, structures, and materials, to largevolume commercialsensor production. in 1986, dr. kaiser joined the staff of the jet propulsion laboratory (jpl), where he initiated the nasa microinstrument program. in 1994, he joined the faculty of the university of california at losangeles electrical engineering department, where he served as chairmanof the department from 1996 through 2000. his awards include the alliedsignal faculty research award, the peter mark award of the americanvacuum society, the nasa medal for exceptional scientific achievement, and the arch colwell best paper award of the society of automotive engineers. dr. kaiser has over 100 publications, 100 invited presentations, and 21 patents.nancy g. leveson is professor of aerospace software engineering inthe aeronautics and astronautics department and also professor of engineering systems at the massachusetts institute of technology. previouslyshe was boeing professor of computer science and engineering at theuniversity of washington. she has served as editor in chief of ieeetransactions on software engineering and on the board of directors of theinternational council on systems engineering. dr. leveson is a fellow ofthe acm and is currently an elected member of the board of directors ofthe computing research association, a member of the acm committeeon computers and public policy, and a member of the national researchcouncilõs advisory committee for the division on engineering and physical sciences. she received the 1995 aiaa information systems award foròdeveloping the field of software safety and for promoting responsiblesoftware and system engineering practices where life and property are atstake.ó she is author of a book, safeware: system safety and computers,published by addisonwesley. dr. leveson is a member of the nationalacademy of engineering and was awarded the 1999 acm alan newellaward.barbara h. liskov is the ford professor of engineering at the massachusetts institute of technology. her research interests lie in the areas ofprogramming methodology, programming languages, and programmingsystems, and she has done research on data abstraction, program specifications, objectoriented programming, concurrency control, fault tolerance, parallel and distributed programs, and algorithms for distributedsystems. her projects include the design and implementation of clu, thefirst programming language to support data abstraction; the design andimplementation of argus, the first highlevel language to support implementation of distributed programs; and the thor objectoriented databaseembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.appendix a211system, which provides transactional access to highly available objects ina widescale, distributed environment. professor liskov is a member ofthe national academy of engineering and a fellow of the american academy of arts and sciences and of the association for computing machinery. she received the 1996 achievement award from the society ofwomen engineers. professor liskov has published more than 100 technical papers and is the author of several books, including program development in java, which was recently published by addisonwesley.peter lucas is chief executive officer of maya design, which hecofounded in 1989. he has guided the growth of maya as a premiervenue for interdisciplinary product design and research, serving both theprivate and public sectors. dr. lucas received his ph.d. in 1981 fromcornell university, where he studied educational and cognitive psychology and psycholinguistics. he did postdoctoral research at the university of wisconsin and was a sloan postdoctoral fellow in cognitive scienceat carnegie mellon university. his research interests lie at the intersection of computer architecture and product design. he is currentlyfocused on developing a distributed architecture for ubiquitous computing that is designed to scale to nearly unlimited size, depending primarilyon market forces to maintain tractability and global coherence. he holds13 patents and has coauthored a book on letter and word perception. hewas founding chair of three rivers connect, an initiative of business andcivic leaders that promotes the development of òcivic computingó in thepittsburgh region. he sits on a number of boards in both the public andprivate sectors. he is adjunct associate professor in the humancomputerinteraction institute of carnegie mellon university.david p. maher is chief technology officer of intertrust. he previously served as head of the secure systems research department at at&tlabs. he has a ph.d. in mathematics from lehigh university, and he hastaught electrical engineering, mathematics, and computer science at several institutions. he joined bell labs in 1981, where he developed securewideband transmission systems, cryptographic key management systems, and secure voice, fax, and data devices. he was chief architect forat&tõs stuiii secure voice, data, and video products, used by the president and dod officials for top secret communications. dr. maher wasmade an at&t fellow for his work in communications security. he haspublished papers in the fields of combinatorics, cryptography, numbertheory, signal processing, and electronic commerce. he has been a consultant for the national science foundation, the national security agency,the national institute of standards and technology, and the congressional office of technology assessment. recently, dr. maher has beenembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.212appendix adoing research on electronic payment systems and the protection of intellectual property distributed over the internet.paul m. mankiewich is presently head of the wireless technologyresearch department at lucent technologies. he is also wireless research hardware and architecture director in the wireless networkgroup business unit and in that role is responsible for shepherding researchtechnology into wireless products. his research department has responsibility for novel wireless system and radio architectures, adaptive antennatechnologies, and radio and modem technologies for nextgenerationwireless data and voice networks. his group has been responsible for adiverse set of programs such as a steeredbeam, nextgeneration, fixedwireless system, various issues regarding system improvements throughbaseband signal processing, algorithms for cellular network optimization, 3g wireless system architectures, and systemlevel issues regardinghome networking and bluetooth. he joined bell labs in 1981. he received his ph.d. from boston university in applied physics. he beganworking in wireless in 1988. since then he has been involved in andresponsible for all aspects of wireless system and radio design.richard taylor is a principal scientist at hewlettpackard laboratories, where he leads research programs in the areas of embedded systems analysis and design, distributed media processing, systems architecture, and hardwaresoftware codesign. dr. taylor graduated with a b.sc.(honors) in computing and cybernetics from the university of kent atcanterbury, england, and a ph.d. in computer systems engineering fromthe university of manchester. following his ph.d., he worked for thechristian michelsen institute (bergen, norway) as a computer scientist,combining research and consultancy in the area of highperformance distributed and parallel computing. he joined the electronic systems department of the university of york in 1989, founded and then led the computer systems engineering group, concentrating on the design anddevelopment of novel embedded and realtime systems. in 1993 he joinedthe departments of computer science and electrical engineering at theuniversity of western michigan, again leading a team researching thedesign and application of highperformance embedded computing systems. he joined hewlettpackard in 1995. dr. taylor has published morethan 50 papers and patents in the areas of embedded, parallel, and distributed computing.jim waldo is a distinguished engineer with sun microsystems, wherehe is the lead architect for jini, a distributed programming system basedon java. before that, he worked in javasoft and sun microsystems laboembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.appendix a213ratories, where he did research in the areas of objectoriented programming and systems, distributed computing, and user environments. before joining sun, dr. waldo spent 8 years at apollo computer and hewlettpackard working in distributed object systems, user interfaces, class libraries, text, and internationalization. while at hp, he led the design anddevelopment of the first object request broker and was instrumental ingetting that technology incorporated into the first omg corba specification. he edited the book the evolution of c++: language design in themarketplace of ideas (mit press) and was the author of the java advisorcolumn in unix reviewõs performance computing magazine. dr. waldo isan adjunct faculty member of harvard university, where he teaches distributed computing in the department of computer science. he receivedhis ph.d. in philosophy from the university of massachusetts (amherst).he also holds m.a. degrees in both linguistics and philosophy from theuniversity of utah. he is a member of the ieee and acm.embedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.214bbriefers at plenary meetingsdecember 12, 1999jerry linn, national institute of standards and technology (nist)srikanta kumar, defense advanced research projects agency (darpa)karen sollins, national science foundation (nsf)janos sztipanovits, darpadavid l. tennenhouse, intel corporationellison c. urban, darpafebruary 2829, 2000andrew berlin, xerox palo alto research center (parc)janusz bryzek, maxim integrated products, inc.robert dolin, echelon corporationjohn hines, national aeronautics and space administration (nasa)rodger lea, sony distributed systems laboratoryk. venkatesh prasad, ford research laboratoryapril 1718, 2000david d. clark, massachusetts institute of technologyalan davidson, center for democracy and technologyshankar sastry, darpajonathan smith, university of pennsylvaniaembedded, everywhere: a research agenda for networked systems of embedded computerscopyright national academy of sciences. all rights reserved.appendix b215june 2223, 2000keith uncapher, corporation for national research initiativesmarch 2021, 2001stephen p. boyd, stanford university