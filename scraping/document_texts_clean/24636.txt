detailsdistribution, posting, or copying of this pdf is strictly prohibited without written permission of the national academies press. (request permission) unless otherwise indicated, all materials in this pdf are copyrighted by the national academy of sciences.copyright © national academy of sciences. all rights reserved.the national academies pressvisit the national academies press at nap.edu and login or register to get:œ œ 10% off the price of print titlesœ special offers and discountsget this bookfind related titlesthis pdf is available at sharecontributorshttp://nap.edu/24636cryptographic agility and interoperability: proceedings of aworkshop90 pages | 8.5 x 11 | paperbackisbn 9780309453530 | doi 10.17226/24636anne frances johnson and lynette i. millett, rapporteurs; cyber resilienceworkshop series committee; forum on cyber resilience; computer science andtelecommunications board; division on engineering and physical sciences;national academies of sciences, engineering, and medicinecryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.the national academies press 500 fifth street, nw washington, dc 20001this project was supported by the national science foundation under award number cns14194917 and the national institute of standards and technology under award number 60nanb16d311. any opinions, ndings, conclusions, or recommendations expressed in this publication do not necessarily re˚ect the views of any organization or agency that provided support for this project.digital object identier: 10.17226/24636copyright 2017 by the national academy of sciences. all rights reserved.printed in the united states of americanational academies of sciences, engineering, and medicine. 2016. cryptographic agility and interoperability: proceedings of a workshop. forum on cyber resilience workshop series. washington, dc: the national academies press. doi:10.17226/24636.reports document the evidencebased consensus of an authoring committee of experts. reports typically include proceedingsstatements and opinions contained in proceedings are those of the participants and are not necessarily endorsed whatwedo.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.workshop seriesforum on resilience cyber cryptographic agility  and interoperability proceedings of a workshopanne frances johnson and lynette i. millett, rapporteurscryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.the national academy of sciences was established in 1863 by an act of congress, signed by president lincoln, as a private, nongovernmental institution to advise the nation on issues related to science and technology. members are elected by their peers for outstanding contributions to research. dr. marcia mcnutt is president.the national academy of engineering was established in 1964 under the charter of the national academy of sciences to bring the practices of engineering to advising the nation. members are elected by their peers for extraordinary contributions to engineering. dr. c. d. mote, jr., is president.the national academy of medicine (formerly the institute of medicine) was established in 1970 under the charter of the national academy of sciences to advise the nation on medical and health issues. members are elected by their peers for distinguished contributions to medicine and health. dr. victor j. dzau is president.the three academies work together as the national academies of sciences, engineering, and medicine to provide independent, objective analysis and advice to the nation and conduct other activities to solve complex problems and inform public policy decisions. the national academies also encourage education and research, recognize outstanding contributions to knowledge, and increase public understanding in matters of science, engineering, and medicine. learn more about the national academies of sciences, engineering, and medicine at www.nationalacademies.org. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.iiicyber resilience workshop series committeefred b. schneider, nae,1 cornell university, chairanita allen, nam,2 university of pennsylvaniaeric grosse, google, inc.butler w. lampson, nas3/nae, microsoft corporationsusan landau, worcester polytechnic institutestafflynette i. millett, director, forum on cyber resilienceemily grumbling, program ofcershenae bradley, administrative assistantforum on cyber resiliencefred b. schneider, nae, cornell university, chairanita allen, nam, university of pennsylvaniabob blakley, citigroup, inc.fred h. cate, indiana universitydavid d. clark, nae, massachusetts institute of technology richard j. danzig, center for a new american security eric grosse, google, inc.david a. hoffman, intel corporation paul c. kocher, nae, cryptography research division, rambus, inc.  tadayoshi kohno, university of washingtonbutler w. lampson, nas/nae, microsoft corporationsusan landau, worcester polytechnic institutesteven b. lipner, independent consultantdeirdre k. mulligan, university of california, berkeleytony w. sager, center for internet securitywilliam h. sanders, university of illinois, urbanachampaign stefan savage, university of california, san diegopeter swire, georgia institute of technologydavid c. vladeck, georgetown universitymary ellen zurko, cisco systems, inc.ex ofciodonna f. dodson, national institute for standards and technologyjames kurose, national science foundationwilliam b. martin, national security agencystafflynette i. millett, director emily grumbling, program ofcerkatiria ortiz, research associateshenae bradley, administrative assistantfor more information about the forum, see its website at http://www.cyberforum.org, or email the forum at cyberforum@nas.edu.1national academy of engineering.2national academy of medicine.3national academy of sciences.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.ivcomputer science and telecommunications boardfarnam jahanian, carnegie mellon university, chair luiz andre barroso, google, inc. steven m. bellovin, nae, columbia universityrobert f. brammer, brammer technology, llcedward frank, cloud parity, inc.laura haas, nae, ibm corporationmark horowitz, nae, stanford universityeric horvitz, nae, microsoft researchvijay kumar, nae, university of pennsylvaniabeth mynatt, georgia institute of technologycraig partridge, raytheon bbn technologiesdaniela rus, nae, massachusetts institute of technology fred b. schneider, nae, cornell universitymargo seltzer, harvard universityjohn stankovic, university of virginiamoshe vardi, nas/nae, rice universitykatherine yelick, university of california, berkeleystaffjon eisenberg, director lynette i. millett, associate director virginia bacon talati, program ofcershenae bradley, administrative assistantjanel dear, senior program assistantemily grumbling, program ofcerrenee hawkins, financial and administrative managerkatiria ortiz, research associate for more information on cstb, see its website at http://www.cstb.org, write to cstb,national academies of sciences, engineering, and medicine, 500 fifth street, nw,  washington, dc 20001, call (202) 3342605, or email the cstb at cstb@nas.edu.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.vprefacethe forum on cyber resilienceša roundtable established in 2015 by the national academies of sciences, engineering, and medicinešfacilitates and enhances the exchange of ideas among scientists, practitioners, and policy makers who are concerned with urgent and important issues related to the resilience of the nation™s computing and communications systems, including the internet, other critical infrastructures, and commercial systems. forum activities help to inform and engage a broad range of stakeholders around technology and policy issues related to cyber resilience, cybersecurity, privacy, and associated emerging issues. a key role for the forum is to uncover and explore topics that can help advance the national conversation. during our early discussions exploring technical aspects of cyber resilience, the question of how to deploy systems whose cryptographic elements would be resistant to eventual quantum computers arose. further discussion made clear that because we are all highly dependent on widely deployed cryptosystems, there is a complex, rich set of issues, beyond the potential impact of quantum computers, that affects how resilient our information and communications systems are (or could be) with regard to the cryptographic components used to ensure data secrecy, integrity, and authenticity. cryptographic agility encompasses not just what can be done about the prospects of quantum computing breaking widely deployed publickey cryptography, but also how to address newlydiscovered ˚aws in longdeployed cryptographic components such as secure sockets layer/cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.vitransport layer security (ssl/tls)1 (the technology that secures links between web servers and browsers), as well as challenges related to nationstate preferences for homegrown cryptographic suites in commodity operating systems. cryptographic agility thus not only poses difcult technical challenges, but also has economic and foreign policy implications. to explore these issues further, the forum decided to host a workshop. a planning group has been appointed to oversee the forum™s workshop series. this workshop, held on may 9, 2016, in washington, d.c., featured invited speakers from government, the private sector, and academia. this workshop proceedings summarizes the presentations made by invited speakers and remarks made by workshop participants, as well as the ensuing discussions. in keeping with the workshop™s exploratory purpose and the national academies™ guidelines, this proceedings does not contain ndings or recommendations, nor does it necessarily re˚ect consensus views of the workshop participants or planning committee. the planning committee™s role was limited to organizing the workshop, and the workshop proceedings has been prepared by the workshop rapporteurs and forum staff as a factual summary of what occurred at the workshop. the introduction provides an overview of the workshop and reproduces background material provided to all participants. chapters 1 through 5 summarize speaker presentations. note that although the chapter headings re˚ect the titles given to these sessions at the workshop, most speakers covered many aspects of the topic. chapter 6 describes the content of the nal plenary discussion, highlighting some of the broader themes that emerged throughout the workshop. the workshop agenda and participants list are provided in appendix a. short biosketches of the planning committee and speakers appear in appendixes b and c, respectively. we hope that the workshop and this proceedings will encourage the exchange of ideas and fresh thinking about the critical cryptographic technologies that underpin much of our economy and critical infrastructure. my sincere thanks to the planning committee, forum members, and staff who planned and organized the workshop as well as the invited speakers for their thoughtful remarks and enthusiastic participation in the discussions that ensued. writing support was provided by anne frances johnson and kathleen pierce, creative science writing. we also extend our appreciation to the national science foundation, the national security agency, the special cyber operations research and engineering working group, and the national institute of standards and technology for their support and encouragement of forum activities.   fred b. schneider, chair forum on cyber resilience1ssl and tls are two names for the same family of security protocols. sslv2 and sslv3 were developed by netscape and the name of the protocol was changed to tlsv1 when it was standardized by (and change control moved to) the internet engineering task force.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.viicontentsworkshop introduction 1 opening remarks 1 workshop context and charge 41 context 7 cryptography: if and when it breaks 7 lessons learned from realworld cryptography 112 government and infrastructure 19 how the national institute of standards and technology thinks  about cryptography 19 cryptography through the years 243 standards and security implications 29 rfc 7696: guidelines for cryptographic algorithm agility and  selecting mandatorytoimplement algorithms 29 cryptographic agility in the real world 344 engineering at scale and user implications 39 transport layer security and the downsides of agility 39 extensibility and agility 44 the importance of the human factor in cryptographic agility 495 research, industry, and policy implications 53 agility is essential (but extremely challenging) 53 agility and the need to prepare for failure 57cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.viii6 discussion and wrapup 62 planning for an uncertain future 62 technical solutions 63 sharing expertise 64 international issues and human rights 65 agility beyond cryptography 66appendixes 67a workshop agenda and participants list 68b planning committee biographies 71c speaker biographies 74cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.ixacknowledgment of reviewersthis workshop proceedings has been reviewed in draft form by individuals chosen for their diverse perspectives and technical expertise. the purpose of this independent review is to provide candid and critical comments that will assist the institution in making its published proceedings as sound as possible and to ensure it meets institutional standards for objectivity, evidence, and responsiveness to the project™s charge. the review comments and draft manuscript remain condential to protect the integrity of the deliberative process. we wish to thank the following individuals for their review of this proceedings:paul kocher, cryptography research division, rambus, inc., nae,1brian lamacchia, microsoft corporation,john manferdelli, google, inc., and jr rao, ibm corporation.although the reviewers listed above have provided many constructive comments and suggestions, they were not asked to endorse the views presented at the workshop, nor did they see the nal draft of the proceedings before its release. the review of this report was overseen by samuel h. fuller, analog devices, inc., nae, who was responsible for making certain that an independent examination of this proceedings was carried out in accordance with institutional procedures and that all review comments were carefully considered. responsibility for the nal content of this proceedings rests entirely with the authors and the institution.1national academy of engineering.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.1workshop introductionthe forum on cyber resilience of the national academies of sciences, engineering, and medicine hosted a workshop on cryptographic agility and interoperability at its spring 2016 meeting, on may 9, 2016, in washington, d.c.  the workshop featured 11 speakers who addressed various aspects of cryptographic agility and interoperability. these distinguished researchers, computer scientists, and industry leaders shared their diverse experiences and expertise related to the history and practice of cryptography, its current challenges, and its future possibilities. they also asked questions, probed assumptions, and explored uncertainties when dealing with cryptography. the meeting was open to the public. this proceedings was created from the presenters™ slides, the rapporteurs™ notes, and a full transcript of the workshop; it is intended to serve as a public record of the workshop presentations and discussions. opening remarksfred b. schneider, samuel b. eckert professor of computer science at cornell university, member of the national academy of engineering, and workshop chair, opened the meeting with a brief description of the national academies™ forum on cyber resilience. the forum convenes experts from various backgrounds to examine the complicated issues cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.2surrounding cybersecurity and, more broadly, cyber resilience. the forum offers experts in technology, policy, and research an opportunity to discuss critical emerging issues or raise topics that are insufciently addressed or perceived to be underappreciated. although the forum does not conduct traditional national academies™ studies, schneider noted that forum members and the ideas discussed at workshops hosted by the forum can lead to the creation of such studies when deemed appropriate. schneider noted that this workshop focused on challenges surrounding cryptographic agility and interoperability. cryptography is the creation of codes or algorithms to secure communications. cryptographic agility refers to how easy it is to evolve or replace the hardware, software, or entire information technology (it) systems being used to implement cryptographic algorithms or protocols (and, in particular, whether the resulting systems remain ﬁinteroperableﬂ). although cryptographers and computer systems designers might be condent in their work and may not see a strong need for cryptographic agility, ﬁthe reality is that we now know that cryptography breaks,ﬂ schneider said.for example, schneider cited concerns about the possibility of quantum computersštechnologies in very early research stages that would employ a fundamentally different approach from today™s computers. if quantum computing becomes a reality, today™s publickey cryptography systemsšwhich are the basis for securing electronic communications in open environments such as the internetšwould be vulnerable to compromise. agility would make defense against the emergence of quantum computers easier because it would allow simple substitution of quantumresistant publickey algorithms for today™s widely deployed (and quantumsusceptible) algorithms.schneider also drew attention to some immediately practical issues, beyond developing defenses against hypothetical quantum computers, that improvements in cryptographic agility could help address. for example, what happens when foreign nations or other entities want to add their own cryptographic suites to commodity software, instead of using cryptographic approaches provided by the manufacturer? support for this kind of change requires cryptographic agility in the deployed systems. the prospect of deploying more agile cryptography systems also raises some hard questions about trust: who should be authorized to change cryptography in a deployed system? schneider noted that changing cryptography systems can typically cause ﬁreally annoying little headaches,ﬂ such as the need to change key size or format, and the difculty and expense of replacing cryptographic code that pervades several layers of software. such headaches are actually symptoms of a broader set of issues that encompasses not only engineering and design problems but also questions of trust, policy, and even foreign relations, schneider said. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.3despite this broad set of issues, schneider noted that there has not yet been much discussion of this topic outside of highly technical communities. the intent of this workshop is to help explore the issues, educate a wider community, and identify where further work is needed. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.4the following information was provided to workshop speakers and attendees to offer context on cryptographic agility and interoperability and to provide a structure for the workshop and its intended purposes.backgroundthis workshop is an activity of the national academies™ forum on cyber resilience. the forum on cyber resilience facilitates and enhances the exchange of ideas among scientists, practitioners, and policy makers who are concerned with urgent and important issues related to the resilience of the nation™s computing and communications systems, including the internet, other critical infrastructures, and commercial systems. forum activities help to inform and engage a broad range of stakeholders around issues related to technology and policy in the context of cyber resilience, cybersecurity, privacy, and related emerging issues. a key role for the forum is to surface and explore topics that can help advance the national conversation. this workshop focuses on the topic of cryptographic agility and interoperability. additional context and questions to consider for discussion are below. contextwe rely on established cryptographic algorithms, protocols, and implementations to secure our data and communications. greater agility with respect to cryptosystems could potentially help stakeholders better adjust to rapidly changing cybersecurity and privacy landscapes. for example, security leaders might desire the ability to quickly substitute one algorithm, protocol, or implementation for another following the discovery of signicant weakness. individual users may desire the ability to customize the security and speed of their communications, depending on the nature of their use. governments may wish to set their own standards, especially if they do not trust those developed by other entities. achieving such agility, however, poses both technical and policy challenges. generally although cryptographic algorithms and protocols are being deployed in an ever wider array of systems, our understanding of how to achieve agility, when to prioritize it, and how best to deploy it is limited. today, some widely used systems have elements of cryptographic agility. for example, the widespread practice of software updates has been a way to achieve a measure of agility by allowing changes to be made through the deployment of security patches. some protocols, including ssl/tls and ssh, allow implementations to negotiate algorithm combinations. however, the authenticity and integrity of the software update mechanisms or negotiation processes are themselves ensured with cryptographyšwhich may or may not be agile. today, our understanding of how cryptosystems can improve agility, as well as the associated limitations and risks, remains limited. there are two main technical problems that have to be solved to achieve agility in practice. the rst is deployment: how to securely deploy new code to all the places where it needs to run. the second is selection: how to choose the cryptographic suite to use; it must be one that all the parties to the communication can handle, and it must meet the requirements of all the applications and legal jurisdictions involved.deployment itself needs cryptography to authenticate that the new code that is received and installed is what was intended. how can we make this cryptography itself agile? in addition, code that implements cryptographic algorithms and protocols runs in many different kinds of endpoints, in some cases in special purpose hardware such as network interface controllers and trusted platform modules. how can we create code that can run in all these endpoints, and how can we ensure that it gets deployed to all of them? workshop context and chargecryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.5an endpoint can usually run several different cryptographic suites so that it can talk to a variety of other endpoints (including old ones), meet legal or contractual requirements, or make tradeoffs between security and performance. today the application and the operating system together specify a set of acceptable suites for each endpoint, and the endpoints together try to select the ﬁbestﬂ suite that is acceptable to all of them. both of these processes are complicated and poorly specied, and have given rise to many bugs. how can we design a selection mechanism that meets these needs, is understandable, and is implemented correctly? what mechanisms can we put in place to protect against defaulting to the weakest algorithm in the set?challenges related to cryptographic agility cover the following areas: ł cryptographic algorithmsšalgorithmspecic cryptanalytic advances or fundamentally new techniques (such as quantum computing) may necessitate algorithm replacements; ł cryptographic protocolsšupdates to how cryptographic protocols negotiate and use cryptographic methods and other agreements may be needed to address security issues or to add/remove functionality;ł endpointsšcryptographic implementations in endpoint devices and systems range from more agile approaches (such as updatable software) to more robust but less agile approaches (such as implementations in hardware);ł key managementšchanges to how keys and credentials are generated, exchanged, stored, replaced, and revoked may be desired;ł trusted partiesšsome agility mechanisms rely on trusted third parties, such as product developers or certication authorities, to produce and distribute updates; andł usersšsome agility mechanisms depend on user involvement, for example to make conguration decisions, resolve security alerts, or consent to updates, while some devices (such as ﬁinternet of thingsﬂ devices) lack any user interface.separate from the technical challenges are questions of prioritization and economic tradeoffs. when is it appropriate to design for agility and when might an emphasis on designing for truly longterm security be appropriate? for instance, for some critical applications it may be preferable to deploy cryptography that can persist and be secure for a century and those who need such security would have to be willing to tolerate signicantly reduced performance to do so. moreover, although on the surface decisions related to cryptographic agility appear technical, there are economic tradeoffs in the decision to support multiple standards. it is not obvious that these tradeoffs have been well understood or assessed in the past.the workshop was designed to feature presentations on the drivers and technical and societal implications of increased cryptographic agility, addressing the following:ł motivations for and benets of increased agility (security, technical, social, political),ł challenges to implementation (technical, social, political), and ł impacts (security, technical, social, political).cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.6discussion questions for speakers and participants to considerwhy is cryptographic agility useful and what are its potential risks and impacts? what approaches have been attempted for improving cryptographic agility, and how successful have they been? for example, how easy is it today to replace defeated or outdated cryptographic tools in widely deployed commercial software and systems? how should the tradeoff be made between supporting multiple algorithms (thus enabling agility in case of future problems) and supporting fewer algorithms? how does that tradeoff differ by domain? what economic, social, and policy factors enter into that decision?what are the consequences of supporting cryptographic agility on legacy data and systems? what are the tradeoffs related to continuity (e.g., allowing continued use of existing encrypted, signed, or hashed data) and compatibility (such as systems having varying conguration settings and update status) when cryptographic regimes are deprecated?how might more control over (and more variation in) cryptographic routines affect trust in systems by individuals, companies, and governments? for example, are there ways to address concerns that updates may (accidentally or intentionally) create new security vulnerabilities?does the complexity of agility mechanisms themselves or the security modes they enable create security risks?how might privacy and human rights be affected by cryptographic agility?what likely market or economic drivers affect how and whether companies support and improve cryptographic agility in their products? what might happen if support is not maintained for deprecated routines given longerlasting embedded systems, such as found in internet of things devices?what are likely geopolitical drivers of more cryptoagile systems, and what might be the impacts on the global internet and international politics?what are the consequences of cryptographic agility for the interoperability and usability of communications systems?how and on what basis should efforts to improve cryptographic agility be prioritized? what are the key opportunities for standards bodies, governments, researchers, systems developers, and other stakeholders with regard to cryptographic agility? cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.71 contextthe rst two speakers, bob blakley and paul kocher, addressed contexts for cryptographic agility, including the likelihood that cryptographic systems fail as well as the potential sources, causes, and consequences of such failure. kocher also described lessons learned from realworld experiences with cryptography. cryptography: if and when it breaksbob blakley, citigroup, inc.bob blakley, global head of information security innovation at citigroup, inc., emphasized that cryptographic agility is a signicant information security problem that needs to be tackled. noting that most cryptographic systems have eventually failed in use, he described deployed cryptographic systems as prime examples of technologies that are ﬁalmost always ultimately doomed to fail.ﬂ he pointed out that only one cryptographic system, the data encryption standard (des), was considered as strong at the time of its retirement as it was on the day of its release. blakley noted that a clever mathematician could, in principle, crack any cryptographic system (with the exception of a onetime pad) and compromise signicant portions of the current cryptographic infrastructure. in addition to being vulnerable to cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.8breakthroughs in traditional cryptanalysis, many publickey cryptography systems would also be vulnerable to attack by a quantum computer. exploring this issue further, he discussed why vulnerabilities in cryptographic systems are a signicant potential challenge. most of the time, attacks against the underlying cryptographic components of cryptographic systems result in immediate vulnerabilitiesšmathematical problems that weaken the system and can only be xed by replacing the entire cryptographic system. blakley estimated that completely replacing a widely deployed system would take at least 3 yearsšassuming that there is already a welltested replacement system ready for deployment. the timeline would expand to 10 years or more, he said, if a new cryptographic approach had to be developed from scratch starting at the time of the discovery of the vulnerability in the old system. as a result, he said, ﬁit is important to look a long way ahead if you begin to suspect that there might be a problem.ﬂ although attacks occur suddenly, the necessary repairs can take years.replacing a system completely takes a long time because it requires an enormous amount of work. blakley described some of the necessary steps: a new cipher would have to be invented, put through a battery of tests, and standardized for wide use. then it would have to be implemented in a variety of cryptographic libraries; hardware would need to be updated to support it; and then it would have to be bought, deployed in actual products, purchased, and put into use. meanwhile, the old, broken systems would have to be retired so no vulnerabilities would be left behind. unfortunately, no one can predict when a cryptographic system will break, but given the years it would take to roll out new cryptographic systems, the need for improved agility is apparent. the federal government has begun thinking about this challenge, in particular the potential need for quantumresistant cryptography. blakley noted that the national security agency recently issued a document encouraging developers to plan for quantumsafe cryptographic systems.1 the national institute of standards and technology also recently announced an effort to select and standardize quantumsafe cryptographic algorithms.2 blakley said experts put the timeline for developing new cryptographic systems, including standardization and deployment, at roughly 10 years. however, the pace is clearly in˚uenced by perceived urgency, which varies depending on how far off one thinks quantum computing is. blakley pointed out that smaller quantum computers already exist, comprised of on the order of 5 qubits, but he suggested the timing of the 1fuzzy, ﬁnsa switches to quantumresistant cryptography,ﬂ february 8, 2016, https://www.deepdotweb.com/2016/02/08/nsaswitchestoquantumresistantcryptography/.2national institute of standards and technology, ﬁnist kicks off effort to defend encrypted data from quantum computer threat,ﬂ last update september 21, 2016, http://www.nist.gov/itl/csd/nistkicksoffefforttodefendencrypteddatafromquantumcomputerthreat.cfm. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.9development of a quantum computer capable of breaking something like rsa 2048, an extremely strong encryption system, ﬁis a good deal more uncertain.ﬂ it is also conceivable that a quantum computer containing more than a few qubits will turn out to be too challenging to develop. blakley pointed to a recently published comparison of optimistic and pessimistic hypotheses in which the author, a mathematician, concludes that quantum computing on a practical scale is unlikely to be possible for physical reasons.3 industry giants microsoft, google, and ibm, on the other hand, are optimistic; all are working on building a quantum computer, and they predict success within 4 to 10 years. blakley noted google™s claim that a company called dwave has built a special purpose quantum computer, although it is unclear whether its speed comes from quantum mechanics or just extremely fast digital computing. as a systems security expert, blakley said he is less focused on the potential benets of quantum computing and more concerned about what it could break. it is a common belief that widely deployed publickey cryptographic systems would be ﬁrendered totally uselessﬂ in the context of quantum computing, he said. symmetrickey cryptography (which is based on shared secrets) would also be vulnerable to the incredible speed with which quantum computers could break encryption codes designed to resist slower traditional computers. blakley observed that this vulnerability could be mitigated by increasing symmetrickey cryptosystem key lengths by a factor of at least two; key expansion seems to be considered by cryptosystem designers more feasible than it has been in the past. what is at stake if current cryptographic systems are rendered ineffective? publickey systems, server authentication infrastructure, personal computer updates, digital signature systems, and, most worrisome to blakley, our system integrity infrastructure (i.e., code signing) would all be compromised. all of these systems, which play crucial roles in global nance, personal privacy, and national security, depend on the integrity of publickey cryptographic systems. more concretely, banking and ecommerce protocols are among the software systems that rely heavily on publickey distribution systems and, like other public keyœbased systems, would be at risk if current cryptographic systems were broken by a quantum computer. given the level of disruption, and the fact that trillions of dollars are transacted 3g. kalai, 2016, the quantum computer puzzle. american mathematical society, notices of the american mathematical society 63(05): 508516. what is at stake if current cryptographic systems are rendered ineffective?cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.10using banking and ecommerce protocols protected by publickey cryptography, blakley surmised that ﬁit does not seem farfetched that an economically rational attacker would be willing to spend a billion dollars to build a quantum computer.ﬂeven if quantum computers turn out to be impossible to build, blakley asserted that it is plausible to believe that there will be future ﬁmathematical land minesﬂ that could weaken publickey cryptographic systems without any help from a quantum computer.what is the solution if current cryptographic systems break? whatever it is, blakley said, waiting 10 years is too long for comfort. a new cryptographic system should be deployment ready and easy to implement and interoperate withšwhich, blakley reiterated, is a monumental task.blakley closed by underscoring the risks and consequences of cryptographic failure. noting that in the original greek, the word ﬁapocalypseﬂ meant ﬁthe day that all secrets will be revealed,ﬂ he said the end of today™s cryptographic systems would be a literal apocalypsešan ﬁinstantaneous, simultaneous global failureﬂ of all information security. he emphasized that it is very difcult to calculate the risk of such an event. widespread simultaneous cryptographic failure is a ﬁblack swanﬂ problem: because it has never happened, there is no way to calculate when it might happen. blakley also likened it to an asteroid hitting earth: while it may not be very likely to happen, that does not mean that one should not plan for it. finally, blakley summarized the message of the sherlock holmes story ﬁthe adventure of the dancing menﬂ: ﬁwhat the mind of one man can invent, another can discover.ﬂ because people can conceive of quantum computing and other forms of codebreaking, he said, ﬁi think it would pay for us to be worried about the discovery of something that would vitiate all of our publickey infrastructure and to start planning for that.ﬂ he concluded by expressing his hope that something to more readily allow changes in cryptography infrastructure as circumstances warrant would be developed by the year 2020.peter swire, georgia institute of technology, opened the discussion by asking blakley to speculate on the probability of a signicant break of widely deployed cryptography. reiterating his belief that it is impossible to quantify the risk, blakley said he prefers to plan for the worstcase scenario, which in his view means assuming that a quantum computer will be operational by the end of 2020. fred schneider, cornell university, secure communication involves the math, the code, and the trust we put in institutions.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.11commented that whether or not quantum computers become a reality, cryptographic systems will still break, and cryptographic agility will still be required. anita allen, university of pennsylvania law school, questioned whether it might be prudent to more precisely dene the term ﬁcryptographic systems.ﬂ blakley suggested a need for a deeper discussion of this topic but noted his belief that it would be helpful to expand beyond cryptographic systems as formally dened when thinking about secure communication. butler lampson, microsoft corporation, pointed to three levels involved in secure communication: the math, the code, and the trust we put in institutions to authenticate our communication, each of which is subject to compromise. these three levels and their differences create confusion in the cryptography discussion, he said.lynette millett, national academies, noted that although the wellknown y2k bug once seemed like a huge problem requiring signicant engineering effort, it was successfully resolved in time to avoid major issues. she asked whether there are lessons for policy makers and engineers that could be drawn from that experience and how the effort required to solve that comparatively simple problem compares to what would be needed for effective cryptographic agility. blakley noted that companies like ibm began working on the y2k issue in the early 1980s, suggesting that much time and work were required to x it.paul kocher, cryptography research division, rambus, inc., brought up another ramication of quantum computing or the discovery of another signicant weakness: its potential ability to retroactively cause cryptographic breaks and decrypt any encrypted material that has been saved. that is, if data have been encrypted and stored under a particular cryptographic system, and that system is broken, all of those data are now vulnerable to exposure. some data, such as that pertaining to national security and the identity of spies, require longterm protection. the potential vulnerability of this information, he noted, increases the urgency of making cryptographic systems quantum safe. lessons learned from realworld cryptographypaul kocher, cryptography research division, rambus, inc.paul kocher is the president and chief scientist at rambus™ cryptography research division. his presentation focused on the questions, challenges, and lessons learned from his time designing systems for use in the eld. kocher cautioned, however, that while creating and implementing agility mechanisms brings benets, it can also open up new risks and cause other complications. he expressed mixed feelings about the tradeoffs of developing agile cryptographic systems, noting that his experience has left him ﬁvery cynical, but also optimistic.ﬂ beyond the cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.12threat of quantum computing discussed by blakley, kocher emphasized that there are many other reasons to want security mechanisms to be agile. in addition to technical aspects, he noted that agility also has legal, moral, and policy implications, and powerful economic forces can in˚uence whether agility mechanisms succeed or fail. kocher shared three cryptography case studies from his work to illustrate both positive and negative outcomes: improving the secure sockets layer/transport layer security (ssl/tls) protocol, combating piracy of pay television, and securing copyrighted material on bluray discs. the secure sockets layer/transport layer security protocolin 1996, kocher was asked by netscape to help x the poorly designed sslv2 protocol, which direly needed to be upgraded or replaced. the task was enormous and full of uncertainties: what were the technical requirements? how quickly could a replacement be prepared? could the new solution support the current cryptographic algorithms (known as ﬁbackward compatibilityﬂ)? kocher described how it quickly became clear that there would be no ﬁgoldilocksﬂ solution. each algorithm under consideration worried different parties. netscape had signed an agreement with the department of defense that required the use of fortezza, a cryptographic system specially created for classied information but with a key escrow mechanism that would be unacceptable for commercial use. triple des was slow and had problems with its modes of operation. rivest cipher 4 (rc4) was currently in widespread use but was not adequately reviewed. the rsa publickey cryptosystem was constrained by patents. in short, there was no single ﬁgood and reliableﬂ algorithm to which he could turn. ultimately, the team was unable to select any single combination of algorithms that functioned as well as it wanted; the problem was just too large for its time. rsa keys were too small to be effective over the long term, and only newer algorithms, which kocher saw on the horizon but had not been created yet, could build something more reliable and durable.kocher also noted that legal export restrictions further compounded the challenge. u.s. export restrictions at that time required that ﬂexportﬂ versions of browsers and servers support only short, insecure key sizes. at the same time, customers in areas like banking and ecommerce needed strong security. complicating matters, nonexport servers needed to be able to fall back to weak cryptography when communicating with exportable browsers, and nonexport browsers needed to be able to fall back to weak cryptography when communicating with exportable serversšbut these mechanisms needed to prevent attackers from tricking nonexport browsers into using breakable cryptography with nonexport servers.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.13while cryptographic agility mechanisms needed to be created to address the protocol™s needs, kocher was unable to nd any applicable agility research to guide his team. rather, he discovered that sslv2 and other existing protocols typically could be tricked into using the security of the worst supported congurations. this was one of the reasons he decided to work on sslv2™s replacement, sslv3, essentially from scratch.first, kocher said, the team decided not to design the protocol to negotiate every setting separately. with all the different combinations and possible interactions among encryption algorithms, modes of operations, authentication algorithms, and key sizes, some were bound to combine negatively. compatibility problems also had to be addressed, such as cases where some hardware might support only certain key sizes for a particular algorithm. the sslv3 cipher suite approach is designed to address compatibility. each cipher suite species a permitted conguration, typically including an encryption algorithm (and its mode of operation), an authentication algorithm (e.g., message authentication code [mac]), and the associated key size. a cipher suite negotiation mechanism was also dened so that a client and server would select the strongest cipher suite they have in common. however, if the only algorithms a client and server have in common are insecure ones (e.g., because one or both allowed only weak exportable cryptography), then the ﬁbestﬂ option could be very weakšor have no encryption at all. (sslv3 denes cipher suites that include integrity checks but no encryption.)in the actual ﬁhandshakeﬂ process used in sslv3, the client sends the server a list of all cipher suites it will accept in the order of the client™s preference, and the server chooses one from the client™s given list. if the messages exchanged between the client and server are correct (and unmodied by an attacker), the protocol clearly works as intended. (the ssl/tls protocol does not attempt to protect against badly behaved clients or servers making bad choices.) an active maninthemiddle attacker could modify the client™s list and/or the server™s selection, tricking them into agreeing on a mutually supported option that is weaker than the one they would otherwise choose. to deal with this case, the parties include the negotiation messages in computing macs, thwarting the attack. with this negotiation approach, kocher said, ﬁif things are done right, you end up with the strongest combination that they both support, and it works pretty well.ﬂ on the other hand, kocher pointed out that if either the server or the client is not completely backward compatibility is a doubleedged sword.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.14secure, the entire connection will be insecure, regardless of the strength of one side™s cryptography. despite these advantages of sslv3, kocher noted some caveats. the negotiation works for symmetric (nonpublickey) algorithms, but if the client or server supports weaker public keys, those can be forced into use by an adversary. here, the publickey algorithms and key sizes are each a point of failure rather than a strong protector. an insecure connection can also result if the negotiated cipher suite is not sufciently secure. unfortunately the ultimate decision about which publickey algorithms (and their key sizes) to support, as well as the list of cipher suites to support (and their rankings), is typically made by an implementer or systems administrator. experience demonstrates that they often make poor security choices. to correct for this problem, kocher said, ﬁimplementations need to be correct and secure.ﬂ kocher emphasized the enormous complexities he encountered trying to build from scratch this realworld protocol with many challenging security, interoperability, and performance requirements. the constant push and pull, pain, and messiness of various versions of the protocol led him to believe that in the end, ﬁit may have still been too complex for our brains.ﬂ in computer security, we have often ﬁvastly overestimated our ability to understand complexity,ﬂ he said. although he conceded that the team made some design mistakes, the overall protocol has been successful and the issues have been correctable with relatively modest changes. he also noted that while academics can ignore practicalities, realworld applications cannot. agility mechanisms introduce complexity, which leads to unknown consequences; kocher expressed skepticism of any proof of security that fails to take into account the way a product or algorithm is deployed and behaves in the eld.key lessons from the secure sockets layer experiencekocher outlined some lessons learned through this arduous process. first, the ssl/tls cipher suites provide a form of agility. new suites can be added or adapted gracefully; for example, cipher suites that offer quantum resistance can be added. once standard quantumresistant cryptographic algorithms become available, he believes that dening and adding new cipher suites should be a straightforward process. unfortunately, the ability to negotiate cipher suites also has downsides. for example, the choice of which mix to support in the protocol is often made by committees, which can get mired in personal concerns or pet projects. as a result, committees can allow bad choices to ﬁmuddle along,ﬂ leading to bad decisions in the long term. in kocher™s experience, backward compatibility is also a doubleedged sword. in part because sslv3 included smooth backward compatibility with sslv2, the sslv2 protocol was not fully retired as expected. instead, many implementers left sslv2 enabled. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.15just last year, two research projects demonstrated problems in sslv2 backward compatibility mechanisms that are still present in current software versions. kocher described being ﬁjust absolutely aghastﬂ that pieces of sslv2, the protocol he was tasked to completely replace, were still around 20 years later.another solution that perhaps worked too well was sslv3™s nearuniversal adoption. other protocolsšsecure electronic transaction, secure hypertext transfer protocol, microsoft™s private communications technology, among othersšhave faded from use. kocher is unsure whether this is a good thing, in that there is less fragmentation and more consistency, or a bad thing, because other protocols could be better suited to particular use cases.another lesson stems from the idea that certicate authorities whose public keys are embedded in a web browser, for example, must all be secure for the ecosystem to be strong. when kocher was working on sslv3, verisign was the primary certicate authority, and he did not expect there to be more than a few. now, there are hundreds because economic and political pressures led browser makers to include many certicate authorities. the economic pressures of having so many certicate authorities meant that they had little budget for diligence when issuing certicates. ﬁthere was no incentive to do a good job . . . everything economically that could go wrong did,ﬂ kocher said, adding that in some cases certicate authorities found their only protable option was to issue unauthorized certicates to attackers wishing to impersonate legitimate websites. this story demonstrates how the success of cryptographic agility depends not only on sophisticated, ﬁinteresting mathﬂ (which tends to get more attention), but also on a mix of politics, economics, and policy.a nal lesson is the importance of implementation. to put it plainly, kocher stated, ﬁimplementation mistakes are the number one enemy and have been the absolutely overwhelming source of problems.ﬂ when kocher reviews a new security method, he looks for common errors that could occur during implementation and be used to bypass the security, such as bugs in universal serial bus (usb) driver software and certicate parsing routines. he admitted to regret in using the x.509 certicate format in sslv3. a cleaner certicate format could have avoided implementation mistakes but would have made sslv3 adoption more difcult since x.509 was already in widespread use. piracy in pay televisionkocher described his work on a project to prevent piracy in pay television, starting with a brief history of the evolution of pay television technology. early plaintext feeds were easily hacked by hobbyists. the next format, television settop boxes, had a relatively secure single des encryption system, but the hardware and key management were ﬁterrible,ﬂ cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.16kocher said. the united states™ legal responses eventually just drove piracy overseas, he noted, instead of addressing the technical holes that made piracy possible.the next innovation was a removable security chip, present in many of today™s settop boxes, which creates a new key for every 30 seconds or so of video coming onto the television screen. however, if something is broken in the keycreation process (e.g., the chip is hacked), the only remedy is to mail the user a replacement card, which is expensive and logistically difcult. kocher said his team has been deploying approaches that put agility mechanisms and tamperresistant hardware in the video processing chips in the settop box itself. it is an approach kocher believes is working well, though he noted that its impending broader deployment will increase pressure on the new system and likely increase attention to other security risks that will need to be addressed such as recording video from displays. kocher said a key lesson from the television piracy experience is that criminals are agile, too, and that cryptography theory cannot predict all of the practical problems that will be encountered in realworld use. pirates were able to hack the cryptographic systems in place and to continue accessing video despite the replacementcard system. for example, replacement cards often had to be readily available for consumers whose cards had been hacked, and replacement cards made without knowing the ﬁhackﬂ typically had the same vulnerabilities as the ones they were replacing. because of issues like this, kocher and his team focused heavily on preventive methods instead of relying solely on agility methods. he called the preventive approach a technological success, though it made existing vendors unhappy because they had made a prot from replacement cards. ﬁthe idea that you might have a system that does not need replacing on their planned revenue schedule was extremely threatening for them,ﬂ kocher said, offering another example of economic interests gaining the upper hand in security decisions.it also turned out that the pay television operators were subsidizing the cost of the settop boxes and, unwittingly, making it easy for piracy to continue. a box including the security card cost about $200 to make but was being sold to customers for about $50. in this situation, kocher claimed, the pirate could buy the box with the included card, ﬁthrow the box away, hack the card, and sell it,ﬂ making a prot. kocher said this economic problem underscores the point that agility architectures can create risks that require nonagility responses. the card™s vulnerability to pirates has led some designers to eliminate the cards (and card slots) altogether. piracy of content on optical discskocher then described his experience with preventing piracy of content sold on optical discs. the original digital versatile disc (dvd) format and players each had some cryptography, but neither had any agility to deal with their inevitable vulnerabilities. pirates cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.17were able to hack the players in a way that could not be xed, leaving only unappealing choices: allow all copyrighted content issued on dvd to be pirated or issue a massive recall of dvd players, an option kocher described as ﬁtrying to control shoplifting by using nuclear weapons.ﬂ studios and dvd manufacturers never did ﬁpush the button,ﬂ and never could have, because ﬁthere was so much politics involved that nobody could actually decide what to do.ﬂ the result, he said, ﬁwas security that failed in some pretty catastrophic ways.ﬂ in this environment, kocher™s team focused on securing the bluray format and created a system where pieces of security software could be delivered on the disc itself. this approach was a hybrid of copy protection schemes from the 1980s and modern cryptography that, when a disc was inserted, required players to run a specic set of cryptographic algorithms in order for the disc to play. this system meant that it was possible for new discs to bring new security code to mitigate attacks that had appeared.in addition to helping address vulnerabilities in players, the code on the disc can also embed tiny changes in the video stream that can be analyzed forensically on pirated copies. this information can help pinpoint a pirate™s methods and craft a suitable response to them. despite these advantages, bluray players had many vulnerabilities. as a result, the renewability system became what kocher described as ﬁa whackamole system.ﬂ in addition, the business model of pirates changed. with dvd, once a free circumvention tool was released, it never needed to be changed and pirates had limited revenue opportunities. with bluray, piracy tools needed frequent updates, so hackers (usually located out of the reach of u.s. law enforcement) adopted a service model that provided them with recurring revenue. when discs with a new security method were released, it typically took time for attackers to discover and exploit it, but they eventually did. hollywood, kocher said, viewed this as benecial nonetheless because its business model favors the brandnew movie over the monthsold one. however, this security timeline is poorly suited to paid software or other data meant to be used over time, and it has serious implications for longterm classied data. kocher concluded by pointing out, ﬁyou cannot unsteal the information that is leaked.ﬂwhere strong and simple is possible, it should be pursued.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.18agility versus ﬁstrong and simpleﬂwilliam sanders, university of illinois, urbanachampaign, opened the discussion by framing the issue as a tension between agility, which is necessarily going to add some complexity, and ﬁstrong and simpleﬂ security solutions. he questioned whether a strong and simple approach is even possible in many contexts. kocher said that a simple approach is possible and benecial but only within a narrow set of problems, such as cryptographic algorithms themselves. kocher also suggested looking to older systems for ideas. for example, an old personal computer with a ˚oppy disk drive could easily be reverted to a known (presumably good) conguration simply by turning the machine off and then on again. creating a similar property in some of today™s systems should be achievable, he said. however, kocher suggested that a strong and simple method is likely not appropriate or achievable for complex systems of distributed databases, such as those involved in the ofce of personnel management breach. that said, kocher emphasized that where strong and simple is possible, it should be pursued. while the bluray solution may seem somewhat complicated, he noted that the code required thousands, but not tens of thousands, of lines of code, making it relatively strong and simple. but the economics and use cases of bluray players made it impossible to build a system that would be truly impenetrable. while there is a tension between the two approaches, kocher said they are both necessary. prevention is obviously preferred because a theft cannot be fully undone, but one also has to plan for failure. he suggested that equal attention should be paid to preventive measures and agility, as opposed to the situation he sees today, where most of the attention (and resources) are spent on repairs after security breaches. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.192 government and infrastructurethe second section of the workshop featured two speakers, kerry mckay and richard george, with extensive backgrounds working in the area of cryptography for the u.s. government. they covered the government™s use of cryptography and its standardssetting process, the evolution of cryptographic technology, and current and future challenges. how the national institute of standards and technology thinks about cryptographykerry mckay, national institute of standards and technologykerry mckay is a computer scientist in the computer security division at the national institute of standards and technology (nist). her talk focused on the process nist uses when creating cryptographic standards. cryptographic agility and interoperabilitymckay opened by outlining three facets of cryptographic agility: (1) the ability for machines to select their security algorithms in real time and based on their combined security functions; (2) the ability to add new cryptographic features or algorithms to existing cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.20hardware or software, resulting in new, stronger security features; and (3) the ability to gracefully retire cryptographic systems that have become either vulnerable or obsolete. mckay dened ﬁinteroperabilityﬂ as the ability to communicate and exchange information between systems. pursuing the double aims of agility and interoperability works in some ways but not in others, she noted. supporting a wide variety of algorithms for interoperability can increase a machine™s agility. for example, older devices can be updated with new algorithms that allow them to communicate securely with newer devices. however, interoperability can also complicate agility. it makes it harder, for example, to remove outdated protocols or algorithms such as rivest cipher 4 (rc4) and secure sockets layer (ssl) 2.0, which should be retired. some legacy systems cannot be updated because of hardware restrictions. a user might not be willing to pay to have an older machine properly secured or to give up a familiar operating system (such as windows xp) that manufacturers are no longer updating. as a result, interoperability sometimes means supporting algorithms that are not very secure. reiterating a point paul kocher raised, mckay noted the importance of recognizing the potential hazards of implementation ˚aws. supporting agility and interoperability requires more software, but that increases the number of potential security vulnerabilities and bugs, she said. in constrained environments, such as those required to manage small radio frequency identication (rfid) tags, there is not always room for all the security a device might need, making it especially important to employ the right security approach. supporting weaker algorithms instead of retiring them can also lead to what are known as ﬁdowngrade attacks,ﬂ in which hackers are able to nd and exploit known weaknesses in servers that still support these algorithms. the national institute of standards and technology processmckay turned to the standardsmaking process at nist, which seeks to balance agility and interoperability with security for nonclassied government systems. nist™s ﬁtransitions: recommendations for transitioning the use of cryptographic algorithms and key lengthsﬂ (sp800131a) outlines which cryptographic algorithms are allowed, allowed with conditions, or disallowed. for example, data encryption standard (des) is not considered secure enough to encrypt new data, but older data can be decrypted via des with a warning about its insecurity. in the case of twokey triple des, nist allowed its use for encryption only until the end of 2015 and only for limited amounts of data. in another example, nist recommends against using secure hash algorithm1 (sha1) for digital signatures. when sha1 is used for creating digital signatures on shortlived parameters within a protocol, such as ephemeral keys in transport layer security (tls), there is a very small window of opportunity for an attacker to disrupt that cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.21process. the threat changes when using sha1 in a certicate for server authentication. the data that are signed have value for a longer period of time, allowing more time for an attacker to nd a hash collision and create a fraudulent certicate and increasing the potential threat. mckay conceded that nist was not quick to make new standards. it has a small, specialized staff (though nist is, she noted, actively hiring cryptographers) and a strong focus on completing projects carefully and thoroughly. when nist determines that a new standard may be needed, the institute holds workshops and meetings with academics, government employees, industry leaders, and participants from related organizations like the international organization for standardization and the internet engineering task force. through this process, nist studies the available algorithms; determines if new ones are needed; and then develops new standards, adopts a standard that already exists, or holds a competition. the competition model has both benets and drawbacks, mckay said. it worked well for advanced encryption standard (aes) and secure hash algorithm3 (sha3), but competitions are time intensive and expensive to run. aes had 15 submissions and ran from 1997 to 2001. sha3 had 64 submissions and ran from approximately 2004 to 2015.1 because of these downsides, sometimes it is more helpful to focus on algorithms that are already in use. this option works well for block cipher modes, which add features to block ciphers that have already been standardized, with faster timelines and lower implementation cost. when nist is ready to issue new standards, they are written up in a document that goes through a long internal and external review process. if it is a federal information processing standard, the document has to make its way up several management levels before being approved by the secretary of commerce, which adds more time and complexity. this long review process underscores the importance of being thorough and deliberate when creating new standards and explains why nist cannot operate as nimbly as other entities might. those limitations, however, also mean that government systems have a high degree of interoperability because they are highly likely to have algorithms in common. adding algorithms to the approved list could complicate that interoperability because 1the idea for sha3 began in 2004 and the concept was nalized in 2015.deciding when to make a new standard is as hard as deciding whether to do so.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.22each new cryptographic system would have to be fully validated by nist before it could be used. mckay said it works well for nist, and the federal government more broadly, to have general purpose primitives and modes for special features such as authentication or data storage. mckay listed the various standards that nist recommends and uses: secure hash algorithm2 (sha2), sha3, 3des, aes, rsa, elliptic curve digital signature algorithm, digital signature standard, and hash message authentication code. they also use block cipher modes of operation to achieve condentiality, authentication, key wrapping, and format preservation. in addition, she said nist is working on new hash function modes, tentatively named keccak message authentication code, tuplehash, and parallelhash.deciding when to make a new standard is just as hard as deciding whether to do so. sometimes vendors request that nist incorporate a particular algorithm into its standards to improve their business prospects with the government, a suggestion that holds little sway with nist. ﬁin the end, our standards are geared towards the unclassied government it systems and they cannot be driven by vendors,ﬂ mckay said. sharing a story to illustrate this point, she said a recent draft document initially recommended three encryption modes. an issue was discovered in one mode, and it was left out of the nal version. this mode was repaired, but it was no longer needed because the rst two were sufcient. adding it back would have made that vendor happy, but it would have cost taxpayer money and nist time to do it. ﬁit did not align with our mission, so we decided not to do it,ﬂ said mckay. because of the intensive process of creating new standards, longevity is a key concern for nist. these standards should be built to last and possibly even to outlast the technologies that are being used today. ﬁwe have had aes around since 2001 and it is still going strong,ﬂ mckay said. ﬁthat is the kind of thing we like.ﬂfuture directionsmckay noted that newer devices are sometimes too small to have adequate security. light bulbs and rfid tags, for example, are not typically being manufactured to be secure. nist is actively researching lightweight primitives for these small devices, loosely known by the umbrella term ﬁthe internet of things.ﬂ for example, nist could add aes or another strong security mechanism, but with current approaches this would come at the expense of speed or price. quantum computing is also a concern for nist, she said. the institute is currently working to create modes to enhance functionality while using the same core primitives. as an example, sha3 includes the keccak permutation, which could be used to give users more features with less implementation overhead.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.23launching the discussion session, steven lipner, an independent consultant, asked what nist was doing to smooth transitions from one standard to another when they inevitably change. for quantum computing specically, mckay responded that nist was looking at several different designs and putting out a call for new algorithms. donna dodson, nist, suggested creating an algorithm that was resistant to both today™s attacks and future quantum attacks, although it would present key management challenges. she added that it would be even better if such an algorithm could be completed and deployable before quantum computing became a reality. mckay noted that nist does recommend transition periods in sp800131a, including considering the time a vendor needs to anticipate the change to its business.when asked by matthew green, johns hopkins university, whether nist had plans to modernize its approval process for new algorithms, mckay and dodson answered that to do so, nist would need more personnel. mckay explained that the nist team goes through the math and its proofs itself rather than outsourcing the work, which is partly why it takes so long. she expressed her belief that it is important for the institute to be involved in the technical aspects, in part because it is also nist™s duty to help policy makers understand the decisions that are being made. eric grosse asked if nist could adopt a management style similar to the one he used at google, where he strongly encouraged creators to identify which old system would be shut down whenever a new one was initiated. mckay responded that nist already uses a similar approach, citing sha3 as a result of the discovery that sha1 had problems. because they knew it would take a while, they laid the groundwork fairly quickly. in case sha2 started showing the same mathematical weaknesses as sha1, nist realized that it needed to go with a very different design. mckay also pointed to the core standards nist recommends, which rarely have more than two or three options. dodson added that nist does not have policing or enforcement power when it comes to its recommendations. when it no longer recommended sha1, some of the larger federal agencies had signicant challenges guring out where, and with which vendors, they were using this ineffective security mechanism, and it took some of them a full 18 months to replace it. mckay noted that a further complication is that some government websites must interact with the public. for example, there are some versions of tls that are allowed because publicfacing servers need to account for the security of the user™s browser. tls 1.0 is still allowed in this case, despite not being as safe as nist prefers. ﬁit is kind of hard to tell someone they cannot go to [the] social security administration web page and log in because they have to update their browser and they might not know how to do such a thing,ﬂ mckay explained. mckay closed by pointing out that creating governmenttogovernment standards is much easier than interacting with the public. there, she said, ﬁthe water gets muddy really quickly.ﬂ cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.24cryptography through the yearsrichard george, the johns hopkins university, applied physics laboratoryrichard ﬁdickieﬂ george, currently a senior advisor for cybersecurity at the johns hopkins university applied physics laboratory, has had a long career in the eld of information security. he spent more than 30 years at the national security agency (nsa), including 8 years as the technical director at the nsa™s information assurance directorate, a capacity in which he often confronted problems of resilience and agility. he presented a history of cryptographic technology in the government sphere. while businesses may balk at the costs of repairing security, the uncomfortable truth is that all cryptography does eventually break. re˚ecting on 45 years in the eld, george emphasized how essential, yet complex, the issues of cryptographic resilience and agility are and underscored the urgent need to continually work on these issues as technology evolves. early cryptographygeorge began with an overview of vinson, a voice encryption device for military radios. vinson™s initial objective was to encrypt radio communication between a forward observer and up to six contacts. the cryptography behind vinson went through a lengthy design and testing process, spanning nearly two decades from its initiation in 1957 to the system™s approval for use in 1976. the results have been lasting: ﬁit is still secure as far as we can tell,ﬂ said george. ﬁit has never had any modicationsšthat is a pretty good run.ﬂbecause of the limited purpose of vinson, interoperability was not an issue. radios with vinson were not intended to communicate with receivers on satellites, bases, or ghter jets. ﬁthat made it very simple to design only the bare minimum functionality into that system that we needed,ﬂ george said. also, before 1973, software and computers were not considered secure enough to contain cryptography as it existed at the time, so vinson was designed only for the realm of radio. the limited nature of vinsonequipped devices™ functionality had the added benet of keeping communication secure. ﬁfunctionality,ﬂ george cautioned, ﬁis opportunity for the adversary.ﬂthe ﬁagilityﬂ mechanism of the vinson system was strikingly different from how we think of agility today. each cryptographic machine contained one or more boards that implemented its own cryptographic algorithm. any problems were thus limited to the copies of that machine, and the boards could be modied or removed and replaced without impact on the functioning of other cryptographic machines.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.25transitioning to the modern eraeventually, as interoperability became an essential component of secure communication systems, more challenges arose. vinson had few modesšplaintext and encrypted, on and off. the next generation of devices that would be required to interoperate with vinson had 1,024 modes, almost all of which had to be secure. this dramatically increased the challenge of evaluating each algorithm and its implementation. george emphasized the difculty of evaluating the implementation in particular because in addition to knowing the designer™s intentions, one must also take into account a variety of unpredictable realworld scenarios. underscoring the difculty of this task, george noted that the nsa today is still evaluating vinson™s algorithm, 60 years later, just in case there are surprises inside. ﬁoccasionally, you nd things,ﬂ said george. ﬁwhen you do nd them, you have to x them or accept the risk,ﬂ he added, noting that if there are openings, it is often impossible to know whether an adversary has also found them. today‚s technology has so much more functionality. cryptography has also proliferated because increased functionality means there are more places to protect and more ways for data to be attacked. ﬁin order to attack cryptography back in the ‚70s, you had to attack the cryptography,ﬂ george said. ﬁtoday, you go around the cryptography.ﬂ availability is also key to today™s technology, but early cryptography was not designed to accommodate availability. integrity, authentication, condentiality, and nonrepudiation were the traditional aims.the problem of legacy cryptographybuilding on a theme raised earlier in the workshop, george commented on the problem of legacy cryptography that remains in software or hardware after it has become obsolete. this typically happens either because new devices still have to be able to talk to older ones or because there is still information stored and encrypted with those older algorithms. these and other factors mean that in many cases old cryptography can never be fully retired. where legacy algorithms are in use, they present a risk because adversaries can bypass the newer, stronger cryptography and attack the older, less secure algorithms. preventing backward compatibility and forcing old cryptography to break can mitigate the issue, george said. in the discussion following george™s presentation, bob blakley, citigroup, inc., noted that his mentor used to say that code was akin to ﬁoriginal sinﬂ: every line you write stays with you and your descendants forever. therefore, perhaps instead of erasing old algorithms, as george suggested, participants should instead think about how to live with these mistakes, since the more likely scenario is that they will not be retired. george replied that at some point, technologies do become obsolete, such as vacuum tube televisions and rotor encryption machines. butler lampson, microsoft corporation, cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.26weighed in by paraphrasing a suggestion he attributed to alan kay. computers should be like tissues, he said: ﬁyou use it once and throw it away.ﬂ such an approach could greatly simplify the security required. properly storing information is essential to government work and required by law in certain situations. george shared an anecdote in which retrieving stored information proved to be nearly impossible, illustrating that these requirements do not always ensure that stored information will be retrievablešjust that it will be stored. international dimensionsgeorge described some of the international factors that in˚uence cryptography. foreign governments sometimes have very different standards and motivations than the united states. some countries do not value citizens™ privacy in the same way that the united states does, and they are changing or adapting secure cryptography for their own ends. for example, some governments may refuse to use public algorithms and instead require the use of their own cryptography in systems, without sharing that algorithm or allowing designers to evaluate it or its implementation. in such cases, said george, ﬁwe are going to have to trust [that government] and trust that it has not done something to circumvent everything else that we have in there . . . you cannot possibly vet that algorithm.ﬂ another wild card is randomization. countries might require their own randomization, which can create ancillary issues. in this complex environment, the cryptography itself becomes the ﬁsimpleﬂ piece of the puzzle. during the discussion, deirdre mulligan, university of california, berkeley, asked george to expand on situations in which the requirements of foreign governments may be at odds with citizens™ privacy or other rights. while diplomacy is important, she said, citizens are often unaware that there is a security choice at all and end up using an insecure setting by default. george agreed that the average user chooses the default security settings, which are probably insecure. mulligan claried her question to ask if other governments, for example china, could create transparency in their information security process or at least allow their users to understand what level of privacy they actually have. george suggested that the situation is difcult from any perspective. other governments make their own decisions about what cryptography is allowed to be used and sold and are unlikely to be persuaded to change their policies. for the same reason, it would be hard to explain to, say, chinese users what risks they are taking using software whose the average user chooses the default security settings, which are probably insecure.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.27cryptography was likely amended. unfortunately, in foreign countries, there is not much that can be done. ﬁyou do not hold a winning hand in trying to protect people when the government does not want to protect them,ﬂ george explained. preparing for quantum computinggeorge noted that the government is still studying vinson because it is possible that holes may yet be revealed. today™s much more complex cryptography, such as rsa cryptography or quantum key distribution, involves distinctive risks. there is a lot of cryptography in use today that is not fully understood and can perhaps never be fully secure, george argued. an approach known as quantum key distribution might be considered safe, for example, but george asserted that every implementation of quantum key distribution so far has been shown fairly quickly by academic researchers to be insecure. quantumresistant cryptography is so little understood that it would require years of studyštime that we really do not have, george said. the security of government and personal data is at stake. classied documents, nancial information, and health records all need to be protected as well. george pointed out that health records hold information that does not change, such as a person™s blood type or medical history. when a credit card account is breached, it is fairly easy to receive a new card and a new account number. ﬁbut if they steal your health records, you cannot change them that easily,ﬂ said george. ﬁthese are the kinds of things we have to understand. we have to be ready.ﬂ quantum computers represent a real and urgent threat that must be addressed, he said.in the discussion, steven lipner asked george to imagine that quantum computing was real and could break the widely used 2048bit rsa keys. in that situation, how would he advise the president? george said his advice would be rst to go back to an older system, such as symmetric key distribution, although he would prefer not to need such a stopgap. it would be far better to be ready and prepared for quantum computing, he said. the older systems would be merely backup communication systems, like morse code and sextants for navigation on ships. lipner re˚ected that many businesses do not have any backup plan, which could cause big problems both for them and for their customers.addressing current weaknessesjohn manferdelli, google, inc., asked george if insecure hardware, which is most of what people are using today, is a ﬁcatastrophic problem.ﬂ george described the issue as one of risk management, and the answer would depend on what the system is, who the adversary is, and how bad a data breach would be. the online banking industry might be able to live with some of the risk of quantum computing, but the nuclear weapons system probably could not.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.28george emphasized that the nature of our adversaries has changed. in the cold war years, enemies™ motivations were clear and they followed ﬁthe rules,ﬂ both of which are no longer the case. key questions have to be considered: ﬁwho is going to have access to that quantum computer? what are they going to be able to do, and what are you worried about?ﬂ referencing the focus on quantumresistant cryptography, paul kocher, cryptography research division, rambus, inc., questioned whether those more ﬁhypotheticalﬂ challenges should really be the priority or if the more everyday bugs and repairsšwhich we know are problems right nowšshould be attended to rst. george agreed that today™s systems are denitely in need of repair and that part of the problem is that we rely too much on users to protect their computers and software. in a car, he noted, there are seatbelts and warning systems that protect the occupants. ﬁwe ought to have the same kind of regulation that says that the computer ought to protect the user rather than the user protecting the computer,ﬂ george asserted. in the context of the security problem known as buffer over˚ows, george suggested xes must be made in hardware because software is too extensive and diverse. george emphasized how critical it will be to know which adversaries have access to quantum computers and what types of extremely important information must be protected from this threat. however, the vast majority of attacks happening today involve much more runofthemill adversaries who can be defeated through better user behavior. citing a statistic that 91 percent of security attacks in 2015 came from phishingša user clicking on a link that unwittingly let an adversary inšgeorge asserted that better system design, not public education or training, is needed to help prevent these sorts of breaches. ﬁyou really cannot train them not to because you are talking about 4yearolds and 90yearolds . . . that training is not going to work. you have to protect them. let the computer not let them do dumb things,ﬂ he said.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.29standards and security implications3 the workshop™s third session focused on standards for cryptographic agility as well as the security implications for various levels and types of agility. russ housley described the process and perspective of the recent request for comments (rfc) 7696 guidelines from the internet engineering task force, and david mcgrew drew on realworld experiences and data to highlight lessons learned and future directions. rfc 7696: guidelines for cryptographic algorithm agility and selecting mandatorytoimplement algorithmsruss housley, vigil security, llcruss housley, founder of vigil security, llc, and past chair of the internet architecture board (iab), presented on rfc 7696: guidelines for cryptographic algorithm agility and selecting mandatorytoimplement algorithms.rfc 7696, which is also known as best current practices 201, was initiated by iab under its privacy and security program. after the early draft development and initial review and comment process, the project was transferred to the internet engineering task force (ietf) security area advisory group. before publishing the document in november 2015, ietf shepherded it through a broader review process and achieved consensus. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.30the goal of rfc 7696 is simple to state but not so to achieve: to ensure that security protocols can migrate from one algorithm or suite of algorithms to a newer, stronger one when needed. tackling this, housley said, requires viewing the problem from two perspectives: that of the protocol designer and that of the protocol implementer. protocol implementers need to be able to add a new algorithm, which requires modularity that would not otherwise be needed, and they need a way to detect if the new algorithm has been successfully added, which is something many protocols currently lack. ﬁwe are hoping that one of the things that will result from this guidance is that we will get that capability,ﬂ housley said.the protocol designer has a different goal: to identify which algorithms are old, which are new, and which are mandatory to implement to achieve interoperability. the answers to these questions change each time a new algorithm is added, which increases confusion. a registry of identiers for all known protocols, algorithms, and algorithm suites would help both designers and implementers, housley said, noting that popular consensus is that such a registry be created by the internet assigned numbers authority.selecting mandatorytoimplement algorithmshousley emphasized that an important role of rfc 7696 concerns the selection of algorithms that are mandatory to implement and necessary for interoperability. mandatorytoimplement algorithms should be included in any implementation of a particular protocol, although there can be debate over which algorithm to select. for example, there is currently a debate over whether to default to a probabilistic signature scheme (a method for constructing an artifact before applying the signature operation) as part of the transport layer security (tls) 1.3 protocol. either way, once the decision is made, all implementations must include the common algorithm in order to achieve interoperability and to be compliant.prompted by bob blakley, citigroup, inc., housley claried that if the mandatorytoimplement algorithm is not implemented, the product would be considered noncompliant with ietf standards, though he noted that ietf has no policing power to enforce these standards. ﬁit is more of a ‚hall of shame™ kind of a consequence,ﬂ he said.although ietf provides guidance that allows for either choosing algorithm suites or taking a piecebypiece approach (in which a cryptographic mechanism is built from a collection of known elements), housley noted that sometimes a piecebypiece approach can result in a mechanism that looks reasonable but is not actually secure. housley stressed the importance of building a cryptographic mechanism in which each piece is roughly equal in strength. a weak key agreement paired with a strong cipher, for example, is still vulnerable to attack at its weakest pointšanother downside to a piecebycryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.31piece approach. echoing a sentiment expressed by other speakers, housley emphasized that simple implementations are essential to strong security.ideally, housley noted, when a new, stronger algorithm is developed and introduced, the older algorithm is retired. but it takes a lot of work and coordination to make this happen; there must be a mechanism in place to reject the older (often ˚awed) algorithm before the new one is rolled out to all implementations. the challenge is compounded when an algorithm is implemented in hardware. in that case, a piece of equipment such as a chip or board has to be replaced (rather than distributing software patches over the network). ﬁno matter what we do,ﬂ said housley, ﬁtransition is going to be hard.ﬂ and when interoperability fails, the one who turns off the old algorithm becomes ﬁthe bad guyﬂ who is blamed when the two systems are no longer able to work together.the ietf process of selecting mandatorytoimplement algorithms was designed to ﬁlet the experts in this technology do the picking,ﬂ housley said. the number of algorithms or implementations is also important. if there are too many algorithms or implementations available, several may be rarely used; if these have ˚aws or breaches, they can go unnoticed, and thus unxed and exploited, for a long time. on the other hand, if only one algorithm or implementation is chosen and it turns out to have a ˚aw, that is clearly a problem, too. rfc 7696 therefore recommends choosing two algorithms for implementation. the second choice can act as a backup if the rst is found to be ˚awed.during the discussion, blakley inquired about what constraints might be imposed by xedlength elds in hardware and protocol headers in the context of agility. housley responded that in his experience this is less and less of a problem as it gets easier to accommodate variable eld lengths. although the eld length might affect the speed of a communication, he said, it is not likely to drop the communication altogether, as might have been the case in the past.opportunistic security and the need for deliberate security decisionsrfc 7696 came about when the idea of ﬁopportunistic securityﬂ was gaining traction. under this model, communications are encrypted, possibly without any authentication. basically, any encryption technique that is common between the implementations is used, which increases the effort for an adversary to intercept communications. in this sense, opportunistic security makes pervasive, passive surveillance difcult because many users employing a weaker algorithm or shorter keys can force an entity trying to do covert surveillance to break all of those endpoints, which is a difcult and timeconsuming task. in the discussion, eric grosse, google, inc., said that when most communication was clear text, he was in favor of opportunistic security. however, he now opposes it for two reasons: (1) people can become overly reliant on it and neglect true security; and cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.32(2) state actors or enterprises can take advantage of the relative weakness of opportunistic encryption to do their own content injection. housley replied that he does believe opportunistic security increases the amount of work required to conduct surveillance or push content. for example, if a weak cipher is being used, decrypting it still takes time. however, he agreed that data are not well protected with opportunistic encryption, and he cited the difcult situation faced by communications carriers. they want to offer their users the fastest service, while also keeping communication secure. there is currently a debate between the ietf and the groupe speciale mobile association about how wireless service would be affected if everything becomes encrypted. email and web encryption might be hardly noticeable to users, creating only tiny delays in the transmission of information, but users ﬁcertainly would notice if their voice call had sporadic sputters in it.ﬂ housley said that a mechanism is essential to determine what needs encryption and what does not. a onebit covert channel might be enough to enable the right distinctions, he suggested, although he noted that many rewalls currently being used would need to be updated.it is also crucial that cryptography experts be actively engaged in designing and evaluating systems. prompted by a question from donna dodson, national institute of standards and technology, housley pointed to instances where cryptographers were not involved, but they could have been of use. for example, wired equivalent privacy (wep) was ˚awed in ways that would have been relatively obvious to a cryptographer, but ﬁno cryptographer cared to lookﬂ because wep used 40bit keys, which were already known to be breakable. when a 128bit key variant was introduced, the system was still highly ˚awed because the security decisions had been made by a committee with little cryptographic expertise. ﬁi would argue that we need educated people involved in the protocol design to avoid another wep,ﬂ housley said.the international contexthousley touched on how the international context in˚uences standardsetting. offering an example from his past role as ietf security area director, he recalled receiving a complaint from russian nancial institutions that there was no support for the gost algorithms (an alternative to data encryption standard) in the existing tls protocol. they wanted to use tls to secure online banking, but the russian regulations required the use of gost for all nancial transactions in that country. as a consequence, the entire country was unable to bank online. housley and steven bellovin, the two ietf security area directors at the time, agreed to tackle the problem. ﬁi was not willing to be the guy that said the russians cannot do online banking,ﬂ housley said. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.33peter swire, georgia institute of technology, asked how many countries have national encryption standards and how that landscape affects agility. housley noted that, in addition to russia and china, many other countries including korea and japan have these standards. each is different; some focus only on the encryption algorithm (as in the case of korea™s seed algorithm) and others include the whole suite of algorithms, key management, digital signature, hashes, and so on (as in the case of russia™s gost family of algorithms). different countries have different priorities when it comes to investing in cryptography and algorithms, and technologists have no control over these political decisions. ﬁall we can do is come up with a way that lets [the algorithms] be used in the policy environment where they are required,ﬂ said housley.noting that this diverse international context creates modularization of security mechanisms, swire asked whether these differences might be a ﬁblessing in disguise.ﬂ housley categorized it as a doubleedged sword: while modularity has its benets, conguration around national algorithms makes it harder to maintain interoperability and creates a tough situation when ˚aws are found. then, the question becomes how to change the conguration or implementation to eliminate the ˚awed module without losing interoperability.paul kocher, cryptography research division, rambus, inc., raised the ethical side of the international context. given that governments have differing reasons for imposing requirements and that sometimes those reasons are at odds with the ability for individuals to obtain adequate security, he asked about the role of standardsetting bodies like the ietf: do we give these governments the cryptography (and ﬁback doorﬂ) they want, or can we force them to accept something that ﬁgives everybody well understood security properties?ﬂin response, housley said that rst, the mandatorytoimplement algorithm needs to be as strong as possible so as to give all internet users a baseline level of security. beyond that, each country is operating within its own political context, which is beyond the purview of the ietf. ﬁi think we have to accommodate the local decisionši do not see how we cannot,ﬂ he said. a possible balance could be that local identiers recognize the mandatorytoimplement algorithms even if they do not implement them. he also noted a downside to refusing to comply with international requests. if he had refused the russians™ request regarding gost and the tls protocol, someone would likely have built the mandatorytoimplement algorithm needs to be as strong as possible to give all users a baseline level of security.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.34an alternative tls, probably with ˚aws, to accommodate the russian demand for gost. that kind of ﬁforking,ﬂ housley said, is harmful to the internet overall. building on this point, fred schneider, cornell university, noted that while one cannot necessarily prevent a government from acting according to its best interests, the ietf could still benet users by requiring transparency. transparency would allow people to see how secure the algorithms are before making their decisions. such transparency also could discourage the creation of intentionally insecure algorithms. housley said that the ietf has required that certain specications be readily available for review, and some nations have gone even further, translating their algorithm specications to english so that the ietf and other standards organizations can make their own judgments. cryptographic agility in the real worlddavid mcgrew, cisco systems, inc.david mcgrew is a fellow in the advanced security research group at cisco systems, inc. while cryptographic agility is broadly accepted, it is not broadly understood, he said. suggesting that there are in fact different types of agility, he structured his talk to focus rst on principles, then on realworld experiences, and nally on conclusions to inform future efforts. principles relevant to cryptographic agilitymcgrew began by highlighting what he sees as key principles related to cryptographic services, implementations, and agility. the rst is that agility is essential for protecting against future threats and supporting backward compatibility. mcgrew acknowledged quantum computing as an important threat but emphasized that it is not the only one, underscoring the need to be ﬁfuture proof.ﬂ agility is also essential for implementations, not just algorithms, he said.a second principle is a nontechnical one: customers should be able to choose what cryptography they use. he referred to housley™s story of russian online banking as an example of this idea. cisco, as a multinational company, must balance support for international standards with support for the needs of its international customers. ﬁwe do not want to force any particular national agenda,ﬂ he said. for example, cisco supports japan™s use of its own national cipher, camellia, as long as japanese customers are willing to bear the economic costs of that decision. a related principle is that one country should not be able to force its cryptographic choices on the rest of the world, mcgrew said. the nal principle is that complexity should not be forced upon users. agility can be complex, as paul kocher outlined in his talk. ﬁthere is a concentration of interests and cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.35a diffusion of cost,ﬂ mcgrew said. he continued that if any country wants to add cryptography to the current standard to increase agility, that act increases the complexity for all implementers, testers, users, and policy makers, resulting in a ﬁhidden costﬂ each time a new option or cipher is added. ﬁi think this is a really important point that might get lost when talking about the benets of agility,ﬂ mcgrew said. understanding the realworld contextcryptography is implemented in many different places in today™s systems. the level of agility that is appropriate or feasible depends on the context. mcgrew described how hardware, eld programmable gate arrays (fpgas), operating systems, applications, and scripts can be arrayed on a scale ranging from most conservative/least ˚exible to most agile. in hardware, the cryptography is built in, but with fpgas, there is slightly more ˚exibility. operating systems have even more ˚exibility, applications can be very agile, and scripting languages such as javascript offer tremendous agility.it is important to keep this spectrum in mind when designing cryptography to be agile or conservative, mcgrew said. in his view, hashbased signatures can provide the best security against advances in cryptography, potentially even against quantum computing. he emphasized the importance of considering how long the equipment or product is expected to be used. being conservative is more important than being agile in the context of products that are expected to be in the eld a decade or more, he said, pointing to devices in the internet of things as an important example. elucidating the different types of agilitymcgrew posited that there is not one, but three types of agility: algorithm agility, protocol agility, and implementation agility. algorithm agility means being able to swap ciphers or algorithms in and out easily; often this is done by swapping in a new block cipher. while in some senses it is the easiest form of agility, the variety of algorithm designs makes it more difcult than it sounds. he pointed to gost, a cipher with a 64bit block, and advanced encryption standard, one with a 128bit block. ﬁswapping the two is not as easy as you might think,ﬂ he said. differences in modes of operation also affect potential swapping. mcgrew dened protocol agility as moving to a new version of a protocol, such as 1.1 to 1.2 for tls. protocol agility can be easy or difcult, but in mcgrew™s view, it is more important, in many ways, than algorithm agility. mcgrew dened the nal type, implementation agility, as the ability to update or replace software found to have a security ˚aw. this might not seem the same as cryptographic agility, but mcgrew argued that if the user can bring a new implementation cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.36himself, through debian linux aptget or windows update, that counts as a situation requiring agility. lessons learned from discovered flawspointing to an analysis he conducted of openssl common vulnerabilities and exposures (cves), mcgrew described ve categories of ˚aws: (1) algorithm ˚aws, including block ciphers and cryptographic primitives; (2) protocol problems, meaning xes that require changes to the protocol; (3) side channel attacks, where secret keys leak out; (4) padding attacks, which may overlap protocols and implementations; and (5) implementation ˚aws, where there is a bug in the code that is often not revealed until it is too late to rewrite it. of cves logged from 2002 to 2016, implementation ˚aws accounted for far and away the greatest number, ndings that underscore paul kocher™s concern over implementation ˚aws. the analysis also revealed what mcgrew categorized as ﬁa horrifying numberﬂ of ˚aws introduced when trying to x previous ˚aws. although agility allows for known bugs to be xed quickly, all of these ﬁxesﬂ increase complexity and run the risk of introducing yet more ˚aws. ﬁthere may be an implementation bug in the x, or somebody did not think the x through,ﬂ mcgrew said. ﬁi worry a lot about complexity.ﬂcves are not the only measure of successful security. an analysis of the use of network algorithms and key sizes revealed that obsolete cryptography is still available and in use, he said, ﬁincluding some trafc that really should not be using it.ﬂ how to get people to stop using such obsolete ciphers is ﬁa fascinating question,ﬂ he said. with tls up to version 1.2, he continued, it is possible to block particular ciphers known to be insecure, perhaps through a ﬁsmart ruleﬂ that denies connections on the basis of poor security. however, as kerry mckay had noted in her presentation, it would not necessarily be fair to block a senior citizen from accessing the social security administration website when the person might not know how to do that. ﬁthat is a really hard problem,ﬂ he said.data on client key lengths also revealed that very few people were using optimum key sizes to maximize security, a nding that surprised mcgrew. in addition, mcgrew expressed serious concern about the large number of people using software and hardware that is no longer secure or supported by the manufacturer. another problem is that the people who originally bought, sold, installed, or congured a piece although agility  allows for known bugs to be xed quickly, ﬁxesﬂ increase complexity and run the risk of introducing yet  more ˚aws.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.37of software may no longer be available to answer questions or make repairs for the organization that is using it.looking forwardlooking ahead, mcgrew noted the importance of fungibilityšthe ability for security components to be swapped easily. block ciphers, he said, are fungible because they have a simple interface. standards regarding authenticating encryption, for example, should also encourage fungibility. he also posited that the rapid pace of generating the new tls 1.3 standard was making it difcult for engineers to design for better agility, though he noted that it could be debated whether or not it would be worth slowing the deployment of tls 1.3 for this purpose. in closing, mcgrew suggested that ﬁimplementation agility is the most important thing of all,ﬂ and implementation is where security needs to be as conservative as possible. in response to a question from bob blakley, mcgrew elaborated on this point, arguing that system integrity should be a constrained, conservative area because it is best to have a small, trusted computing base. in part, this is why he supports hashbased signatures. later in the discussion, eric grosse agreed that such signatures are the best bet for rmware updates because they are expected to be solid for the many years that rmware lasts. agility in the context of data at resttadayoshi kohno, university of washington, raised a question about the agility context for data at rest as opposed to data in transit. mcgrew hypothesized that a storagebounded model could work to keep stored data secure while it is deencrypted away from a weak security system and reencrypted with stronger security. russ housley added that a working group known as longterm archive and notary standards was looking at this question in terms of the security of digital signatures, but he did not know whether it had considered condential stored data. noting that he is struggling with this issue on a design right now, grosse said his team™s approach is to encrypt stored data on discs with fairly conservative symmetric ciphers. for metadata, which is a smaller amount of data, the team is using publickey algorithms that are more agile and likely to change in the face of a postœquantum computing world. assuming that the current cryptography is secure enough, he estimated that this system provides more agility to reencrypt data as necessary, although it has not been proven. housley shared that he has seen a similar approach work, but not for changing algorithms stored on discs with encrypted data. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.38envisioning a worstcase scenariosteven lipner, independent consultant, speculated about how it might be possible to design for a potential catastrophic future event, whether it is a quantum computer breaking all cryptographic code or another sort of catastrophe that could prompt the failure of an algorithm that we rely on, creating global computing chaos. ﬁi do not think we can get away with ignoring it or hoping it will not happen,ﬂ he contended. emphasizing the importance of implementation agility, mcgrew said that implementation agility can complement algorithm agility when interface designers anticipate future ˚aws, whether in the antireplay, freshness checking, padding, or another aspect of cryptography. whatever it is, it needs to be properly addressed and easily replaceable before such a ˚aw is detected, he said. with true implementation agility, deploying new code offers a lot of ˚exibility to x the problem correctly, without hastily plugging a leak and introducing a new ˚aw. lipner argued that mcgrew was envisioning the fairly quotidian experience of nding and xing a ˚aw, whereas lipner was speaking of a more extreme event. at some point in the future, lipner hypothesized, ﬁthere are going to be some algorithms that are not part of the implementation you are going to want to replace. you are going to have to interface with the implementation [ . . . and . . . ] manage things at that interface,ﬂ which is, perhaps, a far more challenging task. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.39engineering at scale and user implications4 workshop participants next tackled various aspects of cryptographic agility in practice. matthew green of johns hopkins university offered a case study of benets and drawbacks of agility mechanisms in the transport layer security (tls) protocol. google™s adam langley explained agility in the context of extensibility, touched on the international context, and explored how retiring outdated security mechanisms affects users. sara ﬁscoutﬂ sinclair brody of simply secure offered a perspective informed by the eld of usercentered design, explaining how security and agility can be enhanced by better defaults, communication, education, and transparencyšnot only for end users, but also for developers themselves. transport layer security and the downsides of agilitymatthew green, johns hopkins universitymatthew green is an assistant professor at the johns hopkins information security institute and also writes a wellknown cryptography blog titled ﬁa few thoughts on cryptographic engineering.ﬂ1 like other speakers at the workshop, he offered examples of the benets of agility (which he dened as having the ability in place to react quickly and 1the website for green™s blog is http://blog.cryptographyengineering.com/, accessed november 18, 2016.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.40appropriately to change), but he also highlighted some drawbacks. he used the frequent attacks on the tls protocol as a case study. when agility ﬁsaves the dayﬂgreen provided examples of how agility mechanisms have saved tls over the years. today, he said, ﬁwe are so used to tls breaks . . . it has become a joke in our community.ﬂ but when the browser exploit against ssl/tls (beast) attack on tls was rst documented in 2011, it was ﬁthe beginning of an era.ﬂ in response to the attack, most users took advantage of the protocol™s builtin agility to move over to the rivest cipher 4 (rc4) stream cipher. however, rc4 was later found to be itself insecure and therefore a poor defense against beast attacks. in addition, the beast designers introduced another vulnerability called compression ratio infoleak made easy (crime), which went after the preprocessing compression instead of attacking algorithms directly. unfortunately, although cryptographers were theoretically aware of this weakness, those deploying and building servers did not know about it, and crime was able to decrypt tls communication fairly quickly. when crime became known, it was contained by turning off compression on most tls servers: ﬁagility saves the day,ﬂ green summarized.newer, more secure cryptography platforms in subsequent versions of tls brought mixed results. cipher suites, authenticated encryptions, fast stream ciphers, and fast authenticated stream ciphers were all developed to increase security. however, green explained, ﬁit turns out that there were applications that we had not really considered.ﬂ rc4 was fast but not necessarily secure; to attain something fast and secure, designers are now looking at nonstandard cipher suites such as chacha20 and poly1305 and considering whether it would be worth pursuing standardization of these suites by the internet engineering task force (ietf). agility as ﬁour achilles™ heelﬂgreen then turned to what he views as the drawbacks to agility, starting with the caveat that he does not quite agree with richard george™s statement that people now try to nd a way around cryptography instead of attacking it. he suggested that beast, crime, and the ﬁpadding oracleﬂ attack be considered direct cryptography attacks. arguing that many of today™s problems with tls and secure sockets layer (ssl) stem from decisions made in the 1990s, he said that even though our cryptographic algorithms and authenticated encryption have gotten signicantly better, the builtin mechanisms have become ﬁour achilles™ heel.ﬂ green observed that a signicant drawback in most systems is that legacy cryptography is not removed when new cryptography is added. as an example, green said he was recently shown a paper describing vulnerabilities in several ssl stacks that involved cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.41the ﬁcompletely obsoleteﬂ exportgrade (512bit) rsa. despite its obsolescence, ﬁit turns out that at the time of this vulnerability coming out, about 30 percent of the internet browsertrusted certicates were actually supporting export rsa,ﬂ green said. digging deeper, the researchers discovered that there had been an implementation vulnerability that allowed attackers to downgrade from a more secure protocol to export rsa, which could then be exploitedšthe factoring attack on rsaexport keys cve20150204 (freak) vulnerability. noting that this same bug was found in three separate, and supposedly independent, tls implementations, green suggested that the bug may be in the protocol itself, rather than in the implementation. during the later discussion, green speculated that one reason for the bug™s persistence could be the persistence of featuresšand bugsšfrom previous versions of code that remain when a new version is created. adam langley, google, inc., added that the written specications or instructions could inadvertently drive the implementer toward this bug. eric grosse, google, inc., noted that these examples underscore the importance of testing. after discovering the vulnerability that allowed a downgrade to exportgrade rsa, green™s team decided it would be wise to look at other ciphers supported in tls/ssl and check for similar vulnerabilities. the team found a vulnerability, known as logjam, that allows attackers to downgrade from a strong protocol to a weaker export protocol, even when the client does not support export. the cause appears to be a key exchange message that has the proper parameters for the server to talk to the client but is missing an identier that tells whether it is a normal or export protocol. paul kocher, cryptography research division, rambus, inc., interjected to accept the blame for this vulnerability. ﬁleaving aside who is to blame,ﬂ green replied, ﬁthe point here is that these things are incredibly difcult to get right. even today, there are still vulnerabilities that probably we have not found.ﬂ green then described another tls attack, known as decrypting rsa with obsolete and weakened encryption (drown). drown takes advantage of the continued use of sslv2 to lead a crossprotocol attack to decrypt tls communications. ﬁthis is lousy, and it leads to . . . all sorts of bad things that we should not be seeing in protocols in 2016,ﬂ he said.it is extremely challenging to prove today™s protocols secure.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.42the challenge of complexitya big problem, green said, is that it is extremely challenging to prove today™s protocols secure, or even to prove small parts of them secure, because they are so complex. as an example, green pointed to a paper from 2012 that was the rst to fully analyze one part of tls, the difehellman ephemeral protocol.2 the next year, a paper analyzed the rsa handshake, another small aspect of tls.3 in both analyses, the authors were unable to analyze the last renegotiation. green concluded, ﬁit turns out that our agility is actually our weakest point.ﬂin 2014, researchers ﬁgave up on proving the entire protocol secure and they decided to have computers do it,ﬂ green said. yet this effort was inconclusive because, as green put it, ﬁnobody can actually understand what the computers did.ﬂ however, the paper4 did provide some encouraging news: it showed that as long as the client and the server support only secure algorithms, tls is a secure protocol. this is not actually what the tls design community had been assuming, though; they had thought that as long as the intersection of the two sets of algorithms contained secure protocols, that was enough. however, he noted that this work showed that downgrade attacks can still nd a way to use the insecure protocols, if they are also supported. ﬁwe need to improve tls to deal with this kind of problem,ﬂ green concluded.practical mattersagility, then, is both good and bad, green said. it allows us a way to move forward when attacks occur, but it also creates complexity in our protocols and enables new attacks. whether we like agility or not is not the issue, green stressed: ﬁwe are going to get agility no matter what we do because when we do not build agility into our protocols, other people do it for us, and they do it in really bad, dangerous ways.ﬂ an example of this is the fact that most browsers support three tls protocols as fallback maneuvers in case one fails, yet this agility creates insecure situations everywhere because of the possibility of downgrade attacks. ﬁwe have to design [agility] correctly because if we do not, we get the worst of all possible worlds,ﬂ green said. building on the argumentšarticulated many times throughout the workshopšthat implementation is often the source of vulnerabilities, bob blakley, citigroup, inc., posited that the situation is made even worse by the current convention that a reference 2t. jager, f. kohlar, s. schäge, and j. schwenk, 2012, on the security of tlsdhe in the standard model, pp. 273293 in advances in cryptology œ crypto 2012 (r. safavinaini and r. canetti, eds.), lecture notes in computer science, vol 7417, springer, berlin, https://eprint.iacr.org/2011/219.pdf. 3h. krawczyk, k.g. paterson, and h. wee, 2013, on the security of the tls protocol: a systematic analysis, pp. 429448 in advances in cryptology œ crypto 2013 (r. canetti and j.a. garay, eds.), security and cryptology, vol 8042, springer, berlin, https://eprint.iacr.org/2013/339.pdf.4k. bhargavan, c. fournet, m. kohlweiss, a. pironti, p. strub, and s. zanellabéguelin, 2014, proving the tls handshake secure (as it is), pp. 235255 in advances in cryptology œ crypto 2014 (j.a. garay and r. gennaro, eds.), security and cryptology, vol 8616, springer, berlin, https://eprint.iacr.org/2014/182.pdf.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.43implementation guide is released before the ofcial specication guide is nalized. by virtue of being released rst, blakley asserted, this implementation guide will have errors that may be xed in the nal version, yet everyone will still refer to it simply because it is released rst. tadayoshi kohno, university of washington, questioned whether anyone has tried to intentionally break backward compatibility mechanisms for a small set of users (on google chrome, perhaps) in order to study the results. doing so, he suggested, might help to determine whether we need to support agility in certain circumstances or if it is acceptable to ﬁmove to something newﬂ without stranding large numbers of users. in response, green suggested that perhaps a more fruitful approach would be to tap into the developer community and the ietf, who have the clout to in˚uence security decisions and build solutions. another participant mentioned the counterparts to agility (i.e., transition planning and execution), suggesting that any transition is going to break something and what matters is how one plans for that eventuality. pointing to his closing slide, which featured a tweet about how much of the internet is ﬁrotted with age,ﬂ green reiterated how difcult it is to eliminate code and security mechanisms that have become outdated. for example, he said during the disclosure of the logjam vulnerability, green™s team wanted to remove the 512bit difehellman from use and raise the minimum to 1,024 bits. apple, google, and others scanned the internet and found that removing the 512bit difehellman would break 3 percent of the internet, including many older internet of things devices that cannot be upgraded. that experience underscored green™s conclusion that ﬁwe are stuck with these kinds of legacy devices that are dragging us back into the past.ﬂ adam langley noted that google did remove the 512bit difehellman modules internally, though the decision had some negative repercussions for at least one google team.recalling richard george™s story about the multiple decades spent designing, testing, and implementing vinson for radio communication, steven lipner, independent consultant, inquired about whether there is a way to achieve a similar but faster level of validation for security instruments being developed todayšperhaps enabled by more people working in parallel. green suggested the best way forward was for securityfocused people to gain more traction in large companies and to ght for the resources to do it right. the current reliance on open source developers and research cryptographers to do this work has left us ﬁin bad shape,ﬂ he said. langley agreed that formal verication could create good systems and good software, and that the eld of verication is improving. he pointed to the national aeronautics and space administration and space shuttle software as an example. green countered that instead of a slow but steady process, it is going to take a major breakthrough for a signicant portion of cryptography to be formally veried. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.44extensibility and agilityadam langley, google, inc.adam langley is a principal software engineer at google, inc. he discussed extensibility, which he dened as the ability to make additions to a protocol without requiring sweeping, simultaneous global updates (a model, he noted, that is generally impossible anyway). extensibility is a necessary component of agility, langley said, because it provides a practical approach to updating alreadydeployed systems. he also offered examples illustrating how extensibility plays out in realworld situationsšfor better or worse. extensibility in transport layer securitylangley described examples of extensibility mechanisms in tls. when two computers negotiate which version of the protocol to use, it is the extensibility mechanism that allows the computer with an updated protocol to communicate with a computer with the older protocol. it is a system langley described as ﬁcommendably simple,ﬂ yet it does not always work. sometimes the second computer does not recognize the updated information, preventing the communication from taking place. when such failures occur, langley said, ﬁblame attaches to the last thing that changed.ﬂ if google updates chrome™s security mechanisms, for example, and suddenly triggers a bug in a bank™s website, users would blame the chrome update for blocking access to their bank™s website, even though the update was meant to increase the users™ security. google™s solution to such problems is to rely on an older ﬁfallbackﬂ version while attempting to mitigate the disconnect. this intermediate step can last for a very long time; langley said the browser community spent 15 years trying to x several such bugs while relying on a fallback version to ensure continuity of service for users. fallbacks are only used if the breaks caused by updated mechanisms will affect a substantial portion of trafc. if they only affect a small portion of users, say 0.1 percent of trafc, langley said, ﬁwe just break things.ﬂ although developers attempt to build in many extensibility and agility mechanisms, often these supposed points of ˚exibility wind up becoming ﬁrusted solid with bugs,ﬂ langley said. implications for agilityfrom these experiences, langley learned to ﬁhave one joint and keep it well oiled.ﬂ repairs should focus on one specic area, such as compliance suites or implementations, and they should be well tested in order to predict performance and interoperability. testing the extensibility mechanism on a virtually continual basis can help ensure whatever ﬁjointﬂ you are depending on ﬁis going to bend when you need it to,ﬂ langley said.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.45experiences with extensibility underscore one of the workshop™s broader themes, which is that agility should be approached ﬁwith hesitation, at least,ﬂ langley said, outlining the many costs of diverse options. diversity, he said, generally results in more code and more bugs, thus reducing the ability for researchers and testers to focus deeply on any one of the many moving parts. as more interactions are possible, more bugs are created. he pointed to the process of dening primitives for use in tls as an example of agility™s secondary costs. more than 25 different symmetric cipher primitives have been dened so far; although only 9 are currently in use, each of the 25 were put through all the necessary ietf processes, a large expense of time and resources. agreeing with matthew green™s earlier statements, langley asserted that many of today™s challenges stem from decisions made in the 1990s, when technologists were distracted by the ﬁcrypto warﬂ with the u.s. government: ﬁan awful lot of these mistakes got baked in really deep, and we are still ghting them today,ﬂ he said.the international contextlangley then turned to the international context, in particular the question of whether tls should include ciphers for specic nations, which he termed ﬁnational pride cipher suites.ﬂ ciphers for japan and south korea, for example, were included in tls. he views such cipher suites as ﬁall cost and no benetﬂ and recommended that they be ﬁfervently resisted.ﬂ though there might be nothing inherently wrong with themšand indeed, he conceded that to his knowledge, none, including those from russia and china, contain anything deliberately maliciousšhe asserted that they offer no technical advantages over the national institute of standards and technologyœrecommended advanced encryption standardgalois/counter mode (aesgcm). returning to this issue in the discussion, peter swire, georgia institute of technology, suggested that national cipher suites offer other advantages to nations, such as local expertise to better congure cryptography or local intelligence to better disable it. agreeing that national security goals are likely part of the motivation for these cipher suites, langley cautioned that the approach can backre, arguing that making their own primitives, for example, would likely leave countries in a worse situation. another drawback is that accommodating national cipher suites increases costs to everyone: while the nation in question may pay to create the cipher, the world bears the cost of supporting it. he then claried that while he believes national ciphers should be resisted, it is unlikely to be feasible or necessary to ﬁabsolutely banishﬂ them. longterm evolution (lte) security uses a chinese cipher, for example; however, chrome does not support any national ciphers.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.46the imperative to retire old security mechanismsbuilding on previous workshop discussions around the issue of legacy cryptography, langley described a stacked ﬁconveyer beltﬂ of security, with the newest and safest mechanisms at the top and the older, more vulnerable ones at the bottom (figure 1 illustrates such a conveyer belt of symmetric cryptography primitives). ﬁit is very important that we occasionally turn the crank on this conveyor belt so something falls off the bottom,ﬂ langley asserted. retiring outdated security mechanisms is extremely difcult because it means that some devices, connections, or software products will no longer work. for example, it is easy to envision how removing one of the older security mechanisms could cause hundreds of thousands of televisions to stop working, something that many nd unacceptable since users expect televisions to last a long time. however, langley suggested that expecting a complex electronic product to have a lifespan of a decade or more is ﬁincreasingly nonviable.ﬂa signicant downside of agility is that supporting outdated security can encourage its persistence, and new products may even be released today with cryptography from the bottom of the stack. people buying these products are unaware that they might have a very short lifespan because ﬁthey have jumped on this conveyor belt and we are about to turn the crank and they are about to fall off.ﬂ making such decisions, langley said, ﬁis not a job you want if you wish to be well liked.ﬂ while large numbers of people will benet from overall improved security, a concentrated group of users will pay the cost. figure 1 ﬁconveyer beltﬂ of symmetric cryptography primitives. source: courtesy of adam langley, google, inc., presentation to the workshop. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.47during the discussion, paul kocher asked whether strategies for tying new features to new securityšor making software with outdated security slower or otherwise less desirablešcan help to motivate users to upgrade. noting that google has sometimes been able to offer ﬁcarrotsﬂ to users if they make updates, langley said this approach can be helpful. however, it is not without problems: hypertext transfer protocol version 2 (http/2), for example, was built to be usable only with modern cipher suites, but it ended up creating signicant conguration problems. while he had good intentions, langley said, ﬁi am unsure whether that was a good idea.ﬂ noting that the focus of his presentation is on symmetric ciphers in tls, langley said that the same conveyer belt exists for asymmetric ciphers. in one sense, tls is a bit simple because it is a negotiated protocol where two computers can communicate in order to reach a security agreement. in nonnegotiated protocols, such as publickey cryptography standard #12 (pkcs#12), things are much harder because there is no conversation. pkcs#12, in practice, still uses rivest cipher 2 (rc2) (a 64bit block cipher with known vulnerabilities) because that was how it was originally created. a similar situation exists in secure/multipurpose internet mail extensions (s/mime) (for encrypting email). if s/mime is not communicating with a known channel, the recipient may not be able to decrypt the emails unless he agrees to use the lowest security mechanism they share in common. wrapping up, langley pointed to the typically decadelong timelines of retiring security mechanisms such as messagedigest algorithm5 (md5), rsa 1024, and secure hash algorithm1 (sha1) in certicates. preparations for these transitions are often years in the making, and use of the retired mechanisms often persists for years past their supposed nal date. looking toward the future, with regard to the threat of quantum computing, langley said only that he hopes he is retired before the threat becomes a reality. as a cynical upside, he posited that software itself has so many bugs that attackers might ﬁnot even botherﬂ to attack the cryptography. who bears the costs?participants engaged in a lively discussion about the costs that are borne when products or devices become obsolete, and they explored how those costs might be allocated more fairly or equitably. prompted by a comment from grosse, langley described a situation in which google disabled an older version of software used by televisions that caused a break for a tiny fraction of usersšapproximately 0.001 percent. after user complaints, google relented and postponed the switch, giving the manufacturer a deadline to have the devices updated before the old version would be permanently disabled. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.48deirdre mulligan, university of california, berkeley, noted that such experiences raise consumer protection questionsšconsider, for example, the implications of a break if the users who are most affected are also the least able to afford a replacement television. she pointed to the national vaccine injury compensation program as a model of one potential solution. because vaccines are so widely benecial for public health, the program provides compensation to anyone who is injured as a result of receiving a vaccine. could a similar system be instituted to support the common good of cybersecurity, where subsidies could be given to those needing new devices who cannot afford to buy them? langley agreed that this is a challenge, describing the ﬁpainful realizationﬂ that often the users most likely to be affected by a break are the poorest in society, who are more likely to be using older devices and software. expressing his view that subsidizing new device purchases could make removing legacy cryptology signicantly easier, langley conceded that he did not know how such a plan could work from a political standpoint. one partial solution google supports is to allow manufacturers to test new products with google™s test server to ensure that their devices work with the latest cryptography. the idea is that if a product does not work, the manufacturers will x it, thus preventing new devices from being released with security that is at the ﬁbottom of the conveyer belt.ﬂ delving more deeply into the question of who should bear the cost of replacing defunct products, participants noted the many players involved, including users, manufacturers, and service providers. sara brody, simply secure, questioned how a system in which society at large bears the responsibility for upgrades would affect the incentive structures for manufacturers, who already reap prots from upgrades and new device purchases. mulligan added that if a manufacturer decides to stop providing upgrades or services to a product, perhaps it should be required to release its code so that others could repair the ˚aws or install updates to keep those devices functioning. building on this point, brody noted that this problem is particularly acute for internet of things devices, especially when they are sold separately from the service that is required for them to connect online. if the company goes out of business, the service will be cut off and the device will be rendered useless. grosse noted that one reason sslv2 is widely supported overseas, especially in asia, is because lowend ﬁfeature phonesﬂ use it to communicate with online banking sites. it is difcult to conceive of a system for replacing so many devices currently in use by a wide array of people that could continue to support the needed functionality but provide upgraded security, he said. who bears the cost when products or devices become obsolete?cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.49the importance of the human factor in  cryptographic agilitysara ﬁscoutﬂ sinclair brody, simply securesara ﬁscoutﬂ sinclair brody is the executive director at simply secure, a nonprot that aims to increase privacy and security through solutions that are human centered. based on her background in the eld of usable security, she posited that unless a system being built will use solely machinetomachine communication, without contact with people at any point, human factors must be considered when designing the system™s security and agility mechanisms.what role do humans play in cryptographic agility? brody delineated two groups of users: the end users, who actually use the products, and the developers who create and apply the security and agility tools. in considering this second group of users, she urged attendees to include not only elite developers, such as those in attendance at the workshop, but also the vast majority of developers who are simply not experts in cryptography or agility. it is those developers, she noted, who are working on startups whose products may be insignicant now but could quickly balloon to include millions of users: ﬁultimately, they are sort of the front line of cryptographic agility.ﬂ beyond solving the very large problems being discussed at the workshop, brody asserted the need to communicate effectively with this vast developer community about agility principles and policies.moving toward a more nuanced conversationsecurity is a secondary task in the minds of most users and most developers, brody said. both users and developers are far more focused on the primary task of a given product, such as sending and receiving messages. given this mindset and the limited resources most organizations devote to security, nonexperts tend to think of security in a binary way: either a piece of software is secure, or it is not. theyšand this includes both developers and end usersšdo not see the ﬁnuances of grayﬂ or think of security as a spectrum dependent on contexts or threat models. security experts sometimes reinforce this binary thinking, she said, by ˚atly rejecting or endorsing certain systems, or failing to recognize how design constraints or threat models contribute to a more nuanced landscape of options and decisions. brody posited that a better approach is to ﬁcreate more nuance in the conversationﬂ around security needs by reinforcing that security is not a binary property. she also cautioned against letting ﬁthe perfect be the enemy of the good.ﬂ cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.50providing a basis for better decisionshow can this be accomplished? recognizing that many security decisions are situation dependent, brody said that being able to see a stack ranking or prioritization list could help developers make better decisions about security. another way to help developers would be if the cryptography community did something it is unaccustomed to doing: pass value judgment on the algorithms. ﬁwe tend to say, ‚you have to make that decision for yourself,™ﬂ she said. ﬁno; we are the experts. our community needs to be willing to say, ‚these algorithms are denitely better than these other algorithms.™ﬂ brody pointed to langley™s conveyer belt image as a way to guide a developer™s cryptography design choices and explain what cryptography under certain circumstances would require. another way to convey these messages is through the education process. brody suggested students should be learning aboutšor perhaps be taught more effectively aboutšnot just system building, but also recognizing and planning for obsolescence, cryptographic agility, and system maintenance. in the discussion, steven lipner noted that in his experience, most developers do not know much about cryptography and are not taught about software vulnerability, even in the top engineering schools. on one hand, he said he recognized that not every developer can also be a security expert, because it would distract them from their primary task of building software, but on the other hand, developers do need a basic level of knowledge in order to best serve their end users. brody pointed out that developers would also benet from at least having access to people and resources to help with decision making. lipner cautioned that ﬁaccess to peopleﬂ is not a scalable option, though improved access, in addition to a lot of information and the motivation to consume it, would be useful.recognizing realworld constraintsdevelopers are often concerned about how different governments are going to react to their use of cryptography, which brody said was understandable given that developers are humans with real concerns and legitimate fears. ﬁthe legal aspects of cryptography are very scary to them,ﬂ she said. but while it may be easier to ignore the legal landscape of these issues, it is far more useful to engage in the debate on a deeper level and to truly understand both the technical and legal implications.on the subject of legacy cryptography, she agreed with previous speakers that continuing to run insecure software, especially somewhere with sensitive data to protect, like a hospital, is a scary proposition. however, she noted that it is important to recognize security is not a binary property.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.51that sometimes users have no choice. a hospital using a magnetic resonance imaging machine running windows xp, for example, cannot necessarily be expected to acquire a new machine in order to get the latest software. insight about developers, their constraints, and their motivations could help to surface better solutions, she said. an ethnographic study of developers, for example, could help reveal how they think about security, what their concerns are, and what barriers they face in implementing agility. in the discussion, peter swire suggested that the eld of humancomputer interaction is relevant in this context, though he had not previously considered applying humancomputer interaction techniques to gure out how to get developers and others to adopt certain practices. brody reiterated that however much technology there is in cryptography and agility, these are still, in the end, ﬁhuman systems,ﬂ built and implemented by humans to serve human needs. these systems need agility, but what really makes agility happen is the developers, the standards bodies, and the research organizationsšall of which are comprised of humans. systemic improvementsgood defaults are important for developers and end users alike. developers cannot create good user defaults when they are themselves offered too many security options without clear advice or explication of their differences. in such situations, developers often end up passing the decision on to the end user, who is, brody noted, ﬁnot exactly the most qualied person to be deciding what cryptographics [they] should be using.ﬂ providing good defaults rst for developers, and then for users, would be far more helpful.if good defaults cannot be offered, the next best thing is clear recommendations, she said. even a simple dropdown menu with cryptography suites rated ﬁrecommendedﬂ and ﬁnot recommendedﬂ would be preferable to confusing acronyms that mean nothing to the nonexpert. end users would appreciate seeing security options in binary terms and are in fact more likely to make good decisions this way.automatic updates that push important patches out to end users are also crucial, said brody, though she recognized that they are ﬁscary on some levels.ﬂ she suggested that the best practice is to push the update automatically and notify the user, although an easy optout mechanism should still be included with the alert. the benets of transparencyin closing, brody stressed the value of transparency. end users, she said, should be able to determine which security library their various applications are running in order to evaluate the threat posed to them personally by a new vulnerability or attack. such transparency would also be helpful to citizens in the context of national cipher suites and potential government surveillance. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.52opening the discussion, bob blakley agreed that transparency is a good thing, but he said many end users do not have the education or background to make the best decisions when it comes to complex computer security issues. brody agreed, clarifying that she would not expect average users to engage with this information regularly. rather, she suggested having at least the ability to investigate one™s computer security is helpful both for the general population and for populations whose security might be most at risk, such as journalists or human rights activists who might face threats of government surveillance. those groups could benet from increased security transparency because they have a particular need or interest in knowing the safety of their communications. if transparency becomes the standard, accountability could improve and software and applications would be updated regularly.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.53research, industry, and  policy implications5 the nal two presentations of the workshop explored the reasons for pursuing cryptographic agility as well as some of the tricky research questions facing the eld. steven bellovin focused on particular challenges in regard to creating agility in embedded devices, and john manferdelli explored sources of resistance to agility, potential paths forward, and the threat of quantum computing. both speakers touched brie˚y on the policy context. agility is essential (but extremely challenging)steven bellovin, columbia universitysteven bellovin, currently a professor of computer science at columbia university, previously worked as a fellow at at&t labs and served as chief technologist for the u.s. federal trade commission. he opened with the assertion that agility is essential: ﬁit is not even worth discussing whether or not we need it,ﬂ he said. declaring that little of the cryptography that was used 20 years ago is particularly useful anymore, he suggested the same may well be true 20 years hence. publickey algorithms, for example, will not pass muster in a postquantum world. agility is necessary, he emphasized, because an algorithm cannot simply be turned off and replaced with a new one overnight. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.54key agility challengescryptography itself is already very difcult, and, like other workshop speakers, bellovin acknowledged that adding agility invites complications such as new failure modes or downgrade attacks. the transport layer security (tls) anecdote illustrates this fact: many tls errors stem from supporting legacy export ciphers needed for policies that were changed more than 15 years ago. ﬁmost organizations cannot get this stuff right, even the very best,ﬂ bellovin said. ﬁit is just inherently a really hard problem.ﬂhe pointed to the oldest cryptographic protocol in the open literature1 as another example of these challenges; 18 years after the paper was published, a new attack on the protocol was discovered. later, when newly discovered weaknesses in messagedigest algorithm5 (md5) and secure hash algorithm1 (sha1) required that new ones be deployed, bellovin and eric rescorla reported that all the major internet engineering task force (ietf) protocols made mistakes with hash functions negotiation in part because only those two algorithms existed when the protocols were designed.2 put simply, the negotiation process required knowledge of the newer algorithms, but older systems would not know them. in this case even the ietf, representing the eld™s elite experts, ﬁtried hard and got it wrong,ﬂ he said, underscoring the risks for companies attempting to design their own cryptographic agility approaches. bellovin also expressed doubt that negotiation toolkits, code, or application programming interfaces (apis) designed by standards bodies would necessarily fully address these challenges. citing a study that found 80 percent of mobile applications contain cryptography errors in the tls protocol alone,3 he asked, is it likely those designing new mobile applications would understand the even more complex systems under discussion today?a further complication is that when code or protocols are designed successfully, they eventually are used by people all over the world, and so the possibility of transition from one cryptosuite to another must be factored into the design. transition, he emphasized, is a very difcult event to anticipate. he suggested nding ways to test a protocol transition in a limited domain before the system is deployed broadly. this can help illuminate whether there are issues not only with the syntax of the transition but also with the semantics when there are multiple security systems involved. when signing executable programs, for example, the semantics of the signatures should signal whether or not the 1r.m. needham and m.d. schroeder, 1978, using encryption for authentication in large networks of computers, communications of the acm 21 (12): 993999, http://dl.acm.org/citation.cfm?id=359659. 2s. bellovin and e. rescorla, 2006, ﬁdeploying a new hash algorithm,ﬂ paper presented at the nist cryptographic hash workshop, august 2425, santa barbara, calif., http://www.internetsociety.org/sites/default/les/deployingnewhashalgorithm.pdf. 3veracode, 2015, state of software security report: focus on application development (supplement to volume 6), https://www.veracode.com/sites/default/les/resources/reports/stateofsoftwaresecurityfocusonapplicationdevelopment.pdf. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.55code is secure, he explained. he also noted that there have been a number of cases in which trouble stems from the version numbers of the protocols. in the discussion, bellovin shared his calculation that a comprehensive cryptographic upgrade takes about 12 to 15 years from algorithm design to deployment. that timeline accounts for the time it takes for older systems to die off and be replaced, which he estimated at about 5 years on average for generalpurpose computers (shorter for items like phones and longer for items like cars), and about 10 years on average for the engineering, certication, protocol work, design, coding, and testing. though this upgrade process takes a long time, bellovin said, ﬁi cannot see how to lower that number.ﬂ embedded systems and the internet of thingsbellovin shared his perspective that the biggest problem in agility today is embedded systems such as the computers that are now being built into cars and many other internet of things devices. many connected items in the internet of things world lack an update path. while the product itself may need to last for many years, the upgrade lifetime for such systems is actually quite short. rather than supporting upgrades to existing chips and devices, vendors have a nancial incentive to abandon old systems and focus on selling new ones with new chips. today™s connected cars will likely be running cryptography that is 15plus years old at the end of their useful lives, he noted, which raises a host of questions: how can security and functionality be balanced? can the system even be updated? if it cannot, how could a new algorithm be added? bellovin added, ﬁit is especially serious when it comes to agility because algorithms age in a way that other software does notšbecause new attacks are discovered.ﬂpointing to dan geer™s suggestion of a ﬁsuicide dateﬂ for embedded systems,4 bellovin suggested that a guaranteed lifespan of 5 yearsšnot shorter, not longeršmight be one potentially viable approach. such a system could be appealing to vendors, who would sell consumers replacement products after 5 years, and potentially palatable for consumers, who typically are limited to short warranty periods and may benet from a longer period of guaranteed support, even if it comes at the cost of a rm end date. bellovin considered potential approaches to making such devices updatable. would it be possible, he wondered, to decouple the algorithm and protocol update capability 4d. geer, 2014, ﬁsecurity of things keynote address,ﬂ address presented at security of things forum, may 7, cambridge, mass., http://geer.tinho.net/geer.secot.7v14.txt. should algorithm and protocol update capabilities be decoupled from more general software updates?cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.56from the more general software update in order to facilitate upgrades? another problem emerges when vendors go out of business, a somewhat common occurrence in the hightech world. an open api might allow users to make updates themselves in such situations, though an open api also invites its share of problems, not least of which is who maintains the public keys needed to authenticate such updates.more promising, he suggested, are solutions that include parameterized algorithms that allow a higher iteration count, different round counts, and different substitution boxes, for example. downgrade attacks and correctness errors could still cause problems, but these solutions could introduce more agility for embedded systems. new algorithms could be designed to allow for negotiable parameters, which might affect eld lengths but would address the upgrade problem, he said.considering unintended consequencesagility can allow for weaker cryptography to persist, which bellovin emphasized was problematic for many reasons: ﬁbackwards compatibility can be ‚bugwards compatibility,™ and that is a threat we have to meet as well.ﬂ while downgrade attacks need to be prevented, he acknowledged that sometimes it is necessary to roll back to an older version of a security mechanism because the newer one is not working. agility requires thinking seriously about consequences and making unpopular decisions. in addition, he said, outofband knowledge is important when transitioning to a new algorithm. for instance, it can help a service declare its security intentions, such as ﬁi will never again accept tls 1.1 or below. it is not secure. if you see this from me, it is wrong.ﬂ yet such capability is not typically supported and is challenging in systems containing disparate embedded systems (for example, there are at least 50 in a modern car), which typically do not have a centralized system administrator.new algorithms being written should be open to small changes without having to go through major overhauls to the algorithm, its eld sizes, or iterations, bellovin said. designers need to prove not just the algorithm, but also iteration counts and key sizes that would work. in addition, negotiating a stronger mode of operation could help keep ciphers useful, as long as the data structures support that. bellovin concluded, ﬁwe still need to protect the negotiation for algorithm agility.ﬂ although this is challenging when even the primitives are under threat, bellovin suggested research on privacy protection and secure ﬁratchetingﬂ (always increasing the security levels) to protect against downgrade attacks could help address these challenges. peter swire, georgia institute of technology, asked whether there could be something to learn from the design of highly trusted critical systems, such as the software used in aviation. bellovin responded that highly trusted systems in fact raise additional challenges in the context of agility because there is often not a full understanding of cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.57the consequences of making changes. that is one reason, he said, that hospitals are not updating their windows xpœdependent magnetic resonance imaging machines (and, he noted, putting their systems at risk as a result).wrapping up, bellovin expanded on the privacy and human rights implications of certain approaches to cryptographic agility. one, he said, is that if agility weakens overall security, authoritarian governments will be able to spy on people more easily. another concern is that too much ˚exibility for individuals to choose their cryptography could lead to ﬁngerprintingﬂ users based on their preferred security proles. similarly, if a certain website requires an unusual combination of cryptographic parameters, this could make it easy to expose and track the activities of a specic user. a postquantum algorithm cannot use today™s publickey algorithms because they would be broken too easily. the alternative, to use symmetric encryption with a universal key distribution center (kdc), would be a challenge, bellovin said, because it creates a single vulnerable point that puts everyone™s privacy and security at risk if it were broken. a kdc could make it possible to track every website a user visits, creating, in bellovin™s view, ﬁa very serious privacy threat.ﬂ agility and the need to prepare for failurejohn manferdelli, google, inc.john manferdelli is a mathematician at google, inc. (as engineering director) and has also worked at intel (as senior principal engineer) and microsoft. he began by reiterating that agility is importantšnot only in the context of cryptography, but also more broadlyšbecause nothing lasts forever. key management systems and implementations eventually fail, and operational errors eventually arise. ﬁyou have to be able to change things quickly,ﬂ manferdelli said, noting that at the same time, ﬁyou really cannot anticipate what you have to change.ﬂaiming for agility while acknowledging its limitationsmanferdelli noted that agility is important and applies to more than just cryptographic agilityšit is not always clear in advance what will need to be changed, and changed quickly. for example, implementation agility, or the ability to change things in the eld, is crucial. manferdelli pointed to a 2002 event in which a certication authority issued a certicate that looked like it belonged to microsoft but was issued to another party. agility allows a company to revoke fraudulent certicates. instead, microsoft had to recongure the operating system explicitly to render that certicate void. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.58manferdelli expressed doubt that perfectly agile cryptography could ever be designed, in part because it is not possible to fully anticipate all user needs. while acknowledging that designers are ﬁactually pretty goodﬂ at substituting cryptography algorithms like symmetrickey systems, as requirements become more complicated (e.g., wanting both secrecy and integrity), the challenges to designing cryptographic systems increase. commenting on an earlier statement from butler lampson, manferdelli agreed with the advice to ﬁalways be a little circumspect about what you want to make secure.ﬂ there are some things we can get right, and we should try to do sošimplementation agility is an important part of accomplishing thisšbut it must be acknowledged that no device or interface will work for ﬁeverything in the world forever and ever,ﬂ he said. this idea comes into play in the debate over cipher negotiation, for example. on the one hand, negotiation can be a bad thing because there is a chance that a developer or user could make a mistake. on the other hand, developers and users need tools. trying to create a solution that completely satises all scenarios creates an argument with no right answer, and no winner, manferdelli said. another reason we need agility, he emphasized, is because anything that is used long enough will eventually be cracked by attackers. ﬁreally, the best line of defense is being able to change things,ﬂ he said, suggesting that modest goals are preferable to trying to create something to last 50 years. even algorithms change, he said, noting that this has not always, in his experience, been well appreciated: when he rst began working on security for windows, for example, there was no one working on cryptography because it was considered so unlikely that anyone would ever need to move on from md5, data encryption standard (des), or rsa 1024. facing the quantum threatquantum computing is seen as perhaps the biggest reason publickey algorithms might need to change. quantum computing would also bring new opportunities, he noted. computers have been built on the same model since the 1940s, and quantum computing would offer strikingly different capabilities. for that reason alone, it would be wise to plan for agility and to take advantage of cryptographic advances where they emerge. whatever the likelihood that quantum computing will be invented, and however uncertain we are about when it might become a reality, manferdelli emphasized that it is important to plan for a quantum threat because of its potential catastrophic consequences. on the positive side, he is optimistic that quantumresistant algorithms will be created and that they can be added to existing cryptographic systems. while recognizing that dealing with quantum computing would be a huge change (key sizes alone would need to be much larger), manferdelli expressed condence that the computing world can meet these challenges. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.59during the discussion, william sanders, university of illinois, urbanachampaign, explored the topic of implementation agility, questioning whether it would be straightforward to create a framework now that would be usable if quantum computing capabilities were to be realized. manferdelli responded that while he does believe agility is important and improving, it is essential to recognize that errors will inevitably occur. ﬁyou are just not going to get it right the rst time,ﬂ he said. testing and understanding the agile layer fully, before implementation, will save money and conguration problems in the long run. he suggested creating and testing quantumresistant algorithms now, perhaps inside a cipher suite. either an upgrade strategy or short service life could help when a new protocol inevitably goes wrong.why resist agility?manferdelli considered the reasons for resistance to the idea of using or requiring agility. besides the quantum threat, there are plenty of good reasons to use agility todayšfor example, to address the mistakes that are causing today™s keys and information to leak. having fully agile systems is ideal, but even ﬁjust changing keys every once in a while would not be such a bad idea,ﬂ he said. in the past, he said, one reason for not using agility was that the code was so brittle and easily broken when changes were attempted. another was that there was a pervasive resistance to adding new software. manferdelli said both of these issues are now more nuanced, the code libraries have improved, and algorithms can now be switched out successfully as long as the format of the output is not changed too much. managing keys is another reason people avoid agility. noting a rumor that apple had not allowed any new certicates for 6 months, he explained that root keys and certicates last a long time, which causes problems. he pointed to some improvements in this area, including key pinning (a security technique used to prevent ﬁmaninthemiddleﬂ attacks) and certicate transparency. key pinning via upgrades allows a secure, trusted key to persist through the upgrade. such a system allows a measured, reliable security device to travel with a user. another factor is that some businesses might not want to remove old algorithms because they do not want to reduce their market share, which is not something that technological improvements can necessarily address. often, businesses do not make changes until a catastrophic event happens; otherwise, they do not see their business as being impacted.preparing for failurethe biggest problem when making upgrades is that, as with cryptography generally, one can never predict what is going to break, and manferdelli asserted that the debate over cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.60agility today will not be solved until upgrades can be guaranteed to happen. noting that the old bell telephone system was required to run expensive tests to check periodically for catastrophic failure, he suggested it might be good for computer systems and the people who build them to run similar tests. whether one views the glass as halffull or halfempty (or completely empty), it is crucial to prepare for failure, manferdelli asserted. for example, key management might be congured so that keys are expected to change frequently. ﬁany prudent person will really want to be able to make sure they can change their keys quickly,ﬂ he said. while recognizing that complex systems have a lot of moving parts, he asserted that it is possible to allow for key agility, not just algorithm agility. embedded applications with certicate transparency, which make issuing fraudulent certicates more difcult, could also help. it is also necessary, manferdelli noted, to continue monitoring and analyzing keys to make sure that the retired ones are truly retired. kocher, cryptography research division, rambus, inc., expanded on this point in the discussion. one step in deciding whether to retire a protocol is to determine how many people or programs are still using it. kocher wondered if that inadvertently allows attackers to encourage the use of an older, unsafe protocol: if they can force enough trafc through it, it might never be turned off. clarifying that he had spoken specically about key use, and not protocols, manferdelli also expressed support for monitoring and analyzing protocol use, as well as creating an inventory of existing protocols. returning to the focus on keys, he asserted that ﬁthere is really no downside in keeping an eye on what keys people are using and going after them and tapping them on the shoulder and saying, ‚this was not a great idea.™ﬂ to this, bob blakley, citigroup, inc., added that creating a key inventory, especially in a large company, is a very difcult task.wrapping up his presentation, manferdelli shared his hope that a sensible conclusion could be reached on the topic of access to plaintext by law enforcement. under certain circumstances, he allowed that there should be a way for law enforcement to access evidence in data, but giving law enforcement universal access is not, in his view, the optimal way to achieve it. creating a key inventory, especially in a large company, is a very  difcult task.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.61the broader problem of software updatesparticipants discussed the broader context of agility. thinking holistically, the agility problem is not merely one of cryptography; it is a problem for the entire computing system. steven bellovin categorized software update problems as ﬁendishly difcultﬂ research problems that are much harder than the cryptographic agility problem on its own. he pointed out that every major software vendor has experienced update problems, where a patch either had to be recalled or replaced, or it ended up breaking devices completely. manferdelli concurred, though he noted signs of progress, including a recent switch in parts of the u.s. government from a policy of not updating software until exhaustive qualication and certication tests are complete to embracing updates as they are released. fred schneider, cornell university, asked how governance of software updates might t into the discussion, describing a situation in which a user buys a product that is later updated in a way that affects the product™s security or privacy framework. who has control over access to our devices, he askedšthe manufacturers, the government, or some sort of mixed authority? agreeing that it presents a complicated research problem, manferdelli said that the usual practice is to set expectations and legal responses, though the expectations in this context are currently unclear. with regard to the matter of setting a lifetime for embedded devices, for example, manferdelli said that he did not have a specic answer. ﬁi would certainly like it if there were wellformed, wellthoughtout expectations,ﬂ he concluded. ﬁthen, you could think about how policy might ˚ow from that.ﬂ cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.62discussion and wrapup6 the workshop concluded with a period of open discussion, giving speakers and participants a chance to emphasize what they considered the most essential issues and revisit concerns raised earlier in the day. this chapter, organized into thematic areas, describes the content of the nal discussion, highlighting some of the broader themes that emerged throughout the workshop. opening the discussion, paul kocher, cryptography research division, rambus, inc., said that the day™s presentations had ﬁturned what i thought was a hard problem into a really hard problem.ﬂ agility is necessary, but imperfect, he summarized. what can we do to advance agility in a way that does not cause as many problems as it solves? planning for an uncertain futurealthough we can never predict exactly what the future will hold, two main themes emerged throughout the workshop: (1) the potential threat of quantum computing and (2) the near certainty that vulnerabilities will eventually be discovered in any security system, even without quantum computing.kocher expanded on the difculties of devising strategies to address asyetunknown problems. some challenges, such as specic ciphers failing, are easier to solve, while others, such as quantum computing, inevitable software bugs, or the need to cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.63change root keys managed by someone else, are much more difcult. the ﬁunknown unknownsﬂ present particular challenges: what could happen? what is the probability that it will happen? sara brody, simply secure, noted that because we know certain types of vulnerabilities will inevitably keep happening, a network to share information and resources when a bug or other problems are noticed would be useful. bob blakley, citigroup, inc., pointed out that some sectors, such as nancial services, have created information sharing and analysis centers to do just that. participants explored the implications of a catastrophic security failurešsuch as one caused by quantum computingšand what might be done now to prevent or prepare for such an event. peter swire, georgia institute of technology, suggested that institutions will be critical to forging a path forward during and after such an event, and he posited that addressing a disaster will require not only technical solutions and expertise but also communication with society at large and the identication of critical leaders across sectors. blakley brought up a common practice in the corporate security world: using tabletop or paper exercises to test out new ideas or predict their consequences. perhaps this approach could be applied to help organizations envision the problems they may face by simulating a scenario of cryptographic systems breaking. anita allen, university of pennsylvania, agreed that tabletop exercises would be useful in designing for transition and, even more importantly, in designing for disaster. in the context of disaster, she added that it is also important to plan responses to breaches or damages that threaten cultural heritage. butler lampson, microsoft corporation, suggested that live exercises, though more expensive than tabletop exercises, can be more illustrative. several participants noted that organizations often do both tabletop and live exercises, learning different lessons from each. technical solutionsparticipants explored ideas for technical approaches that could help to mitigate agility challenges and allow for more effective ways to improve the prospects of future agility. kocher raised the fundamental tension created by the fact that, because we do not know what future protocols and implementations will look like, we cannot build or test them now. compounding this is the extremely fast pace at which companies develop and deploy products today, leaving little time for thorough testing. identifying testing as an area with room for improvement, he suggested that perhaps, as part of ensuring compliance with standards, designers could use standard test suites or put more emphasis on checking to make sure that implementations interoperate with other systems. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.64later, swire suggested that all of the interactions within today™s dense networks create issues that cannot be identied with tests that focus on updating one system interacting at one level. given that it is so difcult to test an individual system (and get results that are re˚ective of the realworld context), he asked if a new approach is warranted.kocher pointed out that there are good test suites available for ciphers but not for protocols. our current disasterplanning mechanisms are reliant on these protocols, he said, but there is no easy way to test them to see if they will work when they are needed. and while they are not actually hard to test, there is no incentive for companies to do so. perhaps one solution could be to build a shared protocol testing center that would benet the entire ecosystem of electronic communicationsšsystems, products, and users. john manferdelli, google, inc., suggested the notion of a ﬁsafe harborﬂ in which the demonstration of some specic level of upgradeability and transparency would be considered due diligence. if crafted well, such an approach could help to put bounds on the expectations for testing and upgrades that would be useful for designers and manufacturers. migrationšmoving existing systems from one cryptography system or approach to anotheršis an additional key issue. kocher identied four separate elements to migration: designing better cryptography, implementing cryptography for maximum interoperability, turning off old cryptography, and fully removing the old cryptography. each of these elements presents unique challenges. blakley used a medical metaphor to introduce what he called a radical proposal: while liver transplants are possible because the liver is a discrete organ, spinal transplants are not because the spine is so interconnected with the rest of the body. he wondered if cryptography could be made more like a discreet organ by constraining in ways that would allow engineers to separate cryptographic agility from systems updates. kocher pointed out that hardware would also need to be addressed. manferdelli noted that as a designer, he was sympathetic to the goal of streamlining systems, but he expressed concern about the potential for this approach to sacrice aspects of the cryptography itself and perhaps undermine security. sharing expertiseparticipants noted that agility requires making tough choices, and those with the greatest expertise should be helping others make informed decisions. ﬁwhen the experts cannot decide among themselves so you pass the difcult problem off to a nonexpert, that is not really xing the problem,ﬂ kocher asserted. transparency and governance are also areas in which experts should be making or more actively informing choices, he said.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.65steven bellovin, columbia university, noted that all stakeholders, including researchers, standards bodies, engineers, and developers, have a role in solving agility problems, but their specic roles depend on which problem is being examined. software updates are a vendorspecic problem, he suggested. systems administration could benet from more academic research, but thousands of details and consequences, as opposed to unifying principles, make this area ﬁmessyﬂ and therefore not very popular among academic researchers. standards bodies, he suggested, also need to increase their involvement. pointing to examples in which things have gone wrong despite the involvement of standards bodies like the internet engineering task force, bellovin asserted that standards bodies and academia need to feel a greater sense of responsibility or ownership for standards and upgrades. ﬁacademia has to look at this even when it is not nice and neat and academic, and this does not happen,ﬂ he said.with regard to a problem mentioned by nearly every speaker at the workshopšobsolescence and legacy cryptographyšdavid vladeck, georgetown university, proposed looking for legal solutions, pointing to warranties as a potential analog from which to draw. international issues and human rightsparticipants noted that cryptography and agility are in fact global issues, and different nations have drastically different philosophies on privacy, security, and government access to data and communications. swire noted the prospect of increased regulation by countries including china and russia, though he expressed doubts that the united states would move very far in that direction because doing so would threaten its own technology industry. the more general pointšthat there will likely be signicant variation among nations in approaches to cryptography and technology more broadlyšis something he noted will increase the complexity of cryptographic agility approaches. several participants expressed concern about the impact of cryptographic agility on human rights. deirdre mulligan, university of california, berkeley, said that some governments will restrict the use of encryption by citizens. mulligan and allen expanded on that point, explaining that encryption and anonymity are enablers of other human rights, including freedom of expression, freedom of speech, and limited government surveillance. mulligan pointed out that david kaye, the united nations™ special rapporteur on the promotion and protection of the right to freedom of opinion and expression, recently concluded that restrictions on cryptography as an enabler of freedom of expression must be consistent with human rights laws, provided for by law, only imposed for legitimate reasons, and compliant with strict standards. he concluded that any proposal to restrict encryption should be subject to public comment, follow legislative processes, cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.66and be subject to strong procedural and judicial safeguards; these same concerns for human rights should apply, mulligan suggested, in the context of decisions made not only by governments, but also by companies like google, facebook, and microsoft. ﬁi think that there is a real need to be really sensitive to the role of agility and thinking about human rights,ﬂ mulligan asserted. ﬁi think it is a really important part of the conversation.ﬂ building on this point, allen suggested that rather than anonymity or encryption being discussed as human rights themselves, it is perhaps more useful to focus on the role of encryption and anonymity in other human rights including freedom of expression, freedom of speech, and limited government surveillance. tadayoshi kohno, university of washington, added that user demographics should also be a part of the human rights discussion. all users should benet equally from agility and upgrade mechanisms, not just those who can afford to buy (and rapidly replace) highend devices. agility beyond cryptographynoting that failures are inevitable, steven lipner, independent consultant, underscored that everyone would stand to benet from agility mechanisms to deal with vulnerabilities, whether they come from quantum computing, algorithm errors, or merely from the passage of time. one step forward, he suggested, is funding research into these areas. another is for large organizations to devote more engineering expertise to prevent and prepare for failure. william sanders, university of illinois, urbanachampaign, pointed out that the workshop discussions had touched on many aspects of agilityškeys, algorithm replacement, full software upgrades, and morešand suggested that this wideranging eld may benet from a closer look at what, exactly, is desirable in agility. the answers to such questions could help inform an agility framework and determine a goal for ﬁhow agileﬂ our systems should be. lampson suggested that an important aspect of the agility context has been overlooked: computing is increasingly service based. while updates to hardware or software matter, so do cloudbased services such as microsoft™s ofce 365 or google™s chrome. he expressed concern that many of the agility ideas being explored are ﬁrooted in computing practices that are rapidly disappearing.ﬂ building on this point, mulligan noted that the internet of things, products without update channels, and other such issues also raise important questions that go beyond cryptographic agility itself. she referred back to brody™s suggestion that examining the behaviors and motivations of developers and users could provide useful tools for addressing these broader issues. cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.67appendixescryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.68workshop agenda and participants listaworkshop on cryptographic agility and interoperability spring 2016 meeting of the forum on cyber resiliencemay 9, 2016keck center of the national academies of sciences, engineering, and medicinewashington, d.c. agenda10:00 a.m. welcome and overview fred b. schneider, forum on cyber resilience chair10:05 context setting bob blakley, forum member  paul kocher, forum member10:55 break11:10 government and infrastructure session moderator: steven lipner, forum member kerry mckay, national institute of standards and technology richard george, johns hopkins university applied physics laboratory12:00 p.m. break for lunch 1:00 standards and security implications session moderator: mary ellen zurko, forum member  russ housley, vigil security, llc david mcgrew, cisco systems, inc.1:50 breakcryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.692:05 engineering at scale and user implications session moderator: eric grosse, forum member matthew green, johns hopkins university adam langley, google, inc. sara brody, simply secure3:20 break3:35 research, industry, and policy implications session moderator: bob blakley, forum member steven bellovin, columbia university john manferdelli, google, inc.4:25 wrapup discussion and q&a moderator: paul kocher, forum member5:00 reception forum members, speakers, and attendeescryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.70participants listanita allen, university of pennsylvaniasteven bellovin, columbia universitybob blakley, citigroup, inc.shenae bradley, national academies of sciences, engineering, and medicinesara (scout) sinclair brody, simply securefred cate, indiana universitydavid clark, massachusetts institute of technologydonna dodson, national institute of standards and technology jon eisenberg, national academies of sciences, engineering, and medicinerichard george, johns hopkins university matthew green, johns hopkins universityeric grosse, google, inc.david hoffman, intelruss housley, vigil security, llcpaul kocher, cryptography research division, rambus, inc.tadayoshi kohno, university of washingtonbutler lampson, microsoft corporationadam langley, google, inc.steven lipner, independent consultantjohn manferdelli, google, inc.brad martin, national security agencydavid mcgrew, cisco systems, inc.kerry mckay, national institute of standards and technologylynette millett, national academies of sciences, engineering, and medicinedeirdre mulligan, university of california, berkeleykatiria ortiz, national academies of sciences, engineering, and medicinetony sager, council on cybersecuritywilliam sanders, university of illinois, urbanachampaignfred b. schneider, cornell universitypeter swire, georgia institute of technologydavid vladeck, georgetown universitymary ellen zurko, cisco systems, inc.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.71planning committee biographiesfred b. schneider, chair, is the samuel b. eckert professor of computer science at cornell university and chair of the department. he joined cornell™s faculty in fall 1978, having completed a ph.d. at stony brook university and a b.s. in engineering at cornell in 1975. schneider™s research has always concerned various aspects of trustworthy systemsšsystems that will perform as expected, despite failures and attacks. most recently, his interests have focused on system security. his work characterizing what policies can be enforced with various classes of defenses is widely cited, and it is seen as advancing the nascent science base for security. he is also engaged in research concerning legal and economic measures for improving system trustworthiness. dr. schneider was elected a fellow of the american association for the advancement of science (aaas; 1992), the association of computing machinery (acm; 1995), and the institute of electrical and electronics engineers (ieee; 2008). he was named a professoratlarge at the university of tromso (norway) in 1996 and was awarded a doctor of science (honoris causa) by the university of newcastleupontyne in 2003 for his work in computer dependability and security. he received the 2012 ieee emanuel r. piore award for contributions to trustworthy computing through novel approaches to security, fault tolerance, and formal methods for concurrent and distributed systems. the national academy of engineering (nae) elected schneider to membership in 2011, and the norges tekniske vitenskapsakademi (norwegian academy of technological sciences) named him a foreign member in 2010. he is currently a member of the national academies of sciences, engineering, and medicine™s naval studies board and computer science and telecommunications board, and he is founding chair of the national academies™ forum on cyber resilience.anita l. allen is the henry r. silverman professor of law and professor of philosophy at the university of pennsylvania law school, where she is also the university™s vice provost for faculty. she is an expert on privacy law, bioethics, and contemporary values, and is recognized for her scholarship about legal philosophy, women™s rights, and race relations. in 2010 allen was appointed by president obama to the presidential commission for the study of bioethical issues. her books include unpopular privacy: what must we hide (2011); privacy law and society (2011); the new ethics: a guided tour of the 21st century moral landscape (2004); why privacy isn™t everything: feminist reections on personal accountability (2003); and uneasy access: privacy for women in a free society (1988). bcryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.72she coedited (with milton regan) debating democracy™s discontent (1998). allen, who has written more than 100 scholarly articles, has also contributed to popular magazines and blogs and frequently appeared on nationally broadcast television and radio programs. allen has served on numerous editorial and advisory boards, and on the boards of a number of local and national nonprots and professional associations including the hastings center, the electronic information privacy center, and the bazelon center for mental health law. eric grosse is a senior member of the google security team and was previously vice president of security and privacy engineering at google in mountain view, california, leading a team of 512 who ensure systems and data stay safe and users™ privacy remains secure. improved and wider use of secure sockets layer (ssl), stronger consumer authentication technology, detection and blocking of espionage, transparency on legal requests for data, sophisticated malware analysis, and tools and frameworks for safer building of web applications are among the achievements of the google security team. before google, grosse was a research director and fellow at lucent bell labs where he worked on security, networking, algorithms for approximation and visualization, software distribution, and scientic computing. he has a ph.d. in computer science from stanford university.butler w. lampson is a technical fellow at microsoft corporation and an adjunct professor at the massachusetts institute of technology. he has worked on computer architecture, local area networks, raster printers, page description languages, operating systems, remote procedure call, programming languages and their semantics, programming in the large, faulttolerant computing, transaction processing, computer security, ﬁwhat you see is what you getﬂ (wysiwyg) editors, and tablet computers. he was one of the designers of the scientic data systems (sds) 940 timesharing system, the alto personal distributed computing system, the xerox 9700 laser printer, twophase commit protocols, the autonet local area network, the simple publickey infrastructure system for network security, the microsoft tablet personal computer software, the microsoft palladium highassurance stack, and several programming languages. he received the acm software systems award in 1984 for his work on the alto, the ieee computer pioneer award in 1996 and von neumann medal in 2001, the turing award in 1992, and the nae™s draper prize in 2004. he is a member of the national academy of sciences and the nae as well as a fellow of the acm and the american academy of arts and sciences.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.73susan landau is professor of cybersecurity policy in the department of social science and policy studies at worcester polytechnic institute. landau has been a senior staff privacy analyst at google, a distinguished engineer at sun microsystems, and a faculty member at the university of massachusetts, amherst, and wesleyan university. she has held visiting positions at harvard university, cornell university, yale university, and the mathematical sciences research institute. landau is the author of surveillance or security? the risks posed by new wiretapping technologies (2011) and coauthor, with whiteld dife, of privacy on the line: the politics of wiretapping and encryption (1998, rev. ed. 2007). she has written numerous computer science and public policy papers and opeds on cybersecurity and encryption policy and testied in congress on the security risks of wiretapping and on cybersecurity activities at national institute of standards and technology™s information technology laboratory. landau currently serves on the computer science telecommunications board of the national academies. a 2012 guggenheim fellow, landau was a 20102011 fellow at the radcliffe institute for advanced study, the recipient of the 2008 women of vision social impact award, and also a fellow of the american association for the advancement of science and the acm. she received her b.a. from princeton university, her m.s. from cornell university, and her ph.d. from mit.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.74speaker biographiessteven bellovin is a professor of computer science at columbia university, where he does research on networks, security, and especially why the two do not get along. he joined the faculty in 2005 after many years at bell labs and at&t labs research, where he was an at&t fellow. while a graduate student, bellovin helped create netnews; for this, he and the other perpetrators were given the 1995 usenix lifetime achievement award (the flame). he is a member of the national academy of engineering (nae) and is serving on the department of homeland security™s science and technology advisory committee; he has also received the 2007 national institute of standards and technology (nist)/national security agency (nsa) national computer systems security award. bellovin is the coauthor of firewalls and internet security: repelling the wily hacker and holds a number patents on cryptographic and network protocols. he has served on many national academies of sciences, engineering, and medicine study committees, including those on information systems trustworthiness, the privacy implications of authentication technologies, and cybersecurity research needs; he was also a member of the information technology subcommittee of a national academies study group on science versus terrorism. he was a member of the internet architecture board (iab) from 1996 to 2002; he was codirector of the security area of the internet engineering task force (ietf) from 2002 through 2004. he received a b.a. from columbia university, and an m.s. and ph.d. in computer science from the university of north carolina, chapel hill.bob blakley is global director of information security innovation at citigroup, inc. he recently served as plenary chair of the national strategy for trusted identities in cyberspace identity ecosystem steering group and as research and development cochair of the financial services sector coordinating council for critical infrastructure protection and homeland security. he is currently a member of the forum on cyber resilienceša national academies™ roundtable. prior to joining citigroup, inc., blakley was distinguished analyst and agenda manager for identity and privacy at gartner and burton group. before that, he was chief scientist for security and privacy at ibm. he is past general chair of the institute of electrical and electronics engineers (ieee) security and privacy symposium and the applied computer security associates new security paradigms workshop. he was awarded the annual computer security applications conference™s distinguished security practitioner award in 2002 and is a frequent speaker at information security and computer industry events. blakley was general editor of the obccryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.75ject management group corbasecurity specication and the oasis security assertion markup language specication, and is the author of corbasecurity: an introduction to safe computing with objects. he was the rst chair of the open authentication joint coordinating committee. he also participated in the national academies™ panels ﬁauthentication technologies and their privacy implicationsﬂ and ﬁwhither biometrics.ﬂ blakley holds 20 patents in cryptography and information security, and he publishes regularly in the academic literature on information security and privacy. blakley received the a.b. in classics from princeton university, and the m.s. and ph.d. in computer and communications science from the university of michigan.sara ﬁscoutﬂ sinclair brody is executive director of simply secure. simply secure functions as part consultancy, part research group, as it advises those using secure communication tools on how to make those tools easier to use. brody has been establishing and managing the organization and works with user experience experts, software developers, and users in order to improve the usability of opensourced securecommunications software. previously, as an assistant product manager and later a product manager at google, she worked on projects such as twostep verication, the android operating system, and uproxy. she currently holds two patents in connection with her research. she earned her b.a. in computer science and french from wellesley college and her ph.d. in computer science from dartmouth college. is the senior advisor for cybersecurity at the johns hopkins university (jhu) applied physics lab (apl). at apl, he works on a number of projects sponsored by the u.s. government and provides oversight on additional efforts. prior to joining apl, he worked at nsa as a mathematician from 1970 until his retirement in 2011. while at nsa, he wrote more than 125 peerreviewed technical papers on cryptomathematical subjects, ranging from new mathematical methods for attacking cryptographic algorithms, to security evaluations of complex systems. while at nsa, his work was recognized by the cryptomath institute as the most important mathematical contribution to the agency™s mission in 1980, as well as by two presidential rank awards, a superior technical award, and a distinguished senior technical achievement award. he was elected to distinguished member status into both the cryptanalytic society (kryptos) and the cryptomath society (cmi). he served as the technical director of the information assurance directorate for 8 years until his retirement.matthew green is assistant professor at the jhu information security institute. he researches techniques for privacyenhanced information storage, anonymous payment systems, and bilinear mapbased cryptography. he had worked previously as assistant cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.76research professor and assistant research scientist at jhu before becoming an assistant professor. prior to working for jhu, he was a former partner in independent security evaluators, a custom security evaluation and design consultancy. he worked as a senior technical staff member at at&t labs/research. green runs the blog ﬁa few thoughts on cryptographic engineering.ﬂ he earned his b.s. in computer science from oberlin college, a b.m. in electronic music from oberlin college, and his m.s. and ph.d. in computer science from jhu. russ housley formed vigil security, llc, in september 2002 with the goal of helping customers design and implement diligently watchful security solutions. housley has worked in the computer and network security eld since 1982. before starting vigil security llc, he worked at the air force data services center, xerox special information systems, spyrus, and rsa laboratories. his security research and standards interests include security protocols, certicate management, cryptographic key distribution, and high assurance design and development practices. he has been active in many security standards organizations; his recent focus has been on the ietf. since march 2013, housley began serving in the position of iab chair, which is a voting member of the iab, as well as a nonvoting exofcio member of the internet engineering steering group (iesg), a voting member of the ietf administrative oversight committee (iaoc), and a trustee for the ietf trust. this position gives housley a voice in the main leadership and management groups within the ietf. from march 2007 to march 2013, he served in the position of ietf chair, making him the chair of the iesg, a voting member of the iab, a voting member of the iaoc, and a trustee for the ietf trust. from march 2003 to march 2007, housley served in the position of ietf security area director, making him a member of the iesg. prior to accepting the area director position, he chaired the ietf secure/multipurpose internet mail extensions working group, and he has contributed to several cornerstone internet publickey infrastructure standards (including rfc 5280). in november 2004, housley was recognized by the ieee 802.11 working group for his contributions to ieee 802.11i2004, which xes the severe security shortcoming of the wired equivalent privacy. russ provided major contributions to several security protocols, including the cryptographic message syntax, sdns security protocol 4 (sp4), sdns message security protocol, ieee 802.10b secure data exchange protocol, and ieee 802.10c key management protocol. housley received his b.s. in computer science from virginia tech in 1982, and he received his m.s. in computer science from george mason university in 1992.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.77paul kocher is president and chief scientist of cryptography research, a division of rambus, inc. kocher has gained an international reputation for his research and innovative designs in cryptography. an active contributor to major conferences and leading security initiatives, he has designed numerous cryptographic applications and protocols which are successfully deployed in realworld systems. his accomplishments include discovering timing attacks and differential power analysis (including techniques for preventing against these vulnerabilities), helping author the widely used secure sockets layer 3.0 standard, and leading the design of the recordbreaking data encryption standard key search machine. kocher has recently focused on developing antipiracy technologies for securing digital content. he was elected to the nae in 2009. kocher founded cryptography research, previously held positions at rsa security, and was a founding member of valicert, inc. (now tumbleweed). he holds a b.s. degree from stanford university.adam langley is a principal software engineer at google, inc., where he manages ssl/tls across google™s products.john manferdelli is engineering director at google, inc. he currently serves as a member of the information science and technology advisory group at the defense advanced research projects agency and the defense science board. prior to joining google, manferdelli was a senior principal engineer at intel corporation and copi (with david wagner) for the intel science and technology center for secure computing at the university of california, berkeley. before that, he was a distinguished engineer at microsoft and was an afliate faculty member in the computer science department at the university of washington. during his time at the university of washington, he was responsible for research regarding computer security, cryptography, systems, and quantum computing. he holds a b.s. in physics from cooper union for the advancement of science and art and a ph.d. in mathematics from the university of california, berkeley. david mgrew is a cisco fellow at cisco systems, inc. he is in the advanced security research group at cisco, where he works to improve security through applied research, standards, and product engineering. he has been with cisco systems, inc., since 1998. he began his career at cisco as a manager of software development engineering, where he managed the crypto and virtual private network software development team in the internet technologies division and later formed and managed the strategic cryptographic group within the ofce of chief technology ofcer. as a technical leader in foundational engineering, he developed secure realtime transport protocol (rtp) standard and reference implementation. he returned to software development engineering as manager ii and reformed and managed the advanced cryptographic development group, and concryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.78tinued to manage the group as technical leader ii before becoming a cisco fellow. prior to his career at cisco, mcgrew was a cryptographic scientist at trusted information systems, inc. he has been instrumental in the development of several cryptographic algorithms and protocols, including industry standards such as the galois/counter mode of operation for efcient and scalable authenticated encryption, and secure rtp for encrypted voice and video. he is currently listed on 42 patents, has previously served as chair of the internet research task force (irtf) crypto forum research group for years, and was active in the ietf. he earned his b.s. in physics from ohio state university and his ph.d. in theoretical nuclear physics from michigan state university. kerry mkay is a computer scientist in the cryptographic technology group at nist, where she develops cryptographic standards and performs research. her projects include topics in transport layer security, random bit generation, lightweight cryptography, and secure hash algorithm3. fred b. schneider is the samuel b. eckert professor of computer science at cornell university and chair of the department. he joined cornell™s faculty in fall 1978, having completed a ph.d. at stony brook university and a b.s. in engineering at cornell in 1975. schneider™s research has always concerned various aspects of trustworthy systemsšsystems that will perform as expected, despite failures and attacks. most recently, his interests have focused on system security. his work characterizing what policies can be enforced with various classes of defenses is widely cited, and it is seen as advancing the nascent science base for security. he is also engaged in research concerning legal and economic measures for improving system trustworthiness. schneider was elected a fellow of the american association for the advancement of science (1992), the association of computing machinery (1995), and the ieee (2008). he was named a professoratlarge at the university of tromso (norway) in 1996 and was awarded a doctor of science (honoris causa) by the university of newcastleupontyne in 2003 for his work in computer dependability and security. he received the 2012 ieee emanuel r. piore award for contributions to trustworthy computing through novel approaches to security, fault tolerance, and formal methods for concurrent and distributed systems. the nae elected schneider to membership in 2011, and the norges tekniske vitenskapsakademi (norwegian academy of technological sciences) named him a foreign member in 2010. he is currently a member of the naval studies board and the computer science and telecommunications board of the national academies, and he is founding chair of the forum on cyber resilience.cryptographic agility and interoperability: proceedings of a workshopcopyright national academy of sciences. all rights reserved.other recent reports of the computer science and  telecommunications boarda 21st century cyberphysical systems education (2016)continuing innovation in information technology: workshop report (2016)data breach aftermath and recovery for individuals and institutions: proceedings of a workshop (2016)exploring encryption and potential mechanisms for authorized government access to plaintext: proceedings of a workshop (2016)future directions for nsf advanced computing infrastructure to support u.s. science and engineering in 20172020 (2016)privacy research and best practices: summary of a workshop for the intelligence community (2016)bulk collection of signals intelligence: technical options (2015)cybersecurity dilemmas: technology, policy, and incentives: summary of discussions at the 2014 raymond and beverly sackler u.s.u.k. scientic forum (2015)interim report on 21st century cyberphysical systems education (2015)a review of the next generation air transportation system: implications and importance of system architecture (2015)telecommunications research and engineering at the communications technology laboratory of the department of commerce: meeting the nation™s telecommunications needs (2015)telecommunications research and engineering at the institute for telecommunication sciences of the department of commerce: meeting the nation™s telecommunications needs (2015)at the nexus of cybersecurity and public policy: some basic concepts and issues (2014)emerging and readily available technologies and national security: a framework for addressing ethical, legal, and societal issues (2014)future directions for nsf advanced computing infrastructure to support u.s. science and engineering in 20172020: an interim report (2014)geotargeted alerts and warnings: report of a workshop on current knowledge and research gaps (2013)professionalizing the nation™s cybersecurity workforce? criteria for future decisionmaking (2013)public response to alerts and warnings using social media: summary of a workshop on current knowledge and research gaps (2013)continuing innovation in information technology (2012)computing research for sustainability (2012)the safety challenge and promise of automotive electronics: insights from unintended acceleration (2012, with the board on energy and environmental systems and the transportation research board)the future of computing performance: game over or next level? (2011)public response to alerts and warnings on mobile devices: summary of a workshop on current knowledge and research gaps (2011)report of a workshop on the pedagogical aspects of computational thinking (2011)strategies and priorities for information technology at the centers for medicare and medicaid services (2011)wireless technology prospects and policy options (2011)limited copies of cstb reports are available free of charge from:computer science and telecommunications boardkeck center of the national academies of sciences, engineering, and medicine500 fifth street, nw, washington, dc 20001(202) 3342605/cstb@nas.eduwww.cstb.org 